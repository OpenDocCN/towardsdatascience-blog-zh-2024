- en: Framework for Optimizing Generative AI to Meet Business Needs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化生成式AI以满足业务需求的框架
- en: 原文：[https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04](https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04](https://towardsdatascience.com/framework-for-optimizing-generative-ai-to-meet-business-needs-02ac6932d55d?source=collection_archive---------2-----------------------#2024-03-04)
- en: The playbook for selecting right optimization strategy guided by clear business
    objectives to better meet the needs of customers.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择正确优化策略的手册，旨在通过明确的业务目标更好地满足客户需求。
- en: '[](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[![Sarthak
    Handa](../Images/0c75ba0f085fdb22a221705450047c40.png)](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)
    [Sarthak Handa](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[![Sarthak
    Handa](../Images/0c75ba0f085fdb22a221705450047c40.png)](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)
    [Sarthak Handa](https://medium.com/@sarthakh330?source=post_page---byline--02ac6932d55d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)
    ·11 min read·Mar 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--02ac6932d55d--------------------------------)
    ·阅读时间11分钟·2024年3月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/087c9599cd2cdaa90b7b4119bf0d4642.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/087c9599cd2cdaa90b7b4119bf0d4642.png)'
- en: 'Source: Dalle3'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Dalle3
- en: Generating human-like text and speech was once only possible in science fiction.
    But the rapid evolution of Large Language Models (LLMs) like GPT-3 and PaLM has
    brought this vision closer to reality, unlocking a range of promising business
    applications from chatbots to content creation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成类人文本和语音曾经仅存在于科幻小说中。但像GPT-3和PaLM这样的语言大模型的快速发展，将这一愿景拉近了现实，解锁了一系列有前景的商业应用，从聊天机器人到内容创作。
- en: Yet, the general-purpose foundation models often fail to meet the needs of industry
    use cases. Businesses have different requirements for their generative AI applications
    — from **performance**, **cost**, **latency** to **explainability**. Moreover,
    the nature and quantity of the data available for model training can differ significantly.
    It is therefore important for product teams to outline key business criteria for
    their generative AI application and select the right toolkit of optimization techniques
    to meet these needs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通用基础模型通常无法满足行业应用的需求。企业在生成式AI应用上有不同的要求——从**性能**、**成本**、**延迟**到**可解释性**。此外，用于模型训练的数据的性质和数量可能会有很大不同。因此，产品团队需要明确生成式AI应用的关键业务标准，并选择合适的优化技术工具包，以满足这些需求。
- en: In this post, we outline a framework for identifying and prioritizing strategic
    focus areas for your generative AI application. We will also explore popular optimization
    methods and discuss their unique strengths, ideal applications, and trade-offs
    in meeting the application requirements. With the right optimization strategy
    guided by clear business objectives, companies can develop custom AI solutions
    that balance the priorities critical to their success. Let’s dive in!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们概述了一个框架，用于识别和优先考虑生成式AI应用的战略重点领域。我们还将探讨流行的优化方法，并讨论它们在满足应用需求时的独特优势、理想应用场景和权衡取舍。在明确的业务目标指导下，采用正确的优化策略，企业可以开发定制的AI解决方案，平衡成功所需的关键优先事项。让我们开始吧！
- en: Framework to Assess Business Needs & Constraints
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估业务需求和约束的框架
- en: 'To tailor the strategy for optimizing LLMs effectively, product teams should
    start by building a deep understanding of the business objectives and the constraints
    within which they’re operating. Assess and prioritize the key dimensions listed
    below for your business use case:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地量身定制优化大型语言模型的策略，产品团队应该首先深入了解业务目标以及操作的约束条件。评估并优先考虑以下列出的关键维度，适用于您的业务场景：
- en: '![](../Images/9208171a2136d7bb407d35336b95456d.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9208171a2136d7bb407d35336b95456d.png)'
- en: SourceL Author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者
- en: '**1\. Performance Goal**: Define the measure and level of performance your
    AI needs to achieve. This could be combination of factual accuracy, alignment
    with human values, or other task-specific metrics.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 性能目标**：定义您的 AI 需要达到的性能衡量标准和水平。这可以是事实准确性、与人类价值观的一致性，或其他特定任务的指标。'
- en: '**Questions to Consider**: *What are the best dimensions for measuring performance?
    What is the minimum acceptable performance bar? How does performance align with
    user expectations in your industry?*'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*衡量性能的最佳维度是什么？最低可接受的性能标准是什么？性能如何与您所在行业的用户期望相匹配？*'
- en: '**2\. Latency Targets**: Determine the maximum response time that your application
    can afford without negatively impacting user experience. This could be especially
    important when LLMs are deployed in time-sensitive or resource-constrained scenarios
    (e.g., voice assistant, edge devices).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 延迟目标**：确定您的应用能够承受的最大响应时间，而不会对用户体验产生负面影响。在需要在时间敏感或资源受限的场景（例如语音助手、边缘设备）中部署大型语言模型时，这一点尤为重要。'
- en: '**Questions to Consider**: *How does latency impact user satisfaction and retention?
    What are industry standards for response time?*'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*延迟如何影响用户满意度和留存率？行业标准的响应时间是什么？*'
- en: '**3\. Cost Efficiency**: Evaluate the cost of operating AI with the expected
    ROI. Higher initial costs may be justified when they lead to substantial savings,
    revenue growth, or strategic benefits that outweigh investment.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 成本效益**：评估运营 AI 的成本与预期的投资回报率。较高的初始成本可能是合理的，当它们能够带来可观的节省、收入增长或战略性收益，超过了投资成本时。'
- en: '**Questions to Consider**: *How does the cost of operating LLMs impact your
    budget? How does the ROI compare with the cost of AI deployment?*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*运营大型语言模型的成本如何影响您的预算？AI 部署的投资回报率与成本如何比较？*'
- en: '**4\. Explainability & Trust:** Determine if there is a need to ensure that
    the AI decisions are easily understood by users, which is critical for building
    trust, especially in fields with stringent regulatory demands.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 可解释性与信任：** 确定是否需要确保 AI 决策易于用户理解，这对于建立信任至关重要，尤其是在有严格监管要求的领域。'
- en: '**Questions to Consider**: *Is your industry regulated, requiring transparency
    in AI’s decisions? How does explainability affect user trust and adoption?*'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*您的行业是否受到监管，要求 AI 决策透明？可解释性如何影响用户信任与采纳？*'
- en: '**5\. External Knowledge**: Assess if your AI needs access to external data
    sources to remain relevant and provide accurate responses.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 外部知识**：评估您的 AI 是否需要访问外部数据源，以保持其相关性并提供准确的响应。'
- en: '**Questions to Consider**: *Does your AI need real-time data to make decisions?*'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*您的 AI 是否需要实时数据来做出决策？*'
- en: '**6\. Data Availability**: The nature and quantity of data available for training
    your AI could widely impact optimization strategy.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. 数据可用性**：可用于训练 AI 的数据的性质和数量可能会广泛影响优化策略。'
- en: '**Questions to Consider**: *Do you have access to a large dataset for training,
    or will you need to use synthetic or augmented data? How often will you need to
    update the training data to keep the AI relevant?*'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**需要考虑的问题**：*您是否有一个大规模的数据集用于训练，还是需要使用合成数据或增强数据？您需要多频繁地更新训练数据以保持 AI 的相关性？*'
- en: 'Presented below is a table outlining **three distinct use cases** for generative
    AI applications, with a corresponding evaluation of priorities for each dimension
    within the framework:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个表格，概述了生成性 AI 应用的**三个不同使用场景**，并对每个维度在框架中的优先级进行了相应评估：
- en: '![](../Images/68e86d6781466a2dd27403007758c812.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68e86d6781466a2dd27403007758c812.png)'
- en: SourceL Author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者
- en: As you can see, the priorities and constrains can vary widely across different
    use cases.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，优先级和限制在不同的使用场景之间可能会有所不同。
- en: For instance, consider a company aiming to develop a *customer support chatbot*
    to ease the workload on human staff. In this scenario, **accuracy performance**
    and **external data integration** are of high priority to deliver responses that
    are not only factually correct but also up-to-date. While **latency** holds some
    significance, users may be willing to tolerate brief delays. Typically, such a
    company will have access to an **extensive archive** of past customer support
    interactions that can be used for training models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个公司旨在开发一个*客户支持聊天机器人*以减轻人类员工的工作负担。在这种情况下，**准确性表现**和**外部数据集成**是高优先级的，以提供既事实正确又及时的响应。虽然**延迟**具有一定的重要性，但用户可能愿意容忍短暂的延迟。通常，类似的公司会拥有一个**庞大的历史记录**，其中包含过去的客户支持互动，可以用来训练模型。
- en: In contrast, the critical application of AI for *assessing software code quality
    and risk* demands a increased focus on **factual accuracy** and **explainability**
    of the AI’s insights, often due to the potential consequences of errors. **Cost**
    and **latency** are secondary considerations in this context. This use case could
    benefit from **external data integration** in some cases, and it usually faces
    constraints regarding the availability of rich training datasets.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，人工智能在*评估软件代码质量和风险*中的关键应用要求更加关注**事实准确性**和**可解释性**，通常是由于错误可能带来的后果。在这种情况下，**成本**和**延迟**是次要考虑因素。某些情况下，这个用例可能会从**外部数据集成**中受益，但通常会面临关于丰富训练数据集可用性的限制。
- en: A solid understanding of strategic priorities and constraints associated with
    the use case can help teams develop a tailored strategy for optimizing LLMs to
    meet the unique needs of the users.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对与用例相关的战略优先事项和限制有清晰的理解，有助于团队制定量身定制的策略，优化大规模语言模型（LLMs）以满足用户的独特需求。
- en: Diving Deeper Into LLM Optimization Techniques
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探索LLM优化技术
- en: This section delves into the various optimization techniques, highlighting their
    objectives, ideal use-cases, and inherent trade-offs, particularly in the light
    of balancing the business goals discussed above.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了各种优化技术，突出了它们的目标、理想的使用场景以及固有的权衡，特别是在平衡上述业务目标的背景下。
- en: '**Techniques Table Breakdown:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**技术表格解析：**'
- en: '![](../Images/b2a403e1382512ae0bca1ffd4ed8cd8d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2a403e1382512ae0bca1ffd4ed8cd8d.png)'
- en: 'Source: Author'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者
- en: '1\. Prompt Engineering:'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 提示工程：
- en: '**Execution Complexity**: Low'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行复杂性**：低'
- en: '**When to Use**: For reshaping response and quick improvement without altering
    the model. Start with this technique to maximize a pre-trained model’s effectiveness
    before trying more complex optimization methods.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用**：用于重塑回应并快速改进，而不改变模型。开始时使用此技术，以最大化预训练模型的效能，然后再尝试更复杂的优化方法。'
- en: '**What it entails:** Prompt engineering involves crafting the input query to
    a model in a way that elicits the desired output. It requires understanding how
    the model responds to different types of instructions but doesn’t require retraining
    the model or altering its architecture. This method merely optimizes the way the
    existing model accesses and applies its pre-trained knowledge, and does not enhance
    the model’s intrinsic capabilities.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**其内容**：提示工程涉及以某种方式设计输入查询，促使模型产生所需的输出。它需要理解模型如何响应不同类型的指令，但不需要重新训练模型或更改其架构。这种方法仅优化现有模型如何访问和应用其预训练知识，并不会增强模型的内在能力。'
- en: '*“It’s like adjusting the way you ask a question to a knowledgeable friend
    to get the best possible answer.”*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*“这就像调整你向一个知识渊博的朋友提问的方式，以获得最佳答案。”*'
- en: '**Examples:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: Asking a language model to “Write a poem in the style of Shakespeare” versus
    “Write a poem” to elicit a response in a specific literary style.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求语言模型“以莎士比亚的风格写一首诗”与“写一首诗”来引出特定文学风格的回应。
- en: Providing a detailed scenario in prompt for a conversational AI to ensure the
    model understands its role as customer service agent.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个详细的场景提示给对话型人工智能，确保模型理解其作为客服代理的角色。
- en: '**Trade-offs**:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡**：'
- en: '**Trial & Error:** Designing the most effective prompt requires iterations,
    since relationship between prompt and AI output is not always intuitive.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**试错法**：设计最有效的提示需要多次迭代，因为提示与人工智能输出之间的关系并非总是直观的。'
- en: '**Output Quality:** The quality of the output is highly dependent on the design
    of the prompt, and there are limitations to the level of improvements that you
    can achieve through this method.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出质量：** 输出的质量高度依赖于提示的设计，并且通过这种方法可以实现的改进水平是有限的。'
- en: '2\. Fine-Tuning:'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 微调：
- en: '**Execution Complexity**: Medium'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行复杂度：** 中'
- en: '**When to Use**: Fine-tuning should be considered when you need the model to
    adapt to a specific domain or task that may not be well-covered by the base pre-trained
    model. It is a step towards increasing domain specific accuracy and creating a
    more specialized model that can handle domain specific data and terminology.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用：** 当你需要模型适应一个基础预训练模型可能无法很好覆盖的特定领域或任务时，应考虑使用微调。这是提高领域特定准确性并创建一个能够处理领域特定数据和术语的更专业化模型的一步。'
- en: '**What it entails:** Fine-tuning is the process of continuing the training
    of a pre-trained model on a new dataset that is representative of the target task
    or domain. This new dataset consists of input-output pairs that provide examples
    of the desired behavior. During fine-tuning, the model’s weights are updated to
    minimize the loss on this new dataset, effectively adapting the model to the new
    domain.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**其包含内容：** 微调是将预训练模型在一个新的数据集上继续训练的过程，该数据集代表目标任务或领域。这个新数据集由输入-输出对组成，提供了期望行为的示例。在微调过程中，模型的权重会被更新，以最小化在这个新数据集上的损失，从而有效地将模型适应新的领域。'
- en: '*“Think of it as giving your friend a crash course on a topic you want them
    to become an expert in; showing them multiple examples of questions that may come
    in a test and the sample answers that they are expected to respond with.”*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*“可以把它当作是给你的朋友进行一个快速课程，帮助他们成为某个主题的专家；给他们展示一些可能会出现在考试中的问题，并告诉他们预期的回答。”*'
- en: '**Examples**:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: A general-purpose language model can be fine-tuned on legal documents to improve
    its performance for reviewing such documents.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个通用的语言模型可以通过法律文件进行微调，以提高其审查此类文件的性能。
- en: An image recognition model can be fine-tuned with medical imaging datasets to
    better identify specific diseases in X-rays or MRIs.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像识别模型可以通过医学影像数据集进行微调，以更好地识别 X 光片或 MRI 中的特定疾病。
- en: '**Trade-offs**:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：**'
- en: '**Data Requirement:** Fine-tuning requires a labeled dataset that is relevant
    to the task, which can be resource-intensive to create.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据要求：** 微调需要一个与任务相关的标注数据集，创建该数据集可能会消耗大量资源。'
- en: '**Overfitting Risk:** There is a potential risk of the model becoming too specialized
    to the fine-tuning data, which can decrease its ability to generalize to other
    contexts or datasets.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合风险：** 模型可能会过于专注于微调数据，从而降低其在其他上下文或数据集上的泛化能力。'
- en: '3\. Retrieval-Augmented Generation (RAG):'
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 检索增强生成（RAG）：
- en: '**Execution Complexity**: High'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行复杂度：** 高'
- en: '**When** **to use**: RAG should be considered when there is a need for the
    AI model to access and incorporate external information to generate responses.
    This is especially relevant when the model is expected to provide up-to-date or
    highly specific information that is not contained within its pre-trained knowledge
    base.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用：** 当 AI 模型需要访问并结合外部信息来生成响应时，应考虑使用 RAG。特别是在模型需要提供最新的或高度特定的信息，而这些信息并不包含在其预训练知识库中时，RAG
    更为相关。'
- en: '**What it entails:** RAG combines the generative capabilities of an LLM with
    a retrieval system. The retrieval system queries a database, knowledge base, or
    the internet to find information relevant to the input prompt. The retrieved information
    is then provided to the language model, which incorporates this context to generate
    a richer and more accurate response. By citing the sources used by the RAG system
    to generate responses, generative AI applications can offer enhanced explainability
    to the users.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**其包含内容：** RAG 将大语言模型（LLM）的生成能力与检索系统相结合。检索系统会查询数据库、知识库或互联网，以查找与输入提示相关的信息。然后，将检索到的信息提供给语言模型，后者将这些上下文信息纳入生成更丰富、更准确的响应中。通过引用
    RAG 系统在生成响应时所使用的来源，生成式 AI 应用可以为用户提供更好的可解释性。'
- en: In the coming years, this optimization technique is expected to gain widespread
    popularity as an increasing number of products seek to leverage their latest business
    data to tailor experiences for customers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 预计在未来几年，这种优化技术将获得广泛的应用，越来越多的产品将寻求利用其最新的商业数据来为客户定制体验。
- en: '*“It’s akin to your friend being able to look up information online to answer
    questions that are outside their immediate expertise. It’s an open book exam.”*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*“这类似于你的朋友能够在线查找信息，以回答超出自己专业领域的问题。这就像是开卷考试。”*'
- en: '**Examples**:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: In a RAG-based online chatbot, retriever can pull relevant information from
    a database or the internet to provide up-to-date answers.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在基于 RAG 的在线聊天机器人中，检索器可以从数据库或互联网中提取相关信息，以提供最新的答案。
- en: A homework assistant AI could use RAG to fetch the most recent scientific data
    to answer a student’s question about climate change.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业助手 AI 可以使用 RAG 获取最新的科学数据，以回答学生关于气候变化的问题。
- en: '**Trade-offs**:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：**'
- en: '**Complex Implementation:** RAG systems require a well-integrated retrieval
    system, which can be challenging to set up and maintain.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂实现：** RAG 系统需要一个良好集成的检索系统，这可能会增加设置和维护的难度。'
- en: '**Quality of Information:** The usefulness of the generated response is highly
    dependent on the relevance and accuracy of retrieved information. If the retrieval
    system’s sources are outdated or incorrect, the responses will reflect that.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息质量：** 生成响应的有用性高度依赖于检索信息的相关性和准确性。如果检索系统的来源过时或不正确，响应也会反映这一点。'
- en: '**Slow Response Time:** Retrieving information from external source to generate
    response can add latency.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应时间慢：** 从外部来源检索信息以生成响应可能会增加延迟。'
- en: '4\. Reinforcement Learning from Human Feedback (RLHF):'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 来自人类反馈的强化学习（RLHF）：
- en: '**Execution Complexity**: Very High'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行复杂性：** 非常高'
- en: '**When to use**: RLHF should be used when the model’s outputs need to align
    closely with complex human judgments and preferences.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用：** RLHF 应在模型输出需要与复杂的人类判断和偏好紧密对齐时使用。'
- en: '**What it entails:** RLHF is a sophisticated reinforcement learning technique
    that refines a model’s behavior by incorporating human evaluations directly into
    the training process. This process typically involves collecting data from human
    operators who rank the outputs from AI on various quality metrics such as relevance,
    helpfulness, tone, etc. These data signals are then used to train a reward model,
    which guides the reinforcement learning process to produce outputs that are more
    closely aligned with human preferences.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**其内容：** RLHF 是一种复杂的强化学习技术，通过将人类评估直接融入训练过程，来优化模型的行为。这个过程通常包括收集来自人类操作员的数据，这些数据通过各种质量指标（如相关性、帮助性、语气等）对
    AI 输出进行排名。这些数据信号随后用于训练奖励模型，指导强化学习过程生成与人类偏好更加一致的输出。'
- en: '*“It’s similar to your friend learning from past conversations about what makes
    a discussion enjoyable, and using that knowledge to improve future interactions.”*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*“这类似于你的朋友从过去的对话中学习，了解什么使讨论变得愉快，并利用这些知识改善未来的互动。”*'
- en: '**Examples**:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: A social media platform could use RLHF to train a moderation bot that not only
    identifies inappropriate content but also responds to users in a way that is constructive
    and sensitive to context.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体平台可以使用 RLHF 来训练一个审查机器人，这个机器人不仅能识别不当内容，还能以建设性和对上下文敏感的方式回应用户。
- en: A virtual assistant could be fine-tuned using RLHF to provide more personalized
    and context-aware responses to user requests.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟助手可以通过 RLHF 进行微调，以便提供更个性化且具有上下文意识的用户请求响应。
- en: '**Trade-offs**:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：**'
- en: '**High Complexity:** RLHF involves complex, resource-intensive processes, including
    human feedback gathering, reward modeling, and reinforcement learning.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高复杂性：** RLHF 涉及复杂且资源密集的过程，包括人类反馈收集、奖励建模和强化学习。'
- en: '**Quality Risk:** There’s a risk of bias in the feedback data, which can lead
    to affect model quality. Ensuring consistent quality of human feedback and aligning
    the reward model with desired outcomes can be difficult.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量风险：** 反馈数据可能存在偏差，这可能会影响模型质量。确保人类反馈的一致性和将奖励模型与期望结果对齐可能会很困难。'
- en: 5\. Knowledge Distillation
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 知识蒸馏
- en: '**Execution Complexity**: Moderate to High'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行复杂性：** 中等到高'
- en: '**When to use**: Knowledge distillation is used when you need to deploy sophisticated
    models on devices with limited computational power or in applications where response
    time is critical.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用：** 知识蒸馏在需要在计算能力有限的设备上部署复杂模型或在响应时间至关重要的应用中使用。'
- en: '**What it entails:** It’s a compression technique where a smaller, more efficient
    model (known as the student) is trained to replicate the performance of a larger,
    more complex model (the teacher). The training goes beyond just learning the correct
    answers (hard targets), and involves the student trying to produce similar probabilities
    as the teacher’s predictions (soft targets). This approach enables the student
    model to capture the nuanced patterns and insights that teacher model has learned.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**它包含的内容**: 这是一种压缩技术，其中一个较小、更高效的模型（称为学生模型）被训练来复制一个较大、更复杂的模型（称为教师模型）的表现。训练不仅仅是学习正确的答案（硬目标），还包括学生模型尝试产生与教师预测相似的概率（软目标）。这种方法使得学生模型能够捕捉教师模型已学到的细微模式和洞察。'
- en: '*“This is similar to distilling the wisdom of a seasoned expert into a concise
    guidebook that a novice can use to make expert-level decisions without going through
    years of experience.”*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*“这类似于将一位经验丰富的专家的智慧提炼成一本简明的指南，初学者可以利用它做出专家级决策，而不需要经历多年的经验。”*'
- en: '**Examples**:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**:'
- en: A large-scale language model could be distilled into a smaller model that runs
    efficiently on smartphones for real-time language translation.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个大规模语言模型可以被提炼成一个较小的模型，在智能手机上高效运行，用于实时语言翻译。
- en: An image recognition system used in autonomous vehicles can be distilled into
    a light model that can run on vehicle’s onboard computer.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于自动驾驶汽车的图像识别系统可以被提炼成一个轻量级模型，能够在车辆的车载计算机上运行。
- en: '**Trade-offs**:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡**:'
- en: '**Performance vs. Size:** The distilled model may not always match the performance
    of the teacher model, leading to a potential decrease in accuracy or quality.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能与规模**: 提炼后的模型可能无法始终匹配教师模型的性能，从而可能导致准确性或质量的下降。'
- en: '**Training Complexity**: The distillation process is time-consuming and involves
    careful experimentation to ensure the student model learns effectively. It requires
    a deep understanding of models’ architectures and the ability to translate knowledge
    from one to another.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练复杂性**: 提炼过程耗时，并需要仔细的实验以确保学生模型能够有效学习。它需要对模型架构有深入的理解，并能够将知识从一个模型转移到另一个模型。'
- en: Now let’s take a look at a real-world example in action.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个实际应用中的例子。
- en: 'Example: Customer Support Chatbot'
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：客户支持聊天机器人
- en: Let’s revisit the use case of building customer support chatbot to reduce workload
    on human support staff.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视构建客户支持聊天机器人以减轻人工支持工作人员工作量的用例。
- en: '![](../Images/a9afcbd5ed94718665a3356efa82af4f.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9afcbd5ed94718665a3356efa82af4f.png)'
- en: 'Source: Dalle'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Dalle
- en: 'The requirements/ constraints included:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 包括的要求/限制条件有：
- en: '**Performance**: High Priority (Emphasis on Factual Accuracy)'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**性能**: 高优先级（强调事实准确性）'
- en: '**External Knowledge**: High Priority'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**外部知识**: 高优先级'
- en: '**Latency Targets**: Medium Priority'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**延迟目标**: 中优先级'
- en: '**Cost Efficiency**: Low Priority'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本效率**: 低优先级'
- en: '**Explainability & Trust**: Medium Priority'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释性与信任**: 中优先级'
- en: '**Data Availability**: Ample (Past Conversations Data)'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据可用性**: 丰富（过去对话数据）'
- en: With the clear understanding of business context and priorities, product builders
    can devise the most effective optimization strategy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在明确了解业务背景和优先级后，产品开发者可以制定最有效的优化策略。
- en: '**LLM Optimization Decision Steps:**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**大规模语言模型优化决策步骤**:'
- en: '**Prompt Engineering** should serve as the first step to improve chatbot’s
    initial understanding and response capabilities. However, this alone is unlikely
    to suffice for specialized domain accuracy.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示工程**应作为改善聊天机器人初步理解和响应能力的第一步。然而，仅此一步可能不足以确保专门领域的准确性。'
- en: '**Fine-Tuning** the model with historic customer conversation data is critical
    for boosting chatbot’s accuracy performance, and making the model adept at handling,
    nuanced industry-specific inquiries.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调**模型，利用历史客户对话数据，对于提高聊天机器人的准确性表现至关重要，并使模型能够熟练处理细化的行业特定问题。'
- en: Incorporating **Retrieval-Augmented Generation (RAG)** is vital for providing
    users up-to-date product information and relevant web links.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 纳入**检索增强生成（RAG）**对提供最新的产品信息和相关网站链接至关重要。
- en: While a certain degree of latency is tolerable, monitoring and potentially **optimizing
    response times** will still be advisable. Optimization strategies here could include
    caching common queries to speed up responses and using prompt engineering strategically
    to reduce unnecessary external data retrievals.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管在一定程度的延迟是可以容忍的，但监控并可能**优化响应时间**仍然是明智的。这里的优化策略可能包括缓存常见查询以加速响应，以及战略性地使用提示工程来减少不必要的外部数据检索。
- en: As you can see, a combination of strategies is often necessary to meet the specific
    demands of a use case. Flexibility in optimization strategies can be crucial,
    as requirements can change over time, and systems need to balance multiple requirements
    simultaneously.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，通常需要多种策略的结合才能满足特定用例的需求。优化策略的灵活性至关重要，因为需求可能会随时间变化，系统需要同时平衡多个需求。
- en: Conclusion
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Optimizing LLMs for a business use case is both an art and a science, which
    requires a deep understanding of the underlying technology and the objectives
    at hand. As AI continues to evolve, the choice of optimization techniques will
    become increasingly strategic, influencing not only the performance of individual
    applications but also the overall trajectory of AI’s role in society.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 针对商业用例优化大语言模型既是一门艺术，也是一门科学，这需要对底层技术和当前目标有深刻的理解。随着人工智能的不断发展，优化技术的选择将变得越来越具有战略性，影响的不仅是单个应用的性能，还包括人工智能在社会中角色的整体发展方向。
- en: Whether you’re optimizing for speed, accuracy, cost, or transparency, the techniques
    discussed above offer a toolkit for enhancing LLMs to meet the demands of tomorrow’s
    generative AI powered business applications. By thoughtfully applying these methods,
    we can create AI that’s not only effective but also responsible and attuned to
    the nuanced needs of users.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是针对速度、准确性、成本还是透明度进行优化，上述讨论的技巧都为增强大语言模型（LLM）以满足未来生成型人工智能驱动的商业应用需求提供了工具包。通过深思熟虑地应用这些方法，我们可以创造出不仅有效，而且负责任、能够精准满足用户需求的人工智能。
- en: '*Thanks for reading! If these insights resonate with you or spark new thoughts,
    let’s continue the conversation. Share your perspectives in the comments below
    or connect with me on* [***LinkedIn***](https://www.linkedin.com/)*.*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢您的阅读！如果这些见解与您产生共鸣或激发了新的想法，欢迎继续交流。请在下方评论分享您的观点，或通过* [***LinkedIn***](https://www.linkedin.com/)
    *与我联系。*'
