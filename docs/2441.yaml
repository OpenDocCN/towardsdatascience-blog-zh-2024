- en: Supercharge Your LLM Apps Using DSPy and Langfuse
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DSPy和Langfuse提升你的LLM应用程序
- en: 原文：[https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07](https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07](https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07)
- en: Build Production Grade LLM Apps with Ease
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 轻松构建生产级LLM应用
- en: '[](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[![Raghav
    Bali](../Images/49fea68f38f59d0bc39dab484b55684f.png)](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    [Raghav Bali](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[![Raghav
    Bali](../Images/49fea68f38f59d0bc39dab484b55684f.png)](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    [Raghav Bali](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    ·12 min read·Oct 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    ·阅读时间12分钟·2024年10月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/03fee566222b05ecc08e045cd78395f5.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03fee566222b05ecc08e045cd78395f5.png)'
- en: Photo by [Glen Carrie](https://unsplash.com/@glencarrie?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Glen Carrie](https://unsplash.com/@glencarrie?utm_source=medium&utm_medium=referral)
    在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**The Rise of LLMs**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**LLM的崛起**'
- en: Large Language Models (LLMs) have emerged as a transformative force, revolutionizing
    how we interact with and process information. These powerful AI models, capable
    of understanding and generating human-like text, have found applications in a
    wide array of fields, from chatbots and virtual assistants to content creation
    and data analysis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）已成为一种变革性力量，彻底改变了我们与信息的互动和处理方式。这些强大的人工智能模型能够理解和生成类似人类的文本，已经在多个领域找到了应用，从聊天机器人和虚拟助手到内容创作和数据分析。
- en: '![](../Images/ba0872bec49d5fb2b3f7ca3b00afd991.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba0872bec49d5fb2b3f7ca3b00afd991.png)'
- en: 'Usual Prompt based development workflow. Source: Author'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 常规的基于提示的开发工作流。来源：作者
- en: However, building and maintaining effective LLM-powered applications is not
    without its challenges. Prompt engineering, *the art of crafting precise instructions
    for LLMs*, can be a time-consuming and iterative process. Debugging and troubleshooting
    LLM behavior can also be complex, given the inherent “black box” nature of these
    models. Additionally, gaining insights into the performance and cost implications
    of LLM applications is crucial for optimization and scalability (key components
    for any production grade setup).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，构建和维护高效的LLM驱动应用程序并非没有挑战。提示工程，*即为LLM制定精确指令的艺术*，可能是一个耗时且反复迭代的过程。由于这些模型具有固有的“黑箱”特性，调试和故障排除LLM的行为也可能变得复杂。此外，了解LLM应用程序的性能和成本影响对于优化和可扩展性至关重要（这是任何生产环境设置的关键组件）。
- en: '**The LLM Ecosystem**'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LLM生态系统**'
- en: 'The ecosystem for LLMs is still in its nascent stages. To address some of these
    challenges, a number of innovative tools and frameworks are being developed. [DSPy](https://dspy-docs.vercel.app/)
    from Stanford University is one such unique take towards formalizing LLM-based
    app development. [Langfuse](https://langfuse.com/) on the other hand has emerged
    as an offering to streamline and operationalize aspects of LLM app maintenance.
    To put it in brief:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的生态系统仍处于初期阶段。为了解决其中的一些挑战，许多创新工具和框架正在开发中。来自斯坦福大学的[DSPy](https://dspy-docs.vercel.app/)就是一种正式化LLM应用开发的独特尝试。另一方面，[Langfuse](https://langfuse.com/)则作为一个解决方案出现，旨在简化和操作化LLM应用维护的各个方面。简而言之：
- en: '**DSPY** provides a modular and composable framework for building LLM applications,
    abstracting away the complexities of prompt engineering and enabling developers
    to focus on the core logic of their applications.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DSPY**提供了一个模块化和可组合的框架，用于构建LLM应用程序，抽象化了提示工程的复杂性，使开发人员能够专注于应用程序的核心逻辑。'
- en: '**Langfuse** offers a comprehensive observability platform for LLM apps, providing
    deep insights into model performance, cost, and user interactions.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Langfuse**提供了一个全面的可观测性平台，帮助LLM应用程序提供关于模型性能、成本和用户交互的深刻洞察。'
- en: By combining DSPy and Langfuse, developers can unlock the full potential of
    LLMs, building robust, scalable, and insightful applications that deliver exceptional
    user experiences.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合DSPy和Langfuse，开发人员可以释放LLM的全部潜力，构建强大、可扩展且具有深刻洞察力的应用程序，从而提供卓越的用户体验。
- en: Unlocking LLM Potential with DSPy
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用DSPy释放大语言模型（LLM）的潜力
- en: Language Models are extremely complex machines with capabilities to retrieve
    and reformulate information from an extremely large latent space. To guide this
    search and achieve desired responses we heavily rely on complex, long and brittle
    prompts which (at times) are very specific to certain LLMs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型是极其复杂的机器，能够从一个非常大的潜在空间中检索和重组信息。为了引导这个搜索并获得期望的响应，我们在很大程度上依赖复杂、冗长且脆弱的提示（有时这些提示对于特定的LLM来说非常具体）。
- en: Being an open area of research, teams are working from different perspectives
    to abstract and enable rapid development of LLM-enabled systems. DSPy is one such
    framework for algorithmically optimizing LLM prompts and *weights*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个开放的研究领域，各个团队从不同的角度工作，以抽象化和加速LLM系统的快速开发。DSPy就是一个针对LLM提示和*权重*进行算法优化的框架。
- en: '**Ok, You Got Me Intrigued, Tell Me More?**'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**好吧，你让我感兴趣了，能告诉我更多吗？**'
- en: The DSPy framework takes inspiration from deep learning frameworks such as *PyTorch.*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: DSPy框架从深度学习框架（如*PyTorch*）中汲取灵感。
- en: For instance, to build a deep neural network using PyTorch we simply use standard
    layers such as *convolution*, *dropout*, *linear* and attach them to optimizers
    like *Adam* and train without worrying about implementing these from scratch every
    time.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用PyTorch构建深度神经网络时，我们只需使用标准层，如*卷积*、*丢弃*、*线性*，并将其与优化器（如*Adam*）连接，然后进行训练，而不必每次都从头开始实现这些。
- en: Similarly, DSPy provides a a set of standard general purpose modules (such as
    *ChainOfThought*,*Predict*), optimizers (such as *BootstrapFewShotWithRandomSearch*)
    and helps us build systems by composing these components as layers into a *Program*
    without explicitly dealing with prompts! Neat isn’t it?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，DSPy提供了一套标准的通用模块（例如*ChainOfThought*、*Predict*）、优化器（例如*BootstrapFewShotWithRandomSearch*），并通过将这些组件作为层组合成一个*程序*来帮助我们构建系统，而无需显式处理提示！是不是很棒？
- en: '**The DSPy Building Blocks & Workflow**'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DSPy构建块与工作流**'
- en: '![](../Images/490f9851fac27b4b2ff35e95ad3565ff.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/490f9851fac27b4b2ff35e95ad3565ff.png)'
- en: 'Figure 1: (left) DSPy Building Blocks consisting of Signatures, Modules, Optimizers.
    (right) DSPy Program workflow. Source: Author'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：（左）DSPy构建块，包括签名（Signatures）、模块（Modules）、优化器（Optimizers）。(右) DSPy程序工作流。来源：作者
- en: 'As illustrated in *figure 1*, DSPy is a pytorch-like/lego-like framework for
    building LLM-based apps. Out of the box, it comes with:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图1*所示，DSPy是一个类似PyTorch/乐高积木的框架，用于构建基于LLM的应用程序。开箱即用，它包括：
- en: '[**Signatures**](https://dspy-docs.vercel.app/docs/building-blocks/signatures):
    These are specifications to define input and output behaviour of a DSPy program.
    These can be defined using *short-hand* notation (like “question -> answer” where
    the framework automatically understands question is the input while answer is
    the output) or using *declarative specification* using python classes (more on
    this in later sections)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**签名**](https://dspy-docs.vercel.app/docs/building-blocks/signatures)：这些是用于定义DSPy程序输入输出行为的规范。可以使用*简写*表示法（例如，“question
    -> answer”，框架会自动理解question是输入，answer是输出），或者使用*声明式规范*，通过Python类进行定义（后续章节将详细介绍）。'
- en: '[**Modules**](https://dspy-docs.vercel.app/docs/building-blocks/modules): These
    are layers of predefined components for powerful concepts like *Chain of Thought*,
    *ReAct* or even the simple text completion (Predict). These modules abstract underlying
    brittle prompts while still providing extensibility through custom components.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**模块**](https://dspy-docs.vercel.app/docs/building-blocks/modules)：这些是预定义组件的层，用于实现强大的概念，如*Chain
    of Thought*、*ReAct*，甚至是简单的文本完成（Predict）。这些模块抽象了底层脆弱的提示，同时仍然通过自定义组件提供可扩展性。'
- en: '[**Optimizers**](https://dspy-docs.vercel.app/docs/building-blocks/optimizers):
    These are unique to DSPy framework and draw inspiration from PyTorch itself. These
    optimizers make use of annotated datasets and evaluation metrics to help tune/optimize
    our LLM-powered DSPy programs.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**优化器**](https://dspy-docs.vercel.app/docs/building-blocks/optimizers)：这些优化器是DSPy框架特有的，灵感来源于PyTorch本身。这些优化器利用注释数据集和评估指标，帮助调优/优化基于LLM的DSPy程序。'
- en: '**Data**, **Metrics**, [**Assertions**](https://dspy-docs.vercel.app/docs/building-blocks/assertions)
    and **Trackers** are some of the other components of this framework which act
    as glue and work behind the scenes to enrich this overall framework.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据**、**指标**、[**断言**](https://dspy-docs.vercel.app/docs/building-blocks/assertions)和**跟踪器**是该框架的其他组成部分，它们像粘合剂一样在背后工作，丰富了整体框架。'
- en: To build an app/program using DSPy, we go through a modular yet step by step
    approach (as shown in *figure 1 (right)*). We first define our *task* to help
    us clearly define our program’s signature (input and output specifications). This
    is followed by building a *pipeline* program which makes use of one or more abstracted
    prompt modules, language model module as well as retrieval model modules. One
    we have all of this in place, we then proceed to have some *examples* along with
    required metrics to *evaluate* our setup which are used by *optimizers* and *assertion*
    componentsto *compile* a powerful app.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用DSPy构建应用/程序，我们采用模块化且循序渐进的方法（如*图1（右）*所示）。我们首先定义我们的*任务*，以帮助我们清晰地定义程序的签名（输入和输出规范）。接下来，我们构建一个*管道*程序，该程序利用一个或多个抽象化的提示模块、语言模型模块以及检索模型模块。完成这些步骤后，我们接着准备一些*示例*，并结合所需的指标来*评估*我们的设置，这些指标被*优化器*和*断言*组件用来*编译*一个强大的应用。
- en: Gaining LLM Insights with Langfuse
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Langfuse获取LLM洞察
- en: Langfuse is an LLM Engineering platform designed to empower developers in building,
    managing, and optimizing LLM-powered applications. While it offers both managed
    and self-hosting solutions, we’ll focus on the self-hosting option in this post,
    providing you with complete control over your LLM infrastructure.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Langfuse是一个LLM工程平台，旨在帮助开发者构建、管理和优化基于LLM的应用。虽然它提供了托管和自托管解决方案，但在本文中我们将重点介绍自托管选项，使你能够完全控制自己的LLM基础设施。
- en: '**Key Highlights of Langfuse Setup**'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Langfuse设置的主要亮点**'
- en: 'Langfuse equips you with a suite of powerful tools to streamline the LLM development
    workflow:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Langfuse为你提供了一套强大的工具，简化了LLM开发流程：
- en: '**Prompt Management:** Effortlessly version and retrieve prompts, ensuring
    reproducibility and facilitating experimentation.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示管理：** 轻松版本控制和检索提示，确保可重复性并促进实验。'
- en: '**Tracing:** Gain deep visibility into your LLM applications with detailed
    traces, enabling efficient debugging and troubleshooting. The intuitive UI out
    of the box enables teams to annotate model interactions to develop and evaluate
    training datasets.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**追踪：** 通过详细的追踪信息深入了解你的LLM应用，便于高效调试和故障排除。开箱即用的直观UI使团队能够标注模型交互，以开发和评估训练数据集。'
- en: '**Metrics:** Track crucial metrics such as cost, latency, and token usage,
    empowering you to optimize performance and control expenses.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标：** 跟踪重要指标，如成本、延迟和令牌使用情况，使你能够优化性能并控制开销。'
- en: '**Evaluation:** Capture user feedback, annotate LLM responses, and even set
    up evaluation functions to continuously assess and improve your models.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估：** 捕获用户反馈，注释LLM响应，甚至设置评估函数，持续评估并改进你的模型。'
- en: '**Datasets:** Manage and organize datasets derived from your LLM applications,
    facilitating further fine-tuning and model enhancement.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集：** 管理和组织来自LLM应用的数据集，促进进一步的微调和模型增强。'
- en: '**Effortless Setup**'
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**轻松设置**'
- en: Langfuse’s self-hosting solution is remarkably easy to set up, leveraging a
    *docker*-based architecture that you can quickly spin up using *docker compose*.
    This streamlined approach minimizes deployment complexities and allows you to
    focus on building your LLM applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Langfuse的自托管解决方案非常易于设置，利用基于*docker*的架构，你可以通过*docker compose*快速启动。这种简化的方式最小化了部署复杂性，使你能够专注于构建你的LLM应用。
- en: '**Framework Compatibility**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**框架兼容性**'
- en: Langfuse seamlessly integrates with popular LLM frameworks like [LangChain](https://www.langchain.com/),
    [LlamaIndex](https://www.llamaindex.ai/), and, of course, DSPy, making it a versatile
    tool for a wide range of LLM development frameworks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Langfuse与流行的LLM框架如[LangChain](https://www.langchain.com/)、[LlamaIndex](https://www.llamaindex.ai/)以及DSPy无缝集成，使其成为适用于各种LLM开发框架的多功能工具。
- en: The Power of DSPY + Langfuse
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DSPY + Langfuse 的强大功能
- en: By integrating Langfuse into your DSPy applications, you unlock a wealth of
    observability capabilities that enable you to monitor, analyze, and optimize your
    models in real time.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 Langfuse 集成到你的 DSPy 应用中，你可以解锁丰富的可观察性功能，使你能够实时监控、分析和优化你的模型。
- en: '**Integrating Langfuse into Your DSPy App**'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**将 Langfuse 集成到你的 DSPy 应用中**'
- en: The integration process is straightforward and involves instrumenting your DSPy
    code with Langfuse’s SDK.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 集成过程简单，涉及使用 Langfuse 的 SDK 为你的 DSPy 代码添加监控功能。
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Gaining Insights with Langfuse**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**通过 Langfuse 获得洞察**'
- en: 'Once integrated, Langfuse provides a number of actionable insights into your
    DSPy application’s behavior:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦集成，Langfuse 会提供一系列关于 DSPy 应用行为的可操作洞察：
- en: '**Trace-Based Debugging:** Follow the execution flow of your DSPY programs,
    pinpoint bottlenecks, and identify areas for improvement.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于追踪的调试：** 跟踪 DSPY 程序的执行流程，定位瓶颈，并识别需要改进的地方。'
- en: '**Performance Monitoring:** Track key metrics like latency and token usage
    to ensure optimal performance and cost-efficiency.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能监控：** 跟踪关键指标，如延迟和令牌使用量，以确保最佳的性能和成本效益。'
- en: '**User Interaction Analysis:** Understand how users interact with your LLM
    app, identify common queries, and opportunities for enhancement.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户互动分析：** 了解用户如何与 LLM 应用互动，识别常见查询，并发现优化机会。'
- en: '**Data Collection & Fine-Tuning:** Collect and annotate LLM responses, building
    valuable datasets for further fine-tuning and model refinement.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集与微调：** 收集并注解 LLM 的响应，构建有价值的数据集，以便进一步的微调和模型优化。'
- en: '**Use Cases Amplified**'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**用例增强**'
- en: 'The combination of DSPy and Langfuse is particularly important in the following
    scenarios:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: DSPy 和 Langfuse 的结合在以下场景中尤为重要：
- en: '**Complex Pipelines:** When dealing with complex DSPy pipelines involving multiple
    modules, Langfuse’s tracing capabilities become indispensable for debugging and
    understanding the flow of information.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂的管道：** 在处理涉及多个模块的复杂 DSPy 管道时，Langfuse 的追踪功能对调试和理解信息流至关重要。'
- en: '**Production Environments:** In production settings, Langfuse’s monitoring
    features ensure your LLM app runs smoothly, providing early warnings of potential
    issues while keeping an eye on costs involved.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产环境：** 在生产环境中，Langfuse 的监控功能确保你的 LLM 应用顺利运行，提前警告潜在问题，同时关注相关成本。'
- en: '**Iterative Development:** Langfuse’s evaluation and dataset management tools
    facilitate data-driven iteration, allowing you to continuously refine your LLM
    app based on real-world usage.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代开发：** Langfuse 的评估和数据集管理工具促进了基于数据的迭代，允许你根据真实世界的使用情况不断优化你的 LLM 应用。'
- en: 'The Meta Use Case: Q&A Bot for my Workshop'
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元用例：我的工作坊问答机器人
- en: 'To truly showcase the power and versatility of DSPy combined with amazing monitoring
    capabilities of langfuse, I’ve recently applied them to a unique dataset: my recent
    [LLM workshop GitHub repository](https://github.com/raghavbali/llm_workshop).
    This recent full day workshop contains a lot of material to get you started with
    LLMs. The aim of this Q&A bot was to assist participants during and after the
    workshop with answers to a host NLP and LLM related topics covered in the workshop.
    This “meta” use case not only demonstrates the practical application of these
    tools but also adds a touch of self-reflection to our exploration.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了真正展示 DSPy 与 Langfuse 强大监控能力的结合，我最近将它们应用于一个独特的数据集：我最近的 [LLM 工作坊 GitHub 仓库](https://github.com/raghavbali/llm_workshop)。这个为期一天的工作坊包含了大量的材料，帮助你入门
    LLM。这个问答机器人旨在帮助参与者在工作坊期间及其后，解答一系列与 NLP 和 LLM 相关的主题。这个“元”用例不仅展示了这些工具的实际应用，还为我们的探索增添了一些自我反思的色彩。
- en: '**The Task: Building a Q&A System**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**任务：构建问答系统**'
- en: For this exercise, we’ll leverage DSPy to build a Q&A system capable of answering
    questions about the content of my workshop (notebooks, markdown files, etc.).
    This task highlights DSPy’s ability to process and extract information from textual
    data, a crucial capability for a wide range of LLM applications. Imagine having
    a personal AI assistant (or co-pilot) that can help you recall details from your
    past weeks, identify patterns in your work, or even surface forgotten insights!
    It also presents a strong case of how such a modular setup can be easily extended
    to any other textual dataset with little to no effort.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将利用DSPy构建一个问答系统，该系统能够回答关于我的工作坊内容（笔记本、markdown文件等）的问题。这个任务突出了DSPy处理和提取文本数据中信息的能力，这是许多LLM应用中至关重要的功能。试想一下，拥有一个个人AI助手（或副驾驶），能够帮助你回忆过去几周的细节、识别工作中的模式，甚至挖掘被遗忘的洞察！这还展示了这样的模块化设置如何轻松扩展到任何其他文本数据集，几乎不需要任何努力。
- en: Let us begin by setting up the required objects for our program.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从设置程序所需的对象开始。
- en: '[PRE1]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once we have these clients and trackers in place, let us quickly add some documents
    to our collection (refer to this [notebook](https://github.com/raghavbali/llm_workshop/blob/main/module_04/06_supercharge_llm_apps.ipynb)
    for a detailed walk through of how I prepared this dataset in the first place).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们设置好了这些客户端和跟踪器，就让我们快速地向我们的文档库中添加一些文档（有关我如何准备这个数据集的详细操作，请参阅此[笔记本](https://github.com/raghavbali/llm_workshop/blob/main/module_04/06_supercharge_llm_apps.ipynb)）。
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The next step is to simply connect our chromadb retriever to the DSPy framework.
    The following snippet created a RM object and tests if the retrieval works as
    intended.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是简单地将我们的chromadb检索器连接到DSPy框架。以下代码片段创建了一个RM对象，并测试检索是否按预期工作。
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output looks promising given that without any intervention, Chromadb is
    able to fetch the most relevant documents.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来很有前景，因为在没有任何干预的情况下，Chromadb能够获取最相关的文档。
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The final step is to piece all of this together in preparing a DSPy program.
    For our simple Q&A use-case we make prepare a standard RAG program leveraging
    Chromadb as our retriever and Langfuse as our tracker. The following snippet presents
    the pytorch-like approach of developing LLM based apps without worrying about
    brittle prompts!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将所有这些内容整合在一起，准备一个DSPy程序。对于我们的简单问答用例，我们准备了一个标准的RAG程序，利用Chromadb作为检索器，Langfuse作为跟踪器。以下代码片段展示了开发基于LLM的应用程序的类似pytorch的方法，无需担心脆弱的提示！
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Phew! Wasn’t that quick and simple to do? Let us now put this into action using
    a few sample questions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 呼！这不是很简单快速吗？现在让我们通过几个示例问题来实际应用它。
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output is indeed quite on point and serves the purpose of being an assistant
    to this workshop material answering questions and guiding the attendees nicely.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确实非常准确，达到了作为此工作坊材料助手的目的，能够回答问题并很好地引导参与者。
- en: '![](../Images/12ca0eec049875f56d6d90960d5d0723.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12ca0eec049875f56d6d90960d5d0723.png)'
- en: 'Figure 2: Output from the DSPy RAG program. Source: Author'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：DSPy RAG程序的输出。来源：作者
- en: '**The Langfuse Advantage**'
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Langfuse的优势**'
- en: Earlier in this article we discussed how langfuse completes the picture by enabling
    us to monitor LLM usage and improve upon other aspects of the pipeline. The amazing
    integration of langfuse as a tracker glues everything behind the scenes with a
    nice and easy to use interface. For our current setting, the langfuse dashboard
    presents a quick summary of our LLM usage.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的前面部分，我们讨论了langfuse是如何通过让我们监控LLM的使用情况并改进管道的其他方面来完善整个流程的。langfuse作为跟踪工具的惊人集成，通过一个简单易用的界面将所有内容在后台串联起来。在当前的设置中，langfuse仪表板呈现了我们LLM使用情况的快速总结。
- en: '![](../Images/3a36ba9137c9c67f2dd44f0ce7d93a6e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a36ba9137c9c67f2dd44f0ce7d93a6e.png)'
- en: 'Figure 3: Langfuse Dashboard. Source: Author'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：Langfuse仪表板。来源：作者
- en: The dashboard is complete with metrics such as number of traces, overall costs
    and even token usage (which is quite handy when it comes to optimize your pipelines).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板包括如追踪数量、总成本甚至令牌使用等指标（这些在优化管道时非常有用）。
- en: '**Insights and Benefits**'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**洞察与好处**'
- en: Langfuse’s utility does not end with top-level dashboard of metrics. It provides
    trace level details (as shown in *figure 4*).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Langfuse的实用性不仅仅局限于顶层的度量仪表板。它还提供了追踪级别的详细信息（如*图4*所示）。
- en: '![](../Images/f1112de13de787eefe9a218d498d391f.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1112de13de787eefe9a218d498d391f.png)'
- en: 'Figure 4: Langfuse trace detail complete with cost, token usage, prompt as
    well as the model response. Source: Author.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：Langfuse跟踪详细信息，包括成本、令牌使用、提示以及模型响应。来源：作者。
- en: This interface is a gateway to a number of other aspects that are very useful
    in terms of iterating and improving LLM based apps. The first and foremost capability
    is to prepare datasets based on real world usage. These datasets can be used for
    fine-tuning LLMs, optimizing DSPy programs, etc. *Figure 5* illustrates how simple
    it is to define a dataset from the web-UI itself and then add traces (input request
    along with model’s response) as needed to the dataset.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个界面是通往多个其他方面的门户，这些方面在迭代和改进基于 LLM 的应用程序时非常有用。首先要提到的功能是基于实际使用情况准备数据集。这些数据集可用于微调
    LLM、优化 DSPy 程序等。*图 5* 展示了如何从网页 UI 本身轻松定义数据集，并根据需要将跟踪信息（输入请求及模型响应）添加到数据集中。
- en: '![](../Images/db0f7ed09c4a08f8a23720d6a454efbf.png)![](../Images/3f9796f949790f848308a49a81f1545c.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db0f7ed09c4a08f8a23720d6a454efbf.png)![](../Images/3f9796f949790f848308a49a81f1545c.png)'
- en: 'Figure 5: (left) Create a new dataset from the web UI directly by simply providing
    the required details such as dataset name and description. (right) traces can
    be added to datasets at the click of a button. Source: Author'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：（左）通过提供数据集名称和描述等必要信息，直接从网页 UI 创建一个新的数据集。（右）可以通过点击按钮将跟踪记录添加到数据集中。来源：作者
- en: Similar to dataset creation and adding data points to it, langfuse simplifies
    creation of metrics and annotating datapoints. *Figure 6* illustrates how simple
    it is to do the same at the click of a couple of buttons.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于数据集创建和向其中添加数据点，langfuse 简化了指标的创建和数据点的标注。*图 6* 展示了只需点击几下按钮，便能轻松完成相同操作。
- en: '![](../Images/acf9c98a20ba18ecf4c51ad3fca07835.png)![](../Images/e19a439a5374973c5f72cd3a492f60ca.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acf9c98a20ba18ecf4c51ad3fca07835.png)![](../Images/e19a439a5374973c5f72cd3a492f60ca.png)'
- en: 'Figure 6: Metric creation and annotation in Langfuse. Source: Author'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：Langfuse 中的指标创建与标注。来源：作者
- en: Once we have a dataset prepared, langfuse provides a straightforward SDK to
    use it in your language of of preference. The following snippet makes use of get_dataset
    utility from langfuse to get to a couple of traces we added to the sample dataset.
    We then use LLaMA 3.1 to power our DSPy RAG program with just one line change
    (talk about modularity ;) ).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好数据集，langfuse 提供了一个简单的 SDK，让你在你喜欢的编程语言中使用它。以下代码片段使用 langfuse 的 get_dataset
    工具，从我们添加到示例数据集中的几个跟踪记录中获取数据。然后，我们仅通过一行代码修改，便能用 LLaMA 3.1 来驱动我们的 DSPy RAG 程序（说到模块化
    ;)）。
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As shown in the above snippet, we simply iterate through the datapoints in our
    dataset and visually compare the output from both models (see *figure 7*). Using
    Langfuse SDK we attach experiment observations along with new traces and evaluation
    scores very easily.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如上面的代码片段所示，我们只需遍历数据集中的数据点，直观地比较两个模型的输出（参见 *图 7*）。使用 Langfuse SDK，我们可以轻松地将实验观察结果、新的跟踪记录和评估分数附加上去。
- en: '![](../Images/5f7debc33c398b2935a9540b2ca759f1.png)![](../Images/24ffbca1793fbdb95aea3c357b05b398.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f7debc33c398b2935a9540b2ca759f1.png)![](../Images/24ffbca1793fbdb95aea3c357b05b398.png)'
- en: 'Figure 7: Output from LLaMA3.1 powered RAG using datapoints from dataset prepared
    using Langfuse'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：使用 Langfuse 准备的数据集中的数据点为 LLaMA3.1 驱动的 RAG 提供输出
- en: The output presented in figure 7 clearly shows how LLaMA3.1 powered RAG does
    answer the questions but strays from the instructions of being brief. This can
    be easily captured using DSPy assertions as well as scores can be tracked using
    langfuse SDK for further improvements.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 中展示的输出清晰地显示了 LLaMA3.1 驱动的 RAG 确实能回答问题，但在简洁性方面偏离了指令。这可以通过 DSPy 断言轻松捕捉到，同时可以使用
    langfuse SDK 跟踪分数，以便进行进一步改进。
- en: Conclusion
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this rapidly evolving landscape of LLM applications, tools like DSPy and
    Langfuse emerge as invaluable allies for developers & data scientists. DSPy streamlines
    the development process, empowering you to build sophisticated LLM applications
    with ease and efficiency. Meanwhile, Langfuse provides the crucial observability
    layer, enabling you to gain deep insights into your models’ performance, optimize
    resource utilization, and continuously improve your applications based on real-world
    data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个快速发展的 LLM 应用领域，像 DSPy 和 Langfuse 这样的工具成为开发者和数据科学家的宝贵助手。DSPy 简化了开发过程，使你能够轻松高效地构建复杂的
    LLM 应用。同时，Langfuse 提供了关键的可观察性层，让你深入了解模型的表现，优化资源利用，并基于真实数据持续改进应用。
- en: The combination of DSPY and Langfuse unlocks a world of possibilities, allowing
    you to harness the full potential of LLMs. Whether you’re building Q&A systems,
    content generators, or any other LLM-powered application, these tools provide
    the foundation for creating robust, scalable, and insightful solutions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: DSPY 和 Langfuse 的结合解锁了无限可能，让你能够充分发挥 LLM 的潜力。无论你是在构建问答系统、内容生成器，还是其他任何基于 LLM 的应用，这些工具都为创建强大、可扩展和富有洞察力的解决方案奠定了基础。
- en: As I’ve demonstrated through the meta usecase of answering questions for my
    recent LLM-workshop, DSPy and Langfuse can be applied creatively to extract valuable
    insights from even your own personal data. The possibilities are truly endless.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在最近的 LLM 工作坊的元使用案例——回答问题——中所展示的，DSPy 和 Langfuse 可以创造性地应用于从你自己的个人数据中提取有价值的洞察。可能性真的无穷无尽。
- en: I encourage you to explore these tools/frameworks in your own projects. Interested
    folks can leverage the comprehensive hands-on driven workshop material for more
    topics on my [GitHub repository](https://github.com/raghavbali/llm_workshop).
    With these tools at your disposal, you’re well-equipped to ***supercharge*** your
    LLM applications and stay ahead in the ever-evolving world of AI.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你在自己的项目中探索这些工具/框架。感兴趣的朋友可以通过我的[GitHub 仓库](https://github.com/raghavbali/llm_workshop)获取更多关于其他主题的综合性实践工作坊资料。借助这些工具，你将能够***大幅提升***你的
    LLM 应用，并在快速发展的 AI 领域中保持领先。
- en: '*Disclaimer: I have no affiliations, financial or otherwise, with any of the
    tools, products, or companies mentioned in this article. The opinions and insights
    shared are based solely on personal experience and independent research.*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：我与文中提到的任何工具、产品或公司没有任何关联，不论是财务上的还是其他方面的。这些观点和见解仅基于个人经验和独立研究。*'
- en: References
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[DSPy](https://dspy-docs.vercel.app/)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DSPy](https://dspy-docs.vercel.app/)'
- en: '[Langfuse](https://langfuse.com/)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Langfuse](https://langfuse.com/)'
- en: '[](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
    [## GitHub - raghavbali/llm_workshop: LLM Workshop 2024'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
    [## GitHub - raghavbali/llm_workshop: LLM Workshop 2024'
- en: LLM Workshop 2024\. Contribute to raghavbali/llm_workshop development by creating
    an account on GitHub.
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM Workshop 2024。通过在 GitHub 上创建账户，参与 raghavbali/llm_workshop 项目的开发。
- en: github.com](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
