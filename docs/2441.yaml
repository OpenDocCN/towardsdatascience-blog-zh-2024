- en: Supercharge Your LLM Apps Using DSPy and Langfuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07](https://towardsdatascience.com/supercharge-your-llm-apps-using-dspy-and-langfuse-f83c02ba96a1?source=collection_archive---------2-----------------------#2024-10-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Build Production Grade LLM Apps with Ease
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[![Raghav
    Bali](../Images/49fea68f38f59d0bc39dab484b55684f.png)](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    [Raghav Bali](https://medium.com/@Rghv_Bali?source=post_page---byline--f83c02ba96a1--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f83c02ba96a1--------------------------------)
    ·12 min read·Oct 7, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03fee566222b05ecc08e045cd78395f5.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Glen Carrie](https://unsplash.com/@glencarrie?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**The Rise of LLMs**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have emerged as a transformative force, revolutionizing
    how we interact with and process information. These powerful AI models, capable
    of understanding and generating human-like text, have found applications in a
    wide array of fields, from chatbots and virtual assistants to content creation
    and data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ba0872bec49d5fb2b3f7ca3b00afd991.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Usual Prompt based development workflow. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: However, building and maintaining effective LLM-powered applications is not
    without its challenges. Prompt engineering, *the art of crafting precise instructions
    for LLMs*, can be a time-consuming and iterative process. Debugging and troubleshooting
    LLM behavior can also be complex, given the inherent “black box” nature of these
    models. Additionally, gaining insights into the performance and cost implications
    of LLM applications is crucial for optimization and scalability (key components
    for any production grade setup).
  prefs: []
  type: TYPE_NORMAL
- en: '**The LLM Ecosystem**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ecosystem for LLMs is still in its nascent stages. To address some of these
    challenges, a number of innovative tools and frameworks are being developed. [DSPy](https://dspy-docs.vercel.app/)
    from Stanford University is one such unique take towards formalizing LLM-based
    app development. [Langfuse](https://langfuse.com/) on the other hand has emerged
    as an offering to streamline and operationalize aspects of LLM app maintenance.
    To put it in brief:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DSPY** provides a modular and composable framework for building LLM applications,
    abstracting away the complexities of prompt engineering and enabling developers
    to focus on the core logic of their applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Langfuse** offers a comprehensive observability platform for LLM apps, providing
    deep insights into model performance, cost, and user interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By combining DSPy and Langfuse, developers can unlock the full potential of
    LLMs, building robust, scalable, and insightful applications that deliver exceptional
    user experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Unlocking LLM Potential with DSPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Language Models are extremely complex machines with capabilities to retrieve
    and reformulate information from an extremely large latent space. To guide this
    search and achieve desired responses we heavily rely on complex, long and brittle
    prompts which (at times) are very specific to certain LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Being an open area of research, teams are working from different perspectives
    to abstract and enable rapid development of LLM-enabled systems. DSPy is one such
    framework for algorithmically optimizing LLM prompts and *weights*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ok, You Got Me Intrigued, Tell Me More?**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The DSPy framework takes inspiration from deep learning frameworks such as *PyTorch.*
  prefs: []
  type: TYPE_NORMAL
- en: For instance, to build a deep neural network using PyTorch we simply use standard
    layers such as *convolution*, *dropout*, *linear* and attach them to optimizers
    like *Adam* and train without worrying about implementing these from scratch every
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, DSPy provides a a set of standard general purpose modules (such as
    *ChainOfThought*,*Predict*), optimizers (such as *BootstrapFewShotWithRandomSearch*)
    and helps us build systems by composing these components as layers into a *Program*
    without explicitly dealing with prompts! Neat isn’t it?
  prefs: []
  type: TYPE_NORMAL
- en: '**The DSPy Building Blocks & Workflow**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/490f9851fac27b4b2ff35e95ad3565ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: (left) DSPy Building Blocks consisting of Signatures, Modules, Optimizers.
    (right) DSPy Program workflow. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in *figure 1*, DSPy is a pytorch-like/lego-like framework for
    building LLM-based apps. Out of the box, it comes with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Signatures**](https://dspy-docs.vercel.app/docs/building-blocks/signatures):
    These are specifications to define input and output behaviour of a DSPy program.
    These can be defined using *short-hand* notation (like “question -> answer” where
    the framework automatically understands question is the input while answer is
    the output) or using *declarative specification* using python classes (more on
    this in later sections)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Modules**](https://dspy-docs.vercel.app/docs/building-blocks/modules): These
    are layers of predefined components for powerful concepts like *Chain of Thought*,
    *ReAct* or even the simple text completion (Predict). These modules abstract underlying
    brittle prompts while still providing extensibility through custom components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Optimizers**](https://dspy-docs.vercel.app/docs/building-blocks/optimizers):
    These are unique to DSPy framework and draw inspiration from PyTorch itself. These
    optimizers make use of annotated datasets and evaluation metrics to help tune/optimize
    our LLM-powered DSPy programs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data**, **Metrics**, [**Assertions**](https://dspy-docs.vercel.app/docs/building-blocks/assertions)
    and **Trackers** are some of the other components of this framework which act
    as glue and work behind the scenes to enrich this overall framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To build an app/program using DSPy, we go through a modular yet step by step
    approach (as shown in *figure 1 (right)*). We first define our *task* to help
    us clearly define our program’s signature (input and output specifications). This
    is followed by building a *pipeline* program which makes use of one or more abstracted
    prompt modules, language model module as well as retrieval model modules. One
    we have all of this in place, we then proceed to have some *examples* along with
    required metrics to *evaluate* our setup which are used by *optimizers* and *assertion*
    componentsto *compile* a powerful app.
  prefs: []
  type: TYPE_NORMAL
- en: Gaining LLM Insights with Langfuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Langfuse is an LLM Engineering platform designed to empower developers in building,
    managing, and optimizing LLM-powered applications. While it offers both managed
    and self-hosting solutions, we’ll focus on the self-hosting option in this post,
    providing you with complete control over your LLM infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: '**Key Highlights of Langfuse Setup**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Langfuse equips you with a suite of powerful tools to streamline the LLM development
    workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt Management:** Effortlessly version and retrieve prompts, ensuring
    reproducibility and facilitating experimentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracing:** Gain deep visibility into your LLM applications with detailed
    traces, enabling efficient debugging and troubleshooting. The intuitive UI out
    of the box enables teams to annotate model interactions to develop and evaluate
    training datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics:** Track crucial metrics such as cost, latency, and token usage,
    empowering you to optimize performance and control expenses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evaluation:** Capture user feedback, annotate LLM responses, and even set
    up evaluation functions to continuously assess and improve your models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Datasets:** Manage and organize datasets derived from your LLM applications,
    facilitating further fine-tuning and model enhancement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Effortless Setup**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Langfuse’s self-hosting solution is remarkably easy to set up, leveraging a
    *docker*-based architecture that you can quickly spin up using *docker compose*.
    This streamlined approach minimizes deployment complexities and allows you to
    focus on building your LLM applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**Framework Compatibility**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Langfuse seamlessly integrates with popular LLM frameworks like [LangChain](https://www.langchain.com/),
    [LlamaIndex](https://www.llamaindex.ai/), and, of course, DSPy, making it a versatile
    tool for a wide range of LLM development frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: The Power of DSPY + Langfuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By integrating Langfuse into your DSPy applications, you unlock a wealth of
    observability capabilities that enable you to monitor, analyze, and optimize your
    models in real time.
  prefs: []
  type: TYPE_NORMAL
- en: '**Integrating Langfuse into Your DSPy App**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The integration process is straightforward and involves instrumenting your DSPy
    code with Langfuse’s SDK.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Gaining Insights with Langfuse**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once integrated, Langfuse provides a number of actionable insights into your
    DSPy application’s behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trace-Based Debugging:** Follow the execution flow of your DSPY programs,
    pinpoint bottlenecks, and identify areas for improvement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance Monitoring:** Track key metrics like latency and token usage
    to ensure optimal performance and cost-efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User Interaction Analysis:** Understand how users interact with your LLM
    app, identify common queries, and opportunities for enhancement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Collection & Fine-Tuning:** Collect and annotate LLM responses, building
    valuable datasets for further fine-tuning and model refinement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use Cases Amplified**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The combination of DSPy and Langfuse is particularly important in the following
    scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complex Pipelines:** When dealing with complex DSPy pipelines involving multiple
    modules, Langfuse’s tracing capabilities become indispensable for debugging and
    understanding the flow of information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production Environments:** In production settings, Langfuse’s monitoring
    features ensure your LLM app runs smoothly, providing early warnings of potential
    issues while keeping an eye on costs involved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Iterative Development:** Langfuse’s evaluation and dataset management tools
    facilitate data-driven iteration, allowing you to continuously refine your LLM
    app based on real-world usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Meta Use Case: Q&A Bot for my Workshop'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To truly showcase the power and versatility of DSPy combined with amazing monitoring
    capabilities of langfuse, I’ve recently applied them to a unique dataset: my recent
    [LLM workshop GitHub repository](https://github.com/raghavbali/llm_workshop).
    This recent full day workshop contains a lot of material to get you started with
    LLMs. The aim of this Q&A bot was to assist participants during and after the
    workshop with answers to a host NLP and LLM related topics covered in the workshop.
    This “meta” use case not only demonstrates the practical application of these
    tools but also adds a touch of self-reflection to our exploration.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Task: Building a Q&A System**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this exercise, we’ll leverage DSPy to build a Q&A system capable of answering
    questions about the content of my workshop (notebooks, markdown files, etc.).
    This task highlights DSPy’s ability to process and extract information from textual
    data, a crucial capability for a wide range of LLM applications. Imagine having
    a personal AI assistant (or co-pilot) that can help you recall details from your
    past weeks, identify patterns in your work, or even surface forgotten insights!
    It also presents a strong case of how such a modular setup can be easily extended
    to any other textual dataset with little to no effort.
  prefs: []
  type: TYPE_NORMAL
- en: Let us begin by setting up the required objects for our program.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Once we have these clients and trackers in place, let us quickly add some documents
    to our collection (refer to this [notebook](https://github.com/raghavbali/llm_workshop/blob/main/module_04/06_supercharge_llm_apps.ipynb)
    for a detailed walk through of how I prepared this dataset in the first place).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to simply connect our chromadb retriever to the DSPy framework.
    The following snippet created a RM object and tests if the retrieval works as
    intended.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The output looks promising given that without any intervention, Chromadb is
    able to fetch the most relevant documents.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The final step is to piece all of this together in preparing a DSPy program.
    For our simple Q&A use-case we make prepare a standard RAG program leveraging
    Chromadb as our retriever and Langfuse as our tracker. The following snippet presents
    the pytorch-like approach of developing LLM based apps without worrying about
    brittle prompts!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Phew! Wasn’t that quick and simple to do? Let us now put this into action using
    a few sample questions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The output is indeed quite on point and serves the purpose of being an assistant
    to this workshop material answering questions and guiding the attendees nicely.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/12ca0eec049875f56d6d90960d5d0723.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Output from the DSPy RAG program. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Langfuse Advantage**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this article we discussed how langfuse completes the picture by enabling
    us to monitor LLM usage and improve upon other aspects of the pipeline. The amazing
    integration of langfuse as a tracker glues everything behind the scenes with a
    nice and easy to use interface. For our current setting, the langfuse dashboard
    presents a quick summary of our LLM usage.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a36ba9137c9c67f2dd44f0ce7d93a6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Langfuse Dashboard. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: The dashboard is complete with metrics such as number of traces, overall costs
    and even token usage (which is quite handy when it comes to optimize your pipelines).
  prefs: []
  type: TYPE_NORMAL
- en: '**Insights and Benefits**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Langfuse’s utility does not end with top-level dashboard of metrics. It provides
    trace level details (as shown in *figure 4*).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f1112de13de787eefe9a218d498d391f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Langfuse trace detail complete with cost, token usage, prompt as
    well as the model response. Source: Author.'
  prefs: []
  type: TYPE_NORMAL
- en: This interface is a gateway to a number of other aspects that are very useful
    in terms of iterating and improving LLM based apps. The first and foremost capability
    is to prepare datasets based on real world usage. These datasets can be used for
    fine-tuning LLMs, optimizing DSPy programs, etc. *Figure 5* illustrates how simple
    it is to define a dataset from the web-UI itself and then add traces (input request
    along with model’s response) as needed to the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db0f7ed09c4a08f8a23720d6a454efbf.png)![](../Images/3f9796f949790f848308a49a81f1545c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: (left) Create a new dataset from the web UI directly by simply providing
    the required details such as dataset name and description. (right) traces can
    be added to datasets at the click of a button. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to dataset creation and adding data points to it, langfuse simplifies
    creation of metrics and annotating datapoints. *Figure 6* illustrates how simple
    it is to do the same at the click of a couple of buttons.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acf9c98a20ba18ecf4c51ad3fca07835.png)![](../Images/e19a439a5374973c5f72cd3a492f60ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Metric creation and annotation in Langfuse. Source: Author'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a dataset prepared, langfuse provides a straightforward SDK to
    use it in your language of of preference. The following snippet makes use of get_dataset
    utility from langfuse to get to a couple of traces we added to the sample dataset.
    We then use LLaMA 3.1 to power our DSPy RAG program with just one line change
    (talk about modularity ;) ).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the above snippet, we simply iterate through the datapoints in our
    dataset and visually compare the output from both models (see *figure 7*). Using
    Langfuse SDK we attach experiment observations along with new traces and evaluation
    scores very easily.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5f7debc33c398b2935a9540b2ca759f1.png)![](../Images/24ffbca1793fbdb95aea3c357b05b398.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Output from LLaMA3.1 powered RAG using datapoints from dataset prepared
    using Langfuse'
  prefs: []
  type: TYPE_NORMAL
- en: The output presented in figure 7 clearly shows how LLaMA3.1 powered RAG does
    answer the questions but strays from the instructions of being brief. This can
    be easily captured using DSPy assertions as well as scores can be tracked using
    langfuse SDK for further improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this rapidly evolving landscape of LLM applications, tools like DSPy and
    Langfuse emerge as invaluable allies for developers & data scientists. DSPy streamlines
    the development process, empowering you to build sophisticated LLM applications
    with ease and efficiency. Meanwhile, Langfuse provides the crucial observability
    layer, enabling you to gain deep insights into your models’ performance, optimize
    resource utilization, and continuously improve your applications based on real-world
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The combination of DSPY and Langfuse unlocks a world of possibilities, allowing
    you to harness the full potential of LLMs. Whether you’re building Q&A systems,
    content generators, or any other LLM-powered application, these tools provide
    the foundation for creating robust, scalable, and insightful solutions.
  prefs: []
  type: TYPE_NORMAL
- en: As I’ve demonstrated through the meta usecase of answering questions for my
    recent LLM-workshop, DSPy and Langfuse can be applied creatively to extract valuable
    insights from even your own personal data. The possibilities are truly endless.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to explore these tools/frameworks in your own projects. Interested
    folks can leverage the comprehensive hands-on driven workshop material for more
    topics on my [GitHub repository](https://github.com/raghavbali/llm_workshop).
    With these tools at your disposal, you’re well-equipped to ***supercharge*** your
    LLM applications and stay ahead in the ever-evolving world of AI.
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer: I have no affiliations, financial or otherwise, with any of the
    tools, products, or companies mentioned in this article. The opinions and insights
    shared are based solely on personal experience and independent research.*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[DSPy](https://dspy-docs.vercel.app/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Langfuse](https://langfuse.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
    [## GitHub - raghavbali/llm_workshop: LLM Workshop 2024'
  prefs: []
  type: TYPE_NORMAL
- en: LLM Workshop 2024\. Contribute to raghavbali/llm_workshop development by creating
    an account on GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/raghavbali/llm_workshop.git?source=post_page-----f83c02ba96a1--------------------------------)
  prefs: []
  type: TYPE_NORMAL
