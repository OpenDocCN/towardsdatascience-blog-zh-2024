- en: 'Time Series Forecasting in the Age of GenAI: Make Gradient Boosting Behaves
    like LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/time-series-forecasting-in-the-age-of-genai-make-gradient-boosting-behaves-like-llms-674d9e22e1ce?source=collection_archive---------2-----------------------#2024-07-04](https://towardsdatascience.com/time-series-forecasting-in-the-age-of-genai-make-gradient-boosting-behaves-like-llms-674d9e22e1ce?source=collection_archive---------2-----------------------#2024-07-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Applying zero-shot forecasting with standard machine learning models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@cerlymarco?source=post_page---byline--674d9e22e1ce--------------------------------)[![Marco
    Cerliani](../Images/ddc7943bfef3a7d59e36cc525dd5442e.png)](https://medium.com/@cerlymarco?source=post_page---byline--674d9e22e1ce--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--674d9e22e1ce--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--674d9e22e1ce--------------------------------)
    [Marco Cerliani](https://medium.com/@cerlymarco?source=post_page---byline--674d9e22e1ce--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--674d9e22e1ce--------------------------------)
    ·6 min read·Jul 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ceb06c99955f15e354c0d7778da1f3f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [David Menidrey](https://unsplash.com/@cazault?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The rise of Generative AI and Large Language Models (LLMs) has fascinated the
    entire world initializing a revolution in various fields. While the primary focus
    of this kind of technology has been on text sequences, further attention is now
    being given to expanding their capabilities to handle and process data formats
    beyond just text inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Like in most AI areas, time series forecasting is also not immune to the advent
    of LLMs, but this may be a good deal for all. Time series modeling is known to
    be more like an art, where results are highly dependent on prior domain knowledge
    and adequate tuning. On the contrary, LLMs are appreciated for being task-agnostic,
    holding enormous potential in using their knowledge to solve variegated tasks
    coming from different domains. From the union of these two areas, the new frontier
    of time series forecasting models can be born which in the future will be able
    to achieve previously unthinkable results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b0435374fc806308f6b0d1b2eb8f1787.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image by the author]'
  prefs: []
  type: TYPE_NORMAL
