<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>From Retrieval to Intelligence: Exploring RAG, Agent+RAG, and Evaluation with TruLens</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>From Retrieval to Intelligence: Exploring RAG, Agent+RAG, and Evaluation with TruLens</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-retrieval-to-intelligence-exploring-rag-agent-rag-and-evaluation-with-trulens-3c518af836ce?source=collection_archive---------3-----------------------#2024-12-03">https://towardsdatascience.com/from-retrieval-to-intelligence-exploring-rag-agent-rag-and-evaluation-with-trulens-3c518af836ce?source=collection_archive---------3-----------------------#2024-12-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="34a9" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Unlocking the Power of GPT-Generated Private Corpora</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vladyslav.fliahin_1709?source=post_page---byline--3c518af836ce--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vladyslav Fliahin" class="l ep by dd de cx" src="../Images/9ef0a1bc4adaf23c887fa8a9a8563384.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*VBCEqSW88-jbdhuP"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--3c518af836ce--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vladyslav.fliahin_1709?source=post_page---byline--3c518af836ce--------------------------------" rel="noopener follow">Vladyslav Fliahin</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--3c518af836ce--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">21 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">7</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="f358" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Introduction</h1><p id="4db0" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Nowadays the world has a lot of good foundation models to start your custom application with (gpt-4o, Sonnet, Gemini, Llama3.2, Gemma, Ministral, etc.). These models know everything about history, geography, and Wikipedia articles but still have weaknesses. Mostly there are two of them: level of details (e.g., the model knows about BMW, what it does, model names, and some more general info; but the model fails in case you ask about number of sales for Europe or details of the specific engine part) and the recent knowledge (e.g., Llama3.2 model or Ministral release; foundation models are trained at a certain point in time and have some knowledge cutoff date, after which the model doesn’t know anything).</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc od"><img src="../Images/c2c6dbbf6a87facdbce8a1d9d85528df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p0pcMd7oCOFomei5"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Photo by <a class="af ou" href="https://unsplash.com/@jaredd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jaredd Craig</a> on <a class="af ou" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e183" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">This article is focused on both issues, describing the situation of imaginary companies that were founded before the knowledge cutoff, while some information was changed recently.</p><p id="fb60" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To address both issues we will use the RAG technique and the LlamaIndex framework. The idea behind the Retrieval Augmented Generation is to supply the model with the most relevant information during the answer generation. This way we can have a DB with custom data, which the model will be able to utilize. To further assess the system performance we will incorporate the TruLens library and the RAG Triad metrics.</p><blockquote class="pa pb pc"><p id="632b" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Mentioning the knowledge cutoff, this issue is addressed via google-search tools. Nevertheless, we can’t completely substitute the knowledge cutoff with the search tool. To understand this, imagine 2 ML specialists: first knows everything about the current GenAI state, and the second switched from the GenAI to the classic computer vision 6 month ago. If you ask them both the same question about how to use the recent GenAI models, it will take significantly different amount of search requests. The first one will know all about this, but maybe will double-check some specific commands. And the second will have to read a whole bunch of detailed articles to understand what’s going on first, what this model is doing, what is under the hood, and only after that he will be able to answer.</p><p id="eb34" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Basically it is like comparison of the field-expert and some general specialists, when one can answer quickly, and the second should go googling because he doesn’t know all the details the first does.</p><p id="c3c2" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">The main point here is that a lot of googling provides comparable answer within a significantly longer timeframe. For in chat-like applications users won’t wait minutes for the model to google smth. In addition, not all the information is open and can be googled.</p></blockquote><h1 id="d5e4" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Data</h1><p id="f51e" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Right now it may be hard to find a dataset, that is not previously used in the training data of the foundation model. Almost all the data is indexed and used during the large models' pretraining stage.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc pe"><img src="../Images/7ef81bd855098bc93007f6790f622f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RdJvbWcTsG9h4TPW"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image generated by the author using AI (Bing)</figcaption></figure><p id="05b6" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">That’s why I decided to generate the one myself. For this purpose, I used the <em class="pd">chatgpt-4o-latest</em> via the OpenAI UI and several continuous prompts (all of them are similar to the ones below):</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="39a1" class="pj mk fq pg b bg pk pl l pm pn">Generate me a private corpus with some details mentioning the imagined Ukraine Boats Inc.<br/>A list of products, prices, responsible stuff, etc.<br/>I want to use it as my private corpus for the RAG use-case<br/>You can generate really a lot of the text. The more the better.</span></pre><pre class="po pf pg ph bp pi bb bk"><span id="b830" class="pj mk fq pg b bg pk pl l pm pn">Yeah, proceed with partnerships, legal policies, competitions participated<br/>Maybe info about where we manufacture our boats (and add some custom ones)</span></pre><pre class="po pf pg ph bp pi bb bk"><span id="b3c3" class="pj mk fq pg b bg pk pl l pm pn">add client use studies</span></pre><p id="059c" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">As a result, I generated a private corpus for 4 different companies. Below are the calculations of the tokens to better embrace the dataset size.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="4322" class="pj mk fq pg b bg pk pl l pm pn"># Number of tokens using the `o200k_base` tokenizer (gpt-4o/gpt-4o-mini)<br/>nova-drive-motors.txt: 2757<br/>aero-vance-aviation.txt: 1860<br/>ukraine-boats.txt: 3793<br/>city-solve.txt: 3826<br/>total_tokens=12236</span></pre><p id="e84b" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Below you can read the beginning of the Ukraine Boats Inc. description:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="593a" class="pj mk fq pg b bg pk pl l pm pn">## **Ukraine Boats Inc.**<br/>**Corporate Overview:**<br/>Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine. The company prides itself on blending traditional craftsmanship with modern technology to serve clients worldwide. Founded in 2005, the company has grown to be a leader in the boating industry, specializing in recreational, commercial, and luxury vessels.<br/> - -<br/>### **Product Lineup**<br/>#### **Recreational Boats:**<br/>1. **WaveRunner X200**<br/>- **Description:** A sleek speedboat designed for water sports enthusiasts. Equipped with advanced navigation and safety features.<br/>- **Price:** $32,000<br/>- **Target Market:** Young adventurers and watersport lovers.<br/>- **Features:**<br/>- Top speed of 85 mph<br/>- Built-in GPS with autopilot mode<br/>- Seating capacity: 4<br/>- Lightweight carbon-fiber hull<br/>2. **AquaCruise 350**<br/>- **Description:** A versatile motorboat ideal for fishing, family trips, and casual cruising.<br/>- **Price:** $45,000<br/>- **Features:**<br/>- 12-person capacity<br/>- Dual 300HP engines<br/>- Modular interiors with customizable seating and storage<br/>- Optional fishing equipment upgrades<br/>3. **SolarGlide EcoBoat**<br/>- **Description:** A solar-powered boat for environmentally conscious customers.<br/>- **Price:** $55,000<br/>- **Features:**<br/>- Solar panel roof with 12-hour charge life<br/>- Zero emissions<br/>- Maximum speed: 50 mph<br/>- Silent motor technology<br/> - -<br/>…</span></pre><p id="65bc" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">The complete private corpus can be found on <a class="af ou" href="https://github.com/Vlad-Fliahin/rag-llamaindex" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><p id="b0dc" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">For the purpose of the evaluation dataset, I have also asked the model to generate 10 questions (about Ukraine Boats Inc. only) based on the given corpus.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="fe9e" class="pj mk fq pg b bg pk pl l pm pn">based on the whole corpus above, generate 10 questions and answers for them pass them into the python native data structure</span></pre><p id="8b56" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Here is the dataset obtained:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="62d1" class="pj mk fq pg b bg pk pl l pm pn">[<br/>    {<br/>        "question": "What is the primary focus of Ukraine Boats Inc.?",<br/>        "answer": "Ukraine Boats Inc. specializes in manufacturing high-quality recreational, luxury, and commercial boats, blending traditional craftsmanship with modern technology."<br/>    },<br/>    {<br/>        "question": "What is the price range for recreational boats offered by Ukraine Boats Inc.?",<br/>        "answer": "Recreational boats range from $32,000 for the WaveRunner X200 to $55,000 for the SolarGlide EcoBoat."<br/>    },<br/>    {<br/>        "question": "Which manufacturing facility focuses on bespoke yachts and customizations?",<br/>        "answer": "The Lviv Custom Craft Workshop specializes in bespoke yachts and high-end customizations, including handcrafted woodwork and premium materials."<br/>    },<br/>    {<br/>        "question": "What is the warranty coverage offered for boats by Ukraine Boats Inc.?",<br/>        "answer": "All boats come with a 5-year warranty for manufacturing defects, while engines are covered under a separate 3-year engine performance guarantee."<br/>    },<br/>    {<br/>        "question": "Which client used the Neptune Voyager catamaran, and what was the impact on their business?",<br/>        "answer": "Paradise Resorts International used the Neptune Voyager catamarans, resulting in a 45% increase in resort bookings and winning the 'Best Tourism Experience' award."<br/>    },<br/>    {<br/>        "question": "What award did the SolarGlide EcoBoat win at the Global Marine Design Challenge?",<br/>        "answer": "The SolarGlide EcoBoat won the 'Best Eco-Friendly Design' award at the Global Marine Design Challenge in 2022."<br/>    },<br/>    {<br/>        "question": "How has the Arctic Research Consortium benefited from the Poseidon Explorer?",<br/>        "answer": "The Poseidon Explorer enabled five successful Arctic research missions, increased data collection efficiency by 60%, and improved safety in extreme conditions."<br/>    },<br/>    {<br/>        "question": "What is the price of the Odessa Opulence 5000 luxury yacht?",<br/>        "answer": "The Odessa Opulence 5000 luxury yacht starts at $1,500,000."<br/>    },<br/>    {<br/>        "question": "Which features make the WaveRunner X200 suitable for watersports?",<br/>        "answer": "The WaveRunner X200 features a top speed of 85 mph, a lightweight carbon-fiber hull, built-in GPS, and autopilot mode, making it ideal for watersports."<br/>    },<br/>    {<br/>        "question": "What sustainability initiative is Ukraine Boats Inc. pursuing?",<br/>        "answer": "Ukraine Boats Inc. is pursuing the Green Maritime Initiative (GMI) to reduce the carbon footprint by incorporating renewable energy solutions in 50% of their fleet by 2030."<br/>    }<br/>]</span></pre><p id="fbc3" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Now, when we have the private corpus and the dataset of Q&amp;A pairs, we can insert our data into some suitable storage.</p><h1 id="47a4" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Data propagation</h1><p id="b173" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">We can utilize a variety of databases for the RAG use case, but for this project and the possible handling of future relations, I integrated the Neo4j DB into our solution. Moreover, Neo4j provides a free instance after registration.</p><p id="9764" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Now, let’s start preparing nodes. First, we instantiate an embedding model. We used the 256 vector dimensions because some recent tests showed that bigger vector dimensions led to scores with less variance (and that’s not what we need). As an embedding model, we used the <em class="pd">text-embedding-3-small </em>model.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="a268" class="pj mk fq pg b bg pk pl l pm pn"># initialize models<br/>embed_model = OpenAIEmbedding(<br/>  model=CFG['configuration']['models']['embedding_model'],<br/>  api_key=os.getenv('AZURE_OPENAI_API_KEY'),<br/>  dimensions=CFG['configuration']['embedding_dimension']<br/>)</span></pre><p id="1466" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">After that, we read the corpus:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="6e05" class="pj mk fq pg b bg pk pl l pm pn"># get documents paths<br/>document_paths = [Path(CFG['configuration']['data']['raw_data_path']) / document for document in CFG['configuration']['data']['source_docs']]<br/><br/># initialize a file reader<br/>reader = SimpleDirectoryReader(input_files=document_paths)<br/><br/># load documents into LlamaIndex Documents<br/>documents = reader.load_data()</span></pre><p id="e02d" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Furthermore, we utilize the SentenceSplitter to convert documents into separate nodes. These nodes will be stored in the Neo4j database.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="1839" class="pj mk fq pg b bg pk pl l pm pn">neo4j_vector = Neo4jVectorStore(<br/>    username=CFG['configuration']['db']['username'],<br/>    password=CFG['configuration']['db']['password'],<br/>    url=CFG['configuration']['db']['url'],<br/>    embedding_dimension=CFG['configuration']['embedding_dimension'],<br/>    hybrid_search=CFG['configuration']['hybrid_search']<br/>)<br/><br/># setup context<br/>storage_context = StorageContext.from_defaults(<br/>    vector_store=neo4j_vector<br/>)<br/><br/># populate DB with nodes<br/>index = VectorStoreIndex(nodes, storage_context=storage_context, show_progress=True)</span></pre><blockquote class="pa pb pc"><p id="5e3c" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Hybrid search is turned off for now. This is done deliberately to outline the performance of the vector-search algorithm.</p></blockquote><p id="ad0b" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">We are all set, and now we are ready to go to the querying pipeline.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc pp"><img src="../Images/bc8ff5e24813361091f8339a8bdf89fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IQinQaw2ElehpHSlyKHA-w.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image created by the author</figcaption></figure><h1 id="c607" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Pipeline</h1><p id="fce3" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">The RAG technique may be implemented as a standalone solution or as a part of an agent. The agent is supposed to handle all the chat history, tools handling, reasoning, and output generation. Below we will have a walkthrough on how to implement the query engines (standalone RAG) and the agent approach (the agent will be able to call the RAG as one of its tools).</p><p id="61aa" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Often when we talk about the chat models, the majority will pick the OpenAI models without considering the alternatives. We will outline the usage of RAG on OpenAI models and the Meta Llama 3.2 models. Let’s benchmark which one performs better.</p><blockquote class="pa pb pc"><p id="248e" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">All the configuration parameters are moved to the pyproject.toml file.</p></blockquote><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="b504" class="pj mk fq pg b bg pk pl l pm pn">[configuration]<br/>similarity_top_k = 10<br/>vector_store_query_mode = "default"<br/>similarity_cutoff = 0.75<br/>response_mode = "compact"<br/>distance_strategy = "cosine"<br/>embedding_dimension = 256<br/>chunk_size = 512<br/>chunk_overlap = 128<br/>separator = " "<br/>max_function_calls = 2<br/>hybrid_search = false<br/><br/>[configuration.data]<br/>raw_data_path = "../data/companies"<br/>dataset_path = "../data/companies/dataset.json"<br/>source_docs = ["city-solve.txt", "aero-vance-aviation.txt", "nova-drive-motors.txt", "ukraine-boats.txt"]<br/><br/>[configuration.models]<br/>llm = "gpt-4o-mini"<br/>embedding_model = "text-embedding-3-small"<br/>temperature = 0<br/>llm_hf = "meta-llama/Llama-3.2-3B-Instruct"<br/>context_window = 8192<br/>max_new_tokens = 4096<br/>hf_token = "hf_custom-token"<br/>llm_evaluation = "gpt-4o-mini"<br/><br/>[configuration.db]<br/>url = "neo4j+s://custom-url"<br/>username = "neo4j"<br/>password = "custom-password"<br/>database = "neo4j" <br/>index_name = "article" # change if you want to load the new data that won't intersect with the previous uploads<br/>text_node_property = "text"</span></pre><p id="a9a6" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">The common step for both models is connecting to the existing vector index inside the neo4j.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="a5f7" class="pj mk fq pg b bg pk pl l pm pn"># connect to the existing neo4j vector index<br/>vector_store = Neo4jVectorStore(<br/>  username=CFG['configuration']['db']['username'],<br/>  password=CFG['configuration']['db']['password'],<br/>  url=CFG['configuration']['db']['url'],<br/>  embedding_dimension=CFG['configuration']['embedding_dimension'],<br/>  distance_strategy=CFG['configuration']['distance_strategy'],<br/>  index_name=CFG['configuration']['db']['index_name'],<br/>  text_node_property=CFG['configuration']['db']['text_node_property']<br/>)<br/>index = VectorStoreIndex.from_vector_store(vector_store)</span></pre><h1 id="a401" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">OpenAI</h1><p id="7b29" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Firstly we should initialize the OpenAI models needed. We will use the <em class="pd">gpt-4o-mini</em> as a language model and the same embedding model. We specify the LLM and embedding model for the Settings object. This way we don’t have to pass these models further. The LlamaIndex will try to parse the LLM from the Settings if it’s needed.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="0fd7" class="pj mk fq pg b bg pk pl l pm pn"># initialize models<br/>llm = OpenAI(<br/>  api_key=os.getenv('AZURE_OPENAI_API_KEY'),<br/>  model=CFG['configuration']['models']['llm'],<br/>  temperature=CFG['configuration']['models']['temperature']<br/>)<br/>embed_model = OpenAIEmbedding(<br/>  model=CFG['configuration']['models']['embedding_model'],<br/>  api_key=os.getenv('AZURE_OPENAI_API_KEY'),<br/>  dimensions=CFG['configuration']['embedding_dimension']<br/>)<br/><br/>Settings.llm = llm<br/>Settings.embed_model = embed_model</span></pre><h2 id="b2b2" class="pq mk fq bf ml pr ps pt mo pu pv pw mr no px py pz ns qa qb qc nw qd qe qf qg bk">QueryEngine</h2><p id="d423" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">After that, we can create a default query engine from the existing vector index:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="500b" class="pj mk fq pg b bg pk pl l pm pn"># create query engine<br/>query_engine = index.as_query_engine()</span></pre><p id="3fcb" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Furthermore, we can obtain the RAG logic using simply a query() method. In addition, we printed the list of the source nodes, retrieved from the DB, and the final LLM response.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="2596" class="pj mk fq pg b bg pk pl l pm pn"># custom question<br/>response = query_engine.query("What is the primary focus of Ukraine Boats Inc.?")<br/><br/># get similarity scores<br/>for node in response.source_nodes:<br/>  print(f'{node.node.id_}, {node.score}')<br/><br/># predicted answer<br/>print(response.response)</span></pre><p id="d657" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Here is the sample output:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="a068" class="pj mk fq pg b bg pk pl l pm pn">ukraine-boats-3, 0.8536546230316162<br/>ukraine-boats-4, 0.8363556861877441<br/><br/><br/>The primary focus of Ukraine Boats Inc. is designing, manufacturing, and selling luxury and eco-friendly boats, with a strong emphasis on customer satisfaction and environmental sustainability.</span></pre><p id="0a02" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">As you can see, we created custom node ids, so that we can understand the file from which it was taken and the ordinal id of the chunk. We can be much more specific with the query engine attitude using the low-level LlamaIndex API:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="061b" class="pj mk fq pg b bg pk pl l pm pn"># custom retriever<br/>retriever = VectorIndexRetriever(<br/>  index=index,<br/>  similarity_top_k=CFG['configuration']['similarity_top_k'],<br/>  vector_store_query_mode=CFG['configuration']['vector_store_query_mode']<br/>)<br/><br/># similarity threshold<br/>similarity_postprocessor = SimilarityPostprocessor(similarity_cutoff=CFG['configuration']['similarity_cutoff'])<br/><br/># custom response synthesizer<br/>response_synthesizer = get_response_synthesizer(<br/>  response_mode=CFG['configuration']['response_mode']<br/>)<br/><br/># combine custom query engine<br/>query_engine = RetrieverQueryEngine(<br/>  retriever=retriever,<br/>  node_postprocessors=[similarity_postprocessor],<br/>  response_synthesizer=response_synthesizer<br/>)</span></pre><p id="54c4" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Here we specified custom retriever, similarity postprocessor, and refinement stage actions.</p><p id="489f" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">For further customization, you can create custom wrappers around any of the LlamaIndex components to make them more specific and aligned with your needs.</p><h1 id="3054" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Agent</h1><p id="38b4" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">To implement a RAG-based agent inside the LlamaIndex, we need to use one of the predefined AgentWorkers. We will stick to the OpenAIAgentWorker, which uses OpenAI’s LLM as its brain. Moreover, we wrapped our query engine from the previous part into the QueryEngineTool, which the agent may pick based on the tool’s description.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="3a1b" class="pj mk fq pg b bg pk pl l pm pn">AGENT_SYSTEM_PROMPT = "You are a helpful human assistant. You always call the retrieve_semantically_similar_data tool before answering any questions. If the answer to the questions couldn't be found using the tool, just respond with `Didn't find relevant information`."<br/>TOOL_NAME = "retrieve_semantically_similar_data"<br/>TOOL_DESCRIPTION = "Provides additional information about the companies. Input: string"<br/><br/># agent worker<br/>agent_worker = OpenAIAgentWorker.from_tools(<br/>    [<br/>        QueryEngineTool.from_defaults(<br/>            query_engine=query_engine,<br/>            name=TOOL_NAME,<br/>            description=TOOL_DESCRIPTION,<br/>            return_direct=False,<br/>        )<br/>    ],<br/>    system_prompt=AGENT_SYSTEM_PROMPT,<br/>    llm=llm,<br/>    verbose=True,<br/>    max_function_calls=CFG['configuration']['max_function_calls']<br/>)</span></pre><p id="0c4b" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To further use the agent, we need an AgentRunner. The runner is more like an orchestrator, handling top-level interactions and state, while the worker performs concrete actions, like tool and LLM usage.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="67f1" class="pj mk fq pg b bg pk pl l pm pn"># agent runner<br/>agent = AgentRunner(agent_worker=agent_worker)</span></pre><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc qh"><img src="../Images/04e3fcb64f2ec18ce7919ec1e2cf1c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VywweB5tCnegW0L-.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image taken from the <a class="af ou" href="https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner/" rel="noopener ugc nofollow" target="_blank">LlamaIndex docs</a></figcaption></figure><p id="997b" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To test the user-agent interactions efficiently, I implemented a simple chat-like interface:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="088a" class="pj mk fq pg b bg pk pl l pm pn">while True:<br/>  # get user input<br/>  current_message = input('Insert your next message:')<br/>  print(f'{datetime.now().strftime("%H:%M:%S.%f")[:-3]}|User: {current_message}')<br/><br/>  response = agent.chat(current_message)<br/>  print(f'{datetime.now().strftime("%H:%M:%S.%f")[:-3]}|Agent: {response.response}')</span></pre><p id="a864" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Here is a sample of the chat:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="8f92" class="pj mk fq pg b bg pk pl l pm pn">Insert your next message: Hi<br/>15:55:43.101|User: Hi<br/>Added user message to memory: Hi<br/>15:55:43.873|Agent: Didn't find relevant information.<br/>Insert your next message: Do you know anything about the city solve?<br/>15:56:24.751|User: Do you know anything about the city solve?<br/>Added user message to memory: Do you know anything about the city solve?<br/>=== Calling Function ===<br/>Calling function: retrieve_semantically_similar_data with args: {"input":"city solve"}<br/>Got output: Empty Response<br/>========================<br/><br/>15:56:37.267|Agent: Didn't find relevant information.<br/>Insert your next message: What is the primary focus of Ukraine Boats Inc.?<br/>15:57:36.122|User: What is the primary focus of Ukraine Boats Inc.?<br/>Added user message to memory: What is the primary focus of Ukraine Boats Inc.?<br/>=== Calling Function ===<br/>Calling function: retrieve_semantically_similar_data with args: {"input":"Ukraine Boats Inc."}<br/>Got output: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine. Founded in 2005, the company specializes in recreational, commercial, and luxury vessels, blending traditional craftsmanship with modern technology. It has established a strong market presence in Europe, North America, and Asia, supported by partnerships with distribution companies like Baltic Marine Distributors in Germany, OceanCraft LLC in the USA, and Yokohama SeaTech in Japan.<br/><br/>The company is organized into several departments, including Engineering, Sales and Marketing, Production, and Customer Service, each with specific responsibilities to ensure efficient operations and customer satisfaction. Ukraine Boats Inc. is committed to sustainability through initiatives like the Green Maritime Initiative, aiming to reduce its carbon footprint by incorporating renewable energy solutions in its fleet.<br/><br/>The product lineup includes recreational boats such as the WaveRunner X200 and AquaCruise 350, luxury yachts like the Odessa Opulence 5000, and commercial vessels such as the Maritime Hauler 7000. The company also offers customization options, maintenance plans, and a range of accessories to enhance the boating experience.<br/><br/>With a focus on innovation and quality, Ukraine Boats Inc. has received accolades in various marine design competitions and continues to expand its global footprint while maintaining a commitment to environmental compliance and customer service excellence.<br/>========================<br/><br/>15:57:49.505|Agent: The primary focus of Ukraine Boats Inc. is the manufacturing and supplying of high-quality boats and maritime solutions. Based in Odessa, Ukraine, the company specializes in recreational, commercial, and luxury vessels, combining traditional craftsmanship with modern technology. They are committed to sustainability and have initiatives like the Green Maritime Initiative to reduce their carbon footprint. Their product lineup includes various types of boats, and they also offer customization options and maintenance plans.<br/>Insert your next message: Do you know anything about the government company city solve?<br/>15:59:02.830|User: Do you know anything about the government company city solve?<br/>Added user message to memory: Do you know anything about the government company city solve?<br/>=== Calling Function ===<br/>Calling function: retrieve_semantically_similar_data with args: {"input":"government company city solve"}<br/>Got output: CitySolve Municipal Services is a government-owned and operated entity founded in 1988, headquartered in New Urbania, USA. Its mission is to ensure a livable, sustainable, and efficient city by providing prompt solutions to residents' everyday needs. The company focuses on various critical service areas, including waterworks and drainage, parks and greenery management, roads and sidewalks, waste management, public safety infrastructure, and urban utilities. CitySolve emphasizes core values such as responsiveness, reliability, accountability, and sustainability, and utilizes modern technologies to enhance its operations and community impact.<br/>========================<br/><br/>15:59:12.693|Agent: CitySolve Municipal Services is a government-owned and operated entity founded in 1988, headquartered in New Urbania, USA. Its mission is to ensure a livable, sustainable, and efficient city by providing prompt solutions to residents' everyday needs. The company focuses on critical service areas such as waterworks and drainage, parks and greenery management, roads and sidewalks, waste management, public safety infrastructure, and urban utilities. CitySolve emphasizes core values like responsiveness, reliability, accountability, and sustainability, and it utilizes modern technologies to enhance its operations and community impact.<br/>Insert your next message: Thanks<br/>15:59:28.761|User: Thanks<br/>Added user message to memory: Thanks<br/>15:59:30.327|Agent: Didn't find relevant information.</span></pre><blockquote class="pa pb pc"><p id="6f56" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">What we can see, is that for the correct vector search you need to specify the input questions with more details, that can be semantically matched.</p></blockquote><h1 id="6916" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Open source</h1><p id="64ae" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">As an open source model, we have utilized the <em class="pd">meta-llama/Llama-3.2–3B-Instruct.</em> This choice was based on the model latency &amp; performance trade-off. First things first we need to authenticate our HuggingFace account via an access token.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="1b3e" class="pj mk fq pg b bg pk pl l pm pn"># Use your token here<br/>login(token=CFG['configuration']['models']['hf_token'])</span></pre><p id="dc7a" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To use the Llama as an LLM inside the LlamaIndex, we need to create a model wrapper. We will use a single NVIDIA GeForce RTX 3090 to serve our Llama 3.2 model.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="5a2e" class="pj mk fq pg b bg pk pl l pm pn">SYSTEM_PROMPT = """You are an AI assistant that answers questions in a friendly manner, based on the given source documents. Here are some rules you always follow:<br/>- Generate human readable output, avoid creating output with gibberish text.<br/>- Generate only the requested output, don't include any other language before or after the requested output.<br/>- Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.<br/>- Generate professional language typically used in business documents in North America.<br/>- Never generate offensive or foul language.<br/>"""<br/><br/>query_wrapper_prompt = PromptTemplate(<br/>    "&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n" + SYSTEM_PROMPT + "&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;{query_str}&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;"<br/>)<br/><br/>llm = HuggingFaceLLM(<br/>    context_window=CFG['configuration']['models']['context_window'],<br/>    max_new_tokens=CFG['configuration']['models']['max_new_tokens'],<br/>    generate_kwargs={"temperature": CFG['configuration']['models']['temperature'], "do_sample": False},<br/>    query_wrapper_prompt=query_wrapper_prompt,<br/>    tokenizer_name=CFG['configuration']['models']['llm_hf'],<br/>    model_name=CFG['configuration']['models']['llm_hf'],<br/>    device_map="cuda:0",<br/>    model_kwargs={"torch_dtype": torch.bfloat16}<br/>)<br/><br/>Settings.llm = llm</span></pre><h1 id="9158" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">QueryEngine</h1><p id="77d8" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">The interfaces are the same. Example output is below:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="4409" class="pj mk fq pg b bg pk pl l pm pn">ukraine-boats-3, 0.8536546230316162<br/>ukraine-boats-4, 0.8363556861877441<br/><br/><br/>The primary focus of Ukraine Boats Inc. is designing, manufacturing, and selling luxury and eco-friendly boats, with a strong emphasis on customer satisfaction and environmental sustainability.</span></pre><h1 id="21de" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Agent</h1><p id="8ca7" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">For the OpenAI models, LlamaIndex has a special agent wrapper designed, but for the open-source models we should use another wrapper. We selected ReActAgent, which iteratively does reasoning and acting until the final response is ready.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="d799" class="pj mk fq pg b bg pk pl l pm pn">agent_worker = ReActAgentWorker.from_tools(<br/>    [<br/>        QueryEngineTool.from_defaults(<br/>            query_engine=query_engine,<br/>            name=TOOL_NAME,<br/>            description=TOOL_DESCRIPTION,<br/>            return_direct=False,<br/>        )<br/>    ],<br/>    llm=llm,<br/>    verbose=True,<br/>    chat_history=[ChatMessage(content=AGENT_SYSTEM_PROMPT, role="system")]<br/>)<br/><br/># agent runner<br/>agent = AgentRunner(agent_worker=agent_worker)</span></pre><p id="5e3d" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Below is the same discussion but with a different Agent under the hood:</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="304e" class="pj mk fq pg b bg pk pl l pm pn">Insert your next message: Hi<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>16:04:29.117|User: Hi<br/>Thought: The current language of the user is: English. I need to use a tool to help me answer the question.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': 'hello world', 'num_beams': 5}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: Empty Response<br/>Thought: I still need more information to answer the question. The tool did not provide any useful output. I'll try to gather more context.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': 'hello world', 'num_beams': 5}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: Empty Response<br/>Thought: I still don't have enough information to answer the question. The tool did not provide any useful output. I'll try to gather more context.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': 'hello world', 'num_beams': 5}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: Empty Response<br/>Thought: I'm starting to think that the tool is not the best approach to answer this question. The user's input "hello world" is very general and the tool is not providing any useful output. I'll try to think of a different approach.<br/>Answer: Hello, how can I assist you today?<br/>16:04:37.764|Agent: Hello, how can I assist you today?<br/>Insert your next message: Do you know anything about the city solve?<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>16:05:08.756|User: Do you know anything about the city solve?<br/>Thought: The current language of the user is: English. I need to use a tool to help me answer the question.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': 'solve city'}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: <br/><br/>CitySolve Municipal Services is the lifeline of New Urbania, addressing a wide range of city-level concerns and providing prompt solutions to residents' everyday needs.<br/>Thought: I can answer without using any more tools. I'll use the user's language to answer<br/>Answer: CitySolve Municipal Services is a city-level organization that provides solutions to residents' everyday needs in New Urbania.<br/>16:05:13.003|Agent: CitySolve Municipal Services is a city-level organization that provides solutions to residents' everyday needs in New Urbania.<br/>Insert your next message: What is the primary focus of Ukraine Boats Inc.?<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>16:05:34.892|User: What is the primary focus of Ukraine Boats Inc.?<br/>Thought: The current language of the user is: English. I need to use a tool to help me answer the question.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': 'Ukraine Boats Inc.'}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: <br/><br/>Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine. The company prides itself on blending traditional craftsmanship with modern technology to serve clients worldwide. Founded in 2005, the company has grown to be a leader in the boating industry, specializing in recreational, commercial, and luxury vessels.<br/><br/>The company has successfully delivered a range of boats and solutions to various clients, including Blue Horizon Fisheries, Azure Seas Luxury Charters, Coastal Safety Patrol, EcoTrade Logistics, Team HydroBlitz Racing, and Paradise Resorts International. These clients have reported significant benefits from working with Ukraine Boats Inc., including increased efficiency, reduced costs, and enhanced customer satisfaction.<br/><br/>Ukraine Boats Inc. offers a range of products and services, including luxury yachts, commercial boats, and accessories. The company's products are designed to meet the specific needs of each client, and its team of experts works closely with clients to ensure that every boat is tailored to their requirements.<br/><br/>Some of the company's notable products include the Odessa Opulence 5000, a state-of-the-art luxury yacht, and the Maritime Hauler 7000, a robust cargo ship. The company also offers boat customization packages, annual maintenance plans, and other services to support its clients' needs.<br/><br/>Overall, Ukraine Boats Inc. is a trusted and reliable partner for clients seeking high-quality boats and maritime solutions.<br/>Thought: I can answer without using any more tools. I'll use the user's language to answer<br/>Answer: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine, blending traditional craftsmanship with modern technology to serve clients worldwide.<br/>16:05:53.311|Agent: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine, blending traditional craftsmanship with modern technology to serve clients worldwide.<br/>Insert your next message: Do you know anything about the government company city solve?<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>16:06:09.949|User: Do you know anything about the government company city solve?<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Thought: The current language of the user is English. I need to use a tool to help me answer the question.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'input': AttributedDict([('title', 'CitySolve'), ('type', 'string')])}<br/>Observation: Error: 2 validation errors for QueryStartEvent<br/>query.str<br/>  Input should be a valid string [type=string_type, input_value=AttributedDict([('title',...'), ('type', 'string')]), input_type=AttributedDict]<br/>    For further information visit https://errors.pydantic.dev/2.9/v/string_type<br/>query.QueryBundle.query_str<br/>  Field required [type=missing, input_value=AttributedDict([('title',...'), ('type', 'string')]), input_type=AttributedDict]<br/>    For further information visit https://errors.pydantic.dev/2.9/v/missing<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: Error: Could not parse output. Please follow the thought-action-input format. Try again.<br/>Thought: I understand that the tool retrieve_semantically_similar_data requires a specific input format. I will make sure to follow the correct format.<br/>Action: retrieve_semantically_similar_data<br/>Action Input: {'title': 'CitySolve', 'type': 'string'}<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>Observation: <br/><br/>CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.<br/>Thought: I can answer without using any more tools. I'll use the user's language to answer<br/>Answer: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.<br/>16:06:17.799|Agent: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.<br/>Insert your next message: Thanks<br/>Setting `pad_token_id` to `eos_token_id`:None for open-end generation.<br/>16:06:34.232|User: Thanks<br/>Thought: I can answer without using any more tools. I'll use the user's language to answer<br/>Answer: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.<br/>16:06:35.734|Agent: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.</span></pre><p id="639a" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">As we can see, the agents reason differently. Given the same questions, the two models decided to query the tool differently. The second agent failed with the tool once, but it’s more an issue of the tool description than the agent itself. Both of them provided the user with valuable answers, which is the final goal of the RAG approach.</p><blockquote class="pa pb pc"><p id="2e73" class="nf ng pd nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">In addition, there are a lof of different agent wrappers that you can apply on top of your LLM. They may significantly change a way the model interacts with the world.</p></blockquote><h1 id="2d0a" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Evaluation</h1><p id="e617" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">To evaluate the RAG, nowadays there are a lot of frameworks available. One of them is the TruLens. Overall RAG performance is assessed using the so-called RAG Triad (answer relevance, context relevance, and groundedness).</p><p id="9fbc" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To estimate relevances and groundedness we are going to utilize the LLMs. The LLMs will act as judges, which will score the answers based on the information given.</p><p id="60f6" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">TruLens itself is a convenient tool to measure system performance on a metric level and analyze the specific record’s assessments. Here is the leaderboard UI view:</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc qi"><img src="../Images/2e1c68ce16e4ac9f4241f8c34976dc31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OHPe9bYRpIKXhfKIEK9GVA.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image created by the author</figcaption></figure><p id="a71f" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Below is the per-record table of assessments, where you can review all the internal processes being invoked.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc qj"><img src="../Images/5ea278b031342962a1ef3402002cab0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M74gn-100TGEC0HpzN9QGg.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image created by the author</figcaption></figure><p id="f0b5" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To get even more details, you can review the execution process for a specific record.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc qk"><img src="../Images/1cb2793fe322a2f00f79e0d864937cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5d1szNj81qWL9UlCBRXzg.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image created by the author</figcaption></figure><p id="9328" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">To implement the RAG Triad evaluation, first of all, we have to define the experiment name and the model provider. We will utilize the <em class="pd">gpt-4o-mini</em> model for the evaluation.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="da07" class="pj mk fq pg b bg pk pl l pm pn">experiment_name = "llama-3.2-3B-custom-retriever"<br/><br/>provider = OpenAIProvider(<br/>    model_engine=CFG['configuration']['models']['llm_evaluation']<br/>)</span></pre><p id="eed2" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">After that, we define the Triad itself (answer relevance, context relevance, groundedness). For each metric, we should specify inputs and outputs.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="702c" class="pj mk fq pg b bg pk pl l pm pn">context_selection = TruLlama.select_source_nodes().node.text<br/><br/># context relevance (for each of the context chunks)<br/>f_context_relevance = (<br/>    Feedback(<br/>        provider.context_relevance, name="Context Relevance"<br/>    )<br/>    .on_input()<br/>    .on(context_selection)<br/>)<br/><br/># groundedness<br/>f_groundedness_cot = (<br/>    Feedback(<br/>        provider.groundedness_measure_with_cot_reasons, name="Groundedness"<br/>    )<br/>    .on(context_selection.collect())<br/>    .on_output()<br/>)<br/><br/># answer relevance between overall question and answer<br/>f_qa_relevance = (<br/>    Feedback(<br/>        provider.relevance_with_cot_reasons, name="Answer Relevance"<br/>    )<br/>    .on_input_output()<br/>)</span></pre><p id="0a07" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Furthermore, we instantiate the TruLlama object that will handle the feedback calculation during the agent calls.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="6851" class="pj mk fq pg b bg pk pl l pm pn"># Create TruLlama agent<br/>tru_agent = TruLlama(<br/>    agent,<br/>    app_name=experiment_name,<br/>    tags="agent testing",<br/>    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness_cot],<br/>)</span></pre><p id="4a55" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Now we are ready to execute the evaluation pipeline on our dataset.</p><pre class="oe of og oh oi pf pg ph bp pi bb bk"><span id="13b4" class="pj mk fq pg b bg pk pl l pm pn">for item in tqdm(dataset):<br/>    try:<br/>        agent.reset()<br/>        <br/>        with tru_agent as recording:<br/>            agent.query(item.get('question'))<br/>        record_agent = recording.get()<br/>        <br/>        # wait until all the feedback function are finished<br/>        for feedback, result in record_agent.wait_for_feedback_results().items():<br/>            logging.info(f'{feedback.name}: {result.result}')<br/>    except Exception as e:<br/>        logging.error(e)<br/>        traceback.format_exc()</span></pre><p id="3127" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">We have conducted experiments using the 2 models, default/custom query engines, and extra tool input parameters description (ReAct agent struggled without the explicit tool input params description, trying to call non-existing tools to refactor the input). We can review the results as a DataFrame using a get_leaderboard() method.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc ql"><img src="../Images/f70a0571918030d447d1cf343023d50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzHH0FOEaD3O9n02-2paCg.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image created by the author</figcaption></figure><h1 id="1cf9" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Conclusion</h1><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc pe"><img src="../Images/3388eb9d59dc0de70d7834da343d89e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*owdZomyb3ji9PbgY"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Source: Image generate by the author using AI (Bing)</figcaption></figure><p id="4d5b" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">We obtained a private corpus, incorporating GPT models for the custom dataset generation. The actual corpus content is pretty interesting and diverse. That’s the reason why a lot of models are successfully fine-tuned using the GPT-generated samples right now.</p><p id="cfbd" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Neo4j DB provides convenient interfaces for a lot of frameworks while having one of the best UI capabilities (Aura). In real projects, we often have relations between the data, and GraphDB is a perfect choice for such use cases.</p><p id="8c1e" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">On top of the private corpus, we implemented different RAG approaches (standalone and as a part of the agent). Based on the RAG Triad metrics, we observed that an OpenAI-based agent works perfectly, while a well-prompted ReAct agent performs relatively the same. A big difference was in the usage of a custom query engine. That’s reasonable because we configured some specific procedures and thresholds that align with our data. In addition, both solutions have high groundedness, which is very important for RAG applications.</p><p id="bb37" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Another interesting takeaway is that the Agent call latency of the Llama3.2 3B and gpt-4o-mini API was pretty much the same (of course the most time took the DB call, but the difference is still not that big).</p><p id="1ff4" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Though our system works pretty well, there are a lot of improvements to be done, such as keyword search, rerankers, neighbor chunking selection, and the ground truth labels comparison. These topics will be discussed in the next articles on the RAG applications.</p><p id="4237" class="pw-post-body-paragraph nf ng fq nh b go ov nj nk gr ow nm nn no ox nq nr ns oy nu nv nw oz ny nz oa fj bk">Private corpus, alongside the code and prompts, can be found on <a class="af ou" href="https://github.com/Vlad-Fliahin/rag-llamaindex" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><h1 id="733a" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">P.S.</h1><p id="dcfc" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">I want to thank my colleagues: <a class="af ou" href="https://medium.com/u/831f45a955ff" rel="noopener">Alex Simkiv</a>, <a class="af ou" href="https://medium.com/u/8bc8d2a62041" rel="noopener">Andy Bosyi</a>, and <a class="af ou" href="https://www.linkedin.com/in/nazar-savchenko/" rel="noopener ugc nofollow" target="_blank">Nazar Savchenko</a> for productive conversations, collaboration, and valuable advice as well as the entire MindCraft.ai team for their constant support.</p></div></div></div></div>    
</body>
</html>