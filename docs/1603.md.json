["```py\nseed=42\nnp.random.seed(seed)\n\n# create node lookup for channels\nnode_lookup = {0: 'ice cream sales',\n               1: 'coastal visits',\n               2: 'temperature',           \n               3: 'shark attacks',\n }\n\n# data generating process\ndef lin_f(x): \n    return x\n\nlinks_coeffs = {0: [((0, -1), 0.2, lin_f), ((1, -1), 0.9, lin_f)],\n                1: [((1, -1), 0.5, lin_f), ((2, -1), 1.2, lin_f)],\n                2: [((2, -1), 0.7, lin_f)],\n                3: [((3, -1), 0.2, lin_f), ((2, -1), 1.8, lin_f) ],      \n}\n\n# time series length\nT = 1000\n\ndata, _ = toys.structural_causal_process(links_coeffs, T=T, seed=seed)\nT, N = data.shape\n\n# create var name lookup\nvar_names = [node_lookup[i] for i in sorted(node_lookup.keys())]\n\n# initialize dataframe object, specify time axis and variable names\ndf = pp.DataFrame(data, \n                  datatime = {0:np.arange(len(data))}, \n                  var_names=var_names)\n```", "```py\ntp.plot_timeseries(df)\nplt.show()\n```", "```py\n# create dataframne\ndf_pd = pd.DataFrame(df.values[0], columns=var_names)\n\n# calcuate lagged values for each column\nlag_periods = 1 \n\nfor col in var_names:\n    df_pd[f'{col}_lag{lag_periods}'] = df_pd[col].shift(lag_periods)\n\n# remove 1st obervations where we don't have lagged values\ndf_pd = df_pd.iloc[1:, :]\n\ndf_pd\n```", "```py\n# function to introduce feature drift based on indexes\ndef introduce_feature_drift(df, start_idx, end_idx, drift_amount):\n    drift_period = (df.index >= start_idx) & (df.index <= end_idx)\n    df.loc[drift_period, 'shark attacks_lag1'] += np.linspace(0, drift_amount, drift_period.sum())\n    return df\n\n# introduce feature drift\ndf_pd = introduce_feature_drift(df_pd, start_idx=500, end_idx=999, drift_amount=50.0)\n\n# visualise drift\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df_pd[['shark attacks_lag1']])\nplt.title('Feature Drift Over Time')\nplt.xlabel('Index')\nplt.ylabel('Value')\nplt.legend(['shark attacks_lag1'])\nplt.show()\n```", "```py\n# use first 500 observations for training\ndf_train = df_pd.iloc[0:500, :]\n\n# use last 100 observations for evaluation\ndf_test = df_pd.iloc[900:, :]\n\n# set feature lists\nX_causal_cols = [\"ice cream sales_lag1\", \"coastal visits_lag1\"]\nX_spurious_cols = [\"ice cream sales_lag1\", \"coastal visits_lag1\", \"temperature_lag1\", \"shark attacks_lag1\"]\n\n# create target, train and test sets\ny_train = df_train['ice cream sales'].copy()\ny_test = df_test['ice cream sales'].copy()\nX_causal_train = df_train[X_causal_cols].copy()\nX_causal_test = df_test[X_causal_cols].copy()\nX_spurious_train = df_train[X_spurious_cols].copy()\nX_spurious_test = df_test[X_spurious_cols].copy()\n```", "```py\n# train and validate model\nmodel_causal = RidgeCV()\nmodel_causal = model_causal.fit(X_causal_train, y_train)\nprint(f'Coefficient: {model_causal.coef_}')\n\nyhat_causal_train = model_causal.predict(X_causal_train)\nyhat_causal_test = model_causal.predict(X_causal_test)\n\nmse_train = mean_squared_error(y_train, yhat_causal_train)\nmse_test = mean_squared_error(y_test, yhat_causal_test)\nprint(f\"Mean Squared Error train: {round(mse_train, 2)}\")\nprint(f\"Mean Squared Error test: {round(mse_test, 2)}\")\n\nr2_train = r2_score(y_train, yhat_causal_train)\nr2_test = r2_score(y_test, yhat_causal_test)\nprint(f\"R2 train: {round(r2_train, 2)}\")\nprint(f\"R2 test: {round(r2_test, 2)}\")\n```", "```py\n# train and validate model\nmodel_spurious = RidgeCV()\nmodel_spurious = model_spurious.fit(X_spurious_train, y_train)\nprint(f'Coefficient: {model_spurious.coef_}')\n\nyhat_spurious_train = model_spurious.predict(X_spurious_train)\nyhat_spurious_test = model_spurious.predict(X_spurious_test)\n\nmse_train = mean_squared_error(y_train, yhat_spurious_train)\nmse_test = mean_squared_error(y_test, yhat_spurious_test)\nprint(f\"Mean Squared Error train: {round(mse_train, 2)}\")\nprint(f\"Mean Squared Error test: {round(mse_test, 2)}\")\n\nr2_train = r2_score(y_train, yhat_spurious_train)\nr2_test = r2_score(y_test, yhat_spurious_test)\nprint(f\"R2 train: {round(r2_train, 2)}\")\nprint(f\"R2 test: {round(r2_test, 2)}\") \n```", "```py\n# combine results\ndf_comp = pd.DataFrame({\n    'Index': np.arange(99),\n    'Actual': y_test,\n    'Causal prediction': yhat_causal_test,\n    'Spurious prediction': yhat_spurious_test\n})\n\n# melt the DataFrame to long format for seaborn\ndf_melted = df_comp.melt(id_vars=['Index'], value_vars=['Actual', 'Causal prediction', 'Spurious prediction'], var_name='Series', value_name='Value')\n\n# visualise results for test set\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df_melted, x='Index', y='Value', hue='Series')\nplt.title('Actual vs Predicted')\nplt.xlabel('Index')\nplt.ylabel('Value')\nplt.legend(title='Series')\nplt.show()\n```"]