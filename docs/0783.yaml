- en: 'Leverage OpenAI Tool calling: Building a reliable AI Agent from Scratch'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62?source=collection_archive---------0-----------------------#2024-03-26](https://towardsdatascience.com/leverage-openai-tool-calling-building-a-reliable-ai-agent-from-scratch-4e21fcd15b62?source=collection_archive---------0-----------------------#2024-03-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/f07cd9ca3af69f6002589e76d59e1898.png)'
  prefs: []
  type: TYPE_IMG
- en: Created with [DALL·E](https://labs.openai.com/s/1rNDsRujptitO6sPd57aWyZp)
  prefs: []
  type: TYPE_NORMAL
- en: Step-by-Step Workflow for developing and refining an AI Agent while dealing
    with errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@lukas.kowejsza?source=post_page---byline--4e21fcd15b62--------------------------------)[![Lukasz
    Kowejsza](../Images/8d920478bee9ad674a6c79462128b0db.png)](https://medium.com/@lukas.kowejsza?source=post_page---byline--4e21fcd15b62--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4e21fcd15b62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4e21fcd15b62--------------------------------)
    [Lukasz Kowejsza](https://medium.com/@lukas.kowejsza?source=post_page---byline--4e21fcd15b62--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4e21fcd15b62--------------------------------)
    ·16 min read·Mar 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: When we think about the future of AI, we envision intuitive everyday helpers
    seamlessly integrating into our workflows and taking on complex, routinely tasks.
    We all have found touchpoints that relieve us from the tedium of mental routine
    work. Yet, the main tasks currently tackled involve text creation, correction,
    and brainstorming, underlined by the significant role RAG (Retrieval-Augmented
    Generation) pipelines play in ongoing development. We aim to provide Large Language
    Models with better context to generate more valuable content.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about the future of AI conjures images of Jarvis from Iron Man or Rasputin
    from Destiny (the game) for me. In both examples, the AI acts as a voice-controlled
    interface to a complex system, offering high-level abstractions. For instance,
    Tony Stark uses it to manage his research, conduct calculations, and run simulations.
    Even R2D2 can respond to voice commands to interface with unfamiliar computer
    systems and extract data or interact with building systems.
  prefs: []
  type: TYPE_NORMAL
- en: In these scenarios, AI enables interaction with complex systems without requiring
    the end user to have a deep understanding of them. This could be likened to an
    ERP system in a large corporation today. It’s rare to find someone in a large
    corporation who fully knows and understands every facet of the in-house ERP system.
    It’s not far-fetched to imagine that, in the near future, AI might assist nearly
    every interaction with an ERP system. From the end user managing customer data
    or logging orders to the software developer fixing bugs or implementing new features,
    these interactions could soon be facilitated by AI assistants familiar with all
    aspects and processes of the ERP system. Such an AI assistant would know which
    database to enter customer data into and which processes and code might be relevant
    to a bug.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, several challenges and innovations lie ahead. We need to rethink
    processes and their documentation. Today’s ERP processes are designed for human
    use, with specific roles for different users, documentation for humans, input
    masks for humans, and user interactions designed to be intuitive and error-free.
    The design of these aspects will look different for AI interactions. We need specific
    roles for AI interactions and different process designs to enable intuitive and
    error-free AI interaction. This is already evident in our work with prompts. What
    we consider to be a clear task often turns out not to be so straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: 'From Concept to Reality: Building the Basis for AI Agents'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: However, let’s first take a step back to the concept of agents. Agents, or AI
    assistants that can perform tasks using the tools provided and make decisions
    on how to use these tools, are the building blocks that could eventually enable
    such a system. They are the process components we’d want to integrate into every
    facet of a complex system. But as highlighted in a previous article, they are
    challenging to deploy reliably. In this article, I will demonstrate how we can
    design and optimize an agent capable of reliably interacting with a database.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the grand vision of AI’s future is inspiring, it’s crucial to take practical
    steps towards realizing this vision. To demonstrate how we can start building
    the foundation for such advanced AI systems, let’s focus on creating a prototype
    agent for a common task: expense tracking. This prototype will serve as a tangible
    example of how AI can assist in managing financial transactions efficiently, showcasing
    the potential of AI in automating routine tasks and highlighting the challenges
    and considerations involved in designing an AI system that interacts seamlessly
    with databases. By starting with a specific and relatable use case, we can gain
    valuable insights that will inform the development of more complex AI agents in
    the future.'
  prefs: []
  type: TYPE_NORMAL
- en: The Aim of This Article
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article will lay the groundwork for a series of articles aimed at developing
    a chatbot that can serve as a single point of interaction for a small business
    to support and execute business processes or a chatbot that in your personal life
    organizes everything you need to keep track of. From data, routines, files, to
    pictures, we want to simply chat with our Assistant, allowing it to figure out
    where to store and retrieve your data.
  prefs: []
  type: TYPE_NORMAL
- en: Transitioning from the grand vision of AI’s future to practical applications,
    let’s zoom in on creating a prototype agent. This agent will serve as a foundational
    step towards realizing the ambitious goals discussed earlier. We will embark on
    developing an “Expense Tracking” agent, a straightforward yet essential task,
    demonstrating how AI can assist in managing financial transactions efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: This “Expense Tracking” prototype will not only showcase the potential of AI
    in automating routine tasks but also illuminate the challenges and considerations
    involved in designing an AI system that interacts seamlessly with databases. By
    focusing on this example, we can explore the intricacies of agent design, input
    validation, and the integration of AI with existing systems — laying a solid foundation
    for more complex applications in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Hands-On: Testing OpenAI Tool Call'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To bring our prototype agent to life and identify potential bottlenecks, we’re
    venturing into testing the tool call functionality of OpenAI. Starting with a
    basic example of expense tracking, we’re laying down a foundational piece that
    mimics a real-world application. This stage involves creating a base model and
    transforming it into the OpenAI tool schema using the langchain library’s `convert_to_openai_tool`
    function. Additionally, crafting a `report_tool` enables our future agent to communicate
    results or highlight missing information or issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With the data model and tools set up, the next step is to use the OpenAI client
    SDK to initiate a simple tool call. In this initial test, we’re intentionally
    providing insufficient information to the model to see if it can correctly indicate
    what’s missing. This approach not only tests the functional capability of the
    agent but also its interactive and error-handling capacities.
  prefs: []
  type: TYPE_NORMAL
- en: Calling OpenAI API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we’ll use the OpenAI client SDK to initiate a simple tool call. In our
    first test, we deliberately provide the model with insufficient information to
    see if it can notify us of the missing details.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll need a new function to read the arguments of the function call
    from the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can observe, we have encountered several issues in the execution:'
  prefs: []
  type: TYPE_NORMAL
- en: The gross_amount is not calculated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The date is hallucinated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With that in mind. Let’s try to resolve this issues and optimize our agent workflow.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Optimize Tool handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To optimize the agent workflow, I find it crucial to prioritize **workflow over
    prompt engineering**. While it might be tempting to fine-tune the prompt so that
    the agent learns to use the tools provided perfectly and makes no mistakes, it’s
    more advisable to first adjust the tools and processes. When a typical error occurs,
    the initial consideration should be **how to fix it code-based**.
  prefs: []
  type: TYPE_NORMAL
- en: Handling Missing Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Handling missing information effectively is an essential topic for creating
    robust and reliable agents. In the previous example, providing the agent with
    a tool like “get_current_date” is a workaround for specific scenarios. However,
    we must assume that missing information will occur in various contexts, and we
    cannot rely solely on prompt engineering and adding more tools to prevent the
    model from hallucinating missing information.
  prefs: []
  type: TYPE_NORMAL
- en: A simple workaround for this scenario is to modify the tool schema to treat
    all parameters as optional. This approach ensures that the agent only submits
    the parameters it knows, preventing unnecessary hallucination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, let’s take a look at openai tool schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see we have special key `required` , which we need to remove. Here’s
    how you can adjust the `add_expense_tool` schema to make parameters optional by
    removing the `required` key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Designing Tool class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we can design a Tool class that initially checks the input parameters
    for missing values. We create the `Tool` class with two methods: `.run()`, `.validate_input()`,
    and a property `openai_tool_schema`, where we manipulate the tool schema by removing
    required parameters. Additionally, we define the `ToolResult` BaseModel with the
    fields `content` and `success` to serve as the output object for each tool run.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `Tool` class is a crucial component in the AI agent's workflow, serving
    as a blueprint for creating and managing various tools that the agent can utilize
    to perform specific tasks. It is designed to handle input validation, execute
    the tool's function, and return the result in a standardized format.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Tool` class key components:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`name`: The name of the tool.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`model`: The Pydantic BaseModel that defines the input schema for the tool.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`function`: The callable function that the tool executes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`validate_missing`: A boolean flag indicating whether to validate missing input
    values (default is `False`).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `Tool` class two main methods:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`**run(self, **kwargs) -> ToolResult**`**:** This method is responsible for
    executing the tool’s function with the provided input arguments. It first checks
    if `validate_missing` is set to `True`. If so, it calls the `validate_input()`
    method to check for missing input values. If any missing values are found, it
    returns a `ToolResult` object with an error message and `success` set to `False`.
    If all required input values are present, it proceeds to execute the tool''s `function`
    with the provided arguments and returns a `ToolResult` object with the result
    and `success` set to `True`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`**validate_input(self, **kwargs) -> List[str]**`**:** This method compares
    the input arguments passed to the tool with the expected input schema defined
    in the `model`. It iterates over the fields defined in the `model` and checks
    if each field is present in the input arguments. If any field is missing, it appends
    the field name to a list of missing values. Finally, it returns the list of missing
    values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Tool` class also has a property called `openai_tool_schema`, which returns
    the OpenAI tool schema for the tool. It uses the `convert_to_openai_tool()` function
    to convert the `model` to the OpenAI tool schema format. Additionally, it removes
    the `"required"` key from the schema, making all input parameters optional. This
    allows the agent to provide only the available information without the need to
    hallucinate missing values.
  prefs: []
  type: TYPE_NORMAL
- en: By encapsulating the tool’s functionality, input validation, and schema generation,
    the `Tool` class provides a clean and reusable interface for creating and managing
    tools in the AI agent's workflow. It abstracts away the complexities of handling
    missing values and ensures that the agent can gracefully handle incomplete information
    while executing the appropriate tools based on the available input.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Missing Information Handling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we will extend our OpenAI API call. We want the client to utilize our
    tool, and our response object to directly trigger a tool.run(). For this, we need
    to initialize our tools in our newly created Tool class. We define two dummy functions
    which return a success message string.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Next we define our helper function, that each take client response as input
    an help to interact with out tools.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can execute our client with our new tools and use the `run_tool_from_response`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Perfectly, we now see our tool indicating that missing values are present. Thanks
    to our trick of sending all parameters as optional, we now avoid hallucinated
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Building the Agent Workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our process, as it stands, doesn’t yet represent a true agent. So far, we’ve
    only executed a single API tool call. To transform this into an agent workflow,
    we need to introduce an iterative process that feeds the results of tool execution
    back to the client. The basic process should like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41aa2536800140285336ed2dd1dabdaa.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get started by creating a new OpenAIAgent class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Like our `ToolResult`object, we’ve defined a `StepResult` as an object for each
    agent step. We then defined the `__init__` method of the OpenAIAgent class and
    a `to_console()` method to print our intermediate steps and tool calls to the
    console, using colorama for colorful printouts. Next, we define the heart of the
    agent, the `run()` and the `run_step()` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the `run()` method, we start by initializing the `step_history`, which will
    serve as our message memory, with the predefined system_message and the user_input.
    Then we start our while loop, where we call `run_step` during each iteration,
    which will return a StepResult Object. We identify if the agent finished his task
    or if an error occurred, which will be passed to the console as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now we’ve defined the logic for each step. We first obtain a response object
    by our previously tested client API call with tools. We append the response message
    object to our `step_history`. We then verify if a tool call is included in our
    response object, otherwise, we return an error in our StepResult. Then we log
    our tool call to the console and run the selected tool with our previously defined
    method `run_tool_from_response()`. We also need to append the tool result to our
    message history. OpenAI has defined a specific format for this purpose, so that
    the Model knows which tool call refers to which output by passing a tool_call_id
    into our message dict. This is done by our method `tool_call_message()`, which
    takes the response object and the tool_result as input arguments. At the end of
    each step, we assign the tool result to a StepResult Object, which also indicates
    if the step was successful or not, and return it to our loop in `run()`.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Running the Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we can test our agent with the previous example, directly equipping it with
    a `get_current_date_tool` as well. Here, we can set our previously defined `validate_missing`
    attribute to `False`, since the tool doesn't need any input argument.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Following the successful execution of our prototype agent, it’s noteworthy to
    emphasize how effectively the agent utilized the designated tools according to
    plan. Initially, it invoked the `get_current_date_tool`, establishing a foundational
    timestamp for the expense entry. Subsequently, when attempting to log the expense
    via the `add_expense_tool`, our intelligently designed tool class identified a
    missing `gross_amount`—a crucial piece of information for accurate financial tracking.
    Impressively, the agent autonomously resolved this by calculating the `gross_amount`
    using the provided `tax_rate`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s important to mention that in our test run, the nature of the input expense
    — whether the $5 spent on coffee was net or gross — wasn’t explicitly specified.
    At this juncture, such specificity wasn’t required for the agent to perform its
    task successfully. However, this brings to light a valuable insight for refining
    our agent’s understanding and interaction capabilities: Incorporating such detailed
    information into our initial system prompt could significantly enhance the agent’s
    accuracy and efficiency in processing expense entries. This adjustment would ensure
    a more comprehensive grasp of financial data right from the outset.'
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Iterative Development**: The project underscores the critical nature of an
    iterative development cycle, fostering continuous improvement through feedback.
    This approach is paramount in AI, where variability is the norm, necessitating
    an adaptable and responsive development strategy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Handling Uncertainty**: Our journey highlighted the significance of elegantly
    managing ambiguities and errors. Innovations such as optional parameters and rigorous
    input validation have proven instrumental in enhancing both the reliability and
    user experience of the agent.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Customized Agent Workflows for Specific Tasks**: A key insight from this
    work is the importance of customizing agent workflows to suit particular use cases.
    Beyond assembling a suite of tools, the strategic design of tool interactions
    and responses is vital. This customization ensures the agent effectively addresses
    specific challenges, leading to a more focused and efficient problem-solving approach.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The journey we have embarked upon is just the beginning of a larger exploration
    into the world of AI agents and their applications in various domains. As we continue
    to push the boundaries of what’s possible with AI, we invite you to join us on
    this exciting adventure. By building upon the foundation laid in this article
    and staying tuned for the upcoming enhancements, you will witness firsthand how
    AI agents can revolutionize the way businesses and individuals handle their data
    and automate complex tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Together, let us embrace the power of AI and unlock its potential to transform
    the way we work and interact with technology. The future of AI is bright, and
    we are at the forefront of shaping it, one reliable agent at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Looking Ahead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we continue our journey in exploring the potential of AI agents, the upcoming
    articles will focus on expanding the capabilities of our prototype and integrating
    it with real-world systems. In the next article, we will dive into designing a
    robust project structure that allows our agent to interact seamlessly with SQL
    databases. By leveraging the agent developed in this article, we will demonstrate
    how AI can efficiently manage and manipulate data stored in databases, opening
    up a world of possibilities for automating data-related tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Building upon this foundation, the third article in the series will introduce
    advanced query features, enabling our agent to handle more complex data retrieval
    and manipulation tasks. We will also explore the concept of a routing agent, which
    will act as a central hub for managing multiple subagents, each responsible for
    interacting with specific database tables. This hierarchical structure will allow
    users to make requests in natural language, which the routing agent will then
    interpret and direct to the appropriate subagent for execution.
  prefs: []
  type: TYPE_NORMAL
- en: To further enhance the practicality and security of our AI-powered system, we
    will introduce a role-based access control system. This will ensure that users
    have the appropriate permissions to access and modify data based on their assigned
    roles. By implementing this feature, we can demonstrate how AI agents can be deployed
    in real-world scenarios while maintaining data integrity and security.
  prefs: []
  type: TYPE_NORMAL
- en: Through these upcoming enhancements, we aim to showcase the true potential of
    AI agents in streamlining data management processes and providing a more intuitive
    and efficient way for users to interact with databases. By combining the power
    of natural language processing, database management, and role-based access control,
    we will be laying the groundwork for the development of sophisticated AI assistants
    that can revolutionize the way businesses and individuals handle their data.
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned for these exciting developments as we continue to push the boundaries
    of what’s possible with AI agents in data management and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: Source Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Additionally, the entire source code for the projects covered is available on
    GitHub. You can access it at [https://github.com/elokus/AgentDemo](https://github.com/elokus/AgentDemo).
  prefs: []
  type: TYPE_NORMAL
