- en: Data Minimization Does Not Guarantee Privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/data-minimization-does-not-guarantee-privacy-544ca15c7193?source=collection_archive---------10-----------------------#2024-10-28](https://towardsdatascience.com/data-minimization-does-not-guarantee-privacy-544ca15c7193?source=collection_archive---------10-----------------------#2024-10-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Just because it was minimized, doesn’t mean it’s secure!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@prakhargannu?source=post_page---byline--544ca15c7193--------------------------------)[![Prakhar
    Ganesh](../Images/431b1f71bf5f85e3a5105a1e2eb84459.png)](https://medium.com/@prakhargannu?source=post_page---byline--544ca15c7193--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--544ca15c7193--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--544ca15c7193--------------------------------)
    [Prakhar Ganesh](https://medium.com/@prakhargannu?source=post_page---byline--544ca15c7193--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--544ca15c7193--------------------------------)
    ·4 min read·Oct 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*Based on our paper* [*The Data Minimization Principle in Machine Learning*](https://arxiv.org/abs/2405.19471)
    *by Prakhar Ganesh, Cuong Tran, Reza Shokri, and Ferdinando Fioretto*'
  prefs: []
  type: TYPE_NORMAL
- en: The Data Minimization Principle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The proliferation of data-driven systems and ML applications escalates a number
    of privacy risks, including those related to **unauthorized access to sensitive
    information**. In response, international data protection frameworks like the
    *European General Data Protection Regulation (GDPR)*, the *California Privacy
    Rights Act (CPRA)*, the *Brazilian General Data Protection Law (LGPD),* etc.have
    adopted ***data minimization***as a key principle to mitigate these risks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ff3711017864ce681ddb75a5a6a1dea6.png)'
  prefs: []
  type: TYPE_IMG
- en: Excerpts of the **data minimization principle** from six different data protection
    regulations across the world. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, the data minimization principle requires organizations to *collect,
    process, and retain only personal data that is adequate, relevant, and limited
    to what is necessary for specified objectives*. It’s grounded in the expectation
    that not all data is essential and, instead, contributes to a heightened risk
    of information leakage. The data minimization principle builds on two core pillars,
    *purpose limitation* and *data relevance*.
  prefs: []
  type: TYPE_NORMAL
- en: Purpose Limitation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data protection regulations mandate that data be collected for a *legitimate,
    specific and explicit purpose* (LGPD, Brazil) and prohibit using the collected
    data for any other incompatible purpose from the one disclosed (CPRA, USA). Thus,
    data collectors must define a clear, legal objective before data collection and
    use the data solely for that objective. In an ML setting, this *purpose* can be
    seen as collecting data for training models to achieve optimal performance on
    a given task.
  prefs: []
  type: TYPE_NORMAL
- en: Data Relevance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regulations like the GDPR require that all collected data *be adequate, relevant,
    and limited to what is necessary for the purposes it was collected for*. In other
    words, data minimization aims to remove data that does not serve the purpose defined
    above. In ML contexts, this translates to retaining only data that contributes
    to the performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/121ab7da97782b47e5546b1fa9c831d6.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Data minimization.** Image by Author'
  prefs: []
  type: TYPE_NORMAL
- en: Privacy expectations through minimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you might have already noticed, there is an implicit expectation of privacy
    through minimization in data protection regulations. The data minimization principle
    has even been hailed by many in the public discourse ([EDPS](https://www.edps.europa.eu/data-protection/data-protection/glossary/d_en),
    [Kiteworks](https://www.kiteworks.com/risk-compliance-glossary/data-minimization/),
    [The Record](https://therecord.media/lawmakers-set-sights-on-data-minimization-with-new-bills),
    [Skadden](https://www.skadden.com/insights/publications/2024/04/cppas-first-enforcement-advisory),
    [k2view](https://www.k2view.com/blog/data-minimization/)) as a principle to protect
    privacy.
  prefs: []
  type: TYPE_NORMAL
- en: The EU AI Act states in [Recital 69](https://www.euaiact.com/recital/69), “*The
    right to privacy and to protection of personal data must be guaranteed throughout
    the entire lifecycle of the AI system. In this regard, the principles of data
    minimisation and data protection by design and by default, as set out in Union
    data protection law, are applicable when personal data are processed”*.
  prefs: []
  type: TYPE_NORMAL
- en: '***However, this expectation of privacy from minimization overlooks a crucial
    aspect of real world data–the inherent correlations among various features!***
    Information about individuals is rarely isolated, thus, merely minimizing data,
    may still allow for confident reconstruction. This creates a gap, where individuals
    or organizations using the operationalization attempts of data minimization, might
    expect improved privacy, despite using a framework that is limited to only minimization.'
  prefs: []
  type: TYPE_NORMAL
- en: The Correct Way to Talk about Privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Privacy auditing often involves performing attacks to assess real-world information
    leakage. These attacks serve as powerful tools to expose potential vulnerabilities
    and by simulating realistic scenarios, auditors can evaluate the effectiveness
    of privacy protection mechanisms and identify areas where sensitive information
    may be revealed.
  prefs: []
  type: TYPE_NORMAL
- en: Some adversarial attacks that might be relevant in this situation include reconstruction
    and re-identification attacks. *Reconstruction attacks aim to recover missing
    information from a target dataset.* *Re-identification attacks aim to re-identify
    individuals using partial or anonymized data.*
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b5f87e2934643a0718398b8744a28019.png)'
  prefs: []
  type: TYPE_IMG
- en: '**The Overall Framework.** Image by Author'
  prefs: []
  type: TYPE_NORMAL
- en: The gap between Data Minimization and Privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consider the example of minimizing data from an image, and removing pixels that
    do not contribute to the performance of the model. Solving that optimization would
    give you minimized data that looks something like this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2d8b4f73bd7cd506af38c5992946720b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The trends in this example are interesting. As you’ll notice, the central vertical
    line is preserved in the image of the digit ‘1’, while the outer curves are retained
    for ‘0’. In other words, while 50% of the pixels are removed, it doesn’t seem
    like any information is lost. One can even show that is the case by applying a
    very simple reconstruction attack using data imputation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b28845083eae017b06734d96b8d7b27c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Despite minimizing the dataset by 50%, the images can still be reconstructed
    using overall statistics. This provides a strong indication of privacy risks and
    suggests that **a minimized dataset does not equate to enhanced privacy!**
  prefs: []
  type: TYPE_NORMAL
- en: So What Can We Do?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While data protection regulations aim to limit data collection with an expectation
    of privacy, current operationalizations of minimization fall short of providing
    robust privacy safeguards. Notice, however, that this is not to say that minimization
    is incompatible with privacy; instead, the emphasis is on the need for **approaches
    that incorporate privacy into their objectives, rather than treating them as an
    afterthought**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We provide a deeper empirical exploration of data minimization and its misalignment
    with privacy, along with potential solutions, in our [paper](https://arxiv.org/abs/2405.19471).
    We seek to answer a critical question: *“Do current data minimization requirements
    in various regulations genuinely meet privacy expectations in legal frameworks?”*
    Our evaluations reveal that the answer is, unfortunately, **no**.'
  prefs: []
  type: TYPE_NORMAL
