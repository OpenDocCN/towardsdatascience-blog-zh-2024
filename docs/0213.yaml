- en: Enhancing Cancer Detection with StyleGAN-2 ADA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/enhancing-cancer-detection-with-stylegan-2-ada-aee55ef99c5b?source=collection_archive---------5-----------------------#2024-01-22](https://towardsdatascience.com/enhancing-cancer-detection-with-stylegan-2-ada-aee55ef99c5b?source=collection_archive---------5-----------------------#2024-01-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data augmentation for data-deficient deep neural networks.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ianstebbs?source=post_page---byline--aee55ef99c5b--------------------------------)[![Ian
    Stebbins](../Images/50ece59dc136f7d41e02c046ea1216e4.png)](https://medium.com/@ianstebbs?source=post_page---byline--aee55ef99c5b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--aee55ef99c5b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--aee55ef99c5b--------------------------------)
    [Ian Stebbins](https://medium.com/@ianstebbs?source=post_page---byline--aee55ef99c5b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--aee55ef99c5b--------------------------------)
    ·8 min read·Jan 22, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*By:* [*Ian Stebbins*](https://www.linkedin.com/in/ian-stebbins-244a1722b/)*,*
    [*Benjamin Goldfried*](https://www.linkedin.com/in/benjamin-goldfried/)*,* [*Ben
    Maizes*](https://www.linkedin.com/in/benjamin-maizes/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Intro**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often for many domain-specific problems, a lack of data can hinder the effectiveness
    and even disallow the use of deep neural networks. Recent architectures of Generative
    Adversarial Networks (GANs), however, allow us to synthetically augment data,
    by creating new samples that capture intricate details, textures, and variations
    in the data distribution. This synthetic data can act as additional training input
    for deep neural networks, thus making domain tasks with limited data more feasible.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this project, we applied NVIDIA StyleGAN-2 with Adaptive Discriminator Augmentation
    (ADA) to a small [Chest CT-Scan Dataset](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images/code?datasetId=839140&sortBy=voteCount)
    (Licensed under [Database: Open Database, Contents: © Original Authors](http://opendatacommons.org/licenses/odbl/1.0/))[1].
    Additionally, we built a CNN classifier to distinguish normal scans from those
    with tumors. By injecting varying proportions of synthetically generated data
    into the training of different models, we were able to evaluate the performance
    differences between models with all real data and those with a real-synthetic
    mix.'
  prefs: []
  type: TYPE_NORMAL
- en: '**StyleGAN-2 ADA**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'StyleGAN-2 with ADA was first introduced by NVIDIA in the NeurIPS 2020 paper:
    [“Training Generative Adversarial Networks with Limited Data”](https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/ada-paper.pdf)
    [2]. In the past, training GANs on small datasets typically led to the network
    discriminator overfitting. Thus rather than learning to distinguish between real
    and generated data, the discriminator tended to memorize the patterns of noise
    and outliers of the training set, rather than learn the general trends of the
    data distribution. To combat this, ADA dynamically adjusts the strength of data
    augmentation based on the degree of overfitting observed during training. This
    helps the model to generalize better and leads to better GAN performance on smaller
    datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Augmenting The Dataset**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use the StyleGAN-2 ADA model, we used the official NVIDIA model implementation
    from GitHub, which can be found [here](https://github.com/NVlabs/stylegan3). *Note
    that this is the StyleGAN-3 repo but StyleGAN-2 can still be run.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Depending on your setup you may have to install dependencies and do some other
    preprocessing. For example, we chose to resize and shrink our dataset images to
    224x224 since we only had access to a single GPU, and using larger image sizes
    is much more computationally expensive. We chose to use 224x224 because ResNet,
    the pre-trained model we chose for the CNN, is optimized to work with this size
    of image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To begin the training process, navigate to the directory where you cloned the
    repo and then run the following.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**SNAP** refers to the number of Ticks (training steps where information is
    displayed) after which you would like to take a snapshot of your network and save
    it to a pickle file.'
  prefs: []
  type: TYPE_NORMAL
- en: '**KIMG** refers to the number of thousands of images you want to feed into
    your GAN.'
  prefs: []
  type: TYPE_NORMAL
- en: '**GAMMA d**etermines how strongly the regularization affects the discriminator.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b34210233f78736ace829dafc60eb73c.png)![](../Images/6a3268bd615e1c08b05b12fa8d74ea19.png)'
  prefs: []
  type: TYPE_IMG
- en: Initial Generated Images
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86495efb421750130e2efe65762c8570.png)![](../Images/948a9ccdfd5f21abf3313d44279cfa62.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated Images During Training
  prefs: []
  type: TYPE_NORMAL
- en: Once your model has finished training (this can take multiple hours depending
    on your compute resources) you can now use your trained network to generate images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/43a52ee7c15a0a27c8aee5c3c86606fd.png)![](../Images/7496b11702ef63c7c146d11d852d35d2.png)'
  prefs: []
  type: TYPE_IMG
- en: Normal Real Image (Left) vs Normal Generated Image (Right)
  prefs: []
  type: TYPE_NORMAL
- en: '**Transfer Learning & Convolutional Neural Network**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To benchmark the effectiveness of our synthetically generated data, we first
    trained a CNN model on our original data. Once we had a benchmark accuracy on
    the test set, we re-trained the model with increasing amounts of synthetic data
    in the training mix.
  prefs: []
  type: TYPE_NORMAL
- en: To feed our data into the model we used Keras data generators which flow the
    samples directly from a specified directory into the model. The original dataset
    has 4 classes for different types of cancer, however, for simplicity, we turned
    this into a binary classification problem. The two classes we decided to work
    with from the original Kaggle dataset were the normal and squamous classes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: To build our model, we began by using the ResNet50 base architecture and model
    weights. We chose to use ResNet50 due to its moderate-size architecture, good
    documentation, and ease of use through Keras. After importing ResNet50 with the
    Imagenet model weights, we then froze the ResNet50 layers and added trainable
    dense layers on top to help the network learn our specific classification task.
  prefs: []
  type: TYPE_NORMAL
- en: We also chose to incorporate batch normalization, which can lead to faster convergence
    and more stable training by normalizing layer inputs and reducing internal covariate
    shift [3]. Additionally, it can provide a regularization effect that can help
    prevent overfitting in our added trainable dense layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/563757ec5c2f1f0f7c1b6a808ac3f16b.png)'
  prefs: []
  type: TYPE_IMG
- en: Our Model Architecture
  prefs: []
  type: TYPE_NORMAL
- en: Originally, our model was not performing well. We solved this issue by switching
    our activation function from ReLU to leaky ReLU. This suggested that our network
    may have been facing the dying ReLU or dead neuron problem. In short, since the
    gradient of ReLU will always be zero for negative numbers, this can lead to neurons
    “dying” and not contributing to the network [4][5]. Since leaky ReLU is nonzero
    for negative values, using it as an activation function can help combat this issue.
  prefs: []
  type: TYPE_NORMAL
- en: '**Results**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To test our synthetic data, we trained the above CNN on 5 separate instances
    with 0%, 25%, 50%, 75%, and 100% additional synthetic samples. For example, 0%
    synthetic samples meant that the data was all original, while 100% meant the training
    set contained equal amounts of original and synthetic data. For each network,
    we then evaluated the performance using an accuracy metric on a real set of unseen
    test data. The plot below visualizes how different proportions of synthetic data
    affect the testing accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9a3fef522d3001511884da078b5b2dc7.png)'
  prefs: []
  type: TYPE_IMG
- en: Test Accuracy on Binary (Normal vs Squamous Tumor) Classification
  prefs: []
  type: TYPE_NORMAL
- en: Training the model was unstable, thus we ruled out iterations where the accuracy
    was 1.0 or extremely low. This helped us avoid training iterations that were under
    or over fit.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that from 0 to 25% we see a sharp increase in the testing accuracy,
    suggesting that even augmenting the dataset by a small amount can have a large
    impact on problems where the data is initially minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Since we only trained our GAN on 80 KIMG (due to compute limitations) the quality
    of our synthetic data could have potentially been better, given more GAN training
    iterations. Notably, an increase in synthetic data quality could also influence
    the graph above. We hypothesize that an increase in synthetic quality will also
    lead to an increase in the optimal proportion of synthetic data used in training.
    Further, if the synthetic images were better able to fit the real distribution
    of our training data, we could incorporate more of them in model training without
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this project, using GANs for the augmentation of limited data has shown to
    be an effective technique for expanding training sets and more importantly, improving
    classification accuracy. While we opted for a small and basic problem, this could
    easily be upscaled in a few ways. Future work may include using more computational
    resources to get better synthetic samples, introducing more classes into the classification
    task (making it a multi-class problem), and experimenting with newer GAN architectures.
    Regardless, using GANs to augment small datasets can now bring many previously
    data-limited problems into the scope of deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Kaggle Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We compiled our augmented and resized images into the following [Kaggle dataset](https://www.kaggle.com/datasets/benjaminmaizes/formatted-and-augmented-chest-ct-scan-images).
    This contains 501 normal and 501 squamous 224x224 synthetic images which can be
    used for further experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: '[Our *GitHub Repo*](https://github.com/istebbins/Enhancing-Cancer-Detection-with-StyleGAN-2-ADA)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Citations**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1] Hany, Mohamed, [Chest CT-Scan images Dataset](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images/code?datasetId=839140&sortBy=voteCount),
    Kaggle (2020).'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Karras, Tero, et al, [Training Generative Adversarial Networks with Limited
    Data](https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/ada-paper.pdf) (2020), Advances
    in neural information processing systems 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Ioffe, Sergey, and Christian Szegedy, [Batch normalization: Accelerating
    deep network training by reducing internal covariate shift](http://proceedings.mlr.press/v37/ioffe15.pdf),
    (2015), *International conference on machine learning*. pmlr, 2015.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] He, Kaiming, et al, [Delving deep into rectifiers: Surpassing human-level
    performance on imagenet classification](https://arxiv.org/pdf/1502.01852.pdf),
    (2015), *Proceedings of the IEEE international conference on computer vision*.
    2015.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5]Bai, Yuhan, [RELU-function and derived function review](https://www.shs-conferences.org/articles/shsconf/pdf/2022/14/shsconf_stehf2022_02006.pdf),
    (2022), *SHS Web of Conferences*. Vol. 144\. EDP Sciences, 2022.'
  prefs: []
  type: TYPE_NORMAL
