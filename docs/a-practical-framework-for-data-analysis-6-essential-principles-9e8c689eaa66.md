# 数据分析的实用框架：六大核心原则

> 原文：[https://towardsdatascience.com/a-practical-framework-for-data-analysis-6-essential-principles-9e8c689eaa66?source=collection_archive---------0-----------------------#2024-11-14](https://towardsdatascience.com/a-practical-framework-for-data-analysis-6-essential-principles-9e8c689eaa66?source=collection_archive---------0-----------------------#2024-11-14)

![](../Images/6704646a9526498eb9f4d6a10be7ca51.png)

图片来源：[Cytonn Photography](https://unsplash.com/@cytonn_photography?utm_source=medium&utm_medium=referral) via [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

## 如何像专业人士一样从数据中发现洞察

[](https://medium.com/@pararawendy19?source=post_page---byline--9e8c689eaa66--------------------------------)[![Pararawendy Indarjo](../Images/afba0cb7f3af9554a187bbc7a3c00e60.png)](https://medium.com/@pararawendy19?source=post_page---byline--9e8c689eaa66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9e8c689eaa66--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9e8c689eaa66--------------------------------) [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--9e8c689eaa66--------------------------------)

·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9e8c689eaa66--------------------------------) ·阅读时间11分钟·2024年11月14日

--

作为一名在消费科技行业工作了六年的数据科学家，我已经进行了无数次的探索性数据分析（EDA），以从数据中发现洞察，最终目的是回答业务问题并验证假设。

基于我的这些经验，我将我的关键洞察提炼为六个数据分析原则。这些原则在我的日常工作中一再证明了其价值，我很高兴与大家分享。

在本文的其余部分，我们将逐一讨论这六个原则。

1.  建立基准线

1.  标准化指标

1.  MECE 分组

1.  聚合粒度数据

1.  移除无关数据

1.  应用帕累托原则

## 建立基准线

假设你在一家电子商务公司工作，管理层希望识别出拥有优质客户的地区（“优质”可以通过多种指标来定义，比如总支出、平均订单价值或购买频率）。

为了简化起见，假设公司在印度尼西亚的三个最大城市运营：雅加达、万隆和泗水。

一位经验不足的分析师可能会急于计算每个城市中优质客户的数量。假设他们发现如下数据。

![](../Images/93a3a8530c6a84107783237e41b876bf.png)

优质用户分布（图由作者提供）

注意到60%的优质客户位于雅加达。基于这一发现，他们建议管理层在雅加达增加市场营销投入。

然而，我们可以做得更好！

这种方法的问题在于，它只告诉我们哪个城市有最多的优秀客户数量。它没有考虑到，优秀客户最多的城市可能只是用户基数最大的城市。

鉴于此，我们需要将优秀客户分布与**基准：所有用户的分布**进行比较。这个基准帮助我们进行理智的检查，验证雅加达是否真的存在一个令人感兴趣的优秀客户数量。因为也许雅加达的优秀客户数量高，仅仅是因为它的总用户数最高——因此，拥有最多的优秀客户是可以预期的。

我们继续检索总的用户分布并获得以下结果。

![](../Images/705c9aa5d003ef32e5adbdad529be24b.png)

所有用户分布作为基准（图源：作者）

结果显示，雅加达占所有用户的60%。请注意，这验证了我们之前的担忧：雅加达拥有60%的高价值客户，完全是与其用户基数成比例的；因此，雅加达并没有发生什么特别的事情。

当我们将两个数据结合起来，按城市获得优秀客户比例时，请考虑以下数据。

![](../Images/4f2593e17ef61b28a4bb471c4863c730.png)

按城市的优秀用户比例（图源：作者）

观察泗水：它拥有30个优秀用户，而总用户数只有150人，导致优秀用户比例为20%——是所有城市中最高的。

这是值得采取行动的洞察。它表明，泗水在高价值客户方面的倾向高于平均水平——换句话说，泗水的用户比雅加达的用户更有可能成为优秀客户。

## 规范化指标

考虑以下场景：业务团队刚刚进行了两个不同的主题产品活动，我们的任务是评估和比较它们的表现。

为此，我们计算了两个活动的总销售额并进行比较。假设我们获得了以下数据。

![](../Images/19bdc63223b48d2517f64b3f061203d2.png)

活动总销售额（图源：作者）

从这个结果中，我们得出结论，活动A优于活动B，因为450百万大于360百万。

然而，我们忽略了一个重要因素：活动持续时间。如果最终发现两个活动的持续时间不同呢？如果是这样，我们需要规范化比较指标。否则，我们无法公平比较，因为活动A的销售额可能更高，仅仅是因为它持续的时间更长。

**指标规范化确保我们能够公平地比较指标**，使比较变得更加公正。在这种情况下，我们可以通过将销售指标除以活动持续天数来规范化销售指标，从而得出每日报销额。

假设我们得到了以下结果。

![](../Images/b830558bad74b5cd38116869d19fc7b5.png)

规范化销售数据的活动数据（图源：作者）

结论发生了变化！在规范化销售指标后，实际上是 B 活动表现更好。它每天的销售额为 1200 万，比 A 活动的 1000 万高出 20%。

## MECE 分组

MECE 是咨询顾问最喜爱的框架。MECE 是他们将复杂问题拆解成更小、更易管理的部分或分区的首选方法。

MECE 代表互斥、完全穷尽。这里有两个概念。我们一个一个地来解决它们。为了演示这个概念，假设我们希望研究某个特定消费者应用服务的用户获取渠道归因。为了获得更多的洞察，我们根据用户的归因渠道将其分开。

假设在第一次尝试时，我们将归因渠道细分如下：

+   付费社交媒体

+   Facebook 广告

+   自然流量

![](../Images/f52c21c0a1bae42b820c3ef5ed5c3ac1.png)

上述分组的集合图：非 MECE（图由作者提供）

**互斥（ME）**意味着分解集之间不能重叠。换句话说，没有分析单元属于多个分解组。上面的分解*不是*互斥的，因为 Facebook 广告是付费社交媒体的一个子集。因此，Facebook 广告组中的所有用户也是付费社交媒体组的成员。

**完全穷尽（CE）**意味着分解的组必须包括所有可能的情况/子集，即没有分析单元会与任何分解组无关。上面的分解*不是*完全穷尽的，因为它没有包括通过其他渠道（如搜索引擎广告和联盟网络）获得的用户。

上述案例的 MECE 分解版本可以如下：

+   付费社交媒体

+   搜索引擎广告

+   联盟网络

+   自然流量

![](../Images/71e7ce1c37e89a55b97fdfa9ea0c7023.png)

更新后分组的集合图：MECE！（图由作者提供）

MECE 分组使我们能够将大型异质数据集分解成更小、更同质的部分。这种方法有助于特定数据子集的优化、根本原因分析和其他分析任务。

然而，当存在多个子集时，创建 MECE 分解可能会具有挑战性，即当要分解的因子变量包含许多独特值时。考虑一个电子商务应用漏斗分析，用于了解用户的产品发现行为。在电子商务应用中，用户可以通过多种路径发现产品，这使得标准的 MECE 分组变得复杂（如搜索、分类、横幅广告，更不用说它们的组合）。

在这种情况下，假设我们主要关注了解用户的搜索行为。那么，创建二元分组是切实可行的：is_search 用户，其中如果用户曾经使用过应用的搜索功能，值为 1。这简化了 MECE 分解，同时仍然支持主要的分析目标。

如我们所见，二元标志提供了一种简单的MECE分解方法，在这种方法中，我们将最相关的类别作为正值（如is_search、is_paid_channel或is_jakarta_user）。

## 聚合粒度数据

许多行业中的数据集都是粒度化的，这意味着它们以原始详细的级别呈现。例子包括交易数据、支付状态日志、应用内活动日志等。这些粒度数据是低级的，包含丰富的信息，但代价是高冗余。

我们在处理粒度数据时需要小心，因为它可能会妨碍我们获得有用的洞察。考虑以下简化的交易数据示例。

![](../Images/fd42d8c02a2d5d0c8784d867aff96b58.png)

示例粒度交易数据（图片由作者提供）

乍一看，表格似乎没有包含任何有趣的发现。共有20笔交易涉及不同的手机，每笔交易的数量都是1。因此，我们可能得出结论，认为没有有趣的模式，比如哪款手机比其他手机更受欢迎，因为它们的表现完全相同：它们的销量都是一样的。

然而，我们可以通过在手机品牌级别进行聚合，并计算每个品牌销量的百分比份额来改进分析。

![](../Images/9a2807011d9d38b8e1c12c7bb38d6062.png)

交易数据的聚合过程（图片由作者提供）

突然之间，我们得到了不容忽视的发现。三星手机是最流行的，占总销量的45%。其次是苹果手机，占总销量的30%。接下来是小米，占15%。而Realme和Oppo则是购买最少的，每个品牌的份额为5%。

如我们所见，**聚合是处理粒度数据的有效工具**。它有助于将粒度数据的低级表示转换为更高级的表示，从而增加从数据中获得非平凡发现的可能性。

对于想了解更多关于聚合如何帮助发现有趣洞察的读者，请查看我下面的Medium文章。

[](/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=post_page-----9e8c689eaa66--------------------------------) [## 一种强大的EDA工具：分组聚合

### 学习如何使用分组聚合从数据中发现洞察

[towardsdatascience.com](/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=post_page-----9e8c689eaa66--------------------------------)

## 移除无关数据

现实世界的数据既凌乱又脏乱。除了技术性问题，如缺失值和重复条目外，还存在数据完整性方面的问题。

这在消费类应用行业尤其如此。按设计，消费类应用的使用者数量庞大。消费类应用的一个常见特点是它们极度依赖促销策略。然而，存在一类特定的用户，他们非常 opportunistic（机会主义）。如果他们认为某项促销策略具有价值，他们可能会下很多订单以最大化其利益。这种异常行为可能会对我们的分析造成干扰。

举个例子，假设我们是一个电子商务平台的数据分析师。我们被分配了一个有趣的项目：分析每个产品类别的自然重新订购间隔。换句话说，我们想了解：用户通常需要多少天重新订购蔬菜？用户通常多久重新订购洗衣液？零食呢？牛奶呢？等等。这些信息将由CRM团队用来发送及时的订单提醒。

为了回答这个问题，我们检查了过去6个月的交易数据，目的是获得每个产品类别的中位数重新订购间隔。假设我们得到了以下结果。

![](../Images/e7b1e2e36dd33ed22c5a73d6943bf7c2.png)

每个产品类别的中位数重新订购间隔（图源：作者）

从数据来看，结果有些出乎意料。表格显示，米的中位数重新订购间隔为3天，食用油为2天。洗衣液和洗洁精的中位数重新订购间隔为5天。另一方面，蔬菜、牛奶和零食的订单频率大致符合我们的预期：蔬菜每周购买一次，牛奶和零食每月购买两次。

我们应该将这些发现报告给CRM团队吗？别急！

真的吗？人们每3天就购买一次米，或者每2天就购买一次食用油？这种消费者究竟是怎样的呢？

在重新审视数据时，我们发现了一群用户进行交易的频率极高——甚至是每天都在交易。这些过度购买主要集中在受欢迎的非易腐商品上，且对应的产品类别在我们的研究中显示出令人惊讶的低中位数重新订购间隔。

我们认为这些超级频繁的用户并不代表我们的典型目标客户。因此，我们将他们从分析中排除，并生成了更新后的研究结果。

![](../Images/56fbc0701a5dffac390d4718577925ac.png)

更新后的中位数重新订购数据（图源：作者）

现在一切都说得通了。米、食用油、洗衣液和洗洁精的真实重新订购节奏，已被这些异常的超级频繁用户所扭曲，这些用户与我们的分析无关。在剔除这些异常值之后，我们发现人们通常每14天（每两周）重新订购一次米和食用油，而洗衣液和洗洁精则是按月购买的。

现在我们有信心与CRM团队分享这些洞察！

在行业中，从分析中去除无关数据的做法既常见又至关重要。在实际数据中，异常现象很常见，我们需要排除它们，以防止我们的结果受到它们极端行为的扭曲，而这些行为并不代表我们典型用户的行为。

## 应用帕累托原则

我想分享的最后一个原则是如何在分析数据时获得最大效益。为此，我们将应用帕累托原则。

帕累托原则指出，对于许多结果，**大约80%的后果来自20%的原因。**

根据我的行业经验，我观察到帕累托原则在许多场景中都有体现：只有少数产品贡献了大部分销售额，只有少数城市拥有大部分客户群，等等。我们可以在数据分析中运用这一原则，以节省时间和精力，创造出有效的洞察。

假设我们正在为一个跨越印度尼西亚所有一线和二线城市的电子商务平台工作（这些城市有几十个）。我们的任务是基于城市分析用户交易概况，涉及的指标包括购物车大小、交易频率、购买的产品、运输SLA以及用户地址距离等。

在初步查看数据后，我们发现85%的销售额来自仅仅三个城市：雅加达、万隆和泗水。考虑到这一点，将我们的分析重点放在这三个城市上比试图分析所有城市更有意义（后者就像是在“煮海洋”，收效递减）。

采用这一策略，我们最大程度地减少了工作量，同时仍然实现了关键分析目标。所获得的洞察将保持有意义和相关，因为它们来源于大多数人群。此外，基于这些洞察得出的商业建议，按定义将对整个群体产生重大影响，从而依然具有强大的影响力。

应用帕累托原则的另一个优点与建立MECE分组有关。在我们的例子中，我们可以将城市分为四组：雅加达、万隆、泗水和“其他”（将所有剩余的城市合并为一组）。通过这种方式，帕累托原则有助于简化我们的MECE分组：每个主要贡献的城市独立存在，而其余的城市（超过帕累托阈值的）被合并为一个单独的组。

# 结语

感谢你坚持阅读完本文的最后部分！

在这篇文章中，我们讨论了六个数据分析原则，这些原则可以帮助我们更有效地发现洞察。这些原则来源于我多年的行业经验，并且在我的EDA实践中极为有用。希望你在未来的EDA项目中也能发现这些原则的价值。

再次感谢阅读，让我们在[LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)上联系吧！👋
