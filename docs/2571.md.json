["```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\n# Create two arrays of 100 random values, with high correlation between them\nx_data = np.random.random(100) \ny_data = np.random.random(100) / 10.0\n\n# Create a dataframe with this data plus two additional points\ndata = pd.DataFrame({'A': x_data, 'B': x_data + y_data}) \ndata= pd.concat([data, \n   pd.DataFrame([[1.8, 1.8], [0.5, 0.1]], columns=['A', 'B'])])\n\n# Use PCA to transform the data to another 2D space\npca = PCA(n_components=2) \npca.fit(data)\nprint(pca.explained_variance_ratio_)\n\n# Create a dataframe with the PCA-transformed data\nnew_data = pd.DataFrame(pca.transform(data), columns=['0', '1'])\n```", "```py\npip install pyod\n```", "```py\nimport pandas as pd\nfrom pyod.models.pca import PCA\nfrom pyod.models.ecod import ECOD\nfrom sklearn.datasets import fetch_openml\n\n#A Collects the data\ndata = fetch_openml(\"speech\", version=1, parser='auto') \ndf = pd.DataFrame(data.data, columns=data.feature_names)\nscores_df = df.copy()\n\n# Creates an ECOD detector to clean the data\nclf = ECOD(contamination=0.01) \nclf.fit(df)\nscores_df['ECOD Scores'] = clf.predict(df)\n\n# Creates a clean version of the data, removing the top \n# outliers found by ECOD\nclean_df = df[scores_df['ECOD Scores'] == 0] \n\n# Fits a PCA detector to the clean data\nclf = PCA(contamination=0.02) \nclf.fit(clean_df)\n\n# Predicts on the full data\npred = clf.predict(df) \n```", "```py\ndet = KPCA(kernel='linear')\n```"]