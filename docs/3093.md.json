["```py\ndef generate_sythentic_dataset(dim_sample, num_sapmple, sparsity): \n  \"\"\"Generate synthetic dataset according to sparsity\"\"\"\n  dataset=[]\n  for _ in range(num_sapmple): \n    x = np.random.uniform(0, 1, n)\n    mask = np.random.choice([0, 1], size=n, p=[sparsity, 1 - sparsity])\n    x = x * mask  # Apply sparsity\n    dataset.append(x)\n  return np.array(dataset)\n```", "```py\nclass ReLUModel(nn.Module):\n    def __init__(self, n, m):\n        super().__init__()\n        self.W = nn.Parameter(torch.randn(m, n) * np.sqrt(1 / n))\n        self.b = nn.Parameter(torch.zeros(n))\n\n    def forward(self, x):\n        h = torch.relu(torch.matmul(x, self.W.T))  # Add ReLU activation: x (batch, n) * W.T (n, m) -> h (batch, m)\n        x_reconstructed = torch.relu(torch.matmul(h, self.W) + self.b)  # Reconstruction with ReLU\n        return x_reconstructed \n```"]