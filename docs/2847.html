<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Build your Personal Assistant with Agents and Tools</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Build your Personal Assistant with Agents and Tools</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-personal-assistant-with-agents-and-tools-048637ac308e?source=collection_archive---------0-----------------------#2024-11-24">https://towardsdatascience.com/build-your-personal-assistant-with-agents-and-tools-048637ac308e?source=collection_archive---------0-----------------------#2024-11-24</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="554f" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">LLMs alone suffer from not being able to access external or real-time data. Learn how to build your personal assistant using LangChain agents and Gemini by grounding it in external sources.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@benjamin_47408?source=post_page---byline--048637ac308e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Benjamin Etienne" class="l ep by dd de cx" src="../Images/cad8bc2d4b900575e76b7cf9debc9eea.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*zgmYQ0PJ0MHXIc5mEYVSMA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--048637ac308e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@benjamin_47408?source=post_page---byline--048637ac308e--------------------------------" rel="noopener follow">Benjamin Etienne</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--048637ac308e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 24, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">6</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="8362" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">Summary:</h2><ol class=""><li id="cefd" class="np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh oi oj ok bk">The problem with LLMs</li><li id="6b46" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">What are Agents, Tools and Chains ?</li><li id="252c" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Creating a simple chat without Tools</li><li id="c977" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Adding Tools to our chat: The Google way with Function Calling</li><li id="4531" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Adding Tools to our chat : The Langchain way with Agents</li><li id="4e9a" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Adding Memory to our Agent</li><li id="d743" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Creating a Chain with a Human Validation step</li><li id="3432" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh oi oj ok bk">Using search tools</li></ol></div></div></div><div class="ab cb mj mk ml mm" role="separator"><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp mq"/><span class="mn by bm mo mp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="5b18" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">1. The problem with LLMs</h2><p id="4fd2" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">So you have your favorite chatbot, and you use it for your daily job to boost your productivity. It can translate text, write nice emails, tell jokes, etc. And then comes the day when your colleague comes to you and asks :</p><p id="c7a9" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk"><em class="ov">“Do you know the current exchange rate between USD and EUR ? I wonder if I should sell my EUR…”</em></p><p id="1295" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">You ask your favorite chatbot, and the answer pops :</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="b263" class="pf ms fq pc b bg pg ph l pi pj">I am sorry, I cannot fulfill this request. <br/>I do not have access to real-time information, including financial data <br/>like exchange rates.</span></pre><p id="958a" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk"><em class="ov">What is the problem here ?</em></p><p id="2ce4" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">The problem is that you have stumbled on one of the shortcomings of LLMs. Large Language Models (LLMs) are powerful at solving many types of problems, such as problem solving, text summarization, generation, etc.</p><p id="0abd" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">However, they are constrained by the following limitations:</p><ul class=""><li id="193c" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk"><strong class="nr fr">They are frozen after training, leading to stale knowledge.</strong></li><li id="6858" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk"><strong class="nr fr">They can’t query or modify external data.</strong></li></ul><p id="896e" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Same way as we are using search engines every day, reading books and documents or querying databases, we would ideally want to provide this knowledge to our LLM to make it more efficient.</p><p id="6eb4" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Fortunately, there is a way to do that: Tools and Agents.</p><blockquote class="pl pm pn"><p id="c466" class="np nq ov nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Foundational models, despite their impressive text and image generation, remain constrained by their inability to interact with the outside world. Tools bridge this gap, empowering agents to interact with external data and services while unlocking a wider range of actions beyond that of the underlying model alone</p></blockquote><p id="f7fe" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk"><em class="ov">(source : Google Agents whitepaper)</em></p><p id="95d3" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Using agents and tools, we could then be able to, from our chat interface:</p><ul class=""><li id="8616" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">retrieve data from our own documents</li><li id="d440" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">read / send emails</li><li id="8329" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">interact with internal databases</li><li id="2149" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">perform real time Google searches</li><li id="1885" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">etc.</li></ul><h2 id="e52e" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">2. What are Agents, Tools and Chains ?</h2><p id="9aec" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">An <em class="ov">agent</em> is an application which attempts to achieve a goal (or a task) by having at its disposal a set of tools and taking decisions based on its observations of the environment.</p><p id="cede" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">A good example of an agent could be you, for example: if you need to compute a complex mathematical operation (goal), you could use a calculator (tool #1), or a programming language (tool #2). Maybe you would choose the calculator to do a simple addition, but choose tool #2 for more complex algorithms.</p><p id="786c" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Agents are therefore made of :</p><ul class=""><li id="fc19" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">A model : The brain in our agent is the LLM. It will understand the query (the goal), and browse through its tools available to select the best.</li><li id="b236" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">One or more <em class="ov">tools</em> : These are functions, or APIs, that are responsible for performing a specific action (ie: retrieving the current currency rate for USD vs EUR, adding numbers, etc.)</li><li id="01a3" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">An orchestration process: this is how the model will behave when asked to solve a task. It is a cognitive process that defines how the model will analyze the problem, refine inputs, choose a tool, etc. Examples of such processes are ReAct, CoT (Chain of Thought), ToT (Tree-of-Thought)</li></ul><p id="a9f2" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Here is below a workflow explanation</p><figure class="ow ox oy oz pa pr po pp paragraph-image"><div role="button" tabindex="0" class="ps pt ed pu bh pv"><div class="po pp pq"><img src="../Images/85a293f46127b027cf0d29236c2e7d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DTC_r3ofnQ6HsIwm_lIzkQ.png"/></div></div><figcaption class="px py pz po pp qa qb bf b bg z dx">image by author</figcaption></figure><p id="81ca" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk"><em class="ov">Chains </em>are somehow different. Whereas agents can ‘decide’ by themselves what to do and which steps to take, chains are just a sequence of predefined steps. They can still rely on tools though, meaning that they can include a step in which they need to select from available tools. We’ll cover that later.</p><h2 id="48ef" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">3. Creating a simple chat without Tools</h2><p id="fc1f" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">To illustrate our point, we will first of all see how our LLM performs as-is, without any help.</p><p id="1955" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s install the needed libraries :</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="5362" class="pf ms fq pc b bg pg ph l pi pj">vertexai==1.65.0<br/>langchain==0.2.16<br/>langchain-community==0.2.16<br/>langchain-core==0.2.38<br/>langchain-google-community==1.0.8<br/>langchain-google-vertexai==1.0.6</span></pre><p id="4336" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">And create our very simple chat using Google’s Gemini LLM:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="be11" class="pf ms fq pc b bg pg ph l pi pj">from vertexai.generative_models import (<br/>    GenerativeModel,<br/>    GenerationConfig,<br/>    Part<br/>)<br/><br/>gemini_model = GenerativeModel(<br/>    "gemini-1.5-flash",<br/>    generation_config=GenerationConfig(temperature=0),<br/>)<br/>chat = gemini_model.start_chat()</span></pre><p id="7ce2" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">If you run this simple chat and ask a question about the current exchange rate, you might probably get a similar answer:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="627c" class="pf ms fq pc b bg pg ph l pi pj">response = chat.send_message("What is the current exchange rate for USD vs EUR ?")<br/>answer = response.candidates[0].content.parts[0].text<br/><br/>--- OUTPUT ---<br/>"I am sorry, I cannot fulfill this request. I do not have access to real-time information, including financial data like exchange rates."<br/></span></pre><p id="92f1" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Not surprising, as we know LLMs do not have access to real-time data.</p><p id="d34a" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s add a tool for that. Our tool will be little function that calls an API to retrieve exchange rate data in real time.</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="41f8" class="pf ms fq pc b bg pg ph l pi pj">def get_exchange_rate_from_api(params):<br/>    url = f"https://api.frankfurter.app/latest?from={params['currency_from']}&amp;to={params['currency_to']}"<br/>    print(url)<br/>    api_response = requests.get(url)<br/>    return api_response.text<br/><br/># Try it out !<br/>get_exchange_rate_from_api({'currency_from': 'USD', 'currency_to': 'EUR'})<br/>---<br/>'{"amount":1.0,"base":"USD","date":"2024-11-20","rates":{"EUR":0.94679}}'</span></pre><p id="0daf" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Now we know how our tools works, we would like to tell our chat LLM to use this function to answer our question. We will therefore create a mono-tool agent. To do that, we have several options which I will list here:</p><ul class=""><li id="3081" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">Use Google’s Gemini chat API with Function Calling</li><li id="f035" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">Use LangChain’s API with Agents and Tools</li></ul><p id="c76b" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Both have their advantages and drawbacks. The purpose of this article is also to show you the possibilities and let you decide which one you prefer.</p><h2 id="c615" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">4. Adding Tools to our chat: The Google way with Function Calling</h2><p id="4704" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">There are basically two ways of creating a tool out of a function.</p><p id="7c4c" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">The 1st one is a “dictionary” approach where you specify inputs and description of the function in the Tool. The imporant parameters are:</p><ul class=""><li id="b737" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">Name of the function (be explicit)</li><li id="1082" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">Description : be verbose here, as a solid and exhaustive description will help the LLM select the right tool</li><li id="cec4" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">Parameters : this is where you specify your arguments (type and description). Again, be verbose in the description of your arguments to help the LLM know how to pass value to your function</li></ul><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="7c2a" class="pf ms fq pc b bg pg ph l pi pj">import requests<br/><br/>from vertexai.generative_models import FunctionDeclaration<br/><br/>get_exchange_rate_func = FunctionDeclaration(<br/>    name="get_exchange_rate",<br/>    description="Get the exchange rate for currencies between countries",<br/>    parameters={<br/>    "type": "object",<br/>    "properties": {<br/>        "currency_from": {<br/>            "type": "string",<br/>            "description": "The currency to convert from in ISO 4217 format"<br/>        },<br/>        "currency_to": {<br/>            "type": "string",<br/>            "description": "The currency to convert to in ISO 4217 format"<br/>        }<br/>    },<br/>        "required": [<br/>            "currency_from",<br/>            "currency_to",<br/>      ]<br/>  },<br/>)</span></pre><p id="bd44" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">The 2nd way of adding a tool using Google’s SDK is with a <code class="cx qc qd qe pc b">from_func</code> instantiation. This requires editing our original function to be more explicit, with a docstring, etc. Instead of being verbose in the Tool creation, we are being verbose in the function creation.</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="b6f4" class="pf ms fq pc b bg pg ph l pi pj"># Edit our function<br/>def get_exchange_rate_from_api(currency_from: str, currency_to: str):<br/>    """<br/>    Get the exchange rate for currencies   <br/>  <br/>    Args:<br/>        currency_from (str): The currency to convert from in ISO 4217 format<br/>        currency_to (str): The currency to convert to in ISO 4217 format<br/>    """<br/>    url = f"https://api.frankfurter.app/latest?from={currency_from}&amp;to={currency_to}"<br/>    api_response = requests.get(url)<br/>    return api_response.text<br/><br/># Create the tool<br/>get_exchange_rate_func = FunctionDeclaration.from_func(<br/>  get_exchange_rate_from_api<br/>)</span></pre><p id="bbbf" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">The next step is really about creating the tool. For that, we will add our FunctionDeclaration to a list to create our Tool object:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="e2a0" class="pf ms fq pc b bg pg ph l pi pj">from vertexai.generative_models import Tool as VertexTool<br/><br/>tool = VertexTool(<br/>    function_declarations=[<br/>        get_exchange_rate_func,<br/>        # add more functions here !<br/>    ]<br/>)</span></pre><p id="d3dd" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s now pass that to our chat and see if it now can answer our query about exchange rates ! Remember, without tools, our chat answered:</p><figure class="ow ox oy oz pa pr po pp paragraph-image"><div role="button" tabindex="0" class="ps pt ed pu bh pv"><div class="po pp qf"><img src="../Images/8206400b049669a30d50ea74965d1d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xqq7PfZymMoJeqJyPdXMxA.png"/></div></div></figure><p id="ebc6" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s try Google’s Function calling tool and see if this helps ! First, let’s send our query to the chat:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="e6d0" class="pf ms fq pc b bg pg ph l pi pj">from vertexai.generative_models import GenerativeModel<br/><br/>gemini_model = GenerativeModel(<br/>    "gemini-1.5-flash",<br/>    generation_config=GenerationConfig(temperature=0),<br/>    tools=[tool] #We add the tool here !<br/>)<br/>chat = gemini_model.start_chat()<br/><br/>response = chat.send_message(prompt)<br/><br/># Extract the function call response<br/>response.candidates[0].content.parts[0].function_call<br/><br/>--- OUTPUT ---<br/>"""<br/>name: "get_exchange_rate"<br/>args {<br/>  fields {<br/>    key: "currency_to"<br/>    value {<br/>      string_value: "EUR"<br/>    }<br/>  }<br/>  fields {<br/>    key: "currency_from"<br/>    value {<br/>      string_value: "USD"<br/>    }<br/>  }<br/>  fields {<br/>    key: "currency_date"<br/>    value {<br/>      string_value: "latest"<br/>    }<br/>  }<br/>}"""<br/></span></pre><p id="7d3a" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">The LLM correctly guessed it needed to use the <code class="cx qc qd qe pc b">get_exchange_rate</code> function, and also correctly guessed the 2 parameters were <code class="cx qc qd qe pc b">USD</code> and <code class="cx qc qd qe pc b">EUR</code> .</p><p id="2dd5" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">But this is not enough. What we want now is to actually run this function to get our results!</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="f4bb" class="pf ms fq pc b bg pg ph l pi pj"># mapping dictionnary to map function names and function<br/>function_handler = {<br/>    "get_exchange_rate": get_exchange_rate_from_api,<br/>}<br/><br/># Extract the function call name<br/>function_name = function_call.name<br/>print("#### Predicted function name")<br/>print(function_name, "\n")<br/><br/># Extract the function call parameters<br/>params = {key: value for key, value in function_call.args.items()}<br/>print("#### Predicted function parameters")<br/>print(params, "\n")<br/><br/>function_api_response = function_handler[function_name](params)<br/>print("#### API response")<br/>print(function_api_response)<br/>response = chat.send_message(<br/>    Part.from_function_response(<br/>        name=function_name,<br/>        response={"content": function_api_response},<br/>    ),<br/>)   <br/>print("\n#### Final Answer")<br/>print(response.candidates[0].content.parts[0].text)<br/><br/>--- OUTPUT ---<br/>"""<br/>#### Predicted function name<br/>get_exchange_rate <br/><br/>#### Predicted function parameters<br/>{'currency_from': 'USD', 'currency_date': 'latest', 'currency_to': 'EUR'} <br/><br/><br/>#### API response<br/>{"amount":1.0,"base":"USD","date":"2024-11-20","rates":{"EUR":0.94679}}<br/><br/>#### Final Answer<br/>The current exchange rate for USD vs EUR is 0.94679. This means that 1 USD is equal to 0.94679 EUR. <br/>"""</span></pre><p id="aea4" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">We can now see our chat is able to answer our question! It:</p><ul class=""><li id="9691" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">Correctly guessed to function to call, <code class="cx qc qd qe pc b">get_exchange_rate</code></li><li id="e83c" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">Correctly assigned the parameters to call the function <code class="cx qc qd qe pc b">{‘currency_from’: ‘USD’, ‘currency_to’: ‘EUR’}</code></li><li id="d4f7" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">Got results from the API</li><li id="8d87" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">And nicely formatted the answer to be human-readable!</li></ul><p id="cc91" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s now see another way of doing with LangChain.</p><h2 id="a46a" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">5. Adding Tools to our chat: The Langchain way with Agents</h2><p id="0a5b" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">LangChain is a composable framework to build with LLMs. It is the orchestration framework for controllable agentic workflows.</p><p id="e41a" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Similar to what we did before the “Google” way, we will build tools in the Langchain way. Let’s begin with defining our functions. Same as for Google, we need to be exhaustive and verbose in the docstrings:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="2221" class="pf ms fq pc b bg pg ph l pi pj">from langchain_core.tools import tool<br/><br/>@tool<br/>def get_exchange_rate_from_api(currency_from: str, currency_to: str) -&gt; str:<br/>    """<br/>    Return the exchange rate between currencies<br/>    Args:<br/>        currency_from: str<br/>        currency_to: str<br/>    """<br/>    url = f"https://api.frankfurter.app/latest?from={currency_from}&amp;to={currency_to}"<br/>    api_response = requests.get(url)<br/>    return api_response.text</span></pre><p id="eabd" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">In order to spice things up, I will add another tool which can list tables in a BigQuery dataset. Here is the code:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="6173" class="pf ms fq pc b bg pg ph l pi pj">@tool<br/>def list_tables(project: str, dataset_id: str) -&gt; list:<br/>    """<br/>    Return a list of Bigquery tables<br/>    Args:<br/>        project: GCP project id<br/>        dataset_id: ID of the dataset<br/>    """<br/>    client = bigquery.Client(project=project)<br/>    try:<br/>        response = client.list_tables(dataset_id)<br/>        return [table.table_id for table in response]<br/>    except Exception as e:<br/>        return f"The dataset {params['dataset_id']} is not found in the {params['project']} project, please specify the dataset and project"</span></pre><p id="987e" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Add once done, we add our functions to our LangChain toolbox !</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="c97c" class="pf ms fq pc b bg pg ph l pi pj">langchain_tool = [<br/>    list_tables,<br/>    get_exchange_rate_from_api<br/>]</span></pre><p id="c050" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">To build our agent, we will use the <code class="cx qc qd qe pc b">AgentExecutor</code>object from LangChain. This object will basically take 3 components, which are the ones we defined earlier :</p><ul class=""><li id="402f" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">A LLM</li><li id="4ed5" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">A prompt</li><li id="b78a" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">And tools.</li></ul><p id="4e67" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s first choose our LLM:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="5670" class="pf ms fq pc b bg pg ph l pi pj">gemini_llm = ChatVertexAI(model="gemini-1.5-flash")</span></pre><p id="63d9" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Then we create a prompt to manage the conversation:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="3f7e" class="pf ms fq pc b bg pg ph l pi pj">prompt = ChatPromptTemplate.from_messages(<br/>    [<br/>        ("system", "You are a helpful assistant"),<br/>        ("human", "{input}"),<br/>        # Placeholders fill up a **list** of messages<br/>        ("placeholder", "{agent_scratchpad}"),<br/>    ]<br/>)</span></pre><p id="ae2a" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">And finally, we create the <code class="cx qc qd qe pc b">AgentExecutor</code> and run a query:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="5b15" class="pf ms fq pc b bg pg ph l pi pj">agent = create_tool_calling_agent(gemini_llm, langchain_tools, prompt)<br/>agent_executor = AgentExecutor(agent=agent, tools=langchain_tools)<br/>agent_executor.invoke({<br/>    "input": "Which tables are available in the thelook_ecommerce dataset ?"<br/>})<br/><br/>--- OUTPUT ---<br/>"""<br/>{'input': 'Which tables are available in the thelook_ecommerce dataset ?',<br/> 'output': 'The dataset `thelook_ecommerce` is not found in the `gcp-project-id` project. <br/>            Please specify the correct dataset and project. \n'}<br/>"""<br/></span></pre><p id="c3ce" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Hmmm. Seems like the agent is missing one argument, or at least asking for more information…Let’s reply by giving this information:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="dfb0" class="pf ms fq pc b bg pg ph l pi pj">agent_executor.invoke({"input": f"Project id is bigquery-public-data"})<br/><br/>--- OUPTUT ---<br/>"""<br/>{'input': 'Project id is bigquery-public-data',<br/> 'output': 'OK. What else can I do for you? \n'}<br/>"""<br/></span></pre><p id="8449" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Well, seems we’re back to square one. The LLM has been told the project id but forgot about the question. Our agent seems to be lacking memory to remember previous questions and answers. Maybe we should think of…</p><h2 id="d7fa" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">6. Adding Memory to our Agent</h2><p id="466b" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">Memory is another concept in Agents, which basically helps the system to remember the conversation history and avoid endless loops like above. Think of memory as being a notepad where the LLM keeps track of previous questions and answers to build context around the conversation.</p><p id="9ad8" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">We will modify our prompt (instructions) to the model to include memory:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="ec52" class="pf ms fq pc b bg pg ph l pi pj">from langchain_core.chat_history import InMemoryChatMessageHistory<br/>from langchain_core.runnables.history import RunnableWithMessageHistory<br/><br/># Different types of memory can be found in Langchain<br/>memory = InMemoryChatMessageHistory(session_id="foo")<br/><br/>prompt = ChatPromptTemplate.from_messages(<br/>    [<br/>        ("system", "You are a helpful assistant."),<br/>        # First put the history<br/>        ("placeholder", "{chat_history}"),<br/>        # Then the new input<br/>        ("human", "{input}"),<br/>        # Finally the scratchpad<br/>        ("placeholder", "{agent_scratchpad}"),<br/>    ]<br/>)<br/><br/># Remains unchanged<br/>agent = create_tool_calling_agent(gemini_llm, langchain_tools, prompt)<br/>agent_executor = AgentExecutor(agent=agent, tools=langchain_tools)<br/><br/># We add the memory part and the chat history<br/>agent_with_chat_history = RunnableWithMessageHistory(<br/>    agent_executor,<br/>    lambda session_id: memory, #&lt;-- NEW<br/>    input_messages_key="input", <br/>    history_messages_key="chat_history", #&lt;-- NEW<br/>)<br/><br/>config = {"configurable": {"session_id": "foo"}}</span></pre><p id="c89f" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">We will now rerun our query from the beginning:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="779b" class="pf ms fq pc b bg pg ph l pi pj">agent_with_chat_history.invoke({<br/>    "input": "Which tables are available in the thelook_ecommerce dataset ?"<br/>    }, <br/>    config<br/>)<br/><br/>--- OUTPUT ---<br/>"""<br/>{'input': 'Which tables are available in the thelook_ecommerce dataset ?',<br/> 'chat_history': [],<br/> 'output': 'The dataset `thelook_ecommerce` is not found in the `gcp-project-id` project. Please specify the correct dataset and project. \n'}<br/>"""</span></pre><p id="3f4e" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">With an empty chat history, the model still asks for the project id. Pretty consistent with what we had before with a memoryless agent. Let’s reply to the agent and add the missing information:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="92b4" class="pf ms fq pc b bg pg ph l pi pj">reply = "Project id is bigquery-public-data"<br/>agent_with_chat_history.invoke({"input": reply}, config)<br/><br/>--- OUTPUT ---<br/>"""<br/>{'input': 'Project id is bigquery-public-data',<br/> 'chat_history': [HumanMessage(content='Which tables are available in the thelook_ecommerce dataset ?'),<br/>  AIMessage(content='The dataset `thelook_ecommerce` is not found in the `gcp-project-id` project. Please specify the correct dataset and project. \n')],<br/> 'output': 'The following tables are available in the `thelook_ecommerce` dataset:\n- distribution_centers\n- events\n- inventory_items\n- order_items\n- orders\n- products\n- users \n'}<br/>"""</span></pre><p id="dbbb" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Notice how, in the output:</p><ul class=""><li id="7f08" class="np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh pk oj ok bk">The `chat history` keeps track of the previous Q&amp;A</li><li id="6d44" class="np nq fq nr b go ol nt nu gr om nw nx nc on nz oa ng oo oc od nk op of og oh pk oj ok bk">The output now returns the list of the tables!</li></ul><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="9b5c" class="pf ms fq pc b bg pg ph l pi pj">'output': 'The following tables are available in the `thelook_ecommerce` dataset:\n- distribution_centers\n- events\n- inventory_items\n- order_items\n- orders\n- products\n- users \n'}</span></pre><p id="cc54" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">In some use cases however, certain actions might require special attention because of their nature (ie deleting an entry in a database, editing information, sending an email, etc.). Full automation without control might leads to situations where the agent takes wrong decisions and creates damage.</p><p id="7f6c" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">One way to secure our workflows is to add a human-in-the-loop step.</p><h2 id="c657" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">7. Creating a Chain with a Human Validation step</h2><p id="1918" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">A chain is somehow different from an agent. Whereas the agent can decide to use or not to use tools, a chain is more static. It is a sequence of steps, for which we can still include a step where the LLM will choose from a set of tools.</p><p id="4b35" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">To build chains in LangChain, we use LCEL. <br/>LangChain Expression Language, or LCEL, is a declarative way to easily compose chains together. Chains in LangChain use the pipe `|` operator to indicate the orders in which steps have to be executed, such as <code class="cx qc qd qe pc b">step 1 | step 2 | step 3 etc.</code> The difference with Agents is that Chains will always follow those steps, whereas Agents can “decide” by themselves and are autonomous in their decision-making process.</p><p id="0180" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">In our case, we will proceed as follows to build a simple <code class="cx qc qd qe pc b">prompt | llm</code> chain.</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="20db" class="pf ms fq pc b bg pg ph l pi pj"># define the prompt with memory<br/>prompt = ChatPromptTemplate.from_messages(<br/>    [<br/>        ("system", "You are a helpful assistant."),<br/>        # First put the history<br/>        ("placeholder", "{chat_history}"),<br/>        # Then the new input<br/>        ("human", "{input}"),<br/>        # Finally the scratchpad<br/>        ("placeholder", "{agent_scratchpad}"),<br/>    ]<br/>)<br/><br/># bind the tools to the LLM<br/>gemini_with_tools = gemini_llm.bind_tools(langchain_tool)<br/><br/># build the chain<br/>chain = prompt | gemini_with_tools</span></pre><p id="c2c6" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Remember how in the previous step we passed an agent to our `RunnableWithMessageHistory`? Well, we will do the same here, but...</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="e80d" class="pf ms fq pc b bg pg ph l pi pj"># With AgentExecutor<br/><br/># agent = create_tool_calling_agent(gemini_llm, langchain_tool, prompt)<br/># agent_executor = AgentExecutor(agent=agent, tools=langchain_tool)<br/><br/># agent_with_chat_history = RunnableWithMessageHistory(<br/>#     agent_executor,<br/>#     lambda session_id: memory,<br/>#     input_messages_key="input",<br/>#     history_messages_key="chat_history",<br/># )<br/><br/>config = {"configurable": {"session_id": "foo"}}<br/><br/># With Chains<br/>memory = InMemoryChatMessageHistory(session_id="foo")<br/>chain_with_history = RunnableWithMessageHistory(<br/>    chain,<br/>    lambda session_id: memory,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)<br/><br/>response = chain_with_history.invoke(<br/>    {"input": "What is the current CHF EUR exchange rate ?"}, config)<br/><br/>--- OUTPUT<br/>"""<br/>content='', <br/>additional_kwargs={<br/>    'function_call': {<br/>        'name': 'get_exchange_rate_from_api', <br/>        'arguments': '{"currency_from": "CHF", "currency_to": "EUR"}'<br/>    }<br/>}<br/>"""<br/></span></pre><p id="eb7b" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Unlike the agent, a chain does not provide the answer unless we tell it to. In our case, it stopped at the step where the LLM returns the function that needs to be called.</p><p id="a90b" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">We need to add an extra step to actually <em class="ov">call </em>the tool. Let’s add another function to call the tools:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="99f7" class="pf ms fq pc b bg pg ph l pi pj">from langchain_core.messages import AIMessage<br/><br/>def call_tools(msg: AIMessage) -&gt; list[dict]:<br/>    """Simple sequential tool calling helper."""<br/>    tool_map = {tool.name: tool for tool in langchain_tool}<br/>    tool_calls = msg.tool_calls.copy()<br/>    for tool_call in tool_calls:<br/>        tool_call["output"] = tool_map[tool_call["name"]].invoke(tool_call["args"])<br/>    return tool_calls<br/><br/>chain = prompt | gemini_with_tools | call_tools #&lt;-- Extra step<br/><br/>chain_with_history = RunnableWithMessageHistory(<br/>    chain,<br/>    lambda session_id: memory,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)<br/><br/># Rerun the chain <br/>chain_with_history.invoke({"input": "What is the current CHF EUR exchange rate ?"}, config)</span></pre><p id="96df" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">We now get the following output, which shows the API has been successfully called:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="8422" class="pf ms fq pc b bg pg ph l pi pj">[{'name': 'get_exchange_rate_from_api',<br/>  'args': {'currency_from': 'CHF', 'currency_to': 'EUR'},<br/>  'id': '81bc85ea-dfd4-4c01-85e8-f3ca592fff5b',<br/>  'type': 'tool_call',<br/>  'output': '{"amount":1.0,"base":"USD","date":"2024-11-20","rates":{"EUR":0.94679}}'<br/>}]</span></pre><p id="0f5d" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Now we understood how to chain steps, let’s add our human-in-the-loop step ! We want this step to check that the LLM has understood our requests and will make the right call to an API. If the LLM has misunderstood the request or will use the function incorrectly, we can decide to interrupt the process.</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="e465" class="pf ms fq pc b bg pg ph l pi pj">def human_approval(msg: AIMessage) -&gt; AIMessage:<br/>    """Responsible for passing through its input or raising an exception.<br/><br/>    Args:<br/>        msg: output from the chat model<br/><br/>    Returns:<br/>        msg: original output from the msg<br/>    """<br/>    for tool_call in msg.tool_calls:<br/>        print(f"I want to use function [{tool_call.get('name')}] with the following parameters :")<br/>        for k,v in tool_call.get('args').items():<br/>            print(" {} = {}".format(k, v))<br/>            <br/>    print("")<br/>    input_msg = (<br/>        f"Do you approve (Y|y)?\n\n"<br/>        "&gt;&gt;&gt;"<br/>    )<br/>    resp = input(input_msg)<br/>    if resp.lower() not in ("yes", "y"):<br/>        raise NotApproved(f"Tool invocations not approved:\n\n{tool_strs}")<br/>    return msg</span></pre><p id="105f" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Next, add this step to the chain before the function call:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="e5be" class="pf ms fq pc b bg pg ph l pi pj">chain = prompt | gemini_with_tools | human_approval | call_tools<br/><br/>memory = InMemoryChatMessageHistory(session_id="foo")<br/><br/>chain_with_history = RunnableWithMessageHistory(<br/>    chain,<br/>    lambda session_id: memory,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)<br/><br/>chain_with_history.invoke({"input": "What is the current CHF EUR exchange rate ?"}, config)</span></pre><p id="13cf" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">You will then be asked to confirm that the LLM understood correctly:</p><figure class="ow ox oy oz pa pr po pp paragraph-image"><div class="po pp qg"><img src="../Images/5028f700edfcffd815b18eeb32e9da41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*V8_JOLiDcXDv1QtTpGTAmQ.png"/></div></figure><p id="6aa6" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">This human-in-the-loop step can be very helpful for critical workflows where a misinterpretation from the LLM could have dramatic consequences.</p><h2 id="b557" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">8. Using search tools</h2><p id="921a" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">One of the most convenient tools to retrieve information in real-time are search engines . One way to do that is to use <code class="cx qc qd qe pc b">GoogleSerperAPIWrapper</code> (you will need to register to get an API key in order to use it), which provides a nice interface to query Google Search and get results quickly.</p><p id="0cd1" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Luckily, LangChain already provides a tool for you, so we won’t have to write the function ourselves.</p><p id="1816" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s therefore try to ask a question on yesterday’s event (Nov 20th) and see if our agent can answer. Our question is about Rafael Nadal’s last official game (which he lost to van de Zandschulp).</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="08a1" class="pf ms fq pc b bg pg ph l pi pj">agent_with_chat_history.invoke(<br/>    {"input": "What was the result of Rafael Nadal's latest game ?"}, config)<br/><br/>--- OUTPUT ---<br/>"""<br/>{'input': "What was the result of Rafael Nadal's latest game ?",<br/> 'chat_history': [],<br/> 'output': "I do not have access to real-time information, including sports results. To get the latest information on Rafael Nadal's game, I recommend checking a reliable sports website or news source. \n"}<br/>"""</span></pre><p id="56f8" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Without being able to access Google Search, our model is unable to answer because this information was not available at the time it was trained.</p><p id="26bf" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">Let’s now add our Serper tool to our toolbox and see if our model can use Google Search to find the information:</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="b0e1" class="pf ms fq pc b bg pg ph l pi pj">from langchain_community.utilities import GoogleSerperAPIWrapper<br/><br/># Create our new search tool here<br/>search = GoogleSerperAPIWrapper(serper_api_key="...")<br/><br/>@tool<br/>def google_search(query: str):<br/>    """<br/>    Perform a search on Google<br/>    Args:<br/>        query: the information to be retrieved with google search<br/>    """<br/>    return search.run(query)<br/><br/># Add it to our existing tools<br/>langchain_tool = [<br/>    list_datasets,<br/>    list_tables,<br/>    get_exchange_rate_from_api,<br/>    google_search<br/>]<br/><br/># Create agent<br/>agent = create_tool_calling_agent(gemini_llm, langchain_tool, prompt)<br/>agent_executor = AgentExecutor(agent=agent, tools=langchain_tool)<br/><br/># Add memory<br/>memory = InMemoryChatMessageHistory()<br/>agent_with_chat_history = RunnableWithMessageHistory(<br/>    agent_executor,<br/>    lambda session_id: memory,<br/>    input_messages_key="input",<br/>    history_messages_key="chat_history",<br/>)</span></pre><p id="1bd0" class="pw-post-body-paragraph np nq fq nr b go oq nt nu gr or nw nx nc os nz oa ng ot oc od nk ou of og oh fj bk">And rerun our query :</p><pre class="ow ox oy oz pa pb pc pd bp pe bb bk"><span id="6be1" class="pf ms fq pc b bg pg ph l pi pj">agent_with_chat_history.invoke({"input": "What was the result of Rafael Nadal's latest game ?"}, config)<br/><br/>--- OUTPUT ---<br/>"""<br/>{'input': "What was the result of Rafael Nadal's latest game ?",<br/> 'chat_history': [],<br/> 'output': "Rafael Nadal's last match was a loss to Botic van de Zandschulp in the Davis Cup. Spain was eliminated by the Netherlands. \n"}<br/>"""<br/></span></pre><h2 id="6959" class="mr ms fq bf mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bk">Conclusion</h2><p id="e8e4" class="pw-post-body-paragraph np nq fq nr b go ns nt nu gr nv nw nx nc ny nz oa ng ob oc od nk oe of og oh fj bk">LLMs alone often hit a blocker when it comes to using personal, corporate, private or real-data. Indeed, such information is generally not available at training time. Agents and tools are a powerful way to augment these models by allowing them to interact with systems and APIs, and orchestrate workflows to boost productivity.</p></div></div></div></div>    
</body>
</html>