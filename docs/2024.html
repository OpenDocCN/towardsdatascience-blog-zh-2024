<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Integrating LLM Agents with LangChain into VICA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Integrating LLM Agents with LangChain into VICA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/integrating-llm-agents-with-langchain-into-vica-d18a5c8583c6?source=collection_archive---------7-----------------------#2024-08-20">https://towardsdatascience.com/integrating-llm-agents-with-langchain-into-vica-d18a5c8583c6?source=collection_archive---------7-----------------------#2024-08-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="0412" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Learn how we use LLM Agents to improve and customise transactions in a chatbot!</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@weichengac2?source=post_page---byline--d18a5c8583c6--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ng Wei Cheng" class="l ep by dd de cx" src="../Images/8f5701a71082a398fd17faaf7742a353.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*1p7--bZzrwcXmpSOczYkfA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d18a5c8583c6--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@weichengac2?source=post_page---byline--d18a5c8583c6--------------------------------" rel="noopener follow">Ng Wei Cheng</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d18a5c8583c6--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="e4cd" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><em class="ne">Contributors: </em><span class="ia"><span class="ia" aria-hidden="false"><a class="nf ib ng" href="https://medium.com/u/42a2dbebb150?source=post_page---user_mention--d18a5c8583c6--------------------------------" rel="noopener" target="_blank"><em class="ne">Nicole Ren</em></a></span></span><em class="ne"> (GovTech), </em><span class="ia"><span class="ia" aria-hidden="false"><a class="nf ib ng" href="https://medium.com/u/8513221718ba?source=post_page---user_mention--d18a5c8583c6--------------------------------" rel="noopener" target="_blank"><em class="ne">Ng Wei Cheng</em></a></span></span><em class="ne"> (GovTech)</em></p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni nj"><img src="../Images/1fb86611219fcf4022200f541e0b5d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N8B8j5UbDSAKh6KyPDdj0A.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">VICA Logo, Image by Authors</figcaption></figure><p id="72bd" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">VICA (Virtual Intelligent Chat Assistant) is GovTech’s Virtual Assistant platform that leverages Artificial Intelligence (AI) to allow users to create, train and deploy chatbots on their websites. At the time of writing, VICA supports over 100 chatbots and handles over 700,000 user queries in a month.</p><p id="4f98" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Behind the scenes, VICA’s NLP engine makes use of various technologies and frameworks ranging from traditional intent-matching systems to generative AI frameworks like Retrieval Augmented Generation (RAG). By keeping up to date with state-of-the-art technologies, our engine is constantly evolving, ensuring that every citizen’s query gets matched to the best possible answer.</p><p id="eb52" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Beyond simple Question-And-Answer (Q&amp;A) capabilities, VICA aims to supercharge chatbots through conversational transactions. Our goal is to say goodbye to the robotic and awkward form-like experience within a chatbot, and say hello to personalized conversations with human-like assistance.</p><p id="333b" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">This article is the first in a two part article series to share more about the generative AI solutions we have built in VICA. In this article, we will focus on how LLM agents can help improve the transaction process in chatbots through using LangChain’s Agent Framework.</p><h1 id="87c0" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Table of Content</h1><ol class=""><li id="f33a" class="mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd pb pc pd bk"><a class="af pe" href="#e397" rel="noopener ugc nofollow">Introduction</a></li><li id="cf6a" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#cf6a" rel="noopener ugc nofollow">All about LangChain</a></li><li id="0cf1" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#330f" rel="noopener ugc nofollow">LangChain in production</a></li><li id="8e4a" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#0c17" rel="noopener ugc nofollow">Challenges of productionizing LangChain</a></li><li id="b4fd" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#5722" rel="noopener ugc nofollow">Use case of LLM Agents</a></li><li id="8184" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#7b85" rel="noopener ugc nofollow">Conclusion</a></li><li id="e67e" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#3efe" rel="noopener ugc nofollow">Find out more about VICA</a></li><li id="fb88" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#a315" rel="noopener ugc nofollow">Acknowledgements</a></li><li id="c191" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd pb pc pd bk"><a class="af pe" href="#d2f2" rel="noopener ugc nofollow">References</a></li></ol><h1 id="e397" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Introduction</h1><figure class="nk nl nm nn no np nh ni paragraph-image"><div class="nh ni pk"><img src="../Images/7582b660359d7ace3309b965ab0356aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*HTULJI9sLlOrIHytzAx4wQ.png"/></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample transaction chatbot conversation, Image by Authors</figcaption></figure><p id="61f0" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Transaction-based chatbots are conversational agents designed to facilitate and execute specific transactions for users. These chatbots go beyond simple Q&amp;A interactions that occur by allowing users to perform tasks such as booking, purchasing, or form submission directly within the chatbot interface.</p><p id="7cef" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In order to perform transactions, the chatbots have to be customized on the backend to handle additional user flows and make API calls.</p><p id="5f67" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">With the rise of Large Language Models (LLMs), it has opened new avenues for simplifying and enhancing the development of these features for chatbots. LLMs can greatly improve a chatbot’s ability to comprehend and respond to a wide range of queries, helping to manage complex transactions more effectively.</p><p id="18de" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Even though intent-matching chatbot systems already exist to guide users through predefined flows for transactions, LLMs offer significant advantages by maintaining context over multi-turn interactions and handling a wide range of inputs and language variations. Previously, interactions often felt awkward and stilted, as users were required to select options from premade cards or type specific phrases in order to trigger a transaction flow. For example, a slight variation from “Can I make a payment?” to “Let me pay, please” could prevent the transaction flow from triggering. In contrast, LLMs can adapt to various communication styles allowing them to interpret user input that doesn’t fit neatly into predefined intents.</p><p id="5653" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Recognizing this potential, our team decided to leverage LLMs for transaction processing, enabling users to enter transaction flows more naturally and flexibly by breaking down and understanding their intentions. Given that LangChain offers a framework for implementing agentic workflows, we chose to utilize their agent framework to create an intelligent system to process transactions.</p><p id="0920" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In this article, we will also share two use cases we developed that utilize LLM Agents, namely The Department of Statistics (DOS) Statistic Table Builder, and the Natural Conversation Facility Booking chatbot.</p><h1 id="bcea" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">All about LangChain</h1><p id="18a6" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">Before we cover how we made use of LLM Agents to perform transactions, we will first share on what is LangChain and why we opted to experiment with this framework.</p><h2 id="6ae1" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">What is LangChain?</h2><p id="0e43" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">LangChain is an open-source Python framework designed to assist developers in building AI powered applications leveraging LLMs.</p><h2 id="7a08" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">Why use LangChain?</h2><p id="deac" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">The framework helps to simplify the development process by providing abstractions and templates that enable rapid application building, saving time and reducing the need for our development team to code everything from scratch. This allows for us to focus on higher-level functionality and business logic rather than low-level coding details. An example of this is how LangChain helps to streamline third party integration with popular service providers like MongoDB, OpenAI, and AWS, facilitating quicker prototyping and reducing the complexity of integrating various services. These abstractions not only accelerate development but also improve collaboration by providing a consistent structure, allowing our team to efficiently build, test, and deploy AI applications.</p><h2 id="a093" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">What is LangChain’s Agent Framework?</h2><p id="a142" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">One of the main features of using Langchain is their agent framework. The framework allows for management of intelligent agents that interact with LLMs and other tools to perform complex tasks.</p><p id="95dc" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The 3 main components of the framework are</p><ul class=""><li id="d8f4" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd qc pc pd bk"><strong class="mk fr">Agents</strong></li></ul><p id="c883" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Agents act as a reasoning engine as they decide the appropriate actions to take and the order to take these actions. They make use of an LLM to make the decisions for them. An agent has an <em class="ne">AgentExecutor </em>that calls the agent and executes the tools the agent chooses. It also takes the output of the action and passes it to the agent until the final outcome is reached.</p><ul class=""><li id="2b43" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd qc pc pd bk"><strong class="mk fr">Tools</strong></li></ul><p id="4ca6" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Tools are interfaces that the agent can make use of. In order to create a tool, a name and description needs to be provided. The description and name of the tool are important as it will be added into the agent prompt. This means that the agent will decide the tool to use based on the name and description provided.</p><ul class=""><li id="60fc" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd qc pc pd bk"><strong class="mk fr">Chains</strong></li></ul><p id="861b" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">A chain refer to sequences of calls. The chain can be coded out steps or just a call to an LLM or a tool. Chains can be customized or be used off-the-shelf based on what LangChain provides. A simple example of a chain is <em class="ne">LLMChain</em>, a chain that run queries against LLMs.</p><h1 id="330f" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">LangChain in production</h1><h2 id="46c6" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">How did we use LangChain in VICA?</h2><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni qd"><img src="../Images/34e72ebaa9b5b4b0f9757bef59ae8d5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCmCnYw8ztQIJ9Nm2R-VTQ.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample high level microservice architecture diagram, Image by Authors</figcaption></figure><p id="ce44" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In VICA, we set up a microservice for LangChain invoked through REST API. This helps to facilitate integration by allowing different components of VICA to communicate with LangChain independently. As a result, we can efficiently build our LLM agent without being affected by changes or development in other components of the system.</p><p id="1ac0" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">LangChain as a framework is pretty extensive when it comes to the LLM space, covering retrieval methods, agents and LLM evaluation. Here are the components we made use of when developing our LLM Agent.</p><p id="a2ed" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">ReAct Agent</strong></p><p id="c265" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In VICA, we made use of a single agent system. The agent makes use of ReAct logic to determine the sequence of actions to take (Yao et al., 2022). This prompt engineering technique will help generate the following:</p><ul class=""><li id="9f7b" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd qc pc pd bk">Thought (Reasoning taken before choosing the action)</li><li id="cc1a" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Action (Action to take, often a tool)</li><li id="9ea2" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Action Input (Input to the action)</li><li id="7d8f" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Observation (Observation from the tool output)</li><li id="8ebc" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Final Answer (Generative final answer that the agent returns)</li></ul><pre class="nk nl nm nn no qe qf qg bp qh bb bk"><span id="2129" class="qi ob fq qf b bg qj qk l ql qm">&gt; Entering new AgentExecutor chain…<br/>The user wants to know the weather today<br/>Action: Weather Tool<br/>Action Input: "Weather today"<br/>Observation: Answer: "31 Degrees Celsius, Sunny"<br/>Thought: I now know the final answer.<br/>Final Answer: The weather today is sunny at 31 degrees celsius.<br/>&gt; Finished chain.</span></pre><p id="c404" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the above example, the agent was able to understand the user’s intention prior to choosing the tool to use. There was also verbal reasoning being generated that helps the model plan the sequence of action to take. If the observation is insufficient to answer the question given, the agent can cycle to a different action in order to get closer to the final answer.</p><p id="5072" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In VICA, we edited the agent prompt to better suit our use case. The base prompt provided by LangChain (<a class="af pe" href="https://smith.langchain.com/hub/hwchase17/react" rel="noopener ugc nofollow" target="_blank"><em class="ne">link here</em></a>) is generally sufficient for most common use cases, serving as an effective starting point. However, it can be modified to enhance performance and ensure greater relevance to specific applications. This can be done by using a custom prompt before passing it as a parameter to the <em class="ne">create_react_agent </em>(might be different based on your version of LangChain)<em class="ne">.</em></p><p id="63f9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To determine if our custom prompt was an improvement, we employed an iterative prompt engineering approach: <em class="ne">Write, Evaluate and Refine </em>(<a class="af pe" rel="noopener" target="_blank" href="/building-fill-sg-genai-report-toolkit-launch-afc8dfdacd78#5bbd"><em class="ne">more details here</em></a>). This process ensured that the prompt generalized effectively across a broad range of test cases. Additionally, we used the base prompt provided by LangChain as a benchmark to evaluate our custom prompts, enabling us to assess their performance with varying additional context across various transaction scenarios.</p><p id="2a4d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Custom Tools &amp; Chains (Prompt Chaining)</strong></p><p id="93f6" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">For the two custom chatbot features in this article, we made use of custom tools that our Agent can make use of to perform transactions. Our custom tools make use of prompt chaining to breakdown and understand a user’s request before deciding what to do in the particular tool.</p><p id="6288" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Prompt chaining is a technique where multiple prompts are used in sequence to handle complex tasks or queries. It involves starting with an initial prompt and using its output as input for subsequent prompts, allowing for iterative refinement and contextual continuity. This method enhances the handling of intricate queries, improves accuracy, and maintains coherence by progressively narrowing down the focus.</p><p id="a640" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">For each transaction use case, we broke the process into multiple steps, allowing us to give clearer instructions to the LLM at each stage. This method improves accuracy by making tasks more specific and manageable. We also can inject localized context into the prompts, which clarifies the objectives and enhances the LLM’s understanding. Based on the LLM’s reasoning, our custom chains will make requests to external APIs to gather data to perform the transaction.</p><p id="b495" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">At every step of prompt chaining, it is crucial to implement error handling, as LLMs can sometimes produce hallucinations or inaccurate responses. By incorporating error handling mechanisms such as validation checks, we identified and addressed inconsistencies or errors in the outputs. This allowed us to generate fallback responses to our users that explained what the LLM failed to reason at.</p><p id="a750" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Lastly, in our custom tool, we refrained from simply using the LLM generated output as the final response due to the risk of hallucination. As a citizen facing chatbot, it is crucial to prevent our chatbots from disseminating any misleading or inaccurate information. Therefore, we ensure that all responses to user queries are derived from actual data points retrieved through our custom chains. We then format these data points into pre-defined responses, ensuring that users do not see any direct output generated by the LLM.</p><h1 id="0c17" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Challenges of productionizing LangChain</h1><h2 id="a2ec" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">Challenges of using LLMs</h2><p id="2569" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk"><strong class="mk fr">Challenge #1: Prompt chaining leads to slow inference time</strong></p><p id="1bb9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">A challenge with LLMs is their inference times. LLMs have high computational demands due to their large number of parameters and having to be called repeatedly for real time processing, leading to relatively slow inference times (a few seconds per prompt). VICA is a chatbot that gets 700,000 queries in a month. To ensure a good user experience, we aim to provide our responses as quickly as possible while ensuring accuracy.</p><p id="dbf3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Prompt chaining increases the consistency, controllability and reliability of LLM outputs. However, each additional chain we incorporate significantly slows down our solution as it necessitates making an extra LLM request. To balance simplicity with efficiency, we set a hard limit on the number of chains to prevent excessive wait times for users. We also opted not to use better performing LLM models such as GPT-4 due to their slower speed, but opted for faster but generally well performing LLMs.</p><p id="8d1d" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Challenge #2 :Hallucination</strong></p><p id="8790" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As seen in the recent incident with Google’s feature, AI Overview, having LLMs generating outputs can lead to inaccurate or non-factual details. Even though grounding the LLM makes it more consistent and less likely to hallucinate, it does not eliminate hallucination.</p><p id="ef4f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As mentioned above, we made use of prompt chaining to perform reasoning tasks for transactions by breaking it down into smaller, easier to understand tasks. By chaining LLMs, we are able to extract the information needed to process complex queries. However, for the final output, we crafted non-generative messages as the final response from the reasoning tasks that the LLM performs. This means that in VICA, our users do not see generated responses from our LLM Agent.</p><h1 id="bf58" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Challenges of using LangChain</h1><p id="a683" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk"><strong class="mk fr">Challenge #1: Too much abstraction</strong></p><p id="e7c7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The first issue with LangChain is that the framework abstracts away too many details, making it very difficult to customize applications for specific real world use cases.</p><p id="ae97" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In order to overcome such limitations, we had to delve into the package and customize certain classes to better suit our use case. For instance, we modified the <em class="ne">AgentExecutor </em>class to route the ReAct agent’s action input into the tool that was chosen. This gave our custom tools additional context that helped with extracting information from user queries.</p><p id="4703" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Challenge #2: Lack of documentation</strong></p><p id="ffcb" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The second issue is the lack of documentation and the constantly evolving framework. This makes development difficult as it takes time to understand how the framework works through looking at the package code. There is also a lack of consistency on how things work, making it difficult to pick things up as you go. Also with constant updates on existing classes, an upgrade in version can result in previously working code suddenly breaking.</p><p id="b3f7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">If you are planning to use LangChain in production, an advice would be to fix your production version and test before upgrading.</p><h1 id="5722" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Use case of LLM Agents</h1><h2 id="dffe" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">Use case #1: Department of Statistics (DOS) Table builder</h2><figure class="nk nl nm nn no np nh ni paragraph-image"><div class="nh ni qn"><img src="../Images/599487529b46087faa5618a5da93b965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OiVutyfJZYWKEzk7.png"/></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample output from DOS Chatbot (examples are for illustrative purposes only), Image by Authors</figcaption></figure><p id="bb02" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">When it comes to looking at statistical data about Singapore, users can find it difficult to find and analyze the information that they are looking for. To address this issue, we came up with a POC that aims to extract and present statistical data in a table format as a feature in our chatbot.</p><p id="aec6" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">As DOS’s API is open for public use, we made use of the API documentation that was provided in their website. Using LLM’s natural language understanding capabilities, we passed the API documentation into the prompt. The LLM was then tasked to pick the correct API endpoint based on what the statistical data that the user was asking for. This meant that users could ask for statistical information for annual/half-yearly/quarterly/monthly data in percentage change/absolute values in a given time filter. For example, we are able to query specific information such as “GDP for Construction in 2022” or “CPI in quarter 1 for the past 3 years”.</p><p id="d94f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">We then did further prompt chaining to break the task down even more, allowing for more consistency in our final output. The queries were then processed to generate the statistics provided in a table. As all the information were obtained from the API, none of the numbers displayed are generated by LLMs thus avoiding any risk of spreading non-factual information.</p><h2 id="710a" class="pl ob fq bf oc pm pn po of pp pq pr oi mr ps pt pu mv pv pw px mz py pz qa qb bk">Use case #2: Natural Conversation Facility Booking Chatbot</h2><p id="05ff" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">In today’s digital age, the majority of bookings are conducted through online websites. Depending on the user interface, it could be a process that entails sifting through numerous dates to secure an available slot, making it troublesome as you might need to look through multiple dates to find an available booking slot.</p><p id="788f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Booking through natural conversation could simplify this process. By just typing one line such as “I want to book a badminton court at Fengshan at 9.30 am”, you would be able to get a booking or recommendations from a virtual assistant.</p><p id="c96b" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">When it comes to booking a facility, there are three things we need from a user:</p><ul class=""><li id="47f5" class="mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd qc pc pd bk">The facility type (e.g. Badminton, Meeting room, Soccer)</li><li id="c1eb" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Location (e.g. Ang Mo Kio, Maple Tree Business Centre, Hive)</li><li id="7025" class="mi mj fq mk b go pf mm mn gr pg mp mq mr ph mt mu mv pi mx my mz pj nb nc nd qc pc pd bk">Date (this week, 26 Feb, today)</li></ul><p id="4425" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Once we are able to detect these information from natural language, we can create a custom booking chatbot that is reusable for multiple use cases (e.g. the booking of hotdesk, booking of sports facilities, etc).</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div class="nh ni qn"><img src="../Images/87cd6daab7effb6bb9e91c7f2ca94033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XnJ-pj7IaIQdwK4V.png"/></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample output from Facility Booking Chatbot (examples are for illustrative purposes only), Image by Authors</figcaption></figure><p id="24f9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The above example illustrates a user inquiring about the availability of a football field at 2.30pm. However, the user is missing a required information which is the date. Therefore, the chatbot will ask a clarifying question to obtain the missing date. Once the user provides the date, the chatbot will process this multi-turn conversation and attempt to find any available booking slots that matches the user’s request. As there was a booking slot that fits the user’s exact description, the chatbot will present this information as a table.</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div class="nh ni qo"><img src="../Images/9c876aa8a00cea581526b6f85651e700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*J9lgSShnd2XV4TJN.png"/></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample recommendation output from Facility Booking Chatbot (examples are for illustrative purposes only), Image by Authors</figcaption></figure><p id="ded5" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">If there are no available booking slots available, our facility booking chatbot would expand the search, exploring different timeslots or increasing the search date range. It would also attempt to recommend users available booking slots based on their previous query if there their query results in no available bookings. This aims to enhance the user experience by eliminating the need to filter out unavailable dates when making a booking, saving users the hassle and time.</p><p id="2b08" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Because we use LLMs as our reasoning engine, an additional benefit is their multilingual capabilities, which enable them to reason and respond to users writing in different languages.</p><figure class="nk nl nm nn no np nh ni paragraph-image"><div role="button" tabindex="0" class="nq nr ed ns bh nt"><div class="nh ni qn"><img src="../Images/c01629ca78972ae31c7d9a581922a6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tLhz34Vng4yEzfpY.png"/></div></div><figcaption class="nv nw nx nh ni ny nz bf b bg z dx">Sample multilingual output from Facility Booking Chatbot (examples are for illustrative purposes only), Image by Authors</figcaption></figure><p id="2776" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The example above illustrates the chatbot’s ability to accurately process the correct facility, dates, and location from the user’s message that was written in Korean to give the appropriate non-generative response although there are no available slots for the date range provided.</p><p id="8f08" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">What we demonstrated was a brief example of how our LLM Agent handles facility booking transactions. In reality, the actual solution is a lot more complex, being able to give multiple available bookings for multiple locations, handle postal codes, handle locations too far from the stated location, etc. Although we needed to make some modifications to the package to fit our specific use case, LangChain’s Agent Framework was useful in helping us chain multiple prompts together and use their outputs in the ReAct Agent.</p><p id="3d77" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Additionally, we designed this customized solution to be easily extendable to any similar booking system that requires booking through natural language.</p><h1 id="7b85" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Conclusion</h1><p id="b32c" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">In this first part of our series, we explored how GovTech’s Virtual Intelligent Chat Assistant (VICA) leverages LLM Agents to enhance chatbot capabilities, particularly for transaction-based chatbots.</p><p id="e2b3" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">By integrating LangChain’s Agent Framework into VICA’s architecture, we demonstrated its potential through the Department of Statistics (DOS) Table Builder and Facility Booking Chatbot use cases. These examples highlight how LangChain can streamline complex transaction interactions, enabling chatbots to handle transaction related tasks like data retrieval and booking through natural conversation.</p><p id="662f" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">LangChain offers solutions to quickly develop and prototype sophisticated chatbot features, allowing developers to harness the power of large language models efficiently. However, challenges like insufficient documentation and excessive abstraction can lead to increased maintenance efforts as customizing the framework to fit specific needs may require significant time and resources. Therefore, evaluating an in-house solution might offer greater long term customizability and stability.</p><p id="31d6" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the next article, we will be covering how chatbot engines can be improved through understanding multi-turn conversations.</p><h1 id="3efe" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Find out more about VICA</h1><p id="ebca" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">Curious about the potential of AI chatbots? If you are a Singapore public service officer, you can visit our website at <a class="af pe" href="https://www.vica.gov.sg/" rel="noopener ugc nofollow" target="_blank">https://www.vica.gov.sg/</a> to create your own custom chatbot and find out more!</p><h1 id="a315" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Acknowledgements</h1><p id="6fdb" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk"><em class="ne">Special thanks to Wei Jie Kong for establishing requirements for the Facility Booking Chatbot. We also wish to thank Justin Wang and Samantha Yom, our hardworking interns, for their initial work on the DOS Table builder.</em></p><h1 id="d2f2" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">References</h1><p id="1d08" class="pw-post-body-paragraph mi mj fq mk b go ow mm mn gr ox mp mq mr oy mt mu mv oz mx my mz pa nb nc nd fj bk">Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., &amp; Cao, Y. (2022). React: Synergizing reasoning and acting in language models. <em class="ne">arXiv preprint arXiv:2210.03629</em>.</p></div></div></div></div>    
</body>
</html>