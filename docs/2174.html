<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Scaling Numerical Data, Explained: A Visual Guide with Code Examples for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Scaling Numerical Data, Explained: A Visual Guide with Code Examples for Beginners</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb?source=collection_archive---------3-----------------------#2024-09-06">https://towardsdatascience.com/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb?source=collection_archive---------3-----------------------#2024-09-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="9784" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">DATA PREPROCESSING</h2><div/><div><h2 id="34d1" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">Transforming adult-sized data for child-like models</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--11676cdb45cb--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--11676cdb45cb--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--11676cdb45cb--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--11676cdb45cb--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">5</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/11d768248f250e248ee7df254169f857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZQEL4Cs3aNdXlPdcNVubQ.png"/></div></div></figure><p id="b83d" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><code class="cx ny nz oa ob b">⛳️ More <a class="af oc" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4" rel="noopener">DATA PREPROCESSING</a>, explained: <br/> · <a class="af oc" rel="noopener" target="_blank" href="/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb">Missing Value Imputation</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae">Categorical Encoding</a> <br/> ▶ <a class="af oc" rel="noopener" target="_blank" href="/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb">Data Scaling</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86">Discretization</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091">Oversampling &amp; Undersampling</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7">Data Leakage in Preprocessing</a></code></p><p id="42ca" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Numerical features in raw datasets are like adults in a world built for grown-ups. Some tower like skyscrapers (think billion-dollar revenues), while others are barely visible (like 0.001 probabilities). But our machine learning models? They’re children, struggling to make sense of this adult world.</p><p id="8bf5" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Data scaling (including what some call “normalization) is the process of transforming these adult-sized numbers into child-friendly proportions. It’s about creating a level playing field where every feature, big or small, can be understood and valued appropriately.</p><p id="95a2" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We’re gonna see five distinct scaling techniques, all demonstrated on one little dataset (complete with some visuals, of course). From the gentle touch of normalization to the mathematical acrobatics of Box-Cox transformation, you’ll see why picking the right scaling method can be the secret sauce in your machine learning recipe.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/2ddf33dc5b98736388d0deedc869049c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkX5TTTS1oZhY2eW6AdEkg.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="33ce" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Understanding Which Data Needs Transformation</h1><p id="2876" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Before we get into the specifics of scaling techniques, it’s good to understand which types of data benefit from scaling and which don’t:</p><h2 id="aed7" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">Data That Usually Doesn’t Need Scaling:</h2><ol class=""><li id="dd7f" class="nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx pz qa qb bk"><strong class="ne ga">Categorical variables</strong>: These should typically be encoded rather than scaled. This includes both nominal and ordinal categorical data.</li><li id="84ee" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Binary variables</strong>: Features that can only take two values (0 and 1, or True and False) generally don’t need scaling.</li><li id="d618" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Count data</strong>: Integer counts often make sense as they are and scaling may make them harder to understand. Treat them as categorical instead. There are some exceptions, especially with very wide ranges of counts.</li><li id="be15" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Cyclical features</strong>: Data with a cyclical nature (like days of the week or months of the year) often benefit more from cyclical encoding rather than standard scaling techniques.</li></ol><h2 id="ccba" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">Data That Usually Needs Scaling:</h2><ol class=""><li id="6f4c" class="nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx pz qa qb bk"><strong class="ne ga">Continuous numerical features with wide ranges</strong>: Features that can take on a wide range of values often benefit from scaling to prevent them from dominating other features in the model.</li><li id="f3c1" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Features measured in different units</strong>: When your dataset includes features measured in different units (e.g., meters, kilograms, years), scaling helps to put them on a comparable scale.</li><li id="505d" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Features with significantly different magnitudes</strong>: If some features have values in thousands while others are between 0 and 1, scaling can help balance their influence on the model.</li><li id="56d4" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Percentage or ratio features</strong>: While these are already on a fixed scale (typically 0–100 or 0–1), scaling might still be beneficial, especially when used alongside features with much larger ranges.</li><li id="2765" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Bounded continuous features</strong>: Features with a known minimum and maximum often benefit from scaling, especially if their range is significantly different from other features in the dataset.</li><li id="af2d" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Skewed distributions</strong>: Features with highly skewed distributions often benefit from certain types of scaling or transformation to make them more normally distributed and improve model performance.</li></ol><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/f0fa3a06aec3fa8af30392f73dda42b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCNB5u0CngOrpBqW4Hdu4Q.png"/></div></div></figure><h1 id="dd03" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Why Scale Your Data?</h1><p id="d769" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Now, you might be wondering, “Why bother scaling at all? Can’t we just let the data be?” Well, actually, many machine learning algorithms perform their best when all features are on a similar scale. Here’s why scaling is needed:</p><ol class=""><li id="a90c" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk"><strong class="ne ga">Equal Feature Importance</strong>: Unscaled features can accidentally dominate the model. For instance, wind speed (0–50 km/h) might overshadow temperature (10–35°C) simply because of its larger scale, not because it’s more important.</li><li id="82ed" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Faster Convergence</strong>: Many optimization algorithms used in machine learning converge faster when features are on a similar scale.</li><li id="4c3e" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Improved Algorithm Performance</strong>: Some algorithms, like K-Nearest Neighbors and Neural Networks, explicitly require scaled data to perform well.</li><li id="8cf5" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Interpretability</strong>: Scaled coefficients in linear models are easier to interpret and compare.</li><li id="cbd3" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Avoiding Numerical Instability</strong>: Very large or very small values can lead to numerical instability in some algorithms.</li></ol><p id="58b3" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that we understand which and why numerical data need scaling, let’s take a look at our dataset and see how we can scale its numerical variables using five different scaling methods. It’s not just about scaling — it’s about scaling right.</p><h1 id="bdc0" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">The Dataset</h1><p id="b7bb" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Before we get into the scaling techniques, let’s see our dataset. We’ll be working with data from this fictional golf club.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/5e96c302215c84c4798615bad7921f4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*syAvj8W1ku5y2NJQS1VBcA.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="3f23" class="qk oj fq ob b bg ql qm l qn qo">import pandas as pd<br/>import numpy as np<br/>from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler<br/>from scipy import stats<br/><br/># Read the data<br/>data = {<br/>    'Temperature_Celsius': [15, 18, 22, 25, 28, 30, 32, 29, 26, 23, 20, 17],<br/>    'Humidity_Percent': [50, 55, 60, 65, 70, 75, 80, 72, 68, 62, 58, 52],<br/>    'Wind_Speed_kmh': [5, 8, 12, 15, 10, 7, 20, 18, 14, 9, 6, 11],<br/>    'Golfers_Count': [20, 35, 50, 75, 100, 120, 90, 110, 85, 60, 40, 25],<br/>    'Green_Speed': [8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 11.0, 10.5, 10.0, 9.5, 9.0]<br/>}<br/><br/>df = pd.DataFrame(data)</span></pre><p id="1c76" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This dataset is perfect for our scaling tasks because it contains features with different units, scales, and distributions.</p><p id="61f9" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s get into all the scaling methods now.</p><h1 id="269b" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 1: Min-Max Scaling</h1><p id="2bd2" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Min Max Scaling transforms all values to a fixed range, typically between 0 and 1, by subtracting the minimum value and dividing by the range.</p><p id="b7ef" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">📊 Common Data Types:</strong> Features with a wide range of values, where a specific range is desired.</p><p id="607b" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">🎯 Goals:<br/>- </strong>Constrain features to a specific range (e.g., 0 to 1).<br/>- Preserve the original relationships between data points.<br/>- Ensure interpretability of scaled values.</p><p id="65f3" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In Our Case</strong>: We apply this to Temperature because temperature has a natural minimum and maximum in our golfing context. It preserves the relative differences between temperatures, making 0 the coldest day, 1 the hottest, and 0.5 an average temperature day.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/fad5d15d6556b6a9e643d17f120a26b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWzDhEg1uKq1Umhy5ZI0Ag.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="695b" class="qk oj fq ob b bg ql qm l qn qo"># 1. Min-Max Scaling for Temperature_Celsius<br/>min_max_scaler = MinMaxScaler()<br/>df['Temperature_MinMax'] = min_max_scaler.fit_transform(df[['Temperature_Celsius']])</span></pre><h1 id="08e4" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 2: Standard Scaling</h1><p id="113f" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Standard Scaling centers data around a mean of 0 and scales it to a standard deviation of 1, achieved by subtracting the mean and dividing by the standard deviation.</p><p id="0a88" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">📊 Common Data Types:</strong> Features with varying scales and distributions.</p><p id="2f24" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">🎯 Goals:<br/>- </strong>Standardize features to have a mean of 0 and a standard deviation of 1.<br/>- Ensure features with different scales contribute equally to a model.<br/>- Prepare data for algorithms sensitive to feature scales (e.g., SVM, KNN).</p><p id="e3ef" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In Our Case</strong>: We use this for Wind Speed because wind speed often follows a roughly normal distribution. It allows us to easily identify exceptionally calm or windy days by how many standard deviations they are from the mean.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/b67bd03daa7ef7034df660e5e515df8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ny3W0xzUoeDQQzZDsrSo2A.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="9534" class="qk oj fq ob b bg ql qm l qn qo"># 2. Standard Scaling for Wind_Speed_kmh<br/>std_scaler = StandardScaler()<br/>df['Wind_Speed_Standardized'] = std_scaler.fit_transform(df[['Wind_Speed_kmh']])</span></pre><h1 id="c173" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 3: Robust Scaling</h1><p id="1ebe" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Robust Scaling centers data around the median and scales using the interquartile range (IQR)</p><p id="8c2d" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">📊 Common Data Types:</strong> Features with outliers or noisy data.</p><p id="27d8" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">🎯 Goals:<br/>- </strong>Handle outliers effectively without being overly influenced by them.<br/>- Maintain the relative order of data points.<br/>- Achieve a stable scaling in the presence of noisy data.</p><p id="a8ef" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In Our Case</strong>: We apply this to Humidity because humidity readings can have outliers due to extreme weather conditions or measurement errors. This scaling ensures our measurements are less sensitive to these outliers.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/ce5023d35409e401bb082f05ebdfc842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ta2uS4QTZw0E8dm-XasCtA.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="4957" class="qk oj fq ob b bg ql qm l qn qo"># 3. Robust Scaling for Humidity_Percent<br/>robust_scaler = RobustScaler()<br/>df['Humidity_Robust'] = robust_scaler.fit_transform(df[['Humidity_Percent']])</span></pre><p id="757c" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So far, we’ve looked at a few ways to scale data using. Now, let’s explore a different approach — using transformations to achieve scaling, starting with the common technique of log transformation.</p><h1 id="ab98" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 4: Log Transformation</h1><p id="3d60" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">It applies a logarithmic function to the data, compressing the scale of very large values.</p><p id="a838" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">📊 Common Data Types:</strong> <br/>- Right-skewed data (long tail).<br/>- Count data.<br/>- Data with multiplicative relationships.</p><p id="fe42" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">🎯 Goals:<br/>- </strong>Address right-skewness and normalize the distribution.<br/>- Stabilize variance across the feature’s range.<br/>- Improve model performance for data with these characteristics.</p><p id="94bf" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In Our Case</strong>: We use this for Golfers Count because count data often follows a right-skewed distribution. It makes the difference between 10 and 20 golfers more significant than between 100 and 110, aligning with the real-world impact of these differences.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/6cac8419d171cbef009335be8e434ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYjCu4YXUKSuHgviC9b_Jw.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="a517" class="qk oj fq ob b bg ql qm l qn qo"># 4. Log Transformation for Golfers_Count<br/>df['Golfers_Log'] = np.log1p(df['Golfers_Count'])</span></pre><h1 id="3ab9" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 5: Box-Cox Transformation</h1><p id="569f" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">This is a family of power transformations (that includes log transformation as a special case) that aims to normalize the distribution of data by applying a power transformation with a parameter lambda (λ), which is optimized to achieve the desired normality.</p><p id="dbf8" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Types:</strong> Features needing normalization to approximate a normal distribution.</p><p id="708f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">🎯 Goals:<br/>- </strong>Normalize the distribution of a feature.<br/>- Improve the performance of models that assume normally distributed data.<br/>- Stabilize variance and potentially enhance linearity.</p><p id="ff96" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In Our Case</strong>: We apply this to Green Speed because it might have a complex distribution not easily normalized by simpler methods. It allows the data to guide us to the most appropriate transformation, potentially improving its relationships with other variables.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/a112a896cbf3d1119a03d826f46171f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bXL1LaLic1PPe0Lh1fju9Q.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="7880" class="qk oj fq ob b bg ql qm l qn qo"># 5. Box-Cox Transformation for Green_Speed<br/>df['Green_Speed_BoxCox'], lambda_param = stats.boxcox(df['Green_Speed'])</span></pre><p id="dd8c" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">After performing transformation, it is also common to further scale it so it follows a certain distribution (like normal). We can do this to both of the transformed columns we had.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/66bddcf5264947c43f5448f04800efd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3tVTkMMH22aaMKbPvZz4w.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="a665" class="qk oj fq ob b bg ql qm l qn qo"><br/>df['Golfers_Count_Log'] = np.log1p(df['Golfers_Count']) <br/>df['Golfers_Count_Log_std'] = standard_scaler.fit_transform(df[['Golfers_Count_Log']])<br/><br/>box_cox_transformer = PowerTransformer(method='box-cox') # By default already has standardizing<br/>df['Green_Speed_BoxCox'] = box_cox_transformer.fit_transform(df[['Green_Speed']])print("\nBox-Cox lambda parameter:", lambda_param)<br/>print("\nBox-Cox lambda parameter:", lambda_param)</span></pre><h1 id="98bd" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk"><strong class="al">Conclusion: The Power of Scaling</strong></h1><p id="952b" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">So, there you have it. Five different scaling techniques, all applied to our golf course dataset. Now, all numerical features are transformed and ready for machine learning models.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/9caaaf8d9a77227f5a54e1ab5045dd14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5cdCL6zp3aNBOcrsJEHLA.png"/></div></div></figure><p id="5a77" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Here’s a quick recap of each method and its application:</p><ul class=""><li id="7835" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qp qa qb bk"><strong class="ne ga">Min-Max Scaling</strong>: Applied to Temperature, normalizing values to a 0–1 range for better model interpretability.</li><li id="2b41" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx qp qa qb bk"><strong class="ne ga">Standard Scaling</strong>: Used for Wind Speed, standardizing the distribution to reduce the impact of extreme values.</li><li id="2fc4" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx qp qa qb bk"><strong class="ne ga">Robust Scaling</strong>: Applied to Humidity to handle potential outliers and reduce their effect on model performance.</li><li id="7887" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx qp qa qb bk"><strong class="ne ga">Log Transformation</strong>: Used for Golfers Count to normalize right-skewed count data and improve model stability.</li><li id="e812" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx qp qa qb bk"><strong class="ne ga">Box-Cox Transformation</strong>: Applied to Green Speed to make the distribution more normal-like, which is often required by machine learning algorithms.</li></ul><p id="17dc" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Each scaling method serves a specific purpose and is chosen based on the nature of the data and the requirements of the machine learning algorithm. By applying these techniques, we’ve prepared our numerical features for use in various machine learning models, potentially improving their performance and reliability.</p><h1 id="9446" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">🌟 Scaling Numerical Data, Code Summarized</h1><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="7e7e" class="qk oj fq ob b bg ql qm l qn qo">import pandas as pd<br/>import numpy as np<br/>from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer<br/><br/># Read the data<br/>data = {<br/>    'Temperature_Celsius': [15, 18, 22, 25, 28, 30, 32, 29, 26, 23, 20, 17],<br/>    'Humidity_Percent': [50, 55, 60, 65, 70, 75, 80, 72, 68, 62, 58, 52],<br/>    'Wind_Speed_kmh': [5, 8, 12, 15, 10, 7, 20, 18, 14, 9, 6, 11],<br/>    'Golfers_Count': [20, 35, 50, 75, 100, 120, 90, 110, 85, 60, 40, 25],<br/>    'Green_Speed': [8.5, 9.0, 9.5, 10.0, 10.5, 11.0, 11.5, 11.0, 10.5, 10.0, 9.5, 9.0]<br/>}<br/><br/>df = pd.DataFrame(data)<br/><br/># 1. Min-Max Scaling for Temperature_Celsius<br/>min_max_scaler = MinMaxScaler()<br/>df['Temperature_MinMax'] = min_max_scaler.fit_transform(df[['Temperature_Celsius']])<br/><br/># 2. Standard Scaling for Wind_Speed_kmh<br/>std_scaler = StandardScaler()<br/>df['Wind_Speed_Standardized'] = std_scaler.fit_transform(df[['Wind_Speed_kmh']])<br/><br/># 3. Robust Scaling for Humidity_Percent<br/>robust_scaler = RobustScaler()<br/>df['Humidity_Robust'] = robust_scaler.fit_transform(df[['Humidity_Percent']])<br/><br/># 4. Log Transformation for Golfers_Count<br/>df['Golfers_Log'] = np.log1p(df['Golfers_Count'])<br/>df['Golfers_Log_std'] = standard_scaler.fit_transform(df[['Golfers_Log']])<br/><br/># 5. Box-Cox Transformation for Green_Speed<br/>box_cox_transformer = PowerTransformer(method='box-cox') # By default already has standardizing<br/>df['Green_Speed_BoxCox'] = box_cox_transformer.fit_transform(df[['Green_Speed']])<br/><br/># Display the results<br/>transformed_data = df[[<br/>    'Temperature_MinMax', <br/>    'Humidity_Robust', <br/>    'Wind_Speed_Standardized',<br/>    'Green_Speed_BoxCox',<br/>    'Golfers_Log_std', <br/>]]<br/><br/>transformed_data = transformed_data.round(2)<br/>print(transformed_data)</span></pre></div></div></div><div class="ab cb qq qr qs qt" role="separator"><span class="qu by bm qv qw qx"/><span class="qu by bm qv qw qx"/><span class="qu by bm qv qw"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="2f99" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">⚠️ Clarifying “Scaling,” “Normalization,” and “Transformation”</h2><p id="a660" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">As these terms are often used inconsistently in data science, let me clarify the distinctions:</p><ol class=""><li id="fe7b" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk"><strong class="ne ga">Scaling</strong>: This is a broader term that refers to changing the range of values. It includes techniques like:<br/>- Min-Max scaling (scales to a fixed range, often 0–1)<br/>- Standard scaling (scales to mean 0 and standard deviation 1)</li><li id="3355" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Normalization</strong>: In a strict statistical sense, this typically refers to adjusting values measured on different scales to a common scale, often to make features have the properties of a normal distribution. Techniques include:<br/>- Z-score normalization (same as standard scaling)<br/>- Log normalization<br/>- Box-Cox transformation</li><li id="0550" class="nc nd fq ne b gt qc ng nh gw qd nj nk nl qe nn no np qf nr ns nt qg nv nw nx pz qa qb bk"><strong class="ne ga">Transformation</strong>: This is the broadest term, referring to any mathematical operation applied to change the values or distribution of a dataset. It includes both scaling and normalization, as well as other operations like:<br/>- Power transformations (e.g., square root, cube root)<br/>- Logarithmic transformations<br/>- Exponential transformations</li></ol><p id="05ae" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">But, in practice:<br/>- Some people use “normalization” specifically to mean scaling to a [0,1] interval (Min-Max scaling).<br/>- Others use “normalization” and “scaling” almost interchangeably.<br/>- “Transformation” is sometimes used interchangeably with both “scaling” and “normalization,” but it’s actually a more general term.</p><p id="2a16" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Given this overlap and inconsistent usage, for a beginner-focused article, I decided to use “Scaling” for simplicity. It’s better to focus on what each technique does rather than getting caught up in the terminology debate.</p></div></div></div><div class="ab cb qq qr qs qt" role="separator"><span class="qu by bm qv qw qx"/><span class="qu by bm qv qw qx"/><span class="qu by bm qv qw"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="65b8" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">Further Reading</h2><p id="7f11" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">For a detailed explanation of the <a class="af oc" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank">MinMaxScaler</a>, <a class="af oc" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">StandardScaler</a>, <a class="af oc" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html" rel="noopener ugc nofollow" target="_blank">RobustScaler</a> and its implementation in scikit-learn, readers can refer to the official documentation [1], which provides comprehensive information on its usage and parameters.</p><h2 id="e9c5" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">Technical Environment</h2><p id="8ce6" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="6713" class="pj oj fq bf ok pk pl pm on pn po pp oq nl pq pr ps np pt pu pv nt pw px py fw bk">About the Illustrations</h2><p id="570d" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p></div></div><div class="mw"><div class="ab cb"><div class="lr qy ls qz lt ra cf rb cg rc ci bh"><figure class="mr ms mt mu mv mw re rf paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp rd"><img src="../Images/fa7f5bc5b142e80d43d51d383a8b78d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*QVf4s14W7JB8mm2X5JcLJQ.jpeg"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">For a concise visual summary, check out <a class="af oc" href="https://www.instagram.com/p/C_kb6TQSrgY/" rel="noopener ugc nofollow" target="_blank">the companion Instagram post</a>.</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="f817" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Reference</h1><p id="ca60" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">[1] F. Pedregosa et al., <a class="af oc" href="https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf" rel="noopener ugc nofollow" target="_blank">Scikit-learn: Machine Learning in Python</a>, Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.</p><p id="a859" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:</p><div class="rg rh ri rj rk"><div role="button" tabindex="0" class="ab bx cp kj it rl rm bp rn lw ao"><div class="ro l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rp rq cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rp rq em n ay ub"/></div><div class="rr l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq ru hp l"><h2 class="bf ga wx ic it wy iv iw wz iy ja fz bk">Data Preprocessing</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xa vz wa wb wc lj wd we um ii wf wg wh uq ur us ep bm ut oe" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xb l il"><span class="bf b dy z dx">6 stories</span></div></div></div><div class="sd dz se it ab sf il ed"><div class="ed rx bx ry rz"><div class="dz l"><img alt="" class="dz" src="../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*T1bcJ8sv5Rc1lsOyGS1nig.png"/></div></div><div class="ed rx bx kk sa sb"><div class="dz l"><img alt="Cartoon illustration of two figures embracing, with letters ‘A’, ‘B’, ‘C’ and numbers ‘1’, ‘2’, ‘3’ floating around them. A pink heart hovers above, symbolizing affection. The background is a pixelated pattern of blue and green squares, representing data or encoding. This image metaphorically depicts the concept of encoding categorical data, where categories (ABC) are transformed into numerical representations (123)." class="dz" src="../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2_cXKHvfaBTVpDrmz5r5vQ.png"/></div></div><div class="ed bx hx sc sb"><div class="dz l"><img alt="A cartoon illustration representing data scaling in machine learning. A tall woman (representing a numerical feature with a large range) is shown shrinking into a child (representing the same feature after scaling to a smaller range). A red arrow indicates the shrinking process, and yellow sparkles around the child signify the positive impact of scaling." class="dz" src="../Images/d261b2c52a3cafe266d1962d4dbabdbd.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*MkX5TTTS1oZhY2eW6AdEkg.png"/></div></div></div></div></div><p id="595f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:</p><div class="rg rh ri rj rk"><div role="button" tabindex="0" class="ab bx cp kj it rl rm bp rn lw ao"><div class="ro l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rp rq cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rp rq em n ay ub"/></div><div class="rr l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq ru hp l"><h2 class="bf ga wx ic it wy iv iw wz iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xa vz wa wb wc lj wd we um ii wf wg wh uq ur us ep bm ut oe" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xb l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="sd dz se it ab sf il ed"><div class="ed rx bx ry rz"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed rx bx kk sa sb"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx sc sb"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div><div class="rg rh ri rj rk"><div role="button" tabindex="0" class="ab bx cp kj it rl rm bp rn lw ao"><div class="ro l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rp rq cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rp rq em n ay ub"/></div><div class="rr l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq ru hp l"><h2 class="bf ga wx ic it wy iv iw wz iy ja fz bk">Regression Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk xa vz wa wb wc lj wd we um ii wf wg wh uq ur us ep bm ut oe" href="https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----11676cdb45cb--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xb l il"><span class="bf b dy z dx">5 stories</span></div></div></div><div class="sd dz se it ab sf il ed"><div class="ed rx bx ry rz"><div class="dz l"><img alt="A cartoon doll with pigtails and a pink hat. This “dummy” doll, with its basic design and heart-adorned shirt, visually represents the concept of a dummy regressor in machine. Just as this toy-like figure is a simplified, static representation of a person, a dummy regressor is a basic models serve as baselines for more sophisticated analyses." class="dz" src="../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><div class="ed rx bx kk sa sb"><div class="dz l"><img alt="" class="dz" src="../Images/44e6d84e61c895757ff31e27943ee597.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*nMaPpVdNqCci31YmjfCMRQ.png"/></div></div><div class="ed bx hx sc sb"><div class="dz l"><img alt="" class="dz" src="../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qTpdMoaZClu-KDV3nrZDMQ.png"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>