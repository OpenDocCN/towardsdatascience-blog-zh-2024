- en: Label Studio Customized Backend for Semiautomatic Image Segmentation Labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/label-studio-customized-backend-for-semiautomatic-image-segmentation-labeling-324c2310d756?source=collection_archive---------6-----------------------#2024-04-20](https://towardsdatascience.com/label-studio-customized-backend-for-semiautomatic-image-segmentation-labeling-324c2310d756?source=collection_archive---------6-----------------------#2024-04-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Customized backend; GCP Deployment; Data Versioning with GCS Integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@AlisonYuhanYao?source=post_page---byline--324c2310d756--------------------------------)[![Alison
    Yuhan Yao](../Images/c862182d1b3c549dcf1906ca04038b2a.png)](https://medium.com/@AlisonYuhanYao?source=post_page---byline--324c2310d756--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--324c2310d756--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--324c2310d756--------------------------------)
    [Alison Yuhan Yao](https://medium.com/@AlisonYuhanYao?source=post_page---byline--324c2310d756--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--324c2310d756--------------------------------)
    ·13 min read·Apr 20, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/afe12f776d93863b6c22347955c1cdc8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: · [Introduction](#202a)
  prefs: []
  type: TYPE_NORMAL
- en: · [Overview](#d792)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Goal](#2329)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Why semiautomatic?](#b71f)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [Entering Label Studio](#d3f4)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1 frontend + 2 backends](#5a72)
  prefs: []
  type: TYPE_NORMAL
- en: · [Implementation (Local)](#4dc5)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1\. Install git and docker & download backend code](#e769)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2\. Set up frontend to get access token](#fa97)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3\. Set up backend containers](#4cc0)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4\. Connect containers](#f7ab)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [5\. Happy labeling!](#763a)
  prefs: []
  type: TYPE_NORMAL
- en: · [GCP Deployment](#8783)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1\. Select project/Create new project and set up billing account](#8b11)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2\. Create VM instance](#a1b4)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3\. Set up VM environment](#cf45)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4\. Follow previous section & set up everything on VM](#2ea2)
  prefs: []
  type: TYPE_NORMAL
- en: · [GCS Integration](#f815)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [1\. Set up GCS buckets](#4329)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [2\. Create & set up service account key](#84f3)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [3\. Rebuild backend containers](#2e13)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [4\. SDK upload images from source bucket](#3d43)
  prefs: []
  type: TYPE_NORMAL
- en: ∘ [5\. Set up Target Storage](#165a)
  prefs: []
  type: TYPE_NORMAL
- en: · [Acknowledgement](#cc13)
  prefs: []
  type: TYPE_NORMAL
- en: · [References](#cb81)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating training data for image segmentation tasks remains a challenge for
    individuals and small teams. And if you are a student researcher like me, finding
    a cost-efficient way is especially important. In this post, I will talk about
    one solution that I used in [my capstone project](https://seas.harvard.edu/news/2024/05/masters-student-capstone-spotlight-ai-fashion)
    where a team of 9 people successfully labeled 400+ images within a week.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to Politecnico di Milano [Gianfranco Ferré Research Center](https://www.centroricercagianfrancoferre.it/home/FGFhome.php?lang=en),
    we obtained thousands of fashion runway show images from Gianfranco Ferré’s archival
    database. To explore, manage, enrich, and analyze the database, I employed *image
    segmentation* forsmarter cataloging and fine-grained research. Image segmentation
    of runway show photos also lays the foundation for creating informative textual
    descriptions for better search engine and text-to-image generative AI approaches.
    Therefore, this blog will detail:'
  prefs: []
  type: TYPE_NORMAL
- en: how to create your own backend with [label studio](https://labelstud.io/), on
    top of the existing [segment anything backend](https://labelstud.io/blog/get-started-using-segment-anything/),
    for semiautomatic image segmentation labeling,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how to host on Google Cloud Platform for group collaboration, and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how to employ Google Cloud Storage buckets for data versioning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code in this post can be found in this [GitHub repo](https://github.com/AlisonYao/label-studio-customized-ml-backend).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Goal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Segment and identify the names and typologies of fashion clothing items in runway
    show images, as shown in the first image.
  prefs: []
  type: TYPE_NORMAL
- en: Why semiautomatic?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Wouldn’t it be nice if a trained segmentation model out there could perfectly
    recognize every piece of clothing in the runway show images? Sadly, there isn’t
    one. There exist trained models tailored to fashion or clothing images but nothing
    can match our dataset perfectly. Each fashion designer has their own style and
    preferences for certain clothing items and their color and texture, so even if
    a segmentation model can be 60% accurate, we call it a win. Then, we still need
    humans in the loop to correct what the segmentation model got wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Entering Label Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Label Studio provides an open-source, customizable, and free-of-charge community
    version for various types of data labeling. One can create their own backend,
    so I can connect the Label Studio frontend to the trained segmentation model (mentioned
    above) backend for labelers to further improve upon the auto-predictions. Furthermore,
    Label Studio already has an interface that looks somewhat similar to Photoshop
    and a series of segmentation tools that can come in handy for us:'
  prefs: []
  type: TYPE_NORMAL
- en: Brush & eraser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Magic Wand](https://labelstud.io/tags/magicwand) for similar-color pixel selection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Segment Anything](https://labelstud.io/blog/get-started-using-segment-anything/)
    backend which harnesses the power of [Meta’s SAM](https://segment-anything.com/)
    and allows you to recognize the object within a bounding box you draw.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 frontend + 2 backends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we want 2 backends to be connected to the frontend. One backend can
    do the segmentation prediction and the second can speed up labelers’ modification
    if the predictions are wrong.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd0d4db085c10c9080342331e55af566.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Implementation (Local)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s fire up the app locally. That is, you will be able to use the app
    on your laptop or local machine completely for free but you are not able to invite
    your labeling team to collaborate on their laptops yet. We will talk about teamwork
    with GCP in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Install git and docker & download backend code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you don’t have [git](https://git-scm.com/downloads) or [docker](https://www.docker.com/products/docker-desktop/)
    on your laptop or local machine yet, please install them. (Note: you can technically
    bypass the step of installing git if you download the zip file from [this GitHub
    repo](https://github.com/AlisonYao/label-studio-customized-ml-backend). If you
    do so, skip the following.)'
  prefs: []
  type: TYPE_NORMAL
- en: Then, open up your terminal and clone [this repo](https://github.com/AlisonYao/label-studio-customized-ml-backend)
    to a directory you want.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you open up the `label-studio-customized-ml-backend` folder in your code
    editor, you can see the majority are adapted from the [Label Studio ML backend](https://github.com/HumanSignal/label-studio-ml-backend)
    repo, but this directory also contains frontend template code and SDK code adapted
    from [Label Studio SDK](https://github.com/HumanSignal/label-studio-sdk).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Set up frontend to get access token
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Following the official guidelines of [segment anything](https://labelstud.io/blog/get-started-using-segment-anything/),
    do the following in your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Then, open your browser and type [http://0.0.0.0:8080/](http://0.0.0.0:8080/)
    and you will see the frontend of Label Studio. Proceed to sign up with your email
    address. Now, there is no project yet so we need to create our first project by
    clicking **Create Project**. Create a name and description (optional) for your
    project.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d88cff94b8c3228e822bd745514700f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Upload some images locally. (We will talk about how to use cloud storage later.)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/60de7269242fb8747a3f027d848404fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: For Labeling Setup, click on **Custom template** on the left and copy-paste
    the HTML code from the `label-studio-customized-ml-backend/label_studio_frontend/view.html`
    file. You do not need the four lines of Headers if you don’t want to show image
    metadata in the labeling interface. Feel free to modify the code here to your
    need or click **Visual** to add or delete labels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46b0cded775343e89ccd3183fcff4804.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now, click **Save** and your labeling interface should be ready.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/00078d62a35d98139f516039dd133850.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: On the top right, click on the user setting icon and click **Account & Setting**
    and then you should be able to copy your access token.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7514cd7d8f931d1ea809c810d84ecb77.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Set up backend containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the `label-studio-customized-ml-backend` directory, there are many many backends
    thanks to the Label Studio developers. We will be using the customized `./segmentation`
    backend for segmentation prediction (container 1) and the `./label_studio_ml/examples/segment_anything_model`
    for faster labeling (container 2). The former will use port 7070 and the latter
    will use port 9090, making it easy to distinguish from the frontend port 8080.
  prefs: []
  type: TYPE_NORMAL
- en: Now, paste your access token to the 2 `docker-compose.yml` files in `./segmentation`and
    `./label_studio_ml/examples/segment_anything_model` folders.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Open up a new terminal and you cd into the `segment_anything_model` directory
    as you did before. Then, fire up the segment anything container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Then, open up another new terminal cd into the `segmentation` directory and
    fire up the segmentation prediction container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As of now, we have successfully started all 3 containers and you can double-check.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee9e5a21a35b9de9be3eef35678a6ae0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Connect containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before, what we did with the access token was helping us connect containers
    already, so we are almost done. Now, go to the frontend you started a while back
    and click **Settings** in the top right corner. Click **Machine Learning** on
    the left and click **Add Model**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a0e3b4bdce93b16aac9fd0b492838629.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Be sure to use the URL with port 9090 and toggle on interactive preannotation.
    Finish adding by clicking **Validate and Save**.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, do the same with the segmentation prediction backend.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08cba82cb7ad1df12a89c296ab642d4d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Then, I like to toggle on **Retrieve predictions when loading a task automatically**.
    This way, every time we refresh the labeling page, the segmentation predictions
    will be automatically triggered and loaded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a976abd4d9d05a89e50d3dec222ff5c3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Happy labeling!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is a demo of what you should see if you follow the steps above.
  prefs: []
  type: TYPE_NORMAL
- en: Video by Author
  prefs: []
  type: TYPE_NORMAL
- en: If we are not happy with the predictions of let’s say the skirt, we can delete
    the skirt and use the purple magic (segment anything) to quickly label it.
  prefs: []
  type: TYPE_NORMAL
- en: Video By Author
  prefs: []
  type: TYPE_NORMAL
- en: I’m sure you can figure out how to use the brush, eraser and magic wand on your
    own!
  prefs: []
  type: TYPE_NORMAL
- en: If you are working solo, you are all set. But if you are wondering how to collaborate
    with your team without subscribing to Label Studio Enterprise, we need to host
    everything on cloud.
  prefs: []
  type: TYPE_NORMAL
- en: GCP Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I chose GCP because of education credits, but you can use any cloud of your
    choice. The point is to host the app on cloud so that anyone in your labeling
    team can access and use your Label Studio app.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf6b44162a3ee19a94f92d7803258117.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Select project/Create new project and set up billing account
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Go to [GCP console](https://console.cloud.google.com/) and create a new project
    if you don’t have an existing one and set up the billing account information as
    required (unfortunately, cloud costs some money). Here, I will use the *Fashion*
    project I created to demonstrate.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/322a3e2f68d88aa1a2334299bdecfd7e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Create VM instance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To have a public IP address for labeling teamwork, we need to create a Virtual
    Machine (VM) on GCP and host everything here. After going to the project you created
    or selected, search **compute engine** in the search bar and the first thing that
    pops up should be **VM instances**. Click **CREATE INSTANCE** and choose the setting
    based on your need.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/29fec0320e4591a4fb473093aaadaaa0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The default 10GB persistent disk will give you problems, so bump it up please.
    And more importantly, allow HTTP traffic.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4faa2521bf8d60bbe9cbf68c1f90258b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: It is a bit painful to modify these settings later, so try to think it through
    before clicking CREATE.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Set up VM environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can think of a VM as a computer somewhere in the cloud, similar to your
    laptop, but you can only ask it to do things via the terminal or command line.
    So now we need to set up everything on the VM the same way we set up everything
    locally (see previous section).
  prefs: []
  type: TYPE_NORMAL
- en: Click SSH, authorize and open up the command line interface.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5bbbab654b31fbc557ccfd680ded68f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Do routine update and install docker, docker compose, git and Python.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/edcc4f0fbdb9e232df1cc9de344fd89e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Follow previous section & set up everything on VM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, you can follow steps 1–4 in the previous section but there are some changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Add **sudo** when you have docker permission denied error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you have data permission error, modify permission using something like `sudo
    chmod -R 777 mydata`. And then you should be able to run your frontend container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The server is not at [http://0.0.0.0:8080](http://0.0.0.0:8080) anymore. Instead,
    swap 0.0.0.0 with the external IP address of your VM. An example is [http://34.1.1.87:8080/](http://34.1.1.87:8080/).
    You can find the external IP address next to the **SSH** button you clicked before.
    However, you probably still cannot access the frontend just yet. You need to search
    firewall on GCP console and click **Firewall (VPC network)** and then click **default-allow-http.**
    Now, change the setting to the following and you should be able to access the
    frontend.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/5e236f1fbdef468fd80638526158c572.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 4\. When editing `docker-compose.yml` files, apart from copy-pasting access
    token, also modify the `LABEL_STUDIO_HOST`. Again, swap `host.docker.internal`
    with the VM external IP address. An example is [http://34.1.1.87:8080](http://34.1.1.87:8080)
    .
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Similarly, when adding *Machine Learning* in the frontend settings, also
    use [http://34.1.1.87:9090](http://34.1.1.87:9090) and http://34.1.1.87:7070.
  prefs: []
  type: TYPE_NORMAL
- en: You can then export your labeling results and tailor to your uses.
  prefs: []
  type: TYPE_NORMAL
- en: If you only have a couple of images to label or you are fine with uploading
    images from local, by all means. But for my project, there are thousands of images,
    so I prefer using Google Cloud Storage to automate data transferring and data
    versioning.
  prefs: []
  type: TYPE_NORMAL
- en: GCS Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Set up GCS buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Search bucket in the GCP console and navigate to Cloud Storage buckets. Create
    2 buckets: one with your images (source) and another empty (target). The second
    one will be populated later when you start labeling.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e97e77b50ee154b4d579e394380d9b4d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Then, following the [official documentation](https://labelstud.io/guide/storage.html#Google-Cloud-Storage),
    we need to set up cross-origin resource sharing (CORS) access to the buckets.
    Click **Activate Cloud Shell** on the top right, and run the following commands.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If you want to set up data versioning for the labeling results, you can click
    on the bucket and turn on versioning in **PROTECTION**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d160e1c091107c4632ee9de5cd7168f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Create & set up service account key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chances are that you do not want your buckets to be public, then label studio
    needs authentication to have access to these images. Click **CREATE SERVICE ACCOUNT**
    and grant the role of **Storage Admin** so that we can read and write to the GCS
    buckets. You should be able to see this service account in the permissions list
    of the buckets as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0103623a7369a95f066f2fb57f91ddcc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now, click on the newly created service account and click **KEYS**. Now add
    a new key and be sure to download the JSON file to somewhere safe.
  prefs: []
  type: TYPE_NORMAL
- en: Now, open up your local terminal and encode the JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can see the random character and number string and copy it. We are now pasting
    it as metadata for the VM. Click on your VM, click **EDIT**, and add your custom
    metadata. For example, my key is GOOGLE_APPLICATION_CREDENTIALS_BASE64.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4f3dabdc2f3136e2737a1d001d537ecb.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: We will then decode the service account key for authentication in our Python
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Rebuild backend containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we modified the `docker-compose.yml` files, we need to run the new script
    and rebuild the backend containers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, you should see the new containers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e87147432f7663230f802652dda96587.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 4\. SDK upload images from source bucket
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you simply want to upload the images without metadata, you can skip this
    section and do the exact same thing as step 5 (see next). By metadata, I mean
    the useful information for each image on the labeling interface that might help
    with labeling more accurately.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the example from Label Studio SDK repo, you can modify what metadata
    and how you want to import in the `./label_studio_sdk/annotate_data_from_gcs.ipynb`
    file. After running the python notebook locally, you should be able to see your
    images and metadata on the frontend.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/22af11b1076eee4891da4a6fda041c7b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: And you should also see the Source Storage bucket in the settings. Do NOT click
    Sync Storage as it will sync directly from the bucket and mess up the metadata
    we imported.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/85750b44e221bca140385c71d927e2b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Set up Target Storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Click **Add Target Storage**, and filling in the information accordingly. Copy-paste
    your service account key in the Google Application Credentials textbox and you
    are all set.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0126e2fd1425ec034da10e4476c8780b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Every time you click **Sync Storage** on the Target Cloud Storage, it will sync
    the labeling outcome in the format of text into the GCS bucket. After clicking
    sync once, the process should be trigger automatically when submitting labeling
    results, but please check if you need to manually sync from time to time just
    in case.
  prefs: []
  type: TYPE_NORMAL
- en: Happy labeling!
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is my pleasure to be a part of [Data Shack 2024](https://sites.google.com/view/datashack-harvard-polimi/data-shack-2024?authuser=0)
    in collaboration with Politecnico di Milano [Gianfranco Ferré Research Center](https://www.centroricercagianfrancoferre.it/home/FGFhome.php?lang=en).
    I would like to thank Prof. [Pavlos Protopapas](https://medium.com/u/69c7cfe8dc8e?source=post_page---user_mention--324c2310d756--------------------------------)
    and Prof. Paola Bertola for your guidance and for making this project happen in
    the first place. I would like to thank [Chris Gumb](https://medium.com/u/afb3db007f0b?source=post_page---user_mention--324c2310d756--------------------------------)
    and Prof. [Marco Brambilla](https://medium.com/u/88b92e077317?source=post_page---user_mention--324c2310d756--------------------------------)
    for technical support and Prof. Federica Vacca and Dr. [Angelica Vandi](https://medium.com/u/e391affa9647?source=post_page---user_mention--324c2310d756--------------------------------)
    for domain knowledge expertise in fashion. Finally, I would like to thank my teammates
    [Luis Henrique Simplicio Ribeiro](https://medium.com/u/48b7440feb38?source=post_page---user_mention--324c2310d756--------------------------------),
    [Lorenzo Campana](https://medium.com/u/10478e152ee4?source=post_page---user_mention--324c2310d756--------------------------------)
    and Vittoria Corvetti for your help and for figuring things out with me along
    the way. I also want to give a round of applause to Emanuela Di Stefano, Jacopo
    Sileo, Bruna Pio Da Silva Rigato, Martino Fois, Xinxi Liu, and Ilaria Trame for
    your continued support and hard work.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 11655 Gianfranco Ferré, Ready-To-Wear Collection, Fall-Winter 2004\. Courtesy
    of Gianfranco Ferré Research Center
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 13215 Gianfranco Ferré, Ready-To-Wear Collection, Spring-Summer 1991\. Courtesy
    of Gianfranco Ferré Research Center
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for reading! I hope this blog has been helpful to you.
  prefs: []
  type: TYPE_NORMAL
- en: Code in this post can be found in this [GitHub repo](https://github.com/AlisonYao/label-studio-customized-ml-backend).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
