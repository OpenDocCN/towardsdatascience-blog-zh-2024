- en: The Importance of Collaboration in Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/the-importance-of-collaboration-in-data-d144a632ffdc?source=collection_archive---------10-----------------------#2024-05-17](https://towardsdatascience.com/the-importance-of-collaboration-in-data-d144a632ffdc?source=collection_archive---------10-----------------------#2024-05-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Asking for feedback is a secretly powerful tool in data work. Let‚Äôs talk about
    why, and how to do it well
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@s.kirmer?source=post_page---byline--d144a632ffdc--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page---byline--d144a632ffdc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d144a632ffdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d144a632ffdc--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page---byline--d144a632ffdc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d144a632ffdc--------------------------------)
    ¬∑6 min read¬∑May 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da148a2507c9ab41fbe467337c761a9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Priscilla Du Preez üá®üá¶](https://unsplash.com/@priscilladupreez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: A recent conversation with a fellow data practitioner sparked an idea that I
    want to share today. What is your process for conducting data analysis or modeling,
    and what do you consider important but perhaps unsung parts of getting the job
    done well? I realized as we were talking that getting feedback from other people
    as I go through the work is an extremely important part of my process, but it‚Äôs
    not actually something that is explicitly instructed to junior practitioners in
    my experience. I thought it would be useful to explain how I do this and why,
    and what the benefits are, for anyone whose process doesn‚Äôt necessarily include
    a collaborative or peer feedback component.
  prefs: []
  type: TYPE_NORMAL
- en: The kinds of projects where I think this matters are those where you‚Äôre doing
    most of the work in solitude, so you‚Äôre alone with your data and your wits. That
    often includes building models, of course, but also things like analyses that
    are intended to answer specific business questions or explore research topics.
    Most of the work is going to get done alone, which can be nice because you can
    work at your own pace and explore the project area the way you want to. However,
    it‚Äôs easy to get sidetracked, lose the plot, or miss something important when
    you‚Äôre the only one looking at the work.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, I like to consult with other data scientists from time to time
    as I proceed. This can take a number of different forms, and it‚Äôs not necessarily
    the same for every project.
  prefs: []
  type: TYPE_NORMAL
- en: Casual Chats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It‚Äôs important in whatever kind of feedback you‚Äôre getting that you have already
    done a significant amount of work. This is not a time to ask somebody else to
    do the work for you. You should have a solid project plan, and you should have
    already made significant progress (loading your data, looking thoroughly at it,
    and conducting at least some of the analysis, at minimum) and have work to show
    for it before you go bringing in anyone else. Once you‚Äôre there, ping a colleague
    and see if they have a few minutes to look at your work and give their thoughts
    ‚Äî not necessarily right at that moment, but when their schedules permit. If they
    can‚Äôt help, go to somebody else, and take a mental note for the future. It‚Äôs natural
    to be concerned about bothering people, which is why I try to limit this kind
    of thing to one time per project, and try not to bug the same person multiple
    times in a row for different projects. Distribute your asks so that you‚Äôre not
    always taking up one person‚Äôs time. If you need more than one person‚Äôs help, that‚Äôs
    for the next section.
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs also important to note that your feedback solicitation should be structured.
    Don‚Äôt just say ‚Äúwhat do you think?‚Äù or dump a long script on somebody, but prepare
    readable, concise content and ask specific questions. ‚ÄúHere‚Äôs a draft slide. Does
    this EDA look complete to you? Do you see anything I have done that doesn‚Äôt make
    sense?‚Äù or ‚ÄúI tried these different hyperparameter combinations, and the model
    performance just isn‚Äôt improving past X. Do you think that‚Äôs reasonable or is
    there something else I should try to get it higher?‚Äù As you might intuit, this
    means having results, perhaps some visualizations or at least some tables, to
    show.
  prefs: []
  type: TYPE_NORMAL
- en: If you ask somebody and they don‚Äôt give very helpful feedback, make a mental
    note of this too ‚Äî maybe they were busy, or your questions were unclear, or your
    work was hard to read. Experiment with what different reviewers and colleagues
    find easiest to work with, and get better at framing your questions. You should
    also volunteer proactively to return the favor and give feedback to them in future,
    and follow through and do a thorough job when the time comes. You‚Äôll get out of
    this what you put into it, as with most work or life relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Model Reviews
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A model review can be the culmination of a project, but it can also be a nice
    penultimate step before a report or model is completed and productionalized. Let
    me first explain what I mean by a model review, since this is not necessarily
    part of everyone‚Äôs process.
  prefs: []
  type: TYPE_NORMAL
- en: A model review is a presentation, complete with visuals and documentation, that
    explains the project (usually model training) you have completed from start to
    finish. You should explain your data, how it was collected, what it means, how
    you cleaned it, how you chose your model architecture and trained it, what things
    you tried that didn‚Äôt work, how your final model performs, where it excels and
    where it struggles, what things you didn‚Äôt do but would in future, etc. This should
    be a pretty comprehensive discussion of everything that you did as part of the
    work. Your audience should be other data scientists or engineers who are familiar
    with the subject matter to the degree possible, and if they are not familiar with
    the subject, you should explain that too.
  prefs: []
  type: TYPE_NORMAL
- en: This may sound like an overwhelming lot of work when you could just skip this
    step, jot down some notes in a wiki, and toss the model into prod, but I firmly
    believe this is an important part of successful modeling. For one thing, just
    preparing this will require you to review what you did and think about it. Knowing
    that this is coming will incentivize you to document your work and keep a modeling
    journal, like a lab journal in science classes. You‚Äôll do more organized and effective
    work when you‚Äôre tracking your progress.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, producing a quality model review will give you a chance to get
    suggestions and feedback from many of your peers at once. Your team should have
    ground rules around making sure the feedback is constructive, kind, and given
    with good intentions, but if you have that, then the things you learn from doing
    a model review will be invaluable. You will also probably teach other people by
    example, as well! It‚Äôs an opportunity for everyone in the team to observe other
    people‚Äôs processes and ideas, instead of this insight being hidden in a DM thread
    on slack or a 1:1 zoom call.
  prefs: []
  type: TYPE_NORMAL
- en: Go in to a model review expecting that the work is NOT perfect, and that you‚Äôll
    come away with new things to try, changes to make, or questions to investigate
    and answer. The point is not to get accolades but to get insight into what you
    may have missed, so your model will be better at the end of the day.
  prefs: []
  type: TYPE_NORMAL
- en: Other Benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Obviously, soliciting feedback about your work from peers has the end goal of
    getting you advice that will make your work better, on this project and future
    ones as well. But I think it‚Äôs important to note that there are some less obvious
    advantages you can gain from this. For one thing, you will gain a reputation as
    someone who wants to learn and improve, if you do this right ‚Äî take the feedback
    graciously, apply it, and show that you‚Äôre internalizing good notes. Your work
    will get better, but it will also be visible to your peers and managers.
  prefs: []
  type: TYPE_NORMAL
- en: Second, you‚Äôll get better at communicating your ideas. Even if you don‚Äôt do
    full presentation model reviews (though I think you should), it‚Äôs a skill to be
    able to explain your work 1:1 to a peer and frame clear questions that you want
    them to answer. As we progress in our careers, being able to communicate clearly
    about technical topics becomes increasingly important, and practicing this in
    informal, low-pressure situations will benefit you.
  prefs: []
  type: TYPE_NORMAL
- en: Third, feedback will get easier to receive. I know lots of people, including
    myself, feel anxiety about getting feedback sometimes. It‚Äôs easy to find that
    intimidating or to hear only the negatives and not the positives when others are
    evaluating your work. But the more you do it, the easier it gets. Asking repeatedly,
    in a culture of positivity and constructiveness, will desensitize you to hearing
    critiques or ways you can improve, and you‚Äôll get better at absorbing and learning
    from that as a result.
  prefs: []
  type: TYPE_NORMAL
- en: So, as you proceed with your data work, build in intentional opportunities to
    ask for constructive advice to improve your results. If you don‚Äôt have peers who
    are data savvy, get involved with meetups or slack groups of data scientists where
    you can ask for advice (without violating any NDAs of course), and build a network
    of people whose opinions you trust, and offer the same feedback to them. I promise
    you‚Äôll see benefits to your career and your skills, to say nothing of your models
    and data analyses, as a result.
  prefs: []
  type: TYPE_NORMAL
- en: Read more of my work at [www.stephaniekirmer.com.](http://www.stephaniekirmer.com.)
  prefs: []
  type: TYPE_NORMAL
- en: Also, you can see me speaking at the [AIQ Conference in San Francisco on June
    25](https://www.aiqualityconference.com/) about data privacy considerations when
    building ML solutions.
  prefs: []
  type: TYPE_NORMAL
