- en: Evaluation-Driven Development for agentic applications using PydanticAI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PydanticAI进行智能体应用的评估驱动开发
- en: 原文：[https://towardsdatascience.com/evaluation-driven-development-for-agentic-applications-using-pydanticai-d9293ac81d91?source=collection_archive---------0-----------------------#2024-12-21](https://towardsdatascience.com/evaluation-driven-development-for-agentic-applications-using-pydanticai-d9293ac81d91?source=collection_archive---------0-----------------------#2024-12-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluation-driven-development-for-agentic-applications-using-pydanticai-d9293ac81d91?source=collection_archive---------0-----------------------#2024-12-21](https://towardsdatascience.com/evaluation-driven-development-for-agentic-applications-using-pydanticai-d9293ac81d91?source=collection_archive---------0-----------------------#2024-12-21)
- en: An open-source, model-agnostic agentic framework that supports dependency injection
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个开源的、模型无关的智能体框架，支持依赖注入
- en: '[](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--d9293ac81d91--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)
    ·12 min read·Dec 21, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d9293ac81d91--------------------------------)
    ·12分钟阅读·2024年12月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Ideally, you can evaluate agentic applications even as you are developing them,
    instead of evaluation being an afterthought. For this to work, though, you need
    to be able to mock both internal and external dependencies of the agent you are
    developing. I am extremely excited by PydanticAI because it supports dependency
    injection from the ground up. It is the first framework that has allowed me to
    build agentic applications in an evaluation-driven manner.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你可以在开发过程中就评估智能体应用，而不是将评估视为事后的事情。不过，要实现这一点，你需要能够模拟你正在开发的智能体的内部和外部依赖。我对PydanticAI感到非常兴奋，因为它从根本上就支持依赖注入。它是第一个让我能够以评估驱动的方式构建智能体应用的框架。
- en: '![](../Images/6786f9e4942182ffc3b8b875a045bfd6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6786f9e4942182ffc3b8b875a045bfd6.png)'
- en: Image of Krakow Cloth Hall, generated using Google Imagen by the author. This
    building was built in phases over the centuries, with improvements based on where
    the current building was falling short. Evaluation-driven development, in other
    words.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 克拉科夫布料大厅的图像，由作者使用Google Imagen生成。这个建筑是分阶段建设的，经过几个世纪的改进，改进的方向基于当前建筑的不足之处。换句话说，这是一种以评估驱动的开发方式。
- en: In this article, I’ll talk about the core challenges and demonstrate developing
    a simple agent in an evaluation-driven way using PydanticAI.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将讨论核心挑战，并演示如何使用PydanticAI以评估驱动的方式开发一个简单的智能体。
- en: Challenges when developing GenAI applications
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发GenAI应用时的挑战
- en: Like many GenAI developers, I’ve been waiting for an agentic framework that
    supports the full development lifecycle. Each time a new framework comes along,
    I try it out hoping that this will be the One — see, for example, my articles
    about [DSPy](/building-an-ai-assistant-with-dspy-2e1e749a1a95), [Langchain](/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5),
    [LangGraph, and Autogen](https://www.linkedin.com/pulse/how-implement-genai-agent-using-autogen-langgraph-lakshmanan-cwx4c/).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 和许多GenAI开发者一样，我一直在等待一个支持完整开发生命周期的智能体框架。每当一个新框架出现时，我都会尝试，期望这次能是那个“终极框架”——例如，我的文章中提到过的[
    DSPy](/building-an-ai-assistant-with-dspy-2e1e749a1a95)、[Langchain](/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5)、[LangGraph和Autogen](https://www.linkedin.com/pulse/how-implement-genai-agent-using-autogen-langgraph-lakshmanan-cwx4c/)。
- en: I find that there are core challenges that a software developer faces when developing
    an LLM-based application. These challenges are typically not blockers if you are
    building a simple PoC with GenAI, but they will come to bite you if you are building
    LLM-powered applications in production.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现，在开发基于LLM的应用程序时，软件开发者面临一些核心挑战。如果你正在构建一个简单的GenAI概念验证（PoC），这些挑战通常不是阻碍因素，但如果你在生产环境中构建基于LLM的应用程序，它们会成为问题。
- en: What challenges?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 什么挑战？
- en: '(1) **Non-determinism**: Unlike most software APIs, calls to an LLM with the
    exact same input could return different outputs each time. How do you even begin
    to test such an application?'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: (1) **非确定性**：与大多数软件API不同，向LLM发送完全相同的输入，每次调用可能会返回不同的输出。那么，你该如何开始测试这样的应用程序呢？
- en: '(2) **LLM limitations**: Foundational models like GPT-4, Claude, and Gemini
    are limited by their training data (e.g., no access to enterprise confidential
    information), capability (e.g., you can not invoke enterprise APIs and databases),
    and can not plan/reason.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: (2) **LLM的局限性**：像GPT-4、Claude和Gemini这样的基础模型受限于其训练数据（例如，无法访问企业机密信息）、能力（例如，无法调用企业API和数据库），并且不能进行规划/推理。
- en: '(3) **LLM flexibility**: Even if you decide to stick to LLMs from a single
    provider such as Anthropic, you may find that you need a different LLM for each
    step — perhaps one step of your workflow needs a low-latency small language model
    (Haiku), another requires great code-generation capability (Sonnet), and a third
    step requires excellent contextual awareness (Opus).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (3) **LLM灵活性**：即使你决定坚持使用来自单一供应商的LLM（如Anthropic），你可能会发现每个步骤需要不同的LLM——也许你的工作流中的某个步骤需要一个低延迟的小型语言模型（Haiku），另一个步骤需要强大的代码生成能力（Sonnet），而第三个步骤需要出色的上下文意识（Opus）。
- en: (4) **Rate of Change:** GenAI technologies are moving fast. Recently, many of
    the improvements have come about in foundational model capabilities. No longer
    are the foundational models just generating text based on user prompts. They are
    now multimodal, can generate structured outputs, and can have memory. Yet, if
    you try to build in an LLM-agnostic way, you often lose the low-level API access
    that will turn on these features.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (4) **变化速率**：GenAI技术发展迅速。最近，许多改进出现在基础模型的能力上。基础模型不再只是根据用户提示生成文本。它们现在是多模态的，可以生成结构化输出，并且具备记忆能力。然而，如果你试图以LLM无关的方式构建，通常会失去开启这些功能的低级API访问权限。
- en: To help address the first problem, of non-determinism, your software testing
    needs to incorporate an evaluation framework. You will never have software that
    works 100%; instead, you will need to be able to design around software that is
    x% correct, build guardrails and human oversight to catch the exceptions, and
    monitor the system in real-time to catch regressions. Key to this capability is
    **evaluation-driven development** (my term), an extension of test-driven development
    in software.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决第一个问题——非确定性问题，你的软件测试需要纳入一个评估框架。你永远不会有完全完美的软件；相反，你需要能够设计出一个在x%准确的情况下运行的软件，构建保护措施和人工监督以捕捉例外，并实时监控系统以发现回归问题。实现这一能力的关键是**评估驱动开发**（我自己的术语），它是软件中测试驱动开发的扩展。
- en: '![](../Images/9db9ba18e95ae10febbe505241b7d65a.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9db9ba18e95ae10febbe505241b7d65a.png)'
- en: Evaluation-driven development. sketch by author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 评估驱动开发。作者草图。
- en: 'The current workaround for all the LLM limitations in Challenge #2 is to use
    **agentic architectures** like RAG, provide the LLM access to tools, and employ
    patterns like Reflection, ReACT and Chain of Thought. So, your framework will
    need to have the ability to orchestrate agents. However, evaluating agents that
    can call external tools is hard. You need to be able to **inject proxies for these
    external dependencies** so that you can test them individually, and evaluate as
    you build.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于挑战#2中的所有LLM局限性，目前的解决方法是使用**代理架构**（如RAG），为LLM提供工具访问权限，并采用诸如反射（Reflection）、反应（ReACT）和思维链（Chain
    of Thought）等模式。因此，你的框架需要能够协调代理。然而，评估可以调用外部工具的代理是困难的。你需要能够**为这些外部依赖项注入代理**，以便单独测试它们，并在构建过程中进行评估。
- en: 'To handle challenge #3, an agent needs to be able to invoke the capabilities
    of different types of foundational models. Your agent framework needs to be **LLM-agnostic**
    at the granularity of a single step of an agentic workflow. To address the rate
    of change consideration (challenge #4), you want to retain the ability to make
    **low-level access** to the foundational model APIs and to strip out sections
    of your codebase that are no longer necessary.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '为了处理挑战 #3，代理需要能够调用不同类型基础模型的能力。你的代理框架需要在代理工作流的单个步骤粒度上是**与 LLM 无关的**。为了应对变化速度的问题（挑战
    #4），你需要保留对基础模型 API 的**低级访问**权限，并且能够去除不再需要的代码部分。'
- en: 'Is there a framework that meets all these criteria? For the longest time, the
    answer was no. The closest I could get was to use Langchain, pytest’s dependency
    injection, and deepeval with something like this (full example is [here](https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py)):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有一个框架能满足所有这些标准？很长一段时间，答案是否定的。我能做到的最接近的方式是使用 Langchain、pytest 的依赖注入以及 deepeval，像这样（完整示例请见[这里](https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py)）：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Essentially, I’d construct a Mock object (chicago_weather in the above example)
    for every LLM call and patch the call to the LLM (retrieve_weather_data in the
    above example) with the hardcoded object whenever I needed to mock that part of
    the agentic workflow. The dependency injection is all over the place, you need
    a bunch of hardcoded objects, and the calling workflow becomes extremely hard
    to follow. Note that if you don’t have dependency injection, there is no way to
    test a function like this: obviously, the external service will return the current
    weather and there is no way to determine what the correct answer is for a question
    such as whether or not it’s raining right now.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我会为每次 LLM 调用构建一个 Mock 对象（如上例中的 chicago_weather），并在需要模拟代理工作流的部分时，将 LLM 调用（如上例中的
    retrieve_weather_data）替换为硬编码的对象。依赖注入到处都是，你需要一堆硬编码的对象，调用工作流变得非常难以跟踪。注意，如果没有依赖注入，就无法测试这样的函数：显然，外部服务会返回当前天气，而对于像“现在下雨吗？”这样的问题，无法确定正确的答案。
- en: '*So … is there an agent framework that supports dependency injection, is Pythonic,
    provides low-level access to LLMs, is model-agnostic, supports building it one
    eval-at-a-time, and is easy to use and follow?*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*那么…是否有一个支持依赖注入、Pythonic、提供低级 LLM 访问、与模型无关、支持逐步评估构建且易于使用和跟踪的代理框架呢？*'
- en: Almost. [PydanticAI](https://ai.pydantic.dev/) meets the first 3 requirements;
    the fourth (low-level LLM access) is not possible, but the design does not preclude
    it. In the rest of this article, I’ll show you how to use it to develop an agentic
    application in an evaluation-driven way.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎做到了。[PydanticAI](https://ai.pydantic.dev/) 满足了前三个要求；第四个（低级 LLM 访问）是不可能的，但设计上并不排斥这一点。在本文的其余部分，我将向你展示如何以评估驱动的方式使用它来开发一个代理应用。
- en: 1\. Your first PydanticAI Application
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 你的第一个 PydanticAI 应用程序
- en: 'Let’s start out by building a simple PydanticAI application. This will use
    an LLM to answer questions about mountains:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从构建一个简单的 PydanticAI 应用开始。这个应用将使用 LLM 回答有关山脉的问题：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the code above, I’m creating an agent (I’ll show you how, shortly) and then
    calling run_sync passing in the user prompt, and getting back the LLM’s response.
    run_sync is a way to have the agent invoke the LLM and wait for the response.
    Other ways are to run the query asynchronously, or to stream its response. ([Full
    code](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/1_zero_shot.py)
    is here if you want to follow along).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我创建了一个代理（稍后我会告诉你如何做），然后调用 run_sync 传入用户提示，并获取 LLM 的响应。run_sync 是一种让代理调用
    LLM 并等待响应的方式。其他方式是异步执行查询，或者流式返回响应。（[完整代码](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/1_zero_shot.py)
    在这里，如果你想跟着一起做）。
- en: 'Run the code above, and you will get something like:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码，你将得到类似这样的结果：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To create the agent, create a model and then tell the agent to use that Model
    for all its steps.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建代理，先创建一个模型，然后告诉代理在所有步骤中使用该模型。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The idea behind default_model() is to use a relatively inexpensive but fast
    model like Gemini Flash as the default. You can then change the model used in
    specific steps as necessary by passing in a different model to run_sync()
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: default_model() 背后的思路是使用像 Gemini Flash 这样相对廉价但快速的模型作为默认模型。然后，你可以通过传递不同的模型给 run_sync()
    来根据需要更改特定步骤中使用的模型。
- en: PydanticAI model support [looks sparse](https://ai.pydantic.dev/api/models/base/#pydantic_ai.models),
    but the most commonly used models — the current frontier ones from OpenAI, Groq,
    Gemini, Mistral, Ollama, and Anthropic — are all supported. Through Ollama, you
    can get access to Llama3, Starcoder2, Gemma2, and Phi3\. Nothing significant seems
    to be missing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: PydanticAI模型支持[看起来较为稀疏](https://ai.pydantic.dev/api/models/base/#pydantic_ai.models)，但最常用的模型——来自OpenAI、Groq、Gemini、Mistral、Ollama和Anthropic的当前前沿模型——都得到了支持。通过Ollama，你可以访问Llama3、Starcoder2、Gemma2和Phi3。似乎没有什么显著缺失。
- en: 2\. Pydantic with structured outputs
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 使用结构化输出的Pydantic
- en: The example in the previous section returned free-form text. In most agentic
    workflows, you’ll want the LLM to return structured data so that you can use it
    directly in programs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 前一部分的示例返回的是自由格式的文本。在大多数智能体工作流程中，你会希望LLM返回结构化数据，以便可以直接在程序中使用。
- en: 'Considering that this API is from Pydantic, returning structured output is
    quite straightforward. Just define the desired output as a dataclass (full code
    is [here](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/2_zero_shot_structured.py)):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这个API来自Pydantic，返回结构化输出是相当直接的。只需将期望的输出定义为数据类（[完整代码](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/2_zero_shot_structured.py)在这里）：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When you create the Agent, tell it the desired output type:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建智能体时，告诉它期望的输出类型：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note also the use of the system prompt to specify units etc.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另请注意使用系统提示来指定单位等。
- en: 'Running this on three questions, we get:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在三个问题上运行此代码后，我们得到：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: But how good is this agent? Is the height of Mt. Robson correct? Is Mt. Stuart
    really the tallest peak in the Enchantments? All of this information could have
    been hallucinated!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这个智能体有多好呢？罗布森山的高度正确吗？斯图尔特山真的是“魔法山脉”中最高的峰吗？这些信息可能是虚构的！
- en: There is no way for you to know how good an agentic application is unless you
    evaluate the agent against reference answers. You can not just “eyeball it”. Unfortunately,
    this is where a lot of LLM frameworks fall short — they make it really hard to
    evaluate as you develop the LLM application.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你将智能体与参考答案进行评估，否则你无法知道一个智能体应用的好坏。你不能仅凭眼睛“估算”。不幸的是，这正是许多LLM框架的不足之处——它们使得在开发LLM应用时评估变得非常困难。
- en: 3\. Evaluate against reference answers
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 与参考答案进行评估
- en: It is when you start to evaluate against reference answers that PydanticAI starts
    to show its strengths. Everything is quite Pythonic, so you can build custom evaluation
    metrics quite simply.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始与参考答案进行对比评估时，PydanticAI开始展现其优势。一切都非常符合Python风格，因此你可以非常简单地构建自定义评估指标。
- en: 'For example, this is how we will evaluate a returned Mountain object on three
    criteria and create a composite score ([full code](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/3_eval_against_reference.py)
    is here):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，下面是我们如何在三个标准上评估返回的Mountain对象，并创建一个综合得分（[完整代码](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/3_eval_against_reference.py)在这里）：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we can run this on a dataset of questions and reference answers:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在一组问题和参考答案的数据集上运行此功能：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Running this, we get:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们得到：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Mt. Robson’s height is 45m off; Dragontail peak’s height was 318m off. How would
    you fix this?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 罗布森山的高度偏差了45米；龙尾峰的高度偏差了318米。你会如何修正这个问题？
- en: That’s right. You’d use a RAG architecture or arm the agent with a tool that
    provides the correct height information. Let’s use the latter approach and see
    how to do it with Pydantic.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。你会使用RAG架构，或者为智能体提供一个能够提供正确高度信息的工具。我们就使用后者的方法，看看如何用Pydantic实现。
- en: Note how evaluation-driven development shows us the path forward to improve
    our agentic application.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如何通过评估驱动开发向我们展示了改善智能体应用的前进道路。
- en: 4a. Using a tool
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4a. 使用工具
- en: 'PydanticAI supports several ways to provide tools to an agent. Here, I annotate
    a function to be called whenever it needs the height of a mountain ([full code
    here](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/4_use_tool.py)):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PydanticAI支持多种向智能体提供工具的方式。在这里，我为一个函数添加了注解，以便在需要时调用它来获取山的高度（[完整代码在这里](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/4_use_tool.py)）：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The function, though, does something strange. It pulls an object called elev_wiki
    out of the run-time context of the agent. This object is passed in when we call
    run_sync:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个函数做了一些奇怪的事情。它从智能体的运行时上下文中提取了一个名为elev_wiki的对象。这个对象在我们调用run_sync时被传入：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Because the Runtime context can be passed into every agent invocation or tool
    call , we can use it to do dependency injection in PydanticAI. You’ll see this
    in the next section.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因为运行时上下文可以传递给每次代理调用或工具调用，所以我们可以用它来进行依赖注入。在下一节中你会看到这一点。
- en: 'The wiki itself just queries Wikipedia online ([code here](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/wikipedia_tool.py))
    and extracts the contents of the page and passes the appropriate mountain information
    to the agent:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 维基本身只是查询在线的维基百科（[代码在这里](https://github.com/lakshmanok/lakblogs/blob/main/pydantic_ai_mountains/wikipedia_tool.py)），提取页面内容并将适当的山脉信息传递给代理：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Indeed, when we run it, we get correct heights now:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，当我们运行时，现在得到了正确的高度：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 4b. Dependency injecting a mock service
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4b. 依赖注入一个模拟服务
- en: Waiting for the API call to Wikipedia each time during development or testing
    is a bad idea. Instead, we will want to mock the Wikipedia response so that we
    can develop quickly and be guaranteed of the result we are going to get.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 每次在开发或测试期间等待维基百科的API调用是不好的做法。相反，我们希望模拟维基百科的响应，这样我们就能快速开发，并确保得到预期的结果。
- en: 'Doing that is very simple. We create a Fake counterpart to the Wikipedia service:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 做这个非常简单。我们创建一个假的维基百科服务：
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, inject this fake object into the runtime context of the agent during
    development:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在开发过程中，将这个假对象注入到代理的运行时上下文中：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This time when we run, the evaluation uses the cached wikipedia content:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这次当我们运行时，评估使用了缓存的维基百科内容：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Look carefully at the above output — there are different errors from the zero-shot
    example. In Section #2, the LLM picked Vancouver as the closest city to Mt. Robson
    and Dragontail as the tallest peak in the Enchantments. Those answers happened
    to be correct. Now, it picks Jasper and Mt. Stuart. We need to do more work to
    fix these errors — but evaluation-driven development at least gives us a direction
    of travel.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察上面的输出——它与零-shot示例中的错误不同。在第2节中，LLM将温哥华选为最接近罗布森山的城市，将龙尾山选为魔法山脉中最高的峰。这些答案恰好是正确的。现在，它选择了贾斯珀和斯图尔特山。我们需要做更多工作来修复这些错误——但基于评估的开发至少给了我们一个前进的方向。
- en: Current Limitations
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前的局限性
- en: 'PydanticAI is very new. There are a couple of places where it could be improved:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: PydanticAI非常新，还有一些可以改进的地方：
- en: There is no low-level access to the model itself. For example, different foundational
    models support context caching, prompt caching, etc. The model abstraction in
    PydanticAI doesn’t provide a way to set these on the model. Ideally, we can figure
    out a kwargs way of doing such settings.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前没有对模型本身的底层访问。例如，不同的基础模型支持上下文缓存、提示缓存等。PydanticAI中的模型抽象没有提供设置这些功能的方法。理想情况下，我们可以通过传递`kwargs`的方式来实现这种设置。
- en: The need to create two versions of agent dependencies, one real and one fake,
    is quite common. It would be good if we were able to annoate a tool or provide
    a simple way to switch between the two types of services across the board.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建两个版本的代理依赖关系，一个真实的和一个假的，是很常见的。如果我们能够标注一个工具或提供一种简单的方法来在两种类型的服务之间切换，那将是非常好的。
- en: During development, you don’t need logging as much. But when you go to run the
    agent, you will usually want to log the prompts and responses. Sometimes, you
    will want to log the intermediate responses. The way to do this seems to be a
    commercial product called Logfire. An OSS, cloud-agnostic logging framework that
    integrates with the PydanticAI library would be ideal.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发过程中，你不需要那么多的日志记录。但当你运行代理时，通常会希望记录提示和响应。有时，你还需要记录中间的响应。实现这个目标的方法似乎是一个叫做Logfire的商业产品。一个与PydanticAI库集成的开源、与云平台无关的日志框架将是理想的选择。
- en: It is possible that these already exist and I missed them, or perhaps they will
    have been implemented by the time you are reading this article. In either case,
    leave a comment for future readers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可能这些服务已经存在，我没注意到，或者在你读这篇文章的时候它们已经被实现了。不管是哪种情况，都请为未来的读者留个评论。
- en: Overall, I like PydanticAI — it offers a very clean and Pythonic way to build
    agentic applications in an evaluation-driven manner.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我喜欢PydanticAI——它提供了一种非常简洁且符合Python风格的方式，来以评估驱动的方式构建代理应用。
- en: 'Suggested next steps:'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建议的下一步：
- en: 'This is one of those blog posts where you will benefit from actually running
    the examples because it describes a process of development as well as a new library.
    This GitHub repo contains the PydanticAI example I walked through in this post:
    [https://github.com/lakshmanok/lakblogs/tree/main/pydantic_ai_mountains](https://github.com/lakshmanok/lakblogs/tree/main/pydantic_ai_mountains)
    Follow the instructions in the README to try it out.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是那种你通过实际运行示例会受益的博客文章，因为它描述了一个开发过程以及一个新的库。这个 GitHub 仓库包含了我在这篇文章中演示的 PydanticAI
    示例：[https://github.com/lakshmanok/lakblogs/tree/main/pydantic_ai_mountains](https://github.com/lakshmanok/lakblogs/tree/main/pydantic_ai_mountains)。按照
    README 中的说明进行操作试试。
- en: 'Pydantic AI documentation: [https://ai.pydantic.dev/](https://ai.pydantic.dev/)'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pydantic AI 文档：[https://ai.pydantic.dev/](https://ai.pydantic.dev/)
- en: 'Patching a Langchain workflow with Mock objects. My “before” solution: [https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py](https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py)'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Mock 对象修补 Langchain 工作流。我的“前置”解决方案：[https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py](https://github.com/lakshmanok/lakblogs/blob/main/genai_agents/eval_weather_agent.py)
