<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Performance Insights from Sigma Rule Detections in Spark Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Performance Insights from Sigma Rule Detections in Spark Streaming</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/performance-insights-from-sigma-rule-detections-in-spark-streaming-fac8c67d37b8?source=collection_archive---------3-----------------------#2024-06-01">https://towardsdatascience.com/performance-insights-from-sigma-rule-detections-in-spark-streaming-fac8c67d37b8?source=collection_archive---------3-----------------------#2024-06-01</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="bf5b" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Utilizing Sigma rules for anomaly detection in cybersecurity logs: A study on performance optimization</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@jean-claude.cote?source=post_page---byline--fac8c67d37b8--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jean-Claude Cote" class="l ep by dd de cx" src="../Images/aea2df9c7b95fc85cc336f64d64b0a76.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*ZDeTO2JYRo3sVd9Y_iIQ-w.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--fac8c67d37b8--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@jean-claude.cote?source=post_page---byline--fac8c67d37b8--------------------------------" rel="noopener follow">Jean-Claude Cote</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--fac8c67d37b8--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 1, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/37046fd8ffe78e40feab09bcdfb16198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KoP4obKo0-tGSzd0PiqSYg.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by Ed Vazquez on Unsplash</figcaption></figure><p id="1a95" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">One of the roles of the <a class="af nx" href="https://www.cyber.gc.ca/en" rel="noopener ugc nofollow" target="_blank">Canadian Centre for Cyber Security</a> (CCCS) is to detect anomalies and issue mitigations as quickly as possible.</p><p id="f432" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">While putting our Sigma rule detections into production, we made an interesting observation in our Spark streaming application. Running a single large SQL statement expressing 1000 Sigma detection rules was slower than running five separate queries, each applying 200 Sigma rules. This was surprising, as running five queries forces Spark to read the source data five times rather than once. For further details, please refer to our series of articles:</p><div class="ny nz oa ob oc od"><a rel="noopener follow" target="_blank" href="/anomaly-detection-using-sigma-rules-part-1-leveraging-spark-sql-streaming-246900e95457?source=post_page-----fac8c67d37b8--------------------------------"><div class="oe ab ig"><div class="of ab co cb og oh"><h2 class="bf fr hw z io oi iq ir oj it iv fp bk">Anomaly Detection using Sigma Rules (Part 1): Leveraging Spark SQL Streaming</h2><div class="ok l"><h3 class="bf b hw z io oi iq ir oj it iv dx">Sigma rules are used to detect anomalies in cyber security logs. We use Spark structured streaming to evaluate Sigma…</h3></div><div class="ol l"><p class="bf b dy z io oi iq ir oj it iv dx">towardsdatascience.com</p></div></div><div class="om l"><div class="on l oo op oq om or lq od"/></div></div></a></div><p id="e7e9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Given the vast amount of telemetry data and detection rules we need to execute, every gain in performance yields significant cost savings. Therefore, we decided to investigate this peculiar observation, aiming to explain it and potentially discover additional opportunities to improve performance. We learned a few things along the way and wanted to share them with the broader community.</p><h2 id="9174" class="os ot fq bf ou ov ow ox oy oz pa pb pc nk pd pe pf no pg ph pi ns pj pk pl pm bk"><strong class="al">Introduction</strong></h2><p id="36f4" class="pw-post-body-paragraph nb nc fq nd b go pn nf ng gr po ni nj nk pp nm nn no pq nq nr ns pr nu nv nw fj bk">Our hunch was that we were reaching a limit in Spark’s code generation. So, a little background on this topic is required. In 2014, Spark introduced code generation to evaluate expressions of the form<code class="cx ps pt pu pv b"> (id &gt; 1 and id &gt; 2) and (id &lt; 1000 or (id + id) = 12)</code>. This article from Databricks explains it very well: <a class="af nx" href="https://www.databricks.com/blog/2014/06/02/exciting-performance-improvements-on-the-horizon-for-spark-sql.html" rel="noopener ugc nofollow" target="_blank">Exciting Performance Improvements on the Horizon for Spark SQL</a></p><p id="18d4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Two years later, Spark introduced Whole-Stage Code Generation. This optimization merges multiple operators together into a single Java function. Like expression code generation, Whole-Stage Code Generation eliminates virtual function calls and leverages CPU registers for intermediate data. However, rather than being at the expression level, it is applied at the operator level. Operators are the nodes in an execution plan. To find out more, read <a class="af nx" href="https://www.databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html" rel="noopener ugc nofollow" target="_blank">Apache Spark as a Compiler: Joining a Billion Rows per Second on a Laptop</a></p><p id="7abc" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To summarize these articles, let’s generate the plan for this simple query:</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="b214" class="pz ot fq pv b bg qa qb l qc qd">explain codegen<br/>select<br/>    id,<br/>    (id &gt; 1 and id &gt; 2) and (id &lt; 1000 or (id + id) = 12) as test  <br/>from<br/>    range(0, 10000, 1, 32)</span></pre><p id="4bd0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this simple query, we are using two operators: Range to generate rows and Select to perform a projection. We see these operators in the query’s physical plan. Notice the asterisk (*) beside the nodes and their associated <code class="cx ps pt pu pv b">[codegen id : 1]</code>. This indicates that these two operators were merged into a single Java function using Whole-Stage Code Generation.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="36f2" class="pz ot fq pv b bg qa qb l qc qd">|== Physical Plan ==<br/>* Project (2)<br/>+- * Range (1)<br/><br/><br/>(1) Range [codegen id : 1]<br/>Output [1]: [id#36167L]<br/>Arguments: Range (0, 10000, step=1, splits=Some(32))<br/><br/>(2) Project [codegen id : 1]<br/>Output [2]: [id#36167L, (((id#36167L &gt; 1) AND (id#36167L &gt; 2)) AND ((id#36167L &lt; 1000) OR ((id#36167L + id#36167L) = 12))) AS test#36161]<br/>Input [1]: [id#36167L]</span></pre><p id="2011" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The generated code clearly shows the two operators being merged.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="2b47" class="pz ot fq pv b bg qa qb l qc qd">Generated code:<br/>/* 001 */ public Object generate(Object[] references) {<br/>/* 002 */   return new GeneratedIteratorForCodegenStage1(references);<br/>/* 003 */ }<br/>/* 004 */<br/>/* 005 */ // codegenStageId=1<br/>/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {<br/>/* 007 */   private Object[] references;<br/>/* 008 */   private scala.collection.Iterator[] inputs;<br/>/* 009 */   private boolean range_initRange_0;<br/>/* 010 */   private long range_nextIndex_0;<br/>/* 011 */   private TaskContext range_taskContext_0;<br/>/* 012 */   private InputMetrics range_inputMetrics_0;<br/>/* 013 */   private long range_batchEnd_0;<br/>/* 014 */   private long range_numElementsTodo_0;<br/>/* 015 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] range_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[3];<br/>/* 016 */<br/>/* 017 */   public GeneratedIteratorForCodegenStage1(Object[] references) {<br/>/* 018 */     this.references = references;<br/>/* 019 */   }<br/>/* 020 */<br/>/* 021 */   public void init(int index, scala.collection.Iterator[] inputs) {<br/>/* 022 */     partitionIndex = index;<br/>/* 023 */     this.inputs = inputs;<br/>/* 024 */<br/>/* 025 */     range_taskContext_0 = TaskContext.get();<br/>/* 026 */     range_inputMetrics_0 = range_taskContext_0.taskMetrics().inputMetrics();<br/>/* 027 */     range_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);<br/>/* 028 */     range_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);<br/>/* 029 */     range_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);<br/>/* 030 */<br/>/* 031 */   }<br/>/* 032 */<br/>/* 033 */   private void project_doConsume_0(long project_expr_0_0) throws java.io.IOException {<br/>/* 034 */     // common sub-expressions<br/>/* 035 */<br/>/* 036 */     boolean project_value_4 = false;<br/>/* 037 */     project_value_4 = project_expr_0_0 &gt; 1L;<br/>/* 038 */     boolean project_value_3 = false;<br/>/* 039 */<br/>/* 040 */     if (project_value_4) {<br/>/* 041 */       boolean project_value_7 = false;<br/>/* 042 */       project_value_7 = project_expr_0_0 &gt; 2L;<br/>/* 043 */       project_value_3 = project_value_7;<br/>/* 044 */     }<br/>/* 045 */     boolean project_value_2 = false;<br/>/* 046 */<br/>/* 047 */     if (project_value_3) {<br/>/* 048 */       boolean project_value_11 = false;<br/>/* 049 */       project_value_11 = project_expr_0_0 &lt; 1000L;<br/>/* 050 */       boolean project_value_10 = true;<br/>/* 051 */<br/>/* 052 */       if (!project_value_11) {<br/>/* 053 */         long project_value_15 = -1L;<br/>/* 054 */<br/>/* 055 */         project_value_15 = project_expr_0_0 + project_expr_0_0;<br/>/* 056 */<br/>/* 057 */         boolean project_value_14 = false;<br/>/* 058 */         project_value_14 = project_value_15 == 12L;<br/>/* 059 */         project_value_10 = project_value_14;<br/>/* 060 */       }<br/>/* 061 */       project_value_2 = project_value_10;<br/>/* 062 */     }<br/>/* 063 */     range_mutableStateArray_0[2].reset();<br/>/* 064 */<br/>/* 065 */     range_mutableStateArray_0[2].write(0, project_expr_0_0);<br/>/* 066 */<br/>/* 067 */     range_mutableStateArray_0[2].write(1, project_value_2);<br/>/* 068 */     append((range_mutableStateArray_0[2].getRow()));<br/>/* 069 */<br/>/* 070 */   }<br/>/* 071 */<br/>/* 072 */   private void initRange(int idx) {<br/>/* 073 */     java.math.BigInteger index = java.math.BigInteger.valueOf(idx);<br/>/* 074 */     java.math.BigInteger numSlice = java.math.BigInteger.valueOf(32L);<br/>/* 075 */     java.math.BigInteger numElement = java.math.BigInteger.valueOf(10000L);<br/>/* 076 */     java.math.BigInteger step = java.math.BigInteger.valueOf(1L);<br/>/* 077 */     java.math.BigInteger start = java.math.BigInteger.valueOf(0L);<br/>/* 078 */     long partitionEnd;<br/>/* 079 */<br/>/* 080 */     java.math.BigInteger st = index.multiply(numElement).divide(numSlice).multiply(step).add(start);<br/>/* 081 */     if (st.compareTo(java.math.BigInteger.valueOf(Long.MAX_VALUE)) &gt; 0) {<br/>/* 082 */       range_nextIndex_0 = Long.MAX_VALUE;<br/>/* 083 */     } else if (st.compareTo(java.math.BigInteger.valueOf(Long.MIN_VALUE)) &lt; 0) {<br/>/* 084 */       range_nextIndex_0 = Long.MIN_VALUE;<br/>/* 085 */     } else {<br/>/* 086 */       range_nextIndex_0 = st.longValue();<br/>/* 087 */     }<br/>/* 088 */     range_batchEnd_0 = range_nextIndex_0;<br/>/* 089 */<br/>/* 090 */     java.math.BigInteger end = index.add(java.math.BigInteger.ONE).multiply(numElement).divide(numSlice)<br/>/* 091 */     .multiply(step).add(start);<br/>/* 092 */     if (end.compareTo(java.math.BigInteger.valueOf(Long.MAX_VALUE)) &gt; 0) {<br/>/* 093 */       partitionEnd = Long.MAX_VALUE;<br/>/* 094 */     } else if (end.compareTo(java.math.BigInteger.valueOf(Long.MIN_VALUE)) &lt; 0) {<br/>/* 095 */       partitionEnd = Long.MIN_VALUE;<br/>/* 096 */     } else {<br/>/* 097 */       partitionEnd = end.longValue();<br/>/* 098 */     }<br/>/* 099 */<br/>/* 100 */     java.math.BigInteger startToEnd = java.math.BigInteger.valueOf(partitionEnd).subtract(<br/>/* 101 */       java.math.BigInteger.valueOf(range_nextIndex_0));<br/>/* 102 */     range_numElementsTodo_0  = startToEnd.divide(step).longValue();<br/>/* 103 */     if (range_numElementsTodo_0 &lt; 0) {<br/>/* 104 */       range_numElementsTodo_0 = 0;<br/>/* 105 */     } else if (startToEnd.remainder(step).compareTo(java.math.BigInteger.valueOf(0L)) != 0) {<br/>/* 106 */       range_numElementsTodo_0++;<br/>/* 107 */     }<br/>/* 108 */   }<br/>/* 109 */<br/>/* 110 */   protected void processNext() throws java.io.IOException {<br/>/* 111 */     // initialize Range<br/>/* 112 */     if (!range_initRange_0) {<br/>/* 113 */       range_initRange_0 = true;<br/>/* 114 */       initRange(partitionIndex);<br/>/* 115 */     }<br/>/* 116 */<br/>/* 117 */     while (true) {<br/>/* 118 */       if (range_nextIndex_0 == range_batchEnd_0) {<br/>/* 119 */         long range_nextBatchTodo_0;<br/>/* 120 */         if (range_numElementsTodo_0 &gt; 1000L) {<br/>/* 121 */           range_nextBatchTodo_0 = 1000L;<br/>/* 122 */           range_numElementsTodo_0 -= 1000L;<br/>/* 123 */         } else {<br/>/* 124 */           range_nextBatchTodo_0 = range_numElementsTodo_0;<br/>/* 125 */           range_numElementsTodo_0 = 0;<br/>/* 126 */           if (range_nextBatchTodo_0 == 0) break;<br/>/* 127 */         }<br/>/* 128 */         range_batchEnd_0 += range_nextBatchTodo_0 * 1L;<br/>/* 129 */       }<br/>/* 130 */<br/>/* 131 */       int range_localEnd_0 = (int)((range_batchEnd_0 - range_nextIndex_0) / 1L);<br/>/* 132 */       for (int range_localIdx_0 = 0; range_localIdx_0 &lt; range_localEnd_0; range_localIdx_0++) {<br/>/* 133 */         long range_value_0 = ((long)range_localIdx_0 * 1L) + range_nextIndex_0;<br/>/* 134 */<br/>/* 135 */         project_doConsume_0(range_value_0);<br/>/* 136 */<br/>/* 137 */         if (shouldStop()) {<br/>/* 138 */           range_nextIndex_0 = range_value_0 + 1L;<br/>/* 139 */           ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(range_localIdx_0 + 1);<br/>/* 140 */           range_inputMetrics_0.incRecordsRead(range_localIdx_0 + 1);<br/>/* 141 */           return;<br/>/* 142 */         }<br/>/* 143 */<br/>/* 144 */       }<br/>/* 145 */       range_nextIndex_0 = range_batchEnd_0;<br/>/* 146 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(range_localEnd_0);<br/>/* 147 */       range_inputMetrics_0.incRecordsRead(range_localEnd_0);<br/>/* 148 */       range_taskContext_0.killTaskIfInterrupted();<br/>/* 149 */     }<br/>/* 150 */   }<br/>/* 151 */<br/>/* 152 */ }</span></pre><p id="65d9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The <code class="cx ps pt pu pv b">project_doConsume_0</code> function contains the code to evaluate <code class="cx ps pt pu pv b">(id &gt; 1 and id &gt; 2) and (id &lt; 1000 or (id + id) = 12)</code>. Notice how this code is generated to evaluate this specific expression. This is an illustration of expression code generation.</p><p id="c677" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The whole class is an operator with a <code class="cx ps pt pu pv b">processNext </code>method. This generated operator performs both the Projection and the Range operations. Inside the while loop at line 117, we see the code to produce rows and a specific call (not a virtual function) to <code class="cx ps pt pu pv b">project_doConsume_0</code>. This illustrates what Whole-Stage Code Generation does.</p><h2 id="51df" class="os ot fq bf ou ov ow ox oy oz pa pb pc nk pd pe pf no pg ph pi ns pj pk pl pm bk"><strong class="al">Breaking Down the Performance</strong></h2><p id="c8d0" class="pw-post-body-paragraph nb nc fq nd b go pn nf ng gr po ni nj nk pp nm nn no pq nq nr ns pr nu nv nw fj bk">Now that we have a better understanding of Spark’s code generation, let’s try to explain why breaking a query doing 1000 Sigma rules into smaller ones performs better. Let’s consider a SQL statement that evaluates two Sigma rules. These rules are straightforward: Rule1 matches events with an <code class="cx ps pt pu pv b">Imagepath </code>ending in ‘schtask.exe’, and Rule2 matches an <code class="cx ps pt pu pv b">Imagepath </code>starting with ‘d:’.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="751d" class="pz ot fq pv b bg qa qb l qc qd"><br/>select /* #3 */<br/>    Imagepath,<br/>    CommandLine,<br/>    PID,<br/>    map_keys(map_filter(results_map, (k,v) -&gt; v = TRUE)) as matching_rules<br/>from (<br/>    select /* #2 */<br/>        *,<br/>        map('rule1', rule1, 'rule2', rule2) as results_map<br/>    from (<br/>        select /* #1 */<br/>            *,<br/>            (lower_Imagepath like '%schtasks.exe') as rule1,<br/>            (lower_Imagepath like 'd:%') as rule2<br/>        from (<br/>            select <br/>                lower(PID) as lower_PID,<br/>                lower(CommandLine) as lower_CommandLine,<br/>                lower(Imagepath) as lower_Imagepath,<br/>                *<br/>            from (<br/>                select<br/>                    uuid() as PID,<br/>                    uuid() as CommandLine,<br/>                    uuid() as Imagepath,<br/>                    id <br/>                from<br/>                    range(0, 10000, 1, 32)<br/>            )<br/>        )<br/>    )<br/>)</span></pre><p id="b15a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The select labeled #1 performs the detections and stores the results in new columns named rule1 and rule2. Select #2 regroups these columns under a single <code class="cx ps pt pu pv b">results_map</code>, and finally select #3 transforms the map into an array of matching rules. It uses <code class="cx ps pt pu pv b">map_filter </code>to keep only the entries of rules that actually matched, and then <code class="cx ps pt pu pv b">map_keys </code>is used to convert the map entries into a list of matching rule names.</p><p id="f3b8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Let’s print out the Spark execution plan for this query:</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="cd0c" class="pz ot fq pv b bg qa qb l qc qd"><br/>== Physical Plan ==<br/>Project (4)<br/>+- * Project (3)<br/>   +- * Project (2)<br/>      +- * Range (1)<br/><br/>...<br/><br/>(4) Project<br/>Output [4]: [Imagepath#2, CommandLine#1, PID#0, map_keys(map_filter(map(rule1, EndsWith(lower_Imagepath#5, schtasks.exe), rule2, StartsWith(lower_Imagepath#5, d:)), lambdafunction(lambda v#12, lambda k#11, lambda v#12, false))) AS matching_rules#9]<br/>Input [4]: [lower_Imagepath#5, PID#0, CommandLine#1, Imagepath#2]</span></pre><p id="4648" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Notice that node Project (4) is not code generated. Node 4 has a lambda function, does it prevent whole stage code generation? More on this later.</p><p id="5ad2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This query is not quite what we want. We would like to produce a table of events with a column indicating the rule that was matched. Something like this:</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="1381" class="pz ot fq pv b bg qa qb l qc qd">+--------------------+--------------------+--------------------+--------------+<br/>|           Imagepath|         CommandLine|                 PID|  matched_rule|<br/>+--------------------+--------------------+--------------------+--------------+<br/>|09401675-dc09-4d0...|6b8759ee-b55a-486...|44dbd1ec-b4e0-488...|         rule1|<br/>|e2b4a0fd-7b88-417...|46dd084d-f5b0-4d7...|60111cf8-069e-4b8...|         rule1|<br/>|1843ee7a-a908-400...|d1105cec-05ef-4ee...|6046509a-191d-432...|         rule2|<br/>+--------------------+--------------------+--------------------+--------------+</span></pre><p id="2209" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">That’s easy enough. We just need to explode the <code class="cx ps pt pu pv b">matching_rules </code>column.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="a99f" class="pz ot fq pv b bg qa qb l qc qd"><br/>select<br/>    Imagepath,<br/>    CommandLine,<br/>    PID,<br/>    matched_rule<br/>from (<br/>    select<br/>        *,<br/>        explode(matching_rules) as matched_rule<br/>    from (<br/>        /* original statement */<br/>    )<br/>)</span></pre><p id="dbe9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This produces two additional operators: Generate (6) and Project (7). However, there is also a new Filter (3).</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="70ed" class="pz ot fq pv b bg qa qb l qc qd">== Physical Plan ==<br/>* Project (7)<br/>+- * Generate (6)<br/>   +- Project (5)<br/>      +- * Project (4)<br/>         +- Filter (3)<br/>            +- * Project (2)<br/>               +- * Range (1)<br/><br/>...<br/><br/>(3) Filter<br/>Input [3]: [PID#34, CommandLine#35, Imagepath#36]<br/>Condition : (size(map_keys(map_filter(map(rule1, EndsWith(lower(Imagepath#36),<br/> schtasks.exe), rule2, StartsWith(lower(Imagepath#36), d:)), <br/>lambdafunction(lambda v#47, lambda k#46, lambda v#47, false))), true) &gt; 0)<br/>...<br/><br/>(6) Generate [codegen id : 3]<br/>Input [4]: [PID#34, CommandLine#35, Imagepath#36, matching_rules#43]<br/>Arguments: explode(matching_rules#43), [PID#34, CommandLine#35, Imagepath#36], false, [matched_rule#48]<br/><br/>(7) Project [codegen id : 3]<br/>Output [4]: [Imagepath#36, CommandLine#35, PID#34, matched_rule#48]<br/>Input [4]: [PID#34, CommandLine#35, Imagepath#36, matched_rule#48]</span></pre><p id="53be" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The <code class="cx ps pt pu pv b">explode </code>function generates rows for every element in the array. When the array is empty, <code class="cx ps pt pu pv b">explode </code>does not produce any rows, effectively filtering out rows where the array is empty.</p><p id="afa3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Spark has an optimization rule that detects the explode function and produces this additional condition. The filter is an attempt by Spark to short-circuit processing as much as possible. The source code for this rule, named <code class="cx ps pt pu pv b">org.apache.spark.sql.catalyst.optimizer.InferFiltersFromGenerate</code>, explains it like this:</p><blockquote class="qe qf qg"><p id="3625" class="nb nc qh nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Infers filters from Generate, such that rows that would have been removed by this Generate can be removed earlier — before joins and in data sources.</p></blockquote><p id="728c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For more details on how Spark optimizes execution plans please refer to David Vrba’s article <a class="af nx" rel="noopener" target="_blank" href="/mastering-query-plans-in-spark-3-0-f4c334663aa4">Mastering Query Plans in Spark 3.0</a></p><p id="e046" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Another question arises: do we benefit from this additional filter? Notice this additional filter is not whole-stage code generated either, presumably because of the lambda function. Let’s try to express the same query but without using a lambda function.</p><p id="cac7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Instead, we can put the rule results in a map, explode the map, and filter out the rows, thereby bypassing the need for <code class="cx ps pt pu pv b">map_filter</code>.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="2be0" class="pz ot fq pv b bg qa qb l qc qd"><br/>select<br/>    Imagepath,<br/>    CommandLine,<br/>    PID,<br/>    matched_rule<br/>from (<br/>    select<br/>        *<br/>    from (<br/>        select<br/>            *,<br/>            explode(results_map) as (matched_rule, matched_result)<br/>        from (<br/>            /* original statement */<br/>        )<br/>    )<br/>    where<br/>        matched_result = TRUE<br/>)</span></pre><p id="639f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The select #3 operation explodes the map into two new columns. The <code class="cx ps pt pu pv b">matched_rule </code>column will hold the key, representing the rule name, while the <code class="cx ps pt pu pv b">matched_result </code>column will contain the result of the detection test. To filter the rows, we simply keep only those with a positive <code class="cx ps pt pu pv b">matched_result</code>.</p><p id="1f0c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The physical plan indicates that all nodes are whole-stage code generated into a single Java function, which is promising.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="fa5e" class="pz ot fq pv b bg qa qb l qc qd"><br/>== Physical Plan ==<br/>* Project (8)<br/>+- * Filter (7)<br/>   +- * Generate (6)<br/>      +- * Project (5)<br/>         +- * Project (4)<br/>            +- * Filter (3)<br/>               +- * Project (2)<br/>                  +- * Range (1)</span></pre><p id="d72f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Let’s conduct some tests to compare the performance of the query using <code class="cx ps pt pu pv b">map_filter </code>and the one using explode then filter.</p><p id="7c46" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We ran these tests on a machine with 4 CPUs. We generated 1 million rows, each with 100 rules, and each rule evaluating 5 expressions. These tests were run 5 times.</p><p id="4006" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">On average</p><ul class=""><li id="2469" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qi qj qk bk">map_filter took 42.6 seconds</li><li id="bcb4" class="nb nc fq nd b go ql nf ng gr qm ni nj nk qn nm nn no qo nq nr ns qp nu nv nw qi qj qk bk">explode_then_filter took 51.2 seconds</li></ul><p id="e05a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">So, map_filter is slightly faster even though it’s not using whole-stage code generation.</p><p id="23a2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">However, in our production query, we execute many more Sigma rules — a total of 1000 rules. This includes 29 regex expressions, 529 equals, 115 starts-with, 2352 ends-with, and 5838 contains expressions. Let’s test our query again, but this time with a slight increase in the number of expressions, using 7 instead of 5 per rule. Upon doing this, we encountered an error in our logs:</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="cca8" class="pz ot fq pv b bg qa qb l qc qd">Caused by: org.codehaus.commons.compiler.InternalCompilerException: Code grows beyond 64 KB</span></pre><p id="ac98" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We tried increasing <code class="cx ps pt pu pv b">spark.sql.codegen.maxFields</code> and <code class="cx ps pt pu pv b">spark.sql.codegen.hugeMethodLimit</code>, but fundamentally, Java classes have a function size limit of 64 KB. Additionally, the JVM JIT compiler limits itself to compiling functions smaller than 8 KB.</p><p id="0675" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">However, the query still runs fine because Spark falls back to the Volcano execution model for certain parts of the plan. WholeStageCodeGen is just an optimization after all.</p><p id="c9b6" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Running the same test as before but with 7 expressions per rule rather than 5, explode_then_filter is much faster than map_filter.</p><ul class=""><li id="c36b" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qi qj qk bk">map_filter took 68.3 seconds</li><li id="09d8" class="nb nc fq nd b go ql nf ng gr qm ni nj nk qn nm nn no qo nq nr ns qp nu nv nw qi qj qk bk">explode_then_filter took 15.8 seconds</li></ul><p id="5b42" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Increasing the number of expressions causes parts of the explode_then_filter to no longer be whole-stage code generated. In particular, the Filter operator introduced by the rule <code class="cx ps pt pu pv b">org.apache.spark.sql.catalyst.optimizer.InferFiltersFromGenerate</code> is too big to be incorporated into whole-stage code generation. Let’s see what happens if we exclude the InferFiltersFromGenerate rule:</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="4e40" class="pz ot fq pv b bg qa qb l qc qd">spark.sql("SET spark.sql.optimizer.excludedRules=org.apache.spark.sql.catalyst.optimizer.InferFiltersFromGenerate")</span></pre><p id="07f8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As expected, the physical plan of both queries no longer has an additional Filter operator.</p><pre class="ml mm mn mo mp pw pv px bp py bb bk"><span id="bbef" class="pz ot fq pv b bg qa qb l qc qd"><br/>== Physical Plan ==<br/>* Project (6)<br/>+- * Generate (5)<br/>   +- Project (4)<br/>      +- * Project (3)<br/>         +- * Project (2)<br/>            +- * Range (1)<br/><br/><br/><br/>== Physical Plan ==<br/>* Project (7)<br/>+- * Filter (6)<br/>   +- * Generate (5)<br/>      +- * Project (4)<br/>         +- * Project (3)<br/>            +- * Project (2)<br/>               +- * Range (1)</span></pre><p id="8c62" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Removing the rule indeed had a significant impact on performance:</p><ul class=""><li id="a6a3" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qi qj qk bk">map_filter took 22.49 seconds</li><li id="5be9" class="nb nc fq nd b go ql nf ng gr qm ni nj nk qn nm nn no qo nq nr ns qp nu nv nw qi qj qk bk">explode_then_filter took 4.08 seconds</li></ul><p id="a340" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Both queries benefited greatly from removing the rule. Given the improved performance, we decided to increase the number of Sigma rules to 500 and the complexity to 21 expressions:</p><p id="4825" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Results:</p><ul class=""><li id="2bdf" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qi qj qk bk">map_filter took 195.0 seconds</li><li id="dd22" class="nb nc fq nd b go ql nf ng gr qm ni nj nk qn nm nn no qo nq nr ns qp nu nv nw qi qj qk bk">explode_then_filter took 25.09 seconds</li></ul><p id="577c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Despite the increased complexity, both queries still deliver pretty good performance, with explode_then_filter significantly outperforming map_filter.</p><p id="b460" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">It’s interesting to explore the different aspects of code generation employed by Spark. While we may not currently benefit from whole-stage code generation, we can still gain advantages from expression generation.</p><p id="02de" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Expression generation doesn’t face the same limitations as whole-stage code generation. Very large expression trees can be broken into smaller ones, and Spark’s <code class="cx ps pt pu pv b">spark.sql.codegen.methodSplitThreshold</code> controls how these are broken up. Although we experimented with this property, we didn’t observe significant improvements. The default setting seems satisfactory.</p><p id="d8fb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Spark provides a debugging property named <code class="cx ps pt pu pv b">spark.sql.codegen.factoryMode</code>, which can be set to FALLBACK, CODEGEN_ONLY, or NO_CODEGEN. We can turn off expression code generation by setting <code class="cx ps pt pu pv b">spark.sql.codegen.factoryMode=NO_CODEGEN</code>, which results in a drastic performance degradation:</p><p id="00fc" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">With 500 rules and 21 expressions:</p><ul class=""><li id="8af0" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qi qj qk bk">map_filter took 1581 seconds</li><li id="e773" class="nb nc fq nd b go ql nf ng gr qm ni nj nk qn nm nn no qo nq nr ns qp nu nv nw qi qj qk bk">explode_then_filter took 122.31 seconds.</li></ul><p id="21f6" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Even though not all operators participate in whole-stage code generation, we still observe significant benefits from expression code generation.</p><h2 id="f510" class="os ot fq bf ou ov ow ox oy oz pa pb pc nk pd pe pf no pg ph pi ns pj pk pl pm bk">The Results</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qq"><img src="../Images/e6090af0bc9f5f696f7d7887ded95d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpgDy1JKEe8MOAbcFbSgwQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="54a8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">With our best case of 25.1 seconds to evaluate 10,500 expressions on 1 million rows, we achieve a very respectable rate of 104 million expressions per second per CPU.</p><p id="4f6a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The takeaway from this study is that when evaluating a large number of expressions, we benefit from converting our queries that use <code class="cx ps pt pu pv b">map_filter </code>to ones using an explode then filter approach. Additionally, the <code class="cx ps pt pu pv b">org.apache.spark.sql.catalyst.optimizer.InferFiltersFromGenerate</code> rule does not seem beneficial in our use case, so we should exclude that rule from our queries.</p><h2 id="054a" class="os ot fq bf ou ov ow ox oy oz pa pb pc nk pd pe pf no pg ph pi ns pj pk pl pm bk">Does it Explain our Initial Observations?</h2><p id="ad09" class="pw-post-body-paragraph nb nc fq nd b go pn nf ng gr po ni nj nk pp nm nn no pq nq nr ns pr nu nv nw fj bk">Implementing these lessons learned in our production jobs yielded significant benefits. However, even after these optimizations, splitting the large query into multiple smaller ones continued to provide advantages. Upon further investigation, we discovered that this was not solely due to code generation but rather a simpler explanation.</p><p id="0970" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Spark streaming operates by running a micro-batch to completion and then checkpoints its progress before starting a new micro-batch.</p><p id="0379" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">During each micro-batch, Spark has to complete all its tasks, typically 200. However, not all tasks are created equal. Spark employs a round-robin strategy to distribute rows among these tasks. So, on occasion, some tasks can contain events with large attributes, for example, a very large command line, causing certain tasks to finish quickly while others take much longer. For example here the distribution of a micro-batch task execution time. The median task time is 14 seconds. However, the worst straggler is 1.6 minutes!</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qr"><img src="../Images/8b9727dd12cf03571a89fcfbd3947a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LIqW0G0xgYRPohLxGww3g.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="cec8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This indeed sheds light on a different phenomenon. The fact that Spark waits on a few straggler tasks during each micro-batch leaves many CPUs idle, which explains why splitting the large query into multiple smaller ones resulted in faster overall performance.</p><p id="a94c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This picture shows 5 smaller queries running in parallel inside the same Spark application. Batch3 is waiting on a straggler task while the other queries keep progressing.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qs"><img src="../Images/a683d30843790b2d9984ffabbce854f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OOAH44n9ROJGgejAnUPmw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="8d00" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">During these periods of waiting, Spark can utilize the idle CPUs to tackle other queries, thereby maximizing resource utilization and overall throughput.</p><h2 id="1730" class="os ot fq bf ou ov ow ox oy oz pa pb pc nk pd pe pf no pg ph pi ns pj pk pl pm bk">Conclusion</h2><p id="e220" class="pw-post-body-paragraph nb nc fq nd b go pn nf ng gr po ni nj nk pp nm nn no pq nq nr ns pr nu nv nw fj bk">In this article, we provided an overview of Spark’s code generation process and discussed how built-in optimizations may not always yield desirable results. Additionally, we demonstrated that refactoring a query from using lambda functions to one utilizing a simple explode operation resulted in performance improvements. Finally, we concluded that while splitting a large statement did lead to performance boosts, the primary factor driving these gains was the execution topology rather than the queries themselves.</p></div></div></div></div>    
</body>
</html>