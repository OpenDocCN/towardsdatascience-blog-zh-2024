<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Evaluating synthetic data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Evaluating synthetic data</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluating-synthetic-data-c5833f6b2f15?source=collection_archive---------7-----------------------#2024-10-14">https://towardsdatascience.com/evaluating-synthetic-data-c5833f6b2f15?source=collection_archive---------7-----------------------#2024-10-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e5b7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Assessing plausibility and usefulness of data we generated from real data</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@aymeric.floyrac.x?source=post_page---byline--c5833f6b2f15--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Aymeric Floyrac" class="l ep by dd de cx" src="../Images/f598fa3564693e544d02255d527682c2.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*mNwpUtTVRFV1Eb388G3xVg@2x.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--c5833f6b2f15--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@aymeric.floyrac.x?source=post_page---byline--c5833f6b2f15--------------------------------" rel="noopener follow">Aymeric Floyrac</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--c5833f6b2f15--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="e2e4" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Synthetic data serves many purposes, and has been gathering attention for a while, partly due to the convincing capabilities of LLMs. But what is «good» synthetic data, and how can we know we managed to generate it ?</p><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng nh"><img src="../Images/05da845afb54cf39126b28069887e44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*c3PY3XOwqDa5AA4R"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Photo by <a class="af ny" href="https://unsplash.com/@dementedpixel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nigel Hoare</a> on <a class="af ny" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="e6c2" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">What is synthetic data ?</h1><p id="13a1" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">Synthetic data is data that has been generated with the intent to look like real data, at least on some aspects (schema at the very least, statistical distributions, …). It is usually generated randomly, using a wide range of models : random sampling, noise addition, GAN, diffusion models, variational autoencoders, LLM, … <br/>It is used for many purposes, for instance :</p><ul class=""><li id="c269" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne pa pb pc bk">training and education (eg, discovering a new database or teaching a course),</li><li id="ab4b" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk">data augmentation (ie, creating new samples to train a model),</li><li id="2d01" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk">sharing data while protecting privacy (especially useful from an open science point of view),</li><li id="f86e" class="mj mk fq ml b go pd mn mo gr pe mq mr ms pf mu mv mw pg my mz na ph nc nd ne pa pb pc bk">conducting research while protecting privacy.</li></ul><p id="a8d2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">It is particularily used in software testing, and in sensitive domains like healthcare technology : having access to data that behaves like real data without jeopardizing patients privacy is a dream come true.</p><h1 id="1502" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Synthetic data quality principles</h1><h2 id="16cf" class="pi oa fq bf ob pj pk pl oe pm pn po oh ms pp pq pr mw ps pt pu na pv pw px py bk">Individual plausibility</h2><p id="e682" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">For a sample to be useful it must, in some way, look like real data. The ultimate goal is that generated samples must be indistinguishable from real samples : generate hyper-realistic faces, sentences, medical records, … Obviously, the more complex the source data, the harder it is to generate «good» synthetic data.</p><h2 id="9fc6" class="pi oa fq bf ob pj pk pl oe pm pn po oh ms pp pq pr mw ps pt pu na pv pw px py bk">Usefulness</h2><p id="9481" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">In many cases, especially data augmentation, we need more than one realistic sample, we need a whole dataset. And it is not the same to generate a single sample and a whole dataset : the problem is very well known, under the name of <em class="pz">mode collapse</em>, which is especially frequent when training a generative adversarial network (GAN)<em class="pz">. </em>Essentially, the generator (more generally, the model that generates synthetic data) could learn to generate a single type of sample and totally miss out on the rest of the sample space, leading to a synthetic dataset that is not as useful as the original dataset.</p><p id="8188" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For instance, if we train a model to generate animal pictures, and it finds a very efficient way to generate cat pictures, it could stop generating anything else than cat pictures (in particular, no dog pictures). Cat pictures would then be the “mode” of the generated distribution.</p><p id="dda2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This type of behaviour is harmful if our initial goal is to augment our data, or create a dataset for training. What we need is a dataset that is realistic in itself, which in absolute means that any statistic derived from this dataset should be close enough to the same statistic on real data. Statistically speaking, this means that univariate and multivariate distributions should be the same (or at least “close enough”).</p><h2 id="a588" class="pi oa fq bf ob pj pk pl oe pm pn po oh ms pp pq pr mw ps pt pu na pv pw px py bk">Privacy</h2><p id="466f" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">We will not dive too deep on this topic, which would deserve an article in itself. To keep it short : according to our initial goal, we may have to share data (more or less publicly), which means, if it is personal data, that it should be protected. For instance, we need to make sure we cannot retrieve any information on any given individual of the original dataset using the synthetic dataset. In particular, that means being cautious about outliers, or checking that no original sample was generated by the generator.</p><p id="d965" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">One way to consider the privacy issue is to use the differential privacy framework.</p><h1 id="71f0" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Evaluation in practice</h1><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng qa"><img src="../Images/376b37492db54f154482daa4d6ce9919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OMIGJ6aJbmJLaRBA"/></div></div><figcaption class="nt nu nv nf ng nw nx bf b bg z dx">Photo by <a class="af ny" href="https://unsplash.com/@libraryofcongress?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Library of Congress</a> on <a class="af ny" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2a6b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Let’s start by loading data and generating a synthetic dataset from this data. We’ll start with the famous `iris` dataset. To generate it synthetic counterpart, we’ll use the <a class="af ny" href="https://sdv.dev/" rel="noopener ugc nofollow" target="_blank">Synthetic Data Vault</a> package.</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="39c3" class="qf oa fq qc b bg qg qh l qi qj">pip install sdv</span></pre><pre class="qk qb qc qd bp qe bb bk"><span id="c808" class="qf oa fq qc b bg qg qh l qi qj">from sklearn.datasets import load_iris<br/>from sdv.single_table import GaussianCopulaSynthesizer<br/>from sdv.metadata.metadata import Metadata<br/><br/>data = load_iris(return_X_y=False, as_frame=True)<br/>real_data = data["data"]<br/><br/># metadata of the `iris` dataset<br/>metadata = Metadata().load_from_dict({<br/>    "tables": {<br/>        "iris": {<br/>            "columns": {<br/>                "sepal length (cm)": {<br/>                    "sdtype": "numerical",<br/>                    "computer_representation": "Float"<br/>                },<br/>                "sepal width (cm)": {<br/>                    "sdtype": "numerical",<br/>                    "computer_representation": "Float"<br/>                },<br/>                "petal length (cm)": {<br/>                    "sdtype": "numerical",<br/>                    "computer_representation": "Float"<br/>                },<br/>                "petal width (cm)": {<br/>                    "sdtype": "numerical",<br/>                    "computer_representation": "Float"<br/>                }<br/>            },<br/>            "primary_key": None<br/>        }<br/>    },<br/>    "relationships": [],<br/>    "METADATA_SPEC_VERSION": "V1"<br/>})<br/><br/># train the synthesizer<br/>synthesizer = GaussianCopulaSynthesizer(metadata)<br/>synthesizer.fit(data=real_data)<br/># generate samples - in this case, <br/># synthetic_data has the same shape as real_data<br/>synthetic_data = synthesizer.sample(num_rows=150)</span></pre><h2 id="477c" class="pi oa fq bf ob pj pk pl oe pm pn po oh ms pp pq pr mw ps pt pu na pv pw px py bk">Sample level</h2><p id="e554" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">Now, we want to test whether it is possible to tell if a single sample is synthetic or not.</p><p id="bb79" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">With this formulation, we easily see it is fundamentally a binary classification problem (synthetic vs original). Hence, we can train any model to classify original data from synthetic data : if this model achieves a good accuracy (which here means significantly above 0.5), the synthetic samples are not realistic enough. We aim for 0.5 accuracy (if the test set contains half original samples and half synthetic samples), which would mean that the classifier is making random guesses.</p><p id="5c5c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">As in any classification problem, we should not limit ourself to weak models and give a fair amount of effort in hyperparameters selection and model training.</p><p id="fed9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now for the code :</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="6954" class="qf oa fq qc b bg qg qh l qi qj">import pandas as pd <br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.ensemble import RandomForestClassifier<br/><br/><br/>def classification_evaluation(<br/>  real_data: pd.DataFrame, <br/>  synthetic_data: pd.DataFrame<br/>) -&gt; float:<br/><br/>    X = pd.concat((real_data, synthetic_data))<br/>    y = np.concatenate(<br/>        (<br/>            np.zeros(real_data.shape[0]),<br/>            np.ones(synthetic_data.shape[0])<br/>        )<br/>    )<br/><br/>    Xtrain, Xtest, ytrain, ytest = train_test_split(<br/>        X,<br/>        y,<br/>        test_size=0.2,<br/>        stratify=y<br/>    )<br/>    <br/>    clf = RandomForestClassifier()<br/>    clf.fit(Xtrain, ytrain)<br/>    score = accuracy_score(clf.predict(Xtest), ytest)<br/><br/>    return score<br/><br/>classification_evaluation(real_data, synthetic_data)<br/>&gt;&gt;&gt; 0.9</span></pre><p id="b786" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this case, it appears the synthesizer was not able to fool our classifier : the synthetic data is not realistic enough.</p><h2 id="3a2a" class="pi oa fq bf ob pj pk pl oe pm pn po oh ms pp pq pr mw ps pt pu na pv pw px py bk">Dataset level</h2><p id="b9c0" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">If our samples were realistic enough to fool a reasonably powerful classifier, we would need to evaluate our dataset as a whole. This time, it cannot be translated into a classification problem, and we need to use several indicators.</p><p id="fb32" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Statistical distributions</strong></p><p id="4a10" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The most obvious tests are statistical tests : are the univariate distributions in the original dataset the same as in the synthetic dataset ? Are the correlations the same ?</p><p id="b606" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Ideally, we would like to test <em class="pz">N</em>-variate distributions for any <em class="pz">N</em>, which can be particularily expensive for a high number of variables. However, even univariate distributions make it possible to see if our dataset is subject to mode collapse.</p><p id="f74b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now for the code :</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="3b5c" class="qf oa fq qc b bg qg qh l qi qj">import pandas as pd<br/>from scipy.stats import ks_2samp<br/><br/>def univariate_distributions_tests(<br/>  real_data: pd.DataFrame, <br/>  synthetic_data: pd.DataFrame<br/>) -&gt; None:<br/>    for col in real_data.columns:<br/>        if real_data[col].dtype.kind in "biufc": <br/>            stat, p_value = ks_2samp(real_data[col], synthetic_data[col])<br/>            print(f"Column: {col}")<br/>            print(f"P-value: {p_value:.4f}")<br/>            print("Significantly different" if p_value &lt; 0.05 else "Not significantly different")<br/>            print("---")</span></pre><pre class="qk qb qc qd bp qe bb bk"><span id="3bf9" class="qf oa fq qc b bg qg qh l qi qj">univariate_distributions_tests(real_data, synthetic_data)<br/><br/>&gt;&gt;&gt; Column: sepal length (cm)<br/>P-value: 0.9511<br/>Not significantly different<br/>---<br/>Column: sepal width (cm)<br/>P-value: 0.0000<br/>Significantly different<br/>---<br/>Column: petal length (cm)<br/>P-value: 0.0000<br/>Significantly different<br/>---<br/>Column: petal width (cm)<br/>P-value: 0.1804<br/>Not significantly different<br/>---</span></pre><p id="cb96" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In our case, out of the 4 variables, only 2 have similar distributions in the real dataset and in the synthetic dataset. This shows that our synthesizer fails to reproduce basic properties of this dataset.</p><p id="1b2c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Visual inspection</strong></p><p id="d688" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Though no mathematically proof, a visual comparison of the datasets can be useful.</p><p id="f1c0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The first method is to plot bivariate distributions (or correlation plots).</p><p id="75ce" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can also represent all the dataset dimensions at once: for instance, given a tabular dataset and its synthetic equivalent, we can plot both datasets using a dimension reduction technique, such as t-SNE, PCA or UMAP. With a perfect synthetizer, the scatter plots should look the same.</p><p id="25f6" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now for the code :</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="dcc1" class="qf oa fq qc b bg qg qh l qi qj">pip install umap-learn</span></pre><pre class="qk qb qc qd bp qe bb bk"><span id="359a" class="qf oa fq qc b bg qg qh l qi qj">import pandas as pd<br/>import seaborn as sns<br/>import umap<br/>import matplotlib.pyplot as plt<br/><br/><br/>def plot(<br/>  real_data: pd.DataFrame, <br/>  synthetic_data: pd.DataFrame, <br/>  kind: str = "pairplot"<br/>):<br/><br/>    assert kind in ["umap", "pairplot"]<br/>    real_data["label"] = "real"<br/>    synthetic_data["label"] = "synthetic"<br/>    X = pd.concat((real_data, synthetic_data))<br/><br/>    if kind == "pairplot":<br/>        sns.pairplot(X, hue="label")<br/>    <br/>    elif kind == "umap": <br/>        reducer = umap.UMAP()<br/>        embedding = reducer.fit_transform(X.drop("label", axis=1))<br/>        plt.scatter(<br/>            embedding[:, 0],<br/>            embedding[:, 1],<br/>            c=[sns.color_palette()[x] for x in X["label"].map({"real":0, "synthetic":1})],<br/>            s=30,<br/>            edgecolors="white"<br/>        )<br/>        plt.gca().set_aspect('equal', 'datalim')<br/>        sns.despine(top=True, right=True, left=False, bottom=False)</span></pre><pre class="qk qb qc qd bp qe bb bk"><span id="68c8" class="qf oa fq qc b bg qg qh l qi qj">plot(real_data, synthetic_data, kind="pairplot")</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div role="button" tabindex="0" class="no np ed nq bh nr"><div class="nf ng ql"><img src="../Images/cce9d8e2218658a1a2ad69578bef06b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Umx7PBHlmWzr0rvgJEQnug.png"/></div></div></figure><p id="7ee9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We already see on these plots that the bivariate distributions are not identical between real data and synthetic data, which is one more hint that the synthetization process failed to reproduce high-order relationship between data dimensions.</p><p id="37ec" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now let’s take a look at a representation of the four dimensions at once :</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="099c" class="qf oa fq qc b bg qg qh l qi qj">plot(real_data, synthetic_data, kind="umap")</span></pre><figure class="ni nj nk nl nm nn nf ng paragraph-image"><div class="nf ng qm"><img src="../Images/7fd393890001712f5cdf5ec4d0a21d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*CU944oTXzGKPYnUdH62DUA.png"/></div></figure><p id="ea85" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this image is also clear that the two datasets are distinct from one another.</p><p id="d0e7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Information</strong></p><p id="9b9b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">A synthetic dataset should be as useful as the original dataset. Especially, it should be equivalently useful for prediction tasks, meaning it should capture complex relationships between features. Hence a comparison : TSTR vs TRTR, which mean “Train on Synthetic Test on Real” vs “Train on Real Test on Real”. What does it mean in practice ?</p><p id="aea3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For a given dataset, we take a given task, like predicting the next token or the next event, or predicting a column given the others. For this given task, we train a first model on the synthetic dataset, and a second model on the original dataset. We then evaluate these two models on a common test set, which is an extract of the original dataset. Our synthetic dataset is considered useful if the performance of the first model is close to the performance of the second model, <em class="pz">whatever the performance</em>. It would mean that it is possible to learn the same patterns in the synthetic dataset as in the original dataset, which is ultimately what we want (especially in the case of data augmentation).</p><p id="7ad0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Now for the code :</p><pre class="ni nj nk nl nm qb qc qd bp qe bb bk"><span id="d22f" class="qf oa fq qc b bg qg qh l qi qj">import pandas as pd <br/>from typing import Tuple<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestRegressor<br/><br/><br/>def tstr(<br/>  real_data: pd.DataFrame, <br/>  synthetic_data: pd.DataFrame, <br/>  target: str = None<br/>) -&gt; Tuple[float]:<br/>    <br/>    # if no target is specified, use the last column of the dataset<br/>    if target is None: <br/>        target = real_data.columns[-1]<br/>    <br/>    X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(<br/>        real_data.drop(target, axis=1), <br/>        real_data[target],<br/>        test_size=0.2<br/>    )<br/>    <br/>    X_synthetic, y_synthetic = synthetic_data.drop(target, axis=1), synthetic_data[target]<br/>    # create regressors (could have been classifiers)<br/>    reg_real = RandomForestRegressor()<br/>    reg_synthetic = RandomForestRegressor()<br/>    # train the models<br/>    reg_real.fit(X_real_train, y_real_train)<br/>    reg_synthetic.fit(X_synthetic, y_synthetic)<br/>    # evaluate <br/>    trtr_score = reg_real.score(X_real_test, y_real_test)<br/>    tstr_score = reg_synthetic.score(X_real_test, y_real_test)<br/><br/>    return trtr_score, tstr_score</span></pre><pre class="qk qb qc qd bp qe bb bk"><span id="4d39" class="qf oa fq qc b bg qg qh l qi qj">tstr(real_data, synthetic_data)<br/>&gt;&gt;&gt; (0.918261846477529, 0.5644428690930647)</span></pre><p id="0395" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">It appears clearly that a certain relationship was learnt by the “real” regressor, whereas the “synthetic” regressor failed to learn this relationship. This hints that the relationship was not faithfully reproduced in the synthetic dataset.</p><h1 id="990c" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Conclusion</h1><p id="79ec" class="pw-post-body-paragraph mj mk fq ml b go ov mn mo gr ow mq mr ms ox mu mv mw oy my mz na oz nc nd ne fj bk">Synthetic data quality evaluation does not rely on a single indicator, and one should combine metrics to get the whole idea. This article displays some indicators that can easily be built . I hope that this article gave you some useful hints on how to do it best in your use case !</p><p id="ebb8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Feel free to share and comment ✨</p></div></div></div></div>    
</body>
</html>