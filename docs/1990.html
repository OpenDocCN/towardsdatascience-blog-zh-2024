<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Powering Experiments with CUPED and Double Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Powering Experiments with CUPED and Double Machine Learning</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/powering-experiments-with-cuped-and-double-machine-learning-34dc2f3d3284?source=collection_archive---------2-----------------------#2024-08-15">https://towardsdatascience.com/powering-experiments-with-cuped-and-double-machine-learning-34dc2f3d3284?source=collection_archive---------2-----------------------#2024-08-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a798" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Causal AI, exploring the integration of causal reasoning into machine learning</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@raz1470?source=post_page---byline--34dc2f3d3284--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ryan O'Sullivan" class="l ep by dd de cx" src="../Images/7cd161d38d67d2c0b7da2d8f3e7d33fe.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*tAw1S072P0f0sUswKPN6VQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--34dc2f3d3284--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@raz1470?source=post_page---byline--34dc2f3d3284--------------------------------" rel="noopener follow">Ryan O'Sullivan</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--34dc2f3d3284--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">17 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/9853e8cbe533bacb89e3bddd32cb8708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0iCcfXmx4OVfS97r"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@karsten_wuerth?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Karsten Würth</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="48f4" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">What is this series of articles about?</h1><p id="4536" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Welcome to my series on Causal AI, where we will explore the integration of causal reasoning into machine learning models. Expect to explore a number of practical applications across different business contexts.</p><p id="39dc" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">In the last article we covered <em class="pa">safeguarding demand forecasting with causal graphs</em>. Today, we turn our attention to powering experiments using CUPED and double machine learning.</p><p id="a128" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">If you missed the last article on safeguarding demand forecasting, check it out here:</p><div class="pb pc pd pe pf pg"><a rel="noopener follow" target="_blank" href="/safeguarding-demand-forecasting-with-causal-graphs-591511fc8e0e?source=post_page-----34dc2f3d3284--------------------------------"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">Safeguarding Demand Forecasting with Causal Graphs</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Causal AI, exploring the integration of causal reasoning into machine learning</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">towardsdatascience.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu lr pg"/></div></div></a></div><h1 id="3501" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Introduction</h1><p id="6f31" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">In this article, we evaluate whether CUPED and double machine learning can enhance the effectiveness of your experiments. We will use a case study to explore the following areas:</p><ul class=""><li id="75f0" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">The building blocks of experimentation: Hypothesis testing, power analysis, bootstrapping.</li><li id="cde7" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">What is CUPED and how can it help power experiments?</li><li id="2a16" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">What are the conceptual similarities between CUPED and double machine learning?</li><li id="bea6" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">When should we use double machine learning rather than CUPED?</li></ul><p id="dccf" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The full notebook can be found here:</p><div class="pb pc pd pe pf pg"><a href="https://github.com/raz1470/causal_ai/blob/main/notebooks/powering%20your%20experiments%20-%20cuped.ipynb?source=post_page-----34dc2f3d3284--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">causal_ai/notebooks/powering your experiments - cuped.ipynb at main · raz1470/causal_ai</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">This project introduces Causal AI and how it can drive business value. - causal_ai/notebooks/powering your experiments…</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">github.com</p></div></div><div class="pp l"><div class="qd l pr ps pt pp pu lr pg"/></div></div></a></div><h1 id="7780" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Case study</h1><h2 id="03fc" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Background</h2><p id="bede" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">You’ve recently joined the experimentation team at a leading online retailer known for its vast product catalog and dynamic user base. The data science team has deployed an advanced recommender system designed to enhance user experience and drive sales. This system integrates in real-time with the retailer’s platform and involves significant infrastructure and engineering costs.</p><p id="6830" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The finance team is eager to understand the system’s financial impact, specifically how much additional revenue it generates compared to a baseline scenario without recommendations. To evaluate the recommender system’s effectiveness, you plan to conduct a randomized controlled experiment.</p><h2 id="aa0b" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Data-generating process: Pre-experiment</h2><p id="6092" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We start by creating some pre-experiment data. The data-generating process we use has the following characteristics:</p><ul class=""><li id="2289" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">3 observed covariates related to the recency (x_recency), frequency (x_frequency) and value (x_value) of previous sales.</li><li id="648c" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">1 unobserved covariate, the users monthly income (u_income).</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qv"><img src="../Images/bac77761d4e1524256fb74b839f98e5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*VedRF53gJHSnfL-9qAHniw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><ul class=""><li id="1b74" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">A complex relationship between covariates is used to estimate our target metric, sales value:</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qw"><img src="../Images/34a926a337c172ee066ca3cd38c4ce74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaKOT2P2nlgWQnXdb48StA.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="c007" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The python code below is used to create the pre-experiment data:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="e50d" class="rb ne fq qy b bg rc rd l re rf">np.random.seed(123)<br/><br/>n = 10000 # Set number of observations<br/>p = 4 # Set number of pre-experiment covariates<br/><br/># Create pre-experiment covariates<br/>X = np.random.uniform(size=n * p).reshape((n, -1))<br/><br/># Nuisance parameters<br/>b = (<br/>    1.5 * X[:, 0] +<br/>    2.5 * X[:, 1] +<br/>    X[:, 2] ** 3 +     <br/>    X[:, 3] ** 2 +<br/>    X[:, 1] * X[:, 2]  <br/>)<br/><br/># Create some noise<br/>noise = np.random.normal(size=n)<br/><br/># Calculate outcome<br/>y = np.maximum(b + noise, 0)<br/><br/># Scale variables for interpretation<br/>df_pre = pd.DataFrame({"noise": noise * 1000,<br/>                   "u_income": X[:, 0] * 1000,                   <br/>                   "x_recency": X[:, 1] * 1000,<br/>                   "x_frequency": X[:, 2] * 1000,<br/>                   "x_value": X[:, 3] * 1000,<br/>                   "y_value": y * 1000     <br/>})<br/><br/># Visualise target metric<br/>sns.histplot(df_pre['y_value'], bins=30, kde=False)<br/>plt.xlabel('Sales Value')<br/>plt.ylabel('Frequency')<br/>plt.title('Sales Value')<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rg"><img src="../Images/69b2bc0d3c5278b6ed231416969a3a30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*dBv2aQgUebLXbs4TxRPuMA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h1 id="84aa" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">The building blocks of experimentation: Hypothesis testing, power analysis, bootstrapping</h1><p id="53be" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Before we get onto CUPED, I thought it would be worthwhile covering some foundational knowledge on experimentation.</p><h2 id="b340" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Hypothesis testing</h2><p id="2ee3" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Hypothesis testing helps determine if observed differences in an experiment are statistically significant or just random noise. In our experiment, we divide users into two groups:</p><ul class=""><li id="6666" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Control Group</strong>: Receives no recommendations.</li><li id="bbad" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Treatment Group</strong>: Receives personalised recommendations from the system.</li></ul><p id="ffd7" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We define our hypotheses as follows:</p><ul class=""><li id="7611" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Null Hypothesis (H₀)</strong>: The recommender system does not affect revenue. Any observed differences are due to chance.</li><li id="82d6" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Alternative Hypothesis (Hₐ)</strong>: The recommender system increases revenue. Users receiving recommendations generate significantly more revenue compared to those who do not.</li></ul><p id="7d36" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">To assess the hypotheses you will be comparing the mean revenue in the control and treatment group. However, there are a few things to be aware of:</p><ul class=""><li id="0883" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Type I error (False positive)</strong>: If the experiment concludes that the recommender system significantly increases revenue when in reality, it has no effect.</li><li id="b4d3" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Type II error (Beta, False negative)</strong>: If the experiment finds no significant increase in revenue from the recommender system when in reality, it does lead to a meaningful increase</li><li id="0f14" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Significance Level (Alpha)</strong>: If you set the significance level to 0.05, you are accepting a 5% chance of incorrectly concluding that the recommender system improves revenue when it does not (false positive).</li><li id="1230" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Power (1 — Beta)</strong>: Achieving a power of 0.80 means you have an 80% chance of detecting a significant increase in revenue due to the recommender system if it truly has an effect. A higher power reduces the risk of false negatives.</li></ul><p id="aabc" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">As you start to think about designing the experiment, you set some initial goals:</p><ol class=""><li id="bf80" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou rh pw px bk"><strong class="ob fr">You want to reliably detect the effect </strong>— Making sure you balance the risks of detecting a non-existent effect vs the risk of not detecting a real effect.</li><li id="70ab" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk"><strong class="ob fr">As quickly as possible</strong> — Finance are on your case!</li><li id="ae21" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk"><strong class="ob fr">Keeping the sample size as cost efficient as possible </strong>— The business case from the data science team suggests the system is going to drive a large increase in revenue so they don’t want the control group being too big.</li></ol><p id="978a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">But how can you meet these goals? Let’s delve into power analysis next!</p><h2 id="eaae" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Power analysis</h2><p id="4371" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">When we talk about powering experiments, we are usually referring to the process of determining the minimum sample size needed to detect an effect of a certain size with a given confidence. There are 3 components to power analysis:</p><ul class=""><li id="0446" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Effect size </strong>— The difference between the mean value of H₀ and Hₐ. We generally need to make sensible assumptions around this based on understanding what matters to the business/industry we are operating within.</li><li id="c77e" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Significance level </strong>— The probability of incorrectly concluding there is an effect when there isn’t, typically set at 0.05.</li><li id="56b9" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Power </strong>— The probability of correctly detecting an effect when there is one, typically set at 0.80.</li></ul><p id="5a2e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">I found the intuition behind these quite hard to grasp at first, but visualising it can really help. So lets give it a try! The key areas are where H₀ and Hₐ crossover — See if you it helps you tie together the components discussed above…</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ri"><img src="../Images/01eaf60212908ac7aab73804366e2e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNiethwoR1S4KsI2iEtlRQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="a9fc" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">A larger sample size leads to a smaller <strong class="ob fr">standard error</strong>. With a smaller standard error, the sampling distributions of H₀ and Hₐ become narrower and less overlapping. This decreased overlap makes it easier to detect a difference, leading to higher power.</p><p id="ddf0" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The function below shows how we can use the statsmodels python package to carry out a power analysis:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="1a79" class="rb ne fq qy b bg rc rd l re rf">from typing import Union<br/>import pandas as pd<br/>import numpy as np<br/>import statsmodels.stats.power as smp<br/><br/>def power_analysis(metric: Union[np.ndarray, pd.Series], exp_perc_change: float, alpha: float = 0.05, power: float = 0.80) -&gt; int:<br/>    '''<br/>    Perform a power analysis to determine the minimum sample size required for a given metric.<br/><br/>    Args:<br/>        metric (np.ndarray or pd.Series): Array or Series containing the metric values for the control group.<br/>        exp_perc_change (float): The expected percentage change in the metric for the test group.<br/>        alpha (float, optional): The significance level for the test. Defaults to 0.05.<br/>        power (float, optional): The desired power of the test. Defaults to 0.80.<br/><br/>    Returns:<br/>        int: The minimum sample size required for each group to detect the expected percentage change with the specified power and significance level.<br/><br/>    Raises:<br/>        ValueError: If `metric` is not a NumPy array or pandas Series.<br/>    '''<br/>    <br/>    # Validate input types<br/>    if not isinstance(metric, (np.ndarray, pd.Series)):<br/>        raise ValueError("metric should be a NumPy array or pandas Series.")<br/>    <br/>    # Calculate statistics<br/>    control_mean = metric.mean()<br/>    control_std = np.std(metric, ddof=1) # Use ddof=1 for sample standard deviation<br/>    test_mean = control_mean * (1 + exp_perc_change)<br/>    test_std = control_std # Assume the test group has the same standard deviation as the control group<br/>    <br/>    # Calculate (Cohen's D) effect size<br/>    mean_diff = control_mean - test_mean<br/>    pooled_std = np.sqrt((control_std**2 + test_std**2) / 2)<br/>    effect_size = abs(mean_diff / pooled_std)  # Cohen's d should be positive<br/>    <br/>    # Run power analysis<br/>    power_analysis = smp.TTestIndPower()<br/>    sample_size = round(power_analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power))<br/>    <br/>    print(f"Control mean: {round(control_mean, 3)}")<br/>    print(f"Control std: {round(control_std, 3)}")<br/>    print(f"Min sample size: {sample_size}")<br/>    <br/>    return sample_size</span></pre><p id="afc3" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">So let’s test it out with our pre-experiment data!</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="9955" class="rb ne fq qy b bg rc rd l re rf">exp_perc_change = 0.05 # Set the expected percentage change in the chosen metric caused by the treatment<br/><br/>min_sample_size = power_analysis(df_pre["y_value"], exp_perc_change</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rj"><img src="../Images/e766581806e322906648a66eb2e665bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*UKMZ7LaiQeBnRC8lyT41eA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="d99a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We can see that given the distribution of our target metric, we would need a sample size of 1,645 to detect an increase of 5%.</p><h2 id="e4be" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Data-generating process: Experimental data</h2><p id="7524" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Rather than rush into setting up the experiment, you decide to take the pre-experiment data and simulate the experiment.</p><p id="5363" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The following function randomly selects users to be treated and applies a treatment effect. At the end of the function we record the mean difference before and after the treatment was applied as well as the true ATE (average treatment effect):</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="fdcd" class="rb ne fq qy b bg rc rd l re rf">def exp_data_generator(t_perc_change, t_samples):<br/><br/>    # Create copy of pre-experiment data ready to manipulate into experiment data<br/>    df_exp = df_pre.reset_index(drop=True)<br/><br/>    # Calculate the initial treatment effect<br/>    treatment_effect = round((df_exp["y_value"] * (t_perc_change)).mean(), 2)<br/><br/>    # Create treatment column<br/>    treated_indices = np.random.choice(df_exp.index, size=t_samples, replace=False)<br/>    df_exp["treatment"] = 0<br/>    df_exp.loc[treated_indices, "treatment"] = 1<br/><br/>    # treatment effect<br/>    df_exp["treatment_effect"] = 0<br/>    df_exp.loc[df_exp["treatment"] == 1, "treatment_effect"] = treatment_effect<br/><br/>    # Apply treatment effect<br/>    df_exp["y_value_exp"] = df_exp["y_value"] <br/>    df_exp.loc[df_exp["treatment"] == 1, "y_value_exp"] = df_exp["y_value"] + df_exp["treatment_effect"]<br/><br/>    # Calculate mean diff before treatment<br/>    mean_t0_pre = df_exp[df_exp["treatment"] == 0]["y_value"].mean()<br/>    mean_t1_pre = df_exp[df_exp["treatment"] == 1]["y_value"].mean()<br/>    mean_diff_pre  = round(mean_t1_pre  - mean_t0_pre)<br/><br/>    # Calculate mean diff after treatment<br/>    mean_t0_post = df_exp[df_exp["treatment"] == 0]["y_value_exp"].mean()<br/>    mean_t1_post = df_exp[df_exp["treatment"] == 1]["y_value_exp"].mean()<br/>    mean_diff_post  = round(mean_t1_post  - mean_t0_post)<br/><br/>    # Calculate ate<br/>    treatment_effect = round(df_exp[df_exp["treatment"]==1]["treatment_effect"].mean())<br/><br/>    print(f"Diff-in-means before treatment: {mean_diff_pre}")<br/>    print(f"Diff-in-means after treatment: {mean_diff_post}")<br/>    print(f"ATE: {treatment_effect}")<br/>    <br/>    return df_exp</span></pre><p id="fda2" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We can feed through the minimum sample size we previously calculated:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="ddf3" class="rb ne fq qy b bg rc rd l re rf">np.random.seed(123)<br/>df_exp_1 = exp_data_generator(exp_perc_change, min_sample_size)</span></pre><p id="b302" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Let’s start by inspecting the data we created for treated users to help you understand what the function is doing:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rk"><img src="../Images/d5448f96a7709846f3ac08aad74204b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGp4_V_Ey1fvRDELTZc6kg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="e3c3" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Next let’s take a look at the results which the function prints:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rl"><img src="../Images/e68cb71f6cabe6971c08e46b1d947b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*lawV0adE0CM_Mef3FwjWrg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="e7eb" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Interesting, we see that after we select users to be treated, but before we treat them, there is already a difference in means. This difference is due to chance. This means that when we look at the difference after users are treated we don’t correctly estimate the ATE (average treatment effect). We will come back to this point when we cover CUPED.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rm"><img src="../Images/874eed4c5f7388d5a8c7717f0613b3bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12asjntHMMXGhpXQLy3b_w.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="cc63" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Next let’s explore a more sophisticated way of making an inference than just taking the difference in means…</p><h2 id="a71e" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Bootstrapping</h2><p id="1bb7" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Bootstrapping is a powerful statistical technique that involves resampling data with replacement. These resampled datasets, called bootstrap samples, help us estimate the variability of a statistic (like the mean or median) from our original data. This is particularly attractive when it comes to experimentation as it enables us to calculate confidence intervals. Let’s walk through it step by step using a simple example…</p><p id="8e17" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">You have run an experiment with a control and treatment group each made up of 1k users.</p><ol class=""><li id="6dba" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou rh pw px bk">Create bootstrap samples — Randomly select (with replacement) 1k users from the control and then treatment group. This gives us 1 bootstrap sample for control and one for treatment.</li><li id="5bda" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk">Repeat this process n times (e.g. 10k times).</li><li id="4329" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk">For each pair of bootstrap samples calculate the mean difference between control and treatment.</li><li id="9264" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk">We now have a distribution (made up of the mean difference between 10k bootstrap samples) which we can use to calculate confidence intervals.</li></ol><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rn"><img src="../Images/3346768ff5436682708eccc93ac03db7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sLEcRU8lQuPZOfQ84uTbPw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="c116" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Applying it to our case study</h2><p id="235c" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s use our case study to illustrate how it works. Below we use the sciPy stats python package to help calculate bootstrap confidence intervals:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="f5bf" class="rb ne fq qy b bg rc rd l re rf">from typing import Union<br/>import pandas as pd<br/>import numpy as np<br/>from scipy import stats<br/><br/>def mean_diff(group_a: Union[np.ndarray, pd.Series], group_b: Union[np.ndarray, pd.Series]) -&gt; float:<br/>    '''<br/>    Calculate the difference in means between two groups.<br/><br/>    Args:<br/>        group_a (Union[np.ndarray, pd.Series]): The first group of data points.<br/>        group_b (Union[np.ndarray, pd.Series]): The second group of data points.<br/><br/>    Returns:<br/>        float: The difference between the mean of group_a and the mean of group_b.<br/>    '''<br/>    return np.mean(group_a) - np.mean(group_b)<br/><br/>def bootstrapping(df: pd.DataFrame, adjusted_metric: str, n_resamples: int = 10000) -&gt; np.ndarray:<br/>    '''<br/>    Perform bootstrap resampling on the adjusted metric of two groups in the dataframe to estimate the mean difference and confidence intervals.<br/><br/>    Args:<br/>        df (pd.DataFrame): The dataframe containing the data. Must include a 'treatment' column indicating group membership.<br/>        adjusted_metric (str): The name of the column in the dataframe representing the metric to be resampled.<br/>        n_resamples (int, optional): The number of bootstrap resamples to perform. Defaults to 1000.<br/><br/>    Returns:<br/>        np.ndarray: The array of bootstrap resampled mean differences.<br/>    '''<br/>    <br/>    # Separate the data into two groups based on the 'treatment' column<br/>    group_a = df[df["treatment"] == 1][adjusted_metric]<br/>    group_b = df[df["treatment"] == 0][adjusted_metric]<br/><br/>    # Perform bootstrap resampling<br/>    res = stats.bootstrap((group_a, group_b), statistic=mean_diff, n_resamples=n_resamples, method='percentile')<br/>    ci = res.confidence_interval<br/>    <br/>    # Extract the bootstrap distribution and confidence intervals<br/>    bootstrap_means = res.bootstrap_distribution<br/>    bootstrap_ci_lb = round(ci.low,)<br/>    bootstrap_ci_ub = round(ci.high)    <br/>    bootstrap_mean = round(np.mean(bootstrap_means))<br/><br/>    print(f"Bootstrap confidence interval lower bound: {bootstrap_ci_lb}")<br/>    print(f"Bootstrap confidence interval upper bound: {bootstrap_ci_ub}")    <br/>    print(f"Bootstrap mean diff: {bootstrap_mean}")<br/>    <br/>    return bootstrap_means</span></pre><p id="139d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">When we run it for our case study data we can see that we now have some confidence intervals:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="0b04" class="rb ne fq qy b bg rc rd l re rf">bootstrap_og_1 = bootstrapping(df_exp_1, "y_value_exp")</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ro"><img src="../Images/95dea5cf92e093d0a197aec611dafefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*OqEucAFjQuBtbKqZHOKsng.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="98ae" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Our ground truth ATE is 143 (the actual treatment effect from our experiment data generator function), which falls within our confidence intervals. However, it’s worth noting that the mean difference hasn’t changed (it’s still 93 as before when we simply calculated the mean difference of control and treatment), and the pre-treatment difference is still there.</p><p id="bff1" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">So what if we wanted to come up with narrower confidence intervals? And is there any way we can deal with the pre-treatment differences? This leads us nicely into CUPED…</p><h1 id="c3d4" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">What is CUPED and how can it help power experiments?</h1><h2 id="4317" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Background</h2><p id="d93a" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">CUPED (controlled experiments using pre-experiment data) is a powerful technique for improving the accuracy of experiments developed by researchers at Microsoft. The original paper is an insightful read for anyone interested in experimentation:</p><p id="9438" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><a class="af nc" href="https://ai.stanford.edu/~ronnyk/2009controlledExperimentsOnTheWebSurvey.pdf" rel="noopener ugc nofollow" target="_blank">https://ai.stanford.edu/~ronnyk/2009controlledExperimentsOnTheWebSurvey.pdf</a></p><p id="3d60" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The core idea of CUPED is to use data collected before your experiment begins to reduce the variance in your target metric. By doing so, you can make your experiment more sensitive, which has two major benefits:</p><ol class=""><li id="fe57" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou rh pw px bk">You can detect smaller effects with the same sample size.</li><li id="b8e9" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou rh pw px bk">You can detect the same effect with a smaller sample size.</li></ol><p id="295a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Think of it like removing the “background noise” so you can see the “signal” more clearly.</p><h2 id="0a68" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Variance, standard deviation, standard error</h2><p id="0c18" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">When you read about CUPED you may hear people talk about it reducing the variance, standard deviation or standard error. If you are anything like me, you might find yourself forgetting how these are related, so before we go any further let’s recap on this!</p><ul class=""><li id="e68e" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Variance</strong>: Variance measures the average squared deviation of each data point from the mean, reflecting the overall spread or dispersion within a dataset.</li><li id="c5cf" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Standard Deviation</strong>: Standard deviation is the square root of variance, representing the average distance of each data point from the mean, and providing a more interpretable measure of spread.</li><li id="acfe" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk"><strong class="ob fr">Standard Error</strong>: Standard error quantifies the precision of the sample mean as an estimate of the population mean, calculated as the standard deviation divided by the square root of the sample size.</li></ul><h2 id="5185" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">How does CUPED work?</h2><p id="3f5f" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">To understand how CUPED works, let’s break it down…</p><p id="e4df" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Pre-experiment covariate</strong> — In the lightest implementation of CUPED, the pre-experiment covariate would be the target metric measured in a time period before the experiment. So if your target metric was sales value, your covariate could be each customers sales value 4 weeks prior to the experiment.</p><p id="2f8c" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It’s important that your covariate is correlated with your target metric and that it is unaffected by the treatment. This is why we would typically use pre-treatment data from the control group.</p><p id="cbe4" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Regression adjustment </strong>— Linear regression is used to model the relationship between the covariate (measured before the experiment) and the target metric (measured across the experiment period). We can then calculate the CUPED adjusted target metric by removing the influence of the covariate:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rp"><img src="../Images/ee1f5375c1228403ad307b357c55788c.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*tffJ5NEHF_-K2LWp_xlCUg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="8333" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">It is worth noting that taking away the mean of the covariate is done to centre the outcome variable around the mean to make it interpretable when compared to the original target metric.</p><p id="fdfe" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk"><strong class="ob fr">Variance reduction</strong> — After the regression adjustment the variance in our target metric has reduced. Lower variance means that the differences between the control and treatment group are easier to detect, thus increasing the statistical power of the experiment.</p><h2 id="68f0" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Applying it to our case study</h2><p id="3547" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s use our case study to illustrate how it works. Below we code CUPED up in a function:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="06d4" class="rb ne fq qy b bg rc rd l re rf">from typing import Union<br/>import pandas as pd<br/>import numpy as np<br/>import statsmodels.api as sm<br/><br/>def cuped(df: pd.DataFrame, pre_covariates: Union[str, list], target_metric: str) -&gt; pd.Series:<br/>    '''<br/>    Implements the CUPED (Controlled Experiments Using Pre-Experiment Data) technique to adjust the target metric <br/>    by removing predictable variation using pre-experiment covariates. This reduces the variance of the metric and <br/>    increases the statistical power of the experiment.<br/><br/>    Args:<br/>        df (pd.DataFrame): The input DataFrame containing both the pre-experiment covariates and the target metric. <br/>        pre_covariates (Union[str, list]): The column name(s) in the DataFrame corresponding to the pre-experiment covariates used for the adjustment. <br/>        target_metric (str): The column name in the DataFrame representing the metric to be adjusted.<br/><br/>    Returns:<br/>        pd.Series: A pandas Series containing the CUPED-adjusted target metric.<br/>    '''<br/>    <br/>    # Fit control model using pre-experiment covariates<br/>    control_group = df[df['treatment'] == 0]<br/>    X_control = control_group[pre_covariates]<br/>    X_control = sm.add_constant(X_control)<br/>    y_control = control_group[target_metric]<br/>    model_control = sm.OLS(y_control, X_control).fit()<br/><br/>    # Compute residuals and adjust target metric<br/>    X_all = df[pre_covariates]<br/>    X_all = sm.add_constant(X_all)<br/>    residuals = df[target_metric].to_numpy().flatten() - model_control.predict(X_all)<br/>    adjustment_term = model_control.params['const'] + sum(model_control.params[covariate] * df[pre_covariates].mean()[covariate] for covariate in pre_covariates)<br/>    adjusted_target = residuals + adjustment_term<br/>    <br/>    return adjusted_target</span></pre><p id="4b27" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">When we apply it to our case study data and compare the adjusted target metric to the original target metric, we see that the variance has reduced:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="dc7f" class="rb ne fq qy b bg rc rd l re rf"># Apply CUPED<br/>pre_covariates = ["x_recency", "x_frequency", "x_value"]<br/>target_metric = ["y_value_exp"]<br/>df_exp_1["adjusted_target"] = cuped(df_exp_1, pre_covariates, target_metric)<br/><br/># Plot results<br/>plt.figure(figsize=(10, 6))<br/>sns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x="adjusted_target", hue="treatment", fill=True, palette="Set1", label="Adjusted Value")<br/>sns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x="y_value_exp", hue="treatment", fill=True, palette="Set2", label="Original Value")<br/>plt.title(f"Distribution of Value by Original vs CUPED")<br/>plt.xlabel("Value")<br/>plt.ylabel("Density")<br/>plt.legend(title="Distribution")</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rm"><img src="../Images/979220e2d8fa0775cb942bf17a1d1505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4S7TxHBwGaT_hXF_6T8rlg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><h2 id="b813" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Does it reduce the standard error?</h2><p id="ece9" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Now we have applied CUPED and reduced the variance, lets run our bootstrapping function to see what impact it has:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="9003" class="rb ne fq qy b bg rc rd l re rf">bootstrap_cuped_1 = bootstrapping(df_exp_1, "adjusted_target")</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rq"><img src="../Images/7e4f9adbcabe4f1f983b968fa2ced17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*eF6AlRQIebcUNe8kpj-PDA.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="a60e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">If you compare this to our previous result using the original target metric you see that the confidence intervals are narrower:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="7124" class="rb ne fq qy b bg rc rd l re rf">bootstrap_1 = pd.DataFrame({<br/>    'original': bootstrap_og_1,<br/>    'cuped': bootstrap_cuped_1<br/>})<br/><br/># Plot the KDE plots<br/>plt.figure(figsize=(10, 6))<br/>sns.kdeplot(bootstrap_1['original'], fill=True, label='Original', color='blue')<br/>sns.kdeplot(bootstrap_1['cuped'], fill=True, label='CUPED', color='orange')<br/><br/># Add mean lines<br/>plt.axvline(bootstrap_1['original'].mean(), color='blue', linestyle='--', linewidth=1)<br/>plt.axvline(bootstrap_1['cuped'].mean(), color='orange', linestyle='--', linewidth=1)<br/>plt.axvline(round(df_exp_1[df_exp_1["treatment"]==1]["treatment_effect"].mean(), 3), color='green', linestyle='--', linewidth=1, label='Treatment effect')<br/><br/># Customize the plot<br/>plt.title('Distribution of Value by Original vs CUPED')<br/>plt.xlabel('Value')<br/>plt.ylabel('Density')<br/>plt.legend()<br/><br/># Show the plot<br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rr"><img src="../Images/2ca14804954a90f551baa3be1187c7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeQTWTLrED8fSUlpuXTDkg.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="a49e" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The bootstrap difference in means also moves closer to the ground truth treatment effect. This is because CUPED is also very effective at dealing with pre-existing differences between the control and treatment group.</p><h2 id="43f7" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Does it reduce the minimum sample size?</h2><p id="422e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The next question is does it reduce the minimum sample size we need. Well lets find out!</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="089f" class="rb ne fq qy b bg rc rd l re rf">treatment_effect_1 = round(df_exp_1[df_exp_1["treatment"]==1]["treatment_effect"].mean(), 2)<br/>cuped_sample_size = power_analysis(df_exp_1[df_exp_1['treatment'] == 0]['adjusted_target'], treatment_effect_1 / df_exp_1[df_exp_1['treatment'] == 0]['adjusted_target'].mean())</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk rs"><img src="../Images/5c4826146a3028c94472f710ed1844fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*rQArEtlp2cgLsd9V5qr4Rw.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="3a6c" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">The minimum sample size needed has reduced from 1,645 to 901. Both Finance and the Data Science team are going to be pleased as we can run the experiment for a shorter time period with a smaller control sample!</p><h1 id="23ea" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">What are the conceptual similarities between CUPED and double machine learning?</h1><h2 id="b7e5" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">Background</h2><p id="e884" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">When I first read about CUPED, I thought of double machine learning and the similarities. If you aren’t familiar with double machine learning, check out my article from earlier in the series:</p><div class="pb pc pd pe pf pg"><a rel="noopener follow" target="_blank" href="/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">De-biasing Treatment Effects with Double Machine Learning</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Causal AI, exploring the integration of causal reasoning into machine learning</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">towardsdatascience.com</p></div></div><div class="pp l"><div class="rt l pr ps pt pp pu lr pg"/></div></div></a></div><p id="ff9d" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Pay attention to the first stage outcome model in double machine learning:</p><ul class=""><li id="0700" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr"><em class="pa">Outcome model (de-noising):</em></strong> Machine learning model used to estimate the outcome using just the control features. The outcome model residuals are then calculated.</li></ul><p id="7c49" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">This is conceptually very similar to what we are doing with CUPED!</p><h2 id="be2d" class="qe ne fq bf nf qf qg qh ni qi qj qk nl oi ql qm qn om qo qp qq oq qr qs qt qu bk">How does it compare to CUPED?</h2><p id="92db" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Let’s feed through our case study data and see if we get a similar result:</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="21f8" class="rb ne fq qy b bg rc rd l re rf"># Train DML model<br/>dml = LinearDML(discrete_treatment=False)<br/>dml.fit(df_exp_1[target_metric].to_numpy().ravel(), T=df_exp_1['treatment'].to_numpy().ravel(), X=df_exp_1[pre_covariates], W=None)<br/>ate_dml = round(dml.ate(df_exp_1[pre_covariates]))<br/>ate_dml_lb = round(dml.ate_interval(df_exp_1[pre_covariates])[0])<br/>ate_dml_ub = round(dml.ate_interval(df_exp_1[pre_covariates])[1])<br/><br/>print(f'DML confidence interval lower bound: {ate_dml_lb}')<br/>print(f'DML confidence interval upper bound: {ate_dml_ub}')<br/>print(f'DML ate: {ate_dml}')</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk ru"><img src="../Images/edd156ca7a8178703d554a058002f2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*BwyqOLeKM9C2kz7moBhNbQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="a467" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">We get an almost identical result!</p><p id="ac82" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">When we plot the residuals we can see that the variance is reduced like in CUPED (although we don’t add the mean to scale for interpretation):</p><pre class="mm mn mo mp mq qx qy qz bp ra bb bk"><span id="f1ed" class="rb ne fq qy b bg rc rd l re rf"># Fit model outcome model using pre-experiment covariates<br/>X_all = df_exp_1[pre_covariates]<br/>X_all = sm.add_constant(X)<br/>y_all = df_exp_1[target_metric]<br/>outcome_model = sm.OLS(y_all, X_all).fit()<br/><br/># Compute residuals and adjust target metric<br/>df_exp_1['outcome_residuals'] = df_exp_1[target_metric].to_numpy().flatten() - outcome_model.predict(X_all)<br/><br/># Plot results<br/>plt.figure(figsize=(10, 6))<br/>sns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x="outcome_residuals", hue="treatment", fill=True, palette="Set1", label="Adjusted Target")<br/>sns.kdeplot(data=df_exp_1[df_exp_1['treatment'] == 0], x="y_value_exp", hue="treatment", fill=True, palette="Set2", label="Original  Value")<br/>plt.title(f"Distribution of Value by Original vs DML")<br/>plt.xlabel("Value")<br/>plt.ylabel("Density")<br/>plt.legend(title="Distribution")<br/><br/>plt.show()</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rm"><img src="../Images/895d86f01f26912525e039620b535abc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZY_i6qSKBP8o7hulFbbxQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">User generated image</figcaption></figure><p id="7989" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">“So what?” I hear you ask!</p><p id="dca6" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Firstly, I think it’s an interesting observation for anyone using double machine learning — The first stage outcome model help reduce the variance and therefore we should get similar benefits to CUPED.</p><p id="de82" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Secondly, it raises the question when is each method appropriate? Let’s close things off by covering off this question…</p><h1 id="8011" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">When should we use double machine learning rather than CUPED?</h1><p id="1ef1" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">There are several reasons why it may make sense to tend towards CUPED:</p><ul class=""><li id="b317" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">It’s easier to understand.</li><li id="c441" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">It’s simpler to implement.</li><li id="7141" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">It’s one model rather than three, meaning you have less challenges with overfitting.</li></ul><p id="1d8a" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">However, there are a couple of exceptions where double machine learning outperforms CUPED:</p><ul class=""><li id="4829" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Biased treatment assignment </strong>— When the treatment assignment is biased, for example when you are using observational data, double machine learning can deal with this. My article from earlier in the series builds on this:</li></ul><div class="pb pc pd pe pf pg"><a rel="noopener follow" target="_blank" href="/de-biasing-treatment-effects-with-double-machine-learning-63b16fcb3e97?source=post_page-----34dc2f3d3284--------------------------------"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">De-biasing Treatment Effects with Double Machine Learning</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Causal AI, exploring the integration of causal reasoning into machine learning</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">towardsdatascience.com</p></div></div><div class="pp l"><div class="rt l pr ps pt pp pu lr pg"/></div></div></a></div><ul class=""><li id="51d1" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk"><strong class="ob fr">Heterogenous treatment effects</strong> — When you want to understand effects at an individual level, for example finding out who it is worth sending discounts to, double machine learning can help with this. There is a good case study which illustrates this in my previous article on optimising treatment strategies:</li></ul><div class="pb pc pd pe pf pg"><a rel="noopener follow" target="_blank" href="/using-double-machine-learning-and-linear-programming-to-optimise-treatment-strategies-920c20a29553?source=post_page-----34dc2f3d3284--------------------------------"><div class="ph ab ig"><div class="pi ab co cb pj pk"><h2 class="bf fr hw z io pl iq ir pm it iv fp bk">Using Double Machine Learning and Linear Programming to optimise treatment strategies</h2><div class="pn l"><h3 class="bf b hw z io pl iq ir pm it iv dx">Causal AI, exploring the integration of causal reasoning into machine learning</h3></div><div class="po l"><p class="bf b dy z io pl iq ir pm it iv dx">towardsdatascience.com</p></div></div><div class="pp l"><div class="rv l pr ps pt pp pu lr pg"/></div></div></a></div><h1 id="3d14" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Final thoughts</h1><p id="3317" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Today we did a whistle stop tour of experimentation, covering hypothesis testing, power analysis and bootstrapping. We then explored how CUPED can reduce the standard error and increase the power of our experiments. Finally, we touched on it’s similarities to double machine learning and discussed when each method should be used. There are a few additional key points which are worth mentioning in terms CUPED:</p><ul class=""><li id="999e" class="nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou pv pw px bk">We don’t have to use linear regression — If we have multiple covariates, maybe some with non-linear relationships, we could use a machine learning technique like boosting.</li><li id="141b" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">If we do go down the route of using a machine learning technique, we need to make sure not to overfit the data.</li><li id="bfff" class="nz oa fq ob b go py od oe gr pz og oh oi qa ok ol om qb oo op oq qc os ot ou pv pw px bk">Some careful thought should go into when to run CUPED — Are you going to run it before you start your experiment and then run a power analysis to determine your reduced sample size? Or are you just going to run it after your experiment to reduce the standard error?</li></ul></div></div></div><div class="ab cb rw rx ry rz" role="separator"><span class="sa by bm sb sc sd"/><span class="sa by bm sb sc sd"/><span class="sa by bm sb sc"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="8832" class="pw-post-body-paragraph nz oa fq ob b go ov od oe gr ow og oh oi ox ok ol om oy oo op oq oz os ot ou fj bk">Follow me if you want to continue this journey into Causal AI – In the next article we will investigate whether multi-collinearity is harming your causal inferences in marketing mix modelling!</p></div></div></div></div>    
</body>
</html>