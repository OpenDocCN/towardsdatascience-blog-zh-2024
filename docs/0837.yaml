- en: Customizing Large Language Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/customizing-large-language-models-612bbe13bb20?source=collection_archive---------7-----------------------#2024-03-31](https://towardsdatascience.com/customizing-large-language-models-612bbe13bb20?source=collection_archive---------7-----------------------#2024-03-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/3dd1ba13bb74102bc6c8f9e9eb40c8a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (Ideogram)
  prefs: []
  type: TYPE_NORMAL
- en: Customize, run and save LLMs using OLLAMA and the Modelfile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@thomas_reid?source=post_page---byline--612bbe13bb20--------------------------------)[![Thomas
    Reid](../Images/c1b4e5f577272633ba07e5dbfd21c02d.png)](https://medium.com/@thomas_reid?source=post_page---byline--612bbe13bb20--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--612bbe13bb20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--612bbe13bb20--------------------------------)
    [Thomas Reid](https://medium.com/@thomas_reid?source=post_page---byline--612bbe13bb20--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--612bbe13bb20--------------------------------)
    ·11 min read·Mar 31, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’ll show you how to use the Modelfile in Ollama to change
    how an existing LLM (Llama2) behaves when interacting with it. I’ll also show
    you how to save your newly customized model to your personal namespace on the
    Ollama server.
  prefs: []
  type: TYPE_NORMAL
- en: I know it can get a bit confusing with all the different ”**llamas”** flyingaround.
    Just remember, Ollama is the company that enables you to download and locally
    run many different LLMs. Whereas, Llama2 is a particular LLM created by Meta the
    owner of Facebook. Apart from this relationship, they are not connected in any
    other way.
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve never heard of Ollama before I recommend that you check out my article
    below where I go into depth on what Ollama is and how to install it on your system.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://levelup.gitconnected.com/introduction-to-ollama-part-1-1156f9563b8d?source=post_page-----612bbe13bb20--------------------------------)
    [## Introduction to Ollama — Part 1'
  prefs: []
  type: TYPE_NORMAL
- en: Using Ollama to run LLM’s locally
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/introduction-to-ollama-part-1-1156f9563b8d?source=post_page-----612bbe13bb20--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: What is a modelfile?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Ollama, a `modelfile` refers to a configuration file that defines the blueprint
    to create and share models with Ollama.
  prefs: []
  type: TYPE_NORMAL
