- en: Tackle Complex LLM Decision-Making with Language Agent Tree Search (LATS) &
    GPT-4o
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26](https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Enhancing LLM decision-making: integrating language agent tree search with
    GPT-4o for superior problem-solving'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Ozgur
    Guler](../Images/0fa0f9412fddfff81c9004af33e277e8.png)](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    [Ozgur Guler](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    ·9 min read·Aug 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1af94ed3cff9126b91f6176f1e210758.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: midjourney — abstract puzzle'
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have demonstrated exceptional abilities in performing
    natural language tasks that involve complex reasoning. As a result, these models
    have evolved to function as agents capable of planning, strategising, and solving
    complex problems. However, challenges persist when it comes to making decisions
    under uncertainty, where outcomes are not deterministic, or when adaptive decision-making
    is required in changing environments, especially in multi-step scenarios where
    each step influences the next. We need more advanced capabilities…
  prefs: []
  type: TYPE_NORMAL
- en: This is where GPT-4’s advanced reasoning capabilities and Language Agent Tree
    Search (LATS) come together to address these challenges. LATS incorporates a dynamic,
    tree-based search methodology that enhances the reasoning capabilities of GPT-4O.
    By integrating Monte Carlo Tree Search (MCTS) with LLMs, LATS unifies reasoning,
    acting, and planning, creating a more deliberate and adaptive problem-solving
    framework. This powerful combination allows for improved decision-making and more
    robust handling of complex tasks, setting a new standard in the deployment of
    language models as autonomous agents.
  prefs: []
  type: TYPE_NORMAL
- en: Is “search” the missing piece in GenAI problem solving?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/2a16198d5a97e718d980dec57e08a408.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: midjourney — abstract puzzle'
  prefs: []
  type: TYPE_NORMAL
- en: Computational problem solving can be broadly defined as “***search through a
    combinatorial problem space***”, represented as a tree. [**Depth-First Search
    (DFS)**](https://en.wikipedia.org/wiki/Depth-first_search) and [**Breadth-First
    Search (BFS)**](https://en.wikipedia.org/wiki/Breadth-first_search) are fundamental
    methods for exploring such solution spaces. A notable example of the power of
    deep search is AlphaGo’s “[Move 37,”](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol)
    which showcased how innovative, human-surpassing solutions can emerge from extensive
    exploration.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional methods that follow **predefined paths**, LLMs can dynamically
    generate new branches within the solution space by predicting potential outcomes,
    strategies, or actions based on context. This capability allows LLMs to not only
    navigate but also expand the problem space, making them exceptionally powerful
    in situations where the problem structure is not fully known, is continuously
    evolving, or is highly complex.
  prefs: []
  type: TYPE_NORMAL
- en: Inference-time Reasoning with Meta Generation Algorithms (MGA)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/6678b242a08f9b2c8c2ea23a1627ce23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: midjourney — abstract puzzle'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling compute during training is widely recognised for its ability to improve
    model performance. **The benefits of scaling compute during inference remain under-explored.**
    MGA’s offer a novel approach by amplifying computational resources during inference…
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional token-level generation methods, meta-generation algorithms
    employ higher-order control structures such as planning, loops with multiple model
    calls, self-reflection, task decomposition, and dynamic conditioning. These mechanisms
    allow the model to execute tasks end-to-end, mimicking higher-level cognitive
    processes often referred to as Systems-2 thinking.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/398973dd49349edcc22c35cf5384dc0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: Inference-time Reasoning methods — summarised'
  prefs: []
  type: TYPE_NORMAL
- en: '**Therefore one-way meta generation algorithms may enhance LLM reasoning by
    integrating search into the generation process**. During inference, MGA’s dynamically
    explore a broader solution space, allowing the model to reason through potential
    outcomes and adapt strategies in real-time. By generating multiple paths and evaluating
    their viability, meta generation algorithms enable LLMs to simulate deeper, more
    complex reasoning akin to traditional search methods. This approach not only expands
    the model’s ability to generate novel insights but also improves decision-making
    in scenarios with incomplete or evolving information.'
  prefs: []
  type: TYPE_NORMAL
- en: Techniques like **Tree of Thoughts (ToT)**, and **Graph of Thought (GoT)** are
    employed to navigate combinatorial solution spaces efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '**ToT** (*2**) enables hierarchical decision-making by structuring potential
    outcomes as tree branches, facilitating exploration of multiple paths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GoT (***6****)**maps complex relationships between ideas, allowing the model
    to dynamically adjust and optimize its reasoning path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CoT** (*5**) provides step-by-step reasoning that links sequential thoughts,
    improving the coherence and depth of the generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is MCTS better ?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Tree of Thoughts (ToT) approach, traditional methods like Depth-First
    Search (DFS) or Breadth-First Search (BFS) can navigate this tree, but they are
    computationally expensive because they explore each possible path systematically
    & exhaustively.
  prefs: []
  type: TYPE_NORMAL
- en: Monte Carlo Tree Search (MCTS) is an improvement on this by simulating different
    outcomes for actions and updating the tree based on these simulations. It uses
    a “selection” process where it picks decision nodes using a strategy that balances
    exploration (trying new paths) and exploitation (choosing known good paths). This
    is guided by a formula called Upper Confidence Bound (UCB).
  prefs: []
  type: TYPE_NORMAL
- en: 'The UCB formula has two key parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploration Term:** This represents the potential reward of choosing a node
    and is calculated through simulations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Exploitation Term:** This decreases the deeper you go into a certain path,
    meaning that if a path is over-explored, the algorithm may shift to a less-explored
    path even if it seems less promising initially.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By selecting nodes using UCB, simulating outcomes (rewards) with LLMs, and back-propagating
    the rewards up the tree, MCTS effectively balances between exploring new strategies
    and exploiting known successful ones.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of the UCB formula is the **‘exploitation term,’** which decreases
    as you explore deeper into a specific path. This decrease may lead the selection
    algorithm to switch to another path in the decision tree, even if that path has
    a lower immediate reward, because the exploitation term remains higher when that
    path is less explored.
  prefs: []
  type: TYPE_NORMAL
- en: Node selection with UCB, reward calculations with LLM simulations and backpropagation
    are the essence of MCTS.
  prefs: []
  type: TYPE_NORMAL
- en: An Implementation — Financial Decision Making…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/3710dd691db8b2ce49c431938a9ad80f.png)'
  prefs: []
  type: TYPE_IMG
- en: LATS operation (1*) [https://arxiv.org/pdf/2310.04406](https://arxiv.org/pdf/2310.04406)
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of demonstration we will use LATS to solve the challenging problem
    of coming up with the optimal investment strategy in todays macroeconomic climate.
    We will feed LLM with the macro-economic statu susing the “IMF World Economic
    Outlook Report” as the context simply summarising the document. RAG is not used.
    Below is an example as to how LATS searches through the solution space…
  prefs: []
  type: TYPE_NORMAL
- en: 'Iteration 1:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Selection:** We start at the root node, and since this is the first LATS
    iteration, we will select all initial decision nodes generated by the LLM (A,
    B, and C nodes) and simulate their outcomes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Simulation & Backpropagation:** NextLLM “simulates” each strategy based on
    the context it has and assigns the following “rewards” — investment returns —
    to each “node”.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Strategy A**: $5,000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strategy B**: $7,000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strategy C**: $4,000'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3\. **Expansion:** Based on the selection, **Strategy B** has the highest UCB1
    value (since all nodes are at the same depth), so we expand only **Strategy B**
    by simulating its child nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dbce1fa357313bed6d2079283a726f17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: B node expanded as it has the higher simulated reward
    value'
  prefs: []
  type: TYPE_NORMAL
- en: 'Iteration 2:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Selection**: Since B1 & B2 strategies are not simulated, there is a tie in
    terms of their UCB scores and both nodes will be simulated.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Simulate Both Nodes**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Simulate B1**: LLM predicts a return of **$8,500** for **B1**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simulate B2**: LLM predicts a return of **$7,500** for **B2**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3\. **Backpropagation**:'
  prefs: []
  type: TYPE_NORMAL
- en: After each simulation, results of the simulation are back-propagated up the
    tree, updating the values of the parent nodes. This step ensures that the impact
    of the new information is reflected throughout the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '**Updating Strategy B’s Value**: **Strategy B** now needs to reflect the outcomes
    of **B1** and **B2**. One common approach is to average the rewards of **B1**
    and **B2** to update **Strategy B**’s value. Now, **Strategy B** has an updated
    value of **$8,000** based on the outcomes of its child nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc33d70a8576e8f639748eacc8d2360a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: Strategy B reward value is updated following backpropagation'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. **Recalculate UCB Scores:**
  prefs: []
  type: TYPE_NORMAL
- en: After backpropagation, the UCB scores **for all nodes in the tree** are recalculated.
    This recalculation uses the updated values (average rewards) and visit counts,
    ensuring that each node’s UCB1 score accurately reflects both its potential reward
    and how much it has been explored.
  prefs: []
  type: TYPE_NORMAL
- en: UCB(s) = (exploration/reward term)+ (exploitation term)
  prefs: []
  type: TYPE_NORMAL
- en: Note again the exploitation term decreases for all nodes on a path that is continously
    explored deeper.
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Next selection & simulation:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**B1** is selected for further expansion (as it has the higher reward) into
    child nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**B1a**: “Invest in AI companies”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B1b**: “Invest in green tech”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/da47d0a75d12cd098eebbf2a64845349.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: B1 node is expanded further as it has the higher reward'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. **Backpropagation:**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e80b6cb8ff2fcd14c6e1672b6db1165.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: Child node rewards are backpropagated upwards'
  prefs: []
  type: TYPE_NORMAL
- en: B1 reward updated as (9200 + 6800) / 2 = 8000
  prefs: []
  type: TYPE_NORMAL
- en: B reward updated as (8000 + 7500) / 2 = 7750
  prefs: []
  type: TYPE_NORMAL
- en: '**7.UCB Calculation:**'
  prefs: []
  type: TYPE_NORMAL
- en: Following backpropagation UCB values of all nodes are recalculated. Assume that
    due to the decaying exploration factor, **B2** now has a higher UCB score than
    both **B1a** and **B1b**. This could occur if **B1** has been extensively explored,
    reducing the exploration term for its children. Instead of continuing to expand
    **B1**’s children, the algorithm shifts back to explore **B2**, which has become
    more attractive due to its unexplored potential i.e. higher exploitation value.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1f27254ac66074364aa2ee0ff364b4c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: When a path through a node is explored deeper exploitation
    value of the node decreases which may trigger a branch switch — a new path through
    a new decision node to be explored further'
  prefs: []
  type: TYPE_NORMAL
- en: This example illustrates how MCTS can dynamically adjust its search path based
    on new information, ensuring that the algorithm remains efficient and focused
    on the most promising strategies as it progresses.
  prefs: []
  type: TYPE_NORMAL
- en: An Implementation with Azure OpenAI GPT-4o
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next we will build a “financial advisor” using GPT-4o, implementing LATS. (Please
    refer to the Github repo [here](https://github.com/ozgurgulerx/llm-reasoning-lats/tree/main)
    for the code.)
  prefs: []
  type: TYPE_NORMAL
- en: '*(For an accurate analysis I am using the* [*IMF World Economic Outlook report*](https://www.imf.org/en/Publications/WEO)
    *from July, 24 as my LLM context for simulations i.e. for generating child nodes
    and for assigning rewards to decision nodes …)*'
  prefs: []
  type: TYPE_NORMAL
- en: Here is how the code runs…
  prefs: []
  type: TYPE_NORMAL
- en: LATS iterating MCTS over the decision tree, creating new nodes and exploring
    the tree
  prefs: []
  type: TYPE_NORMAL
- en: The code leverages the `graphviz` library to visually represent the decision
    tree generated during the execution of the investment strategy simulations. Decision
    tree is too wide and cannot fit into a single picture hence I have added snippets
    as to how the tree looks below. You can find a sample decision tree in the github
    repo [here](https://github.com/ozgurgulerx/llm-reasoning-lats/blob/main/investment_decision_tree_with_optimal_path.pdf)…
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/be7c8818cadaa56d25b6e271fecc3611.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: Sample run of the MCTS code to find the best investment
    strategy in current macroeconomic climate'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b8b3f1f0093188458ab090f95a3b765d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by the author: Screen capture from the generated decision tree'
  prefs: []
  type: TYPE_NORMAL
- en: Below is the optimal strategy inferred by LATS…
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Conclusion:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By integrating LATS, we harness the reasoning capabilities of LLMs to simulate
    and evaluate potential strategies dynamically. This combination allows for the
    construction of decision trees that not only represent the logical progression
    of decisions but also adapt to changing contexts and insights, provided by the
    LLM through simulations and reflections.
  prefs: []
  type: TYPE_NORMAL
- en: (Unless otherwise noted, all images are by the author)
  prefs: []
  type: TYPE_NORMAL
- en: 'References:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*[1] Language Agent Tree Search: Unifying Reasoning, Acting, and Planning in
    Language Models* by Zhou et al'
  prefs: []
  type: TYPE_NORMAL
- en: '*[2] Tree of Thoughts: Deliberate Problem Solving with Large Language Models*
    by Yao et al'
  prefs: []
  type: TYPE_NORMAL
- en: '*[3] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning,
    and Tool Calling: A Survey* by Tula Masterman, Mason Sawtell, Sandi Besen, and
    Alex Chao'
  prefs: []
  type: TYPE_NORMAL
- en: '*[4] From Decoding to Meta-Generation: Inference-time Algorithms for Large
    Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson*, Hailey Schoelkopf*,
    Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.'
  prefs: []
  type: TYPE_NORMAL
- en: '*[5] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*
    by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,
    Ed H. Chi, Quoc V. Le, and Denny Zhou'
  prefs: []
  type: TYPE_NORMAL
- en: '*[7] Graph of Thoughts: Solving Elaborate Problems with Large Language Models*
    by Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michał Podstawski,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk,
    and Torsten Hoefler.'
  prefs: []
  type: TYPE_NORMAL
- en: '*[8] From Decoding to Meta-Generation: Inference-time Algorithms for Large
    Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf,
    Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.*'
  prefs: []
  type: TYPE_NORMAL
