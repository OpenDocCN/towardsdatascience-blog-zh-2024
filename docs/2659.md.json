["```py\n# Filename: main.py\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom transformers import pipeline\n\napp = FastAPI()\nclassifier = pipeline(\"sentiment-analysis\")\n\nclass TextInput(BaseModel):\n    text: str\n\nclass SentimentOutput(BaseModel):\n    text: str\n    sentiment: str\n    score: float\n\n@app.post(\"/predict\", response_model=SentimentOutput)\nasync def predict_sentiment(input_data: TextInput):\n    result = classifier(input_data.text)[0]\n    return SentimentOutput(\n        text=input_data.text,\n        sentiment=result[\"label\"],\n        score=result[\"score\"]\n    )\n```", "```py\n# Filename: requirements.txt\n# Note: This has all required packages for the final result. \n\nfastapi==0.68.1\nuvicorn==0.15.0\ntransformers==4.30.0\ntorch==2.0.0\npydantic==1.10.0\nnumpy==1.24.3\nsentencepiece==0.1.99\nprotobuf==3.20.3\nprometheus-client==0.17.1\n```", "```py\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"I love using FastAPI!\"}'\n```", "```py\n# Filename: Dockerfile\n\n# Use the official Python 3.9 slim image as the base\nFROM python:3.9-slim\n\n# Set the working directory inside the container to /app\nWORKDIR /app\n\n# Copy the requirements.txt file to the working directory\nCOPY requirements.txt .\n\n# Install the Python dependencies listed in requirements.txt\nRUN pip install -r requirements.txt\n\n# Copy the main application file (main.py) to the working directory\nCOPY main.py .\n\n# Define the command to run the FastAPI application with Uvicorn\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```", "```py\nyour-project/\n├── Dockerfile\n├── requirements.txt\n└── main.py\n```", "```py\n# Build the Docker image\ndocker build -t sentiment-api .\n\n# Run the container\ndocker run -p 8000:8000 sentiment-api\n```", "```py\ncurl -X POST \"http://localhost:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"I love using FastAPI!\"}'\n```", "```py\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom transformers import pipeline\nfrom prometheus_client import Counter, Histogram, start_http_server\nimport time\n\n# Start prometheus metrics server on port 8001\nstart_http_server(8001)\n\napp = FastAPI()\n\n# Metrics\nPREDICTION_TIME = Histogram('prediction_duration_seconds', 'Time spent processing prediction')\nREQUESTS = Counter('prediction_requests_total', 'Total requests')\nSENTIMENT_SCORE = Histogram('sentiment_score', 'Histogram of sentiment scores', buckets=[0.0, 0.25, 0.5, 0.75, 1.0])\n\nclass TextInput(BaseModel):\n    text: str\n\nclass SentimentOutput(BaseModel):\n    text: str\n    sentiment: str\n    score: float\n\n@app.post(\"/predict\", response_model=SentimentOutput)\nasync def predict_sentiment(input_data: TextInput):\n    REQUESTS.inc()\n    start_time = time.time()\n\n    result = classifier(input_data.text)[0]\n\n    score = result[\"score\"]\n    SENTIMENT_SCORE.observe(score)  # Record the sentiment score\n\n    PREDICTION_TIME.observe(time.time() - start_time)\n\n    return SentimentOutput(\n        text=input_data.text,\n        sentiment=result[\"label\"],\n        score=score\n    )\n```", "```py\n# Filename: train.py\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom torch.utils.data import DataLoader\n\ndef train_model():\n    # Load dataset\n    full_dataset = load_dataset(\"stanfordnlp/imdb\", split=\"train\")\n    dataset = full_dataset.shuffle(seed=42).select(range(10000))\n\n    model_name = \"distilbert-base-uncased\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n\n    # Use GPU if available\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    model.train()\n\n    # Create a DataLoader for batching\n    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n\n    # Training loop\n    num_epochs = 3  # Set the number of epochs\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for batch in dataloader:\n            inputs = tokenizer(batch[\"text\"], truncation=True, padding=True, return_tensors=\"pt\", max_length=512).to(device)\n            labels = torch.tensor(batch[\"label\"]).to(device)\n\n            optimizer.zero_grad()\n            outputs = model(**inputs, labels=labels)\n            loss = outputs.loss\n\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(dataloader)\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n\n    # Save the model\n    model.save_pretrained(\"./model/\")\n    tokenizer.save_pretrained(\"./model/\")\n\n    # Test the model with sample sentences\n    test_sentences = [\n        \"This movie was fantastic!\",\n        \"I absolutely hated this film.\",\n        \"It was just okay, not great.\",\n        \"An absolute masterpiece!\",\n        \"Waste of time!\",\n        \"A beautiful story and well acted.\",\n        \"Not my type of movie.\",\n        \"It could have been better.\",\n        \"A thrilling adventure from start to finish!\",\n        \"Very disappointing.\"\n    ]\n\n    # Switch model to evaluation mode\n    model.eval()\n\n    # Prepare tokenizer for test inputs\n    inputs = tokenizer(test_sentences, truncation=True, padding=True, return_tensors=\"pt\", max_length=512).to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predictions = torch.argmax(outputs.logits, dim=1)\n\n    # Print predictions\n    for sentence, prediction in zip(test_sentences, predictions):\n        sentiment = \"positive\" if prediction.item() == 1 else \"negative\"\n        print(f\"Input: \\\"{sentence}\\\" -> Predicted sentiment: {sentiment}\")\n\n# Call the function to train the model and test it\ntrain_model()\n```", "```py\n# Filename: main.py\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import pipeline\nfrom prometheus_client import Counter, Histogram, start_http_server\nimport time\n\n# Start prometheus metrics server on port 8001\nstart_http_server(8001)\n\napp = FastAPI()\n\n# Load the trained model and tokenizer from the local directory\nmodel_path = \"./model\"  # Path to your saved model\ntokenizer = AutoTokenizer.from_pretrained(model_path)\ntrained_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n# Create pipelines\nnaive_classifier = pipeline(\"sentiment-analysis\", device=-1)\ntrained_classifier = pipeline(\"sentiment-analysis\", model=trained_model, tokenizer=tokenizer, device=-1)\n\n# Metrics\nPREDICTION_TIME = Histogram('prediction_duration_seconds', 'Time spent processing prediction')\nREQUESTS = Counter('prediction_requests_total', 'Total requests')\nSENTIMENT_SCORE = Histogram('sentiment_score', 'Histogram of sentiment scores', buckets=[0.0, 0.25, 0.5, 0.75, 1.0])\n\nclass TextInput(BaseModel):\n    text: str\n\nclass SentimentOutput(BaseModel):\n    text: str\n    sentiment: str\n    score: float\n\n@app.post(\"/predict/naive\", response_model=SentimentOutput)\nasync def predict_naive_sentiment(input_data: TextInput):\n    REQUESTS.inc()\n    start_time = time.time()\n\n    result = naive_classifier(input_data.text)[0]\n\n    score = result[\"score\"]\n    SENTIMENT_SCORE.observe(score)  # Record the sentiment score\n\n    PREDICTION_TIME.observe(time.time() - start_time)\n\n    return SentimentOutput(\n        text=input_data.text,\n        sentiment=result[\"label\"],\n        score=score\n    )\n\n@app.post(\"/predict/trained\", response_model=SentimentOutput)\nasync def predict_trained_sentiment(input_data: TextInput):\n    REQUESTS.inc()\n    start_time = time.time()\n\n    result = trained_classifier(input_data.text)[0]\n\n    score = result[\"score\"]\n    SENTIMENT_SCORE.observe(score)  # Record the sentiment score\n```", "```py\n# Filename: Dockerfile\nFROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY main.py .\nCOPY ./model ./model\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```", "```py\n# Filename: test_model.py\n\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom main import app\n\nclient = TestClient(app)\n\ndef test_positive_sentiment():\n    response = client.post(\n        \"/predict/trained\",\n        json={\"text\": \"This is amazing!\"}\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"sentiment\"] == \"LABEL_1\"\n    assert data[\"score\"] > 0.5\n\ndef test_negative_sentiment():\n    response = client.post(\n        \"/predict/trained\",\n        json={\"text\": \"This is terrible!\"}\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"sentiment\"] == \"LABEL_0\"\n    assert data[\"score\"] < 0.5\n```", "```py\n# Filename: .github/workflows/ci_cd.yml\n\nname: CI/CD\n\non: [push]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v2\n        with:\n          lfs: true\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.9'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install pytest httpx\n\n      - name: Run tests\n        run: pytest\n```", "```py\nsentiment-analysis-project/\n├── .github/\n│   └── workflows/\n│       └── ci_cd.yml\n├── test_model.py\n├── main.py\n├── Dockerfile\n├── requirements.txt\n└── train.py\n```"]