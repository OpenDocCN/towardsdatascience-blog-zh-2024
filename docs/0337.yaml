- en: 'Encoding Categorical Variables: A Deep Dive into Target Encoding'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码分类变量：深入探讨目标编码
- en: 原文：[https://towardsdatascience.com/encoding-categorical-variables-a-deep-dive-into-target-encoding-2862217c2753?source=collection_archive---------2-----------------------#2024-02-05](https://towardsdatascience.com/encoding-categorical-variables-a-deep-dive-into-target-encoding-2862217c2753?source=collection_archive---------2-----------------------#2024-02-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/encoding-categorical-variables-a-deep-dive-into-target-encoding-2862217c2753?source=collection_archive---------2-----------------------#2024-02-05](https://towardsdatascience.com/encoding-categorical-variables-a-deep-dive-into-target-encoding-2862217c2753?source=collection_archive---------2-----------------------#2024-02-05)
- en: Data comes in different shapes and forms. One of those shapes and forms is known
    as categorical data.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据有不同的形态和形式，其中一种形式被称为分类数据。
- en: '[](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)[![Juan
    Jose Munoz](../Images/b42d72e9e2a2eaf11da5465e9b041d53.png)](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)
    [Juan Jose Munoz](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)[![Juan
    Jose Munoz](../Images/b42d72e9e2a2eaf11da5465e9b041d53.png)](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)
    [Juan Jose Munoz](https://medium.com/@juanjosemunozp?source=post_page---byline--2862217c2753--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)
    ·10 min read·Feb 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2862217c2753--------------------------------)
    ·10分钟阅读·2024年2月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**This poses a problem because most Machine Learning algorithms use only numerical
    data as input**. However, categorical data is usually not a challenge to deal
    with, thanks to simple, well-defined functions that transform them into numerical
    values. If you have taken any data science course, you will be familiar with the
    one hot encoding strategy for categorical features. This strategy is great when
    your features have limited categories. However, you will run into some issues
    when dealing with high cardinal features (features with many categories)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**这带来了一个问题，因为大多数机器学习算法仅使用数值数据作为输入**。然而，由于有一些简单且定义明确的函数将分类数据转换为数值，因此处理分类数据通常并不困难。如果你参加过任何数据科学课程，你一定会熟悉一热编码策略用于处理分类特征。当你的特征类别有限时，这个策略效果很好。然而，在处理高基数特征（类别众多的特征）时，你将会遇到一些问题。'
- en: '**Here is how you can use target encoding to transform Categorical features
    into numerical values.**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**下面是如何使用目标编码将分类特征转换为数值的方法。**'
- en: '![](../Images/f5faebf9812d3395ba1b4d55a6ddf0f3.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5faebf9812d3395ba1b4d55a6ddf0f3.png)'
- en: Photo by [Sonika Agarwal](https://unsplash.com/@sonika_agarwal?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Sonika Agarwal](https://unsplash.com/@sonika_agarwal?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The problem with One Hot encoding
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一热编码的问题
- en: '**Early in any data science course, you are introduced to one hot encoding
    as a key strategy to deal with categorical values**, and rightfully so, as this
    strategy works really well on low cardinal features (features with limited categories).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**在任何数据科学课程的早期，你都会接触到一热编码，它作为处理分类值的关键策略而被广泛使用**，这也很有道理，因为该策略在低基数特征（类别有限的特征）上效果非常好。'
- en: '**In a nutshell, One hot encoding transforms each category into a binary vector,**
    where the corresponding category is marked as ‘True’ or ‘1’, and all other categories
    are marked with ‘False’ or ‘0’.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**简而言之，一热编码将每个类别转换为一个二进制向量，** 其中相应的类别标记为‘True’或‘1’，其他所有类别标记为‘False’或‘0’。'
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/ba9c89d63e6cba7e5db81567deaf9b35.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba9c89d63e6cba7e5db81567deaf9b35.png)'
- en: One hot encoding output — we could improve this by dropping one column because
    if we know Blue and Green, we can figure the value of Red. Image by author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一热编码输出——我们可以通过去掉一列来改进这一点，因为如果我们知道了蓝色和绿色，就能推断出红色的值。图片由作者提供
- en: While this works great for features with limited categories *(Less than 10–20
    categories)*, as the number of categories increases, the one-hot encoded vectors
    become longer and sparser, potentially leading to increased memory usage and computational
    complexity, let’s look at an example.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法对于具有有限类别的特征*(少于 10 到 20 个类别)*效果很好，但随着类别数量的增加，独热编码的向量会变得更长、更稀疏，这可能导致内存使用增加和计算复杂度上升，我们来看一个例子。
- en: '*The below code uses Amazon Employee Access data, made publicity available
    in kaggle:* [*https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge*](https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*下面的代码使用了亚马逊员工访问数据，该数据在 Kaggle 上公开可用：* [*https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge*](https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge)'
- en: The data contains eight categorical feature columns indicating characteristics
    of the required resource, role, and workgroup of the employee at Amazon.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包含八个类别特征列，表示员工在亚马逊所需资源、角色和工作组的特征。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/5e6c072ac9109edba362fc86ca6496ee.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e6c072ac9109edba362fc86ca6496ee.png)'
- en: Column information. Image by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 列信息。图像来源：作者
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/3272325aaa9c9f09c59e5aa935a95c95.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3272325aaa9c9f09c59e5aa935a95c95.png)'
- en: The eight features have high cardinality. Image by author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这八个特征具有高基数。图像来源：作者
- en: '**Using one hot encoding could be challenging in a dataset like this due to
    the high number of distinct categories for each feature.**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**在像这样的数据集中使用独热编码可能会带来挑战，因为每个特征的不同类别数量非常高。**'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/c46013a222c086c67eca8bdf08167d6a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c46013a222c086c67eca8bdf08167d6a.png)'
- en: The initial dataset is 11.24 MB. Image by author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 初始数据集大小为 11.24 MB。图像来源：作者
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/c18fd40a3d00ecb79244ef3e78d51923.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c18fd40a3d00ecb79244ef3e78d51923.png)'
- en: After on-hot encoding, the dataset has 15 618 columns. Image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码后，数据集有 15,618 列。图像来源：作者
- en: '![](../Images/8d92598376535d840d3f52d59a26e239.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d92598376535d840d3f52d59a26e239.png)'
- en: The resulting data set is highly sparse, meaning it contains a lot of 0s and
    1\. Image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数据集非常稀疏，这意味着它包含了大量的 0 和 1。图像来源：作者
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/ca2ecf4f83515a06eae3394bcd8aa012.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca2ecf4f83515a06eae3394bcd8aa012.png)'
- en: Dataset memory usage increased to 488.08 MB due to the increased number of columns.
    Image by author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于列数增加，数据集的内存使用量增加到 488.08 MB。图像来源：作者
- en: As you can see, one-hot encoding is not a viable solution to deal with high
    cardinal categorical features, as it significantly increases the size of the dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，独热编码并不是处理高基数类别特征的可行解决方案，因为它显著增加了数据集的大小。
- en: '**In cases with high cardinal features, target encoding is a better option.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**在具有高基数特征的情况下，目标编码是更好的选择。**'
- en: Target encoding — overview of basic principle
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标编码 — 基本原理概述
- en: Target encoding transforms a categorical feature into a numeric feature without
    adding any extra columns, avoiding turning the dataset into a larger and sparser
    dataset.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码将一个类别特征转换为一个数值特征，而不会添加任何额外的列，避免将数据集转化为更大且稀疏的数据集。
- en: '**Target encoding works by converting each category of a categorical feature
    into its corresponding expected value.** The approach to calculating the expected
    value will depend on the value you are trying to predict.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标编码通过将每个类别特征转换为其相应的期望值来工作。** 计算期望值的方法将取决于你尝试预测的值。'
- en: For Regression problems, the expected value is simply the average value for
    that category.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于回归问题，期望值仅仅是该类别的平均值。
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For Classification problems, the expected value is the conditional probability
    given that category.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于分类问题，期望值是给定类别下的条件概率。
- en: In both cases, we can get the results by simply using the ‘group_by’ function
    in pandas.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们只需使用 pandas 中的 `group_by` 函数即可得到结果。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/492473834fd253f24f7d6a3fe7c7dcb6.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/492473834fd253f24f7d6a3fe7c7dcb6.png)'
- en: The resulting table indicates the probability of each `ACTION` outcome by unique
    `Role_title` ID. Image by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表格显示了每个 `ACTION` 结果按唯一 `Role_title` ID 的概率。图像来源：作者
- en: The resulting table indicates the probability of each “*ACTION”* outcome by
    unique “*ROLE_TITLE*” id. All that is left to do is replace the “*ROLE_TITLE*”
    id with the values from the probability of “ACTION” being 1 in the original dataset.
    *(i.e instead of category 117879 the dataset will show 0.889331)*
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表格显示了每个 “*ACTION*” 结果按唯一 “*ROLE_TITLE*” ID 的概率。剩下的工作是将 “*ROLE_TITLE*” ID 替换为原始数据集中“*ACTION*”为
    1 的概率值。*(即，代替类别 117879，数据集将显示 0.889331)*
- en: '**While this can give us an intuition of how target encoding works, using this
    simple method runs the risk of overfitting**. Especially for rare categories,
    as in those cases, target encoding will essentially provide the target value to
    the model. Also, the above method can only deal with seen categories, so if your
    test data has a new category, it won’t be able to handle it.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**虽然这能帮助我们直观理解目标编码的工作原理，但使用这个简单的方法存在过拟合的风险**。尤其是对于稀有类别，因为在这种情况下，目标编码基本上会将目标值直接传递给模型。此外，上述方法只能处理已见过的类别，因此如果你的测试数据中有新类别，它将无法处理。'
- en: '**To avoid those errors, you need to make the target encoding transformer more
    robust.**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**为了避免这些错误，你需要使目标编码转换器更加稳健。**'
- en: Defining a Target encoding class
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义目标编码类
- en: To make target encoding more robust, you can create a custom transformer class
    and integrate it with scikit-learn so that it can be used in any model pipeline.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使目标编码更加稳健，你可以创建一个自定义的转换器类，并将其与 scikit-learn 集成，这样就可以在任何模型管道中使用。
- en: '*NOTE: The below code is taken from the book “The Kaggle Book” and can be found
    in Kaggle:* [*https://www.kaggle.com/code/lucamassaron/meta-features-and-target-encoding*](https://www.kaggle.com/code/lucamassaron/meta-features-and-target-encoding)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：以下代码取自《Kaggle书籍》，可以在 Kaggle 中找到：* [*https://www.kaggle.com/code/lucamassaron/meta-features-and-target-encoding*](https://www.kaggle.com/code/lucamassaron/meta-features-and-target-encoding)'
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It might look daunting at first, but let’s break down each part of the code
    to understand how to create a robust Target encoder.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 刚开始可能看起来有些令人生畏，但我们可以逐步解析每一部分代码，以理解如何创建一个强大的目标编码器。
- en: Class Definition
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类定义
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This first step ensures that you can use this transformer class in scikit-learn
    pipelines for data preprocessing, feature engineering, and machine learning workflows.
    It achieves this by inheriting the scikit-learn classes *BaseEstimator* and *TransformerMixin*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这第一步确保你可以在 scikit-learn 管道中使用这个转换器类进行数据预处理、特征工程和机器学习工作流。它通过继承 scikit-learn 类
    *BaseEstimator* 和 *TransformerMixin* 来实现这一点。
- en: Inheritance allows the *TargetEncode* class to reuse or override methods and
    attributes defined in the base classes, in this case, *BaseEstimator* and *TransformerMixin*
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 继承使得 *TargetEncode* 类可以重用或覆盖基类中定义的方法和属性，在此情况下是 *BaseEstimator* 和 *TransformerMixin*。
- en: '*BaseEstimator* is a base class for all scikit-learn estimators. Estimators
    are objects in scikit-learn with a “fit” method for training on data and a “predict”
    method for making predictions.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*BaseEstimator* 是所有 scikit-learn 估计器的基类。估计器是 scikit-learn 中的对象，具有用于训练数据的“fit”方法和用于做出预测的“predict”方法。'
- en: '*TransformerMixin* is a mixin class for transformers in scikit-learn, it provides
    additional methods such as “fit_transform”, which combines fitting and transforming
    in a single step.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*TransformerMixin* 是 scikit-learn 中用于转换器的混入类，它提供了额外的方法，如“fit_transform”，该方法将拟合和转换合并为一个步骤。'
- en: '**Inheriting from *BaseEstimator* & *TransformerMixin,* allows TargetEncode
    to implement these methods, making it compatible with the scikit-learn API.**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**继承自 *BaseEstimator* 和 *TransformerMixin*，使得 TargetEncode 可以实现这些方法，从而与 scikit-learn
    API 兼容。**'
- en: Defining the constructor
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义构造函数
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This second step defines the constructor for the *“TargetEncode*” class and
    initializes the instance variables with default or user-specified values.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步定义了 *“TargetEncode*” 类的构造函数，并用默认值或用户指定的值初始化实例变量。
- en: The “*categories*” parameter determines which columns in the input data should
    be considered as categorical variables for target encoding. It is Set by default
    to ‘auto’ to automatically identify categorical columns during the fitting process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: “*categories*” 参数决定了输入数据中哪些列应该被视为目标编码的分类变量。默认为 'auto'，在拟合过程中自动识别分类列。
- en: The parameters k, f, and noise_level control the smoothing effect during target
    encoding and the level of noise added during transformation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 k、f 和 noise_level 控制目标编码过程中的平滑效果以及在转换过程中添加的噪声量。
- en: Adding noise
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加噪声
- en: '**This next step is very important to avoid overfitting**.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**下一步非常重要，以避免过拟合**。'
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The “*add_noise*” method adds random noise to introduce variability and prevent
    overfitting during the transformation phase.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: “*add_noise*”方法向数据中添加随机噪声，以引入变异性并在转换阶段防止过拟合。
- en: '*“np.random.randn(len(series))”* generates an array of random numbers from
    a standard normal distribution (mean = 0, standard deviation = 1).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*“np.random.randn(len(series))”* 从标准正态分布（均值为 0，标准差为 1）生成一个随机数数组。'
- en: Multiplying this array by “*noise_level” s*cales the random noise based on the
    specified noise level.”
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个数组乘以“*noise_level*” s 以根据指定的噪声级别调整随机噪声的规模。
- en: '**This step contributes to the robustness and generalization capabilities of
    the target encoding process.**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**这一步骤有助于增强目标编码过程的鲁棒性和泛化能力。**'
- en: Fitting the Target encoder
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合目标编码器
- en: This part of the code trains the target encoder on the provided data by calculating
    the target encodings for categorical columns and storing them for later use during
    transformation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分代码通过计算类别列的目标编码并将其存储起来，来训练目标编码器，以便在转换时使用。
- en: '[PRE11]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The smoothing term helps prevent overfitting, especially when dealing with categories
    with small samples.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑项有助于防止过拟合，尤其是在处理样本量小的类别时。
- en: '**The method follows the scikit-learn convention for fit methods in transformers.**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**该方法遵循 scikit-learn 中转换器拟合方法的约定。**'
- en: It starts by checking and identifying the categorical columns and creating a
    temporary DataFrame, containing only the selected categorical columns from the
    input X and the target variable y.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先检查并识别类别列，然后创建一个临时的 DataFrame，包含来自输入 X 的选择的类别列和目标变量 y。
- en: The prior mean of the target variable is calculated and stored in the prior
    attribute. **This represents the overall mean of the target variable across the
    entire dataset.**
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量的先验均值被计算并存储在 prior 属性中。**这代表了整个数据集上目标变量的总体均值。**
- en: '**Then, it calculates the mean and count of the target variable for each category
    using the group-by method, as seen previously.**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**然后，它使用 group-by 方法计算每个类别的目标变量的均值和计数，正如前面所见。**'
- en: There is an additional smoothing step to prevent overfitting on categories with
    small numbers of samples. Smoothing is calculated based on the number of samples
    in each category. The larger the count, the less the smoothing effect.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 还增加了一个平滑步骤，以防止在样本量小的类别上过拟合。平滑是基于每个类别中的样本数量计算的。样本量越大，平滑效应越小。
- en: The calculated encodings for each category in the current variable are stored
    in the encodings dictionary. This dictionary will be used later during the transformation
    phase.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当前变量中每个类别的计算编码被存储在编码字典中。这个字典将在转换阶段后续使用。
- en: Transforming the data
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换数据
- en: This part of the code replaces the original categorical values with their corresponding
    target-encoded values stored in *self.encodings.*
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分代码将原始的类别值替换为存储在*self.encodings*中的相应目标编码值。
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This step has an additional robustness check to ensure the target encoder can
    handle new or unseen categories. **For those new or unknown categories, it replaces
    them with the mean of the target variable** stored in the prior_mean variable.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤增加了一个鲁棒性检查，以确保目标编码器能够处理新的或未见过的类别。**对于这些新的或未知的类别，它将用目标变量的均值替代**，该均值存储在 prior_mean
    变量中。
- en: If you need more robustness against overfitting, you can set up a *noise_level*
    greater than 0 to add random noise to the encoded values.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要更强的抗过拟合能力，可以设置一个大于 0 的*noise_level*，向编码值中添加随机噪声。
- en: The *fit_transform* method combines the functionality of fitting and transforming
    the data by first fitting the transformer to the training data and then transforming
    it based on the calculated encodings.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*fit_transform* 方法结合了拟合和转换数据的功能，首先将转换器拟合到训练数据，然后基于计算出的编码进行转换。'
- en: Now that you understand how the code works, let’s see it in action.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经理解了代码的工作原理，让我们看看它的实际应用。
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/22681eff29fda72f848991a453fed087.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22681eff29fda72f848991a453fed087.png)'
- en: Output with Target encoded Role title. Image by author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出带有目标编码角色标题的结果。图像由作者提供
- en: The Target encoder replaced each “*ROLE_TITLE*” id with the probability of each
    category. Now, let's do the same for all features and check the memory usage after
    using Target Encoding.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码器用每个类别的概率替换了每个“*ROLE_TITLE*” ID。现在，让我们对所有特征做相同的操作，并检查在使用目标编码后内存的使用情况。
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/16cffc6f388731f36b184f0376183964.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16cffc6f388731f36b184f0376183964.png)'
- en: Output, Target encoded features. Image by author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 输出目标编码特征。图像由作者提供
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/9d24943bd0681c1ba70420d2f47e6bdd.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d24943bd0681c1ba70420d2f47e6bdd.png)'
- en: The resulting dataset only uses 2.25 MB, compared to 488.08 MB from the one-hot
    encoder. Image by author
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数据集仅使用了 2.25 MB，而独热编码器则使用了 488.08 MB。图像由作者提供
- en: Target encoding successfully transformed the categorical data into numerical
    without creating extra columns or increasing memory usage.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码成功地将分类数据转换为数值数据，而没有创建额外的列或增加内存使用。
- en: Target encoding with SciKitLearn API
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SciKitLearn API 进行目标编码
- en: '**So far we have created our own target encoder class, however you don’t have
    to do this anymore.**'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**到目前为止，我们已经创建了自己的目标编码器类，但你不再需要这样做。**'
- en: In scikit-learn version 1.3 release, somewhere around June 2023, they introduced
    the Target Encoder class to their API. Here is how you can use target encoding
    with Scikit Learn
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在 scikit-learn 1.3 版本发布中，大约在 2023 年 6 月，他们将 Target Encoder 类引入了他们的 API。这是如何使用目标编码与
    Scikit Learn 的方法。
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/1aaf7df1af07f04088bc8380e62d514f.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1aaf7df1af07f04088bc8380e62d514f.png)'
- en: Output from sklearn Target Encoder transformation. Image by author
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn 目标编码器转换的输出。图片由作者提供
- en: Note that we are getting slightly different results from the manual Target encoder
    class because of the smooth parameter and randomness on the noise level.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于平滑参数和噪声水平的随机性，我们从手动目标编码器类中得到的结果略有不同。
- en: As you see, sklearn makes it easy to run target encoding transformations. **However,
    it is important to understand how the transformation works under the hood first
    to understand and explain the output.**
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，sklearn 使得进行目标编码转换变得简单。**然而，首先了解该转换的内部原理，以便理解和解释输出，是非常重要的。**
- en: While Target encoding is a powerful encoding method, it’s important to consider
    the specific requirements and characteristics of your dataset and choose the encoding
    method that best suits your needs and the requirements of the machine learning
    algorithm you plan to use.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然目标编码是一种强大的编码方法，但重要的是要考虑数据集的特定要求和特点，并选择最适合您的需求以及您计划使用的机器学习算法要求的编码方法。
- en: References
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Banachewicz, K. & Massaron, L. (2022). *The Kaggle Book: Data Analysis
    and Machine Learning for Competitive Data Science*. Packt>'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Banachewicz, K. & Massaron, L. (2022). *《Kaggle 书：用于竞争数据科学的数据分析与机器学习》*。Packt>'
- en: '[2] Massaron, L. (2022, January). Amazon Employee Access Challenge. Retrieved
    February 1, 2024, from [https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge](https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Massaron, L. (2022年1月)。Amazon 员工访问挑战。于 2024 年 2 月 1 日检索自 [https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge](https://www.kaggle.com/datasets/lucamassaron/amazon-employee-access-challenge)'
- en: '[3] Massaron, L. Meta-features and target encoding. Retrieved February 1, 2024,
    from [https://www.kaggle.com/luca-massaron/meta-features-and-target-encoding](https://www.kaggle.com/luca-massaron/meta-features-and-target-encoding)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Massaron, L. 元特征和目标编码。于 2024 年 2 月 1 日检索自 [https://www.kaggle.com/luca-massaron/meta-features-and-target-encoding](https://www.kaggle.com/luca-massaron/meta-features-and-target-encoding)'
- en: '[4] Scikit-learn.`sklearn.preprocessing.TargetEncoder`. In scikit-learn: Machine
    learning in Python (Version 1.3). Retrieved February 1, 2024, from [https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Scikit-learn.`sklearn.preprocessing.TargetEncoder`。在 scikit-learn：Python
    中的机器学习（版本 1.3）。于 2024 年 2 月 1 日检索自 [https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html)'
