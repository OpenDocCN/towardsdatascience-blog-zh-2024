- en: 'Oversampling and Undersampling, Explained: A Visual Guide with Mini 2D Dataset'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26](https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: DATA PREPROCESSING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Artificially generating and deleting data for the greater good
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    Â·9 min readÂ·Oct 26, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d18a47c1be692247ef3ce8e346048f3e.png)'
  prefs: []
  type: TYPE_IMG
- en: '`â›³ï¸ More [DATA PREPROCESSING](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4),
    explained: Â· [Missing Value Imputation](/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb)
    Â· [Categorical Encoding](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    Â· [Data Scaling](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    Â· [Discretization](/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86)
    â–¶ [Oversampling & Undersampling](/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091)
    Â· [Data Leakage in Preprocessing](/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7)`'
  prefs: []
  type: TYPE_NORMAL
- en: Collecting a dataset where each class has exactly the same number of class to
    predict can be a challenge. In reality, things are rarely perfectly balanced,
    and when you are making a classification model, this can be an issue. When a model
    is trained on such dataset, where one class has more examples than the other,
    it has usually become better at predicting the bigger groups and worse at predicting
    the smaller ones. To help with this issue, we can use tactics like oversampling
    and undersampling â€” creating more examples of the smaller group or removing some
    examples from the bigger group.
  prefs: []
  type: TYPE_NORMAL
- en: There are many different oversampling and undersampling methods (with intimidating
    names like SMOTE, ADASYN, and Tomek Links) out there but there doesnâ€™t seem to
    be many resources that visually compare how they work. So, here, we will use one
    simple 2D dataset to show the changes that occur in the data after applying those
    methods so we can see how different the output of each method is. You will see
    in the visuals that these various approaches give different solutions, and who
    knows, one might be suitable for your specific machine learning challenge!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27f80579aa059f5392c5e18ce293068a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Oversampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Oversampling make a dataset more balanced when one group has a lot fewer examples
    than the other. The way it works is by making more copies of the examples from
    the smaller group. This helps the dataset represent both groups more equally.
  prefs: []
  type: TYPE_NORMAL
- en: Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On the other hand, undersampling works by deleting some of the examples from
    the bigger group until itâ€™s almost the same in size to the smaller group. In the
    end, the dataset is smaller, sure, but both groups will have a more similar number
    of examples.
  prefs: []
  type: TYPE_NORMAL
- en: '**Hybrid Sampling**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Combining oversampling and undersampling can be called â€œhybrid samplingâ€. It
    increases the size of the smaller group by making more copies of its examples
    and also, it removes some of example of the bigger group by removing some of its
    examples. It tries to create a dataset that is more balanced â€” not too big and
    not too small.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fbfec21238decaadf5e6de9556274a3f.png)'
  prefs: []
  type: TYPE_IMG
- en: ğŸ“Š Dataset Used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s use a simple artificial golf dataset to show both oversampling and undersampling.
    This dataset shows what kind of golf activity a person do in a particular weather
    condition.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f864e43ec6dfd3779bd2db853fb5dd5d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Columns: Temperature (0â€“3), Humidity (0â€“3), Golf Activity (A=Normal Course,
    B=Drive Range, or C=Indoor Golf). The training dataset has 2 dimensions and 9
    samples.'
  prefs: []
  type: TYPE_NORMAL
- en: âš ï¸ Note that while this small dataset is good for understanding the concepts,
    in real applications youâ€™d want much larger datasets before applying these techniques,
    as sampling with too little data can lead to unreliable results.
  prefs: []
  type: TYPE_NORMAL
- en: Oversampling Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random Oversampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Random Oversampling](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)
    is a simple way to make the smaller group bigger. It works by making duplicates
    of the examples from the smaller group until all the classes are balanced.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for very small datasets that need to be balanced quickly
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended for complicated datasets
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/13295244f5529177e8d14d031dfa1b8d.png)![](../Images/749fd0b088d2dd48976bbd04f9607668.png)'
  prefs: []
  type: TYPE_IMG
- en: Random Oversampling simply duplicates selected samples from the smaller group
    (A) while keeping all samples from the bigger groups (B and C) unchanged, as shown
    by the AÃ—2 markings in the right plot.
  prefs: []
  type: TYPE_NORMAL
- en: SMOTE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)
    (Synthetic Minority Over-sampling Technique) is an oversampling technique that
    makes new examples by interpolating the smaller group. Unlike the random oversampling,
    it doesnâ€™t just copy whatâ€™s there but it uses the examples of the smaller group
    to generate some examples between them.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you have a decent amount of examples to work with and need variety
    in your data
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if you have very few examples
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if data points are too scattered or noisy
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dda912677a7737a5f40d61c11f2d2550.png)![](../Images/8bc0e42698c59189fbe66ff91b6dee53.png)'
  prefs: []
  type: TYPE_IMG
- en: SMOTE creates new A samples by selecting pairs of A points and placing new points
    somewhere along the line between them. Similarly, a new B point is placed between
    pairs of randomly chosen B points
  prefs: []
  type: TYPE_NORMAL
- en: ADASYN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[ADASYN](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html)
    (Adaptive Synthetic) is like SMOTE but focuses on making new examples in the harder-to-learn
    parts of the smaller group. It finds the examples that are trickiest to classify
    and makes more new points around those. This helps the model better understand
    the challenging areas.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when some parts of your data are harder to classify than others
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for complex datasets with challenging areas
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if your data is fairly simple and straightforward
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef640350be2f8f11175deb868837198d.png)![](../Images/cfd7a6cd64777142b381f64cbd598479.png)'
  prefs: []
  type: TYPE_IMG
- en: ADASYN creates more synthetic points from the smaller group (A) in â€˜difficult
    areasâ€™ where A points are close to other groups (B and C). It also generates new
    B points in similar areas.
  prefs: []
  type: TYPE_NORMAL
- en: Undersampling Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Undersampling shrinks the bigger group to make it closer in size to the smaller
    group. There are some ways of doing this:'
  prefs: []
  type: TYPE_NORMAL
- en: Random Undersampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Random Undersampling](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html)
    removes examples from the bigger group at random until itâ€™s the same size as the
    smaller group. Just like random oversampling the method is pretty simple, but
    it might get rid of important info that really show how different the groups are.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for very large datasets with lots of repetitive examples
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you need a quick, simple fix
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if every example in your bigger group is important
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if you canâ€™t afford losing any information
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/338affc600e93a3b9159cd576d5daa3f.png)![](../Images/1ea3f55adc1079391dcd5d339a331aa4.png)'
  prefs: []
  type: TYPE_IMG
- en: Random Undersampling removes randomly chosen points from the bigger groups (B
    and C) while keeping all points from the smaller group (A) unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Tomek Links
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Tomek Links](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html)
    is an undersampling method that makes the â€œlinesâ€ between groups clearer. It searches
    for pairs of examples from different groups that are really alike. When it finds
    a pair where the examples are each otherâ€™s closest neighbors but belong to different
    groups, it gets rid of the example from the bigger group.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when your groups overlap too much
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for cleaning up messy or noisy data
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you need clear boundaries between groups
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if your groups are already well separated
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a66c75601482e491f58bfd01f2fbb85b.png)![](../Images/e2a22ee08d0dd985835582298e45af3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Tomek Links identifies pairs of points from different groups (A-B, B-C) that
    are closest neighbors to each other. Points from the bigger groups (B and C) that
    form these pairs are then removed while all points from the smaller group (A)
    are kept.â€
  prefs: []
  type: TYPE_NORMAL
- en: Near Miss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Near Miss](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html)
    is a set of undersampling techniques that works on different rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Near Miss-1*: Keeps examples from the bigger group that are closest to the
    examples in the smaller group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Near Miss-2*: Keeps examples from the bigger group that have the smallest
    average distance to their three closest neighbors in the smaller group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Near Miss-3*: Keeps examples from the bigger group that are furthest away
    from other examples in their own group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main idea here is to keep the most informative examples from the bigger
    group and get rid of the ones that arenâ€™t as important.
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you want control over which examples to keep
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if you need a simple, quick solution
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3484d2504c3b1c299838a03281e1e89a.png)![](../Images/c2ffc17b3d37927fa513378c6de6a74e.png)'
  prefs: []
  type: TYPE_IMG
- en: NearMiss-1 keeps points from the bigger groups (B and C) that are closest to
    the smaller group (A), while removing the rest. Here, only the B and C points
    nearest to A points are kept.
  prefs: []
  type: TYPE_NORMAL
- en: ENN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Edited Nearest Neighbors](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html)
    (ENN) method gets rid of examples that are probably noise or outliers. For each
    example in the bigger group, it checks whether most of its closest neighbors belong
    to the same group. If they donâ€™t, it removes that example. This helps create cleaner
    boundaries between the groups.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for cleaning up messy data
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you need to remove outliers
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for creating cleaner group boundaries
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if your data is already clean and well-organized
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2c6d1c578f42c121ee08d9d4492a7e95.png)![](../Images/168f72783979a04a0feb28881a6bff14.png)'
  prefs: []
  type: TYPE_IMG
- en: ENN removes points from bigger groups (B and C) whose majority of nearest neighbors
    belong to a different group. In the right plot, crossed-out points are removed
    because most of their closest neighbors are from other groups.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid sampling methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SMOTETomek
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[SMOTETomek](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html)
    works by first creating new examples for the smaller group using SMOTE, then cleaning
    up messy boundaries by removing â€œconfusingâ€ examples using Tomek Links. This helps
    creating a more balanced dataset with clearer boundaries and less noise.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for unbalanced data that is really severe
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you need both more examples and cleaner boundaries
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when dealing with noisy, overlapping groups
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if your data is already clean and well-organized
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended for small dataset
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/711a2e0590e08f16f29cc19029addb27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'SMOTETomek combines two steps: first applying SMOTE to create new A points
    along lines between existing A points (shown in middle plot), then removing Tomek
    Links from bigger groups (B and C). The final result has more balanced groups
    with clearer boundaries between them.'
  prefs: []
  type: TYPE_NORMAL
- en: SMOTEENN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[SMOTEENN](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html)
    works by first creating new examples for the smaller group using SMOTE, then cleaning
    up both groups by removing examples that donâ€™t fit well with their neighbors using
    ENN. Just like SMOTETomek, this helps create a cleaner dataset with clearer borders
    between the groups.'
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best for cleaning up both groups at once
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when you need more examples but cleaner data
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Best when dealing with lots of outliers
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended if your data is already clean and well-organized
  prefs: []
  type: TYPE_NORMAL
- en: ğŸ‘ Not recommended for small dataset
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7c8d78a7ccc58712f284aee986b18d4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'SMOTEENN combines two steps: first using SMOTE to create new A points along
    lines between existing A points (middle plot), then applying ENN to remove points
    from bigger groups (B and C) whose nearest neighbors are mostly from different
    groups. The final plot shows the cleaned, balanced dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: âš ï¸ Risks when using Resampling methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Resampling methods can be helpful but there are some potential risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Oversampling:**'
  prefs: []
  type: TYPE_NORMAL
- en: Making artificial samples can **give false patterns** that donâ€™t exist in real
    life.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models can **become too confident** because of the synthetic samples. This will
    lead to serious failures when it is applied to real situation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thereâ€™s a risk of **data leakage** if resampling is done incorrectly (like before
    splitting the data for cross-validation.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Undersampling:**'
  prefs: []
  type: TYPE_NORMAL
- en: You may **permanently lose important information**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can **accidentally destroy important boundaries** between classes, and will
    cause misunderstanding of the problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may **create artificial class distributions** that is too different compared
    to real-world conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid Methods:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Combining errors** from both methods can **make things worse** instead of
    better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using resampling methods, itâ€™s hard to find the right balance between getting
    class imbalance without changing the important patterns in your data. In my experience,
    incorrect resampling can actually harm model performance rather than improve it.
  prefs: []
  type: TYPE_NORMAL
- en: Before turning to resampling, try using models that naturally handle imbalanced
    data better, such as tree-based algorithms. Resampling should be part of a broader
    strategy rather than the only solution to address class imbalance.
  prefs: []
  type: TYPE_NORMAL
- en: ğŸŒŸ Oversampling & Undersampling Code Summarized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the code example, we will use the methods provided by `[imblearn](https://imbalanced-learn.org/stable/index.html)`
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Technical Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article uses Python 3.7, pandas 1.3, and imblearn 1.2\. While the concepts
    discussed are generally applicable, specific code implementations may vary slightly
    with different versions.
  prefs: []
  type: TYPE_NORMAL
- en: About the Illustrations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¿ğ™–ğ™©ğ™– ğ™‹ğ™§ğ™šğ™¥ğ™§ğ™¤ğ™˜ğ™šğ™¨ğ™¨ğ™ğ™£ğ™œ ğ™¢ğ™šğ™©ğ™ğ™¤ğ™™ğ™¨ ğ™ğ™šğ™§ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Data Preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----1155577d3091--------------------------------)6
    stories![](../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png)![Cartoon illustration
    of two figures embracing, with letters â€˜Aâ€™, â€˜Bâ€™, â€˜Câ€™ and numbers â€˜1â€™, â€˜2â€™, â€˜3â€™
    floating around them. A pink heart hovers above, symbolizing affection. The background
    is a pixelated pattern of blue and green squares, representing data or encoding.
    This image metaphorically depicts the concept of encoding categorical data, where
    categories (ABC) are transformed into numerical representations (123).](../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png)![A
    cartoon illustration representing data scaling in machine learning. A tall woman
    (representing a numerical feature with a large range) is shown shrinking into
    a child (representing the same feature after scaling to a smaller range). A red
    arrow indicates the shrinking process, and yellow sparkles around the child signify
    the positive impact of scaling.](../Images/d261b2c52a3cafe266d1962d4dbabdbd.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Classification Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----1155577d3091--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Regression Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----1155577d3091--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
  prefs: []
  type: TYPE_NORMAL
