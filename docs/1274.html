<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Quantum Mechanics Meets PCA: An (Un)expected Convergence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Quantum Mechanics Meets PCA: An (Un)expected Convergence</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22">https://towardsdatascience.com/quantum-mechanics-meets-pca-an-un-expected-convergence-5e04bcb16376?source=collection_archive---------1-----------------------#2024-05-22</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="108c" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">How quantum states and PCA components connect</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Rodrigo Silva" class="l ep by dd de cx" src="../Images/d260f05ed9887c5072e0590db1481be2.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*heNbe-BQVIx12kMGCHmuHA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@rodrigopesilva?source=post_page---byline--5e04bcb16376--------------------------------" rel="noopener follow">Rodrigo Silva</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--5e04bcb16376--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">5</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/c54c6270dff8c1bf03529adba4ce1195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ej7SBOgK4t5b42ky"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@dynamicwang" rel="noopener ugc nofollow" target="_blank">Dynamic Wang</a><strong class="bf nd"> </strong>on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="526a" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">One of the greatest gifts of maths is its weird ability to be as general as our creativity allows. An important consequence of this generalizability is that we can use the same set of tools to create formalisms for vastly different topics. A side effect of when we do this is that some unexpected analogies will appear between these different areas. To illustrate what I'm saying, I will try to convince you, through this article, that the principal values in PCA coordinates and the energies of a quantum system are the same (mathematical) thing.</p><h1 id="f8da" class="oa ob fq bf nd oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The linear algebra of PCA</h1><p id="a102" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">For those unfamiliar with Principal Component Analysis (or PCA), I will formulate it on the bare minimum. The main idea of PCA is, based on your data, to obtain a new set of coordinates such that when our original data is rewritten in this new coordinate system, the axes point in the direction of the highest variance.</p><p id="ff1c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Suppose you have a set of <em class="pa">n </em>data samples (which I shall refer from now on as <em class="pa">individuals</em>), where each individual consists of <em class="pa">m </em>features. For instance, if I ask for the weight, height, and salary of 10 different people, <em class="pa">n=</em>10 and <em class="pa">m=3</em>. In this example, we expect some relation between weight and height, but there is no relation between these variables and salary, at least not in principle. PCA will help us better visualize these relations. For us to understand how and why this happens, I'll go through each step of the PCA algorithm.</p><p id="44d9" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">To begin the formalism, each individual will be represented by a vector <strong class="ng fr">x</strong>, where each component of this vector is a feature. This means that we will have <em class="pa">n </em>vectors living in an <em class="pa">m</em>-dimensional space. Our dataset can be regarded as a big matrix <em class="pa">X</em>, <em class="pa">m </em>x <em class="pa">n</em>, where we essentially place the individuals side-by-side (a.k.a. each individual is represented as a column vector):</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pb"><img src="../Images/7eeb01ff584ab418e7618165d50bfcfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*ZkmaMrQuN1pSjYvnsDI7Aw.gif"/></div></figure><p id="7f85" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">With this in mind, we can properly begin the PCA algorithm.</p><h2 id="2116" class="pc ob fq bf nd pd pe pf oe pg ph pi oh nn pj pk pl nr pm pn po nv pp pq pr ps bk">Centralize the data</h2><p id="ddc9" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">Centralizing our data means shifting the data points in a way that it becomes distributed around the origin of our coordinate system. To do this, we calculate the mean for each feature and subtract it from the data points. We can express the mean for each feature as a vector <strong class="ng fr">µ</strong>:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pt"><img src="../Images/1522c66363cbc2430708a55432568541.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*t4LQaeJ7FWpUEMXiktin5Q.gif"/></div></figure><p id="01e3" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">where <em class="pa">µ_i</em> is the mean taken for the <em class="pa">i</em>-th feature. By centralizing our data we get a new matrix <em class="pa">B </em>given by:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pu"><img src="../Images/dd96356b4b24dba6ffbbb7e03045c426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*7Q3LMYX-9_DlfO8NmJFd-g.gif"/></div></figure><p id="39ea" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This matrix <em class="pa">B </em>represents our data set centered around the origin. Notice that, since I'm defining the mean vector as a row matrix, I have to use its <em class="pa">transpose</em> to calculate <em class="pa">B </em>(where each individual is represented by a column matrix), but this is just a minor detail.</p><h2 id="dcd0" class="pc ob fq bf nd pd pe pf oe pg ph pi oh nn pj pk pl nr pm pn po nv pp pq pr ps bk">Compute the covariance matrix</h2><p id="20bc" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">We can compute the covariance matrix, <em class="pa">S</em>, by multiplying the matrix <em class="pa">B </em>and its transpose <em class="pa">B^T </em>as shown below:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pv"><img src="../Images/c826739ce5c5dbfeb89e5e59a234535b.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*U9nRqpOLeXc9t7XP4SB1gg.gif"/></div></figure><p id="1a62" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The 1<em class="pa">/(n-</em>1<em class="pa">) </em>factor in front is just to make the definition equal to the statistical definition. One can easily show that elements <em class="pa">S_ij</em> of the above matrix are the covariances of the feature <em class="pa">i </em>with the feature <em class="pa">j</em>, and its diagonal entry <em class="pa">S_ii </em>is the variance of the <em class="pa">i-</em>th feature.</p><h2 id="d0c5" class="pc ob fq bf nd pd pe pf oe pg ph pi oh nn pj pk pl nr pm pn po nv pp pq pr ps bk">Find the eigenvalues and eigenvectors of the covariance matrix</h2><p id="32b5" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">I will list three important facts from linear algebra (that I will not prove here) about the covariance matrix <em class="pa">S </em>that we have constructed so far:</p><ol class=""><li id="8b8c" class="ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz pw px py bk">The matrix <em class="pa">S </em>is symmetric: the mirrored entries with respect to the diagonal are equal (i.e. <em class="pa">S_ij = S_ji</em>);</li><li id="f126" class="ne nf fq ng b go pz ni nj gr qa nl nm nn qb np nq nr qc nt nu nv qd nx ny nz pw px py bk">The matrix <em class="pa">S </em>is orthogonally diagonalizable: there is a set of numbers (λ_1, λ_2, …, λ_m) called <em class="pa">eigenvalues</em>, and a set of vectors (<strong class="ng fr">v_</strong>1, <strong class="ng fr">v_</strong>2 …, <strong class="ng fr">v_</strong>m) called <em class="pa">eigenvectors</em>, such that, when <em class="pa">S </em>is written using the eigenvectors as a basis, it has a diagonal form with diagonal elements being its eigenvalues;</li><li id="e315" class="ne nf fq ng b go pz ni nj gr qa nl nm nn qb np nq nr qc nt nu nv qd nx ny nz pw px py bk">The matrix <em class="pa">S </em>has only real, non-negative eigenvalues.</li></ol><p id="0539" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">In PCA formalism, the eigenvectors of the covariance matrix are called the principal components, and the eigenvalues are called the principal values.</p><p id="b593" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">At first glance, it seems just a bunch of mathematical operations on a data set. But I will give you a last linear algebra fact and we are done with maths for today:</p><p id="66aa" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">4. The trace of a matrix (i.e. the sum of its diagonal terms) is independent of the basis in which the matrix is represented.</p><p id="9672" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This means that, if the sum of the diagonal terms in matrix <em class="pa">S</em> is the total variance of that data set, then the sum of the <em class="pa">eigenvalues</em> of matrix <em class="pa">S </em>is also the total variance of the data set. Let's call this total variance <em class="pa">L.</em></p><p id="2840" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Having this mechanism in mind, we can order the eigenvalues (λ_1, λ_2, …, λ_m) in descending order: λ_1 &gt; λ_2 &gt; … &gt; λ_m in a way that λ_1/<em class="pa">L</em> &gt; λ_2/<em class="pa">L</em> &gt; … &gt; λ_m/<em class="pa">L</em>. We have ordered our eigenvalues using the total variance of our data set as the importance metric. The first principal component, <strong class="ng fr">v_</strong>1, points towards the direction of the largest variance because its eigenvalue, λ_1, accounts for the largest contribution to the total variance.</p><p id="0a87" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This is PCA in a nutshell. Now… what about quantum mechanics?</p><h1 id="0d6b" class="oa ob fq bf nd oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The linear algebra of quantum mechanics</h1><p id="4c44" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">Maybe the most important aspect of quantum mechanics for our discussion here is one of its postulates:</p><blockquote class="qe qf qg"><p id="e28d" class="ne nf pa ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">The states of a quantum system are represented as vectors (usually called state vectors) that live in a vector space, called the Hilbert space.</p></blockquote><p id="45b2" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">As I'm writing this, I noticed that I find this postulate to be very natural because I see this everyday, and I have got used to it. But it's kinda absurd, so take your time to absorb this. Bear in mind that <em class="pa">state</em> is a generic term that we use in physics that means "the configuration of something at a certain time."</p><p id="c5ef" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This postulate implies that when we represent<em class="pa"> </em>our physical system as a vector, all the rules from linear algebra apply here, and there should be no surprise that some connections between PCA (which also relies on linear algebra) and quantum mechanics arise.</p><p id="370d" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Since physics is the science interested in how physical systems change, we should be able to represent <em class="pa">changes </em>in the formalism of quantum mechanics. To <em class="pa">change</em> a vector, we must apply some kind of operation on it using a mathematical entity called (not surprisingly) operator. A class of operators of particular interest is the class of linear operators; in fact, they are so important that we usually omit the term "linear" because it is implied that when we are talking about operators, these are linear operators. Hence, if you want to impress people at a bar table, just drop this bomb:</p><blockquote class="qh"><p id="b3d8" class="qi qj fq bf qk ql qm qn qo qp qq nz dx">In quantum mechanics, it's all about (state) vectors and (linear) operators.</p></blockquote><h2 id="cbda" class="pc ob fq bf nd pd qr pf oe pg qs pi oh nn qt pk pl nr qu pn po nv qv pq pr ps bk">Measurements in quantum mechanics</h2><p id="7120" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">If in the context of quantum mechanics, vectors represent physical states, what does operators represent? Well, they represent physical <em class="pa">measurements</em>. For instance, if I want to measure the position of a quantum particle, it is modeled in quantum mechanics as applying a position operator on the state vector associated with the particle. Similarly, if I want to measure the energy of a quantum particle, I must apply the energy operator to it. The final catch here to connect quantum mechanics and PCA is to remember that a linear operator, when you choose a basis, can be represented as a matrix.</p><p id="defd" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">A very common basis used to represent our quantum systems is the basis made by the eigenvectors of the energy operator. In this basis, the energy operator matrix is diagonal, and its diagonal terms are the energies of the system for different energy (eigen)states. The sum of these energy values corresponds to the trace of your energy operator, and if you stop and think about it, of course this cannot change under a change of basis, as said earlier in this text. If it did change, it would imply that it should be possible to change the energy of a system by writing its components differently, which is absurd. Your measuring apparatus in the lab does not care if you use basis A or B to represent your system: if you measure the energy, you measure the energy and that's it.</p><h1 id="5920" class="oa ob fq bf nd oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Energies and PCA</h1><p id="0b15" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">With all being said, a nice interpretation of the principal values of a PCA decomposition is that they correspond to the "energy" of your system. When you write down your principal values (and principal components) in descending order, you are giving priority to the "states" that carry the largest "energies" of your system.</p><p id="f938" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">This interpretation may be somewhat more insightful than trying to interpret a statistical quantity such as variance. I believe that we have a better intuition about energy since it is a fundamental physical concept.</p><h1 id="08e4" class="oa ob fq bf nd oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Conclusion</h1><p id="5d99" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">"All of this is pretty obvious." This was a provocation made by my dearest friend <a class="af nc" href="https://medium.com/@rodrigodamottacc" rel="noopener">Rodrigo da Motta</a>, referring to the article you've just read.</p><p id="a264" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">When I write posts like this, I try to explain things having in mind the reader with minimum context. This exercise led me to the conclusion that, with the right background, pretty much anything can be potentially obvious. Rodrigo and I are physicists who also happen to be data scientists, so this relationship between quantum mechanics and PCA must be pretty obvious <em class="pa">to us</em>.</p><p id="12d1" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">Writing posts like this gives me more reasons to believe that we should expose ourselves to all kinds of knowledge because that's when interesting connections arise. The same human brain that thinks about and creates the understanding of physics is the one that creates the understanding of biology, and history, and cinema. If the possibilities of language and the connections of our brains are finite, it means that contiously or not, we eventually recycle concepts from one field into another, and this creates underlying shared structures accross the domains of knowledge.</p><p id="213c" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">We, as scientists, should take advantage of this.</p><h1 id="ba2a" class="oa ob fq bf nd oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">References</h1><p id="f4c8" class="pw-post-body-paragraph ne nf fq ng b go ov ni nj gr ow nl nm nn ox np nq nr oy nt nu nv oz nx ny nz fj bk">[1] Linear algebra of PCA: <a class="af nc" href="https://www.math.union.edu/~jaureguj/PCA.pdf" rel="noopener ugc nofollow" target="_blank">https://www.math.union.edu/~jaureguj/PCA.pdf</a></p><p id="babd" class="pw-post-body-paragraph ne nf fq ng b go nh ni nj gr nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz fj bk">[2] The postulates of quantum mechanics: <a class="af nc" href="https://web.mit.edu/8.05/handouts/jaffe1.pdf" rel="noopener ugc nofollow" target="_blank">https://web.mit.edu/8.05/handouts/jaffe1.pdf</a></p></div></div></div></div>    
</body>
</html>