<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Oversampling and Undersampling, Explained: A Visual Guide with Mini 2D Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Oversampling and Undersampling, Explained: A Visual Guide with Mini 2D Dataset</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26">https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="df60" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">DATA PREPROCESSING</h2><div/><div><h2 id="3db6" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">Artificially generating and deleting data for the greater good</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Oct 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">4</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/d18a47c1be692247ef3ce8e346048f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*elYzjkMnnilXE1M9T_wUog.png"/></div></div></figure><p id="af15" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><code class="cx ny nz oa ob b">⛳️ More <a class="af oc" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4" rel="noopener">DATA PREPROCESSING</a>, explained: <br/> · <a class="af oc" rel="noopener" target="_blank" href="/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb">Missing Value Imputation</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae">Categorical Encoding</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb">Data Scaling</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86">Discretization</a> <br/> ▶ <a class="af oc" rel="noopener" target="_blank" href="/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091">Oversampling &amp; Undersampling</a> <br/> · <a class="af oc" rel="noopener" target="_blank" href="/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7">Data Leakage in Preprocessing</a></code></p><p id="0765" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Collecting a dataset where each class has exactly the same number of class to predict can be a challenge. In reality, things are rarely perfectly balanced, and when you are making a classification model, this can be an issue. When a model is trained on such dataset, where one class has more examples than the other, it has usually become better at predicting the bigger groups and worse at predicting the smaller ones. To help with this issue, we can use tactics like oversampling and undersampling — creating more examples of the smaller group or removing some examples from the bigger group.</p><p id="47a4" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">There are many different oversampling and undersampling methods (with intimidating names like SMOTE, ADASYN, and Tomek Links) out there but there doesn’t seem to be many resources that visually compare how they work. So, here, we will use one simple 2D dataset to show the changes that occur in the data after applying those methods so we can see how different the output of each method is. You will see in the visuals that these various approaches give different solutions, and who knows, one might be suitable for your specific machine learning challenge!</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/27f80579aa059f5392c5e18ce293068a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fJpP5sVlXfRY8LSplZAc4g.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="acff" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Definition</h1><h2 id="1bc4" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Oversampling</h2><p id="26e7" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Oversampling make a dataset more balanced when one group has a lot fewer examples than the other. The way it works is by making more copies of the examples from the smaller group. This helps the dataset represent both groups more equally.</p><h2 id="0843" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Undersampling</h2><p id="de42" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">On the other hand, undersampling works by deleting some of the examples from the bigger group until it’s almost the same in size to the smaller group. In the end, the dataset is smaller, sure, but both groups will have a more similar number of examples.</p><h2 id="1bef" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk"><strong class="al">Hybrid Sampling</strong></h2><p id="6e5e" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Combining oversampling and undersampling can be called “hybrid sampling”. It increases the size of the smaller group by making more copies of its examples and also, it removes some of example of the bigger group by removing some of its examples. It tries to create a dataset that is more balanced — not too big and not too small.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/fbfec21238decaadf5e6de9556274a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldYpLhkUQDRI6LDr5XNlcA.png"/></div></div></figure><h1 id="dad9" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">📊 Dataset Used</h1><p id="8775" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Let’s use a simple artificial golf dataset to show both oversampling and undersampling. This dataset shows what kind of golf activity a person do in a particular weather condition.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/f864e43ec6dfd3779bd2db853fb5dd5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwDODhEe86e3Gad29xKfbA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Columns: Temperature (0–3), Humidity (0–3), Golf Activity (A=Normal Course, B=Drive Range, or C=Indoor Golf). The training dataset has 2 dimensions and 9 samples.</figcaption></figure><p id="4f39" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">⚠️ Note that while this small dataset is good for understanding the concepts, in real applications you’d want much larger datasets before applying these techniques, as sampling with too little data can lead to unreliable results.</p><h1 id="3b2a" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Oversampling Methods</h1><h2 id="823d" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Random Oversampling</h2><p id="04c2" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html" rel="noopener ugc nofollow" target="_blank">Random Oversampling</a> is a simple way to make the smaller group bigger. It works by making duplicates of the examples from the smaller group until all the classes are balanced.</p><p id="7827" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best for very small datasets that need to be balanced quickly<br/>👎 Not recommended for complicated datasets</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/13295244f5529177e8d14d031dfa1b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1RmCGS_y8xz-EUeDi_alg.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/749fd0b088d2dd48976bbd04f9607668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pwuCPgff6M6Pl8ZJBEEewA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Random Oversampling simply duplicates selected samples from the smaller group (A) while keeping all samples from the bigger groups (B and C) unchanged, as shown by the A×2 markings in the right plot.</figcaption></figure><h2 id="c046" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">SMOTE</h2><p id="1164" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank">SMOTE</a> (Synthetic Minority Over-sampling Technique) is an oversampling technique that makes new examples by interpolating the smaller group. Unlike the random oversampling, it doesn’t just copy what’s there but it uses the examples of the smaller group to generate some examples between them.</p><p id="62e5" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best when you have a decent amount of examples to work with and need variety in your data<br/>👎 Not recommended if you have very few examples<br/>👎 Not recommended if data points are too scattered or noisy</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/dda912677a7737a5f40d61c11f2d2550.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mo6QfsoPx05aWg2EoGkdQA.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/8bc0e42698c59189fbe66ff91b6dee53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IFIiLi-FBaYni7tkrZkj3A.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">SMOTE creates new A samples by selecting pairs of A points and placing new points somewhere along the line between them. Similarly, a new B point is placed between pairs of randomly chosen B points</figcaption></figure><h2 id="50a2" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">ADASYN</h2><p id="e887" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html" rel="noopener ugc nofollow" target="_blank">ADASYN</a> (Adaptive Synthetic) is like SMOTE but focuses on making new examples in the harder-to-learn parts of the smaller group. It finds the examples that are trickiest to classify and makes more new points around those. This helps the model better understand the challenging areas.</p><p id="7f8a" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best when some parts of your data are harder to classify than others<br/>👍 Best for complex datasets with challenging areas<br/>👎 Not recommended if your data is fairly simple and straightforward</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/ef640350be2f8f11175deb868837198d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKVggmtFgsWNhduv3Ahtaw.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/cfd7a6cd64777142b381f64cbd598479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHsIYvs38-49ZlB19bDKsg.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">ADASYN creates more synthetic points from the smaller group (A) in ‘difficult areas’ where A points are close to other groups (B and C). It also generates new B points in similar areas.</figcaption></figure><h1 id="3a35" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Undersampling Methods</h1><p id="8c2c" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Undersampling shrinks the bigger group to make it closer in size to the smaller group. There are some ways of doing this:</p><h2 id="e91a" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Random Undersampling</h2><p id="b9b2" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html" rel="noopener ugc nofollow" target="_blank">Random Undersampling</a> removes examples from the bigger group at random until it’s the same size as the smaller group. Just like random oversampling the method is pretty simple, but it might get rid of important info that really show how different the groups are.</p><p id="eef0" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best for very large datasets with lots of repetitive examples<br/>👍 Best when you need a quick, simple fix<br/>👎 Not recommended if every example in your bigger group is important<br/>👎 Not recommended if you can’t afford losing any information</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/338affc600e93a3b9159cd576d5daa3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcT99CTdDadflUshs0xyGA.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/1ea3f55adc1079391dcd5d339a331aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7gcqCabTdpjig3218jA9wg.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Random Undersampling removes randomly chosen points from the bigger groups (B and C) while keeping all points from the smaller group (A) unchanged.</figcaption></figure><h2 id="78eb" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Tomek Links</h2><p id="7f18" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html" rel="noopener ugc nofollow" target="_blank">Tomek Links</a> is an undersampling method that makes the “lines” between groups clearer. It searches for pairs of examples from different groups that are really alike. When it finds a pair where the examples are each other’s closest neighbors but belong to different groups, it gets rid of the example from the bigger group.</p><p id="b263" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best when your groups overlap too much<br/>👍 Best for cleaning up messy or noisy data<br/>👍 Best when you need clear boundaries between groups<br/>👎 Not recommended if your groups are already well separated</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/a66c75601482e491f58bfd01f2fbb85b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_sWL-kV77r1E1ioTBFfLQQ.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/e2a22ee08d0dd985835582298e45af3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wbdd0a4kTQIuk1QLKkTCJw.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">Tomek Links identifies pairs of points from different groups (A-B, B-C) that are closest neighbors to each other. Points from the bigger groups (B and C) that form these pairs are then removed while all points from the smaller group (A) are kept.”</figcaption></figure><h2 id="ca0f" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Near Miss</h2><p id="b486" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html" rel="noopener ugc nofollow" target="_blank">Near Miss</a> is a set of undersampling techniques that works on different rules:</p><ul class=""><li id="2b6a" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk"><em class="qc">Near Miss-1</em>: Keeps examples from the bigger group that are closest to the examples in the smaller group.</li><li id="64fc" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk"><em class="qc">Near Miss-2</em>: Keeps examples from the bigger group that have the smallest average distance to their three closest neighbors in the smaller group.</li><li id="116b" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk"><em class="qc">Near Miss-3</em>: Keeps examples from the bigger group that are furthest away from other examples in their own group.</li></ul><p id="d035" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The main idea here is to keep the most informative examples from the bigger group and get rid of the ones that aren’t as important.</p><p id="9a28" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best when you want control over which examples to keep<br/>👎 Not recommended if you need a simple, quick solution</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/3484d2504c3b1c299838a03281e1e89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5K-YRjEyz2osgRE2Ph8IOw.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/c2ffc17b3d37927fa513378c6de6a74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ppXmrxb3qEMlPqkimnLEQ.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">NearMiss-1 keeps points from the bigger groups (B and C) that are closest to the smaller group (A), while removing the rest. Here, only the B and C points nearest to A points are kept.</figcaption></figure><h2 id="5055" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">ENN</h2><p id="e575" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html" rel="noopener ugc nofollow" target="_blank">Edited Nearest Neighbors</a> (ENN) method gets rid of examples that are probably noise or outliers. For each example in the bigger group, it checks whether most of its closest neighbors belong to the same group. If they don’t, it removes that example. This helps create cleaner boundaries between the groups.</p><p id="a8da" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best for cleaning up messy data<br/>👍 Best when you need to remove outliers<br/>👍 Best for creating cleaner group boundaries<br/>👎 Not recommended if your data is already clean and well-organized</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/2c6d1c578f42c121ee08d9d4492a7e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mu7WQgRhegB7XLkj3M0WTA.png"/></div></div></figure><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/168f72783979a04a0feb28881a6bff14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8jDpMYpelVEyiKIJ2WDdVw.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">ENN removes points from bigger groups (B and C) whose majority of nearest neighbors belong to a different group. In the right plot, crossed-out points are removed because most of their closest neighbors are from other groups.</figcaption></figure><h1 id="e138" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Hybrid sampling methods</h1><h2 id="6399" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">SMOTETomek</h2><p id="7ad8" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html" rel="noopener ugc nofollow" target="_blank">SMOTETomek</a> works by first creating new examples for the smaller group using SMOTE, then cleaning up messy boundaries by removing “confusing” examples using Tomek Links. This helps creating a more balanced dataset with clearer boundaries and less noise.</p><p id="cf44" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best for unbalanced data that is really severe<br/>👍 Best when you need both more examples and cleaner boundaries<br/>👍 Best when dealing with noisy, overlapping groups<br/>👎 Not recommended if your data is already clean and well-organized<br/>👎 Not recommended for small dataset</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/711a2e0590e08f16f29cc19029addb27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UAJt_1QIeWPyuS0ga5PepA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">SMOTETomek combines two steps: first applying SMOTE to create new A points along lines between existing A points (shown in middle plot), then removing Tomek Links from bigger groups (B and C). The final result has more balanced groups with clearer boundaries between them.</figcaption></figure><h2 id="eff9" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">SMOTEENN</h2><p id="3a71" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk"><a class="af oc" href="https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html" rel="noopener ugc nofollow" target="_blank">SMOTEENN</a> works by first creating new examples for the smaller group using SMOTE, then cleaning up both groups by removing examples that don’t fit well with their neighbors using ENN. Just like SMOTETomek, this helps create a cleaner dataset with clearer borders between the groups.</p><p id="4150" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">👍 Best for cleaning up both groups at once<br/>👍 Best when you need more examples but cleaner data<br/>👍 Best when dealing with lots of outliers<br/>👎 Not recommended if your data is already clean and well-organized<br/>👎 Not recommended for small dataset</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/b7c8d78a7ccc58712f284aee986b18d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RpB9-pwKCOUaSCuE_WdEvQ.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">SMOTEENN combines two steps: first using SMOTE to create new A points along lines between existing A points (middle plot), then applying ENN to remove points from bigger groups (B and C) whose nearest neighbors are mostly from different groups. The final plot shows the cleaned, balanced dataset.</figcaption></figure></div></div></div><div class="ab cb qi qj qk ql" role="separator"><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="0c0f" class="oi oj fq bf ok ol qq gv on oo qr gy oq or qs ot ou ov qt ox oy oz qu pb pc pd bk">⚠️ Risks when using Resampling methods</h1><p id="d8dd" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Resampling methods can be helpful but there are some potential risks:</p><p id="ff56" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Oversampling:</strong></p><ul class=""><li id="5cd0" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk">Making artificial samples can <strong class="ne ga">give false patterns</strong> that don’t exist in real life.</li><li id="0ca6" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk">Models can <strong class="ne ga">become too confident</strong> because of the synthetic samples. This will lead to serious failures when it is applied to real situation.</li><li id="9c10" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk">There’s a risk of <strong class="ne ga">data leakage</strong> if resampling is done incorrectly (like before splitting the data for cross-validation.)</li></ul><p id="90af" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Undersampling:</strong></p><ul class=""><li id="0585" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk">You may <strong class="ne ga">permanently lose important information</strong>.</li><li id="5883" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk">You can <strong class="ne ga">accidentally destroy important boundaries</strong> between classes, and will cause misunderstanding of the problem.</li><li id="3958" class="nc nd fq ne b gt qd ng nh gw qe nj nk nl qf nn no np qg nr ns nt qh nv nw nx pz qa qb bk">You may <strong class="ne ga">create artificial class distributions</strong> that is too different compared to real-world conditions.</li></ul><p id="9cf8" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Hybrid Methods:</strong></p><ul class=""><li id="602d" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pz qa qb bk"><strong class="ne ga">Combining errors </strong>from both methods can <strong class="ne ga">make things worse</strong> instead of better.</li></ul><p id="e19c" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">When using resampling methods, it’s hard to find the right balance between getting class imbalance without changing the important patterns in your data. In my experience, incorrect resampling can actually harm model performance rather than improve it.</p><p id="d0f2" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before turning to resampling, try using models that naturally handle imbalanced data better, such as tree-based algorithms. Resampling should be part of a broader strategy rather than the only solution to address class imbalance.</p><h1 id="f9f0" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">🌟 Oversampling &amp; Undersampling Code Summarized</h1><p id="4cf9" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">For the code example, we will use the methods provided by <code class="cx ny nz oa ob b"><a class="af oc" href="https://imbalanced-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">imblearn</a></code> library:</p><pre class="mr ms mt mu mv qv ob qw bp qx bb bk"><span id="3de8" class="qy oj fq ob b bg qz ra l rb rc">import pandas as pd<br/>from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler<br/>from imblearn.under_sampling import TomekLinks, NearMiss, RandomUnderSampler<br/>from imblearn.combine import SMOTETomek, SMOTEENN<br/><br/># Create a DataFrame from the dataset<br/>data = {<br/>    'Temperature': [1, 0, 1, 3, 2, 3, 1, 3, 4],<br/>    'Humidity': [0, 2, 1, 1, 3, 2, 3, 4, 4],<br/>    'Activity': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C']<br/>}<br/>df = pd.DataFrame(data)<br/><br/># Split the data into features (X) and target (y)<br/>X, y = df[['Temperature', 'Humidity']], df['Activity'].astype('category')<br/><br/># Initialize a resampling method<br/># sampler = RandomOverSampler()       # Random OverSampler for oversampling<br/>sampler = SMOTE()                     # SMOTE for oversampling<br/># sampler = ADASYN()                  # ADASYN for oversampling<br/># sampler = RandomUnderSampler()      # Random UnderSampler for undersampling<br/># sampler = TomekLinks()              # Tomek Links for undersampling<br/># sampler = NearMiss(version=1)       # NearMiss-1 for undersampling<br/># sampler = EditedNearestNeighbours() # ENN for undersampling<br/># sampler = SMOTETomek()              # SMOTETomek for a combination of oversampling &amp; undersampling<br/># sampler = SMOTEENN()                # SMOTEENN for a combination of oversampling &amp; undersampling<br/><br/># Apply the resampling method<br/>X_resampled, y_resampled = sampler.fit_resample(X, y)<br/><br/># Print the resampled dataset<br/>print("Resampled dataset:")<br/>print(X_resampled)<br/>print(y_resampled)</span></pre></div></div></div><div class="ab cb qi qj qk ql" role="separator"><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo qp"/><span class="qm by bm qn qo"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="46f7" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">Technical Environment</h2><p id="f7a9" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">This article uses Python 3.7, pandas 1.3, and imblearn 1.2. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="aaa6" class="pe oj fq bf ok pf pg ph on pi pj pk oq nl pl pm pn np po pp pq nt pr ps pt fw bk">About the Illustrations</h2><p id="c97f" class="pw-post-body-paragraph nc nd fq ne b gt pu ng nh gw pv nj nk nl pw nn no np px nr ns nt py nv nw nx fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p><p id="c7b4" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:</p><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Data Preprocessing</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">6 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="" class="dz" src="../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*T1bcJ8sv5Rc1lsOyGS1nig.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="Cartoon illustration of two figures embracing, with letters ‘A’, ‘B’, ‘C’ and numbers ‘1’, ‘2’, ‘3’ floating around them. A pink heart hovers above, symbolizing affection. The background is a pixelated pattern of blue and green squares, representing data or encoding. This image metaphorically depicts the concept of encoding categorical data, where categories (ABC) are transformed into numerical representations (123)." class="dz" src="../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2_cXKHvfaBTVpDrmz5r5vQ.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="A cartoon illustration representing data scaling in machine learning. A tall woman (representing a numerical feature with a large range) is shown shrinking into a child (representing the same feature after scaling to a smaller range). A red arrow indicates the shrinking process, and yellow sparkles around the child signify the positive impact of scaling." class="dz" src="../Images/d261b2c52a3cafe266d1962d4dbabdbd.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*MkX5TTTS1oZhY2eW6AdEkg.png"/></div></div></div></div></div><p id="595f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:</p><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Regression Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----1155577d3091--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">5 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="A cartoon doll with pigtails and a pink hat. This “dummy” doll, with its basic design and heart-adorned shirt, visually represents the concept of a dummy regressor in machine. Just as this toy-like figure is a simplified, static representation of a person, a dummy regressor is a basic models serve as baselines for more sophisticated analyses." class="dz" src="../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="" class="dz" src="../Images/44e6d84e61c895757ff31e27943ee597.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*nMaPpVdNqCci31YmjfCMRQ.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="" class="dz" src="../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qTpdMoaZClu-KDV3nrZDMQ.png"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>