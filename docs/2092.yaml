- en: How to Easily Set Up a Neat User Interface for Your Local LLM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28](https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A step-by-step guide to run Llama3 locally with Open WebUI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Guillaume
    Weingertner](../Images/fbfb34af986a7788394b6033c6954d57.png)](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    [Guillaume Weingertner](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    ·6 min read·Aug 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b758ee77d1c941a6348673fd2974348.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by AI (Midjourney) by Author
  prefs: []
  type: TYPE_NORMAL
- en: '#1 Why Local LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether it’s due to company restrictions or a desire to handle personal data
    securely, many have avoided using ChatGPT due to data privacy concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, there are solutions that allow **unlimited** use of LLMs without
    sending sensitive data to the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: In my previous article, I explored one such solution by explaining how to run
    Llama 3 locally thanks to Ollama.
  prefs: []
  type: TYPE_NORMAL
- en: '[](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
    [## Running Local LLMs is More Useful and Easier Than You Think'
  prefs: []
  type: TYPE_NORMAL
- en: A step-by-step guide to run Llama3 locally with Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**PREREQUISITE**: by the end of that last article we had Llama 3 running locally
    thanks to Ollama and we could use it either through the terminal or within a Jupyter
    Notebook.'
  prefs: []
  type: TYPE_NORMAL
- en: In this article I explain how to make the use of local LLMs more user-friendly
    through a neat UI in a matter of minutes!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
