<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Tackle Complex LLM Decision-Making with Language Agent Tree Search (LATS) & GPT-4o</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Tackle Complex LLM Decision-Making with Language Agent Tree Search (LATS) & GPT-4o</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26">https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="9eaf" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Enhancing LLM decision-making: integrating language agent tree search with GPT-4o for superior problem-solving</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------" rel="noopener  ugc nofollow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Ozgur Guler" class="l ep by dd de cx" src="../Images/0fa0f9412fddfff81c9004af33e277e8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*cJACdBGRhiZP2coV0-C18g.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------" rel="noopener  ugc nofollow">Ozgur Guler</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/1af94ed3cff9126b91f6176f1e210758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ko-TYWtzJhZNistEhQSwwQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: midjourney — abstract puzzle</figcaption></figure><p id="6846" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Large Language Models (LLMs) have demonstrated exceptional abilities in performing natural language tasks that involve complex reasoning. As a result, these models have evolved to function as agents capable of planning, strategising, and solving complex problems. However, challenges persist when it comes to making decisions under uncertainty, where outcomes are not deterministic, or when adaptive decision-making is required in changing environments, especially in multi-step scenarios where each step influences the next. We need more advanced capabilities…</p><p id="dbdb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This is where GPT-4’s advanced reasoning capabilities and Language Agent Tree Search (LATS) come together to address these challenges. LATS incorporates a dynamic, tree-based search methodology that enhances the reasoning capabilities of GPT-4O. By integrating Monte Carlo Tree Search (MCTS) with LLMs, LATS unifies reasoning, acting, and planning, creating a more deliberate and adaptive problem-solving framework. This powerful combination allows for improved decision-making and more robust handling of complex tasks, setting a new standard in the deployment of language models as autonomous agents.</p><h2 id="4b77" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">Is “search” the missing piece in GenAI problem solving?</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/2a16198d5a97e718d980dec57e08a408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R42x6oYWgndzHqnqTWTTlw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: midjourney — abstract puzzle</figcaption></figure><p id="750d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Computational problem solving can be broadly defined as “<strong class="nd fr"><em class="os">search through a combinatorial problem space</em></strong>”, represented as a tree. <a class="af ot" href="https://en.wikipedia.org/wiki/Depth-first_search" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">Depth-First Search (DFS)</strong></a> and <a class="af ot" href="https://en.wikipedia.org/wiki/Breadth-first_search" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">Breadth-First Search (BFS)</strong> </a>are fundamental methods for exploring such solution spaces. A notable example of the power of deep search is AlphaGo’s “<a class="af ot" href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol" rel="noopener ugc nofollow" target="_blank">Move 37,”</a> which showcased how innovative, human-surpassing solutions can emerge from extensive exploration.</p><p id="2062" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Unlike traditional methods that follow <strong class="nd fr">predefined paths</strong>, LLMs can dynamically generate new branches within the solution space by predicting potential outcomes, strategies, or actions based on context. This capability allows LLMs to not only navigate but also expand the problem space, making them exceptionally powerful in situations where the problem structure is not fully known, is continuously evolving, or is highly complex.</p><h2 id="4bc4" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">Inference-time Reasoning with Meta Generation Algorithms (MGA)</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/6678b242a08f9b2c8c2ea23a1627ce23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFDSD1E82T5Byerqjqv1rw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: midjourney — abstract puzzle</figcaption></figure><p id="341a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Scaling compute during training is widely recognised for its ability to improve model performance. <strong class="nd fr">The benefits of scaling compute during inference remain under-explored.</strong> MGA’s offer a novel approach by amplifying computational resources during inference…</p><p id="cb6c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Unlike traditional token-level generation methods, meta-generation algorithms employ higher-order control structures such as planning, loops with multiple model calls, self-reflection, task decomposition, and dynamic conditioning. These mechanisms allow the model to execute tasks end-to-end, mimicking higher-level cognitive processes often referred to as Systems-2 thinking.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ou"><img src="../Images/398973dd49349edcc22c35cf5384dc0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2bMSRBLmOzM65kxC1ewb7w.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: Inference-time Reasoning methods — summarised</figcaption></figure><p id="1aca" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Therefore one-way meta generation algorithms may enhance LLM reasoning by integrating search into the generation process</strong>. During inference, MGA’s dynamically explore a broader solution space, allowing the model to reason through potential outcomes and adapt strategies in real-time. By generating multiple paths and evaluating their viability, meta generation algorithms enable LLMs to simulate deeper, more complex reasoning akin to traditional search methods. This approach not only expands the model’s ability to generate novel insights but also improves decision-making in scenarios with incomplete or evolving information.</p><p id="29cb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Techniques like <strong class="nd fr">Tree of Thoughts (ToT)</strong>, and <strong class="nd fr">Graph of Thought (GoT)</strong> are employed to navigate combinatorial solution spaces efficiently.</p><ul class=""><li id="54c9" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ov ow ox bk"><strong class="nd fr">ToT</strong> (<em class="os">2*</em>) enables hierarchical decision-making by structuring potential outcomes as tree branches, facilitating exploration of multiple paths.</li><li id="9769" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">GoT (</strong><em class="os">6*</em><strong class="nd fr">)</strong>maps complex relationships between ideas, allowing the model to dynamically adjust and optimize its reasoning path.</li><li id="82c6" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">CoT</strong> (<em class="os">5*</em>) provides step-by-step reasoning that links sequential thoughts, improving the coherence and depth of the generation.</li></ul><h1 id="fb10" class="pd ny fq bf nz pe pf gq od pg ph gt oh pi pj pk pl pm pn po pp pq pr ps pt pu bk">Why is MCTS better ?</h1><p id="d163" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk">In the Tree of Thoughts (ToT) approach, traditional methods like Depth-First Search (DFS) or Breadth-First Search (BFS) can navigate this tree, but they are computationally expensive because they explore each possible path systematically &amp; exhaustively.</p><p id="ca0a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Monte Carlo Tree Search (MCTS) is an improvement on this by simulating different outcomes for actions and updating the tree based on these simulations. It uses a “selection” process where it picks decision nodes using a strategy that balances exploration (trying new paths) and exploitation (choosing known good paths). This is guided by a formula called Upper Confidence Bound (UCB).</p><p id="b99a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The UCB formula has two key parts:</p><ol class=""><li id="2061" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qa ow ox bk"><strong class="nd fr">Exploration Term:</strong> This represents the potential reward of choosing a node and is calculated through simulations.</li><li id="c053" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw qa ow ox bk"><strong class="nd fr">Exploitation Term:</strong> This decreases the deeper you go into a certain path, meaning that if a path is over-explored, the algorithm may shift to a less-explored path even if it seems less promising initially.</li></ol><p id="6845" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">By selecting nodes using UCB, simulating outcomes (rewards) with LLMs, and back-propagating the rewards up the tree, MCTS effectively balances between exploring new strategies and exploiting known successful ones.</p><p id="9480" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The second part of the UCB formula is the <strong class="nd fr">‘exploitation term,’</strong> which decreases as you explore deeper into a specific path. This decrease may lead the selection algorithm to switch to another path in the decision tree, even if that path has a lower immediate reward, because the exploitation term remains higher when that path is less explored.</p><p id="1c96" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Node selection with UCB, reward calculations with LLM simulations and backpropagation are the essence of MCTS.</p><h2 id="b746" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">An Implementation — Financial Decision Making…</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qb"><img src="../Images/3710dd691db8b2ce49c431938a9ad80f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_lxvu0XVCYjonRJqX0Txg.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">LATS operation (1*) <a class="af ot" href="https://arxiv.org/pdf/2310.04406" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2310.04406</a></figcaption></figure><p id="8242" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For the sake of demonstration we will use LATS to solve the challenging problem of coming up with the optimal investment strategy in todays macroeconomic climate. We will feed LLM with the macro-economic statu susing the “IMF World Economic Outlook Report” as the context simply summarising the document. RAG is not used. Below is an example as to how LATS searches through the solution space…</p><h2 id="88cd" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">Iteration 1:</h2><ol class=""><li id="d0b0" class="nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw qa ow ox bk"><strong class="nd fr">Selection: </strong>We start at the root node, and since this is the first LATS iteration, we will select all initial decision nodes generated by the LLM (A, B, and C nodes) and simulate their outcomes.</li><li id="f1a0" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw qa ow ox bk"><strong class="nd fr">Simulation &amp; Backpropagation: </strong>Next<strong class="nd fr"> </strong>LLM “simulates” each strategy based on the context it has and assigns the following “rewards” — investment returns — to each “node”.</li></ol><ul class=""><li id="0a3d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ov ow ox bk"><strong class="nd fr">Strategy A</strong>: $5,000</li><li id="24bf" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">Strategy B</strong>: $7,000</li><li id="55d7" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">Strategy C</strong>: $4,000</li></ul><p id="583d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">3. <strong class="nd fr">Expansion: </strong>Based on the selection, <strong class="nd fr">Strategy B</strong> has the highest UCB1 value (since all nodes are at the same depth), so we expand only <strong class="nd fr">Strategy B</strong> by simulating its child nodes.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qc"><img src="../Images/dbce1fa357313bed6d2079283a726f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvBpEGEFacwc-O7GhfMJfw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: B node expanded as it has the higher simulated reward value</figcaption></figure><h2 id="b5fb" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">Iteration 2:</h2><ol class=""><li id="f6ec" class="nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw qa ow ox bk"><strong class="nd fr">Selection</strong>: Since B1 &amp; B2 strategies are not simulated, there is a tie in terms of their UCB scores and both nodes will be simulated.</li><li id="ce1a" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw qa ow ox bk"><strong class="nd fr">Simulate Both Nodes</strong>:</li></ol><ul class=""><li id="e43d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ov ow ox bk"><strong class="nd fr">Simulate B1</strong>: LLM predicts a return of <strong class="nd fr">$8,500</strong> for <strong class="nd fr">B1</strong>.</li><li id="7093" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">Simulate B2</strong>: LLM predicts a return of <strong class="nd fr">$7,500</strong> for <strong class="nd fr">B2</strong>.</li></ul><p id="7636" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">3. <strong class="nd fr">Backpropagation</strong>:</p><p id="d5a6" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">After each simulation, results of the simulation are back-propagated up the tree, updating the values of the parent nodes. This step ensures that the impact of the new information is reflected throughout the tree.</p><p id="b558" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Updating Strategy B’s Value</strong>:<strong class="nd fr"> Strategy B </strong>now needs to reflect the outcomes of <strong class="nd fr">B1</strong> and <strong class="nd fr">B2</strong>. One common approach is to average the rewards of <strong class="nd fr">B1</strong> and <strong class="nd fr">B2</strong> to update <strong class="nd fr">Strategy B</strong>’s value. Now, <strong class="nd fr">Strategy B</strong> has an updated value of <strong class="nd fr">$8,000</strong> based on the outcomes of its child nodes.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qd"><img src="../Images/bc33d70a8576e8f639748eacc8d2360a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8FMOVg0sW4ZxqAfiKMPOw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: Strategy B reward value is updated following backpropagation</figcaption></figure><p id="4000" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">4. <strong class="nd fr">Recalculate UCB Scores:</strong></p><p id="1218" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">After backpropagation, the UCB scores <strong class="nd fr">for all nodes in the tree</strong> are recalculated. This recalculation uses the updated values (average rewards) and visit counts, ensuring that each node’s UCB1 score accurately reflects both its potential reward and how much it has been explored.</p><p id="e68a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">UCB(s) = (exploration/reward term)+ (exploitation term)</p><p id="2520" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Note again the exploitation term decreases for all nodes on a path that is continously explored deeper.</p><p id="8810" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">5. Next selection &amp; simulation:</strong></p><p id="7e7f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">B1</strong> is selected for further expansion (as it has the higher reward) into child nodes:</p><ul class=""><li id="cf4d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ov ow ox bk"><strong class="nd fr">B1a</strong>: “Invest in AI companies”</li><li id="8895" class="nb nc fq nd b go oy nf ng gr oz ni nj nk pa nm nn no pb nq nr ns pc nu nv nw ov ow ox bk"><strong class="nd fr">B1b</strong>: “Invest in green tech”</li></ul><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qe"><img src="../Images/da47d0a75d12cd098eebbf2a64845349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RVXM1vYjj_ik4nwBhCKfnw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: B1 node is expanded further as it has the higher reward</figcaption></figure><p id="f434" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">6. <strong class="nd fr">Backpropagation:</strong></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qf"><img src="../Images/0e80b6cb8ff2fcd14c6e1672b6db1165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y2edztQ91etkTh4jaVztCw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: Child node rewards are backpropagated upwards</figcaption></figure><p id="ae7b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">B1 reward updated as (9200 + 6800) / 2 = 8000</p><p id="5c67" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">B reward updated as (8000 + 7500) / 2 = 7750</p><p id="0bcb" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">7.UCB Calculation:</strong></p><p id="ddca" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Following backpropagation UCB values of all nodes are recalculated. Assume that due to the decaying exploration factor, <strong class="nd fr">B2</strong> now has a higher UCB score than both <strong class="nd fr">B1a</strong> and <strong class="nd fr">B1b</strong>. This could occur if <strong class="nd fr">B1</strong> has been extensively explored, reducing the exploration term for its children. Instead of continuing to expand <strong class="nd fr">B1</strong>’s children, the algorithm shifts back to explore <strong class="nd fr">B2</strong>, which has become more attractive due to its unexplored potential i.e. higher exploitation value.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qg"><img src="../Images/1f27254ac66074364aa2ee0ff364b4c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ImbFEpcPLAyWHHyfuL-VjA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: When a path through a node is explored deeper exploitation value of the node decreases which may trigger a branch switch — a new path through a new decision node to be explored further</figcaption></figure><p id="df93" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This example illustrates how MCTS can dynamically adjust its search path based on new information, ensuring that the algorithm remains efficient and focused on the most promising strategies as it progresses.</p><h2 id="67b7" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">An Implementation with Azure OpenAI GPT-4o</h2><p id="675c" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk">Next we will build a “financial advisor” using GPT-4o, implementing LATS. (Please refer to the Github repo <a class="af ot" href="https://github.com/ozgurgulerx/llm-reasoning-lats/tree/main" rel="noopener ugc nofollow" target="_blank">here</a> for the code.)</p><p id="4976" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">(For an accurate analysis I am using the </em><a class="af ot" href="https://www.imf.org/en/Publications/WEO" rel="noopener ugc nofollow" target="_blank"><em class="os">IMF World Economic Outlook report </em></a><em class="os">from July, 24 as my LLM context for simulations i.e. for generating child nodes and for assigning rewards to decision nodes …)</em></p><p id="22fc" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Here is how the code runs…</p><figure class="ml mm mn mo mp mq"><div class="qh io l ed"><div class="qi qj l"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">LATS iterating MCTS over the decision tree, creating new nodes and exploring the tree</figcaption></figure><p id="95ee" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The code leverages the <code class="cx qk ql qm qn b">graphviz</code> library to visually represent the decision tree generated during the execution of the investment strategy simulations. Decision tree is too wide and cannot fit into a single picture hence I have added snippets as to how the tree looks below. You can find a sample decision tree in the github repo <a class="af ot" href="https://github.com/ozgurgulerx/llm-reasoning-lats/blob/main/investment_decision_tree_with_optimal_path.pdf" rel="noopener ugc nofollow" target="_blank">here</a>…</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qo"><img src="../Images/be7c8818cadaa56d25b6e271fecc3611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uGUjzF-NCApwDzgfh8qZ9g.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: Sample run of the MCTS code to find the best investment strategy in current macroeconomic climate</figcaption></figure><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qp"><img src="../Images/b8b3f1f0093188458ab090f95a3b765d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z40muEJiAdMD4BDAgHI7YQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by the author: Screen capture from the generated decision tree</figcaption></figure><p id="3a59" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Below is the optimal strategy inferred by LATS…</p><pre class="ml mm mn mo mp qq qn qr bp qs bb bk"><span id="0efa" class="qt ny fq qn b bg qu qv l qw qx">Optimal Strategy Summary: The optimal investment strategy is structured around several key steps influenced by the IMF report. Here's a concise summary of each step and its significance:<br/>1. **Diversification Across Geographies and Sectors:**<br/> - **Geographic Diversification:** This involves spreading investments across regions to mitigate risk and tap into different growth potentials. Advanced economies like the U.S. remain essential due to their robust consumer spending and resilient labor market, but the portfolio should include cautious weighting to manage risks. Simultaneously, emerging markets in Asia, such as India and Vietnam, are highlighted for their higher growth potential, providing opportunities for higher returns.<br/> - **Sector Diversification:** Incorporating investments in sectors like green energy and sustainability reflects the growing global emphasis on renewable energy and environmentally friendly technologies. This also aligns with regulatory changes and consumer preferences, creating future growth opportunities.<br/>2. **Green Energy and Sustainability:**<br/> - Investing in green energy demonstrates foresight into the global shift toward reducing carbon footprints and reliance on fossil fuels. This is significant due to increased governmental supports, such as subsidies and policy incentives, which are likely to propel growth within this sector.<br/>3. **Fintech and E-Commerce:**<br/> - Allocating capital towards fintech and e-commerce companies capitalizes on the digital transformation accelerated by the global shift towards digital platforms. This sector is expected to grow due to increased adoption of online services and digital payment systems, thus presenting promising investment opportunities.</span></pre><h2 id="8c7d" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">Conclusion:</h2><p id="6237" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk">By integrating LATS, we harness the reasoning capabilities of LLMs to simulate and evaluate potential strategies dynamically. This combination allows for the construction of decision trees that not only represent the logical progression of decisions but also adapt to changing contexts and insights, provided by the LLM through simulations and reflections.</p><p id="8451" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">(Unless otherwise noted, all images are by the author)</p><h2 id="28a7" class="nx ny fq bf nz oa ob oc od oe of og oh nk oi oj ok no ol om on ns oo op oq or bk">References:</h2><p id="fe93" class="pw-post-body-paragraph nb nc fq nd b go pv nf ng gr pw ni nj nk px nm nn no py nq nr ns pz nu nv nw fj bk"><em class="os">[1] Language Agent Tree Search: Unifying Reasoning, Acting, and Planning in Language Models</em> by Zhou et al</p><p id="af94" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[2] Tree of Thoughts: Deliberate Problem Solving with Large Language Models</em> by Yao et al</p><p id="05ca" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[3] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey</em> by Tula Masterman, Mason Sawtell, Sandi Besen, and Alex Chao</p><p id="6377" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[4] From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson</em>, Hailey Schoelkopf*, Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.</p><p id="db98" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[5] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models </em>by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou</p><p id="1562" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[7] Graph of Thoughts: Solving Elaborate Problems with Large Language Models</em> by Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michał Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler.</p><p id="ccc5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="os">[8] From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.</em></p></div></div></div></div>    
</body>
</html>