<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Data-Driven Journey Optimization: Using Deep Learning to Design Customer Journeys</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Data-Driven Journey Optimization: Using Deep Learning to Design Customer Journeys</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-driven-journey-optimization-using-deep-learning-to-design-customer-journeys-93a3f8e92956?source=collection_archive---------5-----------------------#2024-11-06">https://towardsdatascience.com/data-driven-journey-optimization-using-deep-learning-to-design-customer-journeys-93a3f8e92956?source=collection_archive---------5-----------------------#2024-11-06</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e12a" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Can ML models learn to construct optimal customer journeys?</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@brechterlaurin?source=post_page---byline--93a3f8e92956--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Laurin Brechter" class="l ep by dd de cx" src="../Images/5a68b96bddf86846a2bef9d482ef9dd3.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*QHmK9X-MGra2e-1yZwCa2Q.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--93a3f8e92956--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@brechterlaurin?source=post_page---byline--93a3f8e92956--------------------------------" rel="noopener follow">Laurin Brechter</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--93a3f8e92956--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 6, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/141b852186fec6412524cd5d8908e7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yHXbhpXlXtaOJLW8_HTmw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Optimizing Customer Journeys with Beam Search</figcaption></figure><p id="82d1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Marketing attribution has traditionally been backward-looking: analyzing past customer journeys to understand which touchpoints contributed to conversion. But what if we could use this historical data to design optimal future journeys? In this post, I’ll show how we can combine deep learning with optimization techniques to design high-converting customer journeys while respecting real-world constraints. We will do so by using an LSTM to predict journeys with high conversion probability and then using beam search to find sequences with good chances of conversion. All images are created by the author.</p><h1 id="8d23" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Introduction</h1><p id="d252" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Customers interact with businesses on what we can call a customer journey. On this journey, they come into contact with the company through so-called touchpoints (e.g., Social Media, Google Ads, …). At any point, users could convert (e.g. by buying your product). We want to know what touchpoints along that journey contributed to the conversion to optimize the conversion rate.</p><h1 id="f44e" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">The Limitations of Traditional Attribution</h1><p id="317b" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Before diving into our solution, it’s important to understand why traditional attribution models fall short.</p><h2 id="e502" class="oy ny fq bf nz oz pa pb oc pc pd pe of nk pf pg ph no pi pj pk ns pl pm pn po bk">1. Position-Agnostic Attribution</h2><p id="bef5" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Traditional attribution models (first-touch, last-touch, linear, etc.) typically assign a single importance score to each channel, regardless of where it appears in the customer journey. This is fundamentally flawed because:</p><ul class=""><li id="bbda" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk">A social media ad might be highly effective early in the awareness stage but less impactful during consideration</li><li id="93a9" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Email effectiveness often depends on whether it’s a welcome email, nurture sequence, or re-engagement campaign</li><li id="dd58" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Retargeting ads make little sense as a first touchpoint but can be powerful later in the journey</li></ul><h2 id="9802" class="oy ny fq bf nz oz pa pb oc pc pd pe of nk pf pg ph no pi pj pk ns pl pm pn po bk">2. Context Blindness</h2><p id="c348" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Most attribution models (even data-driven ones) ignore crucial contextual factors:</p><ul class=""><li id="738e" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk"><strong class="nd fr">Customer Characteristics</strong>: A young tech-savvy customer might respond differently to digital channels compared to traditional ones</li></ul><pre class="ml mm mn mo mp px py pz bp qa bb bk"><span id="ce48" class="qb ny fq py b bg qc qd l qe qf">Customer 1 (Young, Urban): Social → Video → Purchase<br/>Customer 2 (Older, Rural): Print → Email → Purchase</span></pre><ul class=""><li id="4baa" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk"><strong class="nd fr">Previous Purchase History</strong>: Existing customers often require different engagement strategies than new prospects</li><li id="597e" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk"><strong class="nd fr">Time of Day/Week</strong>: Channel effectiveness can vary significantly based on timing</li><li id="65dd" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk"><strong class="nd fr">Device/Platform</strong>: The same channel might perform differently across different platforms</li><li id="ec35" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk"><strong class="nd fr">Geographic/Cultural Factors</strong>: What works in one market might fail in another</li></ul><h2 id="f2d4" class="oy ny fq bf nz oz pa pb oc pc pd pe of nk pf pg ph no pi pj pk ns pl pm pn po bk">3. Static Channel Values</h2><p id="90c9" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Traditional models assume channel effectiveness can be expressed as a single number where all other factors influencing the effectiveness are marginalized. As mentioned above, channel effectiveness is highly context-dependent and should be a function of said context (e.g. position, other touchpoints, …).</p><h1 id="1c39" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Deep Learning Enters the Stage</h1><p id="80a9" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Customer journeys are inherently sequential — the order and timing of touchpoints matter. We can frame attribution modeling as a <em class="qg">binary time series classification</em> task where we want to predict from the sequence of touchpoints whether a customer converted or not. This makes them perfect candidates for sequence modeling using R<em class="qg">ecurrent Neural Networks</em> (RNNs), specifically <em class="qg">Long Short-Term Memory</em> (LSTM) networks. These models can capture complex patterns in sequential data, including:</p><ul class=""><li id="9204" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk">The effectiveness of different channel combinations</li><li id="cf8f" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">The importance of touchpoint ordering</li><li id="7c06" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Timing sensitivities</li><li id="1968" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Channel interaction effects</li></ul><h2 id="4d2a" class="oy ny fq bf nz oz pa pb oc pc pd pe of nk pf pg ph no pi pj pk ns pl pm pn po bk">Learning from Historical Data</h2><p id="8934" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">The first step is to train an LSTM model on historical customer journey data. For each customer, we need:</p><ol class=""><li id="d6e6" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw qh pq pr bk">The sequence of touchpoints they encountered</li><li id="b801" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw qh pq pr bk">Whether they ultimately converted</li><li id="292b" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw qh pq pr bk">Characteristics of the customer</li></ol><p id="875d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The LSTM learns to predict conversion probability given any sequence of touchpoints. This gives us a powerful “simulator” that can evaluate the likely effectiveness of any proposed customer journey.</p><p id="54d5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As I did not find a suitable dataset (especially one that contains customer characteristics as the contextual data), I decided to generate my own synthetic data. The notebook for the data generation can be found <a class="af qi" href="https://github.com/LaurinBrechter/PatternMining/blob/main/attribution_modelling.ipynb" rel="noopener ugc nofollow" target="_blank">here</a>. We generate some characteristics and a random number of customer journeys for each customer. The journeys are of random length. At each point in the journey, the customer interacts with a touchpoint and has a probability of converting. This probability is composed of multiple factors.</p><ul class=""><li id="ecd5" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk">The base conversion rate of the channel</li><li id="cf8e" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">A positional multiplier. Some channels are more or less effective in some positions of the journey.</li><li id="f02b" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">A segment multiplier. The channel's effectiveness depends on the segment of the customer.</li><li id="072d" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">We also have interaction effects. E.g. if the user is young, touchpoints such as social and search will be more effective.</li><li id="acba" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Additionally, the previous touchpoint matters for the effectiveness of the current touchpoint.</li></ul></div></div><div class="mq"><div class="ab cb"><div class="ll qj lm qk ln ql cf qm cg qn ci bh"><div class="ml mm mn mo mp ab ke"><figure class="le mq qo qp qq qr qs paragraph-image"><img src="../Images/7851800686a72b45682b42118fd66169.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*lawcSYyX_BoBrueT8FJqAQ.png"/></figure><figure class="le mq qt qp qq qr qs paragraph-image"><img src="../Images/53ae754078112929b1a802d2ef534af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*fBfx797J4AjkMeI-14FuZQ.png"/><figcaption class="mw mx my mi mj mz na bf b bg z dx qu ed qv qw">Journey Data (Left) and User Data (Right)</figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="ca34" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We then preprocess the data by merging the two tables, scaling the numerical features, and OneHotEncoding the categorical features. We can then set up an LSTM model that processes the sequences of touchpoints after embedding them. In the final fully connected layer, we also add the contextual features of the customer. The full code for preprocessing and training can be found in this <a class="af qi" href="https://github.com/LaurinBrechter/PatternMining/blob/main/attribution_modelling.ipynb" rel="noopener ugc nofollow" target="_blank">notebook</a>.</p><p id="8b70" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We can then train the neural network with a binary cross-entropy loss. I have plotted the recall achieved on the test set below. In this case, we care more about recall than accuracy as we want to detect as many converting customers as possible. Wrongly predicting that some customers will convert if they don’t is not as bad as missing high-potential customers.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qx"><img src="../Images/5998b8c4871c80ab6116a6a598fd04de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*XS2DnUHaeTw8ZYrmg8AVVA.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Training the JourneyLSTM</figcaption></figure><p id="ae64" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Additionally, we will find that most journeys do not lead to a conversion. We will typically see conversion rates from 2% to 7% which means that we have a highly imbalanced dataset. For the same reason, accuracy isn’t all that meaningful. Always predicting the majority class (in this case ‘no conversion’) will get us a very high accuracy but we won’t find any of the converting users.</p><h1 id="f165" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">From Prediction to Optimization</h1><p id="5f5e" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Once we have a trained model, we can use it to design optimal journeys. We can impose a sequence of channels (in the example below channel 1 then 2) on a set of customers and look at the conversion probability predicted by the model. We can already see that these vary a lot depending on the characteristics of the customer. Therefore, we want to optimize the journey for each customer individually.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qy"><img src="../Images/d571bec702bb098ab68e075be6b6b91c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*EoABJFj4gJeQ5Q-PkWHd0g.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Imposed Journeys and Predicted Conversion Probabilities</figcaption></figure><p id="b1f4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Additionally, we can’t just pick the highest-probability sequence. Real-world marketing has constraints:</p><ul class=""><li id="58d4" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw pp pq pr bk">Channel-specific limitations (e.g., email frequency caps)</li><li id="33d8" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Required touchpoints at specific positions</li><li id="6aba" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Budget constraints</li><li id="b248" class="nb nc fq nd b go ps nf ng gr pt ni nj nk pu nm nn no pv nq nr ns pw nu nv nw pp pq pr bk">Timing requirements</li></ul><p id="8dd8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Therefore, we frame this as a constrained combinatorial optimization problem: find the sequence of touchpoints that maximizes the model’s predicted conversion probability while satisfying all constraints. In this case, we will only constrain the occurrence of touchpoints at certain places in the journey. That is, we have a mapping from position to touchpoint that specifies that a certain touchpoint must occur at a given position.</p><p id="2677" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Note also that we aim to optimize for a predefined journey length rather than journeys of arbitrary length. By the nature of the simulation, the overall conversion probability will be strictly monotonically increasing as we have a non-zero conversion probability at each touchpoint. Therefore, a longer journey (more non-zero entries) would trump a shorter journey most of the time and we would construct infinitely long journeys.</p><h2 id="2899" class="oy ny fq bf nz oz pa pb oc pc pd pe of nk pf pg ph no pi pj pk ns pl pm pn po bk">Optimization using Beam Search</h2><p id="1947" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Below is the implementation for beam search using recursion. At each level, we optimize a certain position in the journey. If the position is in the constraints and already fixed, we skip it. If we have reached the maximum length we want to optimize, we stop recursing and return.</p><p id="4ed2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">At each level, we look at current solutions and generate candidates. At any point, we keep the best K candidates defined by the beam width. Those best candidates are then used as input for the next round of beam search where we optimize the next position in the sequence.</p><pre class="ml mm mn mo mp px py pz bp qa bb bk"><span id="c495" class="qb ny fq py b bg qc qd l qe qf">def beam_search_step(<br/>        model: JourneyLSTM, <br/>        X: torch.Tensor, <br/>        pos: int, <br/>        num_channels: int, <br/>        max_length: int, <br/>        constraints:dict[int, int], <br/>        beam_width: int = 3<br/>    ):<br/>    if pos &gt; max_length:<br/>        return X<br/>    <br/>    if pos in constraints:<br/>        return beam_search_step(model, X, pos + 1, num_channels, max_length, constraints, beam_width)<br/>    <br/>    candidates = []  # List to store (sequence, score) tuples<br/>    <br/>    for sequence_idx in range(min(beam_width, len(X))):<br/>        X_current = X[sequence_idx:sequence_idx+1].clone()<br/>        <br/>        # Try each possible channel<br/>        for channel in range(num_channels):<br/>            X_candidate = X_current.clone()<br/>            X_candidate[0, extra_dim + pos] = channel<br/>            <br/>            # Get prediction score<br/>            pred = model(X_candidate)[0].item()<br/>            candidates.append((X_candidate, pred))<br/>    <br/>    candidates.sort(key=lambda x: x[1], reverse=True)<br/>    best_candidates = candidates[:beam_width]<br/>    <br/>    X_next = torch.cat([cand[0] for cand in best_candidates], dim=0)<br/>    <br/>    # Recurse with best candidates<br/>    return beam_search_step(model, X_next, pos + 1, num_channels, max_length, constraints, beam_width)</span></pre><p id="1d6d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This optimization approach is greedy and we are likely to miss high-probability combinations. Nonetheless, in many scenarios, especially with many channels, brute forcing an optimal solution may not be feasible as the number of possible journeys grows exponentially with the journey length.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/141b852186fec6412524cd5d8908e7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yHXbhpXlXtaOJLW8_HTmw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Optimizing Customer Journeys with Beam Search</figcaption></figure><p id="7867" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In the image above, we optimized the conversion probability for a single customer. In position 0, we have specified ‘email’ as a fixed touchpoint. Then, we explore possible combinations with email. Since we have a beam width of five, all combinations (e.g. email -&gt; search) go into the next round. In that round, we discovered the high-potential journey which would display the user two times email and finally retarget.</p><h1 id="c337" class="nx ny fq bf nz oa ob gq oc od oe gt of og oh oi oj ok ol om on oo op oq or os bk">Conclusion</h1><p id="fb26" class="pw-post-body-paragraph nb nc fq nd b go ot nf ng gr ou ni nj nk ov nm nn no ow nq nr ns ox nu nv nw fj bk">Moving from prediction to optimization in attribution modeling means we are going from predictive to prescriptive modeling where the model tells us actions to take. This has the potential to achieve much higher conversion rates, especially when we have highly complex scenarios with many channels and contextual variables.</p><p id="fd7d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">At the same time, this approach has several drawbacks. Firstly, if we do not have a model that can detect converting customers sufficiently well, we are likely to harm conversion rates. Additionally, the probabilities that the model outputs have to be calibrated well. Otherwiese, the conversion probabilities we are optimizing for are likely not meanningful. Lastly, we will encounter problems when the model has to predict journeys that are outside of its data distribution. It would therefore also be desirable to use a Reinforcement Learning (RL) approach, where the model can actively generate new training data.</p></div></div></div></div>    
</body>
</html>