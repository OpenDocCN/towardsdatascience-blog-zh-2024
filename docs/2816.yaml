- en: Building a Research Agent That Can Write to Google Docs (Part 1)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-research-agent-that-can-write-to-google-docs-part-1-4b49ea05a292?source=collection_archive---------6-----------------------#2024-11-20](https://towardsdatascience.com/building-a-research-agent-that-can-write-to-google-docs-part-1-4b49ea05a292?source=collection_archive---------6-----------------------#2024-11-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/467c2bf3a8c599809df9567803dcb8fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Dalle-3’s interpretation of “A quirky AI assistant hard at work checking documents”.
    Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: A tool that might help with your homework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rmartinshort?source=post_page---byline--4b49ea05a292--------------------------------)[![Robert
    Martin-Short](../Images/e3910071b72a914255b185b850579a5a.png)](https://medium.com/@rmartinshort?source=post_page---byline--4b49ea05a292--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4b49ea05a292--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4b49ea05a292--------------------------------)
    [Robert Martin-Short](https://medium.com/@rmartinshort?source=post_page---byline--4b49ea05a292--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4b49ea05a292--------------------------------)
    ·15 min read·Nov 20, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '***This article is the first of a two part series where we use LangGraph and
    Tavily to build a simple research agent, which writes and refines short articles.
    To keep track of the plans, articles and comments it generates we add the ability
    to programmatically create and edit Google Docs. In this article we focus on the
    agent, leaving the docs connection to the second article. You can find all the
    relevant code*** [***here***](https://github.com/rmartinshort/research_assist)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) are quickly finding use in all sorts of applications
    relevant to analysts and researchers, especially when it comes to the extraction,
    organization and summarization of text information. The community — both commercial
    and open source — is also making it increasingly easy to build and scale so-called
    “agentic” applications, in which the LLM assumes the role of a (hopefully) skilled
    analyst and makes semi-autonomous decisions. In a chatbot application, for example,
    if the user asks a complex or multi-step query the LLM might need to design a
    plan of action, correctly query multiple external tools — perhaps calculators,
    web searchers, vector databases etc — assemble the results and generate an answer.
  prefs: []
  type: TYPE_NORMAL
- en: Systems like this are often said to use the [ReAct framework](https://www.promptingguide.ai/techniques/react)
    of prompt engineering, which stands for “Reasoning-Action”. Basically, the structure
    and sequence of prompts forces the LLM to answer the question in very methodical
    fashion, first by articulating a thought (typically a plan of attack), carrying
    out an action, then making an observation of the result. In agentic systems, this
    process can continue iteratively until the LLM decides that it’s come to an acceptable
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: In this series of articles, we’ll use the [LangGraph](https://www.langchain.com/langgraph)
    library and [Tavily](https://tavily.com/) search tool to build a simple research
    assistant that demonstrates some of these concepts and might even be useful for
    those of us looking to generate quick, well written reports about any subject.
    Our agent will be inspired by the plan -> research -> write -> submit -> review
    -> revise cycle that happens in peer-reviewed research, and you can take a look
    at the prompts for these different sections [here](https://github.com/rmartinshort/research_assist/blob/main/research_assist/researcher/prompts.py).
  prefs: []
  type: TYPE_NORMAL
- en: To make the system feel more complete, we’ll also add the ability to automatically
    add the material generated to a Google Doc, which is explored in [part 2](/building-a-research-assistant-that-can-write-to-google-docs-part-2-ac9dcacff4ff).
    This should be considered as more of an add-on than an integrated component of
    the agent, but it is interesting in its own right and so could also be read as
    a stand-alone article.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. What should our research assistant do?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before looking at how we can build this assistant and what it means for it to
    be “agentic”, we should think briefly about what we’d like it to do. The goal
    is to build a system that can plan and write short, informative articles about
    a given topic, then improve its own work through review and revision.
  prefs: []
  type: TYPE_NORMAL
- en: Why? Mainly this is just an exploration of technology, but the use of LLMs as
    semi-autonomous researchers is an active field of investigation and is yielding
    interesting projects such as [GPT-researcher](https://github.com/assafelovic/gpt-researcher).
    They have the potential to speed up the work of analysts, students, authors and
    researchers — though of course if the goal is human learning, there is no substitute
    for careful reading, note taking and discussion, which AI cannot replace.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs like GPT4, Anthropic Claude Sonnet, Meta Llama 3, Google Gemini Pro etc.
    can already write great articles out of the box with just a single prompt. However,
    these LLMs have knowledge cutoffs and so need access to additional tools in order
    to fetch the latest information, such as news about current events. There are
    plenty of services — notably tools like Perplexity, ChatGPT (now accessible via
    chat.com) and Google’s AI overview that already have this ability, but they are
    geared more towards providing quick summaries than polished research reports.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we’re making the assumption that multiple iterations of review and revision
    will improve the quality of an article generated by an LLM. This is certainly
    how it works in human writing. Our assistant will have the following components,
    each with its own instruction prompt
  prefs: []
  type: TYPE_NORMAL
- en: '**Planner.** Turns a poorly defined task into a structured article plan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Researcher.** Takes the plan and searches the internet for relevant content.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Writer.** Uses the plan, retrieved content and it own knowledge to write
    the report'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reviewer.** Reads the report and offers constructive criticism'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Editor.** Reads the report and the reviewer’s criticism and decides if the
    report needs to be revised. If so, the report is sent back to the researcher and
    writer stages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our implementation each of these components will be calling the same LLM,
    namely GPT4o-mini, but in a real application they could just as easily use different,
    more specialized models.
  prefs: []
  type: TYPE_NORMAL
- en: The output will be a well-written, informative report — preferably with references
    — that we can programmatically drop into a Google doc for safe keeping. It’s easy
    to modify the “personality” or our researcher by adapting the prompts. The editor
    is particularly important, because it’s the gatekeeper for the end of the process.
    If we make our editor very strict, the system might need to loop through many
    revisions to get accepted. To what extent will a stricter editor improve the quality
    of the result? That’s a very interesting question which, as they say, is beyond
    the scope of the current work!
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Structure of the agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our research assistant is based heavily on the example described in this [excellent
    short course about LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/).
    LangGraph is an LLM orchestration library that attempts to make it easier for
    us to design and build reliable agents. For an in-depth comparison of LangGraph
    and LangChain, I recommend this excellent [article](/ai-agent-workflows-a-complete-guide-on-whether-to-build-with-langgraph-or-langchain-117025509fa0).
  prefs: []
  type: TYPE_NORMAL
- en: What exactly is an agent? It appears that the community has not yet settled
    on a definition, but at least broadly speaking we might say that an agent is a
    [multi-step system where an LLM is allowed to make meaningful decisions about
    the outcome](https://blog.langchain.dev/what-is-an-agent/). This makes it more
    complex (and potentially more unpredictable) than a chain, which is just a predefined
    set of LLM calls one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: In an agent framework, the LLM has some autonomy over how to solve the problem
    it’s given, perhaps by choosing the appropriate tool to call or deciding when
    to stop refining a solution once it’s good enough. In that sense the LLM becomes
    more of the brain of the system, acting more like a human analyst than just an
    API call. One interesting challenge here is that while agents might be free to
    make decisions, they are usually embedded within or interact with traditional
    software systems that require structured inputs and outputs. It’s therefore very
    important to force the agent to return its answers in the way that these other
    systems understand, regardless of the decision it makes.
  prefs: []
  type: TYPE_NORMAL
- en: For a more in-depth discussion of agents in the context of LangGraph, this [documentation](https://langchain-ai.github.io/langgraph/concepts/#graphs)
    is very helpful. Our research agent will be quite a simple one (partly because
    I am still learning this material too!) but hopefully could be a stepping stone
    towards something more sophisticated.
  prefs: []
  type: TYPE_NORMAL
- en: In LangGraph we define the logic of our system as a graph, which consists of
    nodes and edges. Nodes are where LLM calls are made, and edges pass information
    from one node to the next. Edges can be conditional, meaning that they can direct
    information to different nodes depending on what decision is made. Information
    is passed between nodes in a structured format defined by a state.
  prefs: []
  type: TYPE_NORMAL
- en: Our research assistant has a single stage called `AgentState` and it looks like
    this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is where all the information relevant to our problem gets stored, and can
    be updated by LLM action inside a node of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can define some nodes. In the code, all the nodes are kept within the
    `AgentNodes` class, which is just a way I found helpful to group them. For example
    the planner node looks like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note how it takes in an `AgentState` and returns a modification to one of its
    components, namely the text for the research plan. When this node is run, the
    plan is updated.
  prefs: []
  type: TYPE_NORMAL
- en: The code inside the node function uses standard LangChain syntax. `self.model`
    is an instance of `ChatOpenAI`, which looks like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The prompt consists of a system message from the `ResearchPlanPrompt` dataclass
    concatenated with the “task” element of the AgentState, which is the research
    topic provided by the user. The plan prompt looks like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Similar nodes need to be made for the following tasks
  prefs: []
  type: TYPE_NORMAL
- en: '**Conduct research**. This is where we use an LLM to convert the research task
    into a series of queries, then use the Tavily search tool to find their answers
    online and save this under “content” in the AgentStage. This process is discussed
    in more detail in section 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Write the report**. Here we make use of the task name, the research plan,
    the research content and any previous reviewer comments to actually write the
    research report. This gets saved under “draft” in the AgentState. Whenever this
    runs, the `revision_number` indicator gets updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review the report.** Call the LLM to critique the research report and save
    the review under “critique”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conduct more research in response to the critique**. This is going to take
    in the original draft and the review and generate some more queries for Tavily
    that should help the system address the reviewer comments. Once again, this information
    is saved under “content”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Make a decision** about whether or not the report satisfies the reviewer’s
    comments. This is done by the LLM with the guidance of the editor prompt, which
    instructs it to make a yes/no decision on the article and explain its reasoning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dummy nodes** for rejecting or accepting the research. Once we get to either
    of these, we can end the flow. The final research report can then be extracted
    from the AgentState'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We need to make a conditional edge in the graph at the editor node: If the
    editor says yes, we go to the accepted node. If no, we go back to the review node.'
  prefs: []
  type: TYPE_NORMAL
- en: To define this logic, we need to make a function to run inside the conditional
    edge. I have chosen to put this in an AgentEdges class, but this is not a requirement.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In code, the entire graph setup looks like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Before data can flow through a graph, the graph must be compiled. My understanding
    from the docs is that just runs some simple checks on the structured of the graph
    and returns a `CompiledGraph` object, which has methods like `stream` and `invoke.`These
    allow you to pass inputs to the start node, which is defined using `set_entry_point`
    in the code above.
  prefs: []
  type: TYPE_NORMAL
- en: When building these graphs, it can be very helpful to visualize all the nodes
    and edges in a notebook. This can be done with the following command
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[LangGraph offers a few different ways of drawing the graph](https://langchain-ai.github.io/langgraph/how-tos/visualization/),
    depending on what visualization package you have installed. I’m using pygraphviz,
    which can be installed on an m-series mac using the following command'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/234af656591507969c2639052529c85b.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualization of the control flow for our agent. Nodes are where LLM calls occur,
    while edges indicate the flow of information. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: How do we test our agent? The simplest way would just be to call invoke with
    initial values of some of the components of AgentState (i.e. task, max_revisions
    and revision number), which enter the graph at the entry point node.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: After some time (can be several minutes if the max_revisions is set to be large)
    this will return a dictionary of the agent state with all the components filled
    in. I’m using gpt4o-mini for this and the results are very impressive, although
    the extent to which adding the “review” and “editor” components really help to
    improve the quality of the article could be debated and we’ll return to that in
    section 3.
  prefs: []
  type: TYPE_NORMAL
- en: What if we want more insight into the inputs and outputs of the nodes at each
    stage of the graph? This is essential for debugging and explainable as the graph
    grows or if we’re hoping to deploy something like this in production. Thankfully
    LangGraph has some great tools here, which are covered under the [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/)
    and [streaming](https://langchain-ai.github.io/langgraph/concepts/streaming/)
    sections of its documentation. A minimal implementation looks something like this,
    where we are using an in memory store to keep track of the updates the come out
    of each stage of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: More sophisticated applications would access the store from inside the nodes
    themselves, allowing a chatbot to recall previous conversations with a given user
    for example. Here we’re just using the memory to save the outputs of each of the
    nodes, which can then be viewed for debugging purposes. We’ll explore that a bit
    more in the final section.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. What’s in the “*do_research*” node? The power of Tavily search**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perhaps the most interesting parts of the control flow above are the `do_research`and
    `research_revise` nodes. Inside both of these nodes we are using an LLM to generate
    some web search queries relevant to the task, and then we’re using the [Tavily](https://docs.tavily.com/docs/welcome)
    API to actually conduct the search. Tavily is a relatively new service that offers
    a search engine optimized for AI agents. Practically what this means is that the
    service returns search results as chunks of relevant text from websites, rather
    than just a list of urls (which would need to be scraped and parsed) as in the
    case of typical search engine APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood, Tavily is likely using web scrapers and LLMs to extract content
    relevant to the user’s search, but all of that is abstracted away. You can sign
    up [here](https://app.tavily.com/home) for Tavily’s free “Researcher” plan which
    gives 1000 free API calls. Unfortunately after that you’d need to pay a monthly
    fee to keep using it, which is likely only worth it for business use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Lets see an example using the code very similar to what’s going on inside `AgentNodes.research_plan_node`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This generates 5 search queries relevant to the task we defined, which look
    like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Next we can call Tavily search on each of these queries
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This provides a nicely formatted result with url, title and text chunk.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d53f7c7858080ce176276d07bcf8a46c.png)'
  prefs: []
  type: TYPE_IMG
- en: Example results from a Tavily search. Image generated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: This is a very powerful and easy to use search tool that can give LLM applications
    access to the web without the need for extra work!
  prefs: []
  type: TYPE_NORMAL
- en: In our researcher agent, we’re currently only using the content field, which
    we extract and append to a list which is passed into the AgentState. That information
    then gets injected into the prompt thats used for the writer node, hence allowing
    the LLM to have access to it when generating the report.
  prefs: []
  type: TYPE_NORMAL
- en: There is a lot more you can do with Tavily search, but be aware that experimenting
    with it will quickly burn through your free API calls. In fact, for our report
    writing task there are many applications where Tavily calls probably aren’t necessary
    (i.e. the LLM already has sufficient knowledge to write the report), so I would
    recommend adding an additional conditional edge that allows the system to bypass
    the `do_research` and `research_revise` nodes if it determines that a web search
    is not needed. I will likely update the repo with this change soon.
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Walk through an example**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To solidify everything we just learned, let’s walk through an example of the
    researcher in action, using the same task as above.
  prefs: []
  type: TYPE_NORMAL
- en: First, we import the libraries and set up our LLM and searcher models
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now we can run the agent on a task and give it a maximum number of revisions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Now the agent will run its task, which might take about a minute. Logging has
    been added to show what it’s doing and importantly, the results are being saved
    to the `in_memory_store` , which we saw at the end of section 2.
  prefs: []
  type: TYPE_NORMAL
- en: The final report is accessible in a few ways. Its stored in the result list
    and can be visualized in a notebook like this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Its also stored in the agent’s memory along with all the other outputs. We can
    access it as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The report itself is about 1300 words long — a bit too much to copy here — but
    I’ve pasted it into the repo [here](https://github.com/rmartinshort/research_assist/tree/main/research_assist/examples).
    We can also take a look at what the editor thought of it after one round of revision
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It seems the editor was satisfied!
  prefs: []
  type: TYPE_NORMAL
- en: For debugging purposes, we probably need to read though all the other outputs
    though. This can be painful to do in a notebook so in the next article we’ll discuss
    how they can be programmatically dropped into Google Docs. Thanks for making it
    to the end and [we’ll pick up in part 2](/building-a-research-assistant-that-can-write-to-google-docs-part-2-ac9dcacff4ff)!
  prefs: []
  type: TYPE_NORMAL
- en: The author is unaffiliated with any of the tools discussed in this article.
  prefs: []
  type: TYPE_NORMAL
