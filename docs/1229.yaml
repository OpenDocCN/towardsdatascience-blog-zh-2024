- en: A Whimsical Journey Through Wait Times
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-whimsical-journey-through-wait-times-b02a41d337fc?source=collection_archive---------9-----------------------#2024-05-15](https://towardsdatascience.com/a-whimsical-journey-through-wait-times-b02a41d337fc?source=collection_archive---------9-----------------------#2024-05-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: From Microwave Countdowns to Never-Ending Call Holds, with Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@carlmkadie?source=post_page---byline--b02a41d337fc--------------------------------)[![Carl
    M. Kadie](../Images/9dbe27c76e9567136e5a7dc587f1fb15.png)](https://medium.com/@carlmkadie?source=post_page---byline--b02a41d337fc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b02a41d337fc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b02a41d337fc--------------------------------)
    [Carl M. Kadie](https://medium.com/@carlmkadie?source=post_page---byline--b02a41d337fc--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b02a41d337fc--------------------------------)
    ·16 min read·May 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f115c1bd71d609d4441bd795efbdcef4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Waiting “on hold”, for popcorn, and for a lottery win — Source: [https://openai.com/dall-e-2/](https://openai.com/dall-e-2/).
    All other figures from the author.'
  prefs: []
  type: TYPE_NORMAL
- en: Ever notice how microwave oven minutes march steadily toward zero, yet phone
    hold minutes stretch into eternity?
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this: barely a minute into microwaving your popcorn, you’re gathering
    bowls to be ready to serve. But a minute into a call hold? You’re wondering if
    you’ll ever speak to a human again. Fast forward 10 minutes, and you are enjoying
    your popcorn. But on the phone? The hold music has become the soundtrack for an
    endless purgatory.'
  prefs: []
  type: TYPE_NORMAL
- en: And lurking in a twilight zone between waiting for popcorn and waiting on hold
    … your weekly lottery ticket. You wait for a win. Each week’s new ticket holds
    a fresh promise, a promise untouched by previous weekly disappointments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, there appears to be three disparate types of waiting:'
  prefs: []
  type: TYPE_NORMAL
- en: “On Hold”-Type — The longer you’ve waited, the longer you expect to wait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Popcorn”-Type — The longer you’ve waited, the less you expect to wait.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Lottery Win”-Type — Regardless of your wait so far, your expected wait remains
    the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are these disparities in wait-times genuine, or a trick of the mind? We’ll answer
    this question in two parts.
  prefs: []
  type: TYPE_NORMAL
- en: Part 1 — Analyzing Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part 2 — Modeling Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each part, we’ll look at each type of waiting, alternating between detailed
    Python code and a discussion. If you are interested in Python, read the code sections.
    If you are only interested in learning about wait times, you may skip over the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 1: Analyzing Data'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “On Hold”-Type Waits — The longer you’ve waited, the longer you expect to wait.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’d like to start with data, but I don’t have data for “on hold” times. So,
    instead, how about the time between edits of a computer file? One place that I
    see such edit times is on Wikipedia.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose I place you on a Wikipedia page. Can you look at just the time since
    the last edit and predict how long until the next edit?
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside 1: No fair editing the page yourself.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Aside 2: Analogously, if I somehow place you “on hold” for some number of minutes
    (so far), can you predict how much longer until the call is re-connected?'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For Wikipedia page edits, how might you express your prediction of the time
    until the next edit? You could try to predict the **exact** moment of the next
    edit, for example: “I predict this page will next be edited in exactly 5 days,
    3 hours, 20 minutes” That, however, seems too specific, and you’d nearly always
    be wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You could predict a range of times: “I predict this page will be next edited
    sometime between now and 100 years from now”. That would nearly always be right
    but is vague and uninteresting.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A more practical prediction takes the form of the “median next-edit time”.
    You might say: “I predict a 50% chance that this page will be edited within the
    next 5 days, 3 hours, 20 minutes.” I, your adversary, would then pick “before”
    or “after”. Suppose I think the real median next-edit time is 3 days. I would
    then pick “before”. We then wait up to 5 days, 3 hours, 20 minutes. If anyone
    (again, other than us) edits the page in that time, I get a point; otherwise,
    you get a point. With this scoring system, if you’re a better predictor than I,
    you should earn more points.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s next dive into Python and see how we might make such predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: “On Hold”-Type Waits — Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider the Wikipedia article about the artist Marie Cochran. We can look
    at the article’s [revision history](https://en.wikipedia.org/w/index.php?title=Marie_Cochran&action=history):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/73cb643a251b40fd0dfd20c22cdb0e8a.png)'
  prefs: []
  type: TYPE_IMG
- en: Screen capture from Wikipedia. Subsequent figures from author.
  prefs: []
  type: TYPE_NORMAL
- en: 'To gather such data from various Wikipedia articles, I wrote a little Python
    script that:'
  prefs: []
  type: TYPE_NORMAL
- en: Picks a random English-language Wikipedia page via `[https://en.wikipedia.org/wiki/Special:Random](https://en.wikipedia.org/wiki/Special:Random)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goes to that page’s revision history, for example, `[https://en.wikipedia.org/w/index.php?title=Marie_Cochran&action=history](https://en.wikipedia.org/w/index.php?title=Marie_Cochran&action=history)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pulls out the date and times of (up to the) last 50 edits. Times are to the
    resolution of a minute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates lines made up of the article title, an edit time, and the time of the
    script’s run. All times use the UTC time zone. Tabs separate columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appends the lines to a file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aside: This approach brings up several issues. First, in what sense `Special:Random`
    random? I don’t know. For the purpose of this demonstration, it seems random enough.
    Why up-to-the-last 50 edits? Why not all the edits? Why not just the most recent
    edit? I don’t have a good reason beyond “up-to-the-last 50” is the default and
    works well enough for this article. Finally, why script against the regular Wikipedia
    server when we could instead retrieve the **full** edit history for **all** articles
    from `[https://dumps.wikimedia.org](https://dumps.wikimedia.org/)`? Because we
    only need a sample. Also, writing this script was easy, but writing a program
    to process the full data would be hard. Sadly, I will not share the easy script
    because I don’t want to enable uncontrolled bots hitting the Wikipedia site. Happily,
    I am sharing on [GitHub](https://raw.githubusercontent.com/CarlKCarlK/wait-times/main/edit_history.txt)
    all the data I collected. You may use it as you wish.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here is a fragment of the edit time data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s read this into a Pandas dataframe and compute `Time Delta`, the wait
    times between edits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting Pandas dataframe starts with the alphabetically-first article
    (among those sampled). That article tells readers about [Öndör Gongor](https://en.wikipedia.org/wiki/%C3%96nd%C3%B6r_Gongor),
    a very tall person from Mongolia:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f684364a802b3584aa6e528df26fefb4.png)'
  prefs: []
  type: TYPE_IMG
- en: Within that article’s last 50 edits, we first see an edit on January 27th, 2008,
    at 3:13 PM (UTC). We next see an edit 16 minutes later. The edit after that occurs
    within a minute (the limit of the data’s resolution) and so shows `0 days 00:00:00`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing our processing, let’s drop the `NaT` (not-a-time) rows that appear
    at the start of each article. We’ll also sort by the wait times and reset Panda’s
    index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces a dataframe that start and ends like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a429039bac77612e79f5cd06d2c6745.png)'
  prefs: []
  type: TYPE_IMG
- en: 'with this statistical summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We see that the sampled wait times vary from `0 days 00:00:00` (so, less than
    a minute) to over 13 years. (The 13 year edit wait was for an article about [a
    building at a Virginia university](https://en.wikipedia.org/wiki/The_Rotunda_(Longwood_University)).)
    One quarter of the edits happen within 27 minutes of a previous edit. The median
    time between edits is just over 15 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go farther, I want to improve the display of wait times with a little
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `seconds_to_text` function displays 100 seconds as `'1m 40s'`.
  prefs: []
  type: TYPE_NORMAL
- en: With this we can construct a “wait wait” table for the Wikipedia data. Given
    the wait so far for the next edit on an article, the table tells our median additional
    wait. (Recall that “median” means that half the time, we expect to wait less than
    this time for an edit. The other half of the time, we expect to wait more than
    this time.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We’ll discuss the output of this table next.
  prefs: []
  type: TYPE_NORMAL
- en: “On Hold”-Type Waits — Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding Python code produces this table. Call it a “wait-wait” table.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7a64fcdaa5c9e78090147ec0fe2295f8.png)'
  prefs: []
  type: TYPE_IMG
- en: The table says that if we haven’t waited at all (in other words, someone just
    edited the page), we can anticipate the next edit in just over 15 days. However,
    if after a minute, no one has edited the article again, we can anticipate a wait
    of 19 days. Thus, waiting one minute leads to almost 4 days more of additional
    expected waiting. If, after one hour, no one has edited the article, our anticipated
    additional wait more-than-doubles to 47 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside: When I use the term ‘anticipate’ in this context, I’m referring to the
    median waiting time derived from our historical data. In other words, based on
    past trends, we bet that half of the very next edits will occur sooner than this
    time frame, and half will occur later.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'One way to think about this phenomenon: When we start our wait for the next
    edit, we don’t know what kind of page we are on. Is this an article about a hot
    pop-culture topic such as `[Taylor Swift](https://en.wikipedia.org/w/index.php?title=Taylor_Swift&action=history)`?
    Or is this an article about a niche, slow-moving topic such as [The Rotunda, a
    building at a 5000-student university](https://en.wikipedia.org/w/index.php?title=The_Rotunda_%28Longwood_University%29&action=history).
    With every minute that passes without an edit, the probabilities shift from this
    being a Taylor-Swift-like article and toward a The-Rotunda-like article.'
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, when we call customer service and are put on hold — at the start we
    don’t know what kind of customer service we are waiting on. With every passing
    minute, however, we learn that we are likely waiting for poor, slow customer service.
    Our anticipated additional wait, thus, grows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Up to this point, we have used the data directly. We can also try to model
    the data with a probability distribution. Before we move to modeling, however,
    let’s look at our other two examples: microwaving popcorn and waiting for a lotto
    win.'
  prefs: []
  type: TYPE_NORMAL
- en: “Popcorn”-type Waits — The longer you’ve waited, the less you expect to wait.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s apply the techniques from waiting for Wikipedia edits to waiting for microwave
    popcorn. Rather than collecting real data (as delicious as that might be), I’m
    content to simulate data. We’ll use a random number generator. We assume that
    the time to cook, perhaps based on a sensor, is 5 minutes plus or minus 15 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: “Popcorn”-type Waits — Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Specifically in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Which produces a Panda dataframe with this statistical summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As expected, when generating data from this normal distribution, the mean is
    5 minutes, and the standard deviation is about 15 seconds. Our simulated waits
    range from 3 minutes 52 seconds to 6 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now generate a “wait-wait” table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: “Popcorn”-type Waits — Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our “wait-wait” table for popcorn looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/04468d41f7961a6b20b39e48fa20a444.png)'
  prefs: []
  type: TYPE_IMG
- en: Our table says that at the beginning, we expect a 5-minute wait. After we wait
    for 10 seconds, our additional expected wait falls exactly 10 seconds (to 4 minutes
    50 seconds). After we wait one minute, our additional wait falls to 4 minutes
    and so on. At 5 minutes, the anticipated additional wait continues to go down
    (but not to zero).
  prefs: []
  type: TYPE_NORMAL
- en: In a later section, we’ll see how to model this data. For now, let’s look next
    at waiting for a lottery win.
  prefs: []
  type: TYPE_NORMAL
- en: “Lottery Win”-Style Waits — Regardless of your wait so far, your expected wait
    remains the same.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For lottery data, I’m again comfortable creating simulated data. The Washington
    State Lotto offers odds of 1 to 27.1 for a win. (The most common win, pays $3
    for a $1 bet.) Let’s play the lotto for 1 million weeks (about 19,000 years) and
    collect data on our waits between wins.
  prefs: []
  type: TYPE_NORMAL
- en: “Lottery Win”-Style Waits — Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We simulate 1 million weeks of lotto play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Our shortest possible interval between wins is 7 days. Our longest simulated
    dry spell is over 6 years. Our median wait is 133 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'We generate the “wait-wait” table with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: “Lottery Win”-Style Waits — Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the “wait-wait” table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/091b3e4d2b53a58d7f313e50ed5b2d4e.png)'
  prefs: []
  type: TYPE_IMG
- en: The table shows that the lotto doesn’t care how long we’ve waited for a win.
    Whether we just won (`Wait So Far < 1s`) or haven’t won for a year, our anticipated
    additional wait until our next win is almost always between 126 days and 133 days.
  prefs: []
  type: TYPE_NORMAL
- en: 'Three entries on the table might seem strange. What do you think is going on
    at `7d` and `7d 1s`? Why does the additional wait jump, almost instantly from
    126 days to about 133 days? The answer is at the moment of the weekly drawing,
    the minimum wait for a win shifts from 0 days to 7 days. And what about `5y`?
    Is this showing that if we wait 5 years, we can anticipate a win in just 50 days,
    much less than the usual 133 days? Sadly, no. Rather it shows the limitation of
    our data. In the data, we only see 5-year waits three times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5d73f7a2e2968fecd5ad995b1a9d3498.png)'
  prefs: []
  type: TYPE_IMG
- en: Three values lead to a noisy estimate of the median.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize what we’ve seen so far in real and simulated data:'
  prefs: []
  type: TYPE_NORMAL
- en: Wikipedia Edits —The longer you’ve waited, the longer you expect to wait
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popcorn — The longer you’ve waited, the less you expect to wait
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lottery Wins— Regardless of your wait so far, your expected wait remains the
    same
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we’ll look at the hows and (importantly) the whys of modeling.
    We’ll start with our lotto data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Modeling Data'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this part, we’ll try to find simple expressions for wait-time predictions.
    Such simplicity is not needed for predictions. What we’ve created so far, called
    an *empirical distribution*, works fine. A simpler expression can, however, be
    more convenient. Also, it may make comparisons between different types of waits
    easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: We will proceed by looking at our three examples starting with the simplest
    (Lottery Wins) to the most complex (Wikipedia Edits). As before, I’ll alternate
    between Python code (that you can skip over) and discussion.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by adding a cumulative distribution column to our three wait-time
    dataframes. Recall that we previously sorted the dataframes by `Time Delta`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The column labeled `CDF`, for cumulative distribution function, contains values
    near 0.0 for the shortest wait times and a value of 1.0 for the longest wait time.
    In other words, it is the rank of each row expressed as a fraction. The Wikipedia
    dataframe now looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f87f0a93e618e63753f80656682b2bfe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can now plot `CDF` (y-axis) vs. the wait time `Time Delta` (x-axis). Here
    is some plotting code in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the CDF plot of Lottery Wins with wait time on a log scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eba178ed8ad2f3e946719a620171f932.png)'
  prefs: []
  type: TYPE_IMG
- en: The curve looks simple so let’s try to fit a simple curve to it. The obvious
    candidate curve is the exponential distribution. It’s the simplest common function
    related to wait times.
  prefs: []
  type: TYPE_NORMAL
- en: Python’s `scipy.stats` package makes it easy to fit an exponential curve to
    our data and to represent the resulting curve as a Python object, here named `lotto_expon_dist`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This code prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Lottery wins exponential median is 131d 22h 32m 20s. The scale parameter is
    190d 8h 21m.`'
  prefs: []
  type: TYPE_NORMAL
- en: The median of the fitted curve, about 132 days, is close to the empirical median
    of 133 days. By convention, we parameterize an exponential curve with a single
    number, here called `scale`. It corresponds to the mean of the distribution, but
    we can easily determine median from mean and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a plot of the empirical CDF and fitted CDF for Lottery Wins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b6e0a0cf0a28750d18f06ed80a26079d.png)'
  prefs: []
  type: TYPE_IMG
- en: They match closely. The slight mismatch on the left is caused by the instant
    7-day jump at the moment of the lottery drawing. We’ll ignore this tiny mismatch
    in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential works well on our (simulated) lottery win data. Let’s see how it
    works on our Popcorn and Wikipedia data. Here is the code to fit an exponential
    distribution to these dataframes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And here are the plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83422f297200848b69f412cce3ecb918.png)![](../Images/c9442dbe769a11121b8f180276b80f6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Yikes, these curve fits are terrible! The problem is that exponential distributions
    *only* model “Lottery-Win”-like data. Specifically, waits in which regardless
    of your wait so far, your expected wait remains the same. Because the exponential
    distribution fits waits that ignore your wait so far, it is called *memoryless*.
    Moreover, among continuous distributions, the exponential distribution is the
    *only* memoryless distribution.
  prefs: []
  type: TYPE_NORMAL
- en: But what if we need our distribution to have memory? The next simplest distribution
    to try is the Weibull distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two parameters, `shape` and `scale` parameterize a Weibull. Let’s give it a
    try starting with the lottery data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This produces a fitted curve that looks like the exponential. Indeed, when `shape`
    is 1, a Weibull distribution **is** an exponential distribution. Here shape is
    1.06.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/de58306913bf8afdcc66e9fc78bd423f.png)'
  prefs: []
  type: TYPE_IMG
- en: What happens when we try to fit a Weibull to our Popcorn data?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fcfbcaf877b73111e0f8e805369e1232.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While not perfect, this fit is much better than the exponential’s fit. Notice
    the shape parameter’s value of 20\. When a Weibull’s shape parameter is greater
    than 1, it indicates: “the longer you’ve waited, the less you expect to wait”.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let’s try the Weibull on the Wikipedia data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/507d924fff7d2bc30c6aeca9d9d54958.png)'
  prefs: []
  type: TYPE_IMG
- en: This curve fit is less than perfect, but still much better than the exponential’s
    fit. Notice the shape parameter value of 0.292\. When a Weibull’s shape parameter
    is less than 1 that indicates that “the longer you’ve waited, the longer you expect
    to wait”. However, the Weibull is not unique in this. An infinite number of distributions
    also have this property. Indeed, the empirical Wikipedia distribution has this
    property but is not a Weibull.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside: I don’t know of a better simple model for the Wikipedia data. The empirical
    curve looks only a little more complicated than the Weibull. Perhaps we just need
    to identify (or invent) a slightly more general distribution with one or two additional
    parameters.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, you and I are not (necessarily) crazy.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen that there really are situations for which the longer you have
    waited, the longer you should expect to wait. We see it empirically in the times
    between Wikipedia edits. We also see it in the Weibull distribution when the shape
    parameter is less than 1.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, for some other waits, “The longer you’ve waited, the less you expect
    to wait”. We see that for popcorn. We also see it in the Weibull distribution
    when the shape parameter is greater than 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, there exists a third class of waits: memoryless. For these, regardless
    of your wait so far, your expected wait remains the same. We saw this with the
    time between lottery wins. It also corresponds to a Weibull distribution with
    a shape parameter of 1 (which is the same as an exponential distribution).'
  prefs: []
  type: TYPE_NORMAL
- en: When you have wait data to analyze, I recommend trying a Weibull distribution.
    Python makes fitting such a curve easy. However, if your data doesn’t fit the
    Weibull well, don’t use the Weibull. Instead, let your data speak for itself by
    using your empirical distribution directly.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for joining me on this journey into wait times. I hope you now better
    understand wait times and their analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '*Please* [*follow Carl on Medium*](https://medium.com/@carlmkadie)*. I write
    on scientific programming in Rust and Python, machine learning, and statistics.
    I tend to write about one article per month.*'
  prefs: []
  type: TYPE_NORMAL
