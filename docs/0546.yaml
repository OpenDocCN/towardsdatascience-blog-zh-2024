- en: Diffusion Transformer Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/diffusion-transformer-explained-e603c4770f7e?source=collection_archive---------2-----------------------#2024-02-28](https://towardsdatascience.com/diffusion-transformer-explained-e603c4770f7e?source=collection_archive---------2-----------------------#2024-02-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploring the architecture that brought transformers into image generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mnslarcher.medium.com/?source=post_page---byline--e603c4770f7e--------------------------------)[![Mario
    Larcher](../Images/57a031fe2a1931c9cdd63b9f35f3d136.png)](https://mnslarcher.medium.com/?source=post_page---byline--e603c4770f7e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e603c4770f7e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e603c4770f7e--------------------------------)
    [Mario Larcher](https://mnslarcher.medium.com/?source=post_page---byline--e603c4770f7e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e603c4770f7e--------------------------------)
    ·12 min read·Feb 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d6f5ca3c1cb0d9569dfd8b8ce4a076be.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with DALL·E.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After shaking up NLP and moving into computer vision with the Vision Transformer
    (ViT) and its successors, transformers are now entering the field of image generation.
    They are gradually becoming an alternative to the U-Net, the convolutional architecture
    upon which all the early diffusion models were built. This article looks into
    the **Diffusion Transformer** (**DiT**), introduced by William Peebles and Saining
    Xie in their paper “**Scalable Diffusion Models with Transformers**.”
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://arxiv.org/abs/2212.09748?source=post_page-----e603c4770f7e--------------------------------)
    [## Scalable Diffusion Models with Transformers'
  prefs: []
  type: TYPE_NORMAL
- en: We explore a new class of diffusion models based on the transformer architecture.
    We train latent diffusion models of…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: arxiv.org](https://arxiv.org/abs/2212.09748?source=post_page-----e603c4770f7e--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: DiT has influenced the development of other transformer-based diffusion models
    like [PIXART-α](https://pixart-alpha.github.io/), [Sora](https://openai.com/sora)
    (OpenAI’s astonishing text-to-video model), and, as I write this article, [Stable
    Diffusion 3](https://stability.ai/news/stable-diffusion-3). Let’s start exploring
    this emerging class of architectures that are contributing to the evolution of
    diffusion models.
  prefs: []
  type: TYPE_NORMAL
- en: Preliminaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given that this is an advanced topic, I’ll have to assume a certain familiarity
    with…
  prefs: []
  type: TYPE_NORMAL
