- en: 'Reinforcement Learning, Part 3: Monte Carlo Methods'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习，第三部分：蒙特卡罗方法
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb?source=collection_archive---------3-----------------------#2024-05-23](https://towardsdatascience.com/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb?source=collection_archive---------3-----------------------#2024-05-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb?source=collection_archive---------3-----------------------#2024-05-23](https://towardsdatascience.com/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb?source=collection_archive---------3-----------------------#2024-05-23)
- en: 'From casinos to AI: unveiling the power of Monte Carlo methods in complex environments'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从赌场到人工智能：揭示蒙特卡罗方法在复杂环境中的强大力量
- en: '[](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--7ce2828a1fdb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)
    ·12 min read·May 23, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7ce2828a1fdb--------------------------------)
    ·阅读时间：12分钟·2024年5月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/37d7bbb391066cffc3bf52feb6fac980.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37d7bbb391066cffc3bf52feb6fac980.png)'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: R**einforcement learning** is a domain in machine learning that introduces the
    concept of an agent who must learn optimal strategies in complex environments.
    The agent learns from its actions that result in rewards given the environment’s
    state. Reinforcement learning is a difficult topic and differs significantly from
    other areas of machine learning. That is why it should only be used when a given
    problem cannot be solved otherwise.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**是机器学习中的一个领域，它引入了一个智能体的概念，该智能体必须在复杂的环境中学习最佳策略。智能体通过其行动学习，依据环境状态获得奖励。强化学习是一个复杂的课题，与机器学习的其他领域有显著区别。因此，只有在给定问题无法通过其他方式解决时，才应使用强化学习。'
- en: In this article, we are going to discover Monte Carlo algorithms. Compared to
    standard approaches, their elegance lies in the fact that they do not require
    any knowledge about the environment’s dynamics. This aspect makes all the difference
    because in real life we do not normally know all possible transition probabilities
    between states.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探索蒙特卡罗算法。与标准方法相比，蒙特卡罗算法的优雅之处在于，它们不需要了解环境的动态特性。这一点非常重要，因为在现实生活中，我们通常并不知道状态之间的所有可能转移概率。
- en: '**Note**. To fully understand the concepts included in this article, it is
    highly recommended to be familiar with the main concepts of reinforcement learning
    as well as the policy improvement methods introduced in the first two articles
    of this series.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**：为了充分理解本文中包含的概念，强烈建议熟悉强化学习的主要概念，以及本系列前两篇文章中介绍的策略改进方法。'
