["```py\nimport pandas as pd\nimport torch\nfrom torch_geometric.data import Data, Batch\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom torch_geometric.data import DataLoader\n\n# load and scale the dataset\ndf = pd.read_csv('SensorDataSynthetic.csv').dropna()\nscaler = MinMaxScaler()\ndf_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n```", "```py\nnodes_order = [\n    'Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', \n    'Sensor5', 'Sensor6', 'Sensor7', 'Sensor8'\n]\n\n# define the graph connectivity for the data\nedges = torch.tensor([\n    [0, 1, 2, 2, 3, 3, 6, 2],  # source nodes\n    [1, 2, 3, 4, 5, 6, 2, 7]   # target nodes\n], dtype=torch.long)\n```", "```py\ngraphs = []\n\n# iterate through each row of data to create a graph for each observation\n# some nodes will not have any data, not the case here but created a mask to allow us to deal with any nodes that do not have data available\nfor _, row in df_scaled.iterrows():\n    node_features = []\n    node_data_mask = []\n    for node in nodes_order:\n        if node in df_scaled.columns:\n            node_features.append([row[node]])\n            node_data_mask.append(1) # mask value of to indicate present of data\n        else:\n            # missing nodes feature if necessary\n            node_features.append(2)\n            node_data_mask.append(0) # data not present\n\n    node_features_tensor = torch.tensor(node_features, dtype=torch.float)\n    node_data_mask_tensor = torch.tensor(node_data_mask, dtype=torch.float)\n\n    # Create a Data object for this row/graph\n    graph_data = Data(x=node_features_tensor, edge_index=edges.t().contiguous(), mask = node_data_mask_tensor)\n    graphs.append(graph_data)\n\n#### splitting the data into train, test observation\n# Split indices\nobservation_indices = df_scaled.index.tolist()\ntrain_indices, test_indices = train_test_split(observation_indices, test_size=0.05, random_state=42)\n\n# Create training and testing graphs\ntrain_graphs = [graphs[i] for i in train_indices]\ntest_graphs = [graphs[i] for i in test_indices]\n```", "```py\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nG = nx.Graph() \nfor src, dst in edges.t().numpy():\n    G.add_edge(nodes_order[src], nodes_order[dst])\n\nplt.figure(figsize=(10, 8))\npos = nx.spring_layout(G)\nnx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=2000, font_weight='bold')\nplt.title('Graph Visualization')\nplt.show()\n```", "```py\nfrom torch_geometric.nn import GATConv\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nclass GNNModel(nn.Module):\n    def __init__(self, num_node_features):\n        super(GNNModel, self).__init__()\n        self.conv1 = GATConv(num_node_features, 16)\n        self.conv2 = GATConv(16, 8)\n        self.fc = nn.Linear(8, 1)  # Outputting a single value per node\n\n    def forward(self, data, target_node_idx=None):\n        x, edge_index = data.x, data.edge_index\n        edge_index = edge_index.T\n        x = x.clone()\n\n        # Mask the target node's feature with a value of zero! \n        # Aim is to predict this value from the features of the neighbours\n        if target_node_idx is not None:\n            x[target_node_idx] = torch.zeros_like(x[target_node_idx])\n\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.dropout(x, p=0.05, training=self.training)\n        x = F.relu(self.conv2(x, edge_index))\n        x = F.relu(self.conv3(x, edge_index))\n        x = F.dropout(x, p=0.05, training=self.training)\n        x = self.fc(x)\n\n        return x\n```", "```py\nmodel = GNNModel(num_node_features=1) \nbatch_size = 8\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=1e-6)\ncriterion = torch.nn.MSELoss()\nnum_epochs = 200  \ntrain_loader = DataLoader(train_graphs, batch_size=1, shuffle=True) \nmodel.train()\n```", "```py\nfor epoch in range(num_epochs):\n    accumulated_loss = 0 \n    optimizer.zero_grad()\n    loss = 0  \n    for batch_idx, data in enumerate(train_loader):\n        mask = data.mask  \n        for i in range(1,data.num_nodes):\n            if mask[i] == 1:  # Only train on nodes with data\n                output = model(data, i)  # get predictions with the target node masked\n                                         # check the feed forward part of the model\n                target = data.x[i] \n                prediction = output[i].view(1) \n                loss += criterion(prediction, target)\n        #Update parameters at the end of each set of batches\n        if (batch_idx+1) % batch_size == 0 or (batch_idx +1 ) == len(train_loader):\n            loss.backward() \n            optimizer.step()\n            optimizer.zero_grad()\n            accumulated_loss += loss.item()\n            loss = 0\n\n    average_loss = accumulated_loss / len(train_loader)\n    print(f'Epoch {epoch+1}, Average Loss: {average_loss}')\n```", "```py\ntest_loader = DataLoader(test_graphs, batch_size=1, shuffle=True)\nmodel.eval()\n\nactual = []\npred = []\n\nfor data in test_loader:\n    mask = data.mask\n    for i in range(1,data.num_nodes):\n        output = model(data, i)\n        prediction = output[i].view(1)\n        target = data.x[i]\n\n        actual.append(target)\n        pred.append(prediction)\n```", "```py\nimport plotly.graph_objects as go\nfrom plotly.offline import iplot\n\nactual_values_float = [value.item() for value in actual]\npred_values_float = [value.item() for value in pred]\n\nscatter_trace = go.Scatter(\n    x=actual_values_float,\n    y=pred_values_float,\n    mode='markers',\n    marker=dict(\n        size=10,\n        opacity=0.5,  \n        color='rgba(255,255,255,0)',  \n        line=dict(\n            width=2,\n            color='rgba(152, 0, 0, .8)', \n        )\n    ),\n    name='Actual vs Predicted'\n)\n\nline_trace = go.Scatter(\n    x=[min(actual_values_float), max(actual_values_float)],\n    y=[min(actual_values_float), max(actual_values_float)],\n    mode='lines',\n    marker=dict(color='blue'),\n    name='Perfect Prediction'\n)\n\ndata = [scatter_trace, line_trace]\n\nlayout = dict(\n    title='Actual vs Predicted Values',\n    xaxis=dict(title='Actual Values'),\n    yaxis=dict(title='Predicted Values'),\n    autosize=False,\n    width=800,\n    height=600\n)\n\nfig = dict(data=data, layout=layout)\n\niplot(fig)\n```"]