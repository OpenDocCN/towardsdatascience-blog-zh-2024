<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Decoding Time: Unraveling the Power of LSTM vs. N-BEATS for Accurate Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Decoding Time: Unraveling the Power of LSTM vs. N-BEATS for Accurate Time Series Forecasting</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19">https://towardsdatascience.com/decoding-time-unraveling-the-power-of-lstm-vs-n-beats-for-accurate-time-series-forecasting-ca5fdd20dbc?source=collection_archive---------11-----------------------#2024-04-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="fo bh"><figure class="fp fo bh paragraph-image"><img src="../Images/7f89a7d4b8fac9fdb276d5798b65164e.png" data-original-src="https://miro.medium.com/v2/resize:fit:4800/format:webp/1*1VElhFqWj7dcCjyICD1gPA.jpeg"/><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Photo by <a class="af fz" href="https://unsplash.com/@aronvisuals?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Aron Visuals</a> on <a class="af fz" href="https://unsplash.com/photos/selective-focus-photo-of-brown-and-blue-hourglass-on-stones-BXOXnQ26B7o?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="faee" class="pw-subtitle-paragraph gz gb gc bf b ha hb hc hd he hf hg hh hi hj hk hl hm hn ho cq dx">Comparing how two deep learning models perform short-term and long-term</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hp hq hr hs ht ab"><div><div class="ab hu"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------" rel="noopener follow"><div class="l hv hw by hx hy"><div class="l ed"><img alt="Frida Karvouni" class="l ep by dd de cx" src="../Images/49aad19f6bdd7ffdc68c212722079c6f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*ziXwt36YQgi3M1bO7pLFzQ.jpeg"/><div class="hz by l dd de em n ia eo"/></div></div></a></div></div><div class="ib ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------" rel="noopener follow"><div class="l ic id by hx ie"><div class="l ed"><img alt="Towards Data Science" class="l ep by br if cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hz by l br if em n ia eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="ig ab q"><div class="ab q ih"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ii ij bk"><a class="af ag ah ai aj ak al am an ao ap aq ar ik" data-testid="authorName" href="https://medium.com/@fkarvoun?source=post_page---byline--ca5fdd20dbc--------------------------------" rel="noopener follow">Frida Karvouni</a></p></div></div></div><span class="il im" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b ii ij dx"><button class="in io ah ai aj ak al am an ao ap aq ar ip iq ir" disabled="">Follow</button></p></div></div></span></div></div><div class="l is"><span class="bf b bg z dx"><div class="ab cn it iu iv"><div class="iw ix ab"><div class="bf b bg z dx ab iy"><span class="iz l is">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar ik ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--ca5fdd20dbc--------------------------------" rel="noopener follow"><p class="bf b bg z ja jb jc jd je jf jg jh bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="il im" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">6 min read</span><div class="ji jj l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz"><div class="h k w ea eb q"><div class="kp l"><div class="ab q kq kr"><div class="pw-multi-vote-icon ed iz ks kt ku"><div class=""><div class="kv kw kx ky kz la lb am lc ld le ku"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l lf lg lh li lj lk ll"><p class="bf b dy z dx"><span class="kw">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kv lm ln ab q ee lo lp" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="fp"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q ka kb kc kd ke kf kg kh ki kj kk kl km kn ko"><div class="lq k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lr an ao ap ip ls lt lu" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lv cn"><div class="l ae"><div class="ab cb"><div class="lw lx ly lz ma fq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lr an ao ap ip mb mc lp md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="0789" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Time series forecasting plays a pivotal role across various domains by facilitating predictions of future trends. This exploration focuses on two prominent deep learning models, delving into their respective strengths and weaknesses.</p><p id="6cac" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="mu gd">LSTM</strong> (Long Short-Term Memory) stands out as a specialised variant of RNN, adept at capturing patterns characterised by long-term dependencies in sequential data. It enhances traditional RNNs by effectively addressing the vanishing gradient problem, allowing for the modelling of extended dependencies. LSTM achieves this by selectively retaining or forgetting information over time through the incorporation of memory cells and gating mechanisms, including input, output, and forget gates. An inherent limitation of LSTM models is that the forecasting horizon must align with the length of the input sequences utilised during training.</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw no"><img src="../Images/c70ad5ef5d4fc304d3824aaa7beb19b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*54wARPvWNOz1-S6sfpJ7gQ.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">LSTM architecture is built on RNNs<strong class="bf ny"> [1]</strong></figcaption></figure><p id="3b51" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="mu gd">N-BEATS</strong> (Neural Basis Expansion Analysis for Time Series) represents a non-recurrent architecture renowned for its ability to accurately forecast multiple time series. Constructed with distinct building blocks, it adopts a hierarchical structure wherein each block specialises in forecasting a specific horizon. The “backcast” block delves into the historical horizon, while the “forecast” block focuses on predicting future periods, which might vary in size.</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw nz"><img src="../Images/111c8a4dd4deeb5c0524e170e7a55906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*BnlSe5_8KkcjyWj7Dhcb6w.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">N-BEATS look-back and forecast horizons may differ in size <strong class="bf ny">[2]</strong></figcaption></figure><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw oa"><img src="../Images/2bbb57d8b26c59c0414a6df3c507d82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5W0xOH7f619_JyRvU_aYsg.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">N-BEATS architecture <strong class="bf ny">[2]</strong></figcaption></figure><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw ob"><img src="../Images/dd8de56ec473f89ccbec96981f92f6fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMWZ1Py6LKdHzjlRinQKYQ.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">N-BEATS architecture of each stack (left) and each block within each stack (right) <strong class="bf ny">[2]</strong></figcaption></figure><p id="7646" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">N-BEATS excels in modelling seasonality by decomposing the series into trend and seasonality, akin to the approach taken by STL (Seasonal-Trend decomposition using LOESS). This decomposition allows the model to capture both short-term fluctuations (seasonality) and long-term trends separately. It utilises Fast Fourier transform to effectively model seasonality, a pivotal component in time series analysis. N-BEATS is designed to be robust to different types of seasonality patterns, including regular and irregular patterns.</p><h1 id="1594" class="oc od gc bf ny oe of hc og oh oi hf oj ok ol om on oo op oq or os ot ou ov ow bk">Practical example</h1><p id="fbbe" class="pw-post-body-paragraph ms mt gc mu b ha ox mw mx hd oy mz na nb oz nd ne nf pa nh ni nj pb nl nm nn fj bk">To better understand the theoretical concepts discussed above, let’s delve into a practical example by applying both models. Initially, we’ll generate synthetic data at a daily frequency, featuring an ascending trend and seasonality patterns.</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="db23" class="pg od gc pd b bg ph pi l pj pk">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/><br/># Generate synthetic time series data<br/>def generate_synthetic_data():<br/>    # Create a time range with daily frequency<br/>    start_time = pd.Timestamp("1990-01-01 00:00:00")<br/>    end_time = pd.Timestamp("2023-12-31 23:59:00")<br/>    time = pd.date_range(start=start_time, end=end_time, freq='D')<br/><br/>    # Weekly seasonality and ascending trend<br/>    weekly_seasonality = 10 * np.sin(2 * np.pi * <br/>                         np.arange(len(time)) / (7 * 24 * 60))<br/><br/>    ascending_trend = 0.01 * np.arange(len(time))<br/><br/>    # Combine the components to generate synthetic data<br/>    uplift = 100<br/>    x = weekly_seasonality + ascending_trend + uplift<br/><br/>    noise_level = 5<br/>    noise = white_noise(len(time), noise_level, seed=42)<br/>    x += noise<br/>    return time, x<br/><br/>def white_noise(length, noise_level=1, seed=None):<br/>    rnd = np.random.RandomState(seed)<br/>    return rnd.randn(length) * noise_level<br/><br/>time_series_data = generate_synthetic_data_minute()<br/>data = pd.DataFrame({'ds': time_series_data[0], 'y': time_series_data[1]})<br/>data= data.set_index("ds")<br/><br/># Plot the generated synthetic data<br/>plt.plot(data["y"])<br/>plt.title("Synthetic Time Series Data")<br/>plt.show()</span></pre><p id="3110" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The simulated data appears as follows:</p><figure class="np nq nr ns nt fo fv fw paragraph-image"><div class="fv fw pl"><img src="../Images/918cbd7e9a9a1c60336653338cc19873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*oBFJm6fSPLkgTQnpEHoTmA.png"/></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">Synthetic time-series data</figcaption></figure><p id="9acd" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The dataset exhibits seasonality, an ascending trend, and noise, making accurate forecasting challenging for most models. This difficulty arises because many models specialise in identifying either long-term or short-term patterns individually. Consequently, accurately predicting this data requires a model capable of capturing both types of patterns simultaneously. To facilitate this, the data has been scaled to ensure compatibility with an LSTM model.</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="c438" class="pg od gc pd b bg ph pi l pj pk">data = data.reset_index()<br/>train_data = data[data.ds&lt;='2022-01-01']<br/>test_data = data[data.ds&gt;'2022-01-01']<br/><br/># Normalize the data<br/>scaler = MinMaxScaler()<br/>train_data['x'] = scaler.fit_transform(train_data[['x']])<br/>test_data['x'] = scaler.transform(test_data[['x']])<br/><br/># Create sequences for the LSTM model<br/>sequence_length = 10<br/>train_sequences = []<br/>test_sequences = []<br/><br/>for i in range(len(train_data) - sequence_length):<br/>    train_sequences.append(train_data['x'].iloc[i:i+sequence_length].values)<br/><br/>for i in range(len(test_data) - sequence_length):<br/>    test_sequences.append(test_data['x'].iloc[i:i+sequence_length].values)<br/><br/>train_sequences = np.array(train_sequences)<br/>test_sequences = np.array(test_sequences)<br/><br/># Prepare train and test targets<br/>train_targets = train_data['x'].iloc[sequence_length:].values<br/>test_targets = test_data['x'].iloc[sequence_length:].values<br/><br/>import time<br/>start_time = time.time()<br/><br/># Create and train an LSTM model<br/>model = Sequential()<br/>model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1)))<br/>model.add(Dense(1))<br/>model.compile(optimizer='adam', loss='mean_squared_error')<br/>model.fit(train_sequences.reshape(-1, sequence_length, 1), train_targets, <br/>epochs=5, batch_size=32)<br/><br/># Make predictions<br/>test_predictions = model.predict(<br/>                   test_sequences.reshape(-1, sequence_length, 1))<br/><br/>print(time.time() - start_time)<br/><br/># Inverse transform the predictions to the original scale<br/>test_predictions = scaler.inverse_transform(test_predictions).flatten()<br/>test_targets = scaler.inverse_transform(test_targets.reshape(-1, 1))</span></pre><p id="724e" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The model for this dataset was trained in 23 seconds. The test set and predictions cover the period after January 1st, 2022. Here are the forecasted values:</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="3e48" class="pg od gc pd b bg ph pi l pj pk"># Plot the original data and LSTM predictions<br/>plt.figure(figsize=(10, 6))<br/>plt.plot(test_data['ds'].iloc[sequence_length:], test_targets, <br/>label="Actual Data", linestyle='-')<br/>plt.plot(test_data['ds'].iloc[sequence_length:], test_predictions, <br/>label="LSTM Predictions", linestyle='--')<br/>plt.xlabel("Time")<br/>plt.ylabel("Value")<br/>plt.legend()<br/>plt.grid(False)<br/>plt.show()</span></pre><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw pm"><img src="../Images/2fc38115dc852fb4ab1814b60fe30c4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j2Fbj1pgcJWE4IW6VZzHCQ.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">LSTM predictions within the test set</figcaption></figure><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw pn"><img src="../Images/5349877e2859c072600d8185b0a7aad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NZ3DtIm57gSKG3ZA0U7kw.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">LSTM predictions within the entire dataset</figcaption></figure><p id="dd62" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The forecasts appear to capture the ascending trend and seasonality effectively, which is promising. However, there seems to be a significant amount of noise in the predictions. Moreover, as the forecast horizon extends further, deviations from the test data become noticeable.</p><p id="7c27" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Now, let’s assess the Weighted Absolute Percentage Error (WAPE):</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="3293" class="pg od gc pd b bg ph pi l pj pk">test_predictions_df = pd.DataFrame(test_predictions, columns = ["LSTM"])<br/>test_targets_df = pd.DataFrame(test_targets, columns = ["actuals"])<br/>predictions = pd.concat([test_predictions_df, test_targets_df], axis=1)<br/><br/>wape = (predictions['actuals'] - predictions['LSTM']).abs().sum() <br/>        / predictions['actuals'].sum()<br/><br/>print(wape * 100)</span></pre><pre class="po pc pd pe bp pf bb bk"><span id="d4d8" class="pg od gc pd b bg ph pi l pj pk">WAPE = 1.89%</span></pre><p id="9032" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The results are indeed promising.</p><p id="358f" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Next, let’s explore fitting an N-BEATS model to the same dataset and examine its performance.</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="4574" class="pg od gc pd b bg ph pi l pj pk">data = generate_data_specific_column(col_name = "y")<br/><br/># create column unique_id specifically for N-BEATS model with only 1.0<br/>data['unique_id'] = 1.0<br/><br/>data = data.reset_index()<br/>train_data = data[data.ds&lt;='2022-01-01']<br/>test_data = data[data.ds&gt;'2022-01-01']<br/><br/>from neuralforecast.models import NBEATS, NHITS<br/>from neuralforecast import NeuralForecast<br/>import time<br/>start_time = time.time()<br/><br/>horizon = len(test_data)<br/><br/>models = [NBEATS(input_size=2 * horizon, h=horizon, max_steps=50)]<br/><br/>nf = NeuralForecast(models=models, freq='D')<br/>nf.fit(df=train_data) # default optimizer is MAE<br/>test_predictions = nf.predict().reset_index()<br/><br/>print(time.time() - start_time)</span></pre><p id="edf2" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">The N-BEATS model was trained in 83 seconds, which, although fast, is slower than the LSTM model.</p><p id="1acf" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Now, let’s examine the predictions generated by the N-BEATS model.</p><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="4653" class="pg od gc pd b bg ph pi l pj pk"># Plot predictions<br/>predictions = test_data.merge(test_predictions, how='left', <br/>on=['unique_id', 'ds'])<br/><br/>plt.figure(figsize=(10, 6))<br/>plt.plot(predictions['ds'], predictions['y'], label="Actual Data", <br/>linestyle='-')<br/>plt.plot(predictions['ds'], predictions['NBEATS'], <br/>label="NBEATS Predictions", linestyle='--')<br/>plt.xlabel("Time")<br/>plt.ylabel("Demand per Minute")<br/>plt.legend()<br/>plt.grid(False)<br/>plt.show()</span></pre><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw pm"><img src="../Images/5793207e79e22f0a125334e38873eef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m99bi2hNfyXpUAO7hs3SRQ.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">N-BEATS predictions within the test set</figcaption></figure><figure class="np nq nr ns nt fo fv fw paragraph-image"><div role="button" tabindex="0" class="nu nv ed nw bh nx"><div class="fv fw pp"><img src="../Images/d8f833e2eee729cefde99d30afc8e5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G1QtSY1AcXcO7AX_kYYDtA.png"/></div></div><figcaption class="fs ft fu fv fw fx fy bf b bg z dx">N-BEATS predictions within the entire dataset</figcaption></figure><pre class="np nq nr ns nt pc pd pe bp pf bb bk"><span id="35d4" class="pg od gc pd b bg ph pi l pj pk">wape = (predictions['y'] - predictions['NBEATS']).abs().sum() <br/>        / predictions['y'].sum()<br/><br/>print(wape * 100)</span></pre><pre class="po pc pd pe bp pf bb bk"><span id="a6f3" class="pg od gc pd b bg ph pi l pj pk">WAPE = 1.80%</span></pre><p id="6f95" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk">Both models demonstrate high accuracy according to the chosen metric. Interestingly, the forecasts generated by N-BEATS do not seem to deteriorate as we approach the end of the forecasting horizon. This suggests that N-BEATS could be particularly suitable for projects requiring long-term forecasts.</p><h1 id="b6fd" class="oc od gc bf ny oe of hc og oh oi hf oj ok ol om on oo op oq or os ot ou ov ow bk">Summary</h1><p id="2d18" class="pw-post-body-paragraph ms mt gc mu b ha ox mw mx hd oy mz na nb oz nd ne nf pa nh ni nj pb nl nm nn fj bk">N-BEATS and LSTM bring unique strengths to the forecasting domain. N-BEATS excels in its ability to capture diverse patterns for longer horizons, while being highly interpretable. On the other hand, LSTM is a fast, stable and complex neural network mechanism which achieves accurate predictions.</p><h1 id="6e15" class="oc od gc bf ny oe of hc og oh oi hf oj ok ol om on oo op oq or os ot ou ov ow bk">References</h1><p id="3d27" class="pw-post-body-paragraph ms mt gc mu b ha ox mw mx hd oy mz na nb oz nd ne nf pa nh ni nj pb nl nm nn fj bk">*Unless otherwise noted, all images have been generated by the author</p><p id="e76a" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="mu gd">[1] </strong>Van Houdt, Greg &amp; Mosquera, Carlos &amp; Nápoles, Gonzalo. (2020). A Review on the Long Short-Term Memory Model. Artificial Intelligence Review. 53. 10.1007/s10462–020–09838–1.</p><p id="a51f" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><strong class="mu gd">[2]</strong> Binte Habib, Adria. (2022). A Detailed Explanation of the workflow of N-BEATS Architecture. 10.13140/RG.2.2.36379.34083.</p><div class="pq pr ps pt pu pv"><a href="https://medium.com/mlearning-ai/building-a-neural-network-zoo-from-scratch-the-long-short-term-memory-network-1cec5cf31b7?source=post_page-----ca5fdd20dbc--------------------------------" rel="noopener follow" target="_blank"><div class="pw ab is"><div class="px ab co cb py pz"><h2 class="bf gd ii z ja qa jc jd qb jf jh gb bk">Building a Neural Network Zoo From Scratch: The Long Short-Term Memory Network</h2><div class="qc l"><h3 class="bf b ii z ja qa jc jd qb jf jh dx">Long Short-Term Memory (LSTM) networks are one of the most well known types of recurrent neural networks. Originally…</h3></div><div class="qd l"><p class="bf b dy z ja qa jc jd qb jf jh dx">medium.com</p></div></div><div class="qe l"><div class="qf l qg qh qi qe qj fq pv"/></div></div></a></div><div class="pq pr ps pt pu pv"><a href="https://forecastegy.com/posts/multiple-time-series-forecasting-nbeats-python/?source=post_page-----ca5fdd20dbc--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pw ab is"><div class="px ab co cb py pz"><h2 class="bf gd ii z ja qa jc jd qb jf jh gb bk">Multiple Time Series Forecasting With N-BEATS In Python</h2><div class="qc l"><h3 class="bf b ii z ja qa jc jd qb jf jh dx">Imagine having a robust forecasting solution capable of handling multiple time series data without relying on complex…</h3></div><div class="qd l"><p class="bf b dy z ja qa jc jd qb jf jh dx">forecastegy.com</p></div></div><div class="qe l"><div class="qk l qg qh qi qe qj fq pv"/></div></div></a></div><p id="05aa" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><a class="af fz" href="https://nixtlaverse.nixtla.io/neuralforecast/index.html" rel="noopener ugc nofollow" target="_blank">Neural forecast — Nixtla</a></p><p id="1549" class="pw-post-body-paragraph ms mt gc mu b ha mv mw mx hd my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn fj bk"><a class="af fz" href="https://machinelearningmastery.com/how-to-scale-data-for-long-short-term-memory-networks-in-python/" rel="noopener ugc nofollow" target="_blank">How to scale data for LSTM</a></p></div></div></div></div>    
</body>
</html>