<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Why Machine Learning Is Not Made for Causal Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Why Machine Learning Is Not Made for Causal Estimation</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-machine-learning-is-not-made-for-causal-estimation-f2add4a36e85?source=collection_archive---------0-----------------------#2024-07-18">https://towardsdatascience.com/why-machine-learning-is-not-made-for-causal-estimation-f2add4a36e85?source=collection_archive---------0-----------------------#2024-07-18</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="99f2" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Predictive vs. causal inference: a critical distinction</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@quentin.gallea?source=post_page---byline--f2add4a36e85--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Quentin Gallea, PhD" class="l ep by dd de cx" src="../Images/457af55dd9c6121da7ec97f8e2991c43.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*wzHWI-3NPH0r-C_MwE7-CQ.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f2add4a36e85--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@quentin.gallea?source=post_page---byline--f2add4a36e85--------------------------------" rel="noopener follow">Quentin Gallea, PhD</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f2add4a36e85--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">13 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jul 18, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">15</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/4b6605a18f5ad4bbdf67340018305b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OheiyRPG-YLAtihjLo-jmQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Image by author, generated with Dall-E 3.</figcaption></figure><blockquote class="nc"><p id="7667" class="nd ne fq bf nf ng nh ni nj nk nl nm dx"><em class="nn">“If all you have is a hammer, everything looks like a nail.”</em></p></blockquote><p id="69b4" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">In the era of AI/ML, Machine Learning is often used as a hammer to solve every problem. While ML is profoundly useful and important, ML is not always the solution.</p><p id="7047" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Most importantly, Machine Learning is made essentially for predictive inference, which is inherently different from causal inference. Predictive models are incredibly powerful tools, allowing us to detect patterns and associations, but they fall short in explaining why events occur. This is where causal inference steps in, allowing for more informed decision-making, that can effectively influence outcomes and go beyond mere association.</p><blockquote class="nc"><p id="65f7" class="nd ne fq bf nf ng oo op oq or os nm dx">Predictive inference exploits correlations. So if you know that “Correlation does not imply causation”, you should understand that Machine Learning should not be used blindly to measure causal effects.</p></blockquote><p id="db51" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">Mistaking predictive inference for causal inference can lead to costly mistakes as we are going to see together! To avoid making such mistakes, we will examine the main differences between these two approaches, discuss the limitations of using machine learning for causal estimation, explore how to choose the appropriate method correctly, how often they work together to solve different parts of a question, and explore how both can be effectively integrated within the framework of Causal Machine Learning.</p><h2 id="2423" class="ot ou fq bf ov ow ox oy oz pa pb pc pd nx pe pf pg ob ph pi pj of pk pl pm pn bk">This article will answer the following questions:</h2><ul class=""><li id="7fd1" class="no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm pt pu pv bk"><strong class="nq fr">What is causal inference and what is predictive inference?</strong></li><li id="f67c" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">What are the main differences between them, and why does correlation not imply causation?</strong></li><li id="2b41" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Why is it problematic to use Machine Learning for inferring causal effects?</strong></li><li id="0ae1" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">When should each type of inference be used?</strong></li><li id="3078" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">How can causal and predictive inference be used together?</strong></li><li id="4379" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">What is Causal Machine Learning and how does it fit into this context?</strong></li></ul></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="86fc" class="qj ou fq bf ov qk ql gq oz qm qn gt pd qo qp qq qr qs qt qu qv qw qx qy qz ra bk">What is predictive inference?</h1><p id="d2dc" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Machine Learning is about prediction.</p><p id="023b" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Predictive inference</strong> involves estimating the value of something (an outcome) based on the values of other variables (as they are). If you look outside and people are wearing gloves and hats, it is most certainly cold.</p><p id="1c00" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Examples:</strong></p><ul class=""><li id="81d3" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><strong class="nq fr">Spam filter:</strong> ML algorithms are used to filter incoming emails between safe and spam using the content, the sender, and other various information attached to an email.</li><li id="e102" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Tumor detection:</strong> Machine Learning (Deep Learning) can be used to detect brain tumors from MRI images.</li><li id="d5f4" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Fraud detection:</strong> In banking, ML is used to detect potential fraud based on credit card activity.</li></ul><p id="549a" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Bias-variance:</strong> In predictive inference, you want a model able to predict the outcome well, most of the time out-of-sample (with new unseen data). You might accept a bit of bias if it results in lower variance in the predictions.</p><h1 id="bfe0" class="qj ou fq bf ov qk rb gq oz qm rc gt pd qo rd qq qr qs re qu qv qw rf qy qz ra bk">What is causal inference?</h1><p id="d8cf" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Causal inference is the study of cause and effect. It is about impact evaluation.</p><p id="7126" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Causal inference</strong> aims to measure the value of the outcome when you change the value of something else. In causal inference, you want to know what would happen if you change the value of a variable (feature), everything else equal. This is completely different from predictive inference where you try to predict the value of the outcome for a different observed value of a feature.</p><p id="9a5a" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Examples:</strong></p><ul class=""><li id="d003" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><strong class="nq fr">Marketing campaign ROI:</strong> Causal inference helps to measure the impact (consequence) of a marketing campaign (cause).</li><li id="ea8b" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Political Economy:</strong> Causal inference is often used to measure the effect (consequence) of a policy (cause).</li><li id="d34b" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Medical research:</strong> Causal inference is key to measuring the effect of drugs or behavior (causes) on health outcomes (consequence).</li></ul><p id="7a22" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Bias-variance:</strong> In causal inference, you do not focus on the quality of the prediction with measures like R-square. Causal inference aims to measure an unbiased coefficient. It is possible to have a valid causal inference model with a relatively low predictive power as the causal effect might explain just a small part of the variance of the outcome.</p><p id="2cdb" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Key conceptual difference: </strong>The complexity of causal inference lies in the fact that we want to measure something that we will never actually observe. To measure a causal effect, you need a reference point: the counterfactual. The counterfactual is the world without your treatment or intervention. The causal effect is measured by comparing the observed situation with this reference (the counterfactual).</p><p id="be86" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Imagine that you have a headache. You take a pill and after a while, your headache is gone. But was it thanks to the pill? Was it because you drank tea or plenty of water? Or just because time went by? It is impossible to know which factor or combination of factors helped as all those effects are confounded. The only way to answer this question perfectly would be to have two parallel worlds. In one of the two worlds, you take the pill and in the other, you don’t. As the pill is the only difference between the two situations, it would allow you to claim that it was the cause. But obviously, we do not have parallel worlds to play with. In causal inference, we call this: <strong class="nq fr">The fundamental problem of causal inference</strong>.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rg"><img src="../Images/128b83f7913ca95a4e03a2ffe56a19c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oi8QZ2R3eVm_7wWB5ZJVcw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Ideally we would need parallel worlds to measure causal effects. Image by author.</figcaption></figure><p id="1537" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">So the whole idea of causal inference is to approach this impossible ideal parallel world situation by finding a good counterfactual. This is why the gold standard is randomized experiments. If you randomize the treatment allocation (pill vs. placebo) within a representative group, the only systematic difference (assuming that everything has been done correctly) is the treatment, and hence a statistically significant difference in outcome can be attributed to the treatment.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk rh"><img src="../Images/d708cfe92c4d6173b98708d6f54ce176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Xd3h7F9nRpXHjI6UG1eYQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Illustration of a randomized experiment. Image by author.</figcaption></figure><p id="b889" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Note that randomized experiments have weaknesses and that it is also possible to measure causal effects with observational data. If you want to know more, I explain those concepts and causal inference more in-depth here:</p><div class="ri rj rk rl rm rn"><a rel="noopener follow" target="_blank" href="/the-science-and-art-of-causality-part-1-5d6fb55b7a7c?source=post_page-----f2add4a36e85--------------------------------"><div class="ro ab ig"><div class="rp ab co cb rq rr"><h2 class="bf fr hw z io rs iq ir rt it iv fp bk">The Science and Art of Causality (part 1)</h2><div class="ru l"><h3 class="bf b hw z io rs iq ir rt it iv dx">If we cannot directly test for causality, what should we do?</h3></div><div class="rv l"><p class="bf b dy z io rs iq ir rt it iv dx">towardsdatascience.com</p></div></div><div class="rw l"><div class="rx l ry rz sa rw sb lr rn"/></div></div></a></div></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="ba60" class="qj ou fq bf ov qk ql gq oz qm qn gt pd qo qp qq qr qs qt qu qv qw qx qy qz ra bk">Why does correlation not imply causation?</h1><p id="8edf" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">We all know that “Correlation does not imply causation”. But why?</p><p id="3018" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">There are two main scenarios. First, as illustrated below in Case 1, the positive relationship between drowning accidents and ice cream sales is arguably just due to a common cause: the weather. When it is sunny, both take place, but there is no direct causal link between drowning accidents and ice cream sales. This is what we call a spurious correlation. The second scenario is depicted in Case 2. There is a direct effect of education on performance, but cognitive capacity affects both. So, in this situation, the positive correlation between education and job performance is confounded with the effect of cognitive capacity.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk sc"><img src="../Images/b6b2497b7a2a72016b8143e4e6e77886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NYHecPy8m4f70Y0omEp8MQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">The main reason why “correlation does not imply causation”. The arrows represent the direction of the causal links in causal graphs. Image by author.</figcaption></figure><p id="0da5" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">As I mentioned in the introduction, predictive inference exploits correlations. So anyone who knows that ‘Correlation does not imply causation’ should understand that Machine Learning is not inherently suited for causal inference. Ice cream sales might be a <strong class="nq fr">good predictor</strong> of the risk of drowning accidents the same day even if there is <strong class="nq fr">no causal link</strong>. This relationship is just correlational and driven by a common cause: the weather.</p><p id="46c7" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">However, if you want to study the potential causal effect of ice cream sales on drowning accidents, you must take this third variable (weather) into account. Otherwise, your estimation of the causal link would be biased due to the famous Omitted Variable Bias. Once you include this third variable in your analysis you would most certainly find that the ice cream sales is not affecting drowning accidents anymore. Often, a simple way to address this is to include this variable in the model so that it is not ‘omitted’ anymore. However, confounders are often unobserved, and hence it is not possible to simply include them in the model. Causal inference has numerous ways to address this issue of unobserved confounders, but discussing these is beyond the scope of this article. If you want to learn more about causal inference, you can follow my guide, here:</p><div class="ri rj rk rl rm rn"><a rel="noopener follow" target="_blank" href="/how-to-learn-causal-inference-on-your-own-for-free-98503abc0a06?source=post_page-----f2add4a36e85--------------------------------"><div class="ro ab ig"><div class="rp ab co cb rq rr"><h2 class="bf fr hw z io rs iq ir rt it iv fp bk">How to Learn Causal Inference on Your Own for Free</h2><div class="ru l"><h3 class="bf b hw z io rs iq ir rt it iv dx">The ultimate self-study guide for all levels</h3></div><div class="rv l"><p class="bf b dy z io rs iq ir rt it iv dx">towardsdatascience.com</p></div></div><div class="rw l"><div class="sd l ry rz sa rw sb lr rn"/></div></div></a></div><blockquote class="nc"><p id="50b5" class="nd ne fq bf nf ng nh ni nj nk nl nm dx">Hence, a central difference between causal and predictive inference is the way you select the “features”.</p></blockquote><p id="a5e8" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">In Machine Learning, you usually include features that might improve the prediction quality, and your algorithm can help to select the best features based on predictive power. However, in causal inference, some features should be included at all costs (confounders/common causes) even if the predictive power is low and the effect is not statistically significant. It is not the predictive power of the confounder that is the primary interest but rather how it affects the coefficient of the cause we are studying. Moreover, there are features that should not be included in the causal inference model, for example, mediators. A mediator represents an indirect causal pathway and controlling for such variables would prevent measuring the total causal effect of interest (see illustration below). Hence, the major difference lies in the fact that the inclusion or not of the feature in causal inference depends on the assumed causal relationship between variables.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk se"><img src="../Images/22306ceaf8d5284aea4098b5dbbc4ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*6Iti2QUnt-WVruLdv-ahng.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Illustration of a mediator. Here Motivation is a mediator of the effect of training on productivity. Imagine that training for the staff increases their productivity directly but also indirectly through their motivation. The employees are now more motivated because they learned new skills and see that the employer put effort into upskilling the employees. If you want to measure the effect of the training, most of the time, you want to measure the total effect of the treatment (direct and indirect), and including motivation as a control variable would prevent doing so. Image by author.</figcaption></figure><p id="f4bd" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">This is a subtle topic. Please refer to <a class="af sf" href="https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf" rel="noopener ugc nofollow" target="_blank">“A Crash Course in Good and Bad Controls” Cinelli et al. (2002)</a> for more details.</p><h1 id="dbbb" class="qj ou fq bf ov qk rb gq oz qm rc gt pd qo rd qq qr qs re qu qv qw rf qy qz ra bk">Why is it problematic to use Machine Learning for inferring causal effects?</h1><p id="dd76" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Imagine that you interpret the positive association between ice cream sales and drowning accidents as causal. You might want to ban ice cream at all costs. But of course, that would have potentially little to no effect on the outcome.</p><p id="7ba7" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">A famous correlation is the one between chocolate consumption and Nobel prize laureates <a class="af sf" href="https://www.biostat.jhsph.edu/courses/bio621/misc/Chocolate%20consumption%20cognitive%20function%20and%20nobel%20laurates%20(NEJM).pdf" rel="noopener ugc nofollow" target="_blank">(Messerli (2012))</a>. The author found a 0.8 linear correlation coefficient between the two variables at the country level. While this sounds like a great argument to eat more chocolate, it should not be interpreted causally. (Note that the arguments of a potential causal relationship presented in Messerli (2012) have been disproved later (e.g., <a class="af sf" href="https://pubmed.ncbi.nlm.nih.gov/23616517/" rel="noopener ugc nofollow" target="_blank">P Maurage et al. (2013)</a>).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk sg"><img src="../Images/97a0dbb3e33556c6fa6d8fd4cfa6e5bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d6LRQUAPE5wX1AfmgbsQ6Q.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Positive correlation between Nobel Laureates per 10 million population and Chocolate Consumption (kg/yr/capita) found in (Messerli (2012)). Image by author.</figcaption></figure><p id="fc64" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Now let me share a more serious example. Imagine trying to optimize the posts of a content creator. To do so, you build an ML model including numerous features. The analysis revealed that posts published late afternoon or in the evening have the best performance. Hence, you recommend a precise schedule where you post exclusively between 5 pm and 9 pm. Once implemented, the impressions per post crashed. What happened? The ML algorithm predicts based on current patterns, interpreting the data as it appears: posts made late in the day correlate with higher impressions. Eventually, the posts published in the evening were the ones more spontaneous, less planned, and where the author didn’t aim to please the audience in particular but just shared something valuable. So the timing was not the cause; it was the nature of the post. This spontaneous nature might be harder to capture with the ML model (even if you code some features as length, tone, etc., it might not be trivial to capture this).</p><p id="ea52" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">In marketing, predictive models are often used to measure the ROI of a marketing campaign.</p><blockquote class="nc"><p id="1692" class="nd ne fq bf nf ng oo op oq or os nm dx">Often, models such as simple <strong class="al">Marketing Mix Modeling (MMM)</strong> suffer from omitted variable bias and the measure of ROI will be misleading.</p></blockquote><p id="173a" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">Typically, the behavior of the competitors might correlate with our campaign and also affect our sales. If this is not taken into account properly, the ROI might be under or over-evaluated, leading to sub-optimal business decisions and ad spending.</p><p id="5cf8" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">This concept is also important for policy and decision-making. At the beginning of the Covid-19 pandemic, a French “expert” used a graph to argue that lockdowns were counterproductive (see figure below). The graph revealed a positive correlation between the stringency of the lockdown and the number of Covid-related deaths (more severe lockdowns were associated with more deaths). However, this relationship was most likely driven by the opposite causal relationship: when the situation was bad (lots of deaths), countries would impose strict measures. This is called reverse causation. Indeed, when you study properly the trajectory of the number of cases and deaths within a country around the lockdowns controlling for potential confounders, you find a strong negative effect (c.f. <a class="af sf" href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2022.4652" rel="noopener ugc nofollow" target="_blank">Bonardi et al. (2023)</a>).</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk sh"><img src="../Images/ee131f954f320b94dea06a8f9aa406df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LEtVAOU9HTlr-ZEb5HU1Fw.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Replication of the graph used to argue that lockdowns were ineffective. The green corresponds to the lowest lockdown measure and the red the most restrictive. Image by author.</figcaption></figure><h1 id="93b7" class="qj ou fq bf ov qk rb gq oz qm rc gt pd qo rd qq qr qs re qu qv qw rf qy qz ra bk">When should each type of inference be used?</h1><blockquote class="nc"><p id="5748" class="nd ne fq bf nf ng oo op oq or os nm dx">Machine learning and causal inference are both profoundly useful; they just serve different purposes.</p></blockquote><p id="d2da" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">As usual with numbers and with statistics, most of the time the problem is not the metrics but their interpretation. Hence, a correlation is informative, it becomes problematic only if you interpret it blindly as a causal effect.</p><p id="8360" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">When to use Causal Inference: </strong>When you want to understand the cause-and-effect relationship and do impact evaluation.</p><ul class=""><li id="94fa" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><strong class="nq fr">Policy Evaluation:</strong> To determine the impact of a new policy, such as the effect of a new educational program on student performance.</li><li id="b301" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Medical Studies:</strong> To assess the effectiveness of a new drug or treatment on health outcomes.</li><li id="3776" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Economics:</strong> To understand the effect of interest rate changes on economic indicators like inflation or employment.</li><li id="b835" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Marketing:</strong> To evaluate the impact of a marketing campaign on sales.</li></ul><p id="2911" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Key Questions in Causal Inference:</strong></p><ul class=""><li id="c02e" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk">What is the effect of X on Y?</li><li id="5a7c" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk">Does changing X cause a change in Y?</li><li id="0fc5" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk">What would happen to Y if we intervene on X?</li></ul><p id="0687" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">When to use Predictive Inference</strong>: When you want to do accurate prediction (association between features and outcome) and learn patterns from the data.</p><ul class=""><li id="f533" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><strong class="nq fr">Risk Assessment:</strong> To predict the likelihood of credit default or insurance claims.</li><li id="cc98" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Recommendation Systems:</strong> To suggest products or content to users based on their past behavior.</li><li id="f918" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><strong class="nq fr">Diagnostics:</strong> To classify medical images for disease detection.</li></ul><p id="d6a4" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Key Questions for Predictive Inference:</strong></p><ul class=""><li id="4f42" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk">What is the expected value of Y given X?</li><li id="1550" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk">Can we predict Y based on new data about X?</li><li id="5523" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk">How accurately can we forecast Y using current and historical data on X?</li></ul></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="a711" class="qj ou fq bf ov qk ql gq oz qm qn gt pd qo qp qq qr qs qt qu qv qw qx qy qz ra bk">How can causal and predictive inference be used together?</h1><p id="2031" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">While causal and predictive inference serve different purposes, they sometimes work together. Dima Goldenberg, Senior Machine Learning Manager at Booking.com, illustrated this perfectly in a <a class="af sf" href="https://www.youtube.com/watch?v=xkx1tXLAP-o" rel="noopener ugc nofollow" target="_blank">podcast</a> with Aleksander Molak (author of ‘Causal Inference and Discovery in Python’).</p><p id="cba0" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Booking.com is obviously working hard on recommendation systems. “Recommendation” is a prediction problem: “What type of product would client X prefer to see?” Hence, this first step is typically solved with Machine Learning. However, there is another connected question: “What is the effect of this new recommendation system on sales/conversion, etc.?” Here, the keyword <strong class="nq fr">“effect … on” </strong>should directly make you realize that you must use causal inference for this second step. This step will require causal inference and more precisely randomized experiments (A/B testing).</p><blockquote class="nc"><p id="2fad" class="nd ne fq bf nf ng oo op oq or os nm dx">This is a typical workflow including complementary roles of Machine Learning and Causal Inference. You develop a predictive model with Machine Learning and you evaluate its impact with Causal Inference.</p></blockquote><h1 id="c64b" class="qj ou fq bf ov qk rb gq oz qm rc gt pd qo si qq qr qs sj qu qv qw sk qy qz ra bk">So, what is Causal Machine Learning and how does it fit into this context?</h1><p id="469d" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Recently, a new field emerged: Causal Machine Learning. While this is an important breakthrough, I think that it added to the confusion.</p><blockquote class="nc"><p id="8ce6" class="nd ne fq bf nf ng oo op oq or os nm dx">Many people see the term “Causal ML” and just think that they can use Machine Learning carelessly for causal inference.</p></blockquote><p id="ab1d" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">Causal ML is an elegant combination of both worlds. However, Causal ML is not Machine Learning used blindly for Causal Inference. It is rather Causal Inference with ML sprinkled on top of it to improve the results. The key differentiating concept of causal inference is still valid with Causal ML. The feature selection relies on the assumed causal relationships.</p><p id="70c3" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">Let me present the two main methods in Causal ML to illustrate this interesting combination.</p><h2 id="0190" class="ot ou fq bf ov ow ox oy oz pa pb pc pd nx pe pf pg ob ph pi pj of pk pl pm pn bk">A. Dealing with High-Dimensional Data and Complex Functional Forms</h2><p id="3b28" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">In some situations, you have numerous control variables in your causal inference models. To reduce the risk of omitted variable bias, you included many potential confounders. How should you deal with this high number of controls? Maybe you have multicollinearity between sets of controls, or maybe you should control for non-linear effects or interactions. This can quickly become very complex and quite arbitrary to solve with traditional causal inference methods.</p><p id="8441" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">As Machine Learning is particularly efficient in dealing with high-dimensional data, it can be used to address these challenges. Machine Learning will be used to find the best set of controls and the right functional form in such a way that your model will not suffer from multicollinearity while still satisfying the conditions to measure a causal effect (see: Double Machine Learning Method).</p><h2 id="9659" class="ot ou fq bf ov ow ox oy oz pa pb pc pd nx pe pf pg ob ph pi pj of pk pl pm pn bk">B. Heterogenous Treatment Effects</h2><p id="4def" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Causal Inference historically focused on measuring the Average Treatment Effect (ATE), which is a measure of the average effect of a treatment. However, as you are certainly aware, the average is useful, but it can also be misleading. The effect of the treatment could lead to different effects depending on the subject. Imagine that a new drug reduces the risk of cancer significantly on average, but actually, the whole effect is driven by the results on men, while the effect on women is null. Or imagine a marketing campaign leading to a higher conversion rate on average while it actually has a negative impact in a specific region.</p><blockquote class="nc"><p id="355e" class="nd ne fq bf nf ng oo op oq or os nm dx">Causal ML allows us to go beyond Average Treatment Effect and uncover this heterogeneity by identifying the Conditional Average Treatment Effect (CATE). In other words, it helps to identify the treatment effect conditionally on different characteristics of the subjects.</p></blockquote><p id="1de1" class="pw-post-body-paragraph no np fq nq b go nr ns nt gr nu nv nw nx ny nz oa ob oc od oe of og oh oi nm fj bk">The main method to uncover the Conditional Average Treatment Effect is called Causal Forest. However, it is important to note that while this methodology will allow us to find sub-groups with different reactions to a treatment, the characteristics defining such groups uncovered with Machine Learning are not necessarily causal. Imagine that the model reveals that the effect of an Ad is completely different for smartphone users vs. tablet users. The ‘device’ should not be interpreted as the cause for this difference. It could be that the real cause is not measured but correlates with this feature, for example, age.</p></div></div></div><div class="ab cb qb qc qd qe" role="separator"><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh qi"/><span class="qf by bm qg qh"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="ebc9" class="qj ou fq bf ov qk ql gq oz qm qn gt pd qo qp qq qr qs qt qu qv qw qx qy qz ra bk">Conclusion</h1><p id="bfdb" class="pw-post-body-paragraph no np fq nq b go po ns nt gr pp nv nw nx pq nz oa ob pr od oe of ps oh oi nm fj bk">Distinguishing predictive from causal inference is central today to avoid costly mistakes in various domains like marketing, policy-making, and medical research. We examined why machine learning, despite its remarkable predictive capabilities, is not intrinsically suited to causal inference due to its reliance on correlations/associations rather than causal relationships. Hopefully, you will be able to understand this distinction and pick the right model for the right type of questions.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk sl"><img src="../Images/630306462fc50e607b6531c292a14222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ta8YjXDX_y0JoBvIx0JaBA.jpeg"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Illustration of why mistaking a correlation for a causal effect lead to bad decisions. Credit War and Peas, Elizabeth Pich &amp; Jonathan Kunz.</figcaption></figure><p id="6335" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk">If you want to learn more about causal machine learning here are a few valuable and reliable <strong class="nq fr">resources:</strong></p><p id="cc80" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Causal Machine Learning:</strong></p><ul class=""><li id="d1ca" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><a class="af sf" href="https://ijbms.net/assets/files/1721058154.pdf" rel="noopener ugc nofollow" target="_blank">Causal Machine Learning in Marketing</a></li><li id="5f30" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><a class="af sf" href="https://arxiv.org/abs/2101.00878" rel="noopener ugc nofollow" target="_blank">The Value Added of Machine Learning to Causal Inference: Evidence from Revisited Studies</a></li><li id="6ae7" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><a class="af sf" href="https://www.nature.com/articles/s41591-024-02902-1" rel="noopener ugc nofollow" target="_blank">Causal machine learning for predicting treatment outcomes</a></li></ul><p id="84f0" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Double Machine Learning:</strong></p><ul class=""><li id="55f6" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><a class="af sf" href="https://matheusfacure.github.io/python-causality-handbook/22-Debiased-Orthogonal-Machine-Learning.html" rel="noopener ugc nofollow" target="_blank">Matheus Facure book cha</a>pter</li><li id="eee6" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><a class="af sf" href="https://arxiv.org/abs/1608.00060" rel="noopener ugc nofollow" target="_blank">Research paper presenting the methodology</a></li></ul><p id="1fc0" class="pw-post-body-paragraph no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm fj bk"><strong class="nq fr">Heterogenous Treatment Effect:</strong></p><ul class=""><li id="3086" class="no np fq nq b go oj ns nt gr ok nv nw nx ol nz oa ob om od oe of on oh oi nm pt pu pv bk"><a class="af sf" href="https://matheusfacure.github.io/python-causality-handbook/18-Heterogeneous-Treatment-Effects-and-Personalization.html" rel="noopener ugc nofollow" target="_blank">Matheus Facure book chapter</a></li><li id="28bf" class="no np fq nq b go pw ns nt gr px nv nw nx py nz oa ob pz od oe of qa oh oi nm pt pu pv bk"><a class="af sf" href="https://www.gsb.stanford.edu/faculty-research/labs-initiatives/sil/research/methods/ai-machine-learning/short-course" rel="noopener ugc nofollow" target="_blank">Stanford class by Susan Athe</a>y</li></ul></div></div></div></div>    
</body>
</html>