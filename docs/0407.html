<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Text Embeddings: Comprehensive Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Text Embeddings: Comprehensive Guide</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5?source=collection_archive---------0-----------------------#2024-02-13">https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5?source=collection_archive---------0-----------------------#2024-02-13</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="65ec" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Evolution, visualisation, and applications of text embeddings</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://miptgirl.medium.com/?source=post_page---byline--afd97fce8fb5--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mariya Mansurova" class="l ep by dd de cx" src="../Images/b1dd377b0a1887db900cc5108bca8ea8.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*7fFHr8XBAuR_SgJknIyODA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--afd97fce8fb5--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://miptgirl.medium.com/?source=post_page---byline--afd97fce8fb5--------------------------------" rel="noopener follow">Mariya Mansurova</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--afd97fce8fb5--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">20 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Feb 13, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">20</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj"><div class="ab cb"><div class="lm mk ln ml lo mm cf mn cg mo ci bh"><figure class="ms mt mu mv mw mj mx my paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq mr"><img src="../Images/edce20eff0ac79af415ddaee3b40cfc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*0OVy_qF0NLJOyUnfz8lRzg.jpeg"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by DALL-E 3</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="4323" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As human beings, we can read and understand texts (at least some of them). Computers in opposite “think in numbers”, so they can’t automatically grasp the meaning of words and sentences. If we want computers to understand the natural language, we need to convert this information into the format that computers can work with — vectors of numbers.</p><p id="a06e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">People learned how to convert texts into machine-understandable format many years ago (one of the first versions was <a class="af of" href="https://en.wikipedia.org/wiki/ASCII" rel="noopener ugc nofollow" target="_blank">ASCII</a>). Such an approach helps render and transfer texts but doesn’t encode the meaning of the words. At that time, the standard search technique was a keyword search when you were just looking for all the documents that contained specific words or N-grams.</p><p id="9c04" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Then, after decades, embeddings have emerged. We can calculate embeddings for words, sentences, and even images. Embeddings are also vectors of numbers, but they can capture the meaning. So, you can use them to do a semantic search and even work with documents in different languages.</p><p id="e509" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In this article, I would like to dive deeper into the embedding topic and discuss all the details:</p><ul class=""><li id="1b22" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">what preceded the embeddings and how they evolved,</li><li id="cfb0" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">how to calculate embeddings using OpenAI tools,</li><li id="f9f2" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">how to define whether sentences are close to each other,</li><li id="5721" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">how to visualise embeddings,</li><li id="14a7" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">the most exciting part is how you could use embeddings in practice.</li></ul><p id="39e6" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s move on and learn about the evolution of embeddings.</p><h1 id="4ca9" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Evolution of Embeddings</h1><p id="3345" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We will start our journey with a brief tour into the history of text representations.</p><h2 id="e233" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Bag of Words</h2><p id="9d62" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The most basic approach to converting texts into vectors is a bag of words. Let’s look at one of the famous quotes of Richard P. Feynman<em class="qg">“We are lucky to live in an age in which we are still making discoveries”. </em>We will use it to illustrate a bag of words approach.</p><p id="0e7f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The first step to get a bag of words vector is to split the text into words (tokens) and then reduce words to their base forms. For example, <em class="qg">“running”</em> will transform into <em class="qg">“run”</em>. This process is called stemming. We can use the NLTK Python package for it.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="bbc3" class="ql op fq qi b bg qm qn l qo qp">from nltk.stem import SnowballStemmer<br/>from nltk.tokenize import word_tokenize<br/><br/>text = 'We are lucky to live in an age in which we are still making discoveries'<br/><br/># tokenization - splitting text into words<br/>words = word_tokenize(text)<br/>print(words)<br/># ['We', 'are', 'lucky', 'to', 'live', 'in', 'an', 'age', 'in', 'which',<br/>#  'we', 'are', 'still', 'making', 'discoveries']<br/><br/>stemmer = SnowballStemmer(language = "english")<br/>stemmed_words = list(map(lambda x: stemmer.stem(x), words))<br/>print(stemmed_words)<br/># ['we', 'are', 'lucki', 'to', 'live', 'in', 'an', 'age', 'in', 'which', <br/>#  'we', 'are', 'still', 'make', 'discoveri']</span></pre><p id="2dd9" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Now, we have a list of base forms of all our words. The next step is to calculate their frequencies to create a vector.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="d493" class="ql op fq qi b bg qm qn l qo qp">import collections<br/>bag_of_words = collections.Counter(stemmed_words)<br/>print(bag_of_words)<br/># {'we': 2, 'are': 2, 'in': 2, 'lucki': 1, 'to': 1, 'live': 1, <br/># 'an': 1, 'age': 1, 'which': 1, 'still': 1, 'make': 1, 'discoveri': 1}</span></pre><p id="30cc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Actually, if we wanted to convert our text into a vector, we would have to take into account not only the words we have in the text but the whole vocabulary. Let’s assume we also have <em class="qg">“i”</em>, <em class="qg">“you”</em> and <em class="qg">”study”</em> in our vocabulary and let’s create a vector from Feynman’s quote.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qq"><img src="../Images/352726337fbddb935f18fb369b489d69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5AP-lvW7c0fD5Pa6suhJQ.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Graph by author</figcaption></figure><p id="49aa" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This approach is quite basic, and it doesn’t take into account the semantic meaning of the words, so the sentences <em class="qg">“the girl is studying data science”</em> and <em class="qg">“the young woman is learning AI and ML”</em> won’t be close to each other.</p><h2 id="0e3d" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">TF-IDF</h2><p id="9e81" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">A slightly improved version of the bag of the words approach is <a class="af of" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"><strong class="nl fr">TF-IDF</strong></a> (<em class="qg">Term Frequency — Inverse Document Frequency</em>). It’s the multiplication of two metrics.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qr"><img src="../Images/48834842d5c59c0eb25c7ba84ffa02da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bt4EIN6sSmoFix_ImYZPtQ.png"/></div></div></figure><ul class=""><li id="d6fa" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk"><strong class="nl fr">Term Frequency </strong>shows the frequency of the word in the document. The most common way to calculate it is to divide the raw count of the term in this document (like in the bag of words) by the total number of terms (words) in the document. However, there are many other approaches like just raw count, boolean “frequencies”, and different approaches to normalisation. You can learn more about different approaches on <a class="af of" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">Wikipedia</a>.</li></ul><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qs"><img src="../Images/4b88c942246dd26a9376e31a1c7eb065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jZJ6EsX8l5Am9LL3ZMVMfg.png"/></div></div></figure><ul class=""><li id="23d4" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk"><strong class="nl fr">Inverse Document Frequency</strong> denotes how much information the word provides. For example, the words <em class="qg">“a”</em> or <em class="qg">“that”</em> don’t give you any additional information about the document’s topic. In contrast, words like <em class="qg">“ChatGPT”</em> or <em class="qg">“bioinformatics”</em> can help you define the domain (but not for this sentence). It’s calculated as the logarithm of the ratio of the total number of documents to those containing the word. The closer IDF is to 0 — the more common the word is and the less information it provides.</li></ul><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qt"><img src="../Images/a07031a5a4933e2fb90ac8384d62f5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EUJyikNdYu4b_8bUW5M3AA.png"/></div></div></figure><p id="0dcd" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, in the end, we will get vectors where common words (like <em class="qg">“I”</em> or <em class="qg">“you”</em>) will have low weights, while rare words that occur in the document multiple times will have higher weights. This strategy will give a bit better results, but it still can’t capture semantic meaning.</p><p id="3281" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The other challenge with this approach is that it produces pretty sparse vectors. The length of the vectors is equal to the corpus size. There are about 470K unique words in English (<a class="af of" href="https://en.wikipedia.org/wiki/List_of_dictionaries_by_number_of_words" rel="noopener ugc nofollow" target="_blank">source</a>), so we will have huge vectors. Since the sentence won’t have more than 50 unique words, 99.99% of the values in vectors will be 0, not encoding any info. Looking at this, scientists started to think about dense vector representation.</p><h2 id="b857" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Word2Vec</h2><p id="0ede" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">One of the most famous approaches to dense representation is word2vec, proposed by Google in 2013 in the paper <a class="af of" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">“Efficient Estimation of Word Representations in Vector Space”</a> by Mikolov et al.</p><p id="a974" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">There are two different word2vec approaches mentioned in the paper: Continuous Bag of Words (when we predict the word based on the surrounding words) and Skip-gram (the opposite task — when we predict context based on the word).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qu"><img src="../Images/a55f2b25a828530cca95fcce2c9901fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcijYYy4Pe9uxsD3_rEiVg.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Figure from the paper by Mikolov et al. 2013 | <a class="af of" href="https://arxiv.org/pdf/1301.3781.pdf" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><p id="fac2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The high-level idea of dense vector representation is to train two models: encoder and decoder. For example, in the case of skip-gram, we might pass the word <em class="qg">“christmas”</em> to the encoder. Then, the encoder will produce a vector that we pass to the decoder expecting to get the words <em class="qg">“merry”</em>, <em class="qg">“to”</em>, and <em class="qg">“you”</em>.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qv"><img src="../Images/eaa26d1a1c68799c60dfe915ea18569b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z43XWknO52TbT4M9hxfZ7g.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Scheme by author</figcaption></figure><p id="1d6e" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This model started to take into account the meaning of the words since it’s trained on the context of the words. However, it ignores morphology (information we can get from the word parts, for example, that “<em class="qg">-less”</em> means the lack of something). This drawback was addressed later by looking at subword skip-grams in <a class="af of" href="https://www-nlp.stanford.edu/pubs/glove.pdf" rel="noopener ugc nofollow" target="_blank">GloVe</a>.</p><p id="ed4f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, word2vec was capable of working only with words, but we would like to encode whole sentences. So, let’s move on to the next evolutional step with transformers.</p><h2 id="0fe3" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Transformers and Sentence Embeddings</h2><p id="2f31" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The next evolution was related to the transformers approach introduced in the <a class="af of" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">“Attention Is All You Need”</a> paper by Vaswani et al. Transformers were able to produce information-reach dense vectors and become the dominant technology for modern language models.</p><p id="afed" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I won’t cover the details of the transformers’ architecture since it’s not so relevant to our topic and would take a lot of time. If you’re interested in learning more, there are a lot of materials about transformers, for example, <a class="af of" href="https://daleonai.com/transformers-explained" rel="noopener ugc nofollow" target="_blank">“Transformers, Explained”</a> or <a class="af of" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">“The Illustrated Transformer”</a>.</p><p id="9db8" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Transformers allow you to use the same “core” model and fine-tune it for different use cases without retraining the core model (which takes a lot of time and is quite costly). It led to the rise of pre-trained models. One of the first popular models was BERT (Bidirectional Encoder Representations from Transformers) by Google AI.</p><p id="2cbe" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Internally, BERT still operates on a token level similar to word2vec, but we still want to get sentence embeddings. So, the naive approach could be to take an average of all tokens’ vectors. Unfortunately, this approach doesn’t show good performance.</p><p id="aa2a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This problem was solved in 2019 when <a class="af of" href="https://arxiv.org/abs/1908.10084" rel="noopener ugc nofollow" target="_blank">Sentence-BERT</a> was released. It outperformed all previous approaches to semantic textual similarity tasks and allowed the calculation of sentence embeddings.</p><p id="aa6f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It’s a huge topic so we won’t be able to cover it all in this article. So, if you’re really interested, you can learn more about the sentence embeddings in <a class="af of" href="https://www.pinecone.io/learn/series/nlp/sentence-embeddings/" rel="noopener ugc nofollow" target="_blank">this article</a>.</p><p id="f983" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve briefly covered the evolution of embeddings and got a high-level understanding of the theory. Now, it’s time to move on to practice and lear how to calculate embeddings using OpenAI tools.</p><h1 id="5a5a" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Calculating embeddings</h1><p id="7dd6" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In this article, we will be using OpenAI embeddings. We will try a new model <code class="cx qw qx qy qi b">text-embedding-3-small</code> that was <a class="af of" href="https://openai.com/blog/new-embedding-models-and-api-updates" rel="noopener ugc nofollow" target="_blank">released</a> just recently. The new model shows better performance compared to <code class="cx qw qx qy qi b">text-embedding-ada-002</code>:</p><ul class=""><li id="8673" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">The average score on a widely used multi-language retrieval (<a class="af of" href="https://github.com/project-miracl/miracl" rel="noopener ugc nofollow" target="_blank">MIRACL</a>) benchmark has risen from 31.4% to 44.0%.</li><li id="2649" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">The average performance on a frequently used benchmark for English tasks (<a class="af of" href="https://github.com/embeddings-benchmark/mteb" rel="noopener ugc nofollow" target="_blank">MTEB</a>) has also improved, rising from 61.0% to 62.3%.</li></ul><p id="b0bf" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">OpenAI also released a new larger model <code class="cx qw qx qy qi b">text-embedding-3-large</code>. Now, it’s their best performing embedding model.</p><p id="3bbb" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As a data source, we will be working with a small sample of <a class="af of" href="https://archive.org/details/stackexchange" rel="noopener ugc nofollow" target="_blank">Stack Exchange Data Dump</a> — an anonymised dump of all user-contributed content on the <a class="af of" href="https://stackexchange.com/" rel="noopener ugc nofollow" target="_blank">Stack Exchange network</a>. I’ve selected a bunch of topics that look interesting to me and sample 100 questions from each of them. Topics range from Generative AI to coffee or bicycles so that we will see quite a wide variety of topics.</p><p id="b840" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, we need to calculate embeddings for all our Stack Exchange questions. It’s worth doing it once and storing results locally (in a file or vector storage). We can generate embeddings using the OpenAI Python package.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="8746" class="ql op fq qi b bg qm qn l qo qp">from openai import OpenAI<br/>client = OpenAI()<br/><br/>def get_embedding(text, model="text-embedding-3-small"):<br/>   text = text.replace("\n", " ")<br/>   return client.embeddings.create(input = [text], model=model)\<br/>       .data[0].embedding<br/><br/>get_embedding("We are lucky to live in an age in which we are still making discoveries.")<br/></span></pre><p id="db45" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As a result, we got a 1536-dimension vector of float numbers. We can now repeat it for all our data and start analysing the values.</p><p id="0620" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The primary question you might have is how close the sentences are to each other by meaning. To uncover answers, let’s discuss the concept of distance between vectors.</p><h1 id="af85" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Distance between vectors</h1><p id="9c7b" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Embeddings are actually vectors. So, if we want to understand how close two sentences are to each other, we can calculate the distance between vectors. A smaller distance would be equivalent to a closer semantic meaning.</p><p id="acd3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Different metrics can be used to measure the distance between two vectors:</p><ul class=""><li id="919b" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">Euclidean distance (L2),</li><li id="86af" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Manhattant distance (L1),</li><li id="3331" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Dot product,</li><li id="3dd1" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Cosine distance.</li></ul><p id="d8f0" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s discuss them. As a simple example, we will be using two 2D vectors.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="06b9" class="ql op fq qi b bg qm qn l qo qp">vector1 = [1, 4]<br/>vector2 = [2, 2]</span></pre><h2 id="d639" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Euclidean distance (L2)</h2><p id="a3fd" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The most standard way to define distance between two points (or vectors) is Euclidean distance or L2 norm. This metric is the most commonly used in day-to-day life, for example, when we are talking about the distance between 2 towns.</p><p id="505d" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Here’s a visual representation and formula for L2 distance.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq qz"><img src="../Images/e4d3008368443f6d56ba82b20c182b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PU2NZcYE0J309KFvV5Or4g.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="5bb9" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can calculate this metric using vanilla Python or leveraging the numpy function.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="f646" class="ql op fq qi b bg qm qn l qo qp">import numpy as np<br/><br/>sum(list(map(lambda x, y: (x - y) ** 2, vector1, vector2))) ** 0.5<br/># 2.2361<br/><br/>np.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 2)<br/># 2.2361</span></pre><h2 id="2fe2" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Manhattant distance (L1)</h2><p id="1f6c" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The other commonly used distance is the L1 norm or Manhattan distance. This distance was called after the island of Manhattan (New York). This island has a grid layout of streets, and the shortest routes between two points in Manhattan will be L1 distance since you need to follow the grid.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ra"><img src="../Images/f4e01e943ce4e010819197e8f2110ce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LP_dKBXD7opCecf4c5NWmA.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="74a6" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can also implement it from scratch or use the numpy function.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="9ab6" class="ql op fq qi b bg qm qn l qo qp">sum(list(map(lambda x, y: abs(x - y), vector1, vector2)))<br/># 3<br/><br/>np.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 1)<br/># 3.0</span></pre><h2 id="7a86" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Dot product</h2><p id="53ac" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Another way to look at the distance between vectors is to calculate a dot or scalar product. Here’s a formula and we can easily implement it.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rb"><img src="../Images/d3e514aa4acf640b217c3c129beb49f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpxhK7WnG_Nu9kvy80FXyw.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="de75" class="ql op fq qi b bg qm qn l qo qp">sum(list(map(lambda x, y: x*y, vector1, vector2)))<br/># 11<br/><br/>np.dot(vector1, vector2)<br/># 11</span></pre><p id="e1f2" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This metric is a bit tricky to interpret. On the one hand, it shows you whether vectors are pointing in one direction. On the other hand, the results highly depend on the magnitudes of the vectors. For example, let’s calculate the dot products between two pairs of vectors:</p><ul class=""><li id="4444" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk"><code class="cx qw qx qy qi b">(1, 1)</code> vs <code class="cx qw qx qy qi b">(1, 1)</code></li><li id="bfa5" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk"><code class="cx qw qx qy qi b">(1, 1)</code> vs <code class="cx qw qx qy qi b">(10, 10)</code>.</li></ul><p id="01ca" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In both cases, vectors are collinear, but the dot product is ten times bigger in the second case: 2 vs 20.</p><h2 id="0a36" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Cosine similarity</h2><p id="82d9" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Quite often, cosine similarity is used. Cosine similarity is a dot product normalised by vectors’ magnitudes (or normes).</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rc"><img src="../Images/a44f78804a4d51ccf45138b17cc279c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqKHhH36cgOsqtdV2E-X7Q.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="fe69" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can either calculate everything ourselves (as previously) or use the function from sklearn.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="6aa2" class="ql op fq qi b bg qm qn l qo qp">dot_product = sum(list(map(lambda x, y: x*y, vector1, vector2)))<br/>norm_vector1 = sum(list(map(lambda x: x ** 2, vector1))) ** 0.5<br/>norm_vector2 = sum(list(map(lambda x: x ** 2, vector2))) ** 0.5<br/><br/>dot_product/norm_vector1/norm_vector2<br/><br/># 0.8575<br/><br/>from sklearn.metrics.pairwise import cosine_similarity<br/><br/>cosine_similarity(<br/>  np.array(vector1).reshape(1, -1), <br/>  np.array(vector2).reshape(1, -1))[0][0]<br/><br/># 0.8575</span></pre><p id="1721" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The function <code class="cx qw qx qy qi b">cosine_similarity</code> expects 2D arrays. That’s why we need to reshape the numpy arrays.</p><p id="3811" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s talk a bit about the physical meaning of this metric. Cosine similarity is equal to the cosine between two vectors. The closer the vectors are, the higher the metric value.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rd"><img src="../Images/f20da9af06b65db763be0113f19108f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WldnKKhKiEVXJkiskfSPsA.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="bb7b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can even calculate the exact angle between our vectors in degrees. We get results around 30 degrees, and it looks pretty reasonable.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="6d82" class="ql op fq qi b bg qm qn l qo qp">import math<br/>math.degrees(math.acos(0.8575))<br/><br/># 30.96</span></pre><h2 id="5dfa" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">What metric to use?</h2><p id="160a" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We’ve discussed different ways to calculate the distance between two vectors, and you might start thinking about which one to use.</p><p id="459a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You can use any distance to compare the embeddings you have. For example, I calculated the average distances between the different clusters. Both L2 distance and cosine similarity show us similar pictures:</p><ul class=""><li id="7eff" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">Objects within a cluster are closer to each other than to other clusters. It’s a bit tricky to interpret our results since for L2 distance, closer means lower distance, while for cosine similarity — the metric is higher for closer objects. Don’t get confused.</li><li id="00ba" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">We can spot that some topics are really close to each other, for example, <em class="qg">“politics”</em> and <em class="qg">“economics”</em> or <em class="qg">“ai”</em> and <em class="qg">“datascience”</em>.</li></ul><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq re"><img src="../Images/c2b2f26c939f419047e52a0c1c7a1fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LsoVYMBbklb07krWEn8DMA.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rf"><img src="../Images/4dc3fdc10fb1dc9616d7ff13a18d177e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VH7CMZZhuT-sZ9XUkH0xgQ.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="dbbe" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, for NLP tasks, the best practice is usually to use cosine similarity. Some reasons behind it:</p><ul class=""><li id="9ab4" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">Cosine similarity is between -1 and 1, while L1 and L2 are unbounded, so it’s easier to interpret.</li><li id="2bf6" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">From the practical perspective, it’s more effective to calculate dot products than square roots for Euclidean distance.</li><li id="33b1" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Cosine similarity is less affected by the curse of dimensionality (we will talk about it in a second).</li></ul><blockquote class="rg rh ri"><p id="a978" class="nj nk qg nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">OpenAI embeddings are already normed, so dot product and cosine similarity are equal in this case.</p></blockquote><p id="f9e6" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">You might spot in the results above that the difference between inter- and intra-cluster distances is not so big. The root cause is the high dimensionality of our vectors. This effect is called “the curse of dimensionality”: the higher the dimension, the narrower the distribution of distances between vectors. You can learn more details about it in <a class="af of" href="https://towardsai.net/p/l/why-should-euclidean-distance-not-be-the-default-distance-measure" rel="noopener ugc nofollow" target="_blank">this article</a>.</p><p id="1532" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I would like to briefly show you how it works so that you get some intuition. I calculated a distribution of OpenAI embedding values and generated sets of 300 vectors with different dimensionalities. Then, I calculated the distances between all the vectors and draw a histogram. You can easily see that the increase in vector dimensionality makes the distribution narrower.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rj"><img src="../Images/fbfdf3c34e03b2ae519e305d5703bfef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sw4cdnFVB9FTDdJxMp-cxQ.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Graph by author</figcaption></figure><p id="4107" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve learned how to measure the similarities between the embeddings. With that we’ve finished with a theoretical part and moving to more practical part (visualisations and practical applications). Let’s start with visualisations since it’s always better to see your data first.</p><h1 id="79a2" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Visualising embeddings</h1><p id="c1d3" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The best way to understand the data is to visualise it. Unfortunately, embeddings have 1536 dimensions, so it’s pretty challenging to look at the data. However, there’s a way: we could use dimensionality reduction techniques to project vectors in two-dimensional space.</p><h2 id="f86a" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">PCA</h2><p id="3dad" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The most basic dimensionality reduction technique is <a class="af of" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">PCA</a> (Principal Component Analysis). Let’s try to use it.</p><p id="0da4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">First, we need to convert our embeddings into a 2D numpy array to pass it to sklearn.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="962d" class="ql op fq qi b bg qm qn l qo qp">import numpy as np<br/>embeddings_array = np.array(df.embedding.values.tolist())<br/>print(embeddings_array.shape)<br/># (1400, 1536)</span></pre><p id="24bf" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Then, we need to initialise a PCA model with <code class="cx qw qx qy qi b">n_components = 2</code> (because we want to create a 2D visualisation), train the model on the whole data and predict new values.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="b6c2" class="ql op fq qi b bg qm qn l qo qp">from sklearn.decomposition import PCA<br/><br/>pca_model = PCA(n_components = 2)<br/>pca_model.fit(embeddings_array)<br/><br/>pca_embeddings_values = pca_model.transform(embeddings_array)<br/>print(pca_embeddings_values.shape)<br/># (1400, 2)<br/><br/></span></pre><p id="159f" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">As a result, we got a matrix with just two features for each question, so we could easily visualise it on a scatter plot.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="eb1e" class="ql op fq qi b bg qm qn l qo qp">fig = px.scatter(<br/>    x = pca_embeddings_values[:,0], <br/>    y = pca_embeddings_values[:,1],<br/>    color = df.topic.values,<br/>    hover_name = df.full_text.values,<br/>    title = 'PCA embeddings', width = 800, height = 600,<br/>    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r<br/>)<br/><br/>fig.update_layout(<br/>    xaxis_title = 'first component', <br/>    yaxis_title = 'second component')<br/>fig.show()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rk"><img src="../Images/a0683ee9c8cfe52995691ef7887777cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U46uJK8QTmK7O5cMLOnIKQ.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Image by author</figcaption></figure><p id="cedc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can see that questions from each topic are pretty close to each other, which is good. However, all the clusters are mixed, so there’s room for improvement.</p><h2 id="2cb2" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">t-SNE</h2><p id="c1f9" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">PCA is a linear algorithm, while most of the relations are non-linear in real life. So, we may not be able to separate the clusters because of non-linearity. Let’s try to use a non-linear algorithm <a class="af of" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank">t-SNE</a> and see whether it will be able to show better results.</p><p id="408c" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The code is almost identical. I just used the t-SNE model instead of PCA.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="5966" class="ql op fq qi b bg qm qn l qo qp">from sklearn.manifold import TSNE<br/>tsne_model = TSNE(n_components=2, random_state=42)<br/>tsne_embeddings_values = tsne_model.fit_transform(embeddings_array)<br/><br/>fig = px.scatter(<br/>    x = tsne_embeddings_values[:,0], <br/>    y = tsne_embeddings_values[:,1],<br/>    color = df.topic.values,<br/>    hover_name = df.full_text.values,<br/>    title = 't-SNE embeddings', width = 800, height = 600,<br/>    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r<br/>)<br/><br/>fig.update_layout(<br/>    xaxis_title = 'first component', <br/>    yaxis_title = 'second component')<br/>fig.show()</span></pre><p id="73d1" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">The t-SNE result looks way better. Most of the clusters are separated except <em class="qg">“genai”</em>, <em class="qg">“datascience”</em> and <em class="qg">“ai”.</em> However, it’s pretty expected — I doubt I could separate these topics myself.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rl"><img src="../Images/c4f6590a648a74f2c411e17a989b4959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMqpwTiXbUiqvSE408yuvg.png"/></div></div></figure><p id="d9fc" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Looking at this visualisation, we see that embeddings are pretty good at encoding semantic meaning.</p><p id="9b0b" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Also, you can make a projection to three-dimensional space and visualise it. I’m not sure whether it would be practical, but it can be insightful and engaging to play with the data in 3D.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="bc5b" class="ql op fq qi b bg qm qn l qo qp">tsne_model_3d = TSNE(n_components=3, random_state=42)<br/>tsne_3d_embeddings_values = tsne_model_3d.fit_transform(embeddings_array)<br/><br/>fig = px.scatter_3d(<br/>    x = tsne_3d_embeddings_values[:,0], <br/>    y = tsne_3d_embeddings_values[:,1],<br/>    z = tsne_3d_embeddings_values[:,2],<br/>    color = df.topic.values,<br/>    hover_name = df.full_text.values,<br/>    title = 't-SNE embeddings', width = 800, height = 600,<br/>    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r,<br/>    opacity = 0.7<br/>)<br/>fig.update_layout(xaxis_title = 'first component', yaxis_title = 'second component')<br/>fig.show()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rm"><img src="../Images/aa256e26b30e0c95d5caf111543890ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qRqBEaETQqudsQlp4dGuQ.png"/></div></div></figure><h2 id="b081" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Barcodes</h2><p id="1805" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">The way to understand the embeddings is to visualise a couple of them as bar codes and see the correlations. I picked three examples of embeddings: two are closest to each other, and the other is the farthest example in our dataset.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="3a0f" class="ql op fq qi b bg qm qn l qo qp">embedding1 = df.loc[1].embedding<br/>embedding2 = df.loc[616].embedding<br/>embedding3 = df.loc[749].embedding</span></pre><pre class="rn qh qi qj bp qk bb bk"><span id="511c" class="ql op fq qi b bg qm qn l qo qp">import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>embed_len_thr = 1536<br/><br/>sns.heatmap(np.array(embedding1[:embed_len_thr]).reshape(-1, embed_len_thr),<br/>    cmap = "Greys", center = 0, square = False, <br/>    xticklabels = False, cbar = False)<br/>plt.gcf().set_size_inches(15,1)<br/>plt.yticks([0.5], labels = ['AI'])<br/>plt.show()<br/><br/>sns.heatmap(np.array(embedding3[:embed_len_thr]).reshape(-1, embed_len_thr),<br/>    cmap = "Greys", center = 0, square = False, <br/>    xticklabels = False, cbar = False)<br/>plt.gcf().set_size_inches(15,1)<br/>plt.yticks([0.5], labels = ['AI'])<br/>plt.show()<br/><br/>sns.heatmap(np.array(embedding2[:embed_len_thr]).reshape(-1, embed_len_thr),<br/>    cmap = "Greys", center = 0, square = False, <br/>    xticklabels = False, cbar = False)<br/>plt.gcf().set_size_inches(15,1)<br/>plt.yticks([0.5], labels = ['Bioinformatics'])<br/>plt.show()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq ro"><img src="../Images/89478c10950950c9aee5c8cfe304754c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yP_aC1hGY90SMXDdby0uIQ.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Graph by author</figcaption></figure><p id="b5d7" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">It’s not easy to see whether vectors are close to each other in our case because of high dimensionality. However, I still like this visualisation. It might be helpful in some cases, so I am sharing this idea with you.</p><p id="9b64" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We’ve learned how to visualise embeddings and have no doubts left about their ability to grasp the meaning of the text. Now, it’s time to move on to the most interesting and fascinating part and discuss how you can leverage embeddings in practice.</p><h1 id="1401" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Practical applications</h1><p id="b7f3" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Of course, embeddings’ primary goal is not to encode texts as vectors of numbers or visualise them just for the sake of it. We can benefit a lot from our ability to capture the texts’ meanings. Let’s go through a bunch of more practical examples.</p><h2 id="538b" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Clustering</h2><p id="5948" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">Let’s start with clustering. Clustering is an unsupervised learning technique that allows you to split your data into groups without any initial labels. Clustering can help you understand the internal structural patterns in your data.</p><p id="50ae" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We will use one of the most basic clustering algorithms — <a class="af of" href="https://scikit-learn.org/stable/modules/clustering.html#k-means" rel="noopener ugc nofollow" target="_blank">K-means</a>. For the K-means algorithm, we need to specify the number of clusters. We can define the optimal number of clusters using <a class="af of" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank">silhouette scores</a>.</p><p id="17cf" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s try k (number of clusters) between 2 and 50. For each k, we will train a model and calculate silhouette scores. The higher silhouette score — the better clustering we got.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="d551" class="ql op fq qi b bg qm qn l qo qp">from sklearn.cluster import KMeans<br/>from sklearn.metrics import silhouette_score<br/>import tqdm<br/><br/>silhouette_scores = []<br/>for k in tqdm.tqdm(range(2, 51)):<br/>    kmeans = KMeans(n_clusters=k, <br/>                    random_state=42, <br/>                    n_init = 'auto').fit(embeddings_array)<br/>    kmeans_labels = kmeans.labels_<br/>    silhouette_scores.append(<br/>        {<br/>            'k': k,<br/>            'silhouette_score': silhouette_score(embeddings_array, <br/>                kmeans_labels, metric = 'cosine')<br/>        }<br/>    )<br/><br/>fig = px.line(pd.DataFrame(silhouette_scores).set_index('k'),<br/>       title = '&lt;b&gt;Silhouette scores for K-means clustering&lt;/b&gt;',<br/>       labels = {'value': 'silhoutte score'}, <br/>       color_discrete_sequence = plotly.colors.qualitative.Alphabet)<br/>fig.update_layout(showlegend = False)</span></pre><p id="0526" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In our case, the silhouette score reaches a maximum when <code class="cx qw qx qy qi b">k = 11</code>. So, let’s use this number of clusters for our final model.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rp"><img src="../Images/4b555cc018bfc29bf8ecea55f54da8f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35MCNGaR6P0VJqGlhuLI4A.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Graph by author</figcaption></figure><p id="9740" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Let’s visualise the clusters using t-SNE for dimensionality reduction as we already did before.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="73fc" class="ql op fq qi b bg qm qn l qo qp">tsne_model = TSNE(n_components=2, random_state=42)<br/>tsne_embeddings_values = tsne_model.fit_transform(embeddings_array)<br/><br/>fig = px.scatter(<br/>    x = tsne_embeddings_values[:,0], <br/>    y = tsne_embeddings_values[:,1],<br/>    color = list(map(lambda x: 'cluster %s' % x, kmeans_labels)),<br/>    hover_name = df.full_text.values,<br/>    title = 't-SNE embeddings for clustering', width = 800, height = 600,<br/>    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r<br/>)<br/>fig.update_layout(<br/>    xaxis_title = 'first component', <br/>    yaxis_title = 'second component')<br/>fig.show()</span></pre><p id="0261" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Visually, we can see that the algorithm was able to define clusters quite well — they are separated pretty well.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rq"><img src="../Images/994324e79d3962523b499f92912d38c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cucEqDL-UYF4leOz8GOVig.png"/></div></div></figure><p id="cc08" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We have factual topic labels, so we can even assess how good clusterisation is. Let’s look at the topics’ mixture for each cluster.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="c0de" class="ql op fq qi b bg qm qn l qo qp">df['cluster'] = list(map(lambda x: 'cluster %s' % x, kmeans_labels))<br/>cluster_stats_df = df.reset_index().pivot_table(<br/>    index = 'cluster', values = 'id', <br/>    aggfunc = 'count', columns = 'topic').fillna(0).applymap(int)<br/><br/>cluster_stats_df = cluster_stats_df.apply(<br/>  lambda x: 100*x/cluster_stats_df.sum(axis = 1))<br/><br/>fig = px.imshow(<br/>    cluster_stats_df.values, <br/>    x = cluster_stats_df.columns,<br/>    y = cluster_stats_df.index,<br/>    text_auto = '.2f', aspect = "auto",<br/>    labels=dict(x="cluster", y="fact topic", color="share, %"), <br/>    color_continuous_scale='pubugn',<br/>    title = '&lt;b&gt;Share of topics in each cluster&lt;/b&gt;', height = 550)<br/><br/>fig.show()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rr"><img src="../Images/58c3df19b731f65894997ea8dddad3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CZeSezPbxeoLWPZpmT9h7w.png"/></div></div></figure><p id="bc21" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">In most cases, clusterisation worked perfectly. For example, cluster 5 contains almost only questions about bicycles, while cluster 6 is about coffee. However, it wasn’t able to distinguish close topics:</p><ul class=""><li id="c8d4" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk"><em class="qg">“ai”</em>, <em class="qg">“genai”</em> and <em class="qg">“datascience”</em> are all in one cluster,</li><li id="62d4" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">the same store with <em class="qg">“economics”</em> and <em class="qg">“politics”</em>.</li></ul><p id="9070" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We used only embeddings as the features in this example, but if you have any additional information (for example, age, gender or country of the user who asked the question), you can include it in the model, too.</p><h2 id="62bb" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Classification</h2><p id="cb5b" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We can use embeddings for classification or regression tasks. For example, you can do it to predict customer reviews’ sentiment (classification) or NPS score (regression).</p><p id="07b4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Since classification and regression are supervised learning, you will need to have labels. Luckily, we know the topics for our questions and can fit a model to predict them.</p><p id="47c4" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">I will use a Random Forest Classifier. If you need a quick refresher about Random Forests, you can find it <a class="af of" href="https://medium.com/towards-data-science/interpreting-random-forests-638bca8b49ea" rel="noopener">here</a>. To assess the classification model’s performance correctly, we will split our dataset into train and test sets (80% vs 20%). Then, we can train our model on a train set and measure the quality on a test set (questions that the model hasn’t seen before).</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="d609" class="ql op fq qi b bg qm qn l qo qp">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>class_model = RandomForestClassifier(max_depth = 10)<br/><br/># defining features and target<br/>X = embeddings_array<br/>y = df.topic<br/><br/># splitting data into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, random_state = 42, test_size=0.2, stratify=y<br/>)<br/><br/># fit &amp; predict <br/>class_model.fit(X_train, y_train)<br/>y_pred = class_model.predict(X_test)</span></pre><p id="a4d3" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To estimate the model’s performance, let’s calculate a confusion matrix. In an ideal situation, all non-diagonal elements should be 0.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="2f6d" class="ql op fq qi b bg qm qn l qo qp">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test, y_pred)<br/><br/>fig = px.imshow(<br/>  cm, x = class_model.classes_,<br/>  y = class_model.classes_, text_auto='d', <br/>  aspect="auto", <br/>  labels=dict(<br/>      x="predicted label", y="true label", <br/>      color="cases"), <br/>  color_continuous_scale='pubugn',<br/>  title = '&lt;b&gt;Confusion matrix&lt;/b&gt;', height = 550)<br/><br/>fig.show()</span></pre><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rs"><img src="../Images/a401de02b5f824451d9efc6db62491d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvZCAE7BQlK0LhZTnMhjqg.png"/></div></div></figure><p id="4961" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We can see similar results to clusterisation: some topics are easy to classify, and accuracy is 100%, for example, <em class="qg">“bicycles” </em>or <em class="qg">“travel”</em>, while some others are difficult to distinguish (especially <em class="qg">“ai”</em>).</p><p id="3152" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">However, we achieved 91.8% overall accuracy, which is quite good.</p><h2 id="d03b" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">Finding anomalies</h2><p id="f062" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">We can also use embedding to find anomalies in our data. For example, at the t-SNE graph, we saw that some questions are pretty far from their clusters, for instance, for the <em class="qg">“travel”</em> topic. Let’s look at this theme and try to find anomalies. We will use <a class="af of" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank">the Isolation Forest algorithm</a> for it.</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="3db6" class="ql op fq qi b bg qm qn l qo qp">from sklearn.ensemble import IsolationForest<br/><br/>topic_df = df[df.topic == 'travel']<br/>topic_embeddings_array = np.array(topic_df.embedding.values.tolist())<br/><br/>clf = IsolationForest(contamination = 0.03, random_state = 42) <br/>topic_df['is_anomaly'] = clf.fit_predict(topic_embeddings_array)<br/><br/>topic_df[topic_df.is_anomaly == -1][['full_text']]</span></pre><p id="11ce" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">So, here we are. We’ve found the most uncommon comment for the travel topic (<a class="af of" href="https://travel.stackexchange.com/questions/150735/is-it-safe-to-drink-the-water-from-the-fountains-found-all-over-the-older-parts" rel="noopener ugc nofollow" target="_blank">source</a>).</p><pre class="ms mt mu mv mw qh qi qj bp qk bb bk"><span id="565b" class="ql op fq qi b bg qm qn l qo qp">Is it safe to drink the water from the fountains found all over <br/>the older parts of Rome?<br/><br/>When I visited Rome and walked around the older sections, I saw many <br/>different types of fountains that were constantly running with water. <br/>Some went into the ground, some collected in basins, etc.<br/><br/>Is the water coming out of these fountains potable? Safe for visitors <br/>to drink from? Any etiquette regarding their use that a visitor <br/>should know about?</span></pre><p id="e014" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Since it talks about water, the embedding of this comment is close to the coffee topic where people also discuss water to pour coffee. So, the embedding representation is quite reasonable.</p><p id="0dff" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We could find it on our t-SNE visualisation and see that it’s actually close to the <em class="qg">coffee</em> cluster.</p><figure class="ms mt mu mv mw mj mp mq paragraph-image"><div role="button" tabindex="0" class="mz na ed nb bh nc"><div class="mp mq rt"><img src="../Images/26e6b84079ede41be03aff139e1c984e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrVsnmcoXbWgdQsOV3eTuw.png"/></div></div><figcaption class="ne nf ng mp mq nh ni bf b bg z dx">Graph by author</figcaption></figure><h2 id="6799" class="pp op fq bf oq pq pr ps ot pt pu pv ow ns pw px py nw pz qa qb oa qc qd qe qf bk">RAG — Retrieval Augmented Generation</h2><p id="79a3" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">With the recently increased popularity of LLMs, embeddings have been broadly used in RAG use cases.</p><p id="9f10" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">We need Retrieval Augmented Generation when we have a lot of documents (for example, all the questions from Stack Exchange), and we can’t pass them all to an LLM because</p><ul class=""><li id="68cf" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">LLMs have limits on the context size (right now, it’s 128K for GPT-4 Turbo).</li><li id="fe15" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">We pay for tokens, so it’s more expensive to pass all the information all the time.</li><li id="97b3" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">LLMs show worse performance with a bigger context. You can check <a class="af of" href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" rel="noopener ugc nofollow" target="_blank">Needle In A Haystack — Pressure Testing LLMs</a> to learn more details.</li></ul><p id="c6bb" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To be able to work with an extensive knowledge base, we can leverage the RAG approach:</p><ul class=""><li id="c3e6" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">Compute embeddings for all the documents and store them in vector storage.</li><li id="0f18" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">When we get a user request, we can calculate its embedding and retrieve relevant documents from the storage for this request.</li><li id="9d66" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Pass only relevant documents to LLM to get a final answer.</li></ul><p id="935a" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">To learn more about RAG, don’t hesitate to read my article with much more details <a class="af of" rel="noopener" target="_blank" href="/rag-how-to-talk-to-your-data-eaf5469b83b0">here.</a></p><h1 id="5c2c" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Summary</h1><p id="6896" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In this article, we’ve discussed text embeddings in much detail. Hopefully, now you have a complete and deep understanding of this topic. Here’s a quick recap of our journey:</p><ul class=""><li id="587b" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">Firstly, we went through the evolution of approaches to work with texts.</li><li id="c8df" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Then, we discussed how to understand whether texts have similar meanings to each other.</li><li id="5ffa" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">After that, we saw different approaches to text embedding visualisation.</li><li id="5178" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk">Finally, we tried to use embeddings as features in different practical tasks such as clustering, classification, anomaly detection and RAG.</li></ul><blockquote class="rg rh ri"><p id="b5a0" class="nj nk qg nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">Thank you a lot for reading this article. If you have any follow-up questions or comments, please leave them in the comments section.</p></blockquote><h1 id="35db" class="oo op fq bf oq or os gq ot ou ov gt ow ox oy oz pa pb pc pd pe pf pg ph pi pj bk">Reference</h1><p id="52f2" class="pw-post-body-paragraph nj nk fq nl b go pk nn no gr pl nq nr ns pm nu nv nw pn ny nz oa po oc od oe fj bk">In this article, I used a dataset from <a class="af of" href="https://archive.org/details/stackexchange" rel="noopener ugc nofollow" target="_blank">Stack Exchange Data Dump</a>, which is available under <a class="af of" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">the Creative Commons license</a>.</p><p id="187c" class="pw-post-body-paragraph nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe fj bk">This article was inspired by the following courses:</p><ul class=""><li id="1267" class="nj nk fq nl b go nm nn no gr np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe og oh oi bk">“<a class="af of" href="https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/" rel="noopener ugc nofollow" target="_blank">Understanding and Applying Text Embeddings”</a> by DeepLearning.AI in collaboration with Google Cloud,</li><li id="0e15" class="nj nk fq nl b go oj nn no gr ok nq nr ns ol nu nv nw om ny nz oa on oc od oe og oh oi bk"><a class="af of" href="https://learn.deeplearning.ai/vector-databases-embeddings-applications/lesson/1/introduction" rel="noopener ugc nofollow" target="_blank">“Vector Databases: From Embeddings to Applications”</a> by DeepLearning.AI in collaboration with Weaviate.</li></ul></div></div></div></div>    
</body>
</html>