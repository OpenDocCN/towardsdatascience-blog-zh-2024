<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Data Science Better Practices, Part 2 — Work Together</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Data Science Better Practices, Part 2 — Work Together</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-better-practices-part-2-work-together-9ec019f8b79e?source=collection_archive---------8-----------------------#2024-01-05">https://towardsdatascience.com/data-science-better-practices-part-2-work-together-9ec019f8b79e?source=collection_archive---------8-----------------------#2024-01-05</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="c56d" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">You can’t just throw more data scientists at this model and expect the accuracy to magically increase.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@scf1984?source=post_page---byline--9ec019f8b79e--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Shachaf Poran" class="l ep by dd de cx" src="../Images/ac1ac57b8777c3441ad69358af1d649b.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*3PGTZONfzzHKuPjT0JaJ9g.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9ec019f8b79e--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@scf1984?source=post_page---byline--9ec019f8b79e--------------------------------" rel="noopener follow">Shachaf Poran</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9ec019f8b79e--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jan 5, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/779611b5d766e019ee32e49510a48cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*alTdK5apwYp0oX2Ngcmqmw.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by Joseph Ruwa: <a class="af nb" href="https://www.pexels.com/photo/set-of-chess-pieces-in-daylight-4038397/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/photo/set-of-chess-pieces-in-daylight-4038397/</a></figcaption></figure><p id="1e09" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><a class="af nb" rel="noopener" target="_blank" href="/data-science-better-practices-part-1-test-your-queries-629ad5209f28">(Part 1 is here)</a></p><p id="8260" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Not all data science projects were created equal.</p><p id="2792" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The vast majority of data science projects I’ve seen and built were born as a throw-away proof-of-concept. Temporary one-off hacks to make something tangentially important work.</p><p id="9074" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Some of these projects might end up becoming something else, perhaps a bit bigger or more central in helping the organization’s goal.</p><p id="028e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Only a select few get to grow and mature over long periods of time.</p><p id="bc85" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These special projects are usually those that solve a problem of special interest to the organization. For example, a CTR predictor for an online advertising network, or an image segmentation model for a visual effects generator, or a profanity detector for a content filtering service<em class="ny">.</em></p><p id="4768" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">These are also the ones that will see considerable company resources used to optimize them, and rightly so. When even a minor improvement of some accuracy metric can be directly responsible for higher revenue or be the make-or-breaker of product launches and funding rounds — the organization should spare no expense.</p><p id="6b58" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The resource we’re talking about in this post is <strong class="ne fr">Data Scientists</strong>.</p><p id="e83d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you’ve never managed a project, a team, a company or such — it might sound strange to treat people as a “resource”. However keep in mind that these are <em class="ny">experts with limited time to offer, and we use this time to accomplish tasks that benefit the organization</em>.</p><p id="823d" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now take note: <strong class="ne fr"><em class="ny">resources have to be managed, and their use should be optimized</em></strong>.</p><p id="d420" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once a model becomes so big and central that more than a couple of Data Scientists work on improving it, it’s crucial to make sure that they can work on it without stepping on each other’s toes, blocking each other, or otherwise impeding each other’s work. Rather, team members should be able to help each other easily, and build on each other’s successes.</p><p id="90ac" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The common practice I witnessed in various places is that each member in the team tries their own “thing”. Depending on the peculiarities of the project, that may mean different models, optimization algorithms, deep learning architectures, engineered features, and so on.</p><p id="0445" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This mode of work may seem to be perpendicular between members as each of them can work separately and no dependencies are created that may impede or block one’s progress.</p><p id="cd11" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">However, that’s not entirely the case, as I’ve <a class="af nb" href="https://digma.ai/blog/coding-horrors-refactoring-and-feature-creep/" rel="noopener ugc nofollow" target="_blank">ranted</a> before.</p><p id="3f70" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For example, if a team member strikes gold with a particularly lucrative feature, other members might want to try and use the same feature in their models.</p><p id="85e8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">At some point in time a specific model might show a leap in performance, and quite quickly we’ll have branched versions of that best model, each slightly different from the next. This is because optimization processes tend to search for better optimums in the vicinity of the current optimum — not only with gradient descent but also with human invention.</p><p id="af60" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This scenario will probably lead to much higher coupling and more dependencies than previously anticipated.</p><p id="5ba6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Even if we do make sure that not all Data Scientists converge this way, we should still try to standardize their work, perhaps enforcing a contract with downstream consumers to ease deployment as well as to save Machine Learning Engineers time.</p><h1 id="d2b7" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">The premise</h1><p id="ba4c" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">We would like to have the Data Scientists work on the same problem in a way that allows independence on the one hand, but allows reuse of other’s work at the same time.</p><p id="e368" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For the sake of examples we’ll assume we are members of a team working on the <a class="af nb" href="https://archive.ics.uci.edu/dataset/53/iris" rel="noopener ugc nofollow" target="_blank">Iris flower data set</a>. This means that the training data will be small enough to hold in a pandas dataframe in memory, though the tools we come up with might be applied to any type and size of data.</p><p id="8875" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We would like to allow creative freedom, which means that each member is at full liberty to choose their modeling framework — be it <code class="cx pa pb pc pd b">scikit-learn</code>, <code class="cx pa pb pc pd b">Keras</code>, Python-only logic, etc.</p><p id="5888" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Our main tool will be the abstraction of the process applied with OOP principles, and the normalization of work of individuals into a unified language.</p><h1 id="3d38" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Disclaimer</h1><p id="a2e7" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">In this post, I am going to exemplify how one could abstract the Data Science process to facilitate teamwork. The main point is <em class="ny">not</em> the specific abstraction we’ll come up with. The main point is that <strong class="ne fr"><em class="ny">data science managers and leaders should strive to facilitate data scientists’ work</em></strong>, be it by abstraction, protocols, version control, process streamlining, or any other method.</p><p id="4eeb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">This blog post is in no way promoting </em><a class="af nb" href="https://en.wikipedia.org/wiki/Reinventing_the_wheel" rel="noopener ugc nofollow" target="_blank"><em class="ny">reinventing the wheel</em></a><em class="ny">. The choice whether to use an off-the-shelf product, open source tools, or developing an in-house solution should be made together with the data science and machine learning engineering teams that are relevant to the project.</em></p><p id="8c24" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now that this is out of the way, let’s cut to the chase.</p><h1 id="8404" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Start from the end</h1><p id="76e6" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">When we’re done, we’d like to have a unified framework to take our model through the entire pipeline from training to prediction. So, we start with defining the common pipeline:</p><ol class=""><li id="b47e" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pe pf pg bk">First we get <strong class="ne fr">training data</strong> as input.</li><li id="f927" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">We might want to extract additional <strong class="ne fr">features</strong> to enhance the dataset.</li><li id="2842" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">We create a model and <strong class="ne fr">train</strong> it repeatedly until we’re satisfied with its loss or metrics.</li><li id="527e" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">We then <strong class="ne fr">save </strong>the model to disk or any other persisting mechanism.</li><li id="83a4" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">We need to later <strong class="ne fr">load </strong>the model back to memory.</li><li id="24bb" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx pe pf pg bk">Then we can apply <strong class="ne fr">prediction</strong> on new unseen data.</li></ol><p id="fee5" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s declare a basic structure (aka interface) for a model according to the above pipeline:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="c5c6" class="pp oa fq pd b bg pq pr l ps pt">class Model:<br/>    def add_features(self, x):<br/>        ...<br/>    def train(self, x, y, train_parameters=None):<br/>        ...<br/>    def save(self, model_dir_path):<br/>        ...<br/>    @classmethod<br/>    def load(cls, model_dir_path):<br/>        ...<br/>    def predict(self, x):<br/>        ...</span></pre><p id="ee97" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Note that this is not much more than the interfaces we’re used to from existing frameworks — however, each framework has its own little quirks, for example in naming: “fit” vs. “train” or the way they persist the models on disk. Encapsulating the pipeline within a uniform structure saves us from having to add implementation details elsewhere, for example when using the different models in a deployment environment.</p><p id="4de3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now, once we’ve defined our basic structure, let’s discuss how we’d expect to actually use it.</p><h1 id="5647" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">System design</h1><h2 id="4d49" class="pu oa fq bf ob pv pw px oe py pz qa oh nl qb qc qd np qe qf qg nt qh qi qj qk bk">Features</h2><p id="d46c" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">We’d like to have “features” as elements that can be easily passed around and added to different models. We should also acknowledge that there may be multiple features used for each model.</p><p id="9ad0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We’ll try to implement a sort of plugin infrastructure for our <code class="cx pa pb pc pd b">Feature</code> class. We’ll have a base class for all features and then we can have the <code class="cx pa pb pc pd b">Model</code> class materialize the different features sequentially in memory when it gets the input data.</p><h2 id="aeb8" class="pu oa fq bf ob pv pw px oe py pz qa oh nl qb qc qd np qe qf qg nt qh qi qj qk bk">Encapsulated models</h2><p id="30bb" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">We’d also like to have actual models that we encapsulate in our system to be transferrable between team members. However we would like to keep the option to change model parameters without writing a lot of new code.</p><p id="a9cc" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We’ll abstract them in a different class and name it <code class="cx pa pb pc pd b">ModelInterface</code> to aviod confusion with our <code class="cx pa pb pc pd b">Model</code> class. The latter will in turn defer the relevant method invocations to the former.</p><h1 id="e2e7" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Features</h1><p id="d439" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Our features can be regarded as functions with a pandas dataframe as an input.</p><p id="aeba" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If we give each feature a unique name and encapsulate it with the same interface as the others, we can allow the reuse of these features quite easily.</p><p id="0ebb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s define a base class:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="5a38" class="pp oa fq pd b bg pq pr l ps pt">class Feature(ABC):<br/>    @abstractmethod<br/>    def add_feature(self, data):<br/>        ...</span></pre><p id="2647" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And let’s create an implementation, for example sepal diagonal length:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="deda" class="pp oa fq pd b bg pq pr l ps pt">class SepalDiagonalFeature(Feature):<br/>    def add_feature(self, data):<br/>        data['SepalDiagonal'] = (data.SepalLength ** 2 + \<br/>                                 data.SepalWidth ** 2) ** 0.5</span></pre><p id="116e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will use an instance of this class, and so I create a separate file where I store all features:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="6037" class="pp oa fq pd b bg pq pr l ps pt">sepal_diagonal = SepalDiagonalFeature()</span></pre><p id="9fa7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This specific implementation already presents a few decisions we made, whether conscious or not:</p><ul class=""><li id="fa9b" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ql pf pg bk">The name of the output column is a literal within the function code, and is not saved elsewhere. This means that we can’t easily construct a list of known columns.</li><li id="ce94" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx ql pf pg bk">We chose to add the new column to the input dataframe within the add_feature function rather than return the column itself and then add it in an outer scope.</li><li id="b43c" class="nc nd fq ne b go ph ng nh gr pi nj nk nl pj nn no np pk nr ns nt pl nv nw nx ql pf pg bk">We do not know, other than by reading the function code, which columns this feature depends on. If we did, we could have constructed a DAG to decide on feature creation order.</li></ul><p id="3e88" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">At this point these decisions are easily reversible, however later when we have dozens of features built this way we may have to refactor all of them to apply a change to the base class. This is to say that <strong class="ne fr">we should decide in advance what we expect from our system </strong>as well as be aware of the implications of each choice.</p><p id="9162" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s expand on our <code class="cx pa pb pc pd b">Model</code> base class by implementing the <code class="cx pa pb pc pd b">add_features </code>function:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="5a45" class="pp oa fq pd b bg pq pr l ps pt">    def __init__(self, features: Sequence[Feature] = tuple()):<br/>        self.features = features<br/><br/>    def add_features(self, x):<br/>        for feature in self.features:<br/>            feature.add_feature(x)</span></pre><p id="de0b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now anyone can take the <code class="cx pa pb pc pd b">sepal_diagonal</code> feature and use it when creating a model instance.</p><p id="651a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If we didn’t facilitate reusing these features with our abstraction, Alice might choose to copy Bob’s logic and change it around a bit to fit with her preprocessing, applying different naming on the way, and generally <strong class="ne fr">inflating technical debt</strong>.</p><p id="bbfa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A question that may arise is “What about common operations, like addition. Do we need to implement an addition each time we want to use it?”.</p><p id="8ee3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The answer is no. For this we may use the instance fields through the self parameter:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="045b" class="pp oa fq pd b bg pq pr l ps pt">@dataclass<br/>class AdditionFeature(Feature):<br/>    col_a: str<br/>    col_b: str<br/>    output_col: str  <br/>    <br/>    def add_feature(self, data):<br/>        data[self.output_col] = data[self.col_a] + data[self.col_b]</span></pre><p id="942b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So if, for example, we want to add petal length and petal width, we’ll create an instance with <code class="cx pa pb pc pd b">petal_sum = AdditionFeature('petalLength', 'petalWidth', 'petalSum')</code>.</p><p id="97c3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">For each operator/function you might have to implement a class, which may seem intimidating at first, but you will quickly find that the list is quite short.</p><h1 id="1c4c" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Model interface</h1><p id="d4b3" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Here is the abstraction I use for model interfaces:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="fe4d" class="pp oa fq pd b bg pq pr l ps pt">class ModelInterface(ABC):<br/>    @abstractmethod<br/>    def initialize(self, model_parameters: dict):<br/>        ...<br/><br/>    @abstractmethod<br/>    def train(self, x, y, train_parameters: dict):<br/>        ...<br/><br/>    @abstractmethod<br/>    def predict(self, x):<br/>        ...<br/><br/>    @abstractmethod<br/>    def save(self, model_interface_dir_path: Path):<br/>        ...<br/><br/>    @classmethod<br/>    def load(cls, model_interface_dir_path: Path):<br/>        ...</span></pre><p id="3bc3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And here’s an example implementation by using a <code class="cx pa pb pc pd b">scikit-learn</code> model is given below:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="2051" class="pp oa fq pd b bg pq pr l ps pt">class SKLRFModelInterface(ModelInterface):<br/>    def __init__(self):<br/>        self.model = None<br/>        self.binarizer = None<br/><br/>    def initialize(self, model_parameters: dict):<br/>        forest = RandomForestClassifier(**model_parameters)<br/>        self.model = MultiOutputClassifier(forest, n_jobs=2)<br/><br/>    def train(self, x, y, w=None):<br/>        self.binarizer = LabelBinarizer()<br/>        y = self.binarizer.fit_transform(y)<br/>        return self.model.fit(x, y)<br/><br/>    def predict(self, x):<br/>        return self.binarizer.inverse_transform(self.model.predict(x))<br/><br/>    def save(self, model_interface_dir_path: Path):<br/>        ...<br/><br/>    def load(self, model_interface_dir_path: Path):<br/>        ...</span></pre><p id="ec52" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">As you can see, the code is mainly about delegating the different actions to the ready-made model. In <code class="cx pa pb pc pd b">train</code> and <code class="cx pa pb pc pd b">predict</code> we also translate the target to and fro between an enumerated value and a one-hot encoded vector, practically between our business need and <code class="cx pa pb pc pd b">scikit-learn</code>’s interface.</p><p id="5f6c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can now update our <code class="cx pa pb pc pd b">Model</code> class to accommodate a <code class="cx pa pb pc pd b">ModelInterface</code> instance. Here it is in full:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="7c65" class="pp oa fq pd b bg pq pr l ps pt">class Model:<br/>    def __init__(self, features: Sequence[Feature] = tuple(), model_interface: ModelInterface = None,<br/>                 model_parameters: dict = None):<br/>        model_parameters = model_parameters or {}<br/><br/>        self.features = features<br/>        self.model_interface = model_interface<br/>        self.model_parameters = model_parameters<br/><br/>        model_interface.initialize(model_parameters)<br/><br/>    def add_features(self, x):<br/>        for feature in self.features:<br/>            feature.add_feature(x)<br/><br/>    def train(self, x, y, train_parameters=None):<br/>        train_parameters = train_parameters or {}<br/>        self.add_features(x)<br/>        self.model_interface.train(x, y, train_parameters)<br/><br/>    def predict(self, x):<br/>        self.add_features(x)<br/>        return self.model_interface.predict(x)<br/><br/>    def save(self, model_dir_path: Path):<br/>        ...<br/><br/>    @classmethod<br/>    def load(cls, model_dir_path: Path):<br/>        ...</span></pre><p id="8da1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once again, I create a file to curate my models and have this line in it:</p><pre class="ml mm mn mo mp pm pd pn bp po bb bk"><span id="a998" class="pp oa fq pd b bg pq pr l ps pt">best_model_so_far = Model([sepal_diagonal], SKLRFModelInterface(), {})</span></pre><p id="04b8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This <code class="cx pa pb pc pd b">best_model_so_far</code> is a reusable instance, however note that it is not trained. To have a reusable trained model instance we’ll need to persist the model.</p><h1 id="1fe9" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Save and load</h1><p id="86a1" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">I choose to omit the specifics of save and load from this post as it is getting wordy, however feel free to check out my <a class="af nb" href="https://github.com/scf1984/clean-data-science/tree/main/team_cooperation" rel="noopener ugc nofollow" target="_blank">clean data science github repository</a> for a fully operational Hey example.</p><h1 id="f8d3" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Summary</h1><p id="b53f" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">The framework proposed in this post is definitely not a one-size-fits-all solution to the problem of standardizing a Data Science team’s work on a single model, nor should it be treated as one. Each project has its own nuances and niches that should be addressed.</p><p id="6af4" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Rather, the framework proposed here should merely be used as a basis for further discussion, putting the subject of <strong class="ne fr"><em class="ny">facilitating Data Scientist work</em></strong> in the spotlight.</p><p id="727f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Streamlining the work should be a goal set by Data Science team leaders and managers in general, and abstractions are just one item in the toolbox.</p><h1 id="8b1b" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">FAQ</h1><p id="ae87" class="pw-post-body-paragraph nc nd fq ne b go ov ng nh gr ow nj nk nl ox nn no np oy nr ns nt oz nv nw nx fj bk">Q: Shouldn’t you use a Protocol instead of ABC if all you need is a specific functionality from your subclasses?<br/>A: I could, but this is not an advanced Python class. There’s a Hebrew saying “The pedant can’t teach”. So, there you go.</p><p id="749b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Q: What about dropping features? That’s important too!<br/>A: Definitely. And you may choose where to drop them! You may use a parameterized <code class="cx pa pb pc pd b">Feature</code> implementation to drop columns or have it done in the <code class="cx pa pb pc pd b">ModelInterface</code> class, for example.</p><p id="4f6f" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Q: What about measuring the models against each other?<br/>A: It will be awesome to have some higher-level mechanism to track model metrics. That’s out of scope for this post.</p><p id="a4c7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Q: How do I keep track of trained models?<br/>A: This could be a list of paths where you saved the trained models. Make sure to give them meaningful names.</p><p id="3bf6" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Q: Shouldn’t we also abstract the dataset creation (before we pass it to the <code class="cx pa pb pc pd b">train</code> function)<br/>A: I was going to get around to it, but then I took an arrow in the knee. But yeah, it’s a swell idea to have different samples of the full dataset, or just multiple datasets that we can pass around like we do with features and model interfaces.</p><p id="7671" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Q: Aren’t we making it hard on data scientists?<br/>A: We should weigh the pros and cons on this matter. Though it takes some time to get used to the restrictive nature of this abstraction, it may save loads of time down the line.</p></div></div></div></div>    
</body>
</html>