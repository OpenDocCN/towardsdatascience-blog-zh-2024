- en: How to Find and Solve Valuable Generative-AI Use Cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-find-and-solve-valuable-generative-ai-use-cases-eae06bfd18a9?source=collection_archive---------10-----------------------#2024-06-18](https://towardsdatascience.com/how-to-find-and-solve-valuable-generative-ai-use-cases-eae06bfd18a9?source=collection_archive---------10-----------------------#2024-06-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*80% of AI projects fail due to poor use cases or technical knowledge. Gen
    AI reduced complexity, and now we must pick the right battles.*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@teemusormunen?source=post_page---byline--eae06bfd18a9--------------------------------)[![Teemu
    Sormunen](../Images/27465c39b711cc8bf0135df6a47d1587.png)](https://medium.com/@teemusormunen?source=post_page---byline--eae06bfd18a9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--eae06bfd18a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--eae06bfd18a9--------------------------------)
    [Teemu Sormunen](https://medium.com/@teemusormunen?source=post_page---byline--eae06bfd18a9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--eae06bfd18a9--------------------------------)
    ·7 min read·Jun 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b51a02fd078e58275c691e99c41737d.png)'
  prefs: []
  type: TYPE_IMG
- en: “Paperclips & Friends” company wants to jump on the AI hype train. How far will
    they ride?
  prefs: []
  type: TYPE_NORMAL
- en: 'It has become apparent that AI projects are hard. Some estimate that [80% of
    the AI projects fail.](https://hbr.org/2023/11/keep-your-ai-projects-on-track#:~:text=Sadly%2C%20beneath%20the%20aspirational%20headlines,increase%20the%20odds%20of%20success.)
    Still, generative AI is here to stay, and companies are searching for how to apply
    it to their operations. AI projects fail, because they fail to deliver value.
    The root cause of failure is applying AI to the wrong use cases. The solution
    for finding the right use cases is with three measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Measure** the **problem magnitude**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Measure** the solution **accuracy retrospectively**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Measure** the solution **accuracy** in **real time**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These steps should be investigated sequentially. If the problem magnitude is
    not big enough to bring the needed value, **do not build.** If the solution accuracy
    on historical data is not high enough, **do not deploy**. If the real-time accuracy
    is not high enough, **adjust the solution.**
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/113584218cd4aef2899cba97ff858d4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Each Measure stage must be passed to move to the next stage.
  prefs: []
  type: TYPE_NORMAL
- en: I will be discussing generative AI instead of AI in general. Generative AI is
    a small subfield of AI. With general AI projects the goal is to find a model to
    approximate how the data is generated — you must have high proficiency in understanding
    different machine learning algorithms and data processing. With generative AI
    the model is given, LLM (e.g. chatGPT), and the goal is to use the existing model
    to solve some business problem. The latter requires less technical skills, and
    more problem solving knowledge. Generative AI use cases are much easier to implement
    and validate, as the step of creating the algorithm is left out, and the data
    (text) is (relatively) standardized.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Measure the problem magnitude
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every person can identify problems in their daily work. The challenge lies in
    determining which issues are significant enough to be solved and where AI could
    and should be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of going through all subjective problems and finding data to validate
    their existence, we can focus on processes that generate textual data. This approach
    narrows the scope to **measurable problems**,where AI and automation can add demonstrable
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Concretely, instead of asking the customer support specialist “What problems
    are there in your work?”, we should measure where the employee spends the most
    time. Let’s go through this with an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7531df5567332ad8e0582d119002d37d.png)'
  prefs: []
  type: TYPE_IMG
- en: Paperclips & Friends is a paper clip company. Look at those happy faces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Paperclips & Friends (P&F) is a company that makes paper clips. They have a
    support channel #**P&FSupport**, where customers discuss issues around paper clips**.**
    P&F responds to customer questions on time, but the channel keeps getting busier.
    The customer support specialists hear about ChatGPT and want it to help with customer
    questions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/752d8c5d3dc394a6dce0d0eb5ed90823.png)'
  prefs: []
  type: TYPE_IMG
- en: The paper clip customer support experts are tired of all the customer questions.
  prefs: []
  type: TYPE_NORMAL
- en: Before the data science team of P&F starts solving the issue, they **measure
    the number of incoming questions** to understand the magnitude of the problem.
    They notice hundreds and hundreds of inquiries, daily.
  prefs: []
  type: TYPE_NORMAL
- en: The data science team develops a [RAG](https://aws.amazon.com/what-is/retrieval-augmented-generation/#:~:text=Retrieval%2DAugmented%20Generation%20(RAG),sources%20before%20generating%20a%20response.)
    chatbot using ChatGPT and P&F internal documentation. They release the chatbot
    to be tested by the customer support specialists and receive mixed feedback. Some
    experts **love** the **solution** and mention that it solves most of the issues,
    while others **criticize it**, claiming it provides **no value**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The P&F data science team faces a challenge — **who speaks the truth?** Is
    the chatbot **any good**? Then, they remember the second Measure:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“****Measure*** *the solution* ***accuracy retrospectively****”*'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE:** it is **crucial** to verify can the root cause be solved. If Paperclips
    & Friends found out, that 90% of the support channel messages were related to
    unclear usage instructions, P&F could create a chatbot for answering those messages.
    **However,** the customer **wouldn’t have sent** the **question** in the first
    place, if P&F **included** a **simple instruction guide** with the paperclip shipment.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/6c12d0f96f17a56d89ecdc144a9c7e66.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of the P&F data science team doing their best to build a chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: Measure the solution accuracy retrospectively
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The P&F data science team faces a challenge: They must weigh each expert opinion
    equally, but can’t satisfy everyone. Instead of focusing on expert subjective
    opinions, they decide to evaluate the chatbot on historical customer questions.
    Now experts do not need to come up with questions to test the chatbot, bringing
    the evaluation closer to real-world conditions. The initial reason for involving
    experts, after all, was their better understanding of real customer questions
    compared to the P&F data science team.'
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that commonly asked questions for P&F are related to paper clip
    technical instructions. P&F customers want to know detailed technical specifications
    of the paper clips. P&F has thousands of different paper clip types, and it takes
    a long time for customer support to answer the questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding the test-driven development, the data science team creates a
    dataset from the conversation history, including the **customer question** and
    **customer support reply**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7dc2f04f3865d0cb20e6fe40ec365525.png)'
  prefs: []
  type: TYPE_IMG
- en: Dataset gathered from Paperclips & Friends discord channel.
  prefs: []
  type: TYPE_NORMAL
- en: Having a dataset of questions and answers, P&F can test and evaluate the chatbot’s
    performance retrospectively. They create a new column, “Chatbot reply”, and store
    the chatbot example replies to the questions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e345050542252723626060bd19a62d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Augmented dataset with proposed chatbot answer.
  prefs: []
  type: TYPE_NORMAL
- en: We can have the experts and GPT-4 evaluate the quality of the chatbot’s replies.
    The ultimate goal is to automate the chatbot accuracy evaluation by utilizing
    GPT-4\. This is possible *if*experts and GPT-4 evaluate the replies similarly.
  prefs: []
  type: TYPE_NORMAL
- en: Experts create a new Excel sheet with each expert's evaluation, and the data
    science team adds the GPT-4 evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/746f84561d45d768f879e2b06a525585.png)'
  prefs: []
  type: TYPE_IMG
- en: Augmented dataset with expert and GPT-4 evaluations.
  prefs: []
  type: TYPE_NORMAL
- en: There are **conflicts** on how **different experts evaluate** the **same chatbot
    replies**. GPT-4 evaluates similarly to expert majority voting, which indicates
    that we could do automatic evaluations with GPT-4\. However, each expert’s opinion
    is valuable, and it’s important to address the conflicting evaluation preferences
    among the experts.
  prefs: []
  type: TYPE_NORMAL
- en: P&F organizes a workshop with the experts to create *golden standard* responses
    to the historical question dataset
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c0f693804bf2ca60f9a34353b02621e.png)'
  prefs: []
  type: TYPE_IMG
- en: The golden standard dataset for evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: and *evaluation* *best practice guidelines*, to which all experts agree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/048f52abc1be0433d5f5ec9fb8fb6bfa.png)'
  prefs: []
  type: TYPE_IMG
- en: Evaluation “best practices guidelines” for the chatbot as defined by customer
    support specialists.
  prefs: []
  type: TYPE_NORMAL
- en: With the insights from the workshop, the data science team can create a more
    detailed evaluation prompt for the GPT-4 that covers edge cases (i.e. “chatbot
    should not ask to raise support tickets”). Now the **experts can use time to improve
    the paper clip documentation** and **define best practices,** instead of laborious
    chatbot evaluations**.**
  prefs: []
  type: TYPE_NORMAL
- en: By measuring the percentage of correct chatbot replies, P&F can decide whether
    they want to deploy the chatbot to the support channel. They approve the accuracy
    and deploy the chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: Measure the solution accuracy in real-time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, it’s time to save all the chatbot responses and calculate how well
    the chatbot performs to solve real customer inquiries. As the customer can directly
    respond to the chatbot, it is also important to record the response from the customer,
    to understand the customer’s sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: The same evaluation workflow can be used to measure the chatbot's success factually,
    without the ground truth replies. But now the customers are getting the initial
    reply from a chatbot, and we do not know if the customers like it. We should investigate
    how customers react to the chatbot's replies. We can detect negative sentiment
    from the customer's replies automatically, and assign customer support specialists
    to handle angry customers.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this short article, I explained three steps to avoid failing your AI project:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Measure** the **problem magnitude**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Measure** the solution **accuracy retrospectively**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Measure** the solution **accuracy** in **real-time**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The first two steps are by far the most crucial and are the primary reasons
    why many projects fail. While it is possible to succeed without measuring the
    problem's magnitude or the solution’s accuracy, subjective estimates are generally
    flawed due to [hundreds of human biases](https://gustdebacker.com/cognitive-biases/).
    Correctly designed data-driven approaches almost always give better results.
  prefs: []
  type: TYPE_NORMAL
- en: If you are curious about how to implement chatbots like this, check out my [blog
    post on RAG](https://medium.datadriveninvestor.com/de-mystifying-vector-databases-for-chatgpt-case-frendi-55e7cf3d60ff),
    and [blog post on advanced RAG](https://medium.datadriveninvestor.com/improve-rag-performance-on-custom-vocabulary-e728b7a691e0).
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, feel free to network with me on LinkedIn and follow me here if you wish
    to read similar articles :)
  prefs: []
  type: TYPE_NORMAL
- en: '**Linkedin**: [@sormunenteemu](https://www.linkedin.com/in/sormunenteemu/)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Unless otherwise noted, all images and data are by the author.*'
  prefs: []
  type: TYPE_NORMAL
