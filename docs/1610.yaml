- en: Your AI Model Is Not Objective
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/your-ai-model-is-not-objective-aaaf92d47f05?source=collection_archive---------13-----------------------#2024-06-28](https://towardsdatascience.com/your-ai-model-is-not-objective-aaaf92d47f05?source=collection_archive---------13-----------------------#2024-06-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Opinion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Where we explore the subjectiveness in AI models and why you should care
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@p.h.hiemstra?source=post_page---byline--aaaf92d47f05--------------------------------)[![Paul
    Hiemstra](../Images/233823df2f4bf81ca07059dd17783ce3.png)](https://medium.com/@p.h.hiemstra?source=post_page---byline--aaaf92d47f05--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--aaaf92d47f05--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--aaaf92d47f05--------------------------------)
    [Paul Hiemstra](https://medium.com/@p.h.hiemstra?source=post_page---byline--aaaf92d47f05--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--aaaf92d47f05--------------------------------)
    ·4 min read·Jun 28, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: I recently visited a conference, and a sentence on one of the slides really
    struck me. The slide mentioned that they where developing an AI model to replace
    a human decision, and that the model was, quote, “objective” in contrast to the
    human decision. After thinking about it for some time, I vehemently disagreed
    with that statement as I feel it tends to isolate us from the people for which
    we create these model. This in turn limits the impact we can have.
  prefs: []
  type: TYPE_NORMAL
- en: In this opinion piece I want to explain where my disagreement with AI and objectiveness
    comes from, and why the focus on “objective” poses a problem for AI researchers
    who want to have impact in the real world. It reflects insights I have gathered
    from the research I have done recently on why many AI models do not reach effective
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b652f4070d04dec86fa2fa0723bcd7fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vlad Hilitanu](https://unsplash.com/@vladhilitanu?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/people-holding-miniature-figures-1FI2QAYPa-Y?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Where math touches reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get my point across we need to agree on what we mean exactly with objectiveness.
    In this essay I use the following [definition of *Objectiveness*](https://www.merriam-webster.com/dictionary/objective):'
  prefs: []
  type: TYPE_NORMAL
- en: expressing or dealing with facts or conditions as perceived without distortion
    by personal feelings, prejudices, or interpretations
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'For me, this definition speaks to something I deeply love about math: within
    the scope of a mathematical system we can reason objectively what the truth is
    and how things work. This appealed strongly to me, as I found social interactions
    and feelings to be very challenging. I felt that if I worked hard enough I could
    understand the math problem, while the real world was much more intimidating.'
  prefs: []
  type: TYPE_NORMAL
- en: As machine learning and AI is built using math (mostly algebra), it is tempting
    to extend this same objectiveness to this context. I do think as a mathematical
    system, machine learning can be seen as objective. If I lower the learning rate,
    we should mathematically be able predict what the impact on the resulting AI should
    be. However, with our ML models becoming larger and much more black box, configuring
    them has become more and more an art instead of a science. Intuitions on how to
    improve the performance of a model can be a powerful tool for the AI researcher.
    This sounds awfully close to “personal feelings, prejudices, or interpretations”.
  prefs: []
  type: TYPE_NORMAL
- en: But where the subjectiveness really kicks in is where the AI model interacts
    with the real world. A model can predict what the probability is that a patient
    has cancer, but how that interacts with the actual medical decisions and treatment
    contains a lot of feelings and interpretations. What will the impact of treatment
    be on the patient, and is the treatment worth it? What is the mental state of
    a patient, and can they bear the treatment?
  prefs: []
  type: TYPE_NORMAL
- en: 'But the subjectiveness does not end with the application of the outcome of
    the AI model in the real world. In how we build and configure a model, a lot of
    choices have to be made that interact with reality:'
  prefs: []
  type: TYPE_NORMAL
- en: What data do we include in the model or not. Which patients do we decide are
    outliers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which metric do we use to evaluate our model? How does this influence the model
    we end up creating? What metric steers us towards a real-world solution? Is there
    a metric at all that does this?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do we define the actual problem to be that our model should solve? This
    will influence the decision we make in regard to configuration of the AI model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, where the real world engages with AI models quite a bit of subjectiveness
    is introduced. This applies to both technical choices we make and in how the outcome
    of the model interacts with the real world.
  prefs: []
  type: TYPE_NORMAL
- en: But why does this matter?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In my experience, one of the key limiting factors in implementing AI models
    in the real world is close collaboration with stakeholders. Be they doctors, employees,
    ethicists, legal experts, or consumers. This lack of cooperation is partly due
    to the isolationist tendencies I see in many AI researchers. They work on their
    models, ingest knowledge from the internet and papers, and try to create the AI
    model to the best of their abilities. But they are focused on the technical side
    of the AI model, and exist in their mathematical bubble.
  prefs: []
  type: TYPE_NORMAL
- en: I feel that the conviction that AI models are objective reinsures the AI researcher
    that this isolationism is fine, the objectiveness of the model means that it can
    be applied in the real world. But the real world is full of “feelings, prejudices
    and interpretations”, making an AI model that impacts this real world also interact
    with these “feelings, prejudices and interpretations”. If we want to create a
    model that has impact in the real world we need to incorporate the subjectiveness
    of the real world. And this requires building a strong community of stakeholders
    around your AI research that explores, exchanges and debates all these “feelings,
    prejudices and interpretations”. It requires us AI researchers to come out of
    our self-imposed mathematical shell.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note*: If you want to read more about doing research in a more holistic and
    collaborative way, I highly recommend the work of Tineke Abma, for example [this
    paper](https://onlinelibrary.wiley.com/doi/10.1002/ev.31).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you enjoyed this article, you might also enjoy some of my other articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[A series of articles on learning an AI bot to play tic-tac-toe](https://towardsdatascience.com/tagged/rl-series-paul)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Altair plot deconstruction: visualizing the correlation structure of weather
    data](/altair-plot-deconstruction-visualizing-the-correlation-structure-of-weather-data-38fb5668c5b1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Advanced functional programming for data science: building code architectures
    with function operators](/advanced-functional-programming-for-data-science-building-code-architectures-with-function-dd989cc3b0da)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
