<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Towards increased truthfulness in LLM applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Towards increased truthfulness in LLM applications</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01">https://towardsdatascience.com/towards-increased-truthfulness-in-llm-applications-d25fc35c7ef9?source=collection_archive---------7-----------------------#2024-03-01</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="62ea" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Application-oriented methods from current research</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Marlon Hamm" class="l ep by dd de cx" src="../Images/fc8c340a9729c9d1623692445e651e57.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*dw9izt1YzVKbeBWnr6B-Ow.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@Marlon_H?source=post_page---byline--d25fc35c7ef9--------------------------------" rel="noopener follow">Marlon Hamm</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d25fc35c7ef9--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 1, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="fa83" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">Abstract</h1><p id="8fc8" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">This article explores methods to enhance the truthfulness of Retrieval Augmented Generation (RAG) application outputs, focusing on mitigating issues like hallucinations and reliance on pre-trained knowledge. I identify the causes of untruthful results, evaluate methods for assessing truthfulness, and propose solutions to improve accuracy. The study emphasizes the importance of groundedness and completeness in RAG outputs, recommending fine-tuning Large Language Models (LLMs) and employing element-aware summarization to ensure factual accuracy. Additionally, it discusses the use of scalable evaluation metrics, such as the Learnable Evaluation Metric for Text Simplification (LENS), and Chain of Thought-based (CoT) evaluations, for real-time output verification. The article highlights the need to balance the benefits of increased truthfulness against potential costs and performance impacts, suggesting a selective approach to method implementation based on application needs.</p><h1 id="c741" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">1. Introduction</h1><p id="ba17" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">A widely used Large Language Model (LLM) architecture which can provide insight into application outputs and reduce hallucinations is Retrieval Augmented Generation (RAG). RAG is a method to expand LLM memory by combining parametric memory (i.e. LLM pre-trained) with non-parametric (i.e. document retrieved) memories. To do this, the most relevant documents are retrieved from a vector database and, together with the user question and a customised prompt, passed to an LLM, which generates a response (see Figure 1). For further details, see Lewis et al. (2021).</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc od"><img src="../Images/6a9c52e4fc242cc2c7cfc03e70b57cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIKb0hmEKNbg3r37POdIZg.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Figure 1 — Simplified RAG architecture</figcaption></figure><p id="5d95" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">A real-world application can, for instance, connect an LLM to a database of medical guideline documents. Medical practitioners can replace manual look-up by asking natural language questions using RAG as a “search engine”. The application would answer the user’s question and reference the source guideline. If the answer is based on parametric memory, e.g. answering on guidelines contained in the pre-training but not the connected database, or if the LLM hallucinates, this could have drastic implications.</p><p id="c623" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Firstly, if the medical practitioners verify with the referenced guidelines, they could lose trust in the application answers, leading to less usage. Secondly, and more worryingly, if not every answer is verified, an answer can be falsely assumed to be based on the queried medical guidelines, directly affecting the patient’s treatment. This highlights the relevance of the truthfulness of output in RAG applications.</p><p id="7451" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">In this article assessing RAG, truth is defined as being firmly grounded in factual knowledge of the retrieved document. To investigate this issue, one General Research Question (GRQ) and three Specific Research Questions (SRQ) are derived.</p><p id="ed58" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">GRQ: How can the truthfulness of RAG outputs be improved?</p><p id="4c89" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">SRQ 1: What causes untruthful results to be generated by RAG applications?</p><p id="e031" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">SRQ 2: How can truthfulness be evaluated?</p><p id="f333" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">SRQ 3: What methods can be used to increase truthfulness?</p><p id="58c9" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">To answer the GRQ, the SRQs are analysed sequentially on the basis of literature research. The aim is to identify methods that can be implemented for use cases such as the above example from the medical field. Ultimately two categories of solution methods will be recommended for further analysis and customisation.</p><h1 id="571f" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">2. Untruthful RAG output</h1><p id="a40f" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">As previously defined, a truthful answer should be firmly grounded in factual knowledge of the retrieved document. One metric for this is factual consistency, measuring if the summary contains untruthful or misleading facts that are not supported by the source text (Liu et al., 2023). It is used as a critical evaluation metric in multiple benchmarks (Kim et al., 2023; Fabbri et al., 2021; Deutsch &amp; Roth, 2022; Wang et al., 2023; Wu et al., 2023). In the area of RAG, this is often referred to as groundedness (Levonian et al., 2023). Moreover, to take the usefulness of a truthful answer into consideration, its completeness is also of relevance. The following paragraphs give insight into the reason behind untruthful RAG results. This refers to the Generation Step in Figure 1, which summarises the retrieved documents with respect to the user question.</p><p id="9c0f" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Firstly, the groundedness of an RAG application is impacted if the LLM answer is based on parametric memory rather than the factual knowledge of the retrieved document. This can, for instance, occur if the answer comes from pre-trained knowledge or is caused by hallucinations. Hallucinations still remain a fundamental problem of LLMs (Bang et al., 2023; Ji et al., 2023; Zhang &amp; Gao, 2023), from which even powerful LLMs suffer (Liu et al., 2023). As per definition, low groundedness results in untruthful RAG results.</p><p id="bcd2" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Secondly, completeness describes if an LLM´s answer lacks factual knowledge from the documents. This can be due to the low summarisation capability of an LLM or missing domain knowledge to interpret the factual knowledge (T. Zhang et al., 2023). The output could still be highly grounded. Nevertheless, an answer could be incomplete with respect to the documents. Leading to incorrect user perception of the content of the database. In addition, if factual knowledge from the document is missing, the LLM can be encouraged to make up for this by answering with its own parametric memory, raising the abovementioned issue.</p><p id="dc62" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Having established the key causes of untruthful outputs, it is necessary to first measure and quantify these errors before a solution can be pursued. Therefore, the following section will cover the methods of measurement for the aforementioned sources of untruthful RAG outputs.</p><h1 id="99cf" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">3. Evaluating truthfulness</h1><p id="b640" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Having elaborated on groundedness and completeness and their origins, this section intends to guide through their measurement methods. I will begin with the widely known general-purpose methods and continue by highlighting recent trends. TruLens´s Feedback Functions plot serves here as a valuable reference for scalability and meaningfulness (see Figure2).</p><p id="e84f" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">When talking about natural language generation evaluations, traditional evaluation metrics like ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002) are widely used but tend to show a discrepancy from human assessments (Liu et al., 2023). Furthermore, Medium Language Models (MLMs) have demonstrated superior results to traditional evaluation metrics, but can be replaced by LLMs in many areas (X. Zhang &amp; Gao, 2023). Lastly, another well-known evaluation method is the human evaluation of generated text, which has apparent drawbacks of scale and cost (Fabbri et al., 2021). Due to the downsides of these methods (see Figure 2), these are not relevant for further consideration in this paper.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc od"><img src="../Images/fb4848d5356e302c9d8324125089d93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4wdBqC0D0TgdwZAdTum4w.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Figure 2 — Feedback functions (Feedback Functions — TruLens, o. J.)</figcaption></figure><p id="fec0" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Concerning recent trends, evaluation metrics have developed with the increase in the popularity of LLMs. One such development are LLM evaluations, allowing another LLM through Chain of Thought (CoT) reasoning to evaluate the generated text (Liu et al., 2023). Through bespoke prompting strategies, areas of focus like groundedness and completeness can be emphasised and numerically scored (Kim et al., 2023). For this method, it has been shown that a larger model size is beneficial for summarisation evaluation (Liu et al., 2023). Moreover, this evaluation can also be based on references or collected ground truth, comparing generated text and reference text (Wu et al., 2023). For open-ended tasks without a single correct answer, LLM-based evaluation outperforms reference-based metrics in terms of correlation with human quality judgements. Moreover, ground-truth collection can be costly. Therefore, reference or ground-truth based metrics are outside the scope of this assessment (Liu et al., 2023; <em class="oz">Feedback Functions — TruLens</em>, o. J.).</p><p id="6272" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Concluding with a noteworthy recent development, the <strong class="nh fr">L</strong>earnable <strong class="nh fr">E</strong>valuatio<strong class="nh fr">n</strong> Metric for Text <strong class="nh fr">S</strong>implification (LENS), stated to be “the first supervised automatic metric for text simplification evaluation” by Maddela et al. (2023), has demonstrated promising outcomes in recent benchmarks. It is recognized for its effectiveness in identifying hallucinations (Kew et al., 2023). In terms of scalability and meaningfulness this is expected to be slightly more scalable, due to lower cost, and slightly less meaningful than LLM evaluations, placing LENS close to LLM Evals in the right top corner of Figure 2. Nevertheless, further assessment would be required to verify these claims. This would conclude the evaluations methods in scope and the next section is focusing on methods of their application.</p><h1 id="8962" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">4. Toward increased truthfulness</h1><p id="3f9f" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Having established in section 1, the relevance of truthfulness in RAG applications, with SRQ1 the causes of untruthful output and with SRQ2 its evaluation, this section will focus on SRQ3. Hence, detailing specific recommended methods improving groundedness and completeness to increase truthful responses. These methods can be categorised into two groups, improvements in the generation of output and validation of output.</p><p id="4e6e" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">In order to improve the generation step of the RAG application, this article will highlight two methods. These are visualised in Figure 3, with the simplified RAG architecture referenced on the left. The first methods is fine-tuning the generation LLM. Instruction tuning over model size is critical to the LLM’s zero-shot summarisation capability. Thus, state-of-the-art LLMs can perform on par with summaries written by freelance writers (T. Zhang et al., 2023). The second method focuses on element-aware summarisation. With CoT prompting, like presented in SumCoT, LLMs can generate summaries step by step, emphasising the factual entities of the source text (Wang et al., 2023). Specifically, in an additional step, factual elements are extracted from the relevant documents and made available to the LLM in addition to the context for the summarisation, see Figure 3. Both methods have shown promising results for improving the groundedness and completeness of LLM-generated summaries.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc od"><img src="../Images/8fc1964dfeef26680b2ff843985779af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V9GI81RDpUJ74pHzoXFCww.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Figure 3 — Improved generation step</figcaption></figure><p id="a195" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">In validation of the RAG outputs, LLM-generated summaries are evaluated for groundedness and completeness. This can be done by CoT prompting an LLM to aggregate a groundedness and completeness score. In Figure 4 an example CoT prompt is depicted, which can be forwarded to an LLM of larger model size for completion. Furthermore, this step can be replaced or advanced by using supervised metrics like LENS. At last, the generated evaluation is compared against a threshold. In case of not grounded or incomplete outputs, those can be modified, raised to the user or potentially rejected.</p><figure class="oe of og oh oi oj ob oc paragraph-image"><div role="button" tabindex="0" class="ok ol ed om bh on"><div class="ob oc od"><img src="../Images/c340417353118f5143a2970195f46942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HyHcLCwh378IgikeUce7ZA.png"/></div></div><figcaption class="op oq or ob oc os ot bf b bg z dx">Figure 4 — Output validation</figcaption></figure><p id="3490" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Before adapting these methods to RAG applications, it should be considered that evaluation at run-time and fine-tuning the generation model will lead to additional costs. Furthermore, the evaluation step will affect the applications’ answering speed. Lastly, no answer due to output rejections and raised truthfulness concerns might confuse application users. Consequently, it is critical to evaluate these methods with respect to the field of application, the functionality of the application and the user´s expectations. Leading to a customised approach increasing outputs truthfulness of RAG applications.</p><p id="4ee7" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Unless otherwise noted, all images are by the author.</p><h1 id="4894" class="mj mk fq bf ml mm mn gq mo mp mq gt mr ms mt mu mv mw mx my mz na nb nc nd ne bk">List of References</h1><p id="10ed" class="pw-post-body-paragraph nf ng fq nh b go ni nj nk gr nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa fj bk">Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., Do, Q. V., Xu, Y., &amp; Fung, P. (2023). <em class="oz">A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity</em> (arXiv:2302.04023). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2302.04023" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2302.04023</a></p><p id="789e" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Deutsch, D., &amp; Roth, D. (2022). <em class="oz">Benchmarking Answer Verification Methods for Question Answering-Based Summarization Evaluation Metrics</em> (arXiv:2204.10206). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2204.10206" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2204.10206</a></p><p id="9c85" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Fabbri, A. R., Kryściński, W., McCann, B., Xiong, C., Socher, R., &amp; Radev, D. (2021). <em class="oz">SummEval: Re-evaluating Summarization Evaluation</em> (arXiv:2007.12626). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2007.12626" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2007.12626</a></p><p id="6d62" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk"><em class="oz">Feedback Functions — TruLens</em>. (o. J.). Abgerufen 11. Februar 2024, von <a class="af pa" href="https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions" rel="noopener ugc nofollow" target="_blank">https://www.trulens.org/trulens_eval/core_concepts_feedback_functions/#feedback-functions</a></p><p id="5634" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Dai, W., Madotto, A., &amp; Fung, P. (2023). Survey of Hallucination in Natural Language Generation. <em class="oz">ACM Computing Surveys</em>, <em class="oz">55</em>(12), 1–38. <a class="af pa" href="https://doi.org/10.1145/3571730" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1145/3571730</a></p><p id="4c95" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Kew, T., Chi, A., Vásquez-Rodríguez, L., Agrawal, S., Aumiller, D., Alva-Manchego, F., &amp; Shardlow, M. (2023). <em class="oz">BLESS: Benchmarking Large Language Models on Sentence Simplification</em> (arXiv:2310.15773). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2310.15773" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2310.15773</a></p><p id="dc02" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Kim, J., Park, S., Jeong, K., Lee, S., Han, S. H., Lee, J., &amp; Kang, P. (2023). <em class="oz">Which is better? Exploring Prompting Strategy For LLM-based Metrics</em> (arXiv:2311.03754). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2311.03754" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2311.03754</a></p><p id="77db" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Levonian, Z., Li, C., Zhu, W., Gade, A., Henkel, O., Postle, M.-E., &amp; Xing, W. (2023). <em class="oz">Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference</em> (arXiv:2310.03184). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2310.03184" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2310.03184</a></p><p id="88de" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., &amp; Kiela, D. (2021). <em class="oz">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</em> (arXiv:2005.11401). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2005.11401" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2005.11401</a></p><p id="54c3" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. <em class="oz">Text Summarization Branches Out</em>, 74–81. <a class="af pa" href="https://aclanthology.org/W04-1013" rel="noopener ugc nofollow" target="_blank">https://aclanthology.org/W04-1013</a></p><p id="634b" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Liu, Y., Iter, D., Xu, Y., Wang, S., Xu, R., &amp; Zhu, C. (2023). <em class="oz">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment</em> (arXiv:2303.16634). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2303.16634" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2303.16634</a></p><p id="4a67" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Maddela, M., Dou, Y., Heineman, D., &amp; Xu, W. (2023). <em class="oz">LENS: A Learnable Evaluation Metric for Text Simplification</em> (arXiv:2212.09739). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2212.09739" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2212.09739</a></p><p id="26b4" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Papineni, K., Roukos, S., Ward, T., &amp; Zhu, W.-J. (2002). Bleu: A Method for Automatic Evaluation of Machine Translation. In P. Isabelle, E. Charniak, &amp; D. Lin (Hrsg.), <em class="oz">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em> (S. 311–318). Association for Computational Linguistics. <a class="af pa" href="https://doi.org/10.3115/1073083.1073135" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.3115/1073083.1073135</a></p><p id="35bf" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Wang, Y., Zhang, Z., &amp; Wang, R. (2023). <em class="oz">Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method</em> (arXiv:2305.13412). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2305.13412" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2305.13412</a></p><p id="39ae" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Wu, N., Gong, M., Shou, L., Liang, S., &amp; Jiang, D. (2023). <em class="oz">Large Language Models are Diverse Role-Players for Summarization Evaluation</em> (arXiv:2303.15078). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2303.15078" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2303.15078</a></p><p id="37cf" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Zhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., &amp; Hashimoto, T. B. (2023). <em class="oz">Benchmarking Large Language Models for News Summarization</em> (arXiv:2301.13848). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2301.13848" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2301.13848</a></p><p id="8395" class="pw-post-body-paragraph nf ng fq nh b go ou nj nk gr ov nm nn no ow nq nr ns ox nu nv nw oy ny nz oa fj bk">Zhang, X., &amp; Gao, W. (2023). <em class="oz">Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method</em> (arXiv:2310.00305). arXiv. <a class="af pa" href="https://doi.org/10.48550/arXiv.2310.00305" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.2310.00305</a></p></div></div></div></div>    
</body>
</html>