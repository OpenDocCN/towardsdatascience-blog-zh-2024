- en: 'â€œJudge an LLM Judgeâ€: A Dual-Layer Evaluation (QA) Framework for Continuous
    Improvement of LLM Applicationâ€™s Evaluation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: â€œè¯„åˆ¤LLMæ³•å®˜â€ï¼šLLMåº”ç”¨è¯„ä¼°æŒç»­æ”¹è¿›çš„åŒå±‚è¯„ä¼°ï¼ˆQAï¼‰æ¡†æ¶
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17](https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17](https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17)
- en: Can â€œthe evaluation of an LLM app by an LLM judgeâ€ be audited by another LLM
    judge for the continuous improvement of the evaluation process?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â€œç”±LLMæ³•å®˜å¯¹LLMåº”ç”¨è¿›è¡Œè¯„ä¼°â€æ˜¯å¦å¯ä»¥é€šè¿‡å¦ä¸€ä¸ªLLMæ³•å®˜è¿›è¡Œå®¡è®¡ï¼Œä»¥å®ç°è¯„ä¼°è¿‡ç¨‹çš„æŒç»­æ”¹è¿›ï¼Ÿ
- en: '[](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    Â·11 min readÂ·Jul 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2024å¹´7æœˆ17æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1ddd8f73fa7bf769628f79323863c090.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ddd8f73fa7bf769628f79323863c090.png)'
- en: Continuous Improvement Framework for LLM Applicationâ€™s Evaluation with Reference-free
    Approach â€” Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: LLMåº”ç”¨è¯„ä¼°çš„æŒç»­æ”¹è¿›æ¡†æ¶â€”â€”æ— å‚è€ƒæ–¹æ³• â€”â€” å›¾åƒç”±ä½œè€…æä¾›
- en: TLDR
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TLDR
- en: This article explains the concept and the low-abstraction implementation of
    employing an LLM judge to evaluate another LLM judge. The purpose is to improve
    the evaluation process of LLM applications, reducing cases where LLM judges fail
    to make fair assessments.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ¬æ–‡è§£é‡Šäº†ä½¿ç”¨LLMæ³•å®˜è¯„ä¼°å¦ä¸€ä¸ªLLMæ³•å®˜çš„æ¦‚å¿µå’Œä½æŠ½è±¡å®ç°ã€‚å…¶ç›®çš„æ˜¯æ”¹è¿›LLMåº”ç”¨çš„è¯„ä¼°è¿‡ç¨‹ï¼Œå‡å°‘LLMæ³•å®˜æœªèƒ½åšå‡ºå…¬æ­£è¯„ä¼°çš„æƒ…å†µã€‚
- en: Table of Contents
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç›®å½•
- en: '[Introduction](#f147)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¼•è¨€](#f147)'
- en: '[Research Question](#422d)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç ”ç©¶é—®é¢˜](#422d)'
- en: '[Experiment Design](#1e42)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å®éªŒè®¾è®¡](#1e42)'
- en: '[Implementation](#2805)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å®ç°](#2805)'
- en: '[Experiment Results](#1fe0)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å®éªŒç»“æœ](#1fe0)'
- en: '[Conclusions](#41bc)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ç»“è®º](#41bc)'
- en: ğŸ‘‰ Introduction
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ å¼•è¨€
- en: â‡ï¸ In the field of building LLM applications, how to ensure consistent and reliable
    performance is one of the most frequently asked questions regarding QA (Quality
    Assurance). Due to their indeterministic nature, LLM models can produce great
    variability in their outputs. Hence, rigorous evaluation of LLM applications is
    strictly required. **Without good evaluation methods, we must accept a certain
    level of risk (e.g. customer complaints, etc.) due to the inability to promptly
    identify unexpected behaviors in LLM applications.** Common LLM evaluation methodologies
    include heuristic evaluations, LLM-as-judge, and human review.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: â‡ï¸ åœ¨æ„å»ºLLMåº”ç”¨çš„é¢†åŸŸï¼Œå¦‚ä½•ç¡®ä¿ä¸€è‡´ä¸”å¯é çš„æ€§èƒ½æ˜¯å…³äºè´¨é‡ä¿è¯ï¼ˆQAï¼‰ä¸­æœ€å¸¸è§çš„æé—®ä¹‹ä¸€ã€‚ç”±äºLLMæ¨¡å‹çš„éç¡®å®šæ€§ç‰¹æ€§ï¼Œå®ƒä»¬çš„è¾“å‡ºå¯èƒ½å…·æœ‰æå¤§çš„å˜åŒ–æ€§ã€‚å› æ­¤ï¼ŒLLMåº”ç”¨çš„ä¸¥æ ¼è¯„ä¼°æ˜¯ç»å¯¹å¿…è¦çš„ã€‚**æ²¡æœ‰è‰¯å¥½çš„è¯„ä¼°æ–¹æ³•ï¼Œæˆ‘ä»¬å¿…é¡»æ¥å—ä¸€å®šç¨‹åº¦çš„é£é™©ï¼ˆä¾‹å¦‚å®¢æˆ·æŠ•è¯‰ç­‰ï¼‰ï¼Œå› ä¸ºæ— æ³•åŠæ—¶è¯†åˆ«LLMåº”ç”¨ä¸­çš„æ„å¤–è¡Œä¸ºã€‚**
    å¸¸è§çš„LLMè¯„ä¼°æ–¹æ³•åŒ…æ‹¬å¯å‘å¼è¯„ä¼°ã€LLMä½œä¸ºæ³•å®˜å’Œäººå·¥è¯„å®¡ã€‚
- en: ğŸ“ **Heuristic evaluators:** e.g. a function to check whether output = â€œyesâ€
    or whether the output > 10.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“ **å¯å‘å¼è¯„ä¼°è€…ï¼š**ä¾‹å¦‚ï¼Œæ£€æŸ¥è¾“å‡ºæ˜¯å¦ç­‰äºâ€œyesâ€æˆ–è¾“å‡ºæ˜¯å¦å¤§äº10çš„å‡½æ•°ã€‚
- en: ğŸ“ **LLM-as-judge:** using an LLM to judge the output of another LLM.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“ **LLMä½œä¸ºæ³•å®˜ï¼š**ä½¿ç”¨LLMå¯¹å¦ä¸€ä¸ªLLMçš„è¾“å‡ºè¿›è¡Œè¯„åˆ¤ã€‚
- en: ğŸ“**Human judge:** employ a human to evaluate the LLMâ€™s output.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“**äººå·¥è¯„åˆ¤è€…ï¼š**ä½¿ç”¨äººå·¥è¯„ä¼°LLMçš„è¾“å‡ºã€‚
- en: â‡ï¸ Employing an LLM judge is a top choice as it can be automated and is much
    cheaper (and more feasible) than human judges. Besides, LLM judges can deal with
    the free-text format, unlike heuristic evaluators. However, the non-deterministic
    nature of LLMs implies that even with controlled parameters, outputs may vary,
    raising concerns about the reliability of these judgments.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: â‡ï¸ ä½¿ç”¨LLMè¯„åˆ¤è€…æ˜¯ä¸€ä¸ªæœ€ä½³é€‰æ‹©ï¼Œå› ä¸ºå®ƒå¯ä»¥è‡ªåŠ¨åŒ–ï¼Œå¹¶ä¸”æ¯”äººå·¥è¯„åˆ¤è€…ä¾¿å®œï¼ˆä¸”æ›´å¯è¡Œï¼‰ã€‚æ­¤å¤–ï¼ŒLLMè¯„åˆ¤è€…å¯ä»¥å¤„ç†è‡ªç”±æ–‡æœ¬æ ¼å¼ï¼Œè¿™ä¸å¯å‘å¼è¯„ä¼°è€…ä¸åŒã€‚ç„¶è€Œï¼ŒLLMçš„éç¡®å®šæ€§ç‰¹å¾æ„å‘³ç€å³ä½¿åœ¨æ§åˆ¶äº†å‚æ•°çš„æƒ…å†µä¸‹ï¼Œè¾“å‡ºä¹Ÿå¯èƒ½æœ‰æ‰€ä¸åŒï¼Œè¿™å¼•å‘äº†å¯¹è¿™äº›åˆ¤æ–­å¯é æ€§çš„æ‹…å¿§ã€‚
- en: ğŸ’¥ **The concern we will address today:**
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¥ **ä»Šå¤©æˆ‘ä»¬å°†è®¨è®ºçš„é—®é¢˜ï¼š**
- en: When opting for an LLM judge to evaluate our LLM application, we should also
    question the integrity of the LLM judge itself.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å½“é€‰æ‹©LLMè¯„åˆ¤è€…æ¥è¯„ä¼°æˆ‘ä»¬çš„LLMåº”ç”¨æ—¶ï¼Œæˆ‘ä»¬è¿˜åº”è´¨ç–‘LLMè¯„åˆ¤è€…æœ¬èº«çš„å®Œæ•´æ€§ã€‚
- en: âœ… So, the experiment described below aims to determine whether we can use an
    LLM judge (letâ€™s call it â€œSupreme LLM Judgeâ€) to evaluate the judgments of another
    LLM judge without any ground truth reference (**reference-free evaluation**).
    The ultimate goal is to find ways to improve the first LLM judge.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… å› æ­¤ï¼Œä¸‹é¢æè¿°çš„å®éªŒæ—¨åœ¨ç¡®å®šæˆ‘ä»¬æ˜¯å¦å¯ä»¥ä½¿ç”¨ä¸€ä¸ªLLMè¯„åˆ¤è€…ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸ºâ€œæœ€é«˜LLMè¯„åˆ¤è€…â€ï¼‰æ¥è¯„ä¼°å¦ä¸€ä¸ªLLMè¯„åˆ¤è€…çš„åˆ¤æ–­ï¼Œè€Œæ— éœ€ä»»ä½•çœŸå®å‚è€ƒï¼ˆ**æ— å‚è€ƒè¯„ä¼°**ï¼‰ã€‚æœ€ç»ˆç›®æ ‡æ˜¯æ‰¾åˆ°æ”¹å–„ç¬¬ä¸€ä¸ªLLMè¯„åˆ¤è€…çš„æ–¹æ³•ã€‚
- en: The graph below explains such a framework.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹å›¾è§£é‡Šäº†è¿™æ ·ä¸€ä¸ªæ¡†æ¶ã€‚
- en: '![](../Images/e64281469a2e8d61880d99dbaa1193e9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e64281469a2e8d61880d99dbaa1193e9.png)'
- en: High-level architecture of using an LLM judge to judge another LLM judge (reference-free)
    â€” Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨LLMè¯„åˆ¤è€…è¯„åˆ¤å¦ä¸€ä¸ªLLMè¯„åˆ¤è€…ï¼ˆæ— å‚è€ƒï¼‰çš„é«˜å±‚æ¶æ„â€”â€”å›¾ç‰‡æ¥è‡ªä½œè€…
- en: ğŸ‘‰ Research Question
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ ç ”ç©¶é—®é¢˜
- en: Can â€œthe evaluation of an LLM application by an LLM judgeâ€ be audited by another
    LLM judge for the continuous improvement of the evaluation process?
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œLLMè¯„åˆ¤è€…å¯¹LLMåº”ç”¨çš„è¯„ä¼°â€æ˜¯å¦å¯ä»¥ç”±å¦ä¸€ä¸ªLLMè¯„åˆ¤è€…è¿›è¡Œå®¡è®¡ï¼Œä»¥ä¾¿ä¸æ–­æ”¹è¿›è¯„ä¼°è¿‡ç¨‹ï¼Ÿ
- en: ğŸ‘‰ Experiment Design
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ å®éªŒè®¾è®¡
- en: ğŸ”¹ One important constraint set out in this experiment that I must mention is
    that **both LLM judges will evaluate without a ground-truth reference**. Evaluation
    with ground-truth reference would provide the judges with the correct answers
    and ask them to compare. However, for most scenarios where we do not have datasets
    curated by humans, reference-free evaluation is the preferred approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¹ åœ¨æ­¤å®éªŒä¸­å¿…é¡»æåˆ°çš„ä¸€ä¸ªé‡è¦é™åˆ¶æ¡ä»¶æ˜¯ï¼Œ**ä¸¤ä¸ªLLMè¯„åˆ¤è€…éƒ½å°†è¿›è¡Œæ— çœŸå®å‚è€ƒçš„è¯„ä¼°**ã€‚å¦‚æœä½¿ç”¨çœŸå®å‚è€ƒè¿›è¡Œè¯„ä¼°ï¼Œè¯„åˆ¤è€…å°†å¾—åˆ°æ­£ç¡®ç­”æ¡ˆå¹¶è¦æ±‚è¿›è¡Œæ¯”è¾ƒã€‚ç„¶è€Œï¼Œå¯¹äºå¤§å¤šæ•°æ²¡æœ‰äººå·¥ç­–åˆ’çš„æ•°æ®é›†çš„åœºæ™¯ï¼Œé‡‡ç”¨æ— å‚è€ƒè¯„ä¼°æ˜¯é¦–é€‰æ–¹æ³•ã€‚
- en: ğŸ”¹ The proposed framework improves the conventional single-layer evaluation of
    LLM applications by adding a `Supreme LLM Judge`. We can have two approaches for
    this framework.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¹ æå‡ºçš„æ¡†æ¶é€šè¿‡å¢åŠ ä¸€ä¸ª`æœ€é«˜LLMè¯„åˆ¤è€…`ï¼Œæ”¹è¿›äº†ä¼ ç»Ÿçš„å•å±‚LLMåº”ç”¨è¯„ä¼°ã€‚æˆ‘ä»¬å¯ä»¥ä¸ºè¿™ä¸ªæ¡†æ¶æä¾›ä¸¤ç§æ–¹æ³•ã€‚
- en: '**Approach 1**: An LLM Application is evaluated by an LLM Judge, whose judgment
    is afterward reviewed by a Supreme LLM Judge (reference-free). Disagreements or
    anomalies are subsequently reviewed by a human.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–¹æ³• 1**ï¼šä¸€ä¸ªLLMåº”ç”¨ç¨‹åºç”±ä¸€ä¸ªLLMè¯„åˆ¤è€…è¿›è¡Œè¯„ä¼°ï¼Œå…¶åˆ¤æ–­éšåç”±æœ€é«˜LLMè¯„åˆ¤è€…ï¼ˆæ— å‚è€ƒï¼‰è¿›è¡Œå®¡æŸ¥ã€‚ä¸åŒæ„è§æˆ–å¼‚å¸¸æƒ…å†µéšåç”±äººå·¥è¿›è¡Œå®¡æŸ¥ã€‚'
- en: '![](../Images/9c6f792f8eebdf17e703a26683bae464.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c6f792f8eebdf17e703a26683bae464.png)'
- en: Approach 1 â€” Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹æ³• 1 â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: '**Approach 2**: Both the LLM Judge and the Supreme LLM Judge independently
    evaluate the LLM Application (reference-free). The judgments are then compared,
    and any discrepancies are flagged for human review.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–¹æ³• 2**ï¼šLLMè¯„åˆ¤è€…å’Œæœ€é«˜LLMè¯„åˆ¤è€…ç‹¬ç«‹è¯„ä¼°LLMåº”ç”¨ç¨‹åºï¼ˆæ— å‚è€ƒï¼‰ã€‚ç„¶åæ¯”è¾ƒè¯„åˆ¤ç»“æœï¼Œä»»ä½•å·®å¼‚éƒ½ä¼šæ ‡è®°å‡ºæ¥è¿›è¡Œäººå·¥å®¡æŸ¥ã€‚'
- en: '**Approach** **1 will be discussed further in this article.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ–¹æ³•** **1å°†åœ¨æœ¬æ–‡ä¸­è¿›ä¸€æ­¥è®¨è®ºã€‚**'
- en: ğŸ‘‰ Implementation
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ å®ç°
- en: ğŸ”¹ **The implementation of the aforementioned framework I opted for focuses on
    the high-level concept without delving too deeply into the fine-tuning for perfect
    performance.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¹ **æˆ‘é€‰æ‹©çš„ä¸Šè¿°æ¡†æ¶å®ç°å…³æ³¨çš„æ˜¯é«˜å±‚æ¬¡æ¦‚å¿µï¼Œè€Œæ²¡æœ‰æ·±å…¥æ¢è®¨å®Œç¾æ€§èƒ½çš„å¾®è°ƒã€‚**
- en: No LLM evaluation libraries or platforms (e.g., LangChain, LangSmith, LangFuse,
    etc.) were used. The code implementation has low abstraction, allowing readers
    to easily follow without getting lost in the intricate details of the code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æœªä½¿ç”¨ä»»ä½•LLMè¯„ä¼°åº“æˆ–å¹³å°ï¼ˆå¦‚LangChainã€LangSmithã€LangFuseç­‰ï¼‰ã€‚ä»£ç å®ç°çš„æŠ½è±¡ç¨‹åº¦è¾ƒä½ï¼Œä¾¿äºè¯»è€…è·Ÿéšï¼Œè€Œä¸ä¼šè¿·å¤±åœ¨å¤æ‚çš„ä»£ç ç»†èŠ‚ä¸­ã€‚
- en: 'Since referencing the *LLM judge* and the *Supreme LLM Judge* can be hard to
    follow, letâ€™s assign nominal roles for the components in the evaluation setup:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¼•ç”¨*LLMè¯„å®¡å‘˜*å’Œ*æœ€é«˜çº§LLMè¯„å®¡å‘˜*å¯èƒ½æ¯”è¾ƒéš¾ä»¥ç†è§£ï¼Œæˆ‘ä»¬ä¸ºè¯„ä¼°è®¾ç½®ä¸­çš„ç»„ä»¶åˆ†é…äº†åä¹‰è§’è‰²ï¼š
- en: '`LLM Application` â¡ï¸`The Student`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Application` â¡ï¸`å­¦ç”Ÿ`'
- en: '`LLM Judge` â¡ï¸ `The Teacher`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Judge` â¡ï¸ `æ•™å¸ˆ`'
- en: '`Supreme LLM Judge` â¡ï¸ `The Reviewer`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Supreme LLM Judge` â¡ï¸ `è¯„å®¡å‘˜`'
- en: '**ğŸ’¥ The complete code can be found in** [**this repository**](https://github.com/khoadaniel/judge-an-llm-judge)**.**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ’¥ å®Œæ•´ä»£ç å¯ä»¥åœ¨** [**è¿™ä¸ªä»“åº“**](https://github.com/khoadaniel/judge-an-llm-judge)**æ‰¾åˆ°ã€‚**'
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A subtle but important decision in this experiment design is to use GPT-4 as
    the Supreme LLM Judge, while the LLM Application and LLM Judge use GPT-3.5-turbo.
    This ensures that the Supreme LLM Judgeâ€™s evaluations are more robust and reliable
    (read more about the comparison [here](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/comparing-gpt-3-5-amp-gpt-4-a-thought-framework-on-when-to-use/ba-p/4088645#:~:text=GPT%2D3.5%20was%20trained%20on,to%20their%20GPT%2D3.5%20counterparts.)).
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ¬å®éªŒè®¾è®¡ä¸­çš„ä¸€ä¸ªå¾®å¦™ä½†é‡è¦çš„å†³ç­–æ˜¯ä½¿ç”¨GPT-4ä½œä¸ºæœ€é«˜çº§LLMè¯„å®¡å‘˜ï¼Œè€ŒLLMåº”ç”¨ç¨‹åºå’ŒLLMè¯„å®¡å‘˜ä½¿ç”¨çš„æ˜¯GPT-3.5-turboã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æœ€é«˜çº§LLMè¯„å®¡å‘˜çš„è¯„ä¼°æ›´åŠ ç¨³å¥å’Œå¯é ï¼ˆå…³äºæ¯”è¾ƒçš„æ›´å¤šä¿¡æ¯è¯·é˜…è¯»[è¿™é‡Œ](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/comparing-gpt-3-5-amp-gpt-4-a-thought-framework-on-when-to-use/ba-p/4088645#:~:text=GPT%2D3.5%20was%20trained%20on,to%20their%20GPT%2D3%2D5%20counterparts.))ã€‚
- en: The prompts for each of the components in this experiment are as follows. You
    can see that I used few-shot prompting technique to improve the consistency of
    the evaluation outputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å®éªŒä¸­å„ä¸ªç»„ä»¶çš„æç¤ºå¦‚ä¸‹ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä½¿ç”¨äº†å°‘æ ·æœ¬æç¤ºæŠ€æœ¯æ¥æé«˜è¯„ä¼°è¾“å‡ºçš„ä¸€è‡´æ€§ã€‚
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ğŸ”¹ **The question we asked the LLM application:**
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¹ **æˆ‘ä»¬é—®LLMåº”ç”¨ç¨‹åºçš„é—®é¢˜æ˜¯ï¼š**
- en: In a group of 30 people who can speak either English or German, 10 can speak
    both, and 25 can speak German.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ªèƒ½è¯´è‹±è¯­æˆ–å¾·è¯­çš„30äººå°ç»„ä¸­ï¼Œæœ‰10äººèƒ½è¯´ä¸¤ç§è¯­è¨€ï¼Œ25äººèƒ½è¯´å¾·è¯­ã€‚
- en: How many speak only English?
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¤šå°‘äººåªä¼šè¯´è‹±è¯­ï¼Ÿ
- en: The LLM Application must not only provide the correct answer but also explain
    its reasoning. The LLM Judge then evaluates this output â€” both the final answer
    and the reasoning. Finally, the Supreme LLM Judge will evaluate the evaluation
    given by the LLM Judge.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: LLMåº”ç”¨ç¨‹åºä¸ä»…éœ€è¦æä¾›æ­£ç¡®ç­”æ¡ˆï¼Œè¿˜éœ€è¦è§£é‡Šå…¶æ¨ç†è¿‡ç¨‹ã€‚LLMè¯„å®¡å‘˜éšåè¯„ä¼°æ­¤è¾“å‡ºâ€”â€”åŒ…æ‹¬æœ€ç»ˆç­”æ¡ˆå’Œæ¨ç†è¿‡ç¨‹ã€‚æœ€åï¼Œæœ€é«˜çº§LLMè¯„å®¡å‘˜å°†è¯„ä¼°LLMè¯„å®¡å‘˜ç»™å‡ºçš„è¯„ä¼°ã€‚
- en: You can notice that I left redundant information in the context of this question
    to challenge the LLM Application.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ³¨æ„åˆ°ï¼Œæˆ‘åœ¨è¿™ä¸ªé—®é¢˜çš„èƒŒæ™¯ä¸­ç•™äº†ä¸€äº›å†—ä½™ä¿¡æ¯ï¼Œä»¥æŒ‘æˆ˜LLMåº”ç”¨ç¨‹åºã€‚
- en: ğŸ”¹ **I ran this evaluation cycle 100 times with the default temperature set by
    OpenAI API using the same question to examine the performance of the judges.**
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¹ **æˆ‘ä½¿ç”¨OpenAI APIé»˜è®¤æ¸©åº¦è®¾ç½®ï¼Œè¿è¡Œäº†100æ¬¡è¯„ä¼°å‘¨æœŸï¼Œä½¿ç”¨ç›¸åŒçš„é—®é¢˜æ¥æ£€éªŒè¯„å®¡çš„è¡¨ç°ã€‚**
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ğŸ‘‰ Experiment Results
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ å®éªŒç»“æœ
- en: 'ğŸ’¥ Once again, before reading our results, just a reminder of our definitions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¥ å†æ¬¡æé†’ï¼Œåœ¨é˜…è¯»æˆ‘ä»¬çš„ç»“æœä¹‹å‰ï¼Œè¯·è®°ä½æˆ‘ä»¬çš„å®šä¹‰ï¼š
- en: '`LLM Application` â¡ï¸`The Student`'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Application` â¡ï¸`å­¦ç”Ÿ`'
- en: '`LLM Judge` â¡ï¸ `The Teacher`'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Judge` â¡ï¸ `æ•™å¸ˆ`'
- en: '`Supreme LLM Judge` â¡ï¸ `The Reviewer`'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Supreme LLM Judge` â¡ï¸ `è¯„å®¡å‘˜`'
- en: ğŸ’¥ **IMPORTANT:** We define a â€œpositive caseâ€ as when the evaluation of the Teacher
    is wrong.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¥ **é‡è¦:** æˆ‘ä»¬å®šä¹‰â€œæ­£ä¾‹â€ä¸ºæ•™å¸ˆè¯„ä¼°é”™è¯¯çš„æƒ…å†µã€‚
- en: We will measure the performance of the Reviewer (Supreme LLM Judge) by the following
    metrics.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é€šè¿‡ä»¥ä¸‹æŒ‡æ ‡æ¥è¡¡é‡è¯„å®¡å‘˜ï¼ˆæœ€é«˜çº§LLMè¯„å®¡å‘˜ï¼‰çš„è¡¨ç°ã€‚
- en: '**recall_of_reviewer:** measures the ability of the Reviewer to identify all
    the positive cases. It indicates how effectively the Reviewer can capture mistakes
    from the Teacher.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**recall_of_reviewer:** è¡¡é‡è¯„å®¡å‘˜è¯†åˆ«æ‰€æœ‰æ­£ä¾‹çš„èƒ½åŠ›ã€‚å®ƒè¡¨ç¤ºè¯„å®¡å‘˜èƒ½å¤šæœ‰æ•ˆåœ°ä»æ•™å¸ˆçš„è¯„ä¼°ä¸­æ•æ‰åˆ°é”™è¯¯ã€‚'
- en: '**precision_of_reviewer:** is defined as the proportion of the Reviewerâ€™s identified
    positive cases that are actually positive.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**precision_of_reviewer:** å®šä¹‰ä¸ºè¯„å®¡å‘˜è¯†åˆ«å‡ºçš„æ­£ä¾‹ä¸­ï¼Œå®é™…ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹ã€‚'
- en: There is always a tradeoff between precision and recall. The more true positive
    cases you want to capture in your predictions (and you do not care much about
    false positive cases), the less precise your model becomes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç²¾ç¡®åº¦å’Œå¬å›ç‡ä¹‹é—´æ€»æ˜¯å­˜åœ¨æƒè¡¡ã€‚ä½ å¸Œæœ›åœ¨é¢„æµ‹ä¸­æ•æ‰åˆ°æ›´å¤šçš„çœŸæ­£æ­£ä¾‹ï¼ˆä¸”ä¸å¤ªå…³æ³¨å‡æ­£ä¾‹ï¼‰ï¼Œé‚£ä¹ˆä½ çš„æ¨¡å‹å°±ä¼šå˜å¾—ä¸é‚£ä¹ˆç²¾ç¡®ã€‚
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Letâ€™s revisit our Research Question to see how the Supreme LLM Judge (the Reviewer)
    can help to audit the work of the LLM Judge (the Teacher).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é‡æ–°å®¡è§†æˆ‘ä»¬çš„ç ”ç©¶é—®é¢˜ï¼Œçœ‹çœ‹æœ€é«˜çº§LLMè¯„å®¡å‘˜ï¼ˆè¯„å®¡å‘˜ï¼‰å¦‚ä½•å¸®åŠ©å®¡æŸ¥LLMè¯„å®¡å‘˜ï¼ˆæ•™å¸ˆï¼‰çš„å·¥ä½œã€‚
- en: The Supreme LLM Judge can identify 70% of the instances where the LLM Judge
    made incorrect evaluations. By analyzing these identified cases, we can understand
    why the LLM Judge was confused and improve our LLM Applicationâ€™s evaluation process.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ€é«˜çº§LLMè¯„å®¡å‘˜èƒ½å¤Ÿè¯†åˆ«å‡ºLLMè¯„å®¡å‘˜åšå‡ºé”™è¯¯è¯„ä¼°çš„70%çš„æ¡ˆä¾‹ã€‚é€šè¿‡åˆ†æè¿™äº›å·²è¯†åˆ«çš„æ¡ˆä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£LLMè¯„å®¡å‘˜ä¸ºä½•ä¼šäº§ç”Ÿå›°æƒ‘ï¼Œä»è€Œæ”¹è¿›æˆ‘ä»¬LLMåº”ç”¨çš„è¯„ä¼°æµç¨‹ã€‚
- en: '**ğŸ˜® You might be curious about the wrong judgments from the LLM Judge that
    the Supreme LLM Judge has captured.**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**ğŸ˜® ä½ å¯èƒ½ä¼šå¥½å¥‡ï¼Œæœ€é«˜çº§LLMè¯„å®¡å‘˜æ•æ‰åˆ°çš„LLMè¯„å®¡å‘˜é”™è¯¯åˆ¤å®šã€‚**'
- en: Below are examples where the Reviewer successfully identified the Teacherâ€™s
    grading errors. By looking into these examples, we can study why the LLM Judge
    did not perform well.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯è¯„å®¡å‘˜æˆåŠŸè¯†åˆ«æ•™å¸ˆè¯„åˆ†é”™è¯¯çš„ç¤ºä¾‹ã€‚é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥ç ”ç©¶LLMè¯„å®¡å‘˜è¡¨ç°ä¸ä½³çš„åŸå› ã€‚
- en: ğŸ‘‹ **Before reading the examples below, about the â€œhuman evaluatorâ€:**
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‹ **åœ¨é˜…è¯»ä»¥ä¸‹ç¤ºä¾‹ä¹‹å‰ï¼Œå…³äºâ€œäººå·¥è¯„å®¡å‘˜â€çš„è¯´æ˜ï¼š**
- en: Yes, I (the Author) am the human evaluator!
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œæˆ‘ï¼ˆä½œè€…ï¼‰æ˜¯äººå·¥è¯„å®¡å‘˜ï¼
- en: In the context of this experiment, the human will grade the studentâ€™s answers
    as correct if the reasoning is sound, even if it is lengthy and contains redundant
    calculations and reasonings.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æœ¬å®éªŒçš„èƒŒæ™¯ä¸‹ï¼Œå¦‚æœå­¦ç”Ÿçš„æ¨ç†æ˜¯åˆç†çš„ï¼Œå³ä½¿å›ç­”å†—é•¿ä¸”åŒ…å«å¤šä½™çš„è®¡ç®—å’Œæ¨ç†ï¼Œäººå·¥è¯„å®¡å‘˜ä¹Ÿä¼šåˆ¤å®šå…¶ç­”æ¡ˆä¸ºæ­£ç¡®ã€‚
- en: Please note that this `human_grading`is against the Studentâ€™s answers.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™ä¸ª`human_grading`æ˜¯é’ˆå¯¹å­¦ç”Ÿçš„ç­”æ¡ˆè¿›è¡Œçš„ã€‚
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ğŸ‘‰ Conclusions
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ‘‰ ç»“è®º
- en: âœ… The evaluation of the LLM Judge by the Supreme LLM Judge gave us insights
    into the effectiveness of a multi-layered evaluation system for LLM applications.
    The Supreme LLM Judge achieved a **recall rate of 70%,** successfully identifying
    70% of the incorrect evaluations made by the LLM Judge. **This is not bad for
    the case of reference-free evaluation** and for the proof-of-concept implementation.
    **These captured incorrect evaluations will potentially help us derive solutions
    to continuously improve our LLM Judge.**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… ç”±æœ€é«˜çº§LLMè¯„å®¡å‘˜å¯¹LLMè¯„å®¡å‘˜çš„è¯„ä¼°ä¸ºæˆ‘ä»¬æä¾›äº†å…³äºå¤šå±‚æ¬¡è¯„ä¼°ç³»ç»Ÿåœ¨LLMåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§çš„è§è§£ã€‚æœ€é«˜çº§LLMè¯„å®¡å‘˜æˆåŠŸè¯†åˆ«äº†**70%çš„å¬å›ç‡ï¼Œ**
    æˆåŠŸæ•æ‰åˆ°LLMè¯„å®¡å‘˜åšå‡ºçš„70%çš„é”™è¯¯è¯„ä¼°ã€‚**å¯¹äºæ— å‚è€ƒè¯„ä¼°çš„æƒ…å†µ**ä»¥åŠæ¦‚å¿µéªŒè¯å®ç°æ¥è¯´ï¼Œè¿™ä¸ªç»“æœå¹¶ä¸å·®ã€‚**è¿™äº›æ•æ‰åˆ°çš„é”™è¯¯è¯„ä¼°å¯èƒ½ä¼šå¸®åŠ©æˆ‘ä»¬æ‰¾åˆ°è§£å†³æ–¹æ¡ˆï¼ŒæŒç»­æ”¹è¿›æˆ‘ä»¬çš„LLMè¯„å®¡å‘˜ã€‚**
- en: '![](../Images/05b3263d1a1efaad043d5346bf66a0b2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05b3263d1a1efaad043d5346bf66a0b2.png)'
- en: Continuous Improvement of the LLM Judge â€” Image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLMè¯„å®¡å‘˜çš„æŒç»­æ”¹è¿› â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: âœ… **The difficulties we encounter when using an LLM judge to evaluate an LLM
    application also apply to using a Supreme LLM Judge to judge an LLM Judge (tongue
    twister!).** Besides the quest to aim for high accuracy of the evaluations, ensuring
    consistent evaluation outputs is also a big challenge.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… **æˆ‘ä»¬åœ¨ä½¿ç”¨LLMè¯„å®¡å‘˜æ¥è¯„ä¼°LLMåº”ç”¨æ—¶é‡åˆ°çš„å›°éš¾ï¼ŒåŒæ ·é€‚ç”¨äºä½¿ç”¨æœ€é«˜çº§LLMè¯„å®¡å‘˜æ¥è¯„åˆ¤LLMè¯„å®¡å‘˜ï¼ˆç»•å£ä»¤ï¼ï¼‰**ã€‚é™¤äº†è¿½æ±‚é«˜å‡†ç¡®åº¦çš„è¯„ä¼°å¤–ï¼Œç¡®ä¿è¯„ä¼°ç»“æœçš„ä¸€è‡´æ€§ä¹Ÿæ˜¯ä¸€å¤§æŒ‘æˆ˜ã€‚
- en: âœ… Given that the second layer of evaluation requires human assessment with considerable
    effort, **this approach is more suitable for audits or periodic offline evaluations**
    rather than ongoing evaluations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… ç”±äºç¬¬äºŒå±‚è¯„ä¼°éœ€è¦è€—è´¹ç›¸å½“å¤šçš„äººå·¥è¯„ä¼°å·¥ä½œï¼Œ**è¿™ç§æ–¹æ³•æ›´é€‚åˆç”¨äºå®¡è®¡æˆ–å®šæœŸçš„ç¦»çº¿è¯„ä¼°**ï¼Œè€ŒéæŒç»­æ€§çš„è¯„ä¼°ã€‚
- en: âœ… **It is also worth noting that using a random sampling method for evaluation
    might be a good approach to save resources.** By strategically deploying a second
    layer of LLM evaluation with human reviewers, we can enhance the overall reliability
    and accuracy of the evaluation system, contributing to a high-performing LLM Application.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: âœ… **åŒæ ·å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨éšæœºæŠ½æ ·æ–¹æ³•è¿›è¡Œè¯„ä¼°å¯èƒ½æ˜¯èŠ‚çœèµ„æºçš„å¥½æ–¹æ³•ã€‚** é€šè¿‡æˆ˜ç•¥æ€§åœ°éƒ¨ç½²ç¬¬äºŒå±‚çš„å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°ï¼Œé…åˆäººå·¥è¯„å®¡ï¼Œæˆ‘ä»¬å¯ä»¥å¢å¼ºè¯„ä¼°ç³»ç»Ÿçš„æ•´ä½“å¯é æ€§å’Œå‡†ç¡®æ€§ï¼Œä»è€Œæœ‰åŠ©äºé«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨ã€‚
- en: About me
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³äºæˆ‘
- en: I am Daniel Le, based in Berlin. I currently work in the fields of Machine Learning
    and Data Engineering.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯Daniel Leï¼Œç°å±…æŸæ—ã€‚ç›®å‰æˆ‘ä»äº‹æœºå™¨å­¦ä¹ å’Œæ•°æ®å·¥ç¨‹é¢†åŸŸçš„å·¥ä½œã€‚
- en: I am interested in new technologies and how they can be implemented to solve
    real-world problems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯¹æ–°æŠ€æœ¯æ„Ÿå…´è¶£ï¼Œå¹¶ä¸”å…³æ³¨å®ƒä»¬å¦‚ä½•åº”ç”¨äºè§£å†³ç°å®ä¸–ç•Œä¸­çš„é—®é¢˜ã€‚
- en: Should you have any inquiries or wish to discuss these interests further, please
    do not hesitate to connect with me on [LinkedIn](https://www.linkedin.com/in/khoadaniel/).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å¸Œæœ›è¿›ä¸€æ­¥è®¨è®ºè¿™äº›å…´è¶£ï¼Œæ¬¢è¿é€šè¿‡[LinkedIn](https://www.linkedin.com/in/khoadaniel/)ä¸æˆ‘è”ç³»ã€‚
- en: Reference
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[https://docs.smith.langchain.com/old/evaluation](https://docs.smith.langchain.com/old/evaluation)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.smith.langchain.com/old/evaluation](https://docs.smith.langchain.com/old/evaluation)'
- en: '[https://huyenchip.com/2023/04/11/llm-engineering.html](https://huyenchip.com/2023/04/11/llm-engineering.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huyenchip.com/2023/04/11/llm-engineering.html](https://huyenchip.com/2023/04/11/llm-engineering.html)'
- en: '[https://github.com/khoadaniel/judge-an-llm-judge/tree/main](https://github.com/khoadaniel/judge-an-llm-judge/tree/main)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/khoadaniel/judge-an-llm-judge/tree/main](https://github.com/khoadaniel/judge-an-llm-judge/tree/main)'
