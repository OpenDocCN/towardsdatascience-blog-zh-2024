<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Build Prompt Engineering Expertise at Your Company</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Build Prompt Engineering Expertise at Your Company</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-prompt-engineering-expertise-at-your-company-cc21a67d4072?source=collection_archive---------6-----------------------#2024-12-02">https://towardsdatascience.com/how-to-build-prompt-engineering-expertise-at-your-company-cc21a67d4072?source=collection_archive---------6-----------------------#2024-12-02</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="gr gs gt gu gv ab"><div><div class="ab gw"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vmalyi?source=post_page---byline--cc21a67d4072--------------------------------" rel="noopener follow"><div class="l gx gy by gz ha"><div class="l ed"><img alt="Viktor Malyi" class="l ep by dd de cx" src="../Images/233243e6fd61725e5116c926f9616fa2.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*yMFCPgKKABZZb8ZXg-kvCw.jpeg"/><div class="hb by l dd de em n hc eo"/></div></div></a></div></div><div class="hd ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--cc21a67d4072--------------------------------" rel="noopener follow"><div class="l he hf by gz hg"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hh cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hb by l br hh em n hc eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hi ab q"><div class="ab q hj"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hk hl bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hm" data-testid="authorName" href="https://medium.com/@vmalyi?source=post_page---byline--cc21a67d4072--------------------------------" rel="noopener follow">Viktor Malyi</a></p></div></div></div><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hk hl dx"><button class="hp hq ah ai aj ak al am an ao ap aq ar hr hs ht" disabled="">Follow</button></p></div></div></span></div></div><div class="l hu"><span class="bf b bg z dx"><div class="ab cn hv hw hx"><div class="hy hz ab"><div class="bf b bg z dx ab ia"><span class="ib l hu">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hm ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--cc21a67d4072--------------------------------" rel="noopener follow"><p class="bf b bg z ic id ie if ig ih ii ij bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hn ho" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="ik il l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Dec 2, 2024</span></div></span></div></span></div></div></div><div class="ab cp im in io ip iq ir is it iu iv iw ix iy iz ja jb"><div class="h k w ea eb q"><div class="jr l"><div class="ab q js jt"><div class="pw-multi-vote-icon ed ib ju jv jw"><div class=""><div class="jx jy jz ka kb kc kd am ke kf kg jw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kh ki kj kk kl km kn"><p class="bf b dy z dx"><span class="jy">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao jx kq kr ab q ee ks kt" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="kp"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count ko kp">1</span></p></button></div></div></div><div class="ab q jc jd je jf jg jh ji jj jk jl jm jn jo jp jq"><div class="ku k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al kv an ao ap hr kw kx ky" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep kz cn"><div class="l ae"><div class="ab cb"><div class="la lb lc ld le lf ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al kv an ao ap hr lg lh kt li lj lk ll lm s ln lo lp lq lr ls lt u lu lv lw"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="lx bh"><figure class="ly lz ma mb mc lx bh paragraph-image"><img src="../Images/3044a510a7fd7923a96b5bbd5af04468.png" data-original-src="https://miro.medium.com/v2/resize:fit:3640/format:webp/1*yV5mf2m7716fU-mmvOE_bQ.png"/></figure></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="d99d" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">You decided to employ generative AI at your company and have already conducted initial experiments with it. And now comes the question: do I need a dedicated person (-s) to handle all the upcoming prompt work?</p><p id="4988" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">While the general interest around prompt engineering has remained steady over the last few years, a lot of companies struggle to make their first step in building prompt engineering competency because of simply not knowing where to start.</p><p id="3bf2" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">News like <a class="af nc" href="https://www.yahoo.com/news/ai-prompt-engineer-jobs-pay-201001072.html" rel="noopener ugc nofollow" target="_blank">high salaries for prompt engineering roles</a> don’t help as well, making the natural first reaction to just go to the free market and find prompt engineers too risky. This is because those companies are only at the very beginning of generative AI adoption phase and are not sure that such considerable investments into new hires with this new role are worthwhile at this stage.</p><figure class="ng nh ni nj nk lx nd ne paragraph-image"><div role="button" tabindex="0" class="nl nm ed nn bh no"><div class="nd ne nf"><img src="../Images/1332ff2648ed6ae6f7f79e7d937aa1bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aGrX5JTLMgLn9lLc"/></div></div><figcaption class="np nq nr nd ne ns nt bf b bg z dx">Source: <a class="af nc" href="https://www.businessinsider.com/ai-prompt-engineer-jobs-pay-salary-requirements-no-tech-background-2023-3" rel="noopener ugc nofollow" target="_blank">https://www.businessinsider.com/ai-prompt-engineer-jobs-pay-salary-requirements-no-tech-background-2023-3</a></figcaption></figure><p id="e36a" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Moreover, considering the rapid progress generative AI has made in 2023–2024, many in leadership ask themselves a very valid question: are prompt engineers here to stay long term and will there be a need for writing prompts in a future or just a couple of words thrown to LLM generally describing the problem to solve will suffice?</p><p id="284e" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">While any company is free to choose their own way to fulfill their needs for people who can do prompt engineering, in this post I’m going to focus on raising this expertise inside the company. This way is probably not that streamlined as just hiring someone with existing experience in prompt engineering, but offers some positive side-effects — but more on that later.</p><h1 id="bc85" class="nu nv fq bf nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or bk">Should a prompt engineer be deeply technical?</h1><p id="8d75" class="pw-post-body-paragraph me mf fq mg b mh os mj mk ml ot mn mo mp ou mr ms mt ov mv mw mx ow mz na nb fj bk">Definitely not. The current state of prompt engineering offers <a class="af nc" href="https://www.promptingguide.ai/techniques" rel="noopener ugc nofollow" target="_blank">around 20 advanced techniques</a> and some of them might be efficient for achieving the specific goals of your generative AI-projects, but none strongly requires deep knowledge of, for example, a programming language or the ability to build complex prompt interactions by prompt engineers alone.</p><p id="a2c9" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">A prompt engineer usually starts by defining the problem that an LLM needs to solve. By experimenting with prompt content, how to structure it and maybe how to chain multiple prompts, a person doing prompt engineering is expected to get an LLM output of desired quality.</p><p id="9609" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">All of the above can be done “on paper” and without a need of writing even a single line of code. The paper in this case are playgrounds each LLM vendor have in their offering. And if one needs to make multiple prompts work together, the output of the previous prompt can just be injected into the next prompt by hand.</p><h1 id="1c9e" class="nu nv fq bf nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or bk">What kind of person would shine as a prompt engineer</h1><p id="99e6" class="pw-post-body-paragraph me mf fq mg b mh os mj mk ml ot mn mo mp ou mr ms mt ov mv mw mx ow mz na nb fj bk">We are currently in the unique position where the shape of this role is not final and is being constantly adjusted by the industry needs: literally every half of a year the progress in tooling and prompting techniques in AI requires people working on prompts to expand their skills.</p><p id="a31e" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">But there are two of them which are by-default critical: <em class="ox">curiosity</em> and <em class="ox">creativity</em>.</p><p id="0477" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">A person genuinely curious about the field they are operating within will be the one delivering the best results regardless of what field it is. Constantly staying up-to-date with the latest developments in prompt techniques, unique capabilities of large language models (and the vast variety of both commercial and open-source ones on the market) will allow them to not simply throw “a GPT” on every problem they solve, but instantly recognize that e.g. non-complex tasks can be solved by less capable but cheaper and faster models.</p><p id="22b8" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Another crucial skill is to be creative when doing prompt engineering. While there are already some prompt engineering approaches guaranteeing solid results, we are far from understanding what prompts or techniques would deliver the best output. By just keeping writing their plain and straightforward prompts the people would have never discovered <a class="af nc" href="https://arxiv.org/pdf/2312.16171v1" rel="noopener ugc nofollow" target="_blank">methods</a> which statistically improve model output performance like “I’m going to tip $xxx for a better solution!” and other crazy and unexpected ideas. LLMs are a tool which has never been at our disposal before and at the current stage of their development, staying creative about how to employ them and what instructions to give will result in the best results — so make sure the person you are foreseeing for this role is capable of thinking originally.</p><p id="8d51" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">At some point in time, prompt engineers will make changes to the prompts already deployed to production and preventing regressions in LLM output quality will be their absolute priority. Of course there are tools and approaches helping to reduce this risk, but nothing will substitute an attentive person comparing the output of the model before and after the change by just carefully reading through it and spotting negative patterns.</p><p id="f1bb" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">If a person you are envisioning to be your future prompt engineer has the three above qualities, don’t worry about them e.g. not knowing (yet) the fundamentals of how LLMs work — the curiosity will lead them to learn it naturally and creativity will gift them new tricks and approaches the person will come up with when solving a not obvious problem. An eye for detail will help in the long term and prevent unexpected declines in output quality.</p><p id="ed33" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk"><a class="af nc" href="https://www.youtube.com/watch?v=T9aRN5JkmL8&amp;t=394s" rel="noopener ugc nofollow" target="_blank">Here</a> is another take about other qualities a good prompt engineer should have.</p><h1 id="1a97" class="nu nv fq bf nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or bk">Where to find people working on prompts</h1><p id="dff9" class="pw-post-body-paragraph me mf fq mg b mh os mj mk ml ot mn mo mp ou mr ms mt ov mv mw mx ow mz na nb fj bk">While hiring someone from the outside always remains an option, such a person won’t be having an immediate knowledge about the <em class="ox">output </em>you want to get from LLMs. Because of the non-deterministic nature of LLMs, their output can have a multitude of forms and styles and this is a work of a prompt engineer to make that outcome more predictable.</p><p id="d3a6" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Who would best know the kind of output your LLM assistant should produce? (e.g. how deep must be its answers and what tone of voice should be used?).</p><p id="7393" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Right. These are internal people who are already employed in your organization and deeply involved in working on your product. Take a closer look: maybe some of them are already excited about capabilities of generative AI and want to try out a new role?</p><p id="518a" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">These folks would be ideal candidates to become prompt engineers: their domain and product knowledge is deep enough to <em class="ox">know </em>what level of complexity and accuracy the model output should be. Often they also have useful internal connections to other departments which deeply technical people do not necessarily have. For example a person originating from the customer success department and who became a prompt engineer will have much easier time knowing how the final output of an LLM-based product they’re contributing to should look like VS yesterday’s software engineer who worked inside the technical department previously and most likely was all the time focused on deeper technical work inside of a single product area.</p><h1 id="ec7b" class="nu nv fq bf nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or bk">How to grow your prompt engineers</h1><p id="3c26" class="pw-post-body-paragraph me mf fq mg b mh os mj mk ml ot mn mo mp ou mr ms mt ov mv mw mx ow mz na nb fj bk">With time, you will face the need to grow the people authoring the prompts in your organization. The growth for such specialists doesn’t only mean to be able to quickly find an optimal prompting technique to the given problem (this comes with experience), but rather expanding the horizons of what’s possible for them beyond just defining what the system prompt of an LLM-based application will be.</p><p id="c153" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Besides staying on top of the LLM research and latest advancements in prompt engineering techniques, more advanced prompt engineers need to tackle LLM evaluators — these are tools giving feedback about the performance of the model/prompt (similar to unit tests in software engineering).</p><p id="a753" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Generally, evaluators can be both LLM-based (e.g. model B evaluates the output of the model A) or code-based (e.g. Python functions checking if model output adheres to the expected JSON-schema). Though code-based evaluators don’t require proficient programming skills, the person implementing them must have a high-level understanding about the programming language they are using (mostly Python) — so boosting this skill could be a one direction of growth for prompt engineers.</p><p id="f2d1" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Just imagine: someone has delivered a prompt which not only “works” but also has instructions inside of it covered with tests/evaluators ensuring the safety net similar to unit tests providing in a traditional software development.</p><p id="cb2d" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Prompt engineering is also not only about prompting techniques, output quality and evaluators. On a more proficient level, the people occupied with prompts must deeper understand the effect LLM hyperparameters are having on the output. This means another potential direction of growth for such people — learning machine learning fundamentals and investing in knowledge about how LLMs works under the hood.</p><p id="e85a" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Ideally, your organization already includes a leader who has experience somewhere on the intersection of software development and classical machine learning (or generative AI). Such a person could guide the growth of prompt engineers more precisely by steering their development into areas above.</p><h1 id="7baf" class="nu nv fq bf nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or bk">Building the prompt engineering expertise</h1><p id="68b4" class="pw-post-body-paragraph me mf fq mg b mh os mj mk ml ot mn mo mp ou mr ms mt ov mv mw mx ow mz na nb fj bk">There is no one and all approach to building the expertise of prompt engineering because each organization has its own requirements about the LLM applications those prompts are used in. Building <em class="ox">the</em> <em class="ox">expertise </em>can have a vastly different meaning in different organizations.</p><p id="1b8f" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">But the one thing always remains true: your prompt engineers must be deeply engaged into both product aspects of something they work on and also possess specific knowledge to their unique role: the first allows them to quicker achieve desired model output quality and the latter makes sure those results are sustainable and adhere to current best practices in the very rapidly developing world of generative AI.</p><p id="bbc5" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Give your prompt engineers the freedom to explore novel approaches while holding them accountable for the results they are delivering: despite the non-deterministic nature of LLM output, we could and should reduce the risk of unexpected output quality deviations and there are tools for making those measures quantifiable.</p><p id="9a98" class="pw-post-body-paragraph me mf fq mg b mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb fj bk">Building prompt engineering expertise within your organization is not just about adapting to the current trends in AI — it’s about shaping the future of how your company leverages technology for innovation. By empowering your team to master prompt engineering, you foster a culture of creativity, efficiency, and forward-thinking.</p></div></div></div></div>    
</body>
</html>