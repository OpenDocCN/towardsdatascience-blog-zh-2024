- en: Massive Energy for Massive GPUs Empowering AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 巨大的能源需求驱动着巨大的GPU赋能AI
- en: 原文：[https://towardsdatascience.com/massive-energy-for-massive-gpu-empowering-ai-dff59ae1da44?source=collection_archive---------2-----------------------#2024-08-18](https://towardsdatascience.com/massive-energy-for-massive-gpu-empowering-ai-dff59ae1da44?source=collection_archive---------2-----------------------#2024-08-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/massive-energy-for-massive-gpu-empowering-ai-dff59ae1da44?source=collection_archive---------2-----------------------#2024-08-18](https://towardsdatascience.com/massive-energy-for-massive-gpu-empowering-ai-dff59ae1da44?source=collection_archive---------2-----------------------#2024-08-18)
- en: Massive GPUs for AI model training and deployment require significant energy.
    As AI scales, optimizing energy efficiency will be crucial
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于人工智能模型训练和部署的巨型GPU需要大量能源。随着人工智能的规模扩大，优化能源效率将变得至关重要
- en: '[](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)[![Geo
    Zhang](../Images/3e99845b96ea9dd983d8f3a262c5e20b.png)](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)
    [Geo Zhang](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)[![Geo
    Zhang](../Images/3e99845b96ea9dd983d8f3a262c5e20b.png)](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)
    [Geo Zhang](https://geozhang.medium.com/?source=post_page---byline--dff59ae1da44--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)
    ·7 min read·Aug 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dff59ae1da44--------------------------------)
    ·阅读时间：7分钟·2024年8月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/25023649740c71af576e9bcf20c03fd8.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25023649740c71af576e9bcf20c03fd8.png)'
- en: Photo by [Lucas Kepner](https://unsplash.com/@lucaskphoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Lucas Kepner](https://unsplash.com/@lucaskphoto?utm_source=medium&utm_medium=referral)
    于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: OpenAI founder Sam Altman has made ambitious calculations, suggesting a potential
    investment scale of $7 trillion in GPUs for an AI future. This number, rejected
    by industry leaders like Nvidia’s founder Jensen Huang, implies a monumental acquisition
    of GPUs, requiring enormous energy, almost on a galactic scale. To put this in
    perspective, Nvidia’s current market worth is around $3 trillion, below half of
    Altman’s proposed investment. When compared to the GDPs of the United States (approximately
    $26.8 trillion) and China (around $17.8 trillion), this $7 trillion investment
    is still indeed staggering.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI创始人Sam Altman做出了雄心勃勃的计算，提出人工智能未来可能需要投入7万亿美元用于GPU。这个数字被行业领袖，如Nvidia创始人黄仁勋所拒绝，暗示着对GPU的大规模收购，这需要巨大的能源，几乎是银河级别的。为了给这个数字做个对比，Nvidia目前的市值约为3万亿美元，不到Altman提议投资的一半。与美国（约26.8万亿美元）和中国（约17.8万亿美元）的GDP相比，这7万亿美元的投资确实令人震惊。
- en: 'Despite this, the AI era is still in its infancy, and achieving such a scale
    might necessitate even more advanced computational structures. This brings us
    to a critical underlying question: how much energy will be needed to power computational
    units and data centers?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，人工智能时代仍处于初期阶段，达到如此规模可能需要更加先进的计算结构。这引出了一个关键的基础问题：为计算单元和数据中心提供能源需要多少？
- en: Let's take a look at some simple and direct numbers from three perspectives,
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从三个角度来看一些简单直接的数据，
- en: 1\. Energy consumption per computational unit
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1\. 每个计算单元的能源消耗
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 2\. Energy costs of training/operating modern models
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. 训练/操作现代模型的能源成本
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3\. Energy supply and demand
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3\. 能源供需
- en: Energy consumption per computational unit
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个计算单元的能源消耗
- en: From a user perspective, some video game enthusiasts have built their own PCs
    equipped with high-performance GPUs like the NVIDIA GeForce RTX 4090\. Interestingly,
    this GPU is also capable of handling small-scale deep-learning tasks. The RTX
    4090 requires a power supply of 450 W, with a recommended total power supply of
    850 W (in most cases you don’t need that and will not run under full load). If
    your task runs continuously for a week, that translates to 0.85 kW × 24 hours
    × 7 days = 142.8 kWh per week. In California, PG&E charges as high as 50 cents
    per kWh for residential customers, meaning you would spend around $70 per week
    on electricity. Additionally, you’ll need a CPU and other components to work alongside
    your GPU, which will further increase the electricity consumption. This means
    the overall electricity cost can be even higher.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，一些视频游戏爱好者已经自建了配备高性能GPU（如NVIDIA GeForce RTX 4090）的个人电脑。有趣的是，这款GPU也能够处理小规模的深度学习任务。RTX
    4090的功率需求为450瓦特，推荐的总电源功率为850瓦特（在大多数情况下您并不需要这么高的功率，也不会在满载下运行）。如果您的任务连续运行一周，这意味着0.85千瓦
    × 24小时 × 7天 = 142.8千瓦时每周。在加利福尼亚，PG&E对住宅用户的电价高达每千瓦时50美分，这意味着您每周大约会花费70美元的电费。此外，您还需要配备CPU和其他组件来与GPU协同工作，这将进一步增加电力消耗。这意味着整体的电费可能会更高。
- en: Now, your AI business is going to accelerate. According to the manufacturer,
    an H100 Tensor Core GPU has a maximum thermal design power (TDP) of around 700
    Watts, depending on the specific version. This is the energy required to cool
    the GPU under a full working load. A reliable power supply unit for this high-performance
    deep-learning tool is typically around 1600W. If you use the NVIDIA DGX platform
    for your deep-learning tasks, a single DGX H100 system, equipped with 8 H100 GPUs,
    consumes approximately 10.2 kW. For even greater performance, an NVIDIA DGX SuperPOD
    can include anywhere from 24 to 128 NVIDIA DGX nodes. With 64 nodes, the system
    could conservatively consume about 652.8 kW. While your startup might aspire to
    purchase this millions-dollar equipment, the costs for both the cluster and the
    necessary facilities would be substantial. In most cases, it makes more sense
    to rent GPU clusters from cloud computation providers. Focusing on energy costs,
    commercial and industrial users typically benefit from lower electricity rates.
    If your average cost is around 20 cents per kWh, operating 64 DGX nodes at 652.8
    kW for 24 hours a day, 7 days a week would result in 109.7 MWh per week. This
    could cost you approximately $21,934 per week.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您的人工智能业务将加速发展。根据制造商的说法，H100 Tensor Core GPU的最大热设计功耗（TDP）大约为700瓦特，具体取决于版本。这是为在全负载工作状态下冷却GPU所需的能量。对于这个高性能深度学习工具，通常需要一个大约1600W的可靠电源供应单元。如果您使用NVIDIA
    DGX平台进行深度学习任务，一台配备8个H100 GPU的DGX H100系统大约消耗10.2千瓦特。为了获得更大的性能，NVIDIA DGX SuperPOD可以包括从24到128个NVIDIA
    DGX节点。以64个节点为例，系统的功耗保守估计约为652.8千瓦特。如果您的初创公司计划购买这种数百万美元的设备，那么集群和必要设施的成本将是相当可观的。在大多数情况下，从云计算提供商租用GPU集群更为合理。关注能源成本时，商业和工业用户通常能享受较低的电价。如果您的平均电费大约是每千瓦时20美分，那么在24小时、每周7天全天候运行64个DGX节点，消耗652.8千瓦特，将会产生每周109.7
    MWh的电力消耗，预计每周的电费大约为21,934美元。
- en: According to rough estimations, a typical family in California would spend around
    150 kWh per week on electricity. Interestingly, this is roughly the same cost
    you’d incur if you were to run a model training task at home using a high-performance
    GPU like the RTX 4090.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 根据粗略估算，典型的加利福尼亚家庭每周大约消耗150千瓦时的电力。有趣的是，如果您在家中使用高性能GPU（如RTX 4090）进行模型训练任务，所产生的电力成本大致相同。
- en: '![](../Images/2aa0299aa5d64c76638a28a9f24385da.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2aa0299aa5d64c76638a28a9f24385da.png)'
- en: '**Energy Cost Comparison**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**能源成本比较**'
- en: From this table, we may observe that operating a SuperPOD with 64 nodes could
    consume as much energy in a week as a small community.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从此表格中，我们可以看到，运行64个节点的SuperPOD在一周内的能耗相当于一个小型社区的电力消耗。
- en: Energy costs of training/operating AI models
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练/运行AI模型的能源成本
- en: Training AI models
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练AI模型
- en: Now, let’s dive into some numbers related to modern AI models. OpenAI has never
    disclosed the exact number of GPUs used to train ChatGPT, but a rough estimate
    suggests it could involve thousands of GPUs running continuously for several weeks
    to months, depending on the release date of each ChatGPT model. The energy consumption
    for such a task would easily be on the megawatt scale, leading to costs in the
    thousands scale of MWh.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解一些与现代AI模型相关的数字。OpenAI从未披露过训练ChatGPT所使用的GPU的具体数量，但粗略估计，这可能涉及成千上万个GPU连续运行数周到数月，具体取决于每个ChatGPT模型的发布日期。这样的任务的能源消耗轻松达到兆瓦级别，导致能源消耗的成本在数千MWh的规模。
- en: Recently, [Meta released LLaMA 3.1](https://llama.meta.com/), described as their
    “most capable model to date.” According to Meta, this is their largest model yet,
    trained on over 16,000 H100 GPUs — the first LLaMA model trained at this scale.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，[Meta发布了LLaMA 3.1](https://llama.meta.com/)，并称其为“迄今为止最强大的模型”。根据Meta的说法，这是他们最大的一款模型，训练使用了超过16,000个H100
    GPU——这是首个在此规模下训练的LLaMA模型。
- en: 'Let’s break down the numbers: LLaMA 2 was released in July 2023, so it’s reasonable
    to assume that LLaMA 3 took at least a year to train. While it’s unlikely that
    all GPUs were running 24/7, we can estimate energy consumption with a 50% utilization
    rate:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来拆解这些数字：LLaMA 2于2023年7月发布，因此可以合理推测，LLaMA 3至少训练了一年。虽然不太可能所有GPU都在全天候24小时运行，但我们可以估算出以50%的利用率的能源消耗：
- en: 1.6 kW × 16,000 GPUs × 24 hours/day × 365 days/year × 50% ≈ 112,128 MWh
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 1.6 kW × 16,000个GPU × 24小时/天 × 365天/年 × 50% ≈ 112,128 MWh
- en: At an estimated cost of $0.20 per kWh, this translates to around **$22.4 million**
    in energy costs. This figure only accounts for the GPUs, excluding additional
    energy consumption related to data storage, networking, and other infrastructure.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以每千瓦时$0.20的估算成本，这大约意味着**2240万美元**的能源费用。这个数字仅包括GPU的费用，未包括与数据存储、网络和其他基础设施相关的额外能源消耗。
- en: Training modern large language models (LLMs) requires power consumption on a
    megawatt scale and represents a million-dollar investment. This is why modern
    AI development often excludes smaller players.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 训练现代大型语言模型（LLMs）需要兆瓦级别的电力消耗，并代表着百万美元的投资。这也是为什么现代AI开发往往排除了较小的参与者。
- en: Operating AI models
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行AI模型
- en: Running AI models also incurs significant energy costs, as each inquiry and
    response requires computational power. Although the energy cost per interaction
    is small compared to training the model, the cumulative impact can be substantial,
    especially if your AI business achieves large-scale success with billions of users
    interacting with your advanced LLM daily. Many insightful articles discuss this
    issue, including [comparisons of energy costs among companies operating ChatBots](https://www.trgdatacenters.com/resource/ai-chatbots-energy-usage-of-2023s-most-popular-chatbots-so-far/#:~:text=The%20training%20time%20of%20GPT,%2Dhours%2C%20or%207%2C200%20MWh.).
    The conclusion is that, since each query could cost from 0.002 to 0.004 kWh, currently,
    popular companies would spend hundreds to thousands of MWh per year. And this
    number is still increasing.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 运行AI模型也会带来显著的能源成本，因为每一次查询和回应都需要计算能力。尽管每次交互的能源成本相较于训练模型而言较小，但累积的影响可能是巨大的，特别是当你的AI业务在有数十亿用户每天与先进的语言模型互动的情况下，规模化成功。许多富有洞察力的文章讨论了这个问题，包括[公司之间运营ChatBot的能源成本比较](https://www.trgdatacenters.com/resource/ai-chatbots-energy-usage-of-2023s-most-popular-chatbots-so-far/#:~:text=The%20training%20time%20of%20GPT,%2Dhours%2C%20or%207%2C200%20MWh.)。结论是，由于每次查询的能源消耗可能在0.002至0.004千瓦时之间，目前流行的公司每年将消耗数百到数千MWh的电力。而且这个数字仍在增长。
- en: '![](../Images/b8447ba9f7ff22174d0d95b72dc2146d.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8447ba9f7ff22174d0d95b72dc2146d.png)'
- en: Photo by [Solen Feyissa](https://unsplash.com/@solenfeyissa?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Solen Feyissa](https://unsplash.com/@solenfeyissa?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Imagine for a moment that one billion people use a ChatBot frequently, averaging
    around 100 queries per day. The energy cost for this usage can be estimated as
    follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果有10亿人经常使用一个ChatBot，每人每天平均进行100次查询。可以按如下方式估算这类使用的能源成本：
- en: 0.002 kWh × 100 queries/day × 1e9 people × 365 days/year ≈ 7.3e7 MWh/year
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 0.002 kWh × 100次查询/天 × 1e9人 × 365天/年 ≈ 7.3e7 MWh/年
- en: This would require an 8000 MW power supply and could result in an energy cost
    of approximately $14.6 billion annually, assuming an electricity rate of $0.20
    per kWh.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要一个8000 MW的电力供应，并可能导致每年大约146亿美元的能源费用，假设电价为每千瓦时$0.20。
- en: Energy supply and demand
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 能源供应与需求
- en: '![](../Images/ee6947891845fb3dbe0e722555c2e2f2.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee6947891845fb3dbe0e722555c2e2f2.png)'
- en: Photo by [Matthew Henry](https://unsplash.com/@matthewhenry?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：来自[Matthew Henry](https://unsplash.com/@matthewhenry?utm_source=medium&utm_medium=referral)的照片，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The largest power plant in the U.S. is the [Grand Coulee Dam](https://en.wikipedia.org/wiki/Grand_Coulee_Dam)
    in Washington State, with a capacity of 6,809 MW. The largest solar farm in the
    U.S. is [Solar Star](https://en.wikipedia.org/wiki/Solar_Star) in California,
    which has a capacity of 579 MW. In this context, no single power plant is capable
    of supplying all the electricity required for a large-scale AI service. This becomes
    evident when considering the annual electricity generation statistics provided
    by [EIA (Energy Information Administration)](https://www.eia.gov/todayinenergy/detail.php?id=46676),
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 美国最大的发电厂是位于华盛顿州的[大库利水坝](https://en.wikipedia.org/wiki/Grand_Coulee_Dam)，其容量为6809兆瓦。美国最大的太阳能电站是位于加利福尼亚的[太阳星](https://en.wikipedia.org/wiki/Solar_Star)，容量为579兆瓦。在这种背景下，单一的发电厂无法提供大型人工智能服务所需的全部电力。考虑到[EIA（能源信息管理局）](https://www.eia.gov/todayinenergy/detail.php?id=46676)提供的年度电力生产统计数据，这一点变得尤为明显，
- en: '![](../Images/b0ac3c75e9a926ead922713ecbf04df7.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0ac3c75e9a926ead922713ecbf04df7.png)'
- en: '**Source:** U.S. Energy Information Administration, [*Annual Energy Outlook
    2021*](https://www.eia.gov/outlooks/aeo/) (AEO2021)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源：** 美国能源信息管理局，[*2021年年度能源展望*](https://www.eia.gov/outlooks/aeo/)（AEO2021）'
- en: The 73 billion kWh calculated above would account for approximately 1.8% of
    the total electricity generated annually in the US. However, it’s reasonable to
    believe that this figure could be much higher. According to some media reports,
    when considering all energy consumption related to AI and data processing, the
    impact could be around 4% of the total U.S. electricity generation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 上述计算的730亿千瓦时大约占美国每年总电力生产的1.8%。然而，合理的猜测是这个数字可能远高于此。根据一些媒体报道，当考虑到所有与人工智能和数据处理相关的能源消耗时，影响可能接近美国总电力生产的4%。
- en: However, this is the current energy usage.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这只是目前的能源使用情况。
- en: Today, Chatbots primarily generate text-based responses, but they are increasingly
    capable of producing two-dimensional images, “three-dimensional” videos, and other
    forms of media. The next generation of AI will extend far beyond simple Chatbots,
    which may provide high-resolution images for spherical screens (e.g. for [Las
    Vegas Sphere](https://gotickets.com/venues/msg-sphere)), 3D modeling, and interactive
    robots capable of performing complex tasks and executing deep logistical. As a
    result, the energy demands for both model training and deployment are expected
    to increase dramatically, far exceeding current levels. Whether our existing power
    infrastructure can support such advancements remains an open question.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，聊天机器人主要生成基于文本的响应，但它们越来越能够生成二维图像、“三维”视频和其他形式的媒体。下一代人工智能将远远超出简单的聊天机器人，可能会为球形屏幕（例如[拉斯维加斯球体](https://gotickets.com/venues/msg-sphere)）提供高分辨率图像、三维建模，并能执行复杂任务和深度物流的互动机器人。因此，模型训练和部署的能源需求预计将大幅增加，远超当前水平。我们现有的电力基础设施是否能够支持这些进步仍然是一个悬而未决的问题。
- en: On the sustainability front, the carbon emissions from industries with high
    energy demands are significant. One approach to mitigating this impact involves
    using renewable energy sources to power energy-intensive facilities, such as data
    centers and computational hubs. A notable example is the collaboration between
    [Fervo Energy and Google](https://blog.google/outreach-initiatives/sustainability/google-fervo-geothermal-energy-partnership/),
    where geothermal power is being used to supply energy to a data center. However,
    the scale of these initiatives remains relatively small compared to the overall
    energy needs anticipated in the upcoming AI era. There is still much work to be
    done to address the challenges of sustainability in this context.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在可持续性方面，能源需求较高的行业碳排放量显著。减缓这一影响的一种方法是使用可再生能源为高能耗设施（如数据中心和计算中心）提供电力。一个显著的例子是[Fervo
    Energy和谷歌](https://blog.google/outreach-initiatives/sustainability/google-fervo-geothermal-energy-partnership/)之间的合作，利用地热能为数据中心提供能源。然而，与即将到来的人工智能时代的整体能源需求相比，这些举措的规模仍然相对较小。要解决这一背景下的可持续性挑战，仍然需要做很多工作。
- en: '![](../Images/0626d1f593da360739755a8155a627f3.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0626d1f593da360739755a8155a627f3.png)'
- en: Photo by [Ben White](https://unsplash.com/@benwhitephotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Ben White](https://unsplash.com/@benwhitephotography?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*Please correct any numbers if you find them unreasonable.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你发现任何数字不合理，请进行修正。*'
