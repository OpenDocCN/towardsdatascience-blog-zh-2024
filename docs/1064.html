<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The Stream Processing Model Behind Google Cloud Dataflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The Stream Processing Model Behind Google Cloud Dataflow</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-stream-processing-model-behind-google-cloud-dataflow-0d927c9506a0?source=collection_archive---------3-----------------------#2024-04-27">https://towardsdatascience.com/the-stream-processing-model-behind-google-cloud-dataflow-0d927c9506a0?source=collection_archive---------3-----------------------#2024-04-27</a></blockquote><div><div class="em ff fg fh fi fj"/><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><div/><div><h2 id="91db" class="pw-subtitle-paragraph go fq fr bf b gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd cq dx">Balancing correctness, latency, and cost in unbounded data processing</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vutrinh274?source=post_page---byline--0d927c9506a0--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Vu Trinh" class="l ep by dd de cx" src="../Images/b62e4a2605fcacf679a72787daa2b821.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Pn2C-qSJVHq3nURZKDmOzA.jpeg"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--0d927c9506a0--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@vutrinh274?source=post_page---byline--0d927c9506a0--------------------------------" rel="noopener follow">Vu Trinh</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--0d927c9506a0--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">14 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 27, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk lb lc ab q ee ld le" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lf"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap ie li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap ie ls lt le lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div></div></div><div class="mj bh"><figure class="mk ml mm mn mo mj bh paragraph-image"><img src="../Images/7d2d4818f0ca3e0538f82f7b4d3ded71.png" data-original-src="https://miro.medium.com/v2/resize:fit:2798/format:webp/0*my1u-3-QpTMOTfhG.png"/><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><blockquote class="nf"><p id="a1d7" class="ng nh fr bf ni nj nk nl nm nn no np dx"><em class="nq">This was originally published at </em><a class="af nr" href="https://open.substack.com/pub/vutr?utm_source=share&amp;utm_medium=android&amp;r=171vwv" rel="noopener ugc nofollow" target="_blank"><em class="nq">https://vutr.substack.com</em></a><em class="nq">.</em></p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="02ca" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Table of contents</h1><ul class=""><li id="6d9a" class="oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np pj pk pl bk"><em class="pm">Before we move on</em></li><li id="79df" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Introduction from the paper.</em></li><li id="2b8c" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">The details of the Dataflow model.</em></li><li id="28cd" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Implementation and designs of the model.</em></li></ul></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="b636" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Intro</h1><p id="8ec8" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk"><a class="af nr" href="https://cloud.google.com/dataflow?hl=en" rel="noopener ugc nofollow" target="_blank">Google Dataflow</a> is a fully managed data processing service that provides serverless unified stream and batch data processing. It is the first choice Google would recommend when dealing with a stream processing workload. The service promises to ensure correctness and latency regardless of how big your workload is. To achieve these characteristics, Google Dataflow is backed by a dedicated processing model, Dataflow, resulting from many years of Google research and development. This blog post is my note after reading the paper: <a class="af nr" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43864.pdf" rel="noopener ugc nofollow" target="_blank">The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing</a>. If you want to learn more about stream processing, I strongly recommend this paper. It contains all the lessons and insights from Google’s introduction of the Dataflow model to deal with its global-scale stream processing demand. Despite being written in 2015, I believe this paper’s contribution will never be old.</p><blockquote class="ps pt pu"><p id="2404" class="oo op pm oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk"><strong class="oq fs">Note</strong>: The paper was published in 2015, so some details may be changed or updated now; if you have any feedback or information that can supplement my blog, feel free to comment.</p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="09c9" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Before we move on</h1><blockquote class="ps pt pu"><p id="a7b4" class="oo op pm oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">To avoid more confusing</p></blockquote><ul class=""><li id="2348" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">Dataflow</strong> is the Google stream processing model.</li><li id="9a92" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><a class="af nr" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="oq fs">Apache Beam</strong></a> lets users define processing logic based on the Dataflow model.</li><li id="67d8" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Google Cloud Dataflow</strong> is a unified processing service from Google Cloud; you can think it’s the destination execution engine for the Apache Beam pipeline.</li></ul><p id="174c" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk"><strong class="oq fs">Workflow</strong>: You define the unified processing logic using Apache Beam and decide to run the pipeline on the execution engine you want, such as Google Dataflow, <a class="af nr" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Spark</a>, <a class="af nr" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank">Flink</a>, etc.</p></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><blockquote class="nf"><p id="20be" class="ng nh fr bf ni nj nk nl nm nn no np dx">Before we explore the Dataflow model in depth, the following sections will introduce some information, such as context, challenges, and concepts.</p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="9057" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Paper’s Introduction</h1><p id="4b4e" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">At the time of the paper writing, data processing frameworks like <a class="af nr" href="https://en.wikipedia.org/wiki/MapReduce" rel="noopener ugc nofollow" target="_blank">MapReduce</a> and its “cousins “ like <a class="af nr" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank">Hadoop</a>, <a class="af nr" href="https://pig.apache.org/" rel="noopener ugc nofollow" target="_blank">Pig</a>, <a class="af nr" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank">Hive</a>, or <a class="af nr" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Spark</a> allow the data consumer to process batch data at scale. On the stream processing side, tools like <a class="af nr" href="https://research.google/pubs/millwheel-fault-tolerant-stream-processing-at-internet-scale/" rel="noopener ugc nofollow" target="_blank">MillWheel</a>, <a class="af nr" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">Spark Streaming</a>, or <a class="af nr" href="https://storm.apache.org/" rel="noopener ugc nofollow" target="_blank">Storm</a> came to support the user. Still, these existing models did not satisfy the requirement in some common use cases.</p><p id="de55" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">Consider an example: A streaming video provider’s business revenue comes from billing advertisers for the amount of advertising watched on their content. They want to know how much to bill each advertiser daily and aggregate statistics about the videos and ads. Moreover, they want to run offline experiments over large amounts of historical data. They want to know how often and for how long their videos are being watched, with which content/ads, and by which demographic groups. All the information must be available quickly to adjust their business in near real-time. The processing system must also be simple and flexible to adapt to the business’s complexity. They also require a system that can handle global-scale data since the Internet allows companies to reach more customers than ever. Here are some observations from people at Google about the state of the data processing systems of that time:</p><ul class=""><li id="6f8d" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><em class="pm">Batch systems such as </em><a class="af nr" href="https://en.wikipedia.org/wiki/MapReduce" rel="noopener ugc nofollow" target="_blank"><em class="pm">MapReduce</em></a><em class="pm">, </em><a class="af nr" href="https://research.google/pubs/flumejava-easy-efficient-data-parallel-pipelines/" rel="noopener ugc nofollow" target="_blank"><em class="pm">FlumeJava</em></a><em class="pm"> (internal Google technology), and Spark fail to ensure the latency SLA since they require waiting for all data input to fit into a batch before processing it.</em></li><li id="5b2a" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Streaming processing systems that provide scalability and fault tolerance fall short of the expressiveness or correctness aspect.</em></li><li id="2a16" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Many cannot provide exactly once semantics, impacting correctness.</em></li><li id="669c" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Others lack the primitives necessary for windowing or provide windowing semantics that are limited to tuple- or processing-time-based windows (e.g., </em><a class="af nr" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"><em class="pm">Spark Streaming</em></a><em class="pm">)</em></li><li id="e70f" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Most that provide event-time-based windowing rely on ordering or have limited window triggering.</em></li><li id="769b" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">MillWheel and Spark Streaming are sufficiently scalable, fault-tolerant, and low-latency but lack high-level programming models.</em></li></ul><p id="a864" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">They conclude the major weakness of all the models and systems mentioned above is the assumption that the unbounded input data will eventually be complete. This approach does not make sense anymore when faced with the realities of today’s enormous, highly disordered data. They also believe that any approach to solving diverse real-time workloads must provide simple but powerful interfaces for balancing the correctness, latency, and cost based on specific use cases. From that perspective, the paper has the following conceptual contribution to the unified stream processing model:</p><ul class=""><li id="927d" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk">Allowing for calculating event-time ordered (when the event happened) results over an unbounded, unordered data source with configurable combinations of correctness, latency, and cost attributes.</li><li id="b674" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk">Separating pipeline implementation across four related dimensions:</li></ul><blockquote class="ps pt pu"><p id="8ee6" class="oo op pm oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">- What results are being computed?<br/>- Where in event time they are being computed.<br/>- When they are materialized during processing time,<br/>- How do earlier results relate to later refinements?</p></blockquote><ul class=""><li id="af7b" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk">Separating the logical abstraction of data processing from the underlying physical implementation layer allows users to choose the processing engine.</li></ul><p id="e549" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">In the rest of this blog, we will see how Google enables this contribution. One last thing before we move to the next section: Google noted that there is “<em class="pm">nothing magical about this model. “</em> The model doesn’t make your expensive-computed task suddenly run faster; it provides a general framework that allows for the simple expression of parallel computation, which is not tied to any specific execution engine like Spark or Flink.</p><h1 id="36c2" class="ns nt fr bf nu nv qa gr nx ny qb gu oa ob qc od oe of qd oh oi oj qe ol om on bk">Unbounded/Bounded</h1><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qf"><img src="../Images/b600c3a3d1d9b71e57545ed30fd2fe74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*k0wXVPWgxcvW9wBC.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><p id="0e93" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">The paper’s authors use the term unbounded/bounded to define infinite/finite data. They avoid using streaming/batch terms because they usually imply using a specific execution engine. The term unbound data describes the data that doesn’t have a predefined boundary, e.g., the user interaction events of an active e-commerce application; the data stream only stops when the application is inactive. Whereas bounded data refers to data that can be defined by clear start and end boundaries, e.g., daily data export from the operation database.</p></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><blockquote class="nf"><p id="b7f9" class="ng nh fr bf ni nj nk nl nm nn no np dx">To continue with the introduction section, we will review some concepts used throughout the paper.</p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="d628" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Windowing</h1><blockquote class="ps pt pu"><p id="9f60" class="oo op pm oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">The organizer</p></blockquote><p id="ddf8" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">Windowing divides the data into finite chunks. Usually, the system uses time notions to organize data into the window (e.g., all data in the last 1 hour will belong to one window). All data in the windows are processed as a group. Users require grouping operations on the window abstractions: aggregation or time-bounded operation when processing unbound data. On the other hand, some operations on unbounded data don’t need the window notion, like filtering, mapping, or inner join. Windows may be aligned, e.g., applied across all the data for a given window, or unaligned, e.g., applied across only specific subsets of the data in that window. There are three major types of windows:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qk"><img src="../Images/4e03f22f65b904cf7b97c9f9de7d290b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*12A0py3ETpkqi-x3.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><ul class=""><li id="0f6c" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">Fixed</strong>: The windows are defined as static window size, e.g., hourly windows.</li><li id="0736" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Sliding: </strong>The windows are defined by a window size and slide period, e.g., 30-minute windows starting every five minutes.</li><li id="4261" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Sessions: </strong>The windows capture some period of activity over a subset of the data, in this case, per key. Typically, they are defined by a timeout gap.</li></ul></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="f9aa" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Time Domains</h1><p id="2f06" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">When handling time-related events data, there are two domains of time to consider:</p><ul class=""><li id="b03d" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">Event Time</strong>: the time the event itself happened. For example, if the system device recorded you purchasing a game item at 11:30, this is considered the event time.</li><li id="8373" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Processing Time</strong>: The time at which an event is observed at any given point during processing. For example, the purchased game item is recorded at 11:30 but only arrives at the stream processing system at 11:35; this “11:35“ is the processing time.</li></ul><p id="975f" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">Given that definition, event time will never change, but processing time changes constantly for each event as it flows through the pipeline step. This is a critical factor when analyzing events in the context of when they occurred. The difference between the event_time and the processing_time is called time domain skew. The skew can result from many potential reasons, such as communication delays or time spent processing in each pipeline stage. Metrics, such as watermarks, are good ways to visualize the skew. For the paper, the authors considered a lower watermark on event times that the pipeline has processed. These watermarks provide a notion to tell the system that: <strong class="oq fs"><em class="pm">“no more data which have event time sooner this point of time will appear in the pipeline.”</em></strong> the watermarks are used not only to observe the skew between time domains but also to monitor the overall system. In a super-ideal world, the skew would always be zero; we could always process all events right when they happen.</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu ql"><img src="../Images/4a1327f226be77c03f1911ae75999655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b149Aw-cNYTac1NO.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><blockquote class="nf"><p id="2cfb" class="ng nh fr bf ni nj nk nl nm nn no np dx">In the following sections, we will learn the details of the Dataflow model.</p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="24b6" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Core primitives</h1><p id="baf1" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">The model has two core transformations that operate on the <code class="cx qm qn qo qp b">(key, value)</code> pair; both transformations can work on bounded and unbounded data:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qq"><img src="../Images/c4485cf3b3b6d6be67d4ab71ab77a2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tcVo1GFga7N3VNp_.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><ul class=""><li id="5e0e" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><code class="cx qm qn qo qp b">ParDo</code> is for generic parallel processing. It will process each input element with a provided user-defined function (called a <code class="cx qm qn qo qp b">DoFn</code> in Dataflow), which can produce zero or more output per input element. The input doesn’t need to be the unbound collections.</li><li id="4055" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><code class="cx qm qn qo qp b">GroupByKey</code> for grouping operations based on the defined key.</li></ul><p id="fc95" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">The <code class="cx qm qn qo qp b">ParDo</code> operates on each element so it can be translated to unbounded data. The <code class="cx qm qn qo qp b">GroupByKey</code> collects all data for a given key before sending it to the downstream steps. If the input source is unbounded, it is impossible to define when it will end. The standard solution is data windowing.</p></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="2c2f" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Windowing</h1><p id="2812" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">Systems that support grouping typically redefine their <code class="cx qm qn qo qp b">GroupByKey</code> operation to be <code class="cx qm qn qo qp b">GroupByKeyAndWindow</code>. The authors' significant contribution in this aspect is the unaligned window. The first is treating all windowing strategies as unaligned from the dataflow model and allowing custom adjustments to apply aligned windows when needed. The second is any windowing process can be broken apart into two related operations:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qf"><img src="../Images/00c182d4cd7e9b73bb943724146758f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v2WibTwFOrVapujg.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><ul class=""><li id="ddc2" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">AssignWindows </strong>assigns the element to zero or more windows. From the model’s view, window assignment creates a new copy of a component in each window.</li><li id="56f8" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">MergeWindows</strong> merges windows at grouping time. This allows the construction of data-driven windows over time as data arrive and are grouped. Window merging occurs as part of the <code class="cx qm qn qo qp b">GroupByKeyAndWindow</code> operation. We see the example below for a better understanding:</li></ul><h1 id="4ffc" class="ns nt fr bf nu nv qa gr nx ny qb gu oa ob qc od oe of qd oh oi oj qe ol om on bk">Triggers &amp; Incremental Processing</h1><p id="7912" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">Although there is support for unaligned windows, event-time windows raised another challenge: The need to tell the system when to emit the results for a window because the data can appear in the pipeline in an unordered way. The initial solution of using event-time progress metrics like watermark (which is mentioned above) has some shortcomings:</p><blockquote class="ps pt pu"><p id="fee3" class="oo op pm oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk"><strong class="oq fs">A reminder so you don’t have to scroll up</strong>: The watermark is an indicator that tells the system that “no more data which have event time sooner this point of time will appear in the pipeline.” For example, at the given time, the watermark is “11:30”, meaning no events with event_time less than 11:30 will appear anymore.</p></blockquote><ul class=""><li id="7dd0" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">They are sometimes too fast</strong>: this behavior means late data may arrive behind the watermark.</li><li id="f741" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">They are sometimes too slow</strong>: this behavior can cause the whole pipeline to be held back to wait for a slow data point.</li></ul><p id="e669" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">This led to the observation that using only watermarks to decide when to emit the window’s result is likely to increase the latency (when the watermark is slow) or impact the accuracy of the pipeline (missing some data if the watermark is too fast ). The authors observe in the Lambda Architecture (which has two separate pipelines, streaming and batch, and the result from the two pipelines finally converge in the end) that the paradigm doesn’t solve the completeness problem by providing correct answers faster; instead, it gives the low-latency estimate of a result from the streaming pipeline, then promises to deliver the correctness result from the batch pipeline. They stated that if we want to achieve the same thing in a single pipeline, we need a mechanism to provide multiple panes (answers) for any given window. This feature, called trigger, allows the user to specify when to trigger the output results for a given window. Here is an illustration to provide you with a similar idea between the trigger and the semantics in Lambda Architecture</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qr"><img src="../Images/eb2b6fb1621bf6cb50d441b19e5f2a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XL9R2ZmEbNJ54uIK.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><p id="e048" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">The system the authors introduce supports the following trigger implementation:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qs"><img src="../Images/a831282ccd30ace2528a98f6dbb9f062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IvwAcu0Yt-_ehV_Z.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><ul class=""><li id="6f56" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk">Triggering at completion estimates such as watermarks.</li><li id="4f51" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk">Triggering at the point in processing time.</li><li id="d57d" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk">Triggering based on data-arriving characteristics such as counts, bytes, data punctuations, pattern matching, etc.</li><li id="ac1f" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk">Supporting the implementation combination using loops, sequences, or logical combinations (AND, OR)</li><li id="c216" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk">The users can define their triggers utilizing both the underlying primitives of the execution runtime (e.g., watermark timers, processing-time timers) and external signals (e.g., data injection requests, external progress metrics)</li></ul><p id="c351" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">Besides controlling when the system will emit the window’s result, the trigger mechanism also provides a way to control how panes (answers) for a given window relate to each other via the following refinement modes:</p><figure class="mk ml mm mn mo mj mt mu paragraph-image"><div role="button" tabindex="0" class="qg qh ed qi bh qj"><div class="mt mu qt"><img src="../Images/1b5901e09ce2e8247d282836691bfb0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2Iu802iEybQpRLW2.png"/></div></div><figcaption class="mq mr ms mt mu mv mw bf b bg z dx">Image created by the author.</figcaption></figure><ul class=""><li id="8592" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs">Discarding: </strong>When triggering, the system discards all content’s window. The later results have no relation to previous results. This mode is helpful in cases where the downstream consumer needs the values from various triggers to be independent. This is also the most efficient option in terms of space for buffering data.</li><li id="e7d8" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Accumulating: </strong>When triggering, the system keeps window contents in a persistent state; later results are related to previous results. This is useful when the downstream consumer expects to overwrite old values with new ones when receiving multiple results for the same window. It is also the mode used in Lambda Architecture systems, where the streaming pipeline outputs low-latency results, which are then overwritten later by the results from the batch pipeline.</li><li id="11b3" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs">Accumulating &amp; Retracting: </strong>When triggering, in addition to the Accumulating semantics, the emitted result’s copy is also stored in a persistent state. When the window triggers again in the future, a retraction for the previous value will be emitted first, followed by the new value.</li></ul></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><blockquote class="nf"><p id="86a4" class="ng nh fr bf ni nj nk nl nm nn no np dx">The following section will describe how Google implements and designs the Dataflow model.</p></blockquote></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="0318" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Implementation</h1><p id="cd48" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">The paper’s authors say they’ve implemented this model internally using <a class="af nr" href="https://research.google/pubs/flumejava-easy-efficient-data-parallel-pipelines/" rel="noopener ugc nofollow" target="_blank">FlumeJava</a>, a Java library that makes it easy to develop, test, and run efficient data-parallel pipelines. MillWheel acts as the beneath stream execution engine. Additionally, an external reimplementation for Google Cloud Dataflow is primarily complete at the time of the paper’s writing. Interestingly, the core windowing and triggering code is quite general, and a significant portion is shared across batch and streaming implementations.</p><h1 id="8103" class="ns nt fr bf nu nv qa gr nx ny qb gu oa ob qc od oe of qd oh oi oj qe ol om on bk">Design Principles</h1><p id="75e6" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">The core principles of the Dataflow model:</p><ul class=""><li id="5870" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><em class="pm">Never rely on any notion of completeness.</em></li><li id="f034" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Be flexible to accommodate the diversity of known use cases and those to come in the future.</em></li><li id="211c" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">It not only makes sense but also adds value in the context of each of the envisioned execution engines.</em></li><li id="8830" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Encourage clarity of implementation.</em></li><li id="a154" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><em class="pm">Support robust analysis of data in the context in which they occurred.</em></li></ul><h1 id="2f4d" class="ns nt fr bf nu nv qa gr nx ny qb gu oa ob qc od oe of qd oh oi oj qe ol om on bk">Motivating Experiences</h1><p id="1ad9" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">As they designed the Model, they gained real-world experiences with FlumeJava and MillWheel. Things that worked well would be reflected in the model; things that were less well would motivate changes in approach. Here are some of their experiences that influenced the design choice:</p><ul class=""><li id="2742" class="oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Unified Model: </em></strong><em class="pm">The original motivation for this design choice is that one huge pipeline runs in streaming mode on MillWheel by default but with a dedicated FlumeJava batch implementation for large-scale backfills. Another motivation came from an experience with Lambda Architecture, where one customer ran the streaming pipeline in MillWheel with a nightly MapReduce (batch) to generate truth. They found that customers stopped trusting the weakly consistent results between pipelines over time.</em></li><li id="761e" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Sessions</em></strong><em class="pm"> are a critical use case within Google. This mechanism is used in many cases, including search, ads, analytics, social media, and YouTube. Any users who care about correlating bursts of user activity over a period of time would leverage sessions. Thus, support for sessions became an indispensable part of the model’s design.</em></li><li id="4646" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Triggers, Accumulation, &amp; Retraction: </em></strong><em class="pm">Two teams with billing pipelines running on MillWheel had problems that motivated parts of the model. The best practice at the time was to use the watermark as a completion metric, with extra ad hoc logic for late data. Lacking a system for updates and retractions, a team that processed resource utilization statistics decided to build their own solution. Another billing team had significant issues with watermark lags caused by stragglers (slow-running units affect overall job performance completion.) in the input. These shortcomings became significant motivators in the design and shifted the focus from targeting completeness to adaptability over time. This results in two decisions: triggers, which allow the flexible specification of when results are materialized, and incremental processing support via accumulation.</em></li><li id="c805" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Watermark Triggers: </em></strong><em class="pm">Many MillWheel pipelines calculate aggregate statistics. Most do not require 100% accuracy; they care about having a mostly complete view of their data in a reasonable amount of time. Given the high level of accuracy that they achieve with watermarks for structured input sources like log files, customers find watermarks very effective in triggering a single, highly accurate aggregate per window.</em></li><li id="939c" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Processing Time Triggers: </em></strong><em class="pm">The recommendation pipelines emit their output using processing-time timers. These systems, having regularly updated, partial views of the data, were much more valuable than waiting until mostly complete views were ready based on the watermark. This also meant that the notion of a watermark would not affect the timeliness of output for the rest of the data.</em></li><li id="4278" class="oo op fr oq b gp pn os ot gs po ov ow ox pp oz pa pb pq pd pe pf pr ph pi np pj pk pl bk"><strong class="oq fs"><em class="pm">Data-Driven &amp; Composite Triggers: </em></strong><em class="pm">The different detection systems in the anomaly detection pipeline used to track trends in Google web search motivated the data-driven triggers. These differences observe the stream of queries and calculate statistical estimates to check whether a spike exists. When they believe a spike is happening, they emit a start record; when they think it has ceased, they emit a stop. It was also a motivating case for trigger composition because, in reality, the system runs multiple differs simultaneously, multiplexing the output according to a set of logic.</em></li></ul></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="b518" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">Outro</h1><p id="4875" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">In this week’s blog, we’ve discussed the design principle and implementation of the Dataflow model, the backbone behind the famous Google Cloud Dataflow service. If you want to dive deeper into the model, I highly recommend the book <a class="af nr" href="https://www.amazon.com/Streaming-Systems-Where-Large-Scale-Processing/dp/1491983876" rel="noopener ugc nofollow" target="_blank">Streaming Systems: The What, Where, When, and How of Large-Scale Data Processing</a> or the two-part blog from one of the paper’s authors: <a class="af nr" href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/" rel="noopener ugc nofollow" target="_blank">Streaming 101</a> and <a class="af nr" href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/" rel="noopener ugc nofollow" target="_blank">Streaming 102</a>. I hope my work brings some value, especially to someone who wants to learn more about the stream processing world.</p><p id="f683" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk">See you next blog!</p></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><h1 id="257a" class="ns nt fr bf nu nv nw gr nx ny nz gu oa ob oc od oe of og oh oi oj ok ol om on bk">References</h1><p id="0b15" class="pw-post-body-paragraph oo op fr oq b gp or os ot gs ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi np fk bk">[1] Google, <a class="af nr" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43864.pdf" rel="noopener ugc nofollow" target="_blank">The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Dat</a>a (2015).</p></div></div></div><div class="ab cb mx my mz na" role="separator"><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd ne"/><span class="nb by bm nc nd"/></div><div class="fk fl fm fn fo"><div class="ab cb"><div class="ci bh ew ex ey ez"><p id="5ecc" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk"><em class="pm">My newsletter is a weekly blog-style email in which I note things I learn from people smarter than me.</em></p><p id="3256" class="pw-post-body-paragraph oo op fr oq b gp pv os ot gs pw ov ow ox px oz pa pb py pd pe pf pz ph pi np fk bk"><em class="pm">So, if you want to learn and grow with me, subscribe here: </em><a class="af nr" href="https://open.substack.com/pub/vutr?utm_source=share&amp;utm_medium=android&amp;r=171vwv" rel="noopener ugc nofollow" target="_blank"><em class="pm">https://vutr.substack.com</em></a><em class="pm">.</em></p></div></div></div></div>    
</body>
</html>