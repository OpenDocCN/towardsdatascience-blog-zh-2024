- en: How to Implement State-of-the-Art Masked AutoEncoders (MAE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-implement-state-of-the-art-masked-autoencoders-mae-6f454b736087?source=collection_archive---------9-----------------------#2024-09-16](https://towardsdatascience.com/how-to-implement-state-of-the-art-masked-autoencoders-mae-6f454b736087?source=collection_archive---------9-----------------------#2024-09-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A Step-by-Step Guide to Building MAE with Vision Transformers**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@francoisporcher?source=post_page---byline--6f454b736087--------------------------------)[![François
    Porcher](../Images/9ddb233f8cadbd69026bd79e2bd62dea.png)](https://medium.com/@francoisporcher?source=post_page---byline--6f454b736087--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6f454b736087--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6f454b736087--------------------------------)
    [François Porcher](https://medium.com/@francoisporcher?source=post_page---byline--6f454b736087--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6f454b736087--------------------------------)
    ·7 min read·Sep 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Hi everyone! For those who do not know me yet, my name is Francois, I am a Research
    Scientist at Meta. I have a passion for explaining advanced AI concepts and making
    them more accessible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today, I’m excited to delve into one of the most significant breakthroughs
    in Computer Vision post-Vision Transformers: **Masked Autoencoders (MAE).** This
    article serves as the practical implementation companion to my previous post:
    [The Ultimate Guide to Masked Autoencoders (MAE)](https://medium.com/ai-advances/the-ultimate-guide-to-masked-autoencoders-mae-87aa6883ff47)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the following tutorial, we will use the code available on this github repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----6f454b736087--------------------------------)
    [## GitHub - FrancoisPorcher/awesome-ai-tutorials: The best collection of AI tutorials
    to make you a…'
  prefs: []
  type: TYPE_NORMAL
- en: The best collection of AI tutorials to make you a boss of Data Science! - FrancoisPorcher/awesome-ai-tutorials
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/FrancoisPorcher/awesome-ai-tutorials?source=post_page-----6f454b736087--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a brief reminder of how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4bb371ea36f5a017424c55d6032f01dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from article [MAE are Scalable Learners](https://arxiv.org/abs/2111.06377)
  prefs: []
  type: TYPE_NORMAL
- en: '**Here’s how the methodology works:**'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The image is split into patches.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. A subset of these patches is randomly masked.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Only the visible patches are fed into the encoder **(this is crucial).**
  prefs: []
  type: TYPE_NORMAL
