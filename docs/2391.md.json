["```py\ndef plot_two_tailed_test(z_value):\n    # Generate a range of x values\n    x = np.linspace(-4, 4, 1000)\n    # Get the standard normal distribution values for these x values\n    y = stats.norm.pdf(x)\n\n    # Create the plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(x, y, label='Standard Normal Distribution', color='black')\n\n    # Shade the areas in both tails with red\n    plt.fill_between(x, y, where=(x >= z_value), color='red', alpha=0.5, label='Right Tail Area')\n    plt.fill_between(x, y, where=(x <= -z_value), color='red', alpha=0.5, label='Left Tail Area')\n\n    # Define critical values for alpha = 0.05\n    alpha = 0.05\n    critical_value = stats.norm.ppf(1 - alpha / 2)\n\n    # Add vertical dashed blue lines for critical values\n    plt.axvline(critical_value, color='blue', linestyle='dashed', linewidth=1, label=f'Critical Value: {critical_value:.2f}')\n    plt.axvline(-critical_value, color='blue', linestyle='dashed', linewidth=1, label=f'Critical Value: {-critical_value:.2f}')\n\n    # Mark the z-value\n    plt.axvline(z_value, color='red', linestyle='dashed', linewidth=1, label=f'Z-Value: {z_value:.2f}')\n\n    # Add labels and title\n    plt.title('Two-Tailed Z-Test Visualization')\n    plt.xlabel('Z-Score')\n    plt.ylabel('Probability Density')\n    plt.legend()\n    plt.grid(True)\n\n    # Show plot\n    plt.savefig(f'../images/p-value_location_in_z_dist_z_test_proportionality.png')\n    plt.show()\n\ndef two_proportion_z_test(successes1, total1, successes2, total2):\n    \"\"\"\n    Perform a two-proportion z-test to check if two population proportions are significantly different.\n\n    Parameters:\n    - successes1: Number of successes in the first sample\n    - total1: Total number of observations in the first sample\n    - successes2: Number of successes in the second sample\n    - total2: Total number of observations in the second sample\n\n    Returns:\n    - z_value: The z-statistic\n    - p_value: The p-value of the test\n    \"\"\"\n    # Calculate sample proportions\n    p1 = successes1 / total1\n    p2 = successes2 / total2\n\n    # Combined proportion\n    p_combined = (successes1 + successes2) / (total1 + total2)\n\n    # Standard error\n    se = np.sqrt(p_combined * (1 - p_combined) * (1/total1 + 1/total2))\n\n    # Z-value\n    z_value = (p1 - p2) / se\n\n    # P-value for two-tailed test\n    p_value = 2 * (1 - stats.norm.cdf(np.abs(z_value)))\n\n    return z_value, p_value\n\nmin_score_for_semi_finals = 7.040\nis_semi_finalist = df.PROMEDIO >= min_score_for_semi_finals\n\n# Number of couples scored by panel 1 advancing to semi-finals\nsuccesses_1 = df[is_semi_finalist][panel_1].dropna(axis=0).shape[0]  \n# Number of couples scored by panel 2 advancing to semi-finals\nsuccesses_2 = df[is_semi_finalist][panel_2].dropna(axis=0).shape[0] \n\n# Total number of couples that where scored by panel 1\nn1 = df[panel_1].dropna(axis=0).shape[0] \n# Total sample of couples that where scored by panel 2\nn2 = df[panel_2].dropna(axis=0).shape[0]\n\n# Perform the test\nz_value, p_value = two_proportion_z_test(successes_1, n1, successes_2, n2)\n\n# Print the results\nprint(f\"Z-Value: {z_value:.4f}\")\nprint(f\"P-Value: {p_value:.4f}\")\n\n# Check significance at alpha = 0.05\nalpha = 0.05\nif p_value < alpha:\n    print(\"The difference between the two proportions is statistically significant.\")\nelse:\n    print(\"The difference between the two proportions is not statistically significant.\")\n\n# Generate the plot\n# P-Value: 0.0000\nplot_two_tailed_test(z_value)\n```", "```py\n# Calculate mean and standard deviation of the distribution of mean scores\ndistribution_mean = np.mean(judge_means)\ndistribution_std = np.std(judge_means, ddof=1)\n\n# Function to perform T-test\ndef t_test(score, mean, std_dev, n):\n    \"\"\"Perform a T-test to check if a score is significantly different from the mean.\"\"\"\n    t_value = (score - mean) / (std_dev / np.sqrt(n))\n    # Degrees of freedom for the T-test\n    df = n - 1\n    # Two-tailed test\n    p_value = 2 * (1 - stats.t.cdf(np.abs(t_value), df))\n    return t_value, p_value\n\n# Number of samples in the distribution\nn = len(judge_means)\n\n# Dictionary to store the test results\nresults = {}\n\n# Iterate through each judge's mean score and perform T-test\nfor judge, score in zip(judge_features, judge_means):\n    t_value, p_value = t_test(score, distribution_mean, distribution_std, n)\n\n    # Store results in the dictionary\n    results[judge] = {\n        'mean_score': score,\n        'T-Value': t_value,\n        'P-Value': p_value,\n        'Significant': p_value < 0.05\n    }\n\n# Convert results to DataFrame and process\ndf_judge_means_test = pd.DataFrame(results).T\ndf_judge_means_test.mean_score = df_judge_means_test.mean_score.astype(float)\ndf_judge_means_test.sort_values('mean_score')\n```", "```py\npanel_1 = judge_features[:5] + judge_features[10:15]\npanel_2 = judge_features[5:10] + judge_features[15:]\n\ndf_judge_means = df_judge_means_test.sort_values('mean_score').mean_score\n\n# Calculate ranks\nranks = df_judge_means.rank()\n\n# Calculate mean and std of ranks\nmeans_ranks = ranks.mean()\nstds_ranks = ranks.std()\n\n# Standardize ranks\ndf_judge_ranks = (ranks - means_ranks) / stds_ranks\ndf_judge_ranks\n# these are the same judges sorted in the same way as before based on their mean scores\n# except here we have converted mean values into rankings and standardized the rankings \n# Now we want to see how these 20 judges are distributed between the two panels \n# do the biases for each judge get canceled out by their peers on the same panel?\n```"]