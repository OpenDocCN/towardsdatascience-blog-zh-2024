<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The One Billion Row Challenge in Julia</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The One Billion Row Challenge in Julia</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05">https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b782" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">What can data scientists learn should they choose to accept this mission?</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vikas Negi" class="l ep by dd de cx" src="../Images/3f5974d44cfdbdecb77e3b4cb3098af0.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/2*1xvONKOlT77RqFmciJS_UQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------" rel="noopener follow">Vikas Negi</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 5, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/dded10279fcf25261adbea5aecf60745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K4UvBUM1JkuzTD9b"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by <a class="af nb" href="https://unsplash.com/@indiratjokorda?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Indira Tjokorda</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8370" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Earlier this year, Gunnar Morling launched the<a class="af nb" href="https://www.morling.dev/blog/one-billion-row-challenge/" rel="noopener ugc nofollow" target="_blank"> One Billon Row Challenge</a>, which has since gained a lot of popularity. Although the original challenge was meant to be done using Java, the amazing open-source community has since shared impressive solutions in different programming languages. I noticed that not many people had tried using Julia (or at least not publicly shared results), so decided to share my own humble attempt via this article.</p><p id="e2ff" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A question that often came to my mind was what value does this challenge bring to a data scientist? Can we learn something more other than just doing a fun exercise? After all, the goal of the challenge is to “simply” parse a large dummy data file, calculate basic statistics (min, max and mean), and output the data in a specific format. This might not be a realistic situation for most if not all projects that data scientists usually work on.</p><p id="b237" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Well, one aspect of the problem has to do with the size of the data versus the available RAM. When working locally (laptop or a desktop), for most people, it will be difficult to load the data all at once into memory. Dealing with larger than memory data sets therefore becomes an essential skill, which might come in handy when prototyping big data pipelines or performing big data analysis/visualization tasks. The rules of the original challenge also state that use of external libraries/packages should be avoided. This forces you to think of novel solutions and provides a fascinating opportunity to learn the nuances of the language itself.</p><p id="01c2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In rest of the article, I will share results from both the approaches — using base Julia and also with external packages. This way, we get to compare the pros and cons of each. All experiments have been performed on a desktop equipped with AMD Ryzen 9 5900X (12 cores, 24 threads), 32 GB RAM and Samsung NVMe SSD. Julia 1.10.2 is running on Linux (Elementary OS 7.1 Horus). All relevant code is available <a class="af nb" href="https://github.com/vnegi10/1brc_julia" rel="noopener ugc nofollow" target="_blank">here</a>. Do note that the performance in this case is also tied to the hardware, so results may vary in case you decide to run the scripts on your own system.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="7087" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Prerequisites</h1><p id="d41c" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">A recent release of <a class="af nb" href="https://julialang.org/downloads/" rel="noopener ugc nofollow" target="_blank">Julia</a> such as 1.10 is recommended. For those wanting to use a notebook, the <a class="af nb" href="https://github.com/vnegi10/1brc_julia" rel="noopener ugc nofollow" target="_blank">repository</a> shared above also contains a Pluto file, for which <a class="af nb" href="https://github.com/fonsp/Pluto.jl" rel="noopener ugc nofollow" target="_blank">Pluto.jl</a> needs to be installed. The input data file for the challenge is unique for everyone and needs to be generated using <a class="af nb" href="https://github.com/gunnarmorling/1brc/blob/main/src/main/python/create_measurements.py" rel="noopener ugc nofollow" target="_blank">this Python script</a>. Keep in mind that the file is about 15 GB in size.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="0c3c" class="pl oh fq pi b bg pm pn l po pp">python3 create_measurements.py 1000000000</span></pre><p id="f911" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Additionally, we will be running benchmarks using the <a class="af nb" href="https://github.com/JuliaCI/BenchmarkTools.jl" rel="noopener ugc nofollow" target="_blank">BenchmarkTools.jl</a> package. Note that this does not impact the challenge, it’s only meant to collect proper statistics to measure and quantify the performance of the Julia code.</p><h1 id="d917" class="og oh fq bf oi oj pq gq ol om pr gt oo op ps or os ot pt ov ow ox pu oz pa pb bk">Using base Julia</h1><p id="e9cc" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">The structure of the input data file <code class="cx pv pw px pi b">measurements.txt</code> is as follows (only the first five lines are shown):</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="d3ef" class="pl oh fq pi b bg pm pn l po pp">attipūdi;-49.2<br/>Bas Limbé;-43.8<br/>Oas;5.6<br/>Nesebar;35.9<br/>Saint George’s;-6.6</span></pre><p id="5968" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The file contains a billion lines (also known as rows or records). Each line has a station name followed by the <code class="cx pv pw px pi b">; </code>separator and then the recorded temperature. The number of unique stations can be up to 10,000. This implies that the same station appears on multiple lines. We therefore need to collect all the temperatures for all distinct stations in the file, and then calculate the required statistics. Easy, right?</p><h2 id="eff6" class="py oh fq bf oi pz qa qb ol qc qd qe oo nl qf qg qh np qi qj qk nt ql qm qn qo bk">Let’s start slow but simple</h2><p id="4b7d" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">My first attempt was to simply parse the file one line at a time, and then collect the results in a dictionary where every station name is a key and the temperatures are added to a vector of <code class="cx pv pw px pi b">Float64</code> to be used as the value mapped to the key. I expected this to be slow, but our aim here is to get a number for the baseline performance.</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="0e4b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Once the dictionary is ready, we can calculate the necessary statistics:</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="ee3b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The output of all the data processing needs to be displayed in a certain format. This is achieved by the following function:</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="3d5e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Since this implementation is expected to take long, we can run a simple test by timing <code class="cx pv pw px pi b">@time</code> the following only once:</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="455e" class="pl oh fq pi b bg pm pn l po pp">@time get_stations_dict_v2("measurements.txt") |&gt; calculate_output_v3 |&gt; print_output_v1<br/><br/>&lt;output omitted for brevity&gt; 526.056399 seconds (3.00 G allocations: 302.881 GiB, 3.68% gc time)</span></pre><p id="4ec9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Our poor man’s implementation takes about 526 seconds, so ~ 9 minutes. It’s definitely slow, but not that bad at all!</p><h2 id="1524" class="py oh fq bf oi pz qa qb ol qc qd qe oo nl qf qg qh np qi qj qk nt ql qm qn qo bk">Taking it up a notch — Enter multithreading!</h2><p id="778e" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Instead of reading the input file one line at a time, we can try to split it into chunks, and then process all the chunks in parallel. Julia makes it quite easy to implement a parallel <code class="cx pv pw px pi b">for</code> loop. However, we need to take some <a class="af nb" href="https://docs.julialang.org/en/v1/manual/multi-threading/#Caveats" rel="noopener ugc nofollow" target="_blank">precautions</a> while doing so.</p><p id="d5df" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Before we get to the loop, we first need to figure out how to split the file into chunks. This can be achieved using <a class="af nb" href="https://docs.julialang.org/en/v1/stdlib/Mmap/https://docs.julialang.org/en/v1/stdlib/Mmap/" rel="noopener ugc nofollow" target="_blank">memory mapping</a> to read the file. Then we need to determine the <code class="cx pv pw px pi b">start</code> and <code class="cx pv pw px pi b">end</code> positions of each chunk. It’s important to note that each line in the input data file ends with a new-line character, which has <code class="cx pv pw px pi b">0x0a</code> as the byte representation. So each chunk should end at that character to ensure that we don’t make any errors while parsing the file.</p><p id="a1cf" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The following function takes the number of chunks<code class="cx pv pw px pi b">num_chunks</code>as an input argument, then returns an array with each element as the memory mapped chunk.</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="4e8b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Since we are parsing station and temperature data from different chunks, we also need to combine them in the end. Each chunk will first be processed into a dictionary as shown before. Then, we combine all chunks as follows:</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="6629" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Now we know how to split the file into chunks, and how we can combine the parsed dictionaries from the chunks at the end. However, the desired speedup can only be obtained if we are also able to process the chunks in parallel. This can be done in a <code class="cx pv pw px pi b">for</code> loop. Note that Julia should be <a class="af nb" href="https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads" rel="noopener ugc nofollow" target="_blank">started with multiple threads</a> <code class="cx pv pw px pi b">julia -t 12</code> for this solution to have any impact.</p><p id="7be3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Additionally, we now want to run a proper statistical benchmark. This means that the challenge should be executed a certain number of times, and we should then be able to visualize the distribution of the results. Thankfully, all of this can be easily done with <a class="af nb" href="https://github.com/JuliaCI/BenchmarkTools.jl" rel="noopener ugc nofollow" target="_blank">BenchmarkTools.jl</a>. We cap the maximum number of samples to 10, maximum time for the total run to be 20 minutes and enable garbage collection (will free up memory) to execute between samples. All of this can be brought together in a single script. Note that the input arguments are now the name of the file <code class="cx pv pw px pi b">fname</code> and the number of chunks <code class="cx pv pw px pi b">num_chunks.</code></p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="bb5a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Benchmark results along with the inputs used are shown below. Note that we have used 12 threads here.</p><pre class="ml mm mn mo mp ph pi pj bp pk bb bk"><span id="e5fa" class="pl oh fq pi b bg pm pn l po pp">julia&gt; Threads.nthreads()<br/>12<br/><br/>julia&gt; ARGS = ["measurements.txt", "48"]<br/>2-element Vector{String}:<br/> "measurements.txt"<br/> "48"</span></pre><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qs"><img src="../Images/72ec4e552a082a0938866ae4f1e12de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*peBs7HCXwJR8iS4SX9qTcw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">12 threads, number of chunks = 48 (Image by author)</figcaption></figure><p id="f666" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Multi-threading provides a big performance boost, we are now down to roughly over 2 minutes. Let’s see what else we can improve.</p><h2 id="1db8" class="py oh fq bf oi pz qa qb ol qc qd qe oo nl qf qg qh np qi qj qk nt ql qm qn qo bk">Avoiding storing all temperature data</h2><p id="0324" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Until now, our approach has been to store all the temperatures, and then determine the required statistics (min, mean and max) at the very end. However, the same can already be achieved while we parse every line from the input file. We replace existing values each time a new value which is either larger (for maximum) or smaller (for minimum) is found. For mean, we sum all the values and keep a separate counter as to how many times a temperature for a given station has been found.</p><p id="9480" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Overall, out new logic looks like the following:</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="9720" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The function to combine all the results (from different chunks) also needs to be updated accordingly.</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="ec37" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s run a new benchmark and see if this change improves the timing.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qt"><img src="../Images/03e629680c5f7ea6a82d412a8dfd74b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1BNMi1Lhberg0BWiXn1UA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">12 threads, number of chunks = 48 (Image by author)</figcaption></figure><p id="0838" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The median time seems to have improved, but only slightly. It’s a win, nonetheless!</p><h2 id="157e" class="py oh fq bf oi pz qa qb ol qc qd qe oo nl qf qg qh np qi qj qk nt ql qm qn qo bk">More performance enhancement</h2><p id="e69b" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Our previous logic to calculate and save the mix, max for temperature can be further simplified. Moreover, following the suggestion from this <a class="af nb" href="https://discourse.julialang.org/t/the-one-billion-row-challenge/109534/24" rel="noopener ugc nofollow" target="_blank">Julia Discourse post</a>, we can make use of views (using <code class="cx pv pw px pi b">@view</code> ) when parsing the station names and temperature data. This has also been <a class="af nb" href="https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Consider-using-views-for-slices-1" rel="noopener ugc nofollow" target="_blank">discussed</a> in the Julia performance manual. Since we are using a slice expression for parsing every line, <code class="cx pv pw px pi b">@view</code> helps us avoid the cost of allocation and copying.</p><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="a598" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Rest of the logic remains the same. Running the benchmark now gives the following:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qu"><img src="../Images/f521124dfe4e634f7f0478fcbea99c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KQKKAh05bGwUz5pcKyhWiw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">12 threads, number of chunks = 48 (Image by author)</figcaption></figure><p id="9298" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Whoa! We managed to reach down to almost a minute. It seems switching to a view does make a big difference. Perhaps, there are further tweaks that could be made to improve performance even further. In case you have any suggestions, do let me know in the comments.</p><h1 id="f4dc" class="og oh fq bf oi oj pq gq ol om pr gt oo op ps or os ot pt ov ow ox pu oz pa pb bk">Using external packages</h1><p id="5086" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">Restricting ourselves only to base Julia was fun. However, in the real world, we will almost always be using packages and thus making use of existing efficient implementations for performing the relevant tasks. In our case, CSV.jl (parsing the file in parallel) and DataFrames.jl (performing <code class="cx pv pw px pi b">groupby</code> and <code class="cx pv pw px pi b">combine</code>) will come in handy.</p><p id="6bf8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The function below performs the following tasks:</p><ul class=""><li id="2371" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx qv qw qx bk">Use <code class="cx pv pw px pi b">Mmap</code> to read the large file</li><li id="fd8a" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx qv qw qx bk">Split file into a predefined number of chunks</li><li id="0a5e" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx qv qw qx bk">Loop through the chunks, read each chunk in parallel using <code class="cx pv pw px pi b">CSV.read</code> (12 threads passed to <code class="cx pv pw px pi b">ntasks</code>) into a DataFrame.</li><li id="782f" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx qv qw qx bk">Use DataFrame <code class="cx pv pw px pi b">groupby</code> and <code class="cx pv pw px pi b">combine</code> to get the results for each station</li><li id="729d" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx qv qw qx bk">Concatenate all DataFrames to combine results from all chunks</li><li id="6c3a" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx qv qw qx bk">Once outside the loop, perform a <code class="cx pv pw px pi b">groupby</code> and <code class="cx pv pw px pi b">combine</code> again to get the final set of results for all stations.</li></ul><figure class="ml mm mn mo mp mq"><div class="qp io l ed"><div class="qq qr l"/></div></figure><p id="47b9" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We can now run the benchmark in the same manner as before.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rd"><img src="../Images/72da5f5c1ebda12a8453bd0ddd76df4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nsZlqCM_HlItl1rNT3Xqrw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">12 threads, number of chunks = 48, using external packages (Image by author)</figcaption></figure><p id="6f51" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The performance using CSV.jl and DataFrames.jl is quite good, albeit slower than our base Julia implementation. When working on real world projects, these packages are an essential part of a data scientist’s toolkit. It would thus be interesting to explore if further optimizations are possible using this approach.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="13d1" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">Conclusion</h1><p id="e427" class="pw-post-body-paragraph nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx fj bk">In this article, we tackled the One Billion Row Challenge using Julia. Starting from a very naive implementation that took ~ 10 minutes, we managed to gain significant performance improvement through iterative changes to the code. The most optimized implementation completes the challenge in ~ 1 minute. I am certain that there’s still more room for improvement. As an added bonus, we learned some valuable tricks on how to deal with larger than memory data sets. This might come in handy when doing some big data analysis and visualization using Julia.</p><p id="c593" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">I hope you found this exercise useful. Thank you for your time! Connect with me on <a class="af nb" href="https://www.linkedin.com/in/negivikas/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a> or visit my <a class="af nb" href="https://vikasnegi.eth.limo/" rel="noopener ugc nofollow" target="_blank">Web 3.0 powered website</a>.</p></div></div></div><div class="ab cb ny nz oa ob" role="separator"><span class="oc by bm od oe of"/><span class="oc by bm od oe of"/><span class="oc by bm od oe"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="c88a" class="og oh fq bf oi oj ok gq ol om on gt oo op oq or os ot ou ov ow ox oy oz pa pb bk">References</h1><ol class=""><li id="cf5c" class="nc nd fq ne b go pc ng nh gr pd nj nk nl pe nn no np pf nr ns nt pg nv nw nx re qw qx bk"><a class="af nb" href="https://www.morling.dev/blog/one-billion-row-challenge/" rel="noopener ugc nofollow" target="_blank">https://www.morling.dev/blog/one-billion-row-challenge/</a></li><li id="f023" class="nc nd fq ne b go qy ng nh gr qz nj nk nl ra nn no np rb nr ns nt rc nv nw nx re qw qx bk"><a class="af nb" href="https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations" rel="noopener ugc nofollow" target="_blank">https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations</a></li></ol></div></div></div></div>    
</body>
</html>