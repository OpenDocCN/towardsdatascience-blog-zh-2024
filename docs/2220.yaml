- en: Mixture of KAN Experts for High-Performance Time Series Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mixture-of-kan-experts-for-high-performance-time-series-forecasting-5227e1d2aba2?source=collection_archive---------0-----------------------#2024-09-11](https://towardsdatascience.com/mixture-of-kan-experts-for-high-performance-time-series-forecasting-5227e1d2aba2?source=collection_archive---------0-----------------------#2024-09-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explore the RMoK model and its architecture, and apply it in a small experiment
    using Python.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--5227e1d2aba2--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--5227e1d2aba2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5227e1d2aba2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5227e1d2aba2--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--5227e1d2aba2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5227e1d2aba2--------------------------------)
    ·10 min read·Sep 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4113b5de4b93ff2b0fd2add5e5dbfc73.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Kyaw Tun](https://unsplash.com/@kyawthutun?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of the Kolmogorov-Arnold Network (KAN) marked an important
    contribution to the field of deep learning, as it represented an alternative to
    the multilayer perceptron (MLP).
  prefs: []
  type: TYPE_NORMAL
- en: The MLP is of course the building block of many deep learning models, including
    state-of-the-art forecasting methods like [N-BEATS](/the-easiest-way-to-forecast-time-series-using-n-beats-d778fcc2ba60),
    [NHiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)
    and [TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb).
  prefs: []
  type: TYPE_NORMAL
- en: However, in a [forecasting benchmark](https://medium.com/towards-data-science/kolmogorov-arnold-networks-kans-for-time-series-forecasting-9d49318c3172)
    using KAN, MLP, NHiTS and NBEATS, we discovered that KAN was generally very slow
    and consistently performed worse on various forecasting tasks. Note that the benchmark
    was done on the M3 and M4 datasets, which contain more than 99 000 unique time
    series with frequencies ranging from hourly to yearly.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, at that time, applying KANs for time series forecasting was disappointing
    and not a recommended approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'This has changed now with **Reversible Mixture of KAN** (RMoK) as introduced
    in the paper: [KAN4TSF: Are KAN and KAN-based Models Effective for Time Series
    Forecasting?](https://arxiv.org/abs/2408.11306)'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we first explore the architecture and inner workings of the
    Reversible Mixture of KAN model…
  prefs: []
  type: TYPE_NORMAL
