- en: 'Deep Dive into LlamaIndex Workflow: Event-Driven LLM Architecture'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deep-dive-into-llamaindex-workflow-event-driven-llm-architecture-8011f41f851a?source=collection_archive---------3-----------------------#2024-12-17](https://towardsdatascience.com/deep-dive-into-llamaindex-workflow-event-driven-llm-architecture-8011f41f851a?source=collection_archive---------3-----------------------#2024-12-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What I think about the progress and shortcomings after practice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://qtalen.medium.com/?source=post_page---byline--8011f41f851a--------------------------------)[![Peng
    Qian](../Images/9ce9aeb381ec6b017c1ee5d4714937e2.png)](https://qtalen.medium.com/?source=post_page---byline--8011f41f851a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8011f41f851a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8011f41f851a--------------------------------)
    [Peng Qian](https://qtalen.medium.com/?source=post_page---byline--8011f41f851a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8011f41f851a--------------------------------)
    ·14 min read·Dec 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2acca4fc881e01dadd750e32e0903d01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Deep Dive into LlamaIndex Workflows: Event-driven LLM architecture. Image by
    DALL-E-3'
  prefs: []
  type: TYPE_NORMAL
- en: Recently, LlamaIndex introduced a new feature called [Workflow](https://docs.llamaindex.ai/en/stable/understanding/workflows/)
    in one of its versions, providing event-driven and logic decoupling capabilities
    for LLM applications.
  prefs: []
  type: TYPE_NORMAL
- en: In today’s article, we’ll take a deep dive into this feature through a practical
    mini-project, exploring what’s new and still lacking. Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why event-driven?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More and more LLM applications are shifting towards intelligent agent architectures,
    expecting LLMs to meet user requests through calling different APIs or multiple
    iterative calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'This shift, however, brings a problem: as agent applications make more API
    calls, program responses slow down and code logic becomes more complex.'
  prefs: []
  type: TYPE_NORMAL
- en: A typical example is [ReActAgent](https://docs.llamaindex.ai/en/stable/api_reference/agent/react/#llama_index.core.agent.react.ReActAgent),
    which involves steps like Thought, Action, Observation, and Final Answer, requiring
    at least three LLM calls and one tool call. If loops are needed, there will be
    even more I/O calls.
  prefs: []
  type: TYPE_NORMAL
