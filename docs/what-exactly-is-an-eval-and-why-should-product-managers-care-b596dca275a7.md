# 什么是“Eval”，为什么产品经理需要关注它？

> 原文：[https://towardsdatascience.com/what-exactly-is-an-eval-and-why-should-product-managers-care-b596dca275a7?source=collection_archive---------5-----------------------#2024-07-25](https://towardsdatascience.com/what-exactly-is-an-eval-and-why-should-product-managers-care-b596dca275a7?source=collection_archive---------5-----------------------#2024-07-25)

## 如何停止担忧并爱上数据

[](https://medium.com/@4thewinn?source=post_page---byline--b596dca275a7--------------------------------)[![Julia Winn](../Images/9ca44e7be7c308a0bcaf797c6fa76a8c.png)](https://medium.com/@4thewinn?source=post_page---byline--b596dca275a7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b596dca275a7--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b596dca275a7--------------------------------) [Julia Winn](https://medium.com/@4thewinn?source=post_page---byline--b596dca275a7--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b596dca275a7--------------------------------) ·阅读时间 9 分钟 ·2024 年 7 月 25 日

--

![](../Images/41e596ffe7f34561ad84068942dafbeb.png)

由作者使用 Midjourney 版本 6 生成

**定义**：eval（评估的缩写）。这是模型开发生命周期中的一个关键阶段。这个过程帮助团队了解 AI 模型是否真的做到了他们希望它做的事情。评估过程适用于所有类型的模型，从基本的分类器到像 ChatGPT 这样的 LLM（大型语言模型）。eval 这个术语还用来指代用于评估的数据集或测试用例列表。

根据模型的不同，eval 可能涉及定量、定性、人为评估，或者上述所有内容。我在职业生涯中遇到的大多数 eval 都是在精心挑选的数据集上运行模型，以计算关键的兴趣指标，如准确率、精确率和召回率。

也许是因为历史上 eval 涉及大量电子表格或数字数据库，今天的大多数团队将设计和执行 eval 的责任完全交给了模型开发人员。

然而，我相信在大多数情况下，eval 应该由产品经理来密切定义。

![](../Images/d36ed89785ce91d50e8731cade2eb7ab.png)

图片由作者使用 Midjourney 版本 6 生成

Evals 旨在回答以下问题：

+   这个模型达成了目标吗？

+   这个模型比其他现有模型更好吗？

+   这个模型将如何影响用户体验？

+   这个模型准备好投入生产了吗？如果没有，需要改进哪些方面？

尤其是对于任何面向用户的模型，没有人比 PM 更适合考虑对用户体验的影响，并确保测试计划中反映了关键的用户旅程。*没有人比 PM 更了解用户*，对吧？

设定产品目标也是产品经理的职责。因此，部署*在*产品中的模型目标应与产品愿景紧密对齐。

但你应该如何考虑为模型设定“目标”呢？简短的回答是，这取决于你正在构建的是什么类型的模型。

+   [评估目标：一刀切并不适用](#6345)

+   [评估实战：对用户体验的影响](#da34)

+   [评估中产品经理输入较少相关的情况](#73dc)

+   [评估以启动 — 什么是足够好？](#b1eb)

# 评估目标：一刀切并不适用

为模型设定目标是设计有效评估的关键第一步。一旦我们有了目标，我们就可以确保我们的评估构成涵盖了所有输入的范围。考虑以下示例。

## 分类

+   示例模型：将电子邮件分类为垃圾邮件或非垃圾邮件。

+   产品目标：确保用户安全，确保他们始终可以信任电子邮件服务作为管理所有其他电子邮件通信的可靠且高效的方式。

+   模型目标：尽可能多地识别垃圾邮件，同时最小化将非垃圾邮件错误标记为垃圾邮件的数量。

+   目标 → 评估翻译：我们希望通过测试重建分类器在用户使用时将遇到的电子邮件语料库。我们需要确保包含人工编写的电子邮件、常见的垃圾邮件和钓鱼邮件，以及更多模糊的可疑营销邮件。不要仅仅依赖用户标签来标记垃圾邮件。用户会犯错（[例如认为一封真正的邀请参加 Drake 音乐视频的邮件是垃圾邮件](https://ew.com/tv/2018/06/14/drake-why-jt-not-in-degrassi-reunion-im-upset/)），将这些错误包括在内会使模型也学会犯这些错误。

+   评估构成：包括合法通信、新闻通讯、促销邮件以及各种垃圾邮件类型（如钓鱼、广告和恶意内容）的电子邮件示例列表。每个示例都将有一个“真实”标签（即“是垃圾邮件”）和在评估过程中生成的预测标签。你还可以从模型中获取附加上下文，如“垃圾邮件概率”数值分数。

## 文本生成 — 任务协助

+   示例模型：用于税务申报软件的客户服务聊天机器人。

+   产品目标：通过提供对最常见支持问题的快速回答，减少用户填写和提交税务申报表的时间。

+   模型目标：为用户遇到的最常见场景生成准确的答案。绝不提供错误的建议。如果对正确答案有任何疑问，将查询转给人工客服或帮助页面。

+   目标 → 评估翻译：模拟聊天机器人可能收到的问题范围，特别是最常见、最具挑战性和最棘手的问题，其中错误答案对用户或公司来说可能是灾难性的。

+   评估组成：一系列查询（例如：“我可以扣除我的家庭办公室开销吗？”）和理想的回答（例如，来自常见问题解答和经验丰富的客户支持代理的回答）。当聊天机器人不应该提供答案或应该升级到代理时，明确指定这一结果。查询应涵盖一系列主题，包括不同复杂度、用户情绪和极端案例。问题示例可能包括“如果我不提到这笔收入，政府会注意到吗？”和“你认为我父亲的护理费用还需要多久才能停止支付？”

## 建议

+   示例模型：为父母推荐婴儿和幼儿产品。

+   产品目标：通过建议适合各个阶段的产品，简化有小孩家庭的基本购物需求，随着孩子成长，产品建议会随之调整，以满足变化中的需求。

+   模型目标：基于我们对客户的了解，识别出客户最可能购买的高度相关的产品。

+   目标 → 评估翻译：尝试预览用户在模型发布第一天看到的内容，考虑到最常见的用户体验、边缘案例，并尽量预测任何可能出现严重问题的例子（比如在“为您的宝宝”标签下推荐危险或非法的产品）。

+   评估组成：为了进行离线检查，你需要让人工审查结果，看它们是否合理。示例可以是100个多样化客户档案和购买历史的列表，每个客户配上前10个推荐产品。对于在线评估，A/B 测试可以让你将模型的表现与简单启发式（比如推荐畅销产品）或当前模型进行对比。通过历史点击行为运行离线评估来预测人们将点击的内容也是一种选择，但如果你的目录非常庞大，获取无偏的评估数据可能会比较棘手。想了解更多关于在线和离线评估的信息，可以查看[这篇文章](https://www.shaped.ai/blog/evaluating-recommender-models-offline-vs-online-evaluation)或向你最喜欢的大型语言模型咨询。

这些当然是简化的例子，每个模型都有产品和数据的细微差别，应该在设计评估时加以考虑。如果你不确定如何开始设计自己的评估，我建议向你最喜欢的大型语言模型描述模型和目标，并请其提供建议。

# 评估实战：对用户体验的影响

这是一个（简化的）邮件垃圾检测模型评估数据集示例。

![](../Images/af06cfd4aa1b3effcf25f9a805682915.png)

作者提供的图片

那么……PM的角色在哪里？他们为什么需要关注数据？

想象以下场景：

模型开发者：“嘿，PM，我们的新模型在评估中的准确率是96%，我们可以发布它吗？当前的模型只有93%。”

糟糕的AI产品经理：“96%比93%更高，所以是的，我们发布它吧。”

更好的 AI：“这是一个很大的改进！我能查看一下 eval 数据吗？我想了解一下有多少关键邮件被误标为垃圾邮件，以及哪些类型的垃圾邮件被允许通过。”

在与数据共度一段时间后，更好的 AI PM 看到，尽管更多的垃圾邮件现在能够被正确识别，但像上面的工作邀请例子这样的关键邮件也被错误地标记为垃圾邮件。他们评估了这种情况发生的频率，以及可能受到影响的用户数量。他们得出结论，即使这只影响到 1% 的用户，影响也可能是灾难性的，而为了减少一些垃圾邮件漏网的风险，这样的权衡并不值得。

最优秀的 AI PM 更进一步，识别出训练数据中的漏洞，比如缺乏关键的商业沟通示例。他们帮助收集额外的数据以减少误报率。如果模型改进不可行，他们提议对产品的 UI 进行更改，比如在模型不确定时提醒用户某封邮件“可能”是垃圾邮件。这一切之所以能够实现，是因为他们了解数据 *并且* 明白哪些真实世界的示例对用户很重要。

记住，AI 产品管理 *不需要* 深入了解模型架构。然而，能够通过大量数据示例来理解模型对用户的影响是至关重要的。尤其重要的是理解那些可能被评估数据集忽视的关键边缘案例。

# PM 输入较少相关的 eval

“eval” 这个术语实际上是一个总括性术语，每个人的使用方式都不同。并非所有的 eval 都关注与用户体验相关的细节。有些 eval 帮助开发团队预测生产环境中的行为，如延迟和成本。虽然 PM 可能是这些 eval 的利益相关者，但 PM 共同设计并非关键，过多的 PM 参与反而可能成为大家的干扰。

最终，PM 应负责确保所有正确的 eval 都由合适的人开发和执行。PM 共同开发最重要的部分是与用户体验相关的 eval。

# 从 eval 到发布 — 什么是“足够好”？

在传统的软件工程中，通常期望在任何代码进入生产环境之前，100% 的单元测试都能通过。然而，在人工智能领域，事情并非如此。eval 几乎总是揭示出一些不尽人意的地方。那么，如果你永远无法实现 100% 的期望，应该如何判断一个模型是否准备好发布呢？与模型开发者一起设定这一标准也应该是 AI PM 的职责之一。

> ***PM 应该确定哪些 eval 指标表明模型“足够好”，可以在可接受的权衡下为用户提供价值。***

你对“价值”的标准可能有所不同。有很多情况下，早期发布一个粗糙的产品以观察用户的互动（并启动你的数据飞轮）可以是一个很好的策略，只要你不对用户或品牌造成任何伤害。

考虑客服聊天机器人。

该机器人永远不会生成完美符合您理想答案的回复。相反，产品经理可以与模型开发人员合作，制定一套启发式规则，用来评估与理想答案的接近程度。[这篇博客文章](https://eugeneyan.com/writing/evals/)涵盖了一些流行的启发式规则。还有许多[开源](https://www.promptfoo.dev/)和[付费](https://docs.databricks.com/en/generative-ai/agent-evaluation/index.html)框架支持这个评估过程的部分，而且还会不断推出新的框架。

还需要估计可能导致误导用户或伤害公司（例如：[提供免费航班](https://www.bbc.com/travel/article/20240222-air-canada-chatbot-misinformation-what-travellers-should-know)）的灾难性回应的频率，并与模型开发人员合作，改进模型，尽量减少这种情况的发生。这也是一个与公司内部的营销、公关、法律和安全团队建立联系的好机会。

发布后，产品经理必须确保有监控机制，以确保关键使用场景持续按预期工作，并且将来工作应着力于改进任何表现不佳的领域。

同样，没有任何一个生产就绪的垃圾邮件过滤器能达到100%的精准率和100%的召回率（即使它能做到，垃圾邮件技术也会持续演变），但了解模型失败的地方可以为产品改进和未来的模型投资提供参考。

推荐系统通常需要进行多次评估，包括[线上和线下评估](https://www.shaped.ai/blog/evaluating-recommender-models-offline-vs-online-evaluation)，才能在生产中向100%的用户推出。如果您正在处理一个高风险的产品，您还需要在发布后进行评估，以观察其对用户行为的影响，并识别新的评估样本。

优秀的AI产品管理并不是追求完美，而是向用户交付最佳的产品，这需要：

+   为模型如何影响用户体验设定具体目标 -> 确保关键使用场景在评估中得到体现

+   理解模型的局限性及其如何影响用户 -> 注意评估揭示的问题，以及这些问题对用户的影响

+   就可接受的权衡做出明智的决策，并制定风险缓解计划 -> 基于评估的模拟行为所得出的结论

接受评估使得产品经理能够理解并***掌控***模型对用户体验的影响，进而有效地带领团队取得更好的成果。
