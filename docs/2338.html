<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Doctors Leverage Multimodal Data; Medical AI Should Too</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Doctors Leverage Multimodal Data; Medical AI Should Too</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/doctors-leverage-multimodal-data-medical-ai-should-too-6475c247b243?source=collection_archive---------6-----------------------#2024-09-25">https://towardsdatascience.com/doctors-leverage-multimodal-data-medical-ai-should-too-6475c247b243?source=collection_archive---------6-----------------------#2024-09-25</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="34e1" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Integrating multimodal data enables a new generation of medical AI systems to better capture doctor’s thoughts and decision process</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@fimafurman?source=post_page---byline--6475c247b243--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Fima Furman" class="l ep by dd de cx" src="../Images/5d25a93fa0bf4f5ebb2c7a684709635c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*GFSkV7m1KBY4ST6DcGh3gQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--6475c247b243--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@fimafurman?source=post_page---byline--6475c247b243--------------------------------" rel="noopener follow">Fima Furman</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--6475c247b243--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 25, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">3</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/83f1507bf05f76192dccc5587b6cabed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9Azt1mD0VsjU7GQy"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Illustration of data types and applications of multimodal medical AI. Image by the author.</em></figcaption></figure><p id="fd23" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A multimodal AI model leverages data from various formats, such as text, images, and audio, to give users a more comprehensive understanding of a medical situation. These models are proliferating due to their ability to process and integrate multiple data types, painting a more holistic picture of health than any single data type can create. With the rise of transformer architectures and large language models (LLMs), broadly generalizable across data modalities, developers are gaining new tools to synthesize these data formats. Google’s <a class="af nz" href="https://blog.google/technology/ai/google-gemini-ai/" rel="noopener ugc nofollow" target="_blank">Gemini multimodal AI</a> and other cutting-edge generative AI models seamlessly understand and synthesize data formats across text, video, image, audio, and codes (genetic or computational). While there have been exciting developments in medical AI over the past several years, adoption has been slow, and existing applications are often targeted at very specific and narrow use cases. The future of medical AI lies in multimodal applications because they mirror the clinical process of doctors, who must consider many factors and data sources when making evaluations. Developers and companies who can execute in this space of immense potential will occupy a vital role in the future of AI-assisted medicine.</p><h1 id="4038" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Benefits of working with multimodal data</h1><p id="c5b8" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Medical data is inherently multimodal, and AI systems should reflect this reality. When evaluating patients, Doctors leverage various data sources, such as patient notes, medical images, audio recordings, and genetic sequences. Traditionally, AI applications have been designed to handle specific, narrowly defined tasks within these individual data types. For instance, an AI system might excel at identifying lung nodules on a CT scan, but it cannot integrate that data with a patient’s reported symptoms, family history, and genetic information to assist a doctor in diagnosing lung cancer. By contrast,<a class="af nz" href="https://www.nature.com/articles/s41591-022-01981-2" rel="noopener ugc nofollow" target="_blank"> multimodal AI applications can integrate diverse data types, combining the flexibility of LLMs with the specialized expertise of specialist AI systems</a>. Such systems also outperform single-modal AI systems on traditional AI tasks, with studies showing an<a class="af nz" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9489871/" rel="noopener ugc nofollow" target="_blank"> improvement in accuracy of 6–33%</a> for multimodal systems.</p><p id="61b3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Multimodal AI models also work to break down silos between medical specialties. The evolution of medicine, driven by increasing specialization and proliferating research and data, has created a fragmented landscape where different fields, such as radiology, internal medicine, and oncology, can operate in silos. Caring for patients with complex diseases often requires collaboration across a large team of specialists, and critical insights can be lost due to poor communication. Multimodal AI models bridge these gaps by capturing knowledge from across specialties to ensure that patients benefit from the latest advances in medical knowledge in all relevant fields.</p><h1 id="96d8" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Overview of different medical data modalities</h1><p id="9d04" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Medical data comprise over 30% of all data produced worldwide and come in many forms. Some of the most prominent forms are listed below (non-exhaustive):</p><p id="48ad" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Medical Images</strong></p><p id="fb2a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Medical imaging plays such a critical role in healthcare diagnosis and treatment planning that it has an entire specialty (radiology). CT scans and X-rays are commonly used for visualizing bone structures and detecting fractures or tumors, while ultrasounds are essential for monitoring fetal development and examining soft tissues. Doctors use pathology slide images to analyze tissue samples for diseases like cancer. AI algorithms like convolutional neural networks (CNNs) learn to identify patterns and anomalies in these images by processing large volumes of labeled images. Such tools help radiologists and other doctors to make faster and more accurate interpretations of images.</p><p id="1b04" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Omics</strong></p><p id="045c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Omics data, including genomics, transcriptomics, and proteomics, has exploded in recent years thanks to falling sequencing costs. It has revolutionized personalized medicine by providing insights into the molecular underpinnings of diseases. In a multimodal medical AI system, omics data can be used to better understand patients’ susceptibility to certain diseases and potential responses to treatment options. For example, specific mutations in the BRCA genes indicate that a patient is significantly more likely to develop certain forms of cancer.</p><p id="767e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Patient &amp; EHR Notes</strong></p><p id="f84a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Traditionally, patient notes (clinical observations, treatment plans, etc.) have been challenging to analyze because of their lack of structure. However, LLMs can use these notes to extract insights, identify patterns, and support new large-scale data analysis that would have been impossible before. For example, LLMs can read through notes on potential patients for a clinical trial and identify those who meet eligibility requirements — a previously labor-intensive task.</p><p id="b9f3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Wearable Device Data</strong></p><p id="c8ea" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Health monitoring sensors, such as wearable fitness trackers, measure vital signs like heart rate, blood pressure, sleep patterns, and glucose levels over time. AI applications can analyze these time series to detect trends and predict health events. Such applications help patients by offering personalized health recommendations and helping doctors monitor patients’ conditions outside the hospital setting.</p><p id="5d3e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Audio Recordings</strong></p><p id="3111" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Audio recordings, such as heart and lung auscultations, are commonly used to diagnose certain forms of disease. Doctors use heart auscultations to tag the range and intensity of heart murmurs, while lung auscultations can help identify conditions such as pneumonia. AI systems can analyze these audio recordings to detect abnormalities and assist in faster and cheaper diagnosis.</p><p id="0e3a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Pathology</strong></p><p id="7729" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Pathology data, derived from tissue samples and microscopic images, play a critical role in diagnosing diseases such as cancer. AI algorithms can analyze these data sources to identify abnormal cell structures, classify tissue types, and detect patterns indicative of disease. By processing vast amounts of pathology data, AI can assist pathologists in making more accurate diagnoses, flagging potential areas of concern, and even predicting disease progression. In fact, a team of researchers at Harvard Medical School and MIT recently launched a <a class="af nz" href="https://www.nature.com/articles/s41586-024-07618-3" rel="noopener ugc nofollow" target="_blank">multimodal generative AI copilot for human pathology</a> to assist pathologists with common medical tasks.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk pb"><img src="../Images/1f87f76ed91f584f102c0f133de95932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AWHr7K3UeAYiZvRo"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Example of integrated annotated image and text data. Image by the author.</em></figcaption></figure><h1 id="1a94" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Applications of multimodal AI models</h1><p id="f030" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Multimodal algorithms have the potential to unlock a new paradigm in AI-powered medical applications. One promising application of multimodal AI is personalized medicine, where a system leverages data such as a patient’s condition, medical history, lifestyle, and genome to predict the most effective treatments for a particular patient. Consider an application designed to identify the most effective treatment options for a lung cancer patient. This application could consider the patient’s genetic profile, pathology (tissue sample) images and notes, radiology images (lung CT scans) and notes, and medical history clinical notes (to collect factors like smoking history and environmental impacts). Using all these data sources, the application could recommend the treatment option with the highest efficacy for a patient’s unique profile. Such an approach has already shown promising results in a<a class="af nz" href="https://www.nature.com/articles/s41598-018-34753-5" rel="noopener ugc nofollow" target="_blank"> study by Huang et. al</a>, where the researchers could predict patients’ responses to standard-of-care chemotherapeutic drugs based on their gene expression profiles with &gt;80% accuracy. This approach will help maximize treatment effectiveness and reduce the trial-and-error approach often associated with finding the proper medication or intervention.</p><p id="615d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Another critical use case is improving speed and accuracy for diagnosis and prognosis. By integrating data sources such as medical imaging, lab results, and patient notes, multimodal medical AI systems can assist doctors with holistic insights. For example,<a class="af nz" href="https://www.tempus.com/cardiology/" rel="noopener ugc nofollow" target="_blank"> Tempus Next</a> leverages waveform data from echocardiograms and ECGs, EHR text data, and abdominal radiological images (CT scans, ultrasounds) to help cardiologists diagnose and predict patient risk for heart issues like abdominal aortic aneurysms and atrial fibrillation.<a class="af nz" href="https://optellum.com/products-and-solutions/lung-cancer-prediction-ai/" rel="noopener ugc nofollow" target="_blank"> Optellum’s Virtual Nodule Clinic</a> is taking a similar approach to assist in diagnosing lung cancer using CT scans and clinical notes. Applications like these both improve diagnosis accuracy and save doctors time, thereby helping to address the ongoing physician shortage and drive down healthcare costs.</p><p id="53e8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Multimodal AI will also enable great advances in remote patient monitoring and telemedicine by integrating data from wearable devices, home monitoring systems, and patient self-reported notes to provide continuous, real-time insights into a patient’s health status. This capability is particularly valuable for managing chronic conditions, where ongoing monitoring can detect early signs of deterioration and prompt timely interventions. For example, an AI system might monitor a patient’s sleep data from an<a class="af nz" href="https://www.eightsleep.com/" rel="noopener ugc nofollow" target="_blank"> Eight Sleep Pod</a> and blood glucose data from<a class="af nz" href="https://www.levelshealth.com/#how-it-works" rel="noopener ugc nofollow" target="_blank"> Levels</a> (continuous glucose monitoring) to identify deterioration in a patient with pre-diabetes. Doctors can use this early warning to make proactive recommendations to help patients avoid further declines. This technology will help reduce hospital readmissions and improve the overall management of chronic diseases, making healthcare more accessible and reducing the overall load on the healthcare system.</p><h1 id="9155" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Approaches to building multimodal AI models</h1><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/2609004ae6b6b4e3e6f64ecadeeecc1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nl2SZY2pNNDcS_nh"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx"><em class="nc">Illustration of different approaches to building multimodal systems. Image by the author.</em></figcaption></figure><p id="31af" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Researchers are currently experimenting with different approaches to building multimodal medical AI systems, and research is still in its preliminary stages. Three<a class="af nz" href="https://research.google/blog/multimodal-medical-ai/" rel="noopener ugc nofollow" target="_blank"> primary methods of developing systems explored by teams at Google are</a>:</p><ul class=""><li id="82b0" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pc pd pe bk"><strong class="nf fr">Tool Use</strong> — In this approach, a master LLM outsources the analysis of different data sources to specialized software subsystems trained on that data form. For example, an LLM might forward a chest X-ray to a radiology AI system and ECG analysis to a specialized waveform analysis system and then integrate the responses with patient notes to evaluate heart health. This method allows for flexibility and independence between subsystems, enabling the use of best-in-class tools for each specific task.</li><li id="d66f" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Model Grafting</strong> — This method involves adapting specialized neural networks for each relevant domain and integrating them directly into the LLM. For instance, a neural network trained to interpret medical images can be grafted onto an LLM by mapping its output directly to the LLM’s input space. This approach leverages existing optimized models and allows for modular development, although it requires creating adapters for each specific model and domain.</li><li id="451e" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Generalist Systems</strong> — The most ambitious approach involves building a single, integrated system capable of processing all data modalities natively. This method uses a unified model,<a class="af nz" href="https://arxiv.org/abs/2307.14334" rel="noopener ugc nofollow" target="_blank"> such as Med-PaLM M</a>, which combines a language model with a vision encoder to handle diverse data types. While this approach maximizes flexibility and information transfer, it also comes with higher computational costs and potential challenges in domain specialization and system debuggability.</li></ul><h1 id="5e50" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Challenges to implementing multimodal AI models</h1><p id="aefe" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">While building multimodal AI models holds great promise, there are multiple challenges to implementing working systems. Some challenges include:</p><ul class=""><li id="d840" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pc pd pe bk"><strong class="nf fr">Data Annotation </strong>— To enable supervised learning, machine learning algorithms require data annotated by expert human labelers with the correct features identified. It can be challenging to identify experts across domains to label different sorts of data modalities. Model builders should consider partnering with dedicated data annotation providers with expertise across modalities, such as <a class="af nz" href="https://hubs.li/Q02Qjm9S0" rel="noopener ugc nofollow" target="_blank">Centaur Labs</a>.</li><li id="9933" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Avoiding Bias — </strong>One of the most significant risks to deploying AI systems in medical contexts is their potential to exacerbate existing biases and inequities in healthcare. Multimodal systems may further ingrain bias because underrepresented populations are more likely to have missing data across one or more modalities a system is built for. To avoid bias, model builders should consider<a class="af nz" rel="noopener" target="_blank" href="/data-curation-practices-to-minimize-bias-in-medical-ai-379bf6983de2"> techniques to minimize bias in their AI applications</a>.</li><li id="a527" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Regulation — </strong>Data privacy regulations like HIPAA impose strict controls on the sharing and use of patient data, making it challenging for developers to integrate and associate data across different modalities. This necessitates additional development efforts to ensure compliance.</li><li id="b03c" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Adoption and Trust — </strong>Many traditional AI systems have found the greatest hurdle to impact is driving adoption and trust within the community of medical users. Doctors are concerned about the accuracy and consistency of AI outputs and do not want to endanger patient health by placing trust in these systems before they use them to inform patient care. Multimodal AI models will face similar hurdles towards adoption. Developers must coordinate closely with end users of such systems to drive trust and ensure that systems fit into existing clinical workflows.</li><li id="302b" class="nd ne fq nf b go pf nh ni gr pg nk nl nm ph no np nq pi ns nt nu pj nw nx ny pc pd pe bk"><strong class="nf fr">Lack of Data Format Sharing Standardization — </strong>For many data formats (e.g., tissue images), there are no standardized protocols for sharing data between different providers. This lack of interoperability can hinder the integration of data sources necessary for developing robust AI models. To expedite the development and adoption of AI systems operating in (currently) unstandardized medical data domains, the research and development community should develop universal standards/frameworks for data sharing and ensure compliance across institutions.</li></ul><h1 id="452c" class="oa ob fq bf oc od oe gq of og oh gt oi oj ok ol om on oo op oq or os ot ou ov bk">Conclusion</h1><p id="81c0" class="pw-post-body-paragraph nd ne fq nf b go ow nh ni gr ox nk nl nm oy no np nq oz ns nt nu pa nw nx ny fj bk">Multimodal AI represents the future of medical applications, offering the potential to revolutionize healthcare by expanding applications’ flexibility, accuracy, and capabilities through integrated and holistic data use. If these applications are effectively developed and deployed, they promise to cut medical costs, expand accessibility, and deliver higher-quality patient care and outcomes.</p><p id="fa05" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The most tremendous advances in knowledge and technology often come when from synthesizing insights from different fields. Consider<a class="af nz" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3361109/" rel="noopener ugc nofollow" target="_blank"> Leonardo Da Vinci, who used his knowledge of drawing and fluid dynamics to inform his studies of the heart and physiology</a>. Medical AI is no different. By integrating discoveries from computer science into medicine, developers unleashed an initial wave of breakthroughs. Now, the promise of integrating multiple data modalities will create a second wave of innovation fueled by ever-smarter AI systems.</p></div></div></div></div>    
</body>
</html>