<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Bayesian Sensor Calibration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Bayesian Sensor Calibration</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-sensor-calibration-9ef53e6c6271?source=collection_archive---------5-----------------------#2024-05-01">https://towardsdatascience.com/bayesian-sensor-calibration-9ef53e6c6271?source=collection_archive---------5-----------------------#2024-05-01</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="a97f" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A hands-on tutorial in Python for sensor engineers</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://gcl-75380.medium.com/?source=post_page---byline--9ef53e6c6271--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Gael Close" class="l ep by dd de cx" src="../Images/48277f8865e4e5f9e092640a12cf1770.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*UiL9D4zAYcla8G9ffADJzQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9ef53e6c6271--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://gcl-75380.medium.com/?source=post_page---byline--9ef53e6c6271--------------------------------" rel="noopener follow">Gael Close</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9ef53e6c6271--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 1, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="11a2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">With contributions from <a class="af nf" href="https://orcid.org/0000-0003-3282-9609" rel="noopener ugc nofollow" target="_blank">Moritz Berger</a>.</p><blockquote class="ng nh ni"><p id="14ab" class="mj mk nj ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Bayesian sensor calibration is an emerging technique combining statistical models and data to optimally calibrate sensors — a crucial engineering procedure. This tutorial provides the Python code to perform such calibration numerically using existing libraries with a minimal math background. As an example case study, we consider a magnetic field sensor whose sensitivity drifts with temperature.</p></blockquote><p id="0f4f" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Glossary. </strong>The bolded terms are defined in the International Vocabulary of Metrology (known as the “<a class="af nf" href="https://jcgm.bipm.org/vim/en/" rel="noopener ugc nofollow" target="_blank">VIM definitions</a>”). Only the first occurrence is in bold.</p><p id="f9c9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Code availability. </strong>An executable Jupyter notebook for the tutorial is available on Github. It can be accessed via <a class="af nf" href="https://nbviewer.org/gist/gael-close/fc2a30b37bacc82a9713f69da1f81bf7/2307-sensor-calib.ipynb#" rel="noopener ugc nofollow" target="_blank">nbviewer</a>.</p><h1 id="c40c" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Introduction</h1><p id="f5cd" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk"><strong class="ml fr">CONTEXT</strong>. Physical sensors provide the primary inputs that enable systems to make sense of their environment. They measure physical quantities such as temperature, electric current, power, speed, or light intensity. A <strong class="ml fr">measurement result</strong> is an estimate of the true value of the measured quantity (the so-called <strong class="ml fr">measurand</strong>). Sensors are never perfect. Non-idealities, part-to-part variations, and random noise all contribute to the sensor error. Sensor <strong class="ml fr">calibration</strong> and the subsequent <strong class="ml fr">adjustment</strong> are critical steps to minimize sensor <strong class="ml fr">measurement uncertainty</strong>. The Bayesian approach provides a mathematical framework to represent uncertainty. In particular, how uncertainty is reduced by “smart” calibration combining prior knowledge about past samples and the new evidence provided by the calibration. The math for the exact analytical solution can be intimidating (Berger 2022), even in simple cases where a sensor response is modeled as a polynomial transfer function with noise. Luckily, Python libraries were developed to facilitate Bayesian statistical modeling. Hence, Bayesian models are increasingly accessible to engineers. While hands-on tutorials exist (Copley 2023; Watts 2020) and even textbooks (Davidson-Pilon 2015; Martin 2021), they lack sensor calibration examples.</p><p id="01c2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">OBJECTIVE. </strong>In this article, we aim to reproduce a simplified case inspired by (Berger 2002) and illustrated in the figure below. A sensor is intended to measure the current <em class="nj">i</em> flowing through a wire via the measurement of the magnetic field <em class="nj">B </em>which is directly proportional to the current. We focus on the magnetic sensor and consider the following non-idealities. (1) The temperature <em class="nj">B</em> is a parasitic <strong class="ml fr">influence quantity</strong> disturbing the measurement. (2) The sensor response varies from one sensor to another due to part-to-part manufacturing variations. (3) The sensed data is polluted by <strong class="ml fr">random errors</strong>. Using a Bayesian approach and the high-level <a class="af nf" href="https://www.pymc.io/welcome.html" rel="noopener ugc nofollow" target="_blank">PyMC</a> Python library, we seek to calculate the optimum set of calibration parameters for a given calibration dataset.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om on"><img src="../Images/8dc3caeb56b1dd6cec8d725fc2391c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1e6NPQUqf1Z6x7eA6QNrg.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">(a) Electric current sensor application. (b) Functional view (Image by author).</figcaption></figure><h1 id="b44d" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Mathematical formulation</h1><p id="90da" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">We assume that the magnetic sensor consists of a magnetic and temperature transducer, which can be modeled as polynomial transfer functions with coefficients varying from one sensor to the next according to normal probability distributions. The raw sensed data (called “<strong class="ml fr">indications</strong>” in the VIM), represented by the vector <strong class="ml fr"><em class="nj">u</em></strong>, consists of the linearly sensed magnetic field <em class="nj">S(T)</em>⋅<em class="nj">B</em> and a dimensionless sensed quantity <em class="nj">V_T</em> indicative of the temperature. We use the specific form <em class="nj">S(T)</em>⋅<em class="nj">B </em>to highlight that the sensitivity <em class="nj">S</em> is influenced by the temperature. The parasitic influence of the temperature is illustrated by the plot in panel (a) below. Ideally, the sensitivity would be independent of the temperature and of <em class="nj">V_T</em>. However, there is a polynomial dependency. The case study being inspired from a real magnetic Hall sensor, the sensitivity can vary by ±40% from its value at room temperature in the temperature range [−40°C, +165°C]. In addition, due to part-to-part variations, there is a set of curves <em class="nj">S</em> vs <em class="nj">V_T</em> instead of just one curve. Mathematically, we want to identify the measurement function returning an accurate estimate of the true value of the magnetic field — like shown in panel (b). Conceptually, this is equivalent to inverting the sensor response model. This boils down to estimating the temperature-dependent sensitivity and using this estimate <em class="nj">Ŝ</em> to recover the field from the sensed field by a division.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om pe"><img src="../Images/d290b1d56787eeaefb86e3c67b3e3f50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wcVdaD5k54AqC1Cpwn9e8g.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">(a) Raw responses of N=30 sensors. (b) Block diagram (image by author).</figcaption></figure><p id="3934" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">For our simplified case, we consider that <em class="nj">S(T)</em> and <em class="nj">VT(T)</em> are second-order polynomials. The polynomial coefficients are assumed to vary around their nominal values following normal distributions. An extra random noise term is added to both sensed signals. Physically, <em class="nj">S </em>is the sensitivity relative to its value at room temperature, and <em class="nj">VT</em> is a normalized voltage from a temperature sensor. This is representative of a large class of sensors, where the primary transducer is linear but temperature-dependent, and a supplementary temperature sensor is used to correct the parasitic dependence. And both transducers are noisy. We assume that a third-order polynomial in <em class="nj">VT</em> is a suitable candidate for the sensitivity estimate <em class="nj">Ŝ:</em></p><p id="6e58" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><em class="nj">Ŝ = w_0 + w_1</em>⋅Δ<em class="nj">T + w_2</em>⋅Δ<em class="nj">T</em>²<em class="nj"> + w_3</em>⋅Δ<em class="nj">T</em>³, where Δ<em class="nj">T</em> = <em class="nj">T</em>−25°C.</p><p id="48d8" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The weight vector <strong class="ml fr"><em class="nj">w</em></strong> aggregates the 4 coefficients of the polynomial. These are the calibration parameters to be adjusted as a result of calibration.</p><h1 id="f8af" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Python formulation</h1><p id="28b2" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">We use the code convention introduced in (Close, 2021). We define a data dictionary <code class="cx pf pg ph pi b">dd</code> to store the nominal value of the parameters. In addition, we define the probability density functions capturing the variability of the parameters. The sensor response is modeled as a transfer function, like the convention introduced in (Close 2021).</p><pre class="oo op oq or os pj pi pk bp pl bb bk"><span id="8684" class="pm nl fq pi b bg pn po l pp pq"># Data dictionary: nominal parameters of the sensor response model<br/>def load_dd():<br/>  return Box({<br/>    'S'  : {<br/>      'TC'   :   [1, -5.26e-3, 15.34e-6],<br/>      'noise':   0.12/100,  },<br/>    'VT': {<br/>      'TC':      [0, 1.16e-3, 2.78e-6],<br/>      'noise':   0.1/100,}  <br/>  })<br/><br/># Probability density functions for the parameter variations<br/>pdfs = {<br/>    'S.TC': (norm(0,1.132e-2), norm(0,1.23e-4), norm(0,5.40e-7)),<br/>    'VT.TC'   : (norm(0,7.66e-6), norm(0,4.38e-7))<br/>}<br/><br/># Sensor response model<br/>def sensor_response_model(T, sensor_id=0, dd={}, delta={}):<br/>    S=np.poly1d(np.flip((dd.S.TC+delta.loc[sensor_id]['S.TC'])))(T-25)<br/>    S+=np.random.normal(0, dd.S.noise, size=len(T))<br/>    <br/>    VT = 10*np.poly1d(np.flip(dd.VT.TC+np.r_[0,delta.loc[sensor_id]['VT.TC'].values]))(T-25)<br/>    VT+= np.random.normal(0, dd.VT.noise, size=len(T))<br/>    <br/>    return {'S': S, 'VT': VT}<br/></span></pre><p id="af71" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can then simulate a first set of <em class="nj">N</em>=30 sensors by drawing from the specified probability distributions, and generate synthetic data in <code class="cx pf pg ph pi b">df1</code> to test various calibration approaches via a build function <code class="cx pf pg ph pi b">build_sensors(ids=[..]).</code></p><pre class="oo op oq or os pj pi pk bp pl bb bk"><span id="297a" class="pm nl fq pi b bg pn po l pp pq">df1,_=build_sensors_(ids=np.arange(30))</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om pr"><img src="../Images/07bb08da8b29b18480077a35eec02c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNHOXXOJF5J88RlwFzRbOg.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">Synthetic data generated by the probabilistic sensor response model (Image by author).</figcaption></figure><h1 id="5902" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk"><strong class="al">Classic approaches</strong></h1><p id="136a" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">We first consider two well-known classic calibration approaches that don’t rely on the Bayesian framework.</p><h2 id="4131" class="ps nl fq bf nm pt pu pv np pw px py ns ms pz qa qb mw qc qd qe na qf qg qh qi bk">Full regression</h2><p id="904c" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">The first calibration approach is a brute-force approach. A comprehensive dataset is collected for each sensor, with more calibration points than unknowns. The calibration parameters <strong class="ml fr"><em class="nj">w </em></strong>for each sensor (4 unknowns) are determined by a regression fit. Naturally, this approach provides the best results in terms of residual error. However, it is very costly in practice, as it requires a full characterization of each individual sensor. The following function performs the full calibration and store the weights as a list in the dataframe for convenience.</p><pre class="oo op oq or os pj pi pk bp pl bb bk"><span id="5f27" class="pm nl fq pi b bg pn po l pp pq">def full_calibration(df):<br/>    W = df.groupby("id").apply(<br/>        lambda g: ols("S ~ 1 + VT + I(VT**2)+ I(VT**3)", data=g).fit().params<br/>    )<br/>    W.columns = [f"w_{k}" for k, col in enumerate(W.columns)]<br/>    df["w"] = df.apply(lambda X: W.loc[X.name[0]].values, axis=1)<br/><br/>df1, W=full_calibration(df1)</span></pre><h2 id="908c" class="ps nl fq bf nm pt pu pv np pw px py ns ms pz qa qb mw qc qd qe na qf qg qh qi bk">Blind calibration</h2><p id="301a" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">A blind calibration represents the other extreme. In this approach, a first reference set of sensors is fully calibrated as above. The following sensors are not individually calibrated. Instead, the average calibration parameters <strong class="ml fr"><em class="nj">w0</em></strong><em class="nj"> </em>of the reference set is reused blindly.</p><pre class="oo op oq or os pj pi pk bp pl bb bk"><span id="7d4b" class="pm nl fq pi b bg pn po l pp pq">w0 = W.mean().values<br/><br/>df2,_=build_sensors_(ids=[0])<br/>def blind_calibration(df):<br/>    return df.assign(w=[w0]*len(df))<br/>df2 = blind_calibration(df2)</span></pre><p id="7c00" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The following plots illustrate the residual sensitivity error <em class="nj">Ŝ</em>−<em class="nj">S </em>for the two above methods. Recall that the error before calibration reaches up to 40%. The green curves are the sensitivity error for the <em class="nj">N</em>=30 sensors from the reference set. Apart from a residual fourth-order error (unavoidable to the limited order of the sensitivity estimator), the fit is satisfactory (&lt;2%). The red curve is the residual sensitivity error for a<em class="nj"> </em>blindly calibrated sensor. Due to part-to-part variation, the average calibration parameters provide only an approximate fit, and the residual error is not satisfactory.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qj"><img src="../Images/b18e83ef7ce003c1126893305d4b4fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GbL4C4O9ksKDF8nUyxgsGA.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">Residual sensitivity error for N=30 fully calibrated and N=1 blindly calibrated sensor. (Image by author).</figcaption></figure><h1 id="5f34" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Bayesian calibration</h1><p id="b8cb" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">The Bayesian calibration is an interesting trade-off between the previous two extremes. A reference set of sensors is fully calibrated as above. The calibration parameters for this reference set constitute some prior knowledge. The average <strong class="ml fr"><em class="nj">w0 </em></strong>and the covariance matrix <strong class="ml fr"><em class="nj">Σ</em></strong> encode some relevant knowledge about the sensor response. The weights are not independent. Some combinations are more probable than others. Such knowledge should be used in a smart calibration. The coverage matrix can be calculated and plotted (for just two weights) using the Pandas and Seaborn libraries.</p><pre class="oo op oq or os pj pi pk bp pl bb bk"><span id="d3d4" class="pm nl fq pi b bg pn po l pp pq">Cov0 = W.cov(ddof=len(W) - len(w0))<br/>sns.jointplot(data=W.apply(pd.Series),x='w_1', y='w_2', kind='kde', fill=True, height=4)</span></pre><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om qk"><img src="../Images/5d78dd3a8b71420b6667b07b65b205c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*IOyuVwDq2syxkGAUhiF__Q.png"/></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">Bivariate plot of the two weights w_1 and <em class="ql">w_2</em> (Image by author).</figcaption></figure><p id="02de" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The Bayesian framework enables us to capture this prior knowledge, and uses it in the calibration of the subsequent samples. We restart from the same blindly calibrated samples above. We simulate the case where just two calibration data points at 0°C and 100°C are collected for each new sensor, enriching our knowledge with new evidence. In practical industrial scenarios where hardware calibration is expensive, this calibration is cost-effective. A reduced reference set is fully characterized once for all to gather prior knowledge. The subsequent samples, possibly the rest of the volume production of this batch, are only characterized at a few points. In Bayesian terminology, this is called “inference”, and the PyMC library provides <a class="af nf" href="https://www.pymc.io/projects/examples/en/latest/variational_inference/variational_api_quickstart.html" rel="noopener ugc nofollow" target="_blank">high-level functions</a> to perform inference. It is a computation-intensive process because the posterior distribution, which is obtained by applying the Bayes’ theorem combining the prior knowledge and the new evidence, can only be sampled. There is no analytical approximation of the obtained probability density function.</p><p id="87fe" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The calibration results are compared below, with the blue dot indicating the two calibration points used by the Bayesian approach. With just two extra points and by exploiting the prior knowledge acquired on the reference set, the Bayesian calibrated sensor exhibits an error hardly degraded compared to the expensive brute-force approach.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qj"><img src="../Images/06fcaca7946254e5f37d1e216357a984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NQ698cRC8rb3fCMfSEfOvQ.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">Comparison of the three calibration approaches.</figcaption></figure><p id="f49c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Credible interval</strong></p><p id="6985" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the Bayesian approach, all variables are characterized by uncertainty in. The parameters of the sensor model, the calibration parameters, but also the <a class="af nf" href="https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/posterior_predictive.html#prediction" rel="noopener ugc nofollow" target="_blank">posterior predictions</a>. We can then construct a ±1σ credible interval covering 68% of the synthetic observations generated by the model for the estimated sensitivity <em class="nj">Ŝ. </em>This plot captures the essence of the calibration and adjustment: the uncertainty has been reduced around the two calibration points at <em class="nj">T</em>=0°C and <em class="nj">T</em>=100°C. The residual uncertainty is due to noisy measurements.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov ed ow bh ox"><div class="ol om qm"><img src="../Images/8543d89b7196bbdd7a6281e6dc802bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GhNB7MFYLj4A41XDQKC2BA.png"/></div></div><figcaption class="oz pa pb ol om pc pd bf b bg z dx">Credible interval (Image by author).</figcaption></figure><h1 id="9159" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">Conclusion</h1><p id="637d" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">This article presented a Python workflow for simulating Bayesian sensor calibration, and compared it against well-known classic approaches. The mathematical and Python formulations are valid for a wide class of sensors, enabling sensor design to explore various approaches. The workflow can be summarized as follows:</p><ol class=""><li id="b46d" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne qn qo qp bk"><strong class="ml fr">Model the sensor response</strong> in terms of transfer function and the parameters (nominal values and statistical variations). Generate corresponding synthetic raw sensed data for a batch of sensors.</li><li id="cfb3" class="mj mk fq ml b go qq mn mo gr qr mq mr ms qs mu mv mw qt my mz na qu nc nd ne qn qo qp bk"><strong class="ml fr">Define the form of the measurement function </strong>from the raw sensed variables. Typically, this is a polynomial, and the calibration should determine the optimum coefficients <strong class="ml fr"><em class="nj">w</em></strong> of this polynomial for each sensor.</li><li id="0dee" class="mj mk fq ml b go qq mn mo gr qr mq mr ms qs mu mv mw qt my mz na qu nc nd ne qn qo qp bk"><strong class="ml fr">Acquire some prior knowledge</strong> by fully characterizing a representative subset of sensors. Encode this knowledge in the form of average calibration parameters and covariance matrix.</li><li id="8600" class="mj mk fq ml b go qq mn mo gr qr mq mr ms qs mu mv mw qt my mz na qu nc nd ne qn qo qp bk"><strong class="ml fr">Acquire limited new evidence </strong>in the form of a handful of calibration points specific to each sensor.</li><li id="4292" class="mj mk fq ml b go qq mn mo gr qr mq mr ms qs mu mv mw qt my mz na qu nc nd ne qn qo qp bk"><strong class="ml fr">Perform Bayesian inference</strong> merging this new sparse evidence with the prior knowledge to find the most likely calibration parameters for this new sensor numerically using PyMC.</li></ol><p id="2ca2" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the frequent cases where sensor calibration is a significant factor of the production cost, Bayesian calibration exhibits substantial business benefits. Consider a batch of 1'000 sensors. One can obtain representative prior knowledge with a full characterization from, say, only 30 sensors. And then for the other 970 sensors, use a few calibration points only. In a classical approach, these extra calibration points lead to an undetermined system of equations. In the Bayesian framework, the prior knowledge fills the gap.</p><h1 id="94ac" class="nk nl fq bf nm nn no gq np nq nr gt ns nt nu nv nw nx ny nz oa ob oc od oe of bk">References</h1><p id="1e0e" class="pw-post-body-paragraph mj mk fq ml b go og mn mo gr oh mq mr ms oi mu mv mw oj my mz na ok nc nd ne fj bk">(Berger 2022) M. Berger, C. Schott, and O. Paul, “Bayesian sensor calibration,” <em class="nj">IEEE Sens. J.</em>, 2022. <a class="af nf" href="https://doi.org/10.1109/JSEN.2022.3199485." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/JSEN.2022.3199485.</a></p><p id="c2fc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(Close, 2021): G. Close, “Signal chain analysis in python: a case study for hardware engineers,” <em class="nj">Towards Data Science</em>, 22-Feb-2021. Available: <a class="af nf" rel="noopener" target="_blank" href="/signal-chain-analysis-in-python-84513fcf7db2.">https://towardsdatascience.com/signal-chain-analysis-in-python-84513fcf7db2.</a></p><p id="e29d" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(Copley 2023) C. Copley, “Navigating Bayesian Analysis with PyMC,” <em class="nj">Towards Data Science</em>, Jun-2023. <a class="af nf" href="https://charlescopley.medium.com/navigating-bayesian-analysis-with-pymc-87683c91f3e4" rel="noopener">https://charlescopley.medium.com/navigating-bayesian-analysis-with-pymc-87683c91f3e4</a></p><p id="f4e3" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(Davidson-Pilon 2015) C. Davidson-Pilon, “Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference,” <em class="nj">Addison-Wesley Professional</em>, 2015. <a class="af nf" href="https://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838" rel="noopener ugc nofollow" target="_blank">https://www.amazon.com/Bayesian-Methods-Hackers-Probabilistic-Addison-Wesley/dp/0133902838</a></p><p id="21cc" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(Martin 2021) O. A. Martin, R. Kumar, and J. Lao, “Bayesian Modeling and Computation in Python,”<em class="nj"> </em>Chapman and Hall/CRC, 2021. <a class="af nf" href="https://www.amazon.com/Bayesian-Modeling-Computation-Chapman-Statistical/dp/036789436X" rel="noopener ugc nofollow" target="_blank">https://www.amazon.com/Bayesian-Modeling-Computation-Chapman-Statistical/dp/036789436X</a></p><p id="b5c0" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">(Watts 2020) A. Watts, “PyMC3 and Bayesian inference for Parameter Uncertainty Quantification Towards Non-Linear Models: Part 2,” <em class="nj">Towards Data Science</em>, Jun-2022. <a class="af nf" rel="noopener" target="_blank" href="/pymc3-and-bayesian-inference-for-parameter-uncertainty-quantification-towards-non-linear-models-a03c3303e6fa">https://towardsdatascience.com/pymc3-and-bayesian-inference-for-parameter-uncertainty-quantification-towards-non-linear-models-a03c3303e6fa</a></p></div></div></div></div>    
</body>
</html>