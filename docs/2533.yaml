- en: 'GraphMuse: A Python Library for Symbolic Music Graph Processing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/graphmuse-a-python-library-for-symbolic-music-graph-processing-40dbd9baf319?source=collection_archive---------3-----------------------#2024-10-17](https://towardsdatascience.com/graphmuse-a-python-library-for-symbolic-music-graph-processing-40dbd9baf319?source=collection_archive---------3-----------------------#2024-10-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yes, music and graphs do mix!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://manoskary.medium.com/?source=post_page---byline--40dbd9baf319--------------------------------)[![Emmanouil
    Karystinaios](../Images/120d889f330aa7b433a0668a1224e1c8.png)](https://manoskary.medium.com/?source=post_page---byline--40dbd9baf319--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--40dbd9baf319--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--40dbd9baf319--------------------------------)
    [Emmanouil Karystinaios](https://manoskary.medium.com/?source=post_page---byline--40dbd9baf319--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--40dbd9baf319--------------------------------)
    ·11 min read·Oct 17, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1bdf8b9613e922ca5924dc48c06da0bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with Dall-E 3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this post, we take a look at one of my latest papers and open-source software:
    the GraphMuse Python library.'
  prefs: []
  type: TYPE_NORMAL
- en: But before we dive in, let me introduce you to some basics of symbolic music
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: '**And the story goes…**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Symbolic music processing mainly refers to extracting information from musical
    scores. The term symbolic refers to the symbols present in any form of musical
    score or notation. A musical score can contain a variety of elements other than
    notes. Such elements may include time signature, key signature, articulation markings,
    dynamic markings, and many others. Music scores can exist in many formats such
    as MIDI, MusicXML, MEI, Kern, ABC, and others.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, Graph Neural Networks (GNNs) have become increasingly popular
    and have seen success in many domains from biology networks to recommender systems
    to music analysis. In the music analysis field, GNNs have been used to solve tasks
    such as harmonic analysis, phrase segmentation, and voice separation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is simple: every note in a score is a vertex in the graph and edges
    are defined by the temporal relations between the notes as shown in the figure
    below.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/48885482c9c9d223613524bad345738a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The edges are separated into 4 categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Notes that start at the same time are connected by the “onset” edge (blue)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notes that start of at the end of some other note are connected by the “consecutive”
    edge (red)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notes that start in between the start and end of another note are connected
    the “during” edge (green)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, whenever there is silence all last note endings are connected to the
    first upcoming notes by the “silent” edge (yellow)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This minimal modeling of the graph guarantees that a score will be continuously
    connected from start to finish without any disconnected subgraphs.
  prefs: []
  type: TYPE_NORMAL
- en: What is GraphMuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraphMuse is a Python Library for training and applying deep graph models for
    music analysis on musical scores.
  prefs: []
  type: TYPE_NORMAL
- en: GraphMuse contains loaders, models, and utils for symbolic music processing
    with GNNs. It is built on top of *PyTorch* and *PyTorch Geometric* for more flexibility
    and interoperability.
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch is an open-source machine learning library that enables efficient deep
    learning model building and supports GPU acceleration. *PyTorch Geometric* is
    a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs)
    for a wide range of applications.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, GraphMuse provides functionalities to transform musical scores into
    graphs. Graph creation is implemented in C code with Python bindings to speedup
    the graph building, up to x300 faster than the previous numpy-based implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The Scientific Foundations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Graphs have been frequently used to analyze and represent music. To cite a few
    examples, the Tonnetz, Schenkerian analysis, and treelike form analysis are some
    notable mentions. The advantage of graphs is that they can capture both the hierarchical
    and the sequential nature of music with the same representation simply by the
    design of the edges.
  prefs: []
  type: TYPE_NORMAL
- en: Graph-based symbolic music processing using GNNs came about in 2021 with a performance
    generation model from the score. Since then many graph models have been introduced
    with some being the state-of-the-art for music analysis tasks up to the date of
    this post.
  prefs: []
  type: TYPE_NORMAL
- en: So, now that I argued for the necessity of graphs let’s face the complexities
    of designing and training graph models for symbolic music.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main complexity of graphs and of course, music is that musical pieces are
    not always of the same length and the graphs that are created from them are not
    the same size either. Their size might vary considerably: for example, a Bach
    chorale might have only 200 notes whereas a Beethoven sonata can have well over
    5000\. In our graphs, the number of notes corresponds directly to the number of
    vertices in each score graph.'
  prefs: []
  type: TYPE_NORMAL
- en: Training efficiently and fast on score graphs is not a trivial task and would
    require a sampling method that can maximize the computational resources in terms
    of both memory and time without deteriorating the performance of the model and
    sometimes even improving it.
  prefs: []
  type: TYPE_NORMAL
- en: In the training process, sampling involves combining graphs from different scores
    to create a new graph, often referred to as a “batch” in computer science. Each
    batch is then fed into the GNN model, where a loss is calculated. This loss is
    used to backpropagate and update the model’s parameters. This single iteration
    is called a training step. To optimize the model, this process is repeated many
    times until the training converges and ideally the model performs optimally.
  prefs: []
  type: TYPE_NORMAL
- en: This all sounds complicated but do not despair because GraphMuse can handle
    this part for you!!
  prefs: []
  type: TYPE_NORMAL
- en: The Inner Workings of GraphMuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/912423daa5f3dedfeb944cd7093845bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The general graph processing/training pipeline for symbolic music scores within
    GraphMuse involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Preprocess the database of scores to generate input graphs, GraphMuse can do
    this for you fast and easy;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sample the input graphs to create memory-efficient batches, again GraphMuse
    got your back;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Form a batch as a new graph with nodes and edges from various sampled input
    graphs; For each graph, a set of nodes is selected which we call *target nodes.*
    The neighbors of the target nodes can also be fetched by demand in a process called
    node-wise sampling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the target nodes’ representations through graph convolution to create
    node embeddings. GraphMuse provides some models that you can use, otherwise PyTorch
    Geometric can also be your friend;
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use these embeddings for task-specific applications. This part is on you but
    I am sure you can make it!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that target nodes may include all or a subset of batch nodes depending
    on the sampling strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the process is graphically explained let’s take a closer look at how
    GraphMuse handles sampling notes from each score.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bd9eb450636f4f2dc08991ca19ba827a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Top: sampled notes and their neighbors; Middle: score graph and sampling process;
    Bottom: sampling process for beats and measures.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling process per score.**'
  prefs: []
  type: TYPE_NORMAL
- en: A randomly selected note (in yellow) is first sampled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The boundaries of the target notes are then computed with a budget of 15 notes
    in this example (pink and yellow notes).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then the k-hop neighbors are fetched for the targets (light blue for 1-hop and
    darker blue for 2-hop). The k-hop neighbors are computed with respect to the input
    graph (depicted with colored edges connecting noteheads in the figure above).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can also extend the sampling process for the beat and measure elements. Note
    that the k-hop neighbors need not be strictly related to a time window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To maximize the computational resources (i.e. memory) the above process is repeated
    for many scores at once to create one batch. Using this process, GraphMuse asserts
    that every sampled segment is going to have the same size of target notes. Every
    sampled segment can be combined to a new graph which will be of size at most *#_scores*
    x *#_target_notes.* This new graph constitutes the batch for the current training
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on with GraphMuse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the hands-on part let’s try to use GraphMuse and use a model for pitch
    spelling. The pitch spelling task is about inferring the note name and accidentals
    when they are absent from the score. An example of this application is when we
    have a quantized midi and want to create a score such as the example in the figure
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46ae97eb1f61b6bc624882d6353af232.png)'
  prefs: []
  type: TYPE_IMG
- en: Midi file is the input (top) and the music score is the desired output (bottom)
  prefs: []
  type: TYPE_NORMAL
- en: Before installing GraphMuse you will need to install PyTorch and PyTorch Geometric.
    Check out the appropriate version for your system [***here***](https://pytorch.org/get-started/locally/)
    and [***here***](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'After this step, to install GraphMuse open your preferred terminal and type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After installation, let's read a MIDI file from a URL and create the score graph
    with GraphMuse.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The underlying process reads the file with Partitura and then feeds it through
    GraphMuse.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train our model to handle Pitch Spelling, we first need a dataset of musical
    scores where the pitch spelling has already been annotated. For this, we’ll be
    using the ASAP Dataset (licenced under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)),
    which will serve as the foundation for our model’s learning. To get the ASAP Dataset
    you can download it using git or [directly from github](https://github.com/cpjku/asap-dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The ASAP dataset includes scores and performances of various classical piano
    pieces. For our use-case we will use only the scores which end in `.musicxml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we load this dataset, we’ll need two essential utilities: one to encode
    pitch spelling and another to handle key signature information, both of which
    will be converted into numerical labels. Fortunately, these utilities are available
    within the pre-built pitch spelling model in GraphMuse. Let’s begin by importing
    all the necessary packages and loading the first score to get started.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, we’ll load the remaining score files from the dataset to continue preparing
    our data for model training.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once the graph structures are ready, we can move on to creating the data loader,
    which is conveniently provided by GraphMuse. At this stage, we’ll also define
    standard training components like the loss function and optimizer to guide the
    learning process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let me comment a bit more on the *gm.loader.MuseNeighborLoader.* This is the
    core dataloader in GraphMuse and it contains the sampling that was explained in
    the previous section. *subgraph_size* refers to the number of target nodes per
    input graph, *batch_size* is the number of sampled graphs per batch, and finally,
    *num_neighbors* refers to the number of neighbors sampled per sampled node in
    each layer.
  prefs: []
  type: TYPE_NORMAL
- en: With everything in place, we are finally ready to train the model. So, let’s
    dive in and start the training process!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Hopefully, we’ll soon see the loss function decreasing, a positive sign that
    our model is effectively learning how to perform pitch spelling. Fingers crossed!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f267c41b5f58259804aa4c0806642c6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Why GraphMuse?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraphMuse is a framework that tries to make the training and deployment of graph
    models for symbolic music processing easier.
  prefs: []
  type: TYPE_NORMAL
- en: For those who want to retrain, deploy, or finetune previous state-of-the-art
    models for symbolic music analysis, GraphMuse contains some of the necessary components
    to re-build and re-train your model faster and more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: GraphMuse retains its flexibility through its simplicity, for those who want
    to prototype, innovate, and design new models. It aims to provide a simple set
    of utilities rather than including complex chained pipelines that can block the
    innovation process.
  prefs: []
  type: TYPE_NORMAL
- en: For those who want to learn, visualize, and get hands-on experience, GraphMuse
    is good to get you started. It offers an easy introduction to basic functions
    and pipelines with a few lines of code. GraphMuse is also linked with [MusGViz](https://github.com/fosfrancesco/musgviz/),
    which allows graphs and scores to be easily visualized together.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations and Future Plans
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot talk about the positive aspects of any project without discussing
    the negative ones as well.
  prefs: []
  type: TYPE_NORMAL
- en: GraphMuse is a newborn project and in its current state, it is pretty simple.
    It is focused on covering the essential parts of graph learning rather than being
    a holistic framework that covers all possibilities. Therefore it still focuses
    a lot on user-based implementation on many parts of the aforementioned pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Like every open-source project in development GraphMuse needs help to grow.
    So please, if you find bugs or want more features do not hesitate to report, request,
    or contribute to the GraphMuse GitHub project.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least, GraphMuse uses C libraries such as torch-sparse and torch-scatter
    and has its own C-bindings to accelerate graph creation therefore installation
    is not always straightforward. The windows installation is more challenging judging
    from our user testing and user interaction reports, although not impossible (I
    am running it on Windows myself).
  prefs: []
  type: TYPE_NORMAL
- en: 'Future plans include:'
  prefs: []
  type: TYPE_NORMAL
- en: Making installation easier;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add more support for models and dataloaders for precise tasks;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grow the open-source community around GraphMuse to keep graph coding for music
    growing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GraphMuse is a Python library that makes working with music graphs a little
    bit easier. It focuses on the training aspect of graph-based models for music
    but aims to retain flexibility when research-based projects require it.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to support the development and future growth of GraphMuse
    please star the repo [here](https://github.com/manoskary/graphmuse) .
  prefs: []
  type: TYPE_NORMAL
- en: Happy graph coding !!!
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/manoskary/graphmuse?source=post_page-----40dbd9baf319--------------------------------)
    [## GitHub - manoskary/graphmuse: A Graph Deep Learning Library for Music.'
  prefs: []
  type: TYPE_NORMAL
- en: A Graph Deep Learning Library for Music. Contribute to manoskary/graphmuse development
    by creating an account on…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/manoskary/graphmuse?source=post_page-----40dbd9baf319--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '[all images are by the author]'
  prefs: []
  type: TYPE_NORMAL
