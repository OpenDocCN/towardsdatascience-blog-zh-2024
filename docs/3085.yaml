- en: 'Building Trust in LLM Answers: Highlighting Source Texts in PDFs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27](https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '100% accuracy isn’t everything: helping users navigate the document is the
    real value'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[![Angela
    & Kezhan Shi](../Images/e6bd57b0ca397b78cf810733c7262e18.png)](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    [Angela & Kezhan Shi](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    ·6 min read·Dec 27, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'So, you are building a RAG system or using an LLM to chat with documents. But
    users often ask: how can we trust the answers?'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we frequently hear about hallucinations, which undermine users’ trust.
  prefs: []
  type: TYPE_NORMAL
- en: If we build an application but fail to show users where the answers come from,
    the application might become unusable in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’ll share an approach to address this concern. By linking
    every answer generated by the LLM to its source text in the document, we can build
    transparency and trust. This method not only provides clear evidence for the answers
    but also allows users to verify the results directly within the PDF.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the generated answer may not be perfectly accurate, but being able
    to locate the correct source text is already helpful for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example of [this paper](https://arxiv.org/pdf/2410.05229) from
    arxiv.org. We can imagine this use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/31cb0653d8ae3ea4091e6e82d5781b0a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author — presentation of the document
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Extracting text from PDFs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step in this approach is to extract the text from the PDF in a structured
    format.
  prefs: []
  type: TYPE_NORMAL
