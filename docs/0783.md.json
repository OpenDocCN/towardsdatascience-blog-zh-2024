["```py\nfrom pydantic.v1 import BaseModel, validator  \nfrom datetime import datetime\nfrom langchain_core.utils.function_calling import convert_to_openai_tool\n\nclass Expense(BaseModel):    \n   description: str    \n   net_amount: float    \n   gross_amount: float    \n   tax_rate: float    \n   date: datetime\n\nclass Report(BaseModel):\n   report: str\n\nadd_expense_tool = convert_to_openai_tool(Expense)\nreport_tool = convert_to_openai_tool(Report)\n```", "```py\nfrom openai import OpenAI  \nfrom langchain_core.utils.function_calling import convert_to_openai_tool  \n\nSYSTEM_MESSAGE = \"\"\"You are tasked with completing specific objectives and \nmust report the outcomes. At your disposal, you have a variety of tools, \neach specialized in performing a distinct type of task.  \n\nFor successful task completion:  \nThought: Consider the task at hand and determine which tool is best suited \nbased on its capabilities and the nature of the work.  \n\nUse the report_tool with an instruction detailing the results of your work.  \nIf you encounter an issue and cannot complete the task:  \n\nUse the report_tool to communicate the challenge or reason for the \ntask's incompletion.  \nYou will receive feedback based on the outcomes of \neach tool's task execution or explanations for any tasks that \ncouldn't be completed. This feedback loop is crucial for addressing \nand resolving any issues by strategically deploying the available tools.  \n\"\"\"  \nuser_message = \"I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2.\"\n\nclient = OpenAI()  \nmodel_name = \"gpt-3.5-turbo-0125\"  \n\nmessages = [  \n    {\"role\":\"system\", \"content\": SYSTEM_MESSAGE},  \n    {\"role\":\"user\", \"content\": user_message}  \n]  \n\nresponse = client.chat.completions.create(  \n            model=model_name,  \n            messages=messages,  \n            tools=[  \n                convert_to_openai_tool(Expense),  \n                convert_to_openai_tool(ReportTool)]  \n        )\n```", "```py\ndef parse_function_args(response):\n    message = response.choices[0].message\n    return json.loads(message.tool_calls[0].function.arguments)\n\nprint(parse_function_args(response))\n```", "```py\n{'description': 'Coffee',\n 'net_amount': 5,\n 'gross_amount': None,\n 'tax_rate': 0.2,\n 'date': '2023-10-06T12:00:00Z'}\n```", "```py\nadd_expense_tool = convert_to_openai_tool(Expense)\nprint(add_expense_tool)\n```", "```py\n{'type': 'function',\n 'function': {'name': 'Expense',\n  'description': '',\n  'parameters': {'type': 'object',\n   'properties': {'description': {'type': 'string'},\n    'net_amount': {'type': 'number'},\n    'gross_amount': {'type': 'number'},\n    'tax_rate': {'type': 'number'},\n    'date': {'type': 'string', 'format': 'date-time'}},\n   'required': ['description',\n    'net_amount',\n    'gross_amount',\n    'tax_rate',\n    'date']}}}\n```", "```py\ndel add_expense_tool[\"function\"][\"parameters\"][\"required\"]\n```", "```py\nfrom pydantic import BaseModel\nfrom typing import Type, Callable, Dict, Any, List\n\nclass ToolResult(BaseModel):  \n    content: str  \n    success: bool  \n\nclass Tool(BaseModel):  \n    name: str  \n    model: Type[BaseModel]  \n    function: Callable  \n    validate_missing: bool = False  \n\n    class Config:  \n        arbitrary_types_allowed = True  \n\n    def run(self, **kwargs) -> ToolResult:\n        if self.validate_missing:\n            missing_values = self.validate_input(**kwargs)  \n            if missing_values:  \n                content = f\"Missing values: {', '.join(missing_values)}\"  \n                return ToolResult(content=content, success=False)  \n        result = self.function(**kwargs)  \n        return ToolResult(content=str(result), success=True)  \n\n    def validate_input(self, **kwargs) -> List[str]:  \n        missing_values = []  \n        for key in self.model.__fields__.keys():  \n            if key not in kwargs:  \n                missing_values.append(key)  \n        return missing_values\n    @property\n    def openai_tool_schema(self) -> Dict[str, Any]:\n        schema = convert_to_openai_tool(self.model)\n        if \"required\" in schema[\"function\"][\"parameters\"]:\n            del schema[\"function\"][\"parameters\"][\"required\"]\n        return schema\n```", "```py\ndef add_expense_func(**kwargs):  \n    return f\"Added expense: {kwargs} to the database.\"\n\nadd_expense_tool = Tool(  \n    name=\"add_expense_tool\",  \n    model=Expense,  \n    function=add_expense_func  \n)  \n\ndef report_func(report: str = None):  \n    return f\"Reported: {report}\"  \n\nreport_tool = Tool(  \n    name=\"report_tool\",  \n    model=ReportTool,  \n    function=report_func  \n)  \n\ntools = [add_expense_tool, report_tool]\n```", "```py\ndef get_tool_from_response(response, tools=tools):  \n    tool_name = response.choices[0].message.tool_calls[0].function.name  \n    for t in tools:  \n        if t.name == tool_name:  \n            return t  \n    raise ValueError(f\"Tool {tool_name} not found in tools list.\")\n\ndef parse_function_args(response):  \n    message = response.choices[0].message  \n    return json.loads(message.tool_calls[0].function.arguments)\n\ndef run_tool_from_response(response, tools=tools):  \n    tool = get_tool_from_response(response, tools)  \n    tool_kwargs = parse_function_args(response)  \n    return tool.run(**tool_kwargs)\n```", "```py\nresponse = client.chat.completions.create(  \n            model=model_name,  \n            messages=messages,  \n            tools=[tool.openai_tool_schema for tool in tools]  \n        )\n\ntool_result = run_tool_from_response(response, tools=tools)\nprint(tool_result)\n```", "```py\ncontent='Missing values: gross_amount, date' success=False\n```", "```py\nclass StepResult(BaseModel):  \n    event: str   \n    content: str  \n    success: bool\n\nclass OpenAIAgent:  \n\n    def __init__(  \n            self,   \n            tools: list[Tool],   \n            client: OpenAI,   \n            system_message: str = SYSTEM_MESSAGE,   \n            model_name: str = \"gpt-3.5-turbo-0125\",  \n            max_steps: int = 5,  \n            verbose: bool = True  \n    ):  \n        self.tools = tools  \n        self.client = client  \n        self.model_name = model_name  \n        self.system_message = system_message  \n        self.step_history = []  \n        self.max_steps = max_steps  \n        self.verbose = verbose  \n\n    def to_console(self, tag: str, message: str, color: str = \"green\"):  \n        if self.verbose:  \n            color_prefix = Fore.__dict__[color.upper()]  \n            print(color_prefix + f\"{tag}: {message}{Style.RESET_ALL}\")\n```", "```py\nclass OpenAIAgent:\n\n    # ... __init__...\n\n    # ... to_console ...\n\n    def run(self, user_input: str):  \n\n        openai_tools = [tool.openai_tool_schema for tool in self.tools]    \n        self.step_history = [    \n            {\"role\":\"system\", \"content\":self.system_message},    \n            {\"role\":\"user\", \"content\":user_input}    \n        ]    \n\n        step_result = None    \n        i = 0\n\n        self.to_console(\"START\", f\"Starting Agent with Input: {user_input}\")\n\n        while i < self.max_steps:  \n            step_result = self.run_step(self.step_history, openai_tools)    \n\n            if step_result.event == \"finish\":    \n                break  \n            elif step_result.event == \"error\":  \n                self.to_console(step_result.event, step_result.content, \"red\")  \n            else:  \n                self.to_console(step_result.event, step_result.content, \"yellow\")  \n            i += 1   \n\n        self.to_console(\"Final Result\", step_result.content, \"green\")  \n        return step_result.content\n```", "```py\nclass OpenAIAgent:\n\n    # ... __init__...\n\n    # ... to_console ...\n    # ... run ...\n    def run_step(self, messages: list[dict], tools):  \n\n        # plan the next step  \n        response = self.client.chat.completions.create(  \n            model=self.model_name,  \n            messages=messages,  \n            tools=tools  \n        )  \n\n        # add message to history  \n        self.step_history.append(response.choices[0].message)  \n\n        # check if tool call is present  \n        if not response.choices[0].message.tool_calls:  \n            return StepResult(\n                event=\"Error\",\n                content=\"No tool calls were returned.\", \n                success=False\n                )  \n\n        tool_name = response.choices[0].message.tool_calls[0].function.name  \n        tool_kwargs = parse_function_args(response)  \n\n        # execute the tool call  \n        self.to_console(\n        \"Tool Call\", f\"Name: {tool_name}\\nArgs: {tool_kwargs}\", \"magenta\"\n        )  \n        tool_result = run_tool_from_response(response, tools=self.tools)  \n        tool_result_msg = self.tool_call_message(response, tool_result)  \n        self.step_history.append(tool_result_msg)  \n\n        if tool_result.success:  \n            step_result = StepResult(  \n                event=\"tool_result\",   \n                content=tool_result.content,   \n                success=True)  \n        else:  \n            step_result = StepResult(  \n                event=\"error\",   \n                content=tool_result.content,   \n                success=False  \n            )   \n\n        return step_result  \n\n    def tool_call_message(self, response, tool_result: ToolResult):  \n        tool_call = response.choices[0].message.tool_calls[0]  \n        return {  \n            \"tool_call_id\": tool_call.id,  \n            \"role\": \"tool\",  \n            \"name\": tool_call.function.name,  \n            \"content\": tool_result.content,  \n        }\n```", "```py\nclass DateTool(BaseModel):  \n    x: str = None  \n\nget_date_tool = Tool(  \n    name=\"get_current_date\",  \n    model=DateTool,  \n    function=lambda: datetime.now().strftime(\"%Y-%m-%d\"),  \n    validate_missing=False  \n)  \n\ntools = [  \n    add_expense_tool,   \n    report_tool,  \n    get_date_tool  \n]  \n\nagent = OpenAIAgent(tools, client)\nagent.run(\"I have spent 5$ on a coffee today please track my expense. The tax rate is 0.2.\")\n```", "```py\nSTART: Starting Agent with Input: \n\"I have spend 5$ on a coffee today please track my expense. The tax rate is 0.2.\"\n\nTool Call: get_current_date\nArgs: {}\ntool_result: 2024-03-15\n\nTool Call: add_expense_tool\nArgs: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15'}\nerror: Missing values: gross_amount\n\nTool Call: add_expense_tool\nArgs: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15', 'gross_amount': 6}\ntool_result: Added expense: {'description': 'Coffee expense', 'net_amount': 5, 'tax_rate': 0.2, 'date': '2024-03-15', 'gross_amount': 6} to the database.\nError: No tool calls were returned.\n\nTool Call: Name: report_tool\nArgs: {'report': 'Expense successfully tracked for coffee purchase.'}\ntool_result: Reported: Expense successfully tracked for coffee purchase.\n\nFinal Result: Reported: Expense successfully tracked for coffee purchase.\n```"]