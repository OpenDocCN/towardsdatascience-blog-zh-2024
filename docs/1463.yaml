- en: A Simple Recipe to Boost the Performance of MLLMs on Your Custom Use Case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11](https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An MLLM QLoRA fine-tuning tutorial using the newest pocket-sized Mini-InternVL
    model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    ·6 min read·Jun 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac67a9c7e6007446e729e1c9c26e9c26.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Maarten van den Heuvel](https://unsplash.com/@mvdheuvel?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The world of large language models (LLMs) is constantly evolving, with new advancements
    emerging rapidly. One exciting area is the development of multi-modal LLMs (MLLMs),
    capable of understanding and interacting with both texts and images. This opens
    up a world of possibilities for tasks like document understanding, visual question
    answering, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'I recently wrote a general post about one such model that you can check out
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
    [## 6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring possible use cases of Phi-3-Vision, a small yet powerful MLLM that
    can be run locally (with code examples)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'But in this one, we’ll explore a powerful combination: the InternVL model and
    the QLoRA fine-tuning technique. **We will focus on how we can easily customize
    such models for any specific use-case.** We’ll use these tools to create a receipt
    understanding pipeline that extracts key information like company name, address,
    and total amount of purchase with high accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Task and Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
