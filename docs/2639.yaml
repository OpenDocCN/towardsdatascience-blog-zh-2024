- en: 'Continual Learning: The Three Common Scenarios'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/continual-learning-the-three-common-scenarios-e6c3260fe0cb?source=collection_archive---------11-----------------------#2024-10-29](https://towardsdatascience.com/continual-learning-the-three-common-scenarios-e6c3260fe0cb?source=collection_archive---------11-----------------------#2024-10-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Plus paper recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://pascaljanetzky.medium.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e6c3260fe0cb--------------------------------)
    ·6 min read·Oct 29, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: As the training costs of machine learning models rise [1], continual learning
    (CL) emerges as a useful countermeasure. In CL, a machine learning model (*e.g.*,
    a LLM such as GPT), is trained on a continually arriving stream of data (*e.g.*,
    text data). Crucially, in CL the data cannot be stored, and thus only the most
    recent data is available for training. The main challenge is then to train on
    the current data (often called *task*) while not forgetting the knowledge learned
    from the old tasks. Not forgetting old knowledge is critical because at test-time,
    the model is evaluated on the test-data of all seen tasks. That challenge is often
    described as catastrophic forgetting in the literature, and is part of the stability-plasticity
    tradeoff.
  prefs: []
  type: TYPE_NORMAL
- en: One the one hand, the stability-plasticity tradeoff refers to keeping network
    parameters (*e.g.*, layer weights) stable to not forget (stability). On the other
    hand, it means to allow parameter changes in order to learn from novel tasks (plasticity).
    CL methods approach this tradeoff from multiple directions, which I have written
    about in [a previous article](https://medium.com/towards-data-science/continual-learning-a-primer-e328ed1d072f).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67d4ce51f17fed060c52239abcd559c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [lionel mermoz](https://unsplash.com/@mermoz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'The focus of today’s article is on the fundamental scenarios that repeatedly
    appear in CL research: class-incremental, domain-incremental, and task-incremental
    learning. The choice of…'
  prefs: []
  type: TYPE_NORMAL
