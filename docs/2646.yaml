- en: Ensemble Learning for Anomaly Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ensemble-learning-for-anomaly-detection-955efb1b2fac?source=collection_archive---------5-----------------------#2024-10-30](https://towardsdatascience.com/ensemble-learning-for-anomaly-detection-955efb1b2fac?source=collection_archive---------5-----------------------#2024-10-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*A dive into the isolation forest model to detect anomalies in time-series
    data*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@adavis08?source=post_page---byline--955efb1b2fac--------------------------------)[![Alex
    Davis](../Images/f773cce9438a68856cb8ba486ac8b051.png)](https://medium.com/@adavis08?source=post_page---byline--955efb1b2fac--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--955efb1b2fac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--955efb1b2fac--------------------------------)
    [Alex Davis](https://medium.com/@adavis08?source=post_page---byline--955efb1b2fac--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--955efb1b2fac--------------------------------)
    ·7 min read·Oct 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection is a must-have capability for any organization. By detecting
    anomalies and outliers, we not only identify data that seems suspicious (or possibly
    wrong), but can also establish what ‘normal’ data looks like. Anomaly detection
    can prove to be a vital capability for a strong data governance system by identifying
    data errors. And for analysis, outliers can be a point of interest in certain
    cases such as fraud detection and predictive maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: However, as data grows, anomaly detection can prove more and more difficult.
    High-dimensional data comes with noise and makes it difficult to use for analysis
    and insights. Large datasets are also likely to have errors and/or special cases.
    Thankfully, ensemble learning brings speed and efficiency to help us wrangle high-dimensional
    data and detect anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: What is ensemble learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensemble learning is a machine learning technique that combines the predictions
    from multiple individual models to obtain a better predictive performance than
    any single model. Each model is considered a “weak learner” and is trained on
    a small subset of the data to make a prediction. Then it goes to a vote. Each
    weak learner is surveyed and the majority vote wins for the final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68ea0c492fe208b9a5695a9c1515eda7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Wikimedia Commons ([https://commons.wikimedia.org/wiki/File:Random_forest_explain.png](https://commons.wikimedia.org/wiki/File:Random_forest_explain.png))
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble models (trained on high-quality data) are robust, accurate, efficient,
    and are good at avoiding overfitting. They have many use cases such as classification,
    optimization, and in our case, anomaly detection.
  prefs: []
  type: TYPE_NORMAL
- en: The Isolation Forest Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The isolation forest model is an ensemble of trees that isolates observations
    that are few and far between. It is very similar to the popular ‘Random Forest’
    model, but instead of a forest of decision trees, the isolation forest produces
    a forest of ‘isolation trees’.
  prefs: []
  type: TYPE_NORMAL
- en: So how does it work? Let’s look at one isolation tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/673e94aca10cdd4218bd7d158965e237.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Consider the data above. We can see that one data point is farther away from
    the rest of the data (our suspected anomaly). **Each isolation tree randomly chooses
    a ‘split value’ to begin to isolate observations.** In this case, the suspected
    outlier is immediately isolated. This would be the case for most of the isolation
    trees due to its distance from the rest of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6aca0034350e7247a47cbe55fb66a21e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Next, it chooses another split. This time, the suspected ‘normal’ data begins
    to get cut up. **This process repeats until each observation is isolated.** Ultimately,
    the model ‘isolates’ observations by randomly selecting a feature and then randomly
    selecting a split value between the maximum and minimum values of the selected
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0ffa29702aebb86c93866eec8b90d6e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that each observation is isolated, we need to ask: **How many splits did
    it take for each observation to be isolated?** In other words, how long is the
    partition path for each data point? Let’s say the results are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e6f94e6695942edff26916a20c5fd124.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how many splits it took to isolate each observation, we calculate
    the mean number of splits. In our example, on average, it takes 2.6 splits to
    isolate an observation. **Observations that have a noticeably shorter partition
    path, or took noticeably less splits to be isolated, are highly likely to be anomalies
    or outliers.** The degree to which they differ from the mean number of splits
    is a parameter in the model. Finally, the isolation tree determines the observation
    G is an anomaly.
  prefs: []
  type: TYPE_NORMAL
- en: '**The last step of the isolation forest model is for each isolation tree to
    ‘vote’ on which observations are anomalies.** If a majority of them think that
    observation G is an anomaly, then the model determines that it is.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Anomalies in Time Series Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lets see a simple example using the isolation forest model to detect anomalies
    in time-series data. Below, we have imported a sales data set that contains the
    day of an order, information about the product, geographical information about
    the customer, and the amount of the sale. To keep this example simple, lets just
    look at one feature (sales) over time.
  prefs: []
  type: TYPE_NORMAL
- en: '*See data here:* [*https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting*](https://www.kaggle.com/datasets/rohitsahoo/sales-forecasting)
    *(GPL 2.0)*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/78621fd24438dc0ad35003bbcd78ff71.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: As you can see above, we have the total sale amount for every order on a particular
    day. Since we have a sufficient amount of data (4 years worth), let’s try to detect
    months where the total sales is either noticeably higher or lower than the expected
    total sales.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to conduct some preprocessing, and sum the sales for every month.
    Then, visualize monthly sales.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/af77b3a53519ce3fe0cc456da4e61675.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Using the line chart above, we can see that while sales fluctuates from month-to-month,
    total sales trends upward over time. Ideally, our model will identify months where
    total sales fluctuates more that expected and is highly influential to our overall
    trend.
  prefs: []
  type: TYPE_NORMAL
- en: Now we need to initialize and fit our model. The model below uses the default
    parameters. I have highlighted these parameters as they are the most important
    to the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**n_estimators**: The number of base estimators in the ensemble.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_samples**: The number of samples to draw from X to train each base estimator
    (if “auto”, then `max_samples = min(256, n_samples)).`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**contamination**: The amount of contamination of the data set, i.e. the proportion
    of outliers in the data set. Used when fitting to define the threshold on the
    scores of the samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_features**: The number of features to draw from X to train each base
    estimator.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Next, lets use the model to display the anomalies and their anomaly score. The
    anomaly score is the mean measure of normality of an observation among the base
    estimators. The lower the score, the more abnormal the observation. Negative scores
    represent outliers, positive scores represent inliers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ca56501e9d6e920ba5ccf90664793ca8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, lets bring up the same line chart from before, but highlighting the
    anomalies with plt.scatter.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4f5c5e6e39a801c2abed486f849e43b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: The model appears to do well. Since the data fluctuates so much month-to-month,
    a worry could be that inliers would get marked as anomalies, but this is not the
    case due to the **bootstrap sampling of the model**. The anomalies appear to be
    the larger fluctuations where sales deviated from the trend a ‘significant’ amount.
  prefs: []
  type: TYPE_NORMAL
- en: However, knowing the data is important here as some of the anomalies should
    come with a caveat. Let’s look at the first (February 2015) and last (November
    2018) anomaly detected. At first, we see that they both are large fluctuations
    from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: However, the first anomaly (February 2015) is only our second month of recording
    sales and the business may have just started operating. Sales are definitely low,
    and we see a large spike the next month. But is it fair to mark the second month
    of business an anomaly because sales were low? Or is this the norm for a new business?
  prefs: []
  type: TYPE_NORMAL
- en: For our last anomaly (November 2018), we see a huge spike in sales that appears
    to deviate from the overall trend. However, we have run out of data. As data continues
    to be recorded, it may not have been an anomaly, but perhaps an identifier of
    a steeper upwards trend.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In conclusion, anomaly detection is a must-have capability for both strong data
    governance and rigorous analysis. While detecting outliers and anomalies in large
    data can be difficult, ensemble learning methods can help as they are robust and
    efficient with large, tabular data.
  prefs: []
  type: TYPE_NORMAL
- en: The isolation forest model detects these anomalies by for using a forest of
    ‘weak learners’ to isolate observations that are few and far between.
  prefs: []
  type: TYPE_NORMAL
- en: '*I hope you have enjoyed my article! Please feel free to comment, ask questions,
    or request other topics.*'
  prefs: []
  type: TYPE_NORMAL
