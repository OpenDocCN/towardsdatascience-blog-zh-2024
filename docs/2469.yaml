- en: From Newton to LLM’s
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/from-newton-to-neural-networks-cbbccc7e3ca0?source=collection_archive---------8-----------------------#2024-10-09](https://towardsdatascience.com/from-newton-to-neural-networks-cbbccc7e3ca0?source=collection_archive---------8-----------------------#2024-10-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A new approach to AI reasoning optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://javier-marin.medium.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)[![Javier
    Marin](../Images/31800b2fbfd1f7c841c9f6a2579d5681.png)](https://javier-marin.medium.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)
    [Javier Marin](https://javier-marin.medium.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--cbbccc7e3ca0--------------------------------)
    ·14 min read·Oct 9, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b124fecc026674193c59cb1970a89b70.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with DALL-E by the author
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multiple facts are needed to answer a multi-hop [question-answering](https://en.wikipedia.org/wiki/Question_answering)
    (QA), which is essential for complex reasoning and explanations in Large Language
    Models (LLMs). QA quantifies and objectively tests intelligent system reasoning.
    Due to their unambiguous correct solutions, QA tasks reduce subjectivity and human
    bias in evaluation. QA functions can evaluate deductive reasoning, inductive reasoning,
    and abductive reasoning, which involves formulating the most plausible answer
    from partial knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: We face several challenges in improving the model’s reasoning processes. One
    of the most important demands is model interpretability and explainability. Large
    AI models, especially deep neural networks, are hard to understand, which makes
    it hard to evaluate them accurately and come up with human-friendly explanations
    for their decisions and conclusions. Another important goal for improving the
    reasoning process is to ensure that reasoning processes are robust to minor variations
    in input or context, as well as to develop models that can generalize reasoning
    skills across different domains and types of questions.
  prefs: []
  type: TYPE_NORMAL
- en: The Power of Physical Analogies in AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
