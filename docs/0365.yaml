- en: Building a Multi-Purpose GenAI Powered Chatbot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-multi-purpose-genai-powered-chatbot-db20f1f81d90?source=collection_archive---------5-----------------------#2024-02-07](https://towardsdatascience.com/building-a-multi-purpose-genai-powered-chatbot-db20f1f81d90?source=collection_archive---------5-----------------------#2024-02-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Utilize SageMaker Inference Components to work with Multiple LLMs Efficiently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ram-vegiraju.medium.com/?source=post_page---byline--db20f1f81d90--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page---byline--db20f1f81d90--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--db20f1f81d90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--db20f1f81d90--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page---byline--db20f1f81d90--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--db20f1f81d90--------------------------------)
    ·10 min read·Feb 7, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4cbd8b29ee6f9710178f1cd6105255f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Unsplash](https://unsplash.com/photos/a-blue-robot-with-a-keyboard-and-monitor-4NYtYSiZVlA)
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) are immensely powerful and can help solve a variety
    of NLP tasks such as question answering, summarization, entity extraction, and
    more. As generative AI use-cases continue to expand, often times real-world applications
    will require the ability to solve multiple of these NLP tasks. For instance if
    you have a chatbot for users to interface with, a common ask is to summarize the
    conversation with the chatbot. This can be used in many settings such as doctor-patient
    transcripts, virtual phone calls/appointments, and more.
  prefs: []
  type: TYPE_NORMAL
- en: How can we build something that solves these types of problems? We could have
    multiple LLMs, one for question answering and the other for summarization. Another
    approach would be taking the same LLM and fine-tuning it across the different
    domains, but we will focus on the former approach for this use-case. With multiple
    LLMs though there are certain challenges that must be addressed.
  prefs: []
  type: TYPE_NORMAL
- en: Hosting even a singular model is computationally expensive and requires large
    GPU instances. In the case of having multiple LLMs it’ll require a persistent
    endpoint/hardware for both. This also leads to overhead with managing multiple
    endpoints and paying for…
  prefs: []
  type: TYPE_NORMAL
