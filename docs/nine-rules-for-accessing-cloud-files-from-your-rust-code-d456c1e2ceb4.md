# ä»ä½ çš„ Rust ä»£ç è®¿é—®äº‘æ–‡ä»¶çš„ä¹ä¸ªè§„åˆ™

> åŸæ–‡ï¼š[`towardsdatascience.com/nine-rules-for-accessing-cloud-files-from-your-rust-code-d456c1e2ceb4?source=collection_archive---------7-----------------------#2024-02-07`](https://towardsdatascience.com/nine-rules-for-accessing-cloud-files-from-your-rust-code-d456c1e2ceb4?source=collection_archive---------7-----------------------#2024-02-07)

## å‡çº§ Bed-Readerï¼šæ¥è‡ªç”Ÿç‰©ä¿¡æ¯å­¦åº“çš„å®è·µç»éªŒ

[](https://medium.com/@carlmkadie?source=post_page---byline--d456c1e2ceb4--------------------------------)![Carl M. Kadie](https://medium.com/@carlmkadie?source=post_page---byline--d456c1e2ceb4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d456c1e2ceb4--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d456c1e2ceb4--------------------------------) [Carl M. Kadie](https://medium.com/@carlmkadie?source=post_page---byline--d456c1e2ceb4--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d456c1e2ceb4--------------------------------) Â·é˜…è¯»æ—¶é•¿ 21 åˆ†é’ŸÂ·2024 å¹´ 2 æœˆ 7 æ—¥

--

![](img/1e411080a4ed67bba652ec6626318f0e.png)

Rust å’Œ Python ç›´æ¥ä»äº‘ç«¯è¯»å– DNA æ•°æ® â€” æ¥æºï¼š[`openai.com/dall-e-2/`](https://openai.com/dall-e-2/)ã€‚æ‰€æœ‰å…¶ä»–å›¾ç‰‡æ¥è‡ªä½œè€…ã€‚

ä½ å¸Œæœ›ä½ çš„ Rust ç¨‹åºèƒ½å¤Ÿæ— ç¼åœ°è®¿é—®äº‘ç«¯çš„æ–‡ä»¶æ•°æ®å—ï¼Ÿå½“æˆ‘æåˆ°â€œäº‘ç«¯æ–‡ä»¶â€æ—¶ï¼Œæˆ‘æŒ‡çš„æ˜¯å­˜å‚¨åœ¨ Web æœåŠ¡å™¨æˆ–äº‘å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼ˆå¦‚ AWS S3ã€Azure Blob Storage æˆ– Google Cloud Storageï¼‰ä¸­çš„æ•°æ®ã€‚è¿™é‡Œæ‰€è¯´çš„â€œè¯»å–â€åŒ…å«äº†å¯¹æ–‡ä»¶å†…å®¹çš„é¡ºåºæ£€ç´¢â€”â€”æ— è®ºæ˜¯æ–‡æœ¬è¿˜æ˜¯äºŒè¿›åˆ¶æ•°æ®ï¼Œä»å¤´åˆ°å°¾â€”â€”å¹¶ä¸”å…·æœ‰æ ¹æ®éœ€è¦å®šä½å¹¶æå–æ–‡ä»¶ä¸­ç‰¹å®šéƒ¨åˆ†çš„èƒ½åŠ›ã€‚

å°†ç¨‹åºå‡çº§ä»¥è®¿é—®äº‘æ–‡ä»¶ï¼Œå¯ä»¥å‡å°‘çƒ¦æ¼å’Œå¤æ‚æ€§ï¼šä¸å†éœ€è¦å°†æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°å­˜å‚¨ï¼Œä¹Ÿä¸å†éœ€è¦å®šæœŸæ£€æŸ¥æœ¬åœ°å‰¯æœ¬æ˜¯å¦ä¸ºæœ€æ–°ã€‚

ä¸å¹¸çš„æ˜¯ï¼Œå°†ä½ çš„ç¨‹åºå‡çº§ä»¥è®¿é—®äº‘æ–‡ä»¶ä¹Ÿå¯èƒ½ä¼š*å¢åŠ *çƒ¦æ¼å’Œå¤æ‚æ€§ï¼šURLs å’Œå‡­è¯ä¿¡æ¯å¸¦æ¥çš„çƒ¦æ¼ï¼Œä»¥åŠå¼‚æ­¥ç¼–ç¨‹çš„å¤æ‚æ€§ã€‚

[Bed-Reader](https://github.com/fastlmm/bed-reader) æ˜¯ä¸€ä¸ªç”¨äºè¯»å– PLINK Bed æ–‡ä»¶çš„ Python åŒ…å’Œ Rust crateï¼Œè¿™æ˜¯ä¸€ç§åœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­ç”¨äºå­˜å‚¨åŸºå› å‹ï¼ˆDNAï¼‰æ•°æ®çš„äºŒè¿›åˆ¶æ ¼å¼ã€‚åº”ç”¨æˆ·çš„è¦æ±‚ï¼Œæˆ‘æœ€è¿‘æ›´æ–°äº† Bed-Readerï¼Œä½¿å…¶èƒ½å¤Ÿé€‰æ‹©æ€§åœ°ç›´æ¥ä»äº‘å­˜å‚¨è¯»å–æ•°æ®ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæˆ‘æ€»ç»“äº†ä¹æ¡è§„åˆ™ï¼Œå¯ä»¥å¸®åŠ©ä½ ä¸ºç¨‹åºæ·»åŠ äº‘æ–‡ä»¶æ”¯æŒã€‚è¿™äº›è§„åˆ™æ˜¯ï¼š

1.  ä½¿ç”¨ crate `[object_store](https://crates.io/crates/object_store)`ï¼ˆä»¥åŠå¯èƒ½çš„ `[cloud-file](https://crates.io/crates/cloud-file)`ï¼‰æŒ‰é¡ºåºè¯»å–äº‘æ–‡ä»¶çš„å­—èŠ‚ã€‚

1.  é€šè¿‡ä¸¤ä¸ªåµŒå¥—çš„å¾ªç¯é¡ºåºè¯»å–äº‘æ–‡ä»¶ä¸­çš„æ–‡æœ¬è¡Œã€‚

1.  éšæœºè®¿é—®äº‘æ–‡ä»¶ï¼Œå³ä½¿æ˜¯éå¸¸å¤§çš„æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨â€œèŒƒå›´â€æ–¹æ³•ï¼ŒåŒæ—¶éµå®ˆæœåŠ¡å™¨æ–½åŠ çš„é™åˆ¶ã€‚

1.  ä½¿ç”¨ URL å­—ç¬¦ä¸²å’Œé€‰é¡¹å­—ç¬¦ä¸²è®¿é—® HTTPã€æœ¬åœ°æ–‡ä»¶ã€AWS S3ã€Azure å’Œ Google Cloudã€‚

1.  é€šè¿‡ `[tokio](https://crates.io/crates/tokio)::test` æµ‹è¯• HTTP å’Œæœ¬åœ°æ–‡ä»¶ã€‚

*å¦‚æœå…¶ä»–ç¨‹åºè°ƒç”¨ä½ çš„ç¨‹åºâ€”â€”æ¢å¥è¯è¯´ï¼Œå¦‚æœä½ çš„ç¨‹åºæä¾›äº†ä¸€ä¸ª APIï¼ˆåº”ç”¨ç¨‹åºæ¥å£ï¼‰â€”â€”åˆ™æœ‰å››æ¡é¢å¤–çš„è§„åˆ™é€‚ç”¨ï¼š*

6\. ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œå¯ä»¥é€šè¿‡å¼‚æ­¥ API å°†äº‘æ–‡ä»¶æ”¯æŒæ·»åŠ åˆ°ä½ çš„ Rust åº“ä¸­ã€‚

7\. æˆ–è€…ï¼Œä¸ºäº†æœ€å¤§ç¨‹åº¦çš„æ–¹ä¾¿ï¼Œå¯ä»¥é€šè¿‡ä¼ ç»Ÿçš„ï¼ˆâ€œåŒæ­¥â€ï¼‰API å°†äº‘æ–‡ä»¶æ”¯æŒæ·»åŠ åˆ°ä½ çš„ Rust åº“ä¸­ã€‚

8\. é€šè¿‡ä½¿ç”¨æ–‡æ¡£æµ‹è¯•ä¸­çš„éšè—è¡Œï¼Œéµå¾ªè‰¯å¥½çš„ API è®¾è®¡è§„åˆ™ã€‚

9\. åŒ…æ‹¬ä¸€ä¸ªè¿è¡Œæ—¶ï¼Œä½†å¯ä»¥é€‰æ‹©æ€§åœ°ä½¿ç”¨ã€‚

> é¡ºä¾¿æä¸€ä¸‹ï¼šä¸ºäº†é¿å…æ¨¡ç³Šä¸æ¸…ï¼Œæˆ‘ç§°è¿™äº›ä¸ºâ€œè§„åˆ™â€ï¼Œä½†å®ƒä»¬å½“ç„¶åªæ˜¯å»ºè®®ã€‚

# è§„åˆ™ 1ï¼šä½¿ç”¨ crate `object_store`ï¼ˆä»¥åŠå¯èƒ½çš„ `cloud-file`ï¼‰é¡ºåºè¯»å–äº‘æ–‡ä»¶çš„å­—èŠ‚ã€‚

å¼ºå¤§çš„`[object_store](https://crates.io/crates/object_store)` crate æä¾›å¯¹å­˜å‚¨åœ¨ HTTPã€AWS S3ã€Azureã€Google Cloud å’Œæœ¬åœ°æ–‡ä»¶ä¸­çš„æ–‡ä»¶çš„å®Œæ•´å†…å®¹è®¿é—®ã€‚å®ƒæ˜¯ [Apache Arrow](https://arrow.apache.org/) é¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œå·²ä¸‹è½½è¶…è¿‡ 240 ä¸‡æ¬¡ã€‚

å¯¹äºæœ¬æ–‡ï¼Œæˆ‘è¿˜åˆ›å»ºäº†ä¸€ä¸ªåä¸º `[cloud-file](https://crates.io/crates/cloud-file)` çš„æ–° crateã€‚å®ƒç®€åŒ–äº† `object_store` crate çš„ä½¿ç”¨ã€‚å®ƒåŒ…è£…å¹¶ä¸“æ³¨äº `object_store` çš„ä¸€ä¸ªæœ‰ç”¨å­é›†ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨å®ƒï¼Œæˆ–è€…å°†å…¶ä»£ç æå–å‡ºæ¥ä¾›ä½ è‡ªå·±ä½¿ç”¨ã€‚

è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä¾‹å­ã€‚æˆ‘ä»¬é€šè¿‡è®¡ç®—äº‘æ–‡ä»¶ä¸­åŒ…å«çš„æ¢è¡Œç¬¦æ•°é‡æ¥ç»Ÿè®¡æ–‡ä»¶çš„è¡Œæ•°ã€‚

```py
use cloud_file::{CloudFile, CloudFileError};
use futures_util::StreamExt; // Enables `.next()` on streams.

async fn count_lines(cloud_file: &CloudFile) -> Result<usize, CloudFileError> {
    let mut chunks = cloud_file.stream_chunks().await?;
    let mut newline_count: usize = 0;
    while let Some(chunk) = chunks.next().await {
        let chunk = chunk?;
        newline_count += bytecount::count(&chunk, b'\n');
    }
    Ok(newline_count)
}

#[tokio::main]
async fn main() -> Result<(), CloudFileError> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/toydata.5chrom.fam";
    let options = [("timeout", "10s")];
    let cloud_file = CloudFile::new_with_options(url, options)?;
    let line_count = count_lines(&cloud_file).await?;
    println!("line_count: {line_count}");
    Ok(())
}
```

å½“æˆ‘ä»¬è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œå®ƒè¿”å›ï¼š

```py
line_count: 500
```

ä¸€äº›è¦ç‚¹ï¼š

+   æˆ‘ä»¬ä½¿ç”¨ `async`ï¼ˆåœ¨è¿™é‡Œä½¿ç”¨çš„æ˜¯`[tokio](https://docs.rs/tokio/latest/tokio/)`ï¼‰ã€‚æˆ‘ä»¬å°†åœ¨è§„åˆ™ 6 å’Œ 7 ä¸­è¿›ä¸€æ­¥è®¨è®ºè¿™ä¸€é€‰æ‹©ã€‚

+   æˆ‘ä»¬é€šè¿‡ `CloudFile::new_with_options(url, options)?` å°† URL å­—ç¬¦ä¸²å’Œé€‰é¡¹å­—ç¬¦ä¸²è½¬æ¢ä¸º `CloudFile` å®ä¾‹ã€‚æˆ‘ä»¬ä½¿ç”¨ `?` æ¥æ•è·æ ¼å¼é”™è¯¯çš„ URLï¼‰ã€‚

+   æˆ‘ä»¬é€šè¿‡ `cloud_file.stream_chunks().await?` åˆ›å»ºä¸€ä¸ªäºŒè¿›åˆ¶å—æµã€‚è¿™æ˜¯ä»£ç é¦–æ¬¡å°è¯•è®¿é—®äº‘æ–‡ä»¶çš„åœ°æ–¹ã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•æ‰“å¼€ï¼Œ`?` ä¼šè¿”å›ä¸€ä¸ªé”™è¯¯ã€‚

+   æˆ‘ä»¬ä½¿ç”¨ `chunks.next().await` æ¥è·å–æ–‡ä»¶çš„ä¸‹ä¸€ä¸ªäºŒè¿›åˆ¶å—ã€‚ï¼ˆè¯·æ³¨æ„ `use futures_util::StreamExt;`ã€‚ï¼‰`next` æ–¹æ³•åœ¨æ‰€æœ‰å—è¢«æ£€ç´¢å®Œåè¿”å› `None`ã€‚

+   å¦‚æœç¡®å®æœ‰ä¸‹ä¸€ä¸ªå—ï¼Œä½†åœ¨æ£€ç´¢æ—¶å‡ºç°é—®é¢˜å‘¢ï¼Ÿæˆ‘ä»¬å°†é€šè¿‡ `let chunk = chunk?;` æ•è·ä»»ä½•é—®é¢˜ã€‚

+   æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å¿«é€Ÿçš„ `[bytecount](https://docs.rs/bytecount/latest/bytecount/)` crate æ¥è®¡ç®—æ¢è¡Œç¬¦çš„æ•°é‡ã€‚

ä¸è¿™ç§äº‘è§£å†³æ–¹æ¡ˆç›¸å¯¹æ¯”ï¼Œæƒ³æƒ³ä½ ä¼šå¦‚ä½•ä¸ºæœ¬åœ°æ–‡ä»¶ç¼–å†™ä¸€ä¸ªç®€å•çš„è¡Œè®¡æ•°å™¨ã€‚ä½ å¯èƒ½ä¼šå†™æˆè¿™æ ·ï¼š

```py
use std::fs::File;
use std::io::{self, BufRead, BufReader};

fn main() -> io::Result<()> {
    let path = "examples/line_counts_local.rs";
    let reader = BufReader::new(File::open(path)?);
    let mut line_count = 0;
    for line in reader.lines() {
        let _line = line?;
        line_count += 1;
    }
    println!("line_count: {line_count}");
    Ok(())
}
```

åœ¨`cloud-file`ç‰ˆæœ¬å’Œæœ¬åœ°æ–‡ä»¶ç‰ˆæœ¬ä¹‹é—´ï¼Œæœ‰ä¸‰ä¸ªçªå‡ºå·®å¼‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†æœ¬åœ°æ–‡ä»¶ä½œä¸ºæ–‡æœ¬è¯»å–ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†äº‘æ–‡ä»¶ä½œä¸ºäºŒè¿›åˆ¶æ–‡ä»¶è¯»å–ï¼ˆä½†è¯·å‚è§è§„åˆ™ 2ï¼‰ã€‚å…¶æ¬¡ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åŒæ­¥è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œç›´åˆ°å®Œæˆæ‰ä¼šé˜»å¡ç¨‹åºæ‰§è¡Œã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬é€šå¸¸å¼‚æ­¥è®¿é—®äº‘æ–‡ä»¶ï¼Œè¿™æ ·åœ¨ç­‰å¾…ç›¸å¯¹è¾ƒæ…¢çš„ç½‘ç»œè®¿é—®å®Œæˆæ—¶ï¼Œç¨‹åºçš„å…¶ä»–éƒ¨åˆ†ä»ç„¶å¯ä»¥ç»§ç»­è¿è¡Œã€‚ç¬¬ä¸‰ï¼Œåƒ`lines()`è¿™æ ·çš„è¿­ä»£å™¨æ”¯æŒ`for`å¾ªç¯ã€‚ç„¶è€Œï¼Œåƒ`stream_chunks()`è¿™æ ·çš„æµåˆ™ä¸æ”¯æŒï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨`while let`ã€‚

æˆ‘ä¹‹å‰æåˆ°è¿‡ï¼Œä½ ä¸éœ€è¦ä½¿ç”¨`cloud-file`åŒ…è£…å™¨ï¼Œè€Œå¯ä»¥ç›´æ¥ä½¿ç”¨`object_store` crateã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹åªä½¿ç”¨`object_store`æ–¹æ³•æ—¶ï¼Œå¦‚ä½•è®¡ç®—äº‘æ–‡ä»¶ä¸­çš„æ¢è¡Œç¬¦ï¼š

```py
use futures_util::StreamExt;  // Enables `.next()` on streams.
pub use object_store::path::Path as StorePath;
use object_store::{parse_url_opts, ObjectStore};
use std::sync::Arc;
use url::Url;

async fn count_lines(
    object_store: &Arc<Box<dyn ObjectStore>>,
    store_path: StorePath,
) -> Result<usize, anyhow::Error> {
    let mut chunks = object_store.get(&store_path).await?.into_stream();
    let mut newline_count: usize = 0;
    while let Some(chunk) = chunks.next().await {
        let chunk = chunk?;
        newline_count += bytecount::count(&chunk, b'\n');
    }
    Ok(newline_count)
}

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/toydata.5chrom.fam";
    let options = [("timeout", "10s")];

    let url = Url::parse(url)?;
    let (object_store, store_path) = parse_url_opts(&url, options)?;
    let object_store = Arc::new(object_store); // enables cloning and borrowing
    let line_count = count_lines(&object_store, store_path).await?;
    println!("line_count: {line_count}");
    Ok(())
}
```

ä½ ä¼šå‘ç°ä»£ç ä¸`cloud-file`ä»£ç éå¸¸ç›¸ä¼¼ã€‚ä¸åŒä¹‹å¤„åœ¨äºï¼š

+   ä¸å•ä¸ª`CloudFile`è¾“å…¥ä¸åŒï¼Œå¤§å¤šæ•°æ–¹æ³•éœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼š`ObjectStore`å’Œ`StorePath`ã€‚å› ä¸º`ObjectStore`æ˜¯ä¸€ä¸ªä¸å¯å…‹éš†çš„ç‰¹æ€§ï¼Œè¿™é‡Œ`count_lines`å‡½æ•°ä¸“é—¨ä½¿ç”¨äº†`&Arc<Box<dyn ObjectStore>>`ã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥å°†å‡½æ•°è®¾ä¸ºæ³›å‹ï¼Œå¹¶ä½¿ç”¨`&Arc<impl ObjectStore>`ã€‚

+   åˆ›å»º`ObjectStore`å®ä¾‹ã€`StorePath`å®ä¾‹å’Œæµéœ€è¦æ¯”åˆ›å»º`CloudFile`å®ä¾‹å’Œæµå¤šä¸€äº›æ­¥éª¤ã€‚

+   ä¸å†åªå¤„ç†ä¸€ç§é”™è¯¯ç±»å‹ï¼ˆå³`CloudFileError`ï¼‰ï¼Œè€Œæ˜¯å¯èƒ½å‡ºç°å¤šç§é”™è¯¯ç±»å‹ï¼Œå› æ­¤æˆ‘ä»¬é€€å›ä½¿ç”¨äº†`[anyhow](https://crates.io/crates/anyhow)` crateã€‚

æ— è®ºä½ æ˜¯ç›´æ¥ä½¿ç”¨`object_store`ï¼ˆç›®å‰ä¸‹è½½é‡ä¸º 240 ä¸‡æ¬¡ï¼‰ï¼Œè¿˜æ˜¯é€šè¿‡`cloud-file`é—´æ¥ä½¿ç”¨ï¼ˆç›®å‰ä¸‹è½½é‡ä¸º 124 æ¬¡ ğŸ˜€ï¼‰ï¼Œéƒ½ç”±ä½ å†³å®šã€‚

åœ¨æœ¬æ–‡çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘å°†é‡ç‚¹è®¨è®º`cloud-file`ã€‚å¦‚æœä½ æƒ³å°†`cloud-file`æ–¹æ³•è½¬æ¢ä¸ºçº¯`object_store`ä»£ç ï¼Œå¯ä»¥æŸ¥é˜…[è¯¥æ–¹æ³•çš„æ–‡æ¡£](https://docs.rs/cloud-file)ï¼Œå¹¶ç‚¹å‡»â€œsourceâ€é“¾æ¥ã€‚æºä»£ç é€šå¸¸åªæœ‰ä¸€ä¸¤è¡Œã€‚

æˆ‘ä»¬å·²ç»äº†è§£äº†å¦‚ä½•é¡ºåºè¯»å–äº‘æ–‡ä»¶çš„å­—èŠ‚ã€‚æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é¡ºåºè¯»å–å®ƒçš„è¡Œã€‚

# è§„åˆ™ 2ï¼šé€šè¿‡ä¸¤ä¸ªåµŒå¥—å¾ªç¯é¡ºåºè¯»å–äº‘æ–‡ä»¶çš„æ–‡æœ¬è¡Œã€‚

æˆ‘ä»¬ç»å¸¸éœ€è¦é¡ºåºè¯»å–äº‘æ–‡ä»¶çš„è¡Œã€‚ä½¿ç”¨`cloud-file`ï¼ˆæˆ–`object_store`ï¼‰æ¥å®ç°è¿™ä¸€ç‚¹éœ€è¦ä¸¤ä¸ªåµŒå¥—å¾ªç¯ã€‚

å¤–éƒ¨å¾ªç¯åƒä»¥å‰ä¸€æ ·è¿”å›äºŒè¿›åˆ¶å—ï¼Œä½†æœ‰ä¸€ä¸ªå…³é”®çš„ä¿®æ”¹ï¼šæˆ‘ä»¬ç°åœ¨ç¡®ä¿æ¯ä¸ªå—åªåŒ…å«å®Œæ•´çš„è¡Œï¼Œä»è¡Œçš„ç¬¬ä¸€ä¸ªå­—ç¬¦å¼€å§‹ï¼Œåˆ°æ¢è¡Œç¬¦ç»“æŸã€‚æ¢å¥è¯è¯´ï¼Œå—å¯èƒ½åŒ…å«ä¸€è¡Œæˆ–å¤šè¡Œå®Œæ•´çš„å†…å®¹ï¼Œä½†æ²¡æœ‰éƒ¨åˆ†è¡Œã€‚å†…éƒ¨å¾ªç¯å°†å—è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå¹¶è¿­ä»£ç”Ÿæˆçš„ä¸€è¡Œæˆ–å¤šè¡Œã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç»™å®šä¸€ä¸ªäº‘æ–‡ä»¶å’Œä¸€ä¸ªæ•°å­—*n*ï¼Œæˆ‘ä»¬æ‰¾å‡ºç´¢å¼•ä½ç½®*n*çš„é‚£ä¸€è¡Œï¼š

```py
use cloud_file::CloudFile;
use futures::StreamExt;  // Enables `.next()` on streams.
use std::str::from_utf8;

async fn nth_line(cloud_file: &CloudFile, n: usize) -> Result<String, anyhow::Error> {
    // Each binary line_chunk contains one or more lines, that is, each chunk ends with a newline.
    let mut line_chunks = cloud_file.stream_line_chunks().await?;
    let mut index_iter = 0usize..;
    while let Some(line_chunk) = line_chunks.next().await {
        let line_chunk = line_chunk?;
        let lines = from_utf8(&line_chunk)?.lines();
        for line in lines {
            let index = index_iter.next().unwrap(); // safe because we know the iterator is infinite
            if index == n {
                return Ok(line.to_string());
            }
        }
    }
    Err(anyhow::anyhow!("Not enough lines in the file"))
}

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/toydata.5chrom.fam";
    let n = 4;

    let cloud_file = CloudFile::new(url)?;
    let line = nth_line(&cloud_file, n).await?;
    println!("line at index {n}: {line}");
    Ok(())
}
```

è¿™æ®µä»£ç æ‰“å°ï¼š

```py
line at index 4: per4 per4 0 0 2 0.452591
```

ä¸€äº›å€¼å¾—æ³¨æ„çš„è¦ç‚¹ï¼š

+   å…³é”®æ–¹æ³•æ˜¯`.stream_line_chunks()`ã€‚

+   æˆ‘ä»¬è¿˜å¿…é¡»è°ƒç”¨`std::str::from_utf8`æ¥åˆ›å»ºæ–‡æœ¬ã€‚ï¼ˆå¯èƒ½ä¼šè¿”å›ä¸€ä¸ª`[Utf8Error](https://doc.rust-lang.org/std/str/struct.Utf8Error.html)`ã€‚ï¼‰æ­¤å¤–ï¼Œæˆ‘ä»¬è°ƒç”¨`.lines()`æ–¹æ³•æ¥åˆ›å»ºä¸€ä¸ªè¡Œè¿­ä»£å™¨ã€‚

+   å¦‚æœæˆ‘ä»¬æƒ³è¦è¡Œç´¢å¼•ï¼Œå¿…é¡»è‡ªå·±åˆ›å»ºã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ï¼š

```py
let mut index_iter = 0usize..;
...
let index = index_iter.next().unwrap(); // safe because we know the iterator is infinite
```

> æ—ç™½ï¼šä¸ºä»€ä¹ˆè¦ç”¨ä¸¤ä¸ªå¾ªç¯ï¼Ÿä¸ºä»€ä¹ˆ`cloud-file`ä¸å®šä¹‰ä¸€ä¸ªè¿”å›æ¯æ¬¡ä¸€è¡Œçš„æµï¼Ÿå› ä¸ºæˆ‘ä¸çŸ¥é“æ€ä¹ˆåšã€‚å¦‚æœæœ‰äººèƒ½ææ˜ç™½ï¼Œè¯·å‘é€ä¸€ä¸ªåŒ…å«è§£å†³æ–¹æ¡ˆçš„ pull è¯·æ±‚ç»™æˆ‘ï¼

æˆ‘å¸Œæœ›è¿™èƒ½æ›´ç®€å•äº›ã€‚æˆ‘å¾ˆé«˜å…´å®ƒæ˜¯é«˜æ•ˆçš„ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸‹ä¸€æ­¥æ¥å›å½’ç®€æ´ï¼Œçœ‹çœ‹å¦‚ä½•éšæœºè®¿é—®äº‘æ–‡ä»¶ã€‚

# è§„åˆ™ 3ï¼šä½¿ç”¨èŒƒå›´æ–¹æ³•éšæœºè®¿é—®äº‘æ–‡ä»¶ï¼Œå³ä½¿æ˜¯å·¨å¤§çš„æ–‡ä»¶ï¼ŒåŒæ—¶å°Šé‡æœåŠ¡å™¨è®¾ç½®çš„é™åˆ¶ã€‚

æˆ‘åœ¨å¤„ç†ä¸€ç§å«åš PLINK Bed 1.9 çš„åŸºå› ç»„å­¦æ–‡ä»¶æ ¼å¼ã€‚æ–‡ä»¶æœ€å¤§å¯è¾¾ 1 TBã€‚æ˜¯ä¸æ˜¯å¤ªå¤§ï¼Œæ— æ³•é€šè¿‡ç½‘ç»œè®¿é—®ï¼Ÿä¸ä¸€å®šã€‚æœ‰æ—¶å€™æˆ‘ä»¬åªéœ€è¦æ–‡ä»¶çš„ä¸€å°éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œç°ä»£äº‘æœåŠ¡ï¼ˆåŒ…æ‹¬å¤§å¤šæ•°ç½‘ç»œæœåŠ¡å™¨ï¼‰å¯ä»¥é«˜æ•ˆåœ°ä»äº‘æ–‡ä»¶ä¸­æå–æ„Ÿå…´è¶£çš„åŒºåŸŸã€‚

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä¾‹å­ã€‚è¿™ä¸ªæµ‹è¯•ä»£ç ä½¿ç”¨äº†ä¸€ä¸ªåä¸º`read_range_and_file_size`çš„`CloudFile`æ–¹æ³•ã€‚å®ƒè¯»å–ä¸€ä¸ª*.bed æ–‡ä»¶çš„å‰ 3 ä¸ªå­—èŠ‚ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»¥é¢„æœŸçš„å­—èŠ‚å¼€å¤´ï¼Œç„¶åæ£€æŸ¥æ–‡ä»¶çš„é¢„æœŸé•¿åº¦ã€‚

```py
#[tokio::test]
async fn check_file_signature() -> Result<(), CloudFileError> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/plink_sim_10s_100v_10pmiss.bed";
    let cloud_file = CloudFile::new(url)?;
    let (bytes, size) = cloud_file.read_range_and_file_size(0..3).await?;

    assert_eq!(bytes.len(), 3);
    assert_eq!(bytes[0], 0x6c);
    assert_eq!(bytes[1], 0x1b);
    assert_eq!(bytes[2], 0x01);
    assert_eq!(size, 303);
    Ok(())
}
```

æ³¨æ„ï¼Œåœ¨ä¸€æ¬¡ç½‘ç»œè°ƒç”¨ä¸­ï¼Œè¿™ä¸ªæ–¹æ³•ä¸ä»…è¿”å›è¯·æ±‚çš„å­—èŠ‚ï¼Œè¿˜è¿”å›äº†æ•´ä¸ªæ–‡ä»¶çš„å¤§å°ã€‚

è¿™é‡Œæ˜¯ä¸€äº›é«˜å±‚æ¬¡çš„`CloudFile`æ–¹æ³•åŠå®ƒä»¬åœ¨ä¸€æ¬¡ç½‘ç»œè°ƒç”¨ä¸­å¯ä»¥æ£€ç´¢çš„å†…å®¹ï¼š

+   `[read_all](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_all)` â€” ä½œä¸ºå†…å­˜ä¸­çš„`[Bytes](https://docs.rs/bytes/latest/bytes/struct.Bytes.html)`è¿”å›çš„æ•´ä¸ªæ–‡ä»¶å†…å®¹

+   `[read_range](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_range)` â€” ä»æŒ‡å®šèŒƒå›´è¯»å–çš„`[Bytes](https://docs.rs/bytes/latest/bytes/struct.Bytes.html)`

+   `[read_ranges](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_ranges)` â€” ä»æŒ‡å®šèŒƒå›´è¯»å–çš„`Vec`ç±»å‹çš„`[Bytes](https://docs.rs/bytes/latest/bytes/struct.Bytes.html)`

+   `[read_range_and_file_size](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_range_and_file_size)` â€” ä»æŒ‡å®šèŒƒå›´è¯»å–çš„`[Bytes](https://docs.rs/bytes/latest/bytes/struct.Bytes.html)`å’Œæ–‡ä»¶çš„å¤§å°

+   `[read_file_size](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_file_size)` â€” æ–‡ä»¶çš„å¤§å°

å¦‚æœæˆ‘ä»¬ä¸€æ¬¡è¯·æ±‚å¤ªå¤šæ•°æ®ï¼Œè¿™äº›æ–¹æ³•å¯èƒ½ä¼šé‡åˆ°ä¸¤ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬çš„äº‘æœåŠ¡å¯èƒ½ä¼šé™åˆ¶æ¯æ¬¡è°ƒç”¨èƒ½æ£€ç´¢çš„å­—èŠ‚æ•°ã€‚å…¶æ¬¡ï¼Œé€šè¿‡åŒæ—¶å‘å‡ºå¤šä¸ªè¯·æ±‚è€Œä¸æ˜¯ä¸€æ¬¡å‘ä¸€ä¸ªè¯·æ±‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¾—åˆ°æ›´å¿«çš„ç»“æœã€‚

è€ƒè™‘è¿™ä¸ªä¾‹å­ï¼šæˆ‘ä»¬æƒ³è¦æ”¶é›†ä¸€ä¸ªä»»æ„å¤§å°çš„æ–‡ä»¶ä¸­ç›¸é‚» ASCII å­—ç¬¦çš„é¢‘ç‡ç»Ÿè®¡ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªåŒ…å« 10,000 ä¸ªç›¸é‚»å­—ç¬¦çš„éšæœºæ ·æœ¬ä¸­ï¼Œæˆ–è®¸â€œthâ€å‡ºç°äº† 171 æ¬¡ã€‚

å‡è®¾æˆ‘ä»¬çš„ Web æœåŠ¡å™¨æ”¯æŒ 10 ä¸ªå¹¶å‘è¯·æ±‚ï¼Œä½†æ¯ä¸ªè¯·æ±‚åªå…è®¸æˆ‘ä»¬è·å– 750 å­—èŠ‚ã€‚ï¼ˆ8 MB ä¼šæ˜¯ä¸€ä¸ªæ›´å¸¸è§çš„é™åˆ¶ï¼‰ã€‚

> æ„Ÿè°¢ Seattle Rust Meetup çš„ Ben Lichtmanï¼ˆB3NNYï¼‰æŒ‡å¼•æˆ‘æ­£ç¡®çš„æ–¹å‘ï¼Œå¸®åŠ©æˆ‘å‘å¼‚æ­¥æµæ·»åŠ äº†é™åˆ¶ã€‚

æˆ‘ä»¬çš„ä¸»å‡½æ•°å¯èƒ½é•¿è¿™æ ·ï¼š

```py
#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let url = "https://www.gutenberg.org/cache/epub/100/pg100.txt";
    let options = [("timeout", "30s")];
    let cloud_file = CloudFile::new_with_options(url, options)?;

    let seed = Some(0u64);
    let sample_count = 10_000;
    let max_chunk_bytes = 750; // 8_000_000 is a good default when chunks are bigger.
    let max_concurrent_requests = 10; // 10 is a good default

    count_bigrams(
        cloud_file,
        sample_count,
        seed,
        max_concurrent_requests,
        max_chunk_bytes,
    )
    .await?;

    Ok(())
}
```

`count_bigrams`å‡½æ•°å¯ä»¥é¦–å…ˆåˆ›å»ºä¸€ä¸ªéšæœºæ•°ç”Ÿæˆå™¨ï¼Œå¹¶è°ƒç”¨æ¥æŸ¥æ‰¾äº‘æ–‡ä»¶çš„å¤§å°ï¼š

```py
#[cfg(not(target_pointer_width = "64"))]
compile_error!("This code requires a 64-bit target architecture.");

use cloud_file::CloudFile;
use futures::pin_mut;
use futures_util::StreamExt; // Enables `.next()` on streams.
use rand::{rngs::StdRng, Rng, SeedableRng};
use std::{cmp::max, collections::HashMap, ops::Range};

async fn count_bigrams(
    cloud_file: CloudFile,
    sample_count: usize,
    seed: Option<u64>,
    max_concurrent_requests: usize,
    max_chunk_bytes: usize,
) -> Result<(), anyhow::Error> {
    // Create a random number generator
    let mut rng = if let Some(s) = seed {
        StdRng::seed_from_u64(s)
    } else {
        StdRng::from_entropy()
    };

    // Find the document size
    let file_size = cloud_file.read_file_size().await?;
//...
```

æ¥ä¸‹æ¥ï¼Œæ ¹æ®æ–‡ä»¶å¤§å°ï¼Œå‡½æ•°å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å« 10,000 ä¸ªéšæœºä¸¤å­—èŠ‚èŒƒå›´çš„å‘é‡ã€‚

```py
 // Randomly choose the two-byte ranges to sample
    let range_samples: Vec<Range<usize>> = (0..sample_count)
        .map(|_| rng.gen_range(0..file_size - 1))
        .map(|start| start..start + 2)
        .collect();
```

ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½ç”Ÿæˆä»¥ä¸‹å‘é‡`[4122418..4122420, 4361192..4361194, 145726..145728,` â€¦ `]`ã€‚ä½†ä¸€æ¬¡æ€§è·å– 20,000 å­—èŠ‚ï¼ˆæˆ‘ä»¬å‡è®¾è¿™æ ·ï¼‰å¤ªå¤šäº†ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å°†å‘é‡åˆ†æˆ 27 ä¸ªå—ï¼Œæ¯ä¸ªå—ä¸è¶…è¿‡ 750 å­—èŠ‚ï¼š

```py
 // Divide the ranges into chunks respecting the max_chunk_bytes limit
    const BYTES_PER_BIGRAM: usize = 2;
    let chunk_count = max(1, max_chunk_bytes / BYTES_PER_BIGRAM);
    let range_chunks = range_samples.chunks(chunk_count);
```

ä½¿ç”¨ä¸€äº›å¼‚æ­¥é­”æ³•ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ª 27 ä¸ªå—åˆ›å»ºä¸€ä¸ªæœªæ¥å·¥ä½œçš„è¿­ä»£å™¨ï¼Œç„¶åå°†è¯¥è¿­ä»£å™¨è½¬æ¢ä¸ºæµã€‚æˆ‘ä»¬å‘Šè¯‰æµæœ€å¤šåŒæ—¶è°ƒç”¨ 10 ä¸ªè¯·æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¡¨ç¤ºå¯ä»¥æ¥å—ä¹±åºçš„ç»“æœã€‚

```py
 // Create an iterator of future work
    let work_chunks_iterator = range_chunks.map(|chunk| {
        let cloud_file = cloud_file.clone(); // by design, clone is cheap
        async move { cloud_file.read_ranges(chunk).await }
    });

    // Create a stream of futures to run out-of-order and with constrained concurrency.
    let work_chunks_stream =
        futures_util::stream::iter(work_chunks_iterator).buffer_unordered(max_concurrent_requests);
    pin_mut!(work_chunks_stream); // The compiler says we need this
```

åœ¨æœ€åä¸€æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨æµä¸­è¿›è¡Œå·¥ä½œï¼Œå¹¶ä¸”â€”éšç€ç»“æœçš„åˆ°æ¥â€”è¿›è¡Œæ±‡æ€»ã€‚æœ€åï¼Œæˆ‘ä»¬å¯¹ç»“æœè¿›è¡Œæ’åºå¹¶æ‰“å°å‡ºæœ€å¥½çš„ç»“æœã€‚

```py
 // Run the futures and, as result bytes come in, tabulate.
    let mut bigram_counts = HashMap::new();
    while let Some(result) = work_chunks_stream.next().await {
        let bytes_vec = result?;
        for bytes in bytes_vec.iter() {
            let bigram = (bytes[0], bytes[1]);
            let count = bigram_counts.entry(bigram).or_insert(0);
            *count += 1;
        }
    }

    // Sort the bigrams by count and print the top 10
    let mut bigram_count_vec: Vec<(_, usize)> = bigram_counts.into_iter().collect();
    bigram_count_vec.sort_by(|a, b| b.1.cmp(&a.1));
    for (bigram, count) in bigram_count_vec.into_iter().take(10) {
        let char0 = (bigram.0 as char).escape_default();
        let char1 = (bigram.1 as char).escape_default();
        println!("Bigram ('{}{}') occurs {} times", char0, char1, count);
    }
    Ok(())
}
```

è¾“å‡ºæ˜¯ï¼š

```py
Bigram ('\r\n') occurs 367 times
Bigram ('e ') occurs 221 times
Bigram (' t') occurs 184 times
Bigram ('th') occurs 171 times
Bigram ('he') occurs 158 times
Bigram ('s ') occurs 143 times
Bigram ('.\r') occurs 136 times
Bigram ('d ') occurs 133 times
Bigram (', ') occurs 127 times
Bigram (' a') occurs 121 times
```

Bed-Reader åŸºå› ç»„å­¦ crate çš„ä»£ç ä½¿ç”¨ç›¸åŒçš„æŠ€æœ¯æ¥ä»åˆ†æ•£çš„ DNA åŒºåŸŸè·å–ä¿¡æ¯ã€‚å½“ DNA ä¿¡æ¯åˆ°è¾¾æ—¶ï¼Œå¯èƒ½æ˜¯ä¹±åºçš„ï¼Œä»£ç ä¼šå¡«å……è¾“å‡ºæ•°ç»„çš„æ­£ç¡®åˆ—ã€‚

> é¡ºä¾¿æä¸€ä¸‹ï¼šæ­¤æ–¹æ³•ä½¿ç”¨äº†è¿­ä»£å™¨ã€æµå’Œå¾ªç¯ã€‚æˆ‘å¸Œæœ›å®ƒèƒ½æ›´ç®€å•ã€‚å¦‚æœä½ èƒ½æ‰¾åˆ°ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•æ¥è·å–åŒºåŸŸçš„å‘é‡ï¼ŒåŒæ—¶é™åˆ¶æœ€å¤§å—å¤§å°å’Œå¹¶å‘è¯·æ±‚æ•°ï¼Œè¯·å‘ç»™æˆ‘ä¸€ä¸ª pull requestã€‚

è¿™æ¶µç›–äº†è®¿é—®å­˜å‚¨åœ¨ HTTP æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶ï¼Œä½† AWS S3 å’Œå…¶ä»–äº‘æœåŠ¡å‘¢ï¼Ÿæœ¬åœ°æ–‡ä»¶æ€ä¹ˆåŠï¼Ÿ

# è§„åˆ™ 4ï¼šä½¿ç”¨ URL å­—ç¬¦ä¸²å’Œé€‰é¡¹å­—ç¬¦ä¸²æ¥è®¿é—® HTTPã€æœ¬åœ°æ–‡ä»¶ã€AWS S3ã€Azure å’Œ Google Cloudã€‚

`object_store` crateï¼ˆä»¥åŠ`cloud-file`åŒ…è£… crateï¼‰æ”¯æŒé€šè¿‡ URL å­—ç¬¦ä¸²æˆ–ç»“æ„ä½“æŒ‡å®šæ–‡ä»¶ã€‚æˆ‘å»ºè®®ä½¿ç”¨ URL å­—ç¬¦ä¸²ï¼Œä½†é€‰æ‹©æƒåœ¨ä½ ã€‚

è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ª AWS S3 çš„ç¤ºä¾‹ã€‚å¦‚ä½ æ‰€è§ï¼ŒAWS è®¿é—®éœ€è¦å‡­è¯ä¿¡æ¯ã€‚

```py
use cloud_file::CloudFile;
use rusoto_credential::{CredentialsError, ProfileProvider, ProvideAwsCredentials};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    // get credentials from ~/.aws/credentials
    let credentials = if let Ok(provider) = ProfileProvider::new() {
        provider.credentials().await
    } else {
        Err(CredentialsError::new("No credentials found"))
    };

    let Ok(credentials) = credentials else {
        eprintln!("Skipping example because no AWS credentials found");
        return Ok(());
    };

    let url = "s3://bedreader/v1/toydata.5chrom.bed";
    let options = [
        ("aws_region", "us-west-2"),
        ("aws_access_key_id", credentials.aws_access_key_id()),
        ("aws_secret_access_key", credentials.aws_secret_access_key()),
    ];
    let cloud_file = CloudFile::new_with_options(url, options)?;

    assert_eq!(cloud_file.read_file_size().await?, 1_250_003);
    Ok(())
}
```

å…³é”®éƒ¨åˆ†æ˜¯ï¼š

```py
 let url = "s3://bedreader/v1/toydata.5chrom.bed";
    let options = [
        ("aws_region", "us-west-2"),
        ("aws_access_key_id", credentials.aws_access_key_id()),
        ("aws_secret_access_key", credentials.aws_secret_access_key()),
    ];
    let cloud_file = CloudFile::new_with_options(url, options)?;
```

å¦‚æœæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ç»“æ„ä½“è€Œä¸æ˜¯ URL å­—ç¬¦ä¸²ï¼Œåˆ™å˜ä¸ºï¼š

```py
 use object_store::{aws::AmazonS3Builder, path::Path as StorePath};

    let s3 = AmazonS3Builder::new()
        .with_region("us-west-2")
        .with_bucket_name("bedreader")
        .with_access_key_id(credentials.aws_access_key_id())
        .with_secret_access_key(credentials.aws_secret_access_key())
        .build()?;
    let store_path = StorePath::parse("v1/toydata.5chrom.bed")?;
    let cloud_file = CloudFile::from_structs(s3, store_path);
```

æˆ‘æ›´å–œæ¬¢ URL æ–¹æ³•è€Œä¸æ˜¯ç»“æ„ä½“ã€‚æˆ‘å‘ç° URL ç¨å¾®ç®€å•ä¸€äº›ï¼Œæ›´åŠ ç»Ÿä¸€ï¼Œè·¨äº‘æœåŠ¡æ—¶ä¹Ÿæ›´å®¹æ˜“äº’æ“ä½œï¼ˆä¾‹å¦‚ä¸ Pythonï¼‰ã€‚

è¿™é‡Œæ˜¯æˆ‘ä½¿ç”¨çš„ä¸‰ä¸ª Web æœåŠ¡çš„ç¤ºä¾‹ URLï¼š

+   HTTP â€” `[`www.gutenberg.org/cache/epub/100/pg100.txt`](https://www.gutenberg.org/cache/epub/100/pg100.txt)`

+   æœ¬åœ°æ–‡ä»¶ â€” `file:///M:/data%20files/small.bed` â€” ä½¿ç”¨`cloud_file::abs_path_to_url_string`å‡½æ•°å°†å®Œæ•´çš„æ–‡ä»¶è·¯å¾„æ­£ç¡®ç¼–ç ä¸º URLã€‚

+   AWS S3 â€” `s3://bedreader/v1/toydata.5chrom.bed`

æœ¬åœ°æ–‡ä»¶ä¸éœ€è¦é€‰é¡¹ã€‚å¯¹äºå…¶ä»–æœåŠ¡ï¼Œè¿™é‡Œæ˜¯å®ƒä»¬æ”¯æŒçš„é€‰é¡¹å’Œä¸€äº›ç¤ºä¾‹é“¾æ¥ï¼š

+   HTTP â€” `[ClientConfigKey](https://docs.rs/object_store/latest/object_store/enum.ClientConfigKey.html#variant.Timeout)` â€” `[("timeout", "30s")]`

+   AWS S3 â€” `[AmazonS3ConfigKey](https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html)` â€” `[("aws_region", "us-west-2"), ("aws_access_key_id",` â€¦`), ("aws_secret_access_key",` â€¦`)]`

+   Azure â€” `[AzureConfigKey](https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html)`

+   Google â€” `[GoogleConfigKey](https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html)`

ç°åœ¨æˆ‘ä»¬å¯ä»¥æŒ‡å®šå’Œè¯»å–äº‘æ–‡ä»¶ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åº”è¯¥åˆ›å»ºæµ‹è¯•ã€‚

# è§„åˆ™ 5ï¼šé€šè¿‡ `tokio::test` å¯¹ HTTP æ–‡ä»¶å’Œæœ¬åœ°æ–‡ä»¶è¿›è¡Œæµ‹è¯•ã€‚

`object_store` crateï¼ˆä»¥åŠ `cloud-file`ï¼‰æ”¯æŒä»»ä½•å¼‚æ­¥è¿è¡Œæ—¶ã€‚ä¸ºäº†æµ‹è¯•ï¼Œ[Tokio è¿è¡Œæ—¶](https://docs.rs/tokio/latest/tokio/index.html)ä½¿å¾—åœ¨äº‘æ–‡ä»¶ä¸Šæµ‹è¯•ä»£ç å˜å¾—ç®€å•ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªé’ˆå¯¹ HTTP æ–‡ä»¶çš„æµ‹è¯•ï¼š

```py
[tokio::test]
async fn cloud_file_extension() -> Result<(), CloudFileError> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/plink_sim_10s_100v_10pmiss.bed";
    let mut cloud_file = CloudFile::new(url)?;
    assert_eq!(cloud_file.read_file_size().await?, 303);
    cloud_file.set_extension("fam")?;
    assert_eq!(cloud_file.read_file_size().await?, 130);
    Ok(())
}
```

è¿è¡Œæ­¤æµ‹è¯•å‘½ä»¤ï¼š

```py
cargo test
```

å¦‚æœæ‚¨ä¸æƒ³é€šè¿‡æµ‹è¯•è®¿é—®å¤–éƒ¨ Web æœåŠ¡å™¨ï¼Œæ‚¨å¯ä»¥æ”¹ä¸ºå°†æœ¬åœ°æ–‡ä»¶å½“ä½œäº‘æ–‡ä»¶è¿›è¡Œæµ‹è¯•ã€‚

```py
#[tokio::test]
async fn local_file() -> Result<(), CloudFileError> {
    use std::env;

    let apache_url = abs_path_to_url_string(env::var("CARGO_MANIFEST_DIR").unwrap()
             + "/LICENSE-APACHE")?;
    let cloud_file = CloudFile::new(&apache_url)?;
    assert_eq!(cloud_file.read_file_size().await?, 9898);
    Ok(())
}
```

è¿™ä½¿ç”¨æ ‡å‡†çš„ Rust ç¯å¢ƒå˜é‡ `[CARGO_MANIFEST_DIR](https://doc.rust-lang.org/cargo/reference/environment-variables.html)` æ¥æŸ¥æ‰¾æ–‡æœ¬æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨ `cloud_file::abs_path_to_url_string` å°†è¯¥å®Œæ•´è·¯å¾„æ­£ç¡®ç¼–ç ä¸º URLã€‚

æ— è®ºæ˜¯åœ¨ HTTP æ–‡ä»¶è¿˜æ˜¯æœ¬åœ°æ–‡ä»¶ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œ`object_store` çš„å¼ºå¤§åŠŸèƒ½æ„å‘³ç€æ‚¨çš„ä»£ç åº”è¯¥èƒ½åœ¨ä»»ä½•äº‘æœåŠ¡ä¸Šè¿è¡Œï¼ŒåŒ…æ‹¬ AWS S3ã€Azure å’Œ Google Cloudã€‚

å¦‚æœæ‚¨åªéœ€è¦è®¿é—®äº‘æ–‡ä»¶ä¾›è‡ªå·±ä½¿ç”¨ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œåœæ­¢é˜…è¯»è§„åˆ™å¹¶è·³åˆ°ç»“è®ºéƒ¨åˆ†ã€‚å¦‚æœæ‚¨æ˜¯ä¸ºä»–äººæ·»åŠ äº‘è®¿é—®åˆ°ä¸€ä¸ªåº“ï¼ˆRust crateï¼‰ï¼Œè¯·ç»§ç»­é˜…è¯»ã€‚

# è§„åˆ™ 6ï¼šä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œé€šè¿‡å¼‚æ­¥ API å°†äº‘æ–‡ä»¶æ”¯æŒæ·»åŠ åˆ°æ‚¨çš„ Rust åº“ä¸­ã€‚

å¦‚æœæ‚¨æä¾› Rust crate ç»™ä»–äººä½¿ç”¨ï¼Œæ”¯æŒäº‘æ–‡ä»¶ä¸ºæ‚¨çš„ç”¨æˆ·æä¾›äº†æå¤§çš„ä¾¿åˆ©ï¼Œä½†ä¹Ÿæœ‰ä¸€å®šæˆæœ¬ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹æˆ‘ä¸º [Bed-Reader](https://pypi.org/project/bed-reader/) æ·»åŠ äº†äº‘æ”¯æŒçš„åŸºå› ç»„å­¦ crateã€‚

å¦‚å‰æ‰€è¿°ï¼ŒBed-Reader æ˜¯ä¸€ä¸ªç”¨äºè¯»å–å’Œå†™å…¥ PLINK Bed æ–‡ä»¶çš„åº“ï¼ŒPLINK Bed æ–‡ä»¶æ˜¯ä¸€ç§åœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­ç”¨äºå­˜å‚¨åŸºå› å‹ï¼ˆDNAï¼‰æ•°æ®çš„äºŒè¿›åˆ¶æ ¼å¼ã€‚Bed æ ¼å¼çš„æ–‡ä»¶å¯ä»¥å¤§åˆ°ä¸€ä¸ª TBã€‚Bed-Reader ä¸ºç”¨æˆ·æä¾›å¯¹å¤§é‡æ•°æ®å­é›†çš„å¿«é€Ÿéšæœºè®¿é—®ã€‚å®ƒè¿”å›ä¸€ä¸ªäºŒç»´æ•°ç»„ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹© int8ã€float32 æˆ– float64 æ ¼å¼ã€‚Bed-Reader è¿˜ä¸ºç”¨æˆ·æä¾›äº† 12 ä¸ªå…ƒæ•°æ®å­—æ®µï¼Œå…¶ä¸­å…­ä¸ªä¸ä¸ªä½“ç›¸å…³ï¼Œå…­ä¸ªä¸ SNPï¼ˆå¤§è‡´æ¥è¯´ï¼Œæ˜¯ DNA ä½ç½®ï¼‰ç›¸å…³ã€‚åŸºå› å‹æ•°æ®é€šå¸¸æ¯”å…ƒæ•°æ®å¤§ 100,000 å€ã€‚

![](img/210196974c88a9518883ab78d09b7c00.png)

PLINK å­˜å‚¨åŸºå› å‹æ•°æ®å’Œå…ƒæ•°æ®ã€‚ï¼ˆå›¾ç”±ä½œè€…æä¾›ã€‚ï¼‰

> æ—æ³¨ï¼šåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ï¼Œâ€œ[API](https://en.wikipedia.org/wiki/API)â€æŒ‡çš„æ˜¯åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ã€‚å®ƒæ˜¯ç”±è¯¸å¦‚ Bed-Reader ä¹‹ç±»çš„åº“ä»£ç æä¾›çš„å…¬å…±ç»“æ„ã€æ–¹æ³•ç­‰ï¼Œä¾›å…¶ä»–ç¨‹åºè°ƒç”¨ã€‚

è¿™é‡Œæ˜¯ä½¿ç”¨ Bed-Reader åŸå§‹â€œæœ¬åœ°æ–‡ä»¶â€API çš„ç¤ºä¾‹ä»£ç ã€‚è¯¥ä»£ç åˆ—å‡ºäº†å‰äº”ä¸ªä¸ªä½“ IDï¼Œå‰äº”ä¸ª SNP IDï¼Œä»¥åŠæ¯ä¸ªç‹¬ç‰¹çš„æŸ“è‰²ä½“ç¼–å·ã€‚ç„¶åï¼Œå®ƒè¯»å–æŸ“è‰²ä½“ 5 ä¸­çš„æ¯ä¸ªåŸºå› ç»„å€¼ï¼š

```py
#[test]
fn lib_intro() -> Result<(), Box<BedErrorPlus>> {
    let file_name = sample_bed_file("some_missing.bed")?;

    let mut bed = Bed::new(file_name)?;
    println!("{:?}", bed.iid()?.slice(s![..5])); // Outputs ndarray: ["iid_0", "iid_1", "iid_2", "iid_3", "iid_4"]
    println!("{:?}", bed.sid()?.slice(s![..5])); // Outputs ndarray: ["sid_0", "sid_1", "sid_2", "sid_3", "sid_4"]
    println!("{:?}", bed.chromosome()?.iter().collect::<HashSet<_>>());
    // Outputs: {"12", "10", "4", "8", "19", "21", "9", "15", "6", "16", "13", "7", "17", "18", "1", "22", "11", "2", "20", "3", "5", "14"}
    let _ = ReadOptions::builder()
        .sid_index(bed.chromosome()?.map(|elem| elem == "5"))
        .f64()
        .read(&mut bed)?;

    Ok(())
}
```

è¿™æ˜¯ä½¿ç”¨æ–°äº‘æ–‡ä»¶ API çš„ç›¸åŒä»£ç ï¼š

```py
#[tokio::test]
async fn cloud_lib_intro() -> Result<(), Box<BedErrorPlus>> {
    let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/some_missing.bed";
    let cloud_options = [("timeout", "10s")];

    let mut bed_cloud = BedCloud::new_with_options(url, cloud_options).await?;
    println!("{:?}", bed_cloud.iid().await?.slice(s![..5])); // Outputs ndarray: ["iid_0", "iid_1", "iid_2", "iid_3", "iid_4"]
    println!("{:?}", bed_cloud.sid().await?.slice(s![..5])); // Outputs ndarray: ["sid_0", "sid_1", "sid_2", "sid_3", "sid_4"]
    println!(
        "{:?}",
        bed_cloud.chromosome().await?.iter().collect::<HashSet<_>>()
    );
    // Outputs: {"12", "10", "4", "8", "19", "21", "9", "15", "6", "16", "13", "7", "17", "18", "1", "22", "11", "2", "20", "3", "5", "14"}
    let _ = ReadOptions::builder()
        .sid_index(bed_cloud.chromosome().await?.map(|elem| elem == "5"))
        .f64()
        .read_cloud(&mut bed_cloud)
        .await?;

    Ok(())
}
```

å½“åˆ‡æ¢åˆ°äº‘æ•°æ®æ—¶ï¼ŒBed-Reader ç”¨æˆ·å¿…é¡»åšå‡ºä»¥ä¸‹æ›´æ”¹ï¼š

+   ä»–ä»¬å¿…é¡»åœ¨ä¸€ä¸ªå¼‚æ­¥ç¯å¢ƒä¸­è¿è¡Œï¼Œè¿™é‡Œæ˜¯ `#[tokio::test]`ã€‚

+   ä»–ä»¬å¿…é¡»ä½¿ç”¨ä¸€ä¸ªæ–°çš„ç»“æ„ä½“ `BedCloud`ï¼Œè€Œä¸æ˜¯ `Bed`ã€‚ï¼ˆå¦å¤–ï¼Œæœªå±•ç¤ºçš„æ˜¯ï¼Œä½¿ç”¨ `BedCloudBuilder` è€Œä¸æ˜¯ `BedBuilder`ã€‚ï¼‰

+   å®ƒä»¬æä¾›äº†ä¸€ä¸ª URL å­—ç¬¦ä¸²å’Œå¯é€‰çš„å­—ç¬¦ä¸²é€‰é¡¹ï¼Œè€Œä¸æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ã€‚

+   ä»–ä»¬å¿…é¡»åœ¨è®¸å¤šåœ°æ–¹ä½¿ç”¨ `.await`ï¼Œè¿™äº›åœ°æ–¹å¾€å¾€æ˜¯ä¸å¯é¢„æµ‹çš„ã€‚ï¼ˆå¹¸è¿çš„æ˜¯ï¼Œå¦‚æœä»–ä»¬æ¼æ‰äº†æŸä¸ªåœ°æ–¹ï¼Œç¼–è¯‘å™¨ä¼šç»™å‡ºå¾ˆå¥½çš„é”™è¯¯æç¤ºã€‚ï¼‰

+   `ReadOptionsBuilder` å¢åŠ äº†ä¸€ä¸ªæ–°æ–¹æ³• `read_cloud`ï¼Œç”¨äºé…åˆä¹‹å‰çš„ `read` æ–¹æ³•ã€‚

ä»åº“å¼€å‘è€…çš„è§’åº¦æ¥çœ‹ï¼Œæ·»åŠ æ–°çš„ `BedCloud` å’Œ `BedCloudBuilder` ç»“æ„ä½“éœ€è¦å¢åŠ å¤§é‡çš„ä¸»ä»£ç å’Œæµ‹è¯•ä»£ç ã€‚åœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œæ˜¯ 2200 è¡Œæ–°çš„ä¸»ä»£ç å’Œ 2400 è¡Œæ–°çš„æµ‹è¯•ä»£ç ã€‚

> æ—æ³¨ï¼šæ­¤å¤–ï¼Œè¿˜å¯ä»¥å‚è€ƒ Mario Ortiz Manero çš„æ–‡ç«  â€œ[æˆ‘ç”Ÿå‘½ä¸­çš„ç—›è‹¦ï¼šåœ¨ Rust ä¸­æ”¯æŒå¼‚æ­¥å’ŒåŒæ­¥ä»£ç ](https://nullderef.com/blog/rust-async-sync/)â€ã€‚

ç”¨æˆ·ä»è¿™äº›æ”¹åŠ¨ä¸­è·å¾—çš„å¥½å¤„æ˜¯å¯ä»¥åˆ©ç”¨å¼‚æ­¥çš„é«˜æ•ˆæ€§ä»äº‘æ–‡ä»¶ä¸­è¯»å–æ•°æ®ã€‚

è¿™ç§å¥½å¤„å€¼å¾—å—ï¼Ÿå¦‚æœä¸å€¼å¾—ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†çœ‹ä¸€ä¸‹æ›¿ä»£æ–¹æ¡ˆã€‚

# è§„åˆ™ 7ï¼šæˆ–è€…ï¼Œä¸ºäº†æœ€å¤§ç¨‹åº¦çš„ä¾¿åˆ©ï¼Œé€šè¿‡ä¼ ç»Ÿçš„ï¼ˆâ€œåŒæ­¥â€ï¼‰API å‘ä½ çš„ Rust åº“æ·»åŠ äº‘æ–‡ä»¶æ”¯æŒã€‚

å¦‚æœä¸ºä½ æ·»åŠ ä¸€ä¸ªé«˜æ•ˆçš„å¼‚æ­¥ API çœ‹èµ·æ¥å¤ªéº»çƒ¦ï¼Œæˆ–è€…å¯¹ä½ çš„ç”¨æˆ·æ¥è¯´å¤ªæ··ä¹±ï¼Œé‚£ä¹Ÿæœ‰æ›¿ä»£æ–¹æ¡ˆã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å¯ä»¥æä¾›ä¸€ä¸ªä¼ ç»Ÿçš„ï¼ˆâ€œåŒæ­¥â€ï¼‰APIã€‚æˆ‘åœ¨ Bed-Reader çš„ Python ç‰ˆæœ¬å’Œæ”¯æŒè¯¥ Python ç‰ˆæœ¬çš„ Rust ä»£ç ä¸­å°±æ˜¯è¿™ä¹ˆåšçš„ã€‚

> æ—æ³¨ï¼šè§ï¼š[ç”¨ Rust ç¼–å†™ Python æ‰©å±•çš„ä¹æ¡è§„åˆ™ï¼šä»å‡çº§ Python ç”Ÿç‰©ä¿¡æ¯å­¦åŒ… Bed-Reader ä¸­è·å¾—çš„å®é™…ç»éªŒæ•™è®­](https://medium.com/towards-data-science/nine-rules-for-writing-python-extensions-in-rust-d35ea3a4ec29)ï¼Œã€Š*Towards Data Science*ã€‹ã€‚

è¿™é‡Œæ˜¯ Python è°ƒç”¨çš„ Rust å‡½æ•°ï¼Œç”¨äºæ£€æŸ¥ä¸€ä¸ª *.bed æ–‡ä»¶æ˜¯å¦ä»¥æ­£ç¡®çš„æ–‡ä»¶ç­¾åå¼€å§‹ã€‚

```py
use tokio::runtime;
// ...
    #[pyfn(m)]
    fn check_file_cloud(location: &str, options: HashMap<&str, String>) -> Result<(), PyErr> {
        runtime::Runtime::new()?.block_on(async {
            BedCloud::new_with_options(location, options).await?;
            Ok(())
        })
    }
```

è¯·æ³¨æ„ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ã€‚å®ƒæ˜¯ä¸€ä¸ªæ™®é€šçš„â€œåŒæ­¥â€å‡½æ•°ã€‚åœ¨è¿™ä¸ªåŒæ­¥å‡½æ•°å†…éƒ¨ï¼ŒRust è¿›è¡Œäº†ä¸€ä¸ªå¼‚æ­¥è°ƒç”¨ï¼š

```py
BedCloud::new_with_options(location, options).await?;
```

æˆ‘ä»¬é€šè¿‡å°†å¼‚æ­¥è°ƒç”¨åŒ…è£…åœ¨ Tokio è¿è¡Œæ—¶ä¸­æ¥ä½¿å…¶å˜ä¸ºåŒæ­¥ï¼š

```py
use tokio::runtime;
// ...

runtime::Runtime::new()?.block_on(async {
    BedCloud::new_with_options(location, options).await?;
    Ok(())
})
```

Bed-Reader çš„ Python ç”¨æˆ·ä¹‹å‰å¯ä»¥ä½¿ç”¨å‘½ä»¤ `open_bed(file_name_string)` æ‰“å¼€ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶è¿›è¡Œè¯»å–ã€‚ç°åœ¨ï¼Œä»–ä»¬ä¹Ÿå¯ä»¥ç”¨ç›¸åŒçš„å‘½ä»¤ `open_bed(url_string)` æ‰“å¼€ä¸€ä¸ªäº‘æ–‡ä»¶è¿›è¡Œè¯»å–ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯ä»–ä»¬ä¼ å…¥çš„å­—ç¬¦ä¸²æ ¼å¼ã€‚

è¿™æ˜¯è§„åˆ™ 6 ä¸­çš„ç¤ºä¾‹ï¼Œä½¿ç”¨æ›´æ–°åçš„ Python API çš„ Python ä»£ç ï¼š

```py
 with open_bed(
      "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/some_missing.bed",
      cloud_options={"timeout": "30s"},
  ) as bed:
      print(bed.iid[:5])
      print(bed.sid[:5])
      print(np.unique(bed.chromosome))
      val = bed.read(index=np.s_[:, bed.chromosome == "5"])
      print(val.shape)
```

è¯·æ³¨æ„ï¼ŒPython API è¿˜æä¾›äº†ä¸€ä¸ªåä¸º `cloud_options` çš„æ–°å¯é€‰å‚æ•°ã€‚æ­¤å¤–ï¼Œå¹•åæœ‰ä¸€å°æ®µæ–°ä»£ç ï¼ŒåŒºåˆ†äº†è¡¨ç¤ºæœ¬åœ°æ–‡ä»¶å’Œè¡¨ç¤º URL çš„å­—ç¬¦ä¸²ã€‚

åœ¨ Rust ä¸­ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ç›¸åŒçš„æŠ€å·§ä½¿ `object_cloud` çš„è°ƒç”¨å˜ä¸ºåŒæ­¥ã€‚å…·ä½“è€Œè¨€ï¼Œä½ å¯ä»¥å°†å¼‚æ­¥è°ƒç”¨åŒ…è£…åœ¨è¿è¡Œæ—¶ä¸­ã€‚å¥½å¤„æ˜¯æ¥å£æ›´ç®€å•ï¼Œåº“ä»£ç æ›´å°‘ã€‚ä»£ä»·æ˜¯æ•ˆç‡æ¯”æä¾›å¼‚æ­¥ API è¦ä½ã€‚

å¦‚æœä½ å†³å®šæ”¾å¼ƒâ€œåŒæ­¥â€æ›¿ä»£æ–¹æ¡ˆï¼Œé€‰æ‹©æä¾›å¼‚æ­¥ APIï¼Œä½ ä¼šå‘ç°ä¸€ä¸ªæ–°é—®é¢˜ï¼šå¦‚ä½•åœ¨æ–‡æ¡£ä¸­æä¾›å¼‚æ­¥ç¤ºä¾‹ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚

# è§„åˆ™ 8ï¼šé€šè¿‡åœ¨æ–‡æ¡£æµ‹è¯•ä¸­ä½¿ç”¨éšè—è¡Œï¼Œéµå¾ªè‰¯å¥½çš„ API è®¾è®¡è§„åˆ™ã€‚

æ–‡ç« ä¸­çš„æ‰€æœ‰è§„åˆ™ [ä¼˜é›… Rust åº“ API çš„ä¹æ¡è§„åˆ™ï¼šä»å°† Bed-Readerï¼ˆä¸€ç§ç”Ÿç‰©ä¿¡æ¯å­¦åº“ï¼‰ä» Python ç§»æ¤åˆ° Rust ä¸­å¾—åˆ°çš„å®è·µç»éªŒ](https://medium.com/towards-data-science/nine-rules-for-elegant-rust-library-apis-9b986a465247) é€‚ç”¨ï¼Œç‰¹åˆ«æ˜¯ä»¥ä¸‹ä¸¤æ¡ï¼š

*ç¼–å†™è‰¯å¥½çš„æ–‡æ¡£ï¼Œä¿æŒè®¾è®¡çš„è¯šå®ã€‚

åˆ›å»ºä¸ä¼šè®©ä½ å°´å°¬çš„ç¤ºä¾‹ã€‚*

è¿™è¡¨æ˜æˆ‘ä»¬åº”è¯¥åœ¨æ–‡æ¡£ä¸­ç»™å‡ºç¤ºä¾‹ï¼Œä½†å¦‚ä½•åœ¨å¼‚æ­¥æ–¹æ³•å’Œ await ä¸­å®ç°è¿™ä¸€ç‚¹å‘¢ï¼Ÿçªé—¨åœ¨äºåœ¨æˆ‘ä»¬çš„[æ–‡æ¡£æµ‹è¯•](https://doc.rust-lang.org/rustdoc/write-documentation/documentation-tests.html)ä¸­ä½¿ç”¨â€œéšè—è¡Œâ€ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹æ˜¯ `[CloudFile::read_ranges](https://docs.rs/cloud-file/0.1.0-beta.2/cloud_file/struct.CloudFile.html#method.read_ranges)` çš„æ–‡æ¡£ï¼š

```py
 /// Return the `Vec` of [`Bytes`](https://docs.rs/bytes/latest/bytes/struct.Bytes.html) from specified ranges.
    ///
    /// # Example
    /// ```

    /// ä½¿ç”¨ cloud_file::CloudFile;

    ///

    /// # Runtime::new().unwrap().block_on(async {

    /// let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/plink_sim_10s_100v_10pmiss.bim";

    /// let cloud_file = CloudFile::new(url)?;

    /// let bytes_vec = cloud_file.read_ranges(&[0..10, 1000..1010]).await?;

    /// assert_eq!(bytes_vec.len(), 2);

    /// assert_eq!(bytes_vec[0].as_ref(), b"1\t1:1:A:C\t");

    /// assert_eq!(bytes_vec[1].as_ref(), b":A:C\t0.0\t4");

    /// # Ok::<(), CloudFileError>(())}).unwrap();

    /// # ä½¿ç”¨ {tokio::runtime::Runtime, cloud_file::CloudFileError};

    /// ```py
```

æ–‡æ¡£æµ‹è¯•ä» ```py` ``` ```py`. Within the doc test, lines starting with `/// #` disappear from the documentation:

![](img/3aa4177d13d6e88dd119ca930801c492.png)

The hidden lines, however, will still be run by `cargo test`.

In my library crates, I try to include a working example with every method. If such an example turns out overly complex or otherwise embarrassing, I try to fix the issue by improving the API.

Notice that in this rule and the previous Rule 7, we added a runtime to the code. Unfortunately, including a runtime can easily double the size of your userâ€™s programs, even if they donâ€™t read files from the cloud. Making this extra size optional is the topic of Rule 9.

# Rule 9: Include a runtime, but optionally.

If you follow Rule 6 and provide async methods, your users gain the freedom to choose their own runtime. Opting for a runtime like Tokio may significantly increase their compiled programâ€™s size. However, if they use no async methods, selecting a runtime becomes unnecessary, keeping the compiled program lean. This embodies the â€œzero cost principleâ€, where one incurs costs only for the features one uses.

On the other hand, if you follow Rule 7 and wrap async calls inside traditional, â€œsynchronousâ€ methods, then you must provide a runtime. This will increase the size of the resultant program. To mitigate this cost, you should make the inclusion of any runtime optional.

Bed-Reader includes a runtime under two conditions. First, when used as a Python extension. Second, when testing the async methods. To handle the first condition, we create a Cargo feature called `extension-module` that pulls in optional dependencies `pyo3` and `tokio`. Here are the relevant sections of `Cargo.toml`:

``` å¼€å§‹

[åŠŸèƒ½]

extension-module = ["pyo3/extension-module", "tokio/full"]

é»˜è®¤ = []

[ä¾èµ–]

#...

pyo3 = { version = "0.20.0", features = ["extension-module"], optional = true }

tokio = { version = "1.35.0", features = ["full"], optional = true }

```py

Also, because Iâ€™m using Maturin to create a Rust extension for Python, I include this text in `pyproject.toml`:

```

[tool.maturin]

features = ["extension-module"]

```py

I put all the Rust code related to extending Python in a file called `python_modules.rs`. It starts with this [conditional compilation attribute](https://doc.rust-lang.org/reference/conditional-compilation.html#the-cfg-attribute):

```

#![cfg(feature = "extension-module")] // å¦‚æœç‰¹æ€§æœªå¼€å¯åˆ™å¿½ç•¥æ–‡ä»¶

```py

This starting line ensures that the compiler includes the extension code only when needed.

With the Python extension code taken care of, we turn next to providing an optional runtime for testing our async methods. I again choose Tokio as the runtime. I put the tests for the async code in their own file called `tests_api_cloud.rs`. To ensure that that async tests are run only when the `tokio` dependency feature is â€œonâ€, I start the file with this line:

```

#![cfg(feature = "tokio")]

```py

As per Rule 5, we should also include examples in our documentation of the async methods. These examples also serve as â€œdoc testsâ€. The doc tests need conditional compilation attributes. Below is the documentation for the method that retrieves chromosome metadata. Notice that the example includes two hidden lines that start
`/// # #[cfg(feature = "tokio")]`

```

/// æ¯ä¸ª SNPï¼ˆå˜å¼‚ï¼‰çš„æŸ“è‰²ä½“

/// [...]

///

/// # ç¤ºä¾‹ï¼š

/// ```py
/// use ndarray as nd;
/// use bed_reader::{BedCloud, ReadOptions};
/// use bed_reader::assert_eq_nan;
///
/// # #[cfg(feature = "tokio")] Runtime::new().unwrap().block_on(async {
/// let url = "https://raw.githubusercontent.com/fastlmm/bed-sample-files/main/small.bed";
/// let mut bed_cloud = BedCloud::new(url).await?;
/// let chromosome = bed_cloud.chromosome().await?;
/// println!("{chromosome:?}"); // Outputs ndarray ["1", "1", "5", "Y"]
/// # Ok::<(), Box<BedErrorPlus>>(())}).unwrap();
/// # #[cfg(feature = "tokio")] use {tokio::runtime::Runtime, bed_reader::BedErrorPlus};
/// ```

```

åœ¨è¿™ä¸ªæ–‡æ¡£æµ‹è¯•ä¸­ï¼Œå½“ `tokio` åŠŸèƒ½â€œå¼€å¯â€æ—¶ï¼Œç¤ºä¾‹ä½¿ç”¨ `tokio` å¹¶åœ¨ Tokio è¿è¡Œæ—¶ä¸­è¿è¡Œå››è¡Œä»£ç ã€‚å½“ `tokio` åŠŸèƒ½â€œå…³é—­â€æ—¶ï¼Œ`#[cfg(feature = "tokio")]` å—ä¸­çš„ä»£ç æ¶ˆå¤±ï¼Œä»è€Œæœ‰æ•ˆåœ°è·³è¿‡å¼‚æ­¥æ“ä½œã€‚

åœ¨æ ¼å¼åŒ–æ–‡æ¡£æ—¶ï¼ŒRust é»˜è®¤åŒ…å«æ‰€æœ‰åŠŸèƒ½çš„æ–‡æ¡£ï¼Œå› æ­¤æˆ‘ä»¬çœ‹åˆ°äº†è¿™å››è¡Œä»£ç ï¼š

![](img/4544233478a0a6911c16e85bb4a9ab4e.png)

æ€»ç»“è§„åˆ™ 9ï¼šé€šè¿‡ä½¿ç”¨ Cargo åŠŸèƒ½å’Œæ¡ä»¶ç¼–è¯‘ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿ç”¨æˆ·åªä¸ºä»–ä»¬ä½¿ç”¨çš„åŠŸèƒ½ä»˜è´¹ã€‚

# ç»“è®º

æ‰€ä»¥ï¼Œå°±è¿™æ ·ï¼šä¹æ¡è§„åˆ™å¸®åŠ©ä½ åœ¨ Rust ç¨‹åºä¸­è¯»å–äº‘æ–‡ä»¶ã€‚å€ŸåŠ©[`object_store`](https://docs.rs/object_store/latest/object_store/) crate çš„å¼ºå¤§åŠŸèƒ½ï¼Œä½ çš„ç¨‹åºå¯ä»¥çªç ´æœ¬åœ°é©±åŠ¨å™¨çš„é™åˆ¶ï¼Œä» Webã€AWS S3ã€Azure å’Œ Google Cloud åŠ è½½æ•°æ®ã€‚ä¸ºäº†è®©è¿™ä¸€è¿‡ç¨‹æ›´ç®€å•ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨æˆ‘ä¸ºæœ¬æ–‡ç¼–å†™çš„å…¨æ–°[`cloud-file`](https://crates.io/crates/cloud-file)åŒ…è£… crateã€‚

æˆ‘è¿˜åº”è¯¥æåˆ°ï¼Œè¿™ç¯‡æ–‡ç« ä»…æ¢è®¨äº†`object_store`çš„ä¸€ä¸ªå­é›†åŠŸèƒ½ã€‚é™¤äº†æˆ‘ä»¬çœ‹åˆ°çš„ï¼Œ`object_store` crate è¿˜å¤„ç†å†™å…¥æ–‡ä»¶å’Œæ“ä½œæ–‡ä»¶å¤¹åŠå­æ–‡ä»¶å¤¹ã€‚å¦ä¸€æ–¹é¢ï¼Œ[`cloud-file`](https://crates.io/crates/cloud-file) crate åªå¤„ç†è¯»å–æ–‡ä»¶ã€‚ï¼ˆä½†å˜¿ï¼Œæˆ‘å¾ˆæ¬¢è¿æäº¤ Pull Requestï¼‰ã€‚

ä½ æ˜¯å¦åº”è¯¥åœ¨ç¨‹åºä¸­æ·»åŠ äº‘æ–‡ä»¶æ”¯æŒï¼Ÿå½“ç„¶ï¼Œè¿™å–å†³äºã€‚æ”¯æŒäº‘æ–‡ä»¶ä¸ºä½ çš„ç¨‹åºç”¨æˆ·æä¾›äº†å·¨å¤§çš„ä¾¿åˆ©ã€‚ä»£ä»·æ˜¯ä½¿ç”¨/æä¾›å¼‚æ­¥æ¥å£çš„é¢å¤–å¤æ‚æ€§ã€‚ä»£ä»·è¿˜åŒ…æ‹¬åƒ Tokio è¿™æ ·çš„è¿è¡Œæ—¶æ–‡ä»¶å¤§å°çš„å¢åŠ ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘è®¤ä¸ºæ·»åŠ æ­¤ç±»æ”¯æŒçš„å·¥å…·å·²ç»éå¸¸å¥½ï¼Œè€Œä¸”å°è¯•å®ƒä»¬ä¹Ÿå¾ˆç®€å•ï¼Œæ‰€ä»¥ä¸å¦¨è¯•è¯•çœ‹ï¼

æ„Ÿè°¢ä½ ä¸æˆ‘ä¸€åŒè¸ä¸Šäº‘ç«¯ä¹‹æ—…ã€‚å¦‚æœä½ é€‰æ‹©æ”¯æŒäº‘æ–‡ä»¶ï¼Œæˆ‘å¸Œæœ›è¿™äº›æ­¥éª¤èƒ½å¸®åŠ©ä½ å®ç°ã€‚

*è¯·* [*å…³æ³¨ Carl çš„ Medium è´¦å·*](https://medium.com/@carlmkadie)*ã€‚æˆ‘åœ¨ Rust å’Œ Python çš„ç§‘å­¦ç¼–ç¨‹ã€æœºå™¨å­¦ä¹ å’Œç»Ÿè®¡å­¦æ–¹é¢å†™ä½œã€‚æˆ‘é€šå¸¸æ¯ä¸ªæœˆå†™ä¸€ç¯‡æ–‡ç« ã€‚*
