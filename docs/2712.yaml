- en: 'Random Forest, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林解析：带有代码示例的视觉指南
- en: 原文：[https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07](https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07](https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07)
- en: ENSEMBLE LEARNING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成学习
- en: Making tree-mendous predictions with random trees
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用随机树做出惊人的预测
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    ·12 min read·Nov 7, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    ·阅读时间12分钟·2024年11月7日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
    [## Decision Tree Classifier, Explained: A Visual Guide with Code Examples for
    Beginners'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
    [## 决策树分类器解析：带有代码示例的初学者视觉指南'
- en: A fresh look on our favorite upside-down tree
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从全新的角度看我们最喜爱的倒立树
- en: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
- en: '[Decision trees](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    are a great starting point in machine learning — they’re clear and make sense.
    But there’s a catch: they often don’t work well when dealing with new data. The
    predictions can be inconsistent and unreliable, which is a real problem when you’re
    trying to build something useful.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[决策树](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)是机器学习的一个很好的起点——它们直观且易于理解。但有一个问题：它们在处理新数据时往往效果不好。预测结果可能不稳定且不可靠，这在你试图构建有用的东西时是一个真正的问题。'
- en: This is where Random Forest comes in. It takes what’s good about decision trees
    and makes them work better by combining multiple trees together. It’s become a
    favorite tool for many data scientists because it’s both effective and practical.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，随机森林就派上用场了。它结合了决策树的优点，并通过将多棵树结合在一起，使它们的效果更好。它已经成为许多数据科学家最喜爱的工具，因为它既有效又实用。
- en: Let’s see how Random Forest works and why it might be exactly what you need
    for your next project. It’s time to stop getting lost in the trees and see the
    forest for what it really is — your next reliable tool in machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看随机森林是如何工作的，以及它为什么可能正是你下一个项目所需要的。是时候不再迷失在树木中，真正看到森林的全貌——你下一个可靠的机器学习工具。
- en: '![](../Images/a46fad3053f42f475b5f070c27b60998.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a46fad3053f42f475b5f070c27b60998.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图像：作者使用Canva Pro创建。优化了移动设备显示；在桌面设备上可能会显得过大。
- en: Definition
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: A Random Forest is an ensemble machine learning model that combines multiple
    decision trees. Each tree in the forest is trained on a random sample of the data
    (bootstrap sampling) and considers only a random subset of features when making
    splits (feature randomization).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种集成机器学习模型，它结合了多个决策树。森林中的每一棵树都在数据的随机样本上进行训练（自助采样），并且在做出分裂时仅考虑特征的随机子集（特征随机化）。
- en: For classification tasks, the forest predicts by majority voting among trees,
    while for regression tasks, it averages the predictions. The model’s strength
    comes from its “wisdom of crowds” approach — while individual trees might make
    errors, the collective decision-making process **tends to average out these mistakes**
    and arrive at more reliable predictions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类任务，森林通过树之间的多数投票来进行预测；而对于回归任务，它通过平均各棵树的预测结果来进行预测。该模型的优势来自于它的“集体智慧”方法——虽然单棵树可能会犯错，但集体决策过程**往往能将这些错误平均化**，从而得出更可靠的预测结果。
- en: '![](../Images/a7c8ea0333ddfcdeb2779b785e896929.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7c8ea0333ddfcdeb2779b785e896929.png)'
- en: Random Forest is a part of bagging (bootstrap aggregating) algorithm because
    it builds each tree using different random part of data and combines their answers
    together.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是袋装（自助聚合）算法的一部分，因为它使用数据的不同随机部分来构建每棵树，并将它们的结果结合起来。
- en: Dataset Used
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的数据集
- en: Throughout this article, we’ll focus on the classic golf dataset as an example
    for classification. While Random Forests can handle both classification and regression
    tasks equally well, we’ll concentrate on the classification part — predicting
    whether someone will play golf based on weather conditions. The concepts we’ll
    explore can be easily adapted to regression problems (like predicting number of
    player) using the same principles.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将以经典的高尔夫数据集为分类任务的例子进行讲解。虽然随机森林既可以处理分类任务，也可以处理回归任务，但我们将集中讨论分类部分——根据天气条件预测某人是否会打高尔夫。我们探讨的概念也可以很容易地应用于回归问题（例如预测球员数量），使用相同的原理。
- en: '![](../Images/05586d1dcea17f8a18206b58019181ea.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05586d1dcea17f8a18206b58019181ea.png)'
- en: 'Columns: ‘Overcast (one-hot-encoded into 3 columns)’, ’Temperature’ (in Fahrenheit),
    ‘Humidity’ (in %), ‘Windy’ (Yes/No) and ‘Play’ (Yes/No, target feature)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 列：‘Overcast（被一热编码成3列）’，’Temperature（华氏温度）’，‘Humidity（湿度，%）’，‘Windy（是否有风，Yes/No）’和‘Play（是否打球，Yes/No，目标特征）’
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Main Mechanism
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要机制
- en: 'Here’s how Random Forest works:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是随机森林的工作原理：
- en: '**Bootstrap Sampling:** Each tree gets its own unique training set, created
    by randomly sampling from the original data with replacement. This means some
    data points may appear multiple times while others aren’t used.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自助采样（Bootstrap Sampling）：** 每棵树都有自己的独特训练集，这些训练集是通过从原始数据中随机抽样并允许重复抽取得到的。这意味着一些数据点可能会出现多次，而其他数据点则未被使用。'
- en: '**Random Feature Selection:** When making a split, each tree only considers
    a random subset of features (typically square root of total features).'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机特征选择：** 在进行分裂时，每棵树只考虑一个随机的特征子集（通常是总特征数的平方根）。'
- en: '**Growing Trees:** Each tree grows using only its bootstrap sample and selected
    features, making splits until it reaches a stopping point (like pure groups or
    minimum sample size).'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生长树木：** 每棵树仅使用其自助样本和选定的特征进行生长，进行分裂，直到达到停止点（如纯净组或最小样本量）。'
- en: '**Final Prediction:** All trees vote together for the final prediction. For
    classification, take the majority vote of class predictions; for regression, average
    the predicted values from all trees.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最终预测：** 所有树一起投票决定最终的预测结果。对于分类任务，采用类别预测的多数投票；对于回归任务，计算所有树的预测值的平均值。'
- en: '![](../Images/3e815426c28ac98519c4884d12f43fac.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e815426c28ac98519c4884d12f43fac.png)'
- en: A Random Forest Classifier makes predictions by combining results from 100 different
    decision trees, each analyzing features like temperature and outlook conditions.
    The final prediction comes from the most common answer among all trees.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林分类器通过结合来自100棵不同决策树的结果来进行预测，每棵树分析的特征包括温度和天气条件。最终的预测来自所有树中最常见的答案。
- en: Training Steps
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练步骤
- en: 'The Random Forest algorithm constructs multiple decision trees and combines
    them. Here’s how it works:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法构建多个决策树并将它们结合起来。其工作原理如下：
- en: '**Step 1: Bootstrap Sample Creation**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1：自助样本创建**'
- en: 1.0\. Set the number of trees (default = 100)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 1.0\. 设置树的数量（默认 = 100）
- en: '1.1\. For each tree in the forest:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1\. 对于森林中的每一棵树：
- en: a. Create new training set by random sampling original data with replacement
    until reaching original dataset size. This is called **bootstrap sampling**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: a. 通过从原始数据中进行随机抽样并允许重复抽取，直到达到原始数据集的大小。这被称为**自助采样**。
- en: b. Mark and set aside non-selected samples as out-of-bag (OOB) samples for later
    error estimation
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: b. 标记并将未选中的样本作为袋外（OOB）样本保留，以便后续进行误差估算
- en: '![](../Images/1671fe794bccb45ec5a642740a8d0d8f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1671fe794bccb45ec5a642740a8d0d8f.png)'
- en: Random Forest creates different training sets for each tree by randomly picking
    data points from the original training set, with some numbers appearing multiple
    times. The unused data points become test sets for checking each tree’s performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林通过从原始训练集中随机选择数据点为每棵树创建不同的训练集，某些数据点可能会被多次选择。未使用的数据点则成为测试集，用于检查每棵树的性能。
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/fd0d49cc5d9614e8b4d96dedd10a6ca2.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd0d49cc5d9614e8b4d96dedd10a6ca2.png)'
- en: Notice how similar the percentages of OOB above? When doing bootstrap sampling
    of *n* samples, each individual sample has about a 37% chance of never being picked.
    This comes from the probability calculation (1–1/*n*)*ⁿ*, which approaches 1/e
    ≈ 0.368 as *n* gets larger. That’s why each tree ends up using roughly 63% of
    the data for training, with the remaining 37% becoming OOB samples.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，OOB的百分比是多么相似？在进行*n*样本的自助法抽样时，每个样本大约有37%的机会永远不会被选择。这来自于概率计算（1–1/*n*)*ⁿ*，随着*n*的增大，它接近1/e
    ≈ 0.368。因此，每棵树最终使用约63%的数据进行训练，其余的37%成为OOB样本。
- en: '**Step 2: Tree Construction**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤2：树的构建**'
- en: 2.1\. Start at root node with complete bootstrap sample
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 2.1. 从根节点开始，使用完整的自助法样本
- en: '![](../Images/58dd94d352eb90afbfe2312662b55270.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58dd94d352eb90afbfe2312662b55270.png)'
- en: When building each decision tree, Random Forest considers a subset of data points
    and creates splits based on questions about their values — sending smaller values
    to the left and larger values to the right to make predictions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建每棵决策树时，随机森林会考虑数据点的子集，并基于这些数据点的值提出分割问题——将较小的值分配到左侧，将较大的值分配到右侧进行预测。
- en: a. Calculate initial node impurity using all samples in node
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: a. 使用节点中的所有样本计算初始节点杂质
- en: '· Classification: Gini or entropy'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: · 分类：基尼指数或熵
- en: '· Regression: MSE'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: · 回归：均方误差（MSE）
- en: '![](../Images/49ffa6509e2a0b7efc710bf7c8891e58.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49ffa6509e2a0b7efc710bf7c8891e58.png)'
- en: Random Forest starts by calculating the Gini Impurity of the entire dataset
    (before any splits) using the ratio of YES and NO labels — a measure of how mixed
    the labels are in the current data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林首先计算整个数据集的基尼杂质（在任何分割之前），使用YES和NO标签的比例——这是一种衡量当前数据中标签混合程度的指标。
- en: 'b. Select random subset of features from total available features:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: b. 从总可用特征中选择随机子集：
- en: '· Classification: √n_features'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: · 分类：√n_features
- en: '· Regression: n_features/3'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: · 回归：n_features/3
- en: '![](../Images/71393bd15609a6d43354efe5d9f06ac3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71393bd15609a6d43354efe5d9f06ac3.png)'
- en: For each split in a tree, Random Forest randomly picks a subset of weather features
    (here 2 out of 6) to consider, making each tree focus on different aspects of
    the data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于树中的每次分割，随机森林会随机选择一个天气特征的子集（这里是从6个特征中选择2个）来进行考虑，从而使每棵树关注数据的不同方面。
- en: 'c. For each selected feature:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: c. 对每个选定的特征：
- en: · Sort data points by feature values
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: · 按特征值对数据点进行排序
- en: · Identify potential split points (midpoints between consecutive unique feature
    values)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: · 确定潜在的分割点（连续唯一特征值之间的中点）
- en: '![](../Images/31b2530c2f2eab495683e971a5cc88da.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31b2530c2f2eab495683e971a5cc88da.png)'
- en: For each chosen feature, Random Forest looks at all possible split points in
    the sorted data (like temperature values 66.0, 69.0, 71.0, etc.) to find the best
    way to separate the data into two groups.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个选定的特征，随机森林会查看排序后的数据中所有可能的分割点（如温度值66.0、69.0、71.0等），以找出最佳的方式将数据分为两组。
- en: 'd. For each potential split point:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: d. 对每个潜在的分割点：
- en: · Divide samples into left and right groups
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: · 将样本分为左右两组
- en: · Calculate left child impurity using its samples
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: · 使用其样本计算左子节点的杂质
- en: · Calculate right child impurity using its samples
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: · 使用其样本计算右子节点的杂质
- en: '· Calculate impurity reduction:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: · 计算杂质减少：
- en: parent_impurity — (left_weight × left_impurity + right_weight × right_impurity)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: parent_impurity — (left_weight × left_impurity + right_weight × right_impurity)
- en: '![](../Images/3a76a1bc476cd60a143540debd4b04b3.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a76a1bc476cd60a143540debd4b04b3.png)'
- en: To find the best split point, Random Forest calculates Gini Impurity for each
    possible split, takes a weighted average based on group sizes, and picks the split
    that gives the biggest reduction in impurity from the parent node.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最佳分割点，随机森林会计算每个可能分割点的基尼杂质，基于组的大小进行加权平均，并选择那个能最大程度减少父节点杂质的分割点。
- en: e. Split the current node data using the feature and split point that gives
    the highest impurity reduction. Then pass data points to the respective child
    nodes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: e. 使用提供最大纯度减少的特征和分割点来分割当前节点的数据。然后将数据点传递给各自的子节点。
- en: '![](../Images/e71e8da4672712136d3478ad9d1cd59b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e71e8da4672712136d3478ad9d1cd59b.png)'
- en: 'After comparing all possible splits, Random Forest picks the temperature threshold
    of 73.5°F as it gives the largest impurity reduction (0.041), creating two groups:
    one mixed group with temperatures below 73.5°F and one pure group.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较所有可能的分割后，随机森林选择73.5°F的温度阈值，因为它提供了最大的纯度减少（0.041），并创建了两个分组：一个是低于73.5°F的混合组，另一个是纯净组。
- en: 'f. For each child node, repeat the process (step b-e) until:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: f. 对每个子节点，重复过程（步骤b-e），直到：
- en: '- Pure node or minimum impurity decrease'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '- 纯节点或最小不纯度减少'
- en: '- Minimum samples threshold'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '- 最小样本数阈值'
- en: '- Maximum depth'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '- 最大深度'
- en: '- Maximum leaf nodes'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '- 最大叶子节点数'
- en: '![](../Images/8e9f1677218a52ede01934cdc731077e.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e9f1677218a52ede01934cdc731077e.png)'
- en: 'This process continues for each new group (node): randomly select features,
    find the best split point, and divide the data further until each group is pure
    (all YES or all NO) or can’t be split anymore.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程对每个新的分组（节点）继续进行：随机选择特征，找到最佳的分割点，并进一步划分数据，直到每个分组是纯净的（全部为YES或全部为NO）或无法再分割。
- en: '**Step 3: Tree Construction** Repeat the whole Step 2 for other bootstrap samples.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤3：树构建** 对其他自助抽样重复整个步骤2。'
- en: '![](../Images/5a6197d5a37f101b794221d1c2c3383d.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a6197d5a37f101b794221d1c2c3383d.png)'
- en: Each decision tree in the Random Forest splits data in different ways using
    different features and thresholds. This variety helps the forest make better predictions
    than any single tree.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林中的每棵决策树通过使用不同的特征和阈值以不同的方式分割数据。这种多样性帮助森林做出比单棵树更好的预测。
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/b46220bdf49910aa49e1d13e353fe1fc.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b46220bdf49910aa49e1d13e353fe1fc.png)'
- en: Accessing the internal bootstrap indices directly isn’t possible in the current
    scikit-learn implementation so this gives different trees than the one calculated
    in our previous example.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的scikit-learn实现中无法直接访问内部的自助抽样索引，因此生成的树与我们之前示例中计算的树不同。
- en: Testing Step
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试步骤
- en: 'For prediction, route new samples through all trees and aggregate:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预测，通过所有树路由新样本并进行汇总：
- en: '- Classification: majority vote'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '- 分类：多数投票'
- en: '- Regression: mean prediction'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '- 回归：平均预测'
- en: '![](../Images/e8bd423acc3d8361e5ce82ec3fd542e4.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8bd423acc3d8361e5ce82ec3fd542e4.png)'
- en: When new data comes in, each tree in the Random Forest uses its own decision
    path to make a prediction. The forest combines all these predictions (74 YES vs
    26 NO) and the majority vote becomes the final answer (YES in this case).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当新数据进入时，随机森林中的每棵树使用自己的决策路径进行预测。森林结合所有这些预测（74个YES与26个NO），并通过多数投票得到最终答案（在这个例子中是YES）。
- en: Out-of-Bag (OOB) Evaluation
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 袋外（OOB）评估
- en: Remember those samples that didn’t get used for training each tree — that leftover
    1/3? Those are your OOB samples. Instead of just ignoring them, Random Forest
    uses them as a convenient validation set for each tree.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 记住那些未被用于训练每棵树的样本——那剩下的1/3？它们就是你的OOB样本。随机森林不仅仅是忽略它们，而是将它们作为每棵树的便捷验证集。
- en: '![](../Images/afccd043882db9aba10d7e5fb93558e5.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afccd043882db9aba10d7e5fb93558e5.png)'
- en: Each tree gets tested on its own out-of-bag samples (data not used in its training).
    By averaging these individual OOB accuracy scores (50%, 66.6%, 60%), Random Forest
    provides a built-in way to measure performance without needing a separate test
    set.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵树都会在其自己的袋外样本上进行测试（即未用于训练的数据）。通过平均这些单个的OOB准确率得分（50%、66.6%、60%），随机森林提供了一种内建的方式来测量性能，无需单独的测试集。
- en: Evaluation Step
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估步骤
- en: After building all the trees, we can evaluate the test set.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 构建完所有树后，我们可以评估测试集。
- en: '![](../Images/55f4ae7dd4d6a6513400959cda5c3c12.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55f4ae7dd4d6a6513400959cda5c3c12.png)'
- en: By combining multiple diverse decision trees and using majority voting, Random
    Forest achieves a high accuracy of 85.7% — typically better than single decision
    trees or simpler models!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合多个多样化的决策树并使用多数投票，随机森林达到了85.7%的高准确率——通常比单棵决策树或更简单的模型表现更好！
- en: Key Parameters
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键参数
- en: The key Random Forest parameters (especially in `scikit-learn`) include all
    Decision Tree parameters, plus some unique ones.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林的关键参数（尤其是在`scikit-learn`中）包括所有决策树参数，以及一些独特的参数。
- en: Random Forest-specific parameters
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机森林特定参数
- en: '`oob_score` This uses leftover data (out-of-bag samples) to check how well
    the model works. This gives you a way to test your model without setting aside
    separate test data. It’s especially helpful with small datasets.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oob_score` 这个参数使用剩余的数据（袋外样本）来检查模型的表现。这为你提供了一种不需要单独设置测试数据来测试模型的方法，尤其适用于小数据集。'
- en: '`n_estimators` This parameter controls how many trees to build (default is
    100).To find the optimal number of trees, **track the OOB error rate** as you
    add more trees to the forest. The error typically drops quickly at first, then
    levels off. **The point where it stabilizes suggests the optimal number** — adding
    more trees after this gives minimal improvement while increasing computation time.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators` 这个参数控制要构建多少棵树（默认值是100）。为了找到最佳的树木数量，**在添加更多树木时跟踪OOB误差率**。误差通常会迅速下降，然后趋于平稳。**稳定的点即是最佳树木数量**——在此之后增加更多树木只会带来最小的改善，同时增加计算时间。'
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/97234d73657a128e85e5409216f55df5.png)![](../Images/3d6b30f69790966d7d1dc81b1bed0c83.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97234d73657a128e85e5409216f55df5.png)![](../Images/3d6b30f69790966d7d1dc81b1bed0c83.png)'
- en: In our results, while around 27 trees showed the best score (0.2857), this early
    performance can be unreliable. Between 40–100 trees, the error rates settle around
    0.5000, showing more consistent results. Using more than 100 trees doesn’t help
    and sometimes makes things worse. This suggests that using about 50–60 trees is
    a good choice — it’s stable, efficient, and reliable.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的结果中，尽管大约27棵树显示出最佳的得分（0.2857），但这个早期表现可能不太可靠。在40到100棵树之间，误差率大约稳定在0.5000，显示出更一致的结果。超过100棵树并没有帮助，反而有时会使结果变差。这表明，使用大约50到60棵树是一个不错的选择——它既稳定、高效，又可靠。
- en: '`bootstrap` This decides whether each tree learns from a random sample of data
    (`True`) or uses all data ( `False`). The default (`True`) helps create different
    kinds of trees, which is key to how Random Forests work. Only consider **setting
    it to** `**False**` **when you have very little data** and can’t afford to skip
    any samples.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap` 这个参数决定了每棵树是从数据的随机样本中学习（`True`），还是使用所有数据（`False`）。默认值（`True`）有助于创建不同类型的树，这是随机森林工作原理的关键。**只有在数据非常少，无法跳过任何样本时，才考虑将其设置为**`**False**`。'
- en: '`n_jobs` This controls how many processor cores to use during training. Setting
    it to `-1` uses all available cores, making training faster but using more memory.
    With big datasets, you might need to use fewer cores to avoid running out of memory.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_jobs` 这个参数控制训练过程中使用的处理器核心数。将其设置为 `-1` 会使用所有可用的核心，加快训练速度，但会占用更多内存。对于大数据集，你可能需要使用更少的核心，以避免内存不足。'
- en: Shared parameters with Decision Trees
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与决策树共享的参数
- en: The following parameters works the [same way as in Decision Tree](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下参数与[决策树中的工作方式相同](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)。
- en: '`max_depth`: Maximum tree depth'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`: 最大树深度'
- en: '`min_samples_split`: Minimum samples needed to split a node'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_split`: 切分节点所需的最小样本数'
- en: '`min_samples_leaf`: Minimum samples required at leaf node'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_leaf`: 叶节点所需的最小样本数'
- en: 'Compared to Decision Tree, here are key differences in parameter importance:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 与决策树相比，以下是参数重要性的关键差异：
- en: '`max_depth` This matters less in Random Forests because combining many trees
    helps prevent overfitting, even with deeper trees. You can usually let trees grow
    deeper to catch complex patterns in your data.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`max_depth` 在随机森林中不太重要，因为结合多个树可以帮助防止过拟合，即使是较深的树也如此。通常你可以让树长得更深，以捕捉数据中的复杂模式。'
- en: '`min_samples_split` and `min_samples_leaf` These are less important in Random
    Forests because using many trees naturally helps avoid overfitting. You can usually
    set these to smaller numbers than you would with a single decision tree.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`min_samples_split` 和 `min_samples_leaf` 在随机森林中不太重要，因为使用多棵树天然有助于避免过拟合。通常可以将这些参数设置为比单棵决策树更小的值。'
- en: Pros & Cons
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优点与缺点
- en: 'Pros:'
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点：
- en: '**Strong and Reliable:** Random Forests give accurate results and are less
    likely to overfit than single decision trees. By using random sampling and mixing
    up which features each tree considers at each node, they work well across many
    problems without needing much adjustment.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**强大且可靠：** 随机森林能提供准确的结果，并且比单棵决策树更不容易发生过拟合。通过使用随机采样并在每个节点混合不同的特征，随机森林能在多个问题上表现良好，且无需过多调整。'
- en: '**Feature Importance:** The model can tell you which features matter most in
    making predictions by measuring how much each feature helps across all trees.
    This helps you understand what drives your predictions.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征重要性：** 通过衡量每个特征在所有树中的贡献，模型可以告诉你哪些特征对预测最为重要。这有助于你理解驱动预测的因素。'
- en: '**Minimal Preprocessing:** Random Forests handle both numerical and categorical
    variables well without much preparation. They work well with missing values and
    outliers, and can find complex relationships in your data automatically.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最小预处理：** 随机森林能够很好地处理数值型和类别型变量，几乎不需要额外的准备工作。它们能够很好地处理缺失值和异常值，并且可以自动发现数据中的复杂关系。'
- en: 'Cons:'
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺点：
- en: '**Computational Cost:** Training and using the model takes more time as you
    add more trees or make them deeper. While you can speed up training by using multiple
    processors, it still needs substantial computing power for big datasets.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算成本：** 随着树的增加或树的深度加深，训练和使用模型所需的时间也会增加。尽管可以通过使用多个处理器来加速训练，但对于大数据集来说，仍然需要大量的计算能力。'
- en: '**Limited Interpretability:** While you can see which features are important
    overall, it’s harder to understand exactly why the model made a specific prediction,
    unlike with single decision trees. This can be a problem when you need to explain
    each decision.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**有限的可解释性：** 尽管你可以看到哪些特征在整体上最重要，但很难确切理解模型为何做出特定预测，这与单棵决策树不同。当你需要解释每个决策时，这可能会成为一个问题。'
- en: '**Prediction Speed:** To make a prediction, data must go through all trees
    and then combine their answers. This makes Random Forests slower than simpler
    models, which might be an issue for real-time applications.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测速度：** 为了做出预测，数据必须通过所有的树，然后将它们的答案结合起来。这使得随机森林比简单模型更慢，可能会成为实时应用中的一个问题。'
- en: Final Remarks
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终评论
- en: I’ve grown to really like Random Forests after seeing how well they work in
    practice. By combining multiple trees and letting each one learn from different
    parts of the data, they consistently make better predictions — of course, more
    than using just one tree alone.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到随机森林在实践中的出色表现后，我开始真正喜欢它们。通过结合多棵树并让每棵树从数据的不同部分学习，它们始终能做出更好的预测——当然，比仅使用单棵树更有效。
- en: While you do need to adjust some settings like the number of trees, they usually
    perform well even without much fine-tuning. They do need more computing power
    (and sometimes struggle with rare cases in the data) but their reliable performance
    and ease of use make them my go-to choice for many projects. It’s clear why so
    many data scientists feel the same way!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你确实需要调整一些设置，比如树的数量，但通常即使没有过多的微调，它们也能表现得很好。它们确实需要更多的计算能力（有时在处理数据中的稀有情况时可能会遇到困难），但它们可靠的性能和易用性使它们成为我许多项目中的首选。很明显，为什么这么多数据科学家也有同样的看法！
- en: 🌟 Random Forest Classifier Code Summarized
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 随机森林分类器代码总结
- en: '[PRE4]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 🌟 Random Forest Regressor Code Summarized
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 随机森林回归器代码总结
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Further Reading
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For a detailed explanation of the [RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    and [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
    and its implementation in scikit-learn, readers can refer to the official documentation,
    which provides comprehensive information on its usage and parameters.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于[RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)和[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)的详细解释及其在scikit-learn中的实现，读者可以参考官方文档，其中提供了关于使用和参数的全面信息。
- en: Technical Environment
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的是Python 3.7和scikit-learn 1.5版本。尽管讨论的概念通常是适用的，但不同版本的代码实现可能会略有不同。
- en: About the Illustrations
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有插图均由作者创作，包含了来自Canva Pro的授权设计元素。
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙀𝙣𝙨𝙚𝙢𝙗𝙡𝙚 𝙇𝙚𝙖𝙧𝙣𝙞𝙣𝙜 𝙝𝙚𝙧𝙚:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看更多关于集成学习的信息：
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
- en: Ensemble Learning
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成学习
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----9f736a6e1b3c--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----9f736a6e1b3c--------------------------------)4个故事![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
- en: Classification Algorithms
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9f736a6e1b3c--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9f736a6e1b3c--------------------------------)8个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
