- en: Model Interpretability Using Credit Card Fraud Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12](https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why model interpretability is important
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Danila
    Morozovskii](../Images/d53b987de52b8c2d4ce264b142b05950.png)](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    [Danila Morozovskii](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    ·17 min read·Jun 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, I stumbled upon an online book which describes different tools that
    can be used for machine learning model interpretability ([https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)).
    The idea that machine learning models should not be a black box and can be explained
    fascinated me, and I decided to dive deep into this topic. Previously, when I
    would start working on a new machine learning project, I would follow the same
    procedure: identifying the problem, getting familiar with a dataset, feature engineering,
    selection of a model, training/testing and hyperparameter tuning, and result analysis.
    However, I didn’t realize I was missing the most crucial step: model interpretability.'
  prefs: []
  type: TYPE_NORMAL
- en: What is model interpretability?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model interpretability is a process of explaining how the black box (model)
    works and how it makes predictions. Let’s imagine a situation where a person applied
    for a credit loan and was denied because the model made a negative prediction.
    Any person would want to know why it was denied and what possibly they can change
    so that the decision would be positive, and all the bank employee can do is point
    at a machine learning model and say “It said so!”. This is not a great scenario
    and damages the bank’s reputation since it looks like it doesn’t have control
    over its product. It would be much better if the bank employee could explain to
    the customer what specific features in…
  prefs: []
  type: TYPE_NORMAL
