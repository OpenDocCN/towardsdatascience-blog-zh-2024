<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Coverage vs. Accuracy: Striking a Balance in Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Coverage vs. Accuracy: Striking a Balance in Data Science</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/coverage-vs-accuracy-striking-a-balance-in-data-science-d555415eebe4?source=collection_archive---------7-----------------------#2024-04-16">https://towardsdatascience.com/coverage-vs-accuracy-striking-a-balance-in-data-science-d555415eebe4?source=collection_archive---------7-----------------------#2024-04-16</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="d156" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">The art of getting quick gains with agile model production</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@nadavgoo?source=post_page---byline--d555415eebe4--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Nadav Har-Tuv" class="l ep by dd de cx" src="../Images/981fadd23cdfb60cfe0fa02dbb8edca6.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*OZAUPBCmsqqbLPi9"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d555415eebe4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@nadavgoo?source=post_page---byline--d555415eebe4--------------------------------" rel="noopener follow">Nadav Har-Tuv</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d555415eebe4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 16, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/b5982740ce463719d4a444ab51fa163a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ObNYYgfVEoJcWeVsRbImA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Cover image by chatGPT</figcaption></figure></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="468e" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This post was written together with and inspired by <a class="af og" href="https://www.linkedin.com/in/yucohen/" rel="noopener ugc nofollow" target="_blank">Yuval Cohen</a></p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="4042" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">Introduction</h2><p id="3905" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">Every day, numerous data science projects are discarded due to insufficient prediction accuracy. It’s a regrettable outcome, considering that often these models could be exceptionally well-suited for some subsets of the dataset.</p><p id="eeee" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Data Scientists often try to improve their models by using more complex models and by throwing more and more data at the problem. But many times there is a much simpler and more productive approach: Instead of trying to make all of our predictions better all at once, we could start by making good predictions for the easy parts of the data, and only then work on the harder parts.</p><p id="a579" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This approach can greatly affect our ability to solve real-world problems. We start with the quick gain on the easy problems and only then focus our effort on the harder problems.</p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="432f" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">Thinking Agile</h2><p id="1294" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">Agile production means focusing on the easy data first, and only after it has been properly modelled, moving on the the more complicated tasks. This allows a workflow that is iterative, value-driven, and collaborative.</p><p id="cae0" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">It allows for quicker results, adaptability to changing circumstances, and continuous improvement, which are core ideas of agile production.</p><ol class=""><li id="4db4" class="nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of ph pi pj bk"><strong class="nm fr">Iterative and incremental approach:</strong> work in short, iterative cycles. Start by achieving high accuracy for the easy problems and then move on to the harder parts.</li><li id="3129" class="nk nl fq nm b go pk no np gr pl nr ns nt pm nv nw nx pn nz oa ob po od oe of ph pi pj bk"><strong class="nm fr">Focus on delivering value: </strong>work on the problem with the highest marginal value for your time.</li><li id="91f1" class="nk nl fq nm b go pk no np gr pl nr ns nt pm nv nw nx pn nz oa ob po od oe of ph pi pj bk"><strong class="nm fr">Flexibility and adaptability:</strong> Allow yourself to adapt to changing circumstances. For example, a client might need you to focus on a certain subset of the data — once you’ve solved that small problem, the circumstances have changed and you might need to work on something completely different. Breaking the problem into small parts allows you to adapt to the changing circumstances.</li><li id="4e0f" class="nk nl fq nm b go pk no np gr pl nr ns nt pm nv nw nx pn nz oa ob po od oe of ph pi pj bk"><strong class="nm fr">Feedback and continuous improvement:</strong> By breaking up a problem you allow yourself to be in constant and continuous improvement, rather than waiting for big improvements in large chunks.</li><li id="b291" class="nk nl fq nm b go pk no np gr pl nr ns nt pm nv nw nx pn nz oa ob po od oe of ph pi pj bk"><strong class="nm fr">Collaboration:</strong> Breaking the problem into small pieces promotes parallelization of the work and collaboration between team members, rather than putting all of the work on one person.</li></ol></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="2e7b" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">Breaking down the complexity</h2><p id="59d0" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">In real-world datasets, complexity is the rule rather than the exception. Consider a medical diagnosis task, where subtle variations in symptoms can make the difference between life-threatening conditions and minor ailments. Achieving high accuracy in such scenarios can be challenging, if not impossible, due to the inherent noise and nuances in the data.</p><p id="519e" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">This is where the idea of <strong class="nm fr">coverage </strong>comes into play. Coverage refers to the portion of the data that a model successfully predicts or classifies with high confidence or high precision. Instead of striving for high accuracy across the entire dataset, researchers can choose to focus on a subset of the data where prediction is relatively straightforward. By doing so, they can achieve high accuracy on this subset while acknowledging the existence of a more challenging, uncovered portion.</p><p id="1cff" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">For instance, consider a trained model with a 50% accuracy rate on a test dataset. In this scenario, it’s possible that if we could identify and select only the predictions we are very sure about (although we should decide what “very sure” means), we could end up with a model that covers fewer cases, let’s say around 60%, but with significantly improved accuracy, perhaps reaching 85%.</p><p id="2a99" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk"><strong class="nm fr">I don’t know any product manager who would say no in such a situation. Especially if there is no model in production, and this is the first model.</strong></p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="f128" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">The two-step model</h2><p id="8bbf" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">We want to divide our data into two distinct subsets: the <em class="pp">covered</em> and the <em class="pp">uncovered. </em>The covered data is the part of the data where the initial model achieves high accuracy and confidence. The uncovered data is the part of the data where our model does not give confident predictions and does not achieve high accuracy.</p><p id="67a4" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">In the first step, a model is trained on the data. Once we identify a subset of data where the model achieves high accuracy, we deploy that model and let it run on that subset — the covered data.</p><p id="7d7a" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">In the second step, we move our focus to the uncovered data. We try to develop a better model for this data by collecting more data, using more advanced algorithms, feature engineering, and incorporating domain-specific knowledge to find patterns in the data.</p><p id="1b5c" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">At this step, the first thing you should do is look at the errors by eye. Many times you will easily identify many patterns this way before using any fancy tricks.</p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="46c8" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">An example</h2><p id="0357" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">This example will show how the concept of agile workflow can create great value. This is a very simple example that is meant to visualize this concept. Real-life examples will be a lot less obvious but the idea that you will see here is just as relevant.</p><p id="3a09" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Let’s look at this two-dimensional data that I simulated from three equally sized classes.</p><pre class="mm mn mo mp mq pq pr ps bp pt bb bk"><span id="93b9" class="pu oi fq pr b bg pv pw l px py">num_samples_A = 500<br/>num_samples_B = 500<br/>num_samples_C = 500<br/><br/><br/># Class A<br/>mean_A = [3, 2]<br/>cov_A = [[0.1, 0], [0, 0.1]]  # Low variance<br/>class_A = np.random.multivariate_normal(mean_A, cov_A, num_samples_A)<br/><br/># Class B<br/>mean_B = [0, 0]<br/>cov_B = [[1, 0.5], [0.5, 1]]  # Larger variance with some overlap with class C<br/>class_B = np.random.multivariate_normal(mean_B, cov_B, num_samples_B)<br/><br/># Class C<br/>mean_C = [0, 1]<br/>cov_C = [[2, 0.5], [0.5, 2]]  # Larger variance with some overlap with class B<br/>class_C = np.random.multivariate_normal(mean_C, cov_C, num_samples_C)</span></pre><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk pz"><img src="../Images/3648a3956ec8fd8748307b3ea1554cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*xlGpf16Ouu5bJwd_RtvnSg.jpeg"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Two-dimensional data from three classes</figcaption></figure><p id="ea26" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Now we try to fit a machine learning classifier to this data, it looks like an SVM classifier with a Gaussian (‘rbf’) kernel might do the trick:</p><pre class="mm mn mo mp mq pq pr ps bp pt bb bk"><span id="bf6e" class="pu oi fq pr b bg pv pw l px py">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.svm import SVC<br/><br/># Creating DataFrame<br/>data = np.concatenate([class_A, class_B, class_C])<br/>labels = np.concatenate([np.zeros(num_samples_A), np.ones(num_samples_B), np.ones(num_samples_C) * 2])<br/>df = pd.DataFrame(data, columns=['x', 'y'])<br/>df['label'] = labels.astype(int)<br/><br/># Splitting data into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(df[['x', 'y']], df['label'], test_size=0.2, random_state=42)<br/><br/># Training SVM model with RBF kernel<br/>svm_rbf = SVC(kernel='rbf', probability= True)<br/>svm_rbf.fit(X_train, y_train)<br/><br/># Predict probabilities for each class<br/>svm_rbf_probs = svm_rbf.predict_proba(X_test)<br/><br/># Get predicted classes and corresponding confidences<br/>svm_rbf_predictions = [(X_test.iloc[i]['x'], X_test.iloc[i]['y'], true_class, np.argmax(probs), np.max(probs)) for i, (true_class, probs) in enumerate(zip(y_test, svm_rbf_probs))]<br/><br/>svm_predictions_df = pd.DataFrame(svm_rbf_predictions).rename(columns={0:'x',1:'y' ,2: 'true_class', 3: 'predicted_class', 4: 'confidence'})</span></pre><p id="bfa5" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">How does this model perform on our data?</p><pre class="mm mn mo mp mq pq pr ps bp pt bb bk"><span id="0e86" class="pu oi fq pr b bg pv pw l px py">accuracy = (svm_predictions_df['true_class'] == svm_predictions_df['predicted_class']).mean()*100<br/>print(f'Accuracy = {round(accuracy,2)}%')</span></pre><p id="c060" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Accuracy = 75.33%</p><p id="5ce7" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">75% percent accuracy is disappointing, but does this mean that this model is useless?</p><p id="8415" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Now we want to look at the most confident predictions and see how the model performs on them. How do we define the most confident predictions? We can try out different confidence (predict_proba) thresholds and see what coverage and accuracy we get for each threshold and then decide which threshold meets our business needs.</p><pre class="mm mn mo mp mq pq pr ps bp pt bb bk"><span id="2c22" class="pu oi fq pr b bg pv pw l px py">thresholds = [.5, .55, .6, .65, .7, .75, .8, .85, .9]<br/>results = []<br/><br/>for threshold in thresholds:<br/>    svm_df_covered = svm_predictions_df.loc[svm_predictions_df['confidence'] &gt; threshold]<br/>    coverage = len(svm_df_covered) / len(svm_predictions_df) * 100<br/>    accuracy_covered = (svm_df_covered['true_class'] == svm_df_covered['predicted_class']).mean() * 100<br/><br/>    results.append({'Threshold': threshold, 'Coverage (%)': round(coverage,2), 'Accuracy on covered data (%)': round(accuracy_covered,2)})<br/><br/>results_df = pd.DataFrame(results)<br/>print(results_df)</span></pre><p id="ce64" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">And we get</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk qa"><img src="../Images/bfe0f866be84c0e1aa19327441e52162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*udLzaPGBE-eB9zD4XAq9IQ.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Coverage and accuracy by threshold table</figcaption></figure><p id="2738" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Or if we want a more detailed look we can create a plot of the coverage and accuracy by threshold:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qb"><img src="../Images/e0e042bd92ac5bd5df2a02a1efa160a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t0SCv4b6Gm4AmnkBXkiINw.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Accuracy and coverage as function as threshold</figcaption></figure><p id="941b" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">We can now select the threshold that fits our business logic. For example, if our company’s policy is to guarantee at least 90% accuracy, then we can choose a threshold of 0.75 and get an accuracy of 90% for 62% of the data. This is a huge improvement to throwing out the model, especially if we don’t have any model in production!</p><p id="b235" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Now that our model is happily working in production on 60% of the data, we can shift our focus to the rest of the data. We can collect more data, do more feature engineering, try more complex models, or get help from a domain expert.</p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="541b" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">Balancing act</h2><p id="0bf7" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">The two-step model allows us to aim for accuracy while acknowledging that it is perfectly fine to start with a high accuracy for only a subset of the data. It is counterproductive to insist that a model will have high accuracy on all the data before deploying it to production.</p><p id="bd5b" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">The agile approach presented in this post aims for resource allocation and efficiency. Instead of spending computational resources on getting high accuracy all across. Focus your resources on where the marginal gain is highest.</p></div></div></div><div class="ab cb nc nd ne nf" role="separator"><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni nj"/><span class="ng by bm nh ni"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="387b" class="oh oi fq bf oj ok ol om on oo op oq or nt os ot ou nx ov ow ox ob oy oz pa pb bk">Conclusion</h2><p id="c831" class="pw-post-body-paragraph nk nl fq nm b go pc no np gr pd nr ns nt pe nv nw nx pf nz oa ob pg od oe of fj bk">In data science, we try to achieve high accuracy. However, in the reality of messy data, we need to find a clever approach to utilize our resources in the best way. Agile model production teaches us to focus on the parts of the data where our model works best, deploy the model for those subsets, and only then start working on a new model for the more complicated part. This strategy will help you make the best use of your resources in the face of real data science problems.</p><p id="4f33" class="pw-post-body-paragraph nk nl fq nm b go nn no np gr nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of fj bk">Think production, Think Agile.</p></div></div></div></div>    
</body>
</html>