- en: Kolmogorov-Arnold Networks (KANs) for Time Series Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/kolmogorov-arnold-networks-kans-for-time-series-forecasting-9d49318c3172?source=collection_archive---------1-----------------------#2024-05-14](https://towardsdatascience.com/kolmogorov-arnold-networks-kans-for-time-series-forecasting-9d49318c3172?source=collection_archive---------1-----------------------#2024-05-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Discover the Kolmogorov-Arnold Networks (KANs) and apply them for time series
    forecasting using Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--9d49318c3172--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--9d49318c3172--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9d49318c3172--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9d49318c3172--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--9d49318c3172--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9d49318c3172--------------------------------)
    ·11 min read·May 14, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb3c6be08cbcefbf664344f9958747ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Eduardo Bergen](https://unsplash.com/@eduardb?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The multilayer perceptron (MLP) is one of the foundational structures of deep
    learning models. It is also the building block of many state-of-the-art forecasting
    models, like [N-BEATS](/the-easiest-way-to-forecast-time-series-using-n-beats-d778fcc2ba60),
    [NHiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)
    and [TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb).
  prefs: []
  type: TYPE_NORMAL
- en: 'On April 30, 2024, the paper [KAN: Kolmogorov-Arnold Network](https://arxiv.org/abs/2404.19756)
    was published, and it has attracted the attention of many practitioners in the
    field of deep learning. There, the authors propose an alternative to the MLP:
    the **K**olmogorov-**A**rnold **N**etwork or **KAN**.'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using weights and fixed activation functions, the KAN uses learnable
    functions that are parametrized as splines. The researchers suggest the KAN can
    thus be more accurate with less trainable parameters than MLPs.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we first explore splines, as they help us understand the architecture
    and key elements of KAN. Then, we make a deep dive inside the inner workings of
    KAN. Finally, we apply KAN to time series forecasting, and evaluate its performance
    against the standard MLP and the N-BEATS model.
  prefs: []
  type: TYPE_NORMAL
- en: For more details on KAN, make sure to read the [original paper](https://arxiv.org/abs/2404.19756).
  prefs: []
  type: TYPE_NORMAL
