- en: An Introduction to Prompting for LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大语言模型提示简介
- en: 原文：[https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048?source=collection_archive---------3-----------------------#2024-02-22](https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048?source=collection_archive---------3-----------------------#2024-02-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048?source=collection_archive---------3-----------------------#2024-02-22](https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048?source=collection_archive---------3-----------------------#2024-02-22)
- en: How do we communicate effectively with LLMs?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何与大语言模型（LLMs）有效沟通？
- en: '[](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)[![Anand
    Subramanian](../Images/096dc5504d6ada2493e0ac26959e60f0.png)](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)
    [Anand Subramanian](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)[![Anand
    Subramanian](../Images/096dc5504d6ada2493e0ac26959e60f0.png)](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)
    [Anand Subramanian](https://medium.com/@anand.subu10?source=post_page---byline--61d36aec2048--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)
    ·30 min read·Feb 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--61d36aec2048--------------------------------)
    ·30分钟阅读·2024年2月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Unless you’ve been completely disconnected from the buzz on social media and
    in the news, it’s unlikely that you’d have missed the excitement around Large
    Language Models (LLMs).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你完全断开了与社交媒体和新闻的联系，否则不太可能错过围绕大语言模型（LLMs）的热议。
- en: '![](../Images/eb60be0bd7ee67fd4f1a4f16239215c8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb60be0bd7ee67fd4f1a4f16239215c8.png)'
- en: The evolution of LLMs. Image borrowed from the paper [1] ([Source](https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/tree.png)).
    Even as I add this image, the pace of current LLM development makes this picture
    obsolete.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的演变。图像来源于论文[1]（[来源](https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/tree.png)）。即使在我添加这张图时，当前LLM发展的速度也让这张图片显得过时。
- en: LLMs have become ubiquitous, with new models being released almost daily. They’ve
    also been made more accessible to the general public, thanks to a thriving open-source
    community that has played a crucial role in reducing memory requirements and developing
    efficient fine-tuning methods for LLMs, even with limited compute resources.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs已变得无处不在，几乎每天都有新模型发布。它们也变得更加普及，得益于一个蓬勃发展的开源社区，该社区在减少内存需求和为LLMs开发高效微调方法方面发挥了关键作用，即使在计算资源有限的情况下。
- en: One of the most exciting use cases for LLMs is their remarkable ability to excel
    at tasks they were not explicitly trained for, using just a task description and,
    optionally, a few examples. You can now get a capable LLM to generate a story
    in the style of your favorite author, summarize long emails into concise ones,
    and develop innovative marketing campaigns by describing your task to the model
    without needing to fine-tune it. But how do you best communicate your requirements
    to the LLM? This is where prompting comes in.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs最令人兴奋的应用之一是它们在没有明确训练的任务中表现出的卓越能力，仅通过任务描述和可选的少量示例。现在，你可以让一个强大的LLM生成你最喜欢的作者风格的故事，将长邮件总结成简洁的版本，甚至通过向模型描述任务来开发创新的营销活动，而无需微调模型。那么，如何最好地将你的需求传达给LLM呢？这就是提示技术的作用所在。
- en: 'Table of Contents:'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录：
- en: '[What is Prompting?](#0f7f)'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[什么是提示？](#0f7f)'
- en: '[Why is Prompting Important?](#a04b)'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[为什么提示很重要？](#a04b)'
- en: '[Exploring different prompting strategies](#f3d4)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[探索不同的提示策略](#f3d4)'
- en: '[How can we implement these techniques?](#3a00) 4.1\. [Prompting Llama 2 7B-Chat
    with a Zero-Shot Prompt](#5921)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[我们如何实现这些技术？](#3a00) 4.1\. [使用零样本提示Llama 2 7B-Chat](#5921)'
- en: 4.2\. [Prompting Llama 2 7B-Chat with a Few-Shot Prompt](#0ac4)
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.2\. [使用少量示例提示Llama 2 7B-Chat](#0ac4)
- en: 4.3\. [What happens if we don’t adhere to the chat template?](#a04e)
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.3\. [如果我们不遵循聊天模板，会发生什么？](#a04e)
- en: 4.4\. [Prompting Llama 2 7B-Chat with CoT Prompting](#bfe1)
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.4\. [使用CoT提示法对Llama 2 7B-Chat进行提示](#bfe1)
- en: 4.5\. [Failure Modes in CoT for Llama 2](#0ac0)
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.5\. [Llama 2中CoT的失败模式](#0ac0)
- en: 4.6\. [Prompting GPT-3.5 with a Zero-Shot Prompt](#c938)
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.6\. [使用零-shot提示法对GPT-3.5进行提示](#c938)
- en: 4.7\. [Prompting GPT-3.5 with a Few-Shot Prompt](#a575)
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.7\. [使用Few-Shot提示法对GPT-3.5进行提示](#a575)
- en: 4.8\. [Prompting GPT-3.5 with CoT Prompting](#18e9)
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4.8\. [使用CoT提示法对GPT-3.5进行提示](#18e9)
- en: '[Conclusion and Takeaways](#913f)'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[结论与要点](#913f)'
- en: '[Reproducibility](#f8e9)'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[可重复性](#f8e9)'
- en: '[References](#42e4)'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[参考文献](#42e4)'
- en: '**What is Prompting?**'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**什么是提示？**'
- en: Prompting, or Prompt Engineering, is a technique used to design inputs or prompts
    that guide artificial intelligence models — particularly those in natural language
    processing and image generation — to produce specific, desired outputs. Prompting
    involves structuring your requirements into an input format that effectively communicates
    the desired outcomes to the model, thereby obtaining the intended output.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 提示，或称为提示工程，是一种用于设计输入或提示的技术，旨在引导人工智能模型——特别是自然语言处理和图像生成领域的模型——生成特定的、期望的输出。提示的过程包括将你的需求结构化成一种输入格式，以便有效地向模型传达期望的结果，从而获得预期的输出。
- en: Large Language Models (LLMs) demonstrate an ability for **in-context learning**
    [2] [3]. This means these models can understand and execute various tasks based
    solely on task descriptions and examples provided to the model through a prompt
    without requiring specialized fine-tuning for each new task. Prompting is significant
    in this context as it is the primary interface between the user and the model
    to harness this ability. A well-defined prompt helps define the nature and expectations
    of the task to the LLM, along with how to provide the output in a utilizable manner
    to the user.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）展现了**上下文学习**的能力[2] [3]。这意味着这些模型能够仅仅根据任务描述和通过提示提供给模型的示例来理解和执行各种任务，而无需为每个新任务进行专门的微调。在这种背景下，提示非常重要，因为它是用户与模型之间的主要接口，帮助利用这种能力。一个定义清晰的提示有助于向LLM定义任务的性质和期望，并指导如何以可用的方式向用户提供输出。
- en: You might be inclined to think that prompting an LLM shouldn’t be that hard;
    after all, it’s just about describing your requirements to the model in natural
    language, right? In practice, it isn’t as straightforward. You will discover that
    different LLMs have varying strengths. Some might better adhere to your desired
    output format, while others may necessitate more detailed instructions. The task
    you wish the LLM to perform could be complex, requiring elaborate and precise
    instructions. Therefore, devising a suitable prompt often entails a lot of experimentation
    and benchmarking.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为提示LLM应该并不困难；毕竟，这只是用自然语言向模型描述你的需求，对吧？但实际上，这并不像看起来那么简单。你会发现不同的LLM有着不同的优势。有些模型可能更好地遵循你期望的输出格式，而其他模型则可能需要更详细的指令。你希望LLM执行的任务可能很复杂，要求精确而详尽的指令。因此，设计一个合适的提示通常需要大量的实验和基准测试。
- en: '**Why is Prompting important?**'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**为什么提示很重要？**'
- en: 'In practice, LLMs are sensitive to how the input is structured and provided
    to them. We can analyze this along various axes to better understand the situation:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，大型语言模型（LLMs）对输入的结构和提供方式非常敏感。我们可以从多个角度分析这一现象，以更好地理解这种情况：
- en: '**Adhering to Prompt Formats**: LLMs often utilize varying prompt formats to
    accept user input. This is typically done when models are instruction-tuned or
    optimized for chat use cases [4] [5]. At a high level, most prompt formats include
    the ***instruction*** and the ***input***. The instruction describes the task
    to be performed by the model, while the input contains the text on which the task
    needs to be executed. Let’s take the Alpaca Instruction format, for example (taken
    from [https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)):'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**遵循提示格式**：LLMs通常采用不同的提示格式来接收用户输入。这通常发生在模型经过指令调优或针对聊天用例进行了优化时[4] [5]。从宏观角度来看，大多数提示格式包括***指令***和***输入***。指令描述模型需要执行的任务，而输入则包含任务需要处理的文本。例如，我们以Alpaca指令格式为例（来源于[https://github.com/tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)）：'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Given the models are instruction-tuned using a template like this, the model
    is expected to perform optimally when a user prompts it using the same format.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型是通过使用类似模板的指令调优的，因此当用户使用相同格式向模型发出提示时，模型期望能够最佳地执行任务。
- en: 2\. **Describing output formats for parseability:** Having provided a prompt
    to the model, you’d want to extract what you need from the model’s output. Ideally,
    these outputs should be in a format you can effortlessly parse through programming
    methods. Depending on the task, such as text classification, this might involve
    leveraging regular expressions (regex) to sift through the LLM’s output. In contrast,
    you might prefer a format like JSON for your output for tasks requiring more fine-grained
    data like Named Entity Recognition (NER).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **描述输出格式以便解析：** 在向模型提供提示后，你可能希望从模型的输出中提取所需的信息。理想情况下，这些输出应该是你可以通过编程方法轻松解析的格式。根据任务的不同，比如文本分类，这可能需要使用正则表达式（regex）来筛选
    LLM 的输出。相反，对于需要更细粒度数据的任务，如命名实体识别（NER），你可能更倾向于使用 JSON 格式来输出。
- en: However, the more you work with LLMs, the faster you learn that obtaining parseable
    outputs can be challenging. LLMs often struggle to deliver outputs precisely in
    the format requested by the user. While strategies like few-shot prompting can
    significantly mitigate this issue, achieving consistent, programmatically parsable
    outputs from LLMs demands careful experimentation and adaptation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你与 LLM 的合作越多，你越快意识到获得可解析的输出是具有挑战性的。LLM 往往难以精确地按用户要求的格式提供输出。虽然像少量示例提示这样的策略可以显著缓解这个问题，但要从
    LLM 获得一致且程序化可解析的输出，还需要通过仔细的实验和调整。
- en: 3\. **Prompting for optimal performance:** LLMs are quite sensitive to how the
    task is described. A prompt that is not well-crafted or leaves too much room for
    interpretation can lead to subpar performance. Imagine explaining a task to someone
    — the clearer and more detailed your explanation, the better the understanding
    on the other end. However, there is no magic formula for arriving at the ideal
    prompt. This requires careful experimentation and evaluation of different prompts
    to select the best-performing prompt.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **优化性能的提示：** LLM 对任务描述非常敏感。如果提示不够精确或者留有太多解释空间，可能会导致较差的表现。想象一下你在向某人解释一项任务——你的解释越清晰、越详细，对方的理解就会越好。然而，达到理想提示并没有魔法公式。这需要通过仔细的实验和评估不同的提示，选择表现最好的提示。
- en: '**Exploring different prompting strategies**'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**探索不同的提示策略**'
- en: Hopefully, you’re convinced you need to take prompting seriously by this point.
    If prompting is a toolkit, what are the tools we can leverage?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到目前为止，你已经认识到需要认真对待提示。如果提示是一个工具箱，那我们可以利用哪些工具呢？
- en: '**Zero-shot Prompting:** Zero-shot prompting [2] [3] involves instructing an
    LLM to perform a task described solely in the prompt without providing examples.
    The term “zero-shot” signifies that the model must rely entirely on the task description
    in the prompt, as it receives no specific demonstrations related to the task.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**零-shot 提示：** 零-shot 提示[2][3]是指仅通过提示中描述的任务来指示 LLM 执行任务，而不提供示例。术语“零-shot”意味着模型必须完全依赖提示中的任务描述，因为它没有得到与任务相关的具体示范。'
- en: '![](../Images/bf12c12c151c864333b4f2fb77809d97.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf12c12c151c864333b4f2fb77809d97.png)'
- en: An overview of Zero-Shot Prompting. (Image by the author)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot 提示概览。（图片由作者提供）
- en: 'In many cases, zero-shot prompting can suffice for instructing an LLM to perform
    your desired task. However, zero-shot prompting may have limitations if your task
    is too ambiguous, open-ended, or vague. Suppose you want an LLM to rank an answer
    on a scale from 1 to 5\. Although the model could perform this task with a zero-shot
    prompt, two possible problems can arise here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，零-shot 提示就足以指示 LLM 执行你希望的任务。然而，如果任务过于模糊、开放性或不明确，零-shot 提示可能会有局限性。假设你想让
    LLM 按 1 到 5 的评分标准对答案进行排名。尽管模型可以使用零-shot 提示完成这个任务，但在这里可能会出现两个问题：
- en: The LLM might not have an objective understanding of what each number on the
    scoring scale signifies. It may struggle to decide when to assign a score of 3
    or 4 to an answer if the task description lacks nuance.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM 可能无法客观理解评分标准中每个分数所代表的含义。如果任务描述缺乏细节，它可能难以判断何时给答案打 3 分或 4 分。
- en: The LLM could have its own concept of scoring from 1 to 5, which might contradict
    your personal scoring rubrics. You might prioritize the factuality of an answer
    when scoring it, but the model could evaluate the answer based on how well it
    is written.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM 可能有自己对 1 到 5 评分的理解，这可能与个人评分标准相冲突。你可能在评分时优先考虑答案的事实准确性，但模型可能会根据答案的写作质量来评估。
- en: To ground the model in your scoring expectations, you can provide a few examples
    of answers and how you might score them. Now, the model has more context and reference
    on how to score documents, thereby narrowing the ambiguity in the task. This brings
    us to few-shot prompting.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让模型更好地理解你的评分预期，你可以提供一些答案示例，并说明如何对它们进行评分。这样，模型就有了更多的上下文和参考，帮助它理解如何评分文档，从而减少任务中的模糊性。这引出了少量示例提示。
- en: '**Few-shot Prompting:** Few-shot prompting enriches the task description with
    a small number of example inputs and their corresponding outputs [3]. This technique
    enhances the model’s understanding by including several example pairs illustrating
    the task.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**少量示例提示（Few-shot Prompting）：** 少量示例提示通过少量的示例输入及其相应的输出丰富了任务描述 [3]。这种技术通过包含几个示范对，帮助模型更好地理解任务。'
- en: '![](../Images/58cc2240a055d9a5cce738de853f7c5b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58cc2240a055d9a5cce738de853f7c5b.png)'
- en: An overview of Few-Shot Prompting. (Image by the author)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 少量示例提示概述。（图片由作者提供）
- en: For instance, to guide an LLM in sentiment classification of movie reviews,
    you would present a few reviews along with their sentiment ratings. The primary
    benefit of few-shot over zero-shot prompting is the ability to demonstrate examples
    of how to perform the task instead of expecting the LLM to perform the task with
    just a description.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了指导 LLM 进行电影评论的情感分类，你可以提供几条评论及其情感评分。少量示例提示相比零示例提示的主要优势是，能够展示如何执行任务的示例，而不是仅凭描述期望
    LLM 完成任务。
- en: '**Chain of Thought:** Chain of Thought (CoT) prompting [6] is a technique that
    enables LLMs to solve complex problems by breaking them down into simpler, intermediate
    steps. This approach encourages the model to “think aloud,” making its reasoning
    process transparent and allowing the LLM to solve reasoning problems more effectively.
    As mentioned by the authors of the work [6], CoT mimics how humans try to solve
    reasoning problems by decomposing the problem into simpler steps and solving them
    one at a time rather than jumping directly to the answer.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维链（Chain of Thought，CoT）：** 思维链（CoT）提示 [6] 是一种技术，能够通过将复杂问题分解为更简单的中间步骤，使
    LLM 解决问题。这种方法鼓励模型“边思考边说”，使其推理过程变得透明，从而让 LLM 更有效地解决推理问题。正如文献 [6] 的作者所提到的，CoT 模拟了人类通过将问题分解为更简单的步骤并逐一解决它们，而不是直接跳到答案的方式来解决推理问题。'
- en: '![](../Images/79baf1845e581cfe3140508309256a9c.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79baf1845e581cfe3140508309256a9c.png)'
- en: An overview of Chain-of-Thought Prompting. (Image by the author)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链提示概述。（图片由作者提供）
- en: CoT prompting is typically implemented as a few-shot prompt, where the model
    receives a task description and examples of input-output pairs. These examples
    include reasoning steps that systematically lead to the correct answer, demonstrating
    how to process the information. Thus, to perform CoT prompting effectively, users
    need high-quality demonstration examples. However, this can be challenging for
    tasks requiring specialized domain expertise. For instance, using an LLM for medical
    diagnosis based on a patient’s history would necessitate the assistance of domain
    experts, such as doctors or physicians, to articulate the correct reasoning steps.
    Moreover, CoT is particularly effective in models with a sufficiently large parameter
    scale. According to the paper [6], CoT is most effective for the 137B parameter
    LaMBDA [7], the 175B parameter GPT-3 [3], and the 540B parameter PaLM [8] models.
    This limitation can restrict its applicability for smaller-scale models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: CoT 提示通常作为少量示例提示实现，其中模型接收任务描述和输入-输出对的示例。这些示例包括推理步骤，这些步骤系统性地引导至正确答案，展示如何处理信息。因此，为了有效地执行
    CoT 提示，用户需要高质量的示范示例。然而，对于需要专门领域知识的任务，这可能是一个挑战。例如，使用大型语言模型（LLM）根据患者病史进行医学诊断时，需要领域专家的协助，如医生或医学专家，来阐明正确的推理步骤。此外，CoT
    在具有足够大参数规模的模型中尤其有效。根据文献 [6]，CoT 在 137B 参数的 LaMBDA [7]、175B 参数的 GPT-3 [3] 和 540B
    参数的 PaLM [8] 模型中最为有效。这个限制可能会限制其在小规模模型中的适用性。
- en: '![](../Images/7e9847b192ff473c6e794fd82530c80e.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e9847b192ff473c6e794fd82530c80e.png)'
- en: Figure taken from [6] ([Source](https://arxiv.org/abs/2201.11903)) shows that
    the performance improvement provided by CoT prompting improves substantially with
    the scale of the model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从文献 [6] 中取图（[来源](https://arxiv.org/abs/2201.11903)）显示，CoT 提示所带来的性能提升随着模型规模的增大而显著提升。
- en: Another aspect of CoT prompting that sets it apart from standard prompting is
    that the model needs to generate significantly more tokens before arriving at
    the final answer. While not necessarily a drawback, this is a factor to consider
    if you are compute-bound at inference time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CoT 提示的另一个特点是，它与标准提示的不同之处在于模型需要生成更多的标记才能得出最终答案。虽然这不一定是缺点，但如果你在推理时受限于计算资源，这是需要考虑的一个因素。
- en: If you want a deeper overview, I recommend OpenAI’s prompting resources, available
    at [https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要更深入的概览，我推荐 OpenAI 的提示资源，可以在 [https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions](https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions)
    查阅。
- en: '**How can we implement these techniques?**'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**我们如何实现这些技术？**'
- en: All code and resources related to this article are made available at [this Github
    repository](https://github.com/anand-subu/blog_resources/tree/main), under the
    introduction_to_prompting folder. Feel free to pull the repository and run the
    notebooks directly to run these experiments. Please let me know if you have any
    feedback or observations or if you notice any mistakes!
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文相关的所有代码和资源都可以在 [这个 Github 仓库](https://github.com/anand-subu/blog_resources/tree/main)
    中找到，位于 introduction_to_prompting 文件夹下。欢迎克隆仓库并直接运行 notebooks 进行实验。如果你有任何反馈或观察，或者发现任何错误，请告诉我！
- en: We can explore these techniques on a sample dataset to make understanding easier.
    To this end, we will work with the MedQA dataset [9], which contains questions
    testing medical and clinical knowledge. We will specifically utilize the USMLE
    questions from this dataset. This task is ideal for analyzing various prompting
    techniques, as answering the questions requires knowledge and reasoning. We will
    test the capabilities of Llama-2 7B [10] and GPT-3.5 [11] on this dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在一个示例数据集上探索这些技术，以便更容易理解。为此，我们将使用 MedQA 数据集[9]，该数据集包含测试医学和临床知识的问题。我们将特别利用该数据集中的
    USMLE 问题。这个任务非常适合分析各种提示技术，因为回答这些问题需要知识和推理。我们将测试 Llama-2 7B[10] 和 GPT-3.5[11] 在该数据集上的表现。
- en: Let’s first download the dataset. The MedQA dataset can be downloaded from [this
    link](https://drive.google.com/file/d/1ImYUSLk9JbgHXOemfvyiDiirluZHPeQw/view).
    After downloading the dataset, we can parse and begin processing the questions.
    The test set contains a total of 1,273 questions. We randomly sample 300 questions
    from the test set to evaluate the models and select 3 random examples from the
    training set as our few-shot demonstrations for the model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先下载数据集。MedQA 数据集可以从 [这个链接](https://drive.google.com/file/d/1ImYUSLk9JbgHXOemfvyiDiirluZHPeQw/view)
    下载。下载数据集后，我们可以解析并开始处理问题。测试集包含 1,273 个问题。我们从测试集中随机抽取 300 个问题来评估模型，并从训练集中随机选择 3
    个示例作为我们对模型的少量示范。
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Prompting Llama 2 7B-Chat with a Zero-Shot Prompt**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**使用零样本提示引导 Llama 2 7B-Chat**'
- en: 'The Llama series of models were released by Meta. They are a decoder-only family
    of LLMs spanning parameter counts from 7B to 70B. The Llama-2 series of models
    comes in two variants: the base version and the chat/instruction-tuned variant.
    For this exercise, we’ll work with the chat-version of the Llama 2-7B model.'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Llama 系列模型由 Meta 发布。它们是仅解码器的 LLM 系列，参数范围从 7B 到 70B。Llama-2 系列模型有两种变体：基础版本和聊天/指令微调版本。对于本次练习，我们将使用
    Llama 2-7B 模型的聊天版本。
- en: 'Let’s see how well we can prompt the Llama model to answer these medical questions.
    We load the model into memory:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何有效地引导 Llama 模型回答这些医学问题。我们将模型加载到内存中：
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you’re working with Nvidia Ampere GPUs, you can load the model using torch.bfloat16\.
    It offers speedups to inference and utilizes lesser GPU memory than normal FP16/FP32.
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你使用的是 Nvidia Ampere GPU，你可以使用 torch.bfloat16 加载模型。它可以加速推理，并比普通的 FP16/FP32
    使用更少的 GPU 内存。
- en: 'First, let’s now craft a basic prompt for our task:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们为我们的任务设计一个基本的提示：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Our prompt is straightforward. It includes information about the nature of the
    task and provides instructions on the format for the output. We’ll see how effectively
    this prompt works in practice.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的提示非常简单，包含任务的性质信息，并提供输出格式的指令。我们将看到这个提示在实践中的效果如何。
- en: The Llama-2 chat models have a particular chat template to be followed for prompting
    them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Llama-2 聊天模型有一个特定的聊天模板，需要遵循该模板来提示它们。
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The task description should be provided between the <<SYS>> tokens, followed
    by the actual question the model needs to answer. The prompt is concluded with
    a [/INST] token to indicate the end of the input text.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 任务描述应位于<<SYS>>标记之间，后跟模型需要回答的实际问题。提示以[/INST]标记结尾，表示输入文本的结束。
- en: The role can be one of “**user**”, “**system**”, or “**assistant**”. The “system”
    role provides the model with the task description, and the “user” role contains
    the input to which the model needs to respond. This is the same convention we
    will utilize later on when interacting with GPT-3.5\. It is equivalent to creating
    a fictional multi-turn conversation history provided to Llama-2, where each turn
    corresponds to an example demonstration and an ideal output from the model.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 角色可以是“**user**”、“**system**”或“**assistant**”之一。系统角色为模型提供任务描述，用户角色包含模型需要响应的输入。这与我们稍后在与GPT-3.5交互时采用的约定相同。它相当于为Llama-2创建一个虚构的多轮对话历史，其中每一轮对应一个示范示例和模型的理想输出。
- en: Sounds complicated? Thankfully, the Huggingface Transformers library supports
    converting prompts to the chat template. We will utilize this functionality to
    make our lives easier. Let’s start with helper functionalities to process the
    dataset and create prompts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很复杂？幸运的是，Huggingface Transformers库支持将提示转换为聊天模板。我们将利用这个功能来简化我们的工作。让我们从辅助功能开始，处理数据集并创建提示。
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This function constructs the query to provide to the LLM. The MedQA dataset
    stores each question as a JSON element, with the questions and options provided
    as keys. We parse the JSON and construct the question along with the choices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该功能构建了提供给LLM的查询。MedQA数据集将每个问题存储为JSON元素，问题和选项作为键提供。我们解析JSON并构建问题及其选择。
- en: Let’s start obtaining outputs from the model. The current task involves answering
    the provided medical question by selecting the correct answer from various options.
    Unlike creative tasks such as content writing or summarization, which may require
    the model to be imaginative and creative in its output, this is a knowledge-based
    task designed to test the model’s ability to answer questions based on knowledge
    encoded in its parameters. Therefore, we will use greedy decoding while generating
    the answer. Let’s define a helper function for parsing the model responses and
    calculating accuracy.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始从模型中获取输出。当前任务是通过从多个选项中选择正确答案来回答提供的医学问题。与内容创作或总结等创造性任务不同，这些任务可能需要模型在输出中展现想象力和创造力，这是一个基于知识的任务，旨在测试模型根据其参数中编码的知识回答问题的能力。因此，在生成答案时，我们将使用贪婪解码。让我们定义一个辅助函数来解析模型的回答并计算准确度。
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We get a performance of 3̶6̶%̶ 35% in the zero-shot setting. Not a bad start,
    but let’s see if we can push this performance further.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在零样本设置下，我们的表现为3̶6̶%̶ 35%。这不是一个糟糕的开始，但让我们看看能否进一步提升表现。
- en: '**Edit on 09/03/2024** — I noticed a minor “bug” in the way the prompt was
    formatted and tokenized. Specifically, I used the tokenizer.apply_chat_template(zero_shot_prompt_messages,
    tokenize = False) and then called the tokenizer to get the input_ids earlier.
    This method adds an extra <s> token at the start to the prompt. The apply_chat_template
    already adds an <s> token to the sequence, but calling the tokenizer after creating
    the chat template adds the specical token <s> again at the start. I fixed this
    by changing tokenize=True in apply_chat_template. The new score I got was 35%,
    a small dip of 1% compared to the old setting where the score was 36%. It’s a
    bit amusing that fixing this “bug” leads to a minor score dip, but I’m making
    the correction here and in the code to avoid any confusion in using chat templates.
    None of the findings or takeaways in this article are otherwise affected by this
    fix.'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑于2024年09月03日** — 我注意到提示格式和标记化方式中有一个小“bug”。具体来说，我使用了tokenizer.apply_chat_template(zero_shot_prompt_messages,
    tokenize = False)，然后调用tokenizer提前获取input_ids。这个方法在提示开始时额外添加了一个<s>标记。apply_chat_template已经将<s>标记添加到序列中，但在创建聊天模板后再次调用tokenizer会在开头再次添加特殊标记<s>。我通过将apply_chat_template中的tokenize设置为True来修正这个问题。我得到的新得分是35%，比原来的36%小幅下降了1%。修复这个“bug”导致得分略微下降，这有点好笑，但为了避免在使用聊天模板时引起混淆，我在此和代码中做了修正。本文的其他发现和结论不受此修复的影响。'
- en: Prompting Llama 2 7B-Chat with a Few-Shot Prompt
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用少量示例提示进行Llama 2 7B-Chat的提示
- en: Let’s now provide task demonstrations to the model. We use the three randomly
    sampled questions from the training set and append them to the model as task demonstrations.
    Fortunately, we can continue using the chat-template support provided by the Transformers
    library and the tokenizer to append our few-shot examples with minimal code changes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let’s visualize what our few-shot prompt looks like.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The prompt is quite long, given that we append three demonstrations. Let’s
    now run Llama-2 with the few-shot prompt and get the results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We now get an overall accuracy of 4̵1̵.̵6̵7̵%̵ 40.33%. Not bad, nearly 6̵%̵
    5% improvement over zero-shot prompting with the same model!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '**Edit on 09/03/2024** — Similar to the zero-shot setting, I fixed the way
    the prompt is sent to the model for the few-shot setting. The new score I got
    was 40.33%, a small dip of ~1.3% compared to the old setting where the score was
    41.67%. It’s again a bit amusing that fixing this “bug” leads to a minor score
    dip, but I’m making the correction here and in the code to avoid any confusion
    in using chat templates. None of the findings or takeaways in this article are
    otherwise affected by this fix.'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What happens if we don’t adhere to the chat template?
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier, I observed that it is advisable to structure our prompt according to
    the prompt template that was used to fine-tune an LLM originally. Let’s verify
    if not adhering to the chat template hurts our performance. We create a function
    that builds a few-shot prompt using the same examples without adhering to the
    chat format.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Our prompts now look like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s now evaluate Llama 2 with these prompts and observe how it performs:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We achieve an accuracy of 36%. This is 6̶%̶ 4.3% lower than our earlier few-shot
    score. This reinforces our previous argument that it is crucial to structure our
    prompts according to the template used to fine-tune the LLM we intend to work
    with. Prompt templates matter!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompting Llama 2 7B-Chat with CoT Prompting**'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s conclude by evaluating CoT prompting. Remember, our dataset includes questions
    designed to test medical knowledge through the USMLE exam. Such questions often
    require both factual recall and conceptual reasoning to answer. This makes it
    a perfect task for testing how well CoT works.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: First, we must provide an example CoT prompt to the model to demonstrate how
    to reason about a question. For this purpose, we will use one of the prompts from
    Google’s MedPALM paper [12].
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e947fa6ba06d18bae65fe3354e5778aa.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: Five-shot CoT prompt used for evaluating the MedPALM model on the MedQA dataset.
    Prompt borrowed from Table A.18, Page 41 of [12] ([Source](https://arxiv.org/abs/2212.13138)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: We use this five-shot prompt for evaluating the models. Since this prompt style
    differs slightly from our earlier prompts, let’s create some helper functions
    again to process them and obtain the outputs. While utilizing CoT prompting, we
    generate the output with a larger output token count to enable the model to “think”
    and “reason” before answering the question.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个五-shot提示词来评估模型。由于这个提示风格与之前的提示略有不同，我们再次创建一些辅助函数来处理这些提示词并获取输出。在使用CoT提示时，我们生成较长的输出令牌，以便让模型在回答问题之前“思考”和“推理”。
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Our performance dips to 2̶0̶%̶ 21.33% using CoT prompting for Llama 2–7B. This
    is generally in line with the findings of the CoT paper [6], where the authors
    mention that CoT is an emergent property for LLMs that improves with the scale
    of the model. That being said, let’s analyze why the performance dipped drastically.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用CoT提示词进行Llama 2–7B模型测试时，性能下降至2̶0̶%̶ 21.33%。这一结果与CoT论文[6]的发现大致一致，论文中提到CoT是LLM模型的一个涌现特性，且随着模型规模的增大，CoT的表现会得到改善。话虽如此，我们来分析为什么性能会急剧下降。
- en: '**Edit on 09/03/2024** — Similar to the zero-shot setting, I fixed the way
    the prompt was sent to the model for the CoT setting. The new score I got was
    21.33%, a small increase of ~1.33% compared to the old setting where the score
    was 20%. I’m making the correction here and in the code to avoid any confusion
    about using chat templates. None of the findings or takeaways in this article
    are otherwise affected by this fix.'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2024年09月03日编辑** — 与零-shot设置类似，我修正了发送到模型的提示词方式，调整为CoT设置下的新方式。我得到的新分数为21.33%，相比原先20%的得分，提升了约1.33%。我在这里和代码中进行了修正，以避免使用聊天模板时的任何混淆。本文中的发现和结论并未受到此次修正的影响。'
- en: Failure Modes in CoT for Llama 2
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Llama 2中CoT的失败模式
- en: 'We sample a few of the responses provided by Llama 2 on some of the test set
    questions to analyze error cases:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们抽取了一些Llama 2在测试集问题中的回答，用以分析错误案例：
- en: The analysis of these CoT samples and the figures are not affected by the fixing
    of the minor “bug”. I’ve verified that the predictions used in these figures are
    identical in both the old and new setting.
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些CoT样本和图表的分析不受小“bug”修复的影响。我已经验证过，这些图表中使用的预测结果，在旧设置和新设置中是相同的。
- en: '![](../Images/bafde2d1cb6d802d5b8c1c826acfc01c.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bafde2d1cb6d802d5b8c1c826acfc01c.png)'
- en: Sample Prediction 1 — The model arrives at an answer but does not adhere to
    the format, making parsing the result hard. (Image by the author)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 示例预测1 — 模型得出一个答案，但没有遵循格式，导致解析结果困难。（作者提供的图片）
- en: '![](../Images/9192f54c14ae9038111571c6319de6cc.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9192f54c14ae9038111571c6319de6cc.png)'
- en: Sample Prediction 2 — The model fails to adhere to the prompt format and arrive
    at a conclusive answer. (Image by the author)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 示例预测2 — 模型未能遵循提示格式，也未能给出确凿的答案。（作者提供的图片）
- en: While CoT prompting allows the model to “think” before arriving at the final
    answer, in most cases, the model either does not arrive at a conclusive answer
    or mentions the answer in a format inconsistent with our example demonstrations.
    A failure mode I haven’t analyzed here, but potentially worth exploring, is to
    check cases in the test set where the model “reasons” incorrectly and, therefore,
    arrives at the wrong answer. This is beyond the scope of the current article and
    my medical knowledge, but it is certainly something I intend to revisit later.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CoT提示词让模型在给出最终答案之前能够“思考”，但在大多数情况下，模型要么无法得出确定的答案，要么给出的答案格式与我们的示例不一致。我没有在这里分析的一种失败模式，但可能值得探索的是，检查测试集中的一些案例，模型可能“推理”错误，从而得到错误的答案。这超出了当前文章和我的医学知识的范围，但肯定是我以后打算重新审视的问题。
- en: Prompting GPT-3.5 with a Zero-Shot Prompt
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用零-shot提示词提示GPT-3.5
- en: 'Let’s begin defining some helper functions that help us process these inputs
    for utilizing the GPT API. You would need to generate an API key to use the GPT-3.5
    API. You can set the API key in Windows using:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始定义一些辅助函数，帮助我们处理这些输入以便利用GPT API。你需要生成一个API密钥才能使用GPT-3.5 API。你可以在Windows中使用以下命令设置API密钥：
- en: '`setx OPENAI_API_KEY "your-api-key-here"`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`setx OPENAI_API_KEY "your-api-key-here"`'
- en: 'or in Linux using:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 或在Linux中使用：
- en: '`export OPENAI_API_KEY "your-api-key-here"`'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`export OPENAI_API_KEY "your-api-key-here"`'
- en: in the current session you are using.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前使用的会话中。
- en: '[PRE17]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This function now constructs the prompt in the format for the GPT-3.5 API. We
    can interact with the GPT-3.5 model through the chat-completions API provided
    by the library. The API requires messages to be structured as a list of dictionaries
    for sending to the API. Each message must specify the role and the content. The
    conventions followed regarding the ***“system”,*** “***user***”, and “***assistant***”
    roles are the same as those described earlier for the Llama-7B Chat Model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数现在构建了适用于 GPT-3.5 API 格式的提示词。我们可以通过该库提供的 chat-completions API 与 GPT-3.5 模型进行互动。该
    API 要求消息按字典列表的格式发送给 API。每个消息必须指定角色和内容。关于***“system”***、***“user”***和***“assistant”***角色的约定与之前为
    Llama-7B 聊天模型描述的相同。
- en: Let’s now use the GPT-3.5 API to process the test set and obtain the responses.
    After receiving all the responses, we extract the options from the model’s responses
    and calculate the accuracy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用 GPT-3.5 API 处理测试集并获取响应。在收到所有响应后，我们从模型的响应中提取选项并计算准确率。
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Our performance now stands at 63%. This is a significant improvement from the
    performance of Llama 2–7B. This isn’t surprising, given that GPT-3.5 is likely
    much larger and trained on more data than Llama 2–7B, along with other proprietary
    optimizations that OpenAI may have included to the model. Let’s see how well few-shot
    prompting works now.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们的性能为 63%。这比 Llama 2–7B 的性能有了显著提升。这并不令人惊讶，因为 GPT-3.5 可能比 Llama 2–7B 大得多，并且训练了更多的数据，另外
    OpenAI 可能还对模型进行了其他专有优化。现在让我们看看少量示例提示的效果如何。
- en: Prompting GPT-3.5 with a Few-Shot Prompt
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用少量示例提示词提示 GPT-3.5
- en: To provide few-shot examples to the LLM, we reuse the three examples we sampled
    from the training set and append them to the prompt. For GPT-3.5, we create a
    list of messages with examples, similar to our earlier processing for Llama 2\.
    The inputs are appended using the “user” role, and the corresponding option is
    presented in the “assistant” role. We reuse the earlier function for building
    few-shot prompts.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向大型语言模型提供少量示例，我们重用从训练集中采样的三个示例，并将它们附加到提示词中。对于 GPT-3.5，我们创建一个包含示例的消息列表，类似于我们之前处理
    Llama 2 的方式。输入通过“user”角色附加，相关的选项通过“assistant”角色呈现。我们重用了之前构建少量示例提示词的函数。
- en: This is again equivalent to creating a fictional multi-turn conversation history
    provided to GPT-3.5, where each turn corresponds to an example demonstration.
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这相当于为 GPT-3.5 创建一个虚构的多轮对话历史，每一轮都对应一个示例演示。
- en: Let’s now obtain the outputs using GPT-3.5.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用 GPT-3.5 获取输出。
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We’ve managed to push the performance from 63% to 67% using few-shot prompting!
    This is a significant improvement, highlighting the value of providing task demonstrations
    to the model.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过少量示例提示将性能从 63% 提高到了 67%！这是一项显著的提升，突显了向模型提供任务演示的价值。
- en: Prompting GPT-3.5 with CoT Prompting
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 CoT 提示词提示 GPT-3.5
- en: 'Let’s now evaluate GPT-3.5 with CoT prompting. We re-use the same CoT prompt
    and get the outputs:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们评估使用 CoT 提示词的 GPT-3.5。我们重新使用相同的 CoT 提示词并获取输出：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Using CoT prompting with GPT-3.5 results in an accuracy of 71%! This represents
    a further 4% improvement over few-shot prompting. It appears that enabling the
    model to “think” out loud before answering the question is beneficial for this
    task. This is also consistent with the findings of the paper [6] that CoT unlocked
    performance improvements for larger parameter models.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CoT 提示词与 GPT-3.5 提示进行的结果准确率为 71%！这比少量示例提示提高了 4%。看起来在回答问题之前让模型“思考”是有益的，这也与论文[6]的发现一致，CoT
    解锁了大参数模型的性能提升。
- en: 'Conclusion and Takeaways:'
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论与收获：
- en: Prompting is a crucial skill for working with Large Language Models (LLMs),
    and understanding that there are various tools in the prompting toolkit that can
    help extract better performance from LLMs for your tasks depending on the context.
    I hope this article serves as a broad and (hopefully!) accessible introduction
    to this subject. However, it does not aim to provide a comprehensive overview
    of all prompting strategies. Prompting remains a highly active field of research,
    with numerous methods being introduced such as ReAct [13], Tree-of-Thought prompting
    [14] etc. I recommend exploring these techniques to better understand them and
    enhance your prompting toolkit.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是使用大型语言模型（LLMs）时的一个关键技能，理解提示工具包中的各种工具可以帮助根据上下文从LLMs中提取更好的性能。我希望这篇文章能作为一个广泛且（希望！）易于理解的介绍。然而，它并不旨在提供所有提示策略的全面概述。提示仍然是一个高度活跃的研究领域，许多方法被提出，如ReAct
    [13]、Tree-of-Thought提示[14]等。我建议探索这些技术，以更好地理解它们并增强你的提示工具包。
- en: Reproducibility
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可重复性
- en: In this article, I’ve aimed to make all experiments as deterministic and reproducible
    as possible. We use greedy decoding to obtain our outputs for zero-shot, few-shot,
    and CoT prompting with Llama-2\. While these scores should technically be reproducible,
    in rare cases, Cuda/GPU-related or library issues could lead to slightly different
    results.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我的目标是尽可能使所有实验具备确定性并且可重复。我们使用贪婪解码来获得零样本、少量样本和CoT提示下的输出，使用Llama-2模型。虽然这些得分从技术上讲应该是可重复的，但在少数情况下，Cuda/GPU相关或库问题可能导致稍微不同的结果。
- en: Similarly, when obtaining responses from the GPT-3.5 API, we use a temperature
    of 0 to get results and choose only the next most likely token without sampling
    for all prompt settings. This makes the results [“mostly deterministic”](https://platform.openai.com/docs/guides/text-generation/reproducible-outputs),
    so it is possible that sending the same prompts to GPT-3.5 again may result in
    slightly different results.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在从GPT-3.5 API获取响应时，我们使用温度值为0来获得结果，并且在所有提示设置中仅选择下一个最可能的标记，而不进行采样。这使得结果[“大多数是确定性的”](https://platform.openai.com/docs/guides/text-generation/reproducible-outputs)，因此再次发送相同的提示给GPT-3.5可能会导致稍有不同的结果。
- en: I have provided the outputs of the models under all prompt settings, along with
    the sub-sampled test set, few-shot prompt examples, and CoT prompt (from the MedPALM
    paper) for reproducing the scores reported in this article.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我已提供在所有提示设置下模型的输出，以及子采样的测试集、少量样本提示示例和CoT提示（来自MedPALM论文），用于重现本文中报告的得分。
- en: '**References:**'
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: All papers referred to in this blog post are listed here. Please let me know
    if I might have missed out any references, and I will add them!
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文中提到的所有论文都在此列出。如果我遗漏了任何参考文献，请告诉我，我会添加它们！
- en: '[1] Yang, J., Jin, H., Tang, R., Han, X., Feng, Q., Jiang, H., … & Hu, X. (2023).
    Harnessing the power of llms in practice: A survey on chatgpt and beyond. *arXiv
    preprint arXiv:2304.13712*.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Yang, J., Jin, H., Tang, R., Han, X., Feng, Q., Jiang, H., … & Hu, X. (2023).
    实践中驾驭LLMs的力量：关于ChatGPT及其以后的调查。*arXiv 预印本 arXiv:2304.13712*。'
- en: '[2] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019).
    Language models are unsupervised multitask learners. *OpenAI blog*, *1*(8), 9.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019).
    语言模型是无监督的多任务学习者。*OpenAI 博客*，*1*(8)，9。'
- en: '[3] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P.,
    … & Amodei, D. (2020). Language models are few-shot learners. *Advances in neural
    information processing systems*, *33*, 1877–1901.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P.,
    … & Amodei, D. (2020). 语言模型是少量学习者。*神经信息处理系统进展*，*33*，1877–1901。'
- en: '[4] Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., … & Le,
    Q. V. (2021). Finetuned language models are zero-shot learners. *arXiv preprint
    arXiv:2109.01652*.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., … & Le,
    Q. V. (2021). 微调语言模型是零样本学习者。*arXiv 预印本 arXiv:2109.01652*。'
- en: '[5] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P.,
    … & Lowe, R. (2022). Training language models to follow instructions with human
    feedback. *Advances in Neural Information Processing Systems*, *35*, 27730–27744.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P.,
    … & Lowe, R. (2022). 训练语言模型以根据人类反馈遵循指令。*神经信息处理系统进展*，*35*，27730–27744。'
- en: '[6] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., … & Zhou,
    D. (2022). Chain-of-thought prompting elicits reasoning in large language models.
    *Advances in Neural Information Processing Systems*, *35*, 24824–24837.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., … & Zhou,
    D. (2022). 连锁思维提示激发大型语言模型的推理能力. *神经信息处理系统进展*, *35*, 24824–24837.'
- en: '[7] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H. T., … & Le, Q. (2022). Lamda: Language models for dialog applications.
    *arXiv preprint arXiv:2201.08239*.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A.,
    Cheng, H. T., … & Le, Q. (2022). Lamda: 面向对话应用的语言模型. *arXiv预印本 arXiv:2201.08239*.'
- en: '[8] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts,
    A., … & Fiedel, N. (2023). Palm: Scaling language modeling with pathways. *Journal
    of Machine Learning Research*, *24*(240), 1–113.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts,
    A., … & Fiedel, N. (2023). Palm: 利用路径扩展语言建模. *机器学习研究期刊*, *24*(240), 1–113.'
- en: '[9] Jin, D., Pan, E., Oufattole, N., Weng, W. H., Fang, H., & Szolovits, P.
    (2021). What disease does this patient have? a large-scale open domain question
    answering dataset from medical exams. *Applied Sciences*, *11*(14), 6421.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Jin, D., Pan, E., Oufattole, N., Weng, W. H., Fang, H., & Szolovits, P.
    (2021). 这个病人得了什么病？来自医学考试的大规模开放域问答数据集. *应用科学*, *11*(14), 6421.'
- en: '[10] Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei,
    Y., … & Scialom, T. (2023). Llama 2: Open foundation and fine-tuned chat models.
    *arXiv preprint arXiv:2307.09288*.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei,
    Y., … & Scialom, T. (2023). Llama 2: 开放的基础和微调的聊天模型. *arXiv预印本 arXiv:2307.09288*.'
- en: '[11] [https://platform.openai.com/docs/models/gpt-3-5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [https://platform.openai.com/docs/models/gpt-3-5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)'
- en: '[12] Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W.,
    … & Natarajan, V. (2023). Large language models encode clinical knowledge. *Nature*,
    *620*(7972), 172–180.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] Singhal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W.,
    … & Natarajan, V. (2023). 大型语言模型编码临床知识. *自然*, *620*(7972), 172–180.'
- en: '[13] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. R., & Cao,
    Y. (2022, September). ReAct: Synergizing Reasoning and Acting in Language Models.
    In *The Eleventh International Conference on Learning Representations*.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. R., & Cao,
    Y. (2022年9月). ReAct: 协同推理与行动在语言模型中的结合. 发表在 *第十一届国际学习表示大会* 上。'
- en: '[14] Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., & Narasimhan,
    K. (2024). Tree of thoughts: Deliberate problem solving with large language models.
    *Advances in Neural Information Processing Systems*, *36*.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., & Narasimhan,
    K. (2024). 思维树：使用大型语言模型进行深思熟虑的问题解决. *神经信息处理系统进展*, *36*.'
