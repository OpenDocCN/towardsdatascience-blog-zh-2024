# ä½¿ç”¨ FAISS å’Œ CLIP æ„å»ºå›¾åƒç›¸ä¼¼åº¦æœç´¢å¼•æ“

> åŸæ–‡ï¼š[`towardsdatascience.com/building-an-image-similarity-search-engine-with-faiss-and-clip-2211126d08fa?source=collection_archive---------3-----------------------#2024-08-23`](https://towardsdatascience.com/building-an-image-similarity-search-engine-with-faiss-and-clip-2211126d08fa?source=collection_archive---------3-----------------------#2024-08-23)

## ä¸€ç¯‡æŒ‡å¯¼æ€§æ•™ç¨‹ï¼Œè§£é‡Šå¦‚ä½•ä½¿ç”¨ CLIP åµŒå…¥å’Œ FAISS ç´¢å¼•ï¼Œé€šè¿‡æ–‡æœ¬æˆ–ç…§ç‰‡æŸ¥è¯¢æœç´¢å›¾åƒæ•°æ®é›†ã€‚

[](https://medium.com/@lihigurarie?source=post_page---byline--2211126d08fa--------------------------------)![Lihi Gur Arie, PhD](https://medium.com/@lihigurarie?source=post_page---byline--2211126d08fa--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2211126d08fa--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2211126d08fa--------------------------------) [Lihi Gur Arie, åšå£«](https://medium.com/@lihigurarie?source=post_page---byline--2211126d08fa--------------------------------)

Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2211126d08fa--------------------------------) Â·6 åˆ†é’Ÿé˜…è¯»Â·2024 å¹´ 8 æœˆ 23 æ—¥

--

![](img/6aa0f89a4ae8ff874b4620b8a4ef873b.png)

å›¾ç‰‡ç”±ä½œè€…åœ¨ Flux-Pro å¹³å°ä¸Šç”Ÿæˆ

# å¼•è¨€

ä½ æ˜¯å¦æ›¾ç»æƒ³åœ¨ä½ çš„æ— å°½å›¾åƒæ•°æ®é›†ä¸­æ‰¾åˆ°ä¸€å¼ å›¾åƒï¼Œå´è§‰å¾—è¿™é¡¹ä»»åŠ¡å¤ªç¹çï¼Ÿåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå›¾åƒç›¸ä¼¼åº¦æœç´¢å¼•æ“ï¼Œé€šè¿‡æ–‡æœ¬æŸ¥è¯¢æˆ–å‚è€ƒå›¾åƒè½»æ¾æ‰¾åˆ°å›¾åƒã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæœ¬æ•™ç¨‹çš„å®Œæ•´ä»£ç å·²æä¾›åœ¨æ–‡ç« åº•éƒ¨ï¼Œä½œä¸ºä¸€ä¸ª**Colab ç¬”è®°æœ¬**ã€‚

> å¦‚æœä½ æ²¡æœ‰ä»˜è´¹çš„ Medium è´¦æˆ·ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œå…è´¹é˜…è¯»ã€‚

## æµç¨‹æ¦‚è§ˆ

å›¾åƒçš„è¯­ä¹‰æ„ä¹‰å¯ä»¥é€šè¿‡ä¸€ä¸ªç§°ä¸ºåµŒå…¥ï¼ˆembeddingï¼‰çš„æ•°å€¼å‘é‡è¡¨ç¤ºã€‚é€šè¿‡æ¯”è¾ƒè¿™äº›ä½ç»´çš„åµŒå…¥å‘é‡ï¼Œè€Œä¸æ˜¯åŸå§‹å›¾åƒï¼Œå¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ã€‚å¯¹äºæ•°æ®é›†ä¸­çš„æ¯ä¸€å¼ å›¾ç‰‡ï¼Œæˆ‘ä»¬éƒ½ä¼šåˆ›å»ºä¸€ä¸ªåµŒå…¥å‘é‡å¹¶å°†å…¶å­˜å‚¨åœ¨ç´¢å¼•ä¸­ã€‚å½“æä¾›æ–‡æœ¬æŸ¥è¯¢æˆ–å‚è€ƒå›¾åƒæ—¶ï¼Œä¼šç”Ÿæˆå…¶åµŒå…¥å¹¶ä¸ç´¢å¼•ä¸­çš„åµŒå…¥è¿›è¡Œæ¯”è¾ƒï¼Œä»¥æ£€ç´¢æœ€ç›¸ä¼¼çš„å›¾åƒã€‚

è¿™é‡Œæ˜¯ç®€è¦æ¦‚è§ˆï¼š

1.  **åµŒå…¥**ï¼šå›¾åƒçš„åµŒå…¥æ˜¯é€šè¿‡ CLIP æ¨¡å‹æå–çš„ã€‚

1.  **ç´¢å¼•**ï¼šåµŒå…¥å‘é‡è¢«å­˜å‚¨ä¸º FAISS ç´¢å¼•ã€‚

1.  **æ£€ç´¢**ï¼šä½¿ç”¨ FAISSï¼ŒæŸ¥è¯¢çš„åµŒå…¥ä¸ç´¢å¼•ä¸­çš„åµŒå…¥è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œæ£€ç´¢æœ€ç›¸ä¼¼çš„å›¾åƒã€‚

## CLIP æ¨¡å‹

CLIPï¼ˆå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼‰æ¨¡å‹æ˜¯ç”± OpenAI å¼€å‘çš„å¤šæ¨¡æ€è§†è§‰ä¸è¯­è¨€æ¨¡å‹ï¼Œå®ƒå°†å›¾åƒå’Œæ–‡æœ¬æ˜ å°„åˆ°ç›¸åŒçš„æ½œåœ¨ç©ºé—´ã€‚ç”±äºæˆ‘ä»¬å°†ä½¿ç”¨å›¾åƒå’Œæ–‡æœ¬æŸ¥è¯¢æ¥æœç´¢å›¾åƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ CLIP æ¨¡å‹æ¥åµŒå…¥æˆ‘ä»¬çš„æ•°æ®ã€‚å…³äº CLIP çš„è¿›ä¸€æ­¥é˜…è¯»ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æˆ‘ä¹‹å‰çš„æ–‡ç« è¿™é‡Œã€‚

## FAISS ç´¢å¼•

FAISSï¼ˆFacebook AI ç›¸ä¼¼åº¦æœç´¢ï¼‰æ˜¯ Meta å¼€å‘çš„å¼€æºåº“ã€‚å®ƒå›´ç»•å­˜å‚¨æ•°æ®åº“åµŒå…¥å‘é‡çš„ç´¢å¼•å¯¹è±¡æ„å»ºã€‚FAISS ä½¿å¾—å¯†é›†å‘é‡çš„é«˜æ•ˆç›¸ä¼¼åº¦æœç´¢å’Œèšç±»æˆä¸ºå¯èƒ½ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒå¯¹æˆ‘ä»¬çš„æ•°æ®é›†è¿›è¡Œç´¢å¼•ï¼Œå¹¶æ£€ç´¢ä¸æŸ¥è¯¢ç›¸ä¼¼çš„ç…§ç‰‡ã€‚

# ä»£ç å®ç°

## **ç¬¬ 1 æ­¥ â€” æ•°æ®é›†æ¢ç´¢**

ä¸ºäº†åˆ›å»ºæœ¬æ•™ç¨‹çš„å›¾åƒæ•°æ®é›†ï¼Œæˆ‘ä»[Pexels](https://www.pexels.com/)æ”¶é›†äº† 52 å¼ å„ç§ä¸»é¢˜çš„å›¾åƒã€‚ä¸ºäº†å¸®åŠ©ç†è§£ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ 10 å¼ éšæœºå›¾åƒï¼š

![](img/5783da36e449663c611c2569c8921c43.png)

## **ç¬¬ 2 æ­¥ â€” ä»å›¾åƒæ•°æ®é›†ä¸­æå– CLIP åµŒå…¥å‘é‡**

è¦æå– CLIP åµŒå…¥å‘é‡ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨ HuggingFace SentenceTransformer åº“åŠ è½½ CLIP æ¨¡å‹ï¼š

```py
model = SentenceTransformer('clip-ViT-B-32')
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨ `glob` éå†æˆ‘ä»¬çš„æ•°æ®é›†ç›®å½•ï¼Œé€šè¿‡ `PIL Image.open` æ‰“å¼€æ¯ä¸ªå›¾åƒï¼Œå¹¶ä½¿ç”¨ `CLIP model.encode` ä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆä¸€ä¸ªåµŒå…¥å‘é‡ã€‚å®ƒå°†è¿”å›ä¸€ä¸ªåµŒå…¥å‘é‡åˆ—è¡¨å’Œæˆ‘ä»¬å›¾åƒæ•°æ®é›†è·¯å¾„çš„åˆ—è¡¨ï¼š

```py
def generate_clip_embeddings(images_path, model):

    image_paths = glob(os.path.join(images_path, '**/*.jpg'), recursive=True)

    embeddings = []
    for img_path in image_paths:
        image = Image.open(img_path)
        embedding = model.encode(image)
        embeddings.append(embedding)

    return embeddings, image_paths

IMAGES_PATH = '/path/to/images/dataset'

embeddings, image_paths = generate_clip_embeddings(IMAGES_PATH, model)
```

## **ç¬¬ 3 æ­¥ â€” ç”Ÿæˆ FAISS ç´¢å¼•**

ä¸‹ä¸€æ­¥æ˜¯ä»åµŒå…¥å‘é‡åˆ—è¡¨åˆ›å»º FAISS ç´¢å¼•ã€‚FAISS æä¾›äº†å¤šç§è·ç¦»åº¦é‡æ–¹æ³•æ¥è¿›è¡Œç›¸ä¼¼åº¦æœç´¢ï¼ŒåŒ…æ‹¬å†…ç§¯ï¼ˆIPï¼‰å’Œ L2ï¼ˆæ¬§å‡ é‡Œå¾—ï¼‰è·ç¦»ã€‚

FAISS è¿˜æä¾›äº†å¤šç§ç´¢å¼•é€‰é¡¹ã€‚å®ƒå¯ä»¥ä½¿ç”¨è¿‘ä¼¼æˆ–å‹ç¼©æŠ€æœ¯é«˜æ•ˆåœ°å¤„ç†å¤§æ•°æ®é›†ï¼ŒåŒæ—¶å¹³è¡¡æœç´¢é€Ÿåº¦å’Œç²¾åº¦ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨â€œFlatâ€ç´¢å¼•ï¼Œå®ƒé€šè¿‡å°†æŸ¥è¯¢å‘é‡ä¸æ•°æ®é›†ä¸­çš„æ¯ä¸ªå‘é‡è¿›è¡Œæ¯”è¾ƒæ¥æ‰§è¡Œæš´åŠ›æœç´¢ï¼Œç¡®ä¿ç²¾ç¡®ç»“æœï¼Œä½†ä»£ä»·æ˜¯æ›´é«˜çš„è®¡ç®—å¤æ‚åº¦ã€‚

```py
def create_faiss_index(embeddings, image_paths, output_path):

    dimension = len(embeddings[0])
    index = faiss.IndexFlatIP(dimension)
    index = faiss.IndexIDMap(index)

    vectors = np.array(embeddings).astype(np.float32)

    # Add vectors to the index with IDs
    index.add_with_ids(vectors, np.array(range(len(embeddings))))

    # Save the index
    faiss.write_index(index, output_path)
    print(f"Index created and saved to {output_path}")

    # Save image paths
    with open(output_path + '.paths', 'w') as f:
        for img_path in image_paths:
            f.write(img_path + '\n')

    return index

OUTPUT_INDEX_PATH = "/content/vector.index"
index = create_faiss_index(embeddings, image_paths, OUTPUT_INDEX_PATH)
```

`faiss.IndexFlatIP` åˆå§‹åŒ–ä¸€ä¸ªç”¨äºå†…ç§¯ç›¸ä¼¼åº¦çš„ç´¢å¼•ï¼Œå°è£…åœ¨ `faiss.IndexIDMap` ä¸­ï¼Œå°†æ¯ä¸ªå‘é‡ä¸ä¸€ä¸ª ID å…³è”ã€‚æ¥ä¸‹æ¥ï¼Œ`index.add_with_ids` å°†å‘é‡æ·»åŠ åˆ°ç´¢å¼•ä¸­ï¼Œå¹¶åˆ†é…é¡ºåº IDï¼Œç´¢å¼•è¿åŒå›¾åƒè·¯å¾„ä¸€èµ·ä¿å­˜åˆ°ç£ç›˜ã€‚

ç´¢å¼•å¯ä»¥ç«‹å³ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ä¿å­˜åˆ°ç£ç›˜ä»¥ä¾›å°†æ¥ä½¿ç”¨ã€‚è¦åŠ è½½ FAISS ç´¢å¼•ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹å‡½æ•°ï¼š

```py
def load_faiss_index(index_path):
    index = faiss.read_index(index_path)
    with open(index_path + '.paths', 'r') as f:
        image_paths = [line.strip() for line in f]
    print(f"Index loaded from {index_path}")
    return index, image_paths

index, image_paths = load_faiss_index(OUTPUT_INDEX_PATH)
```

## **ç¬¬ 4 æ­¥ â€” é€šè¿‡æ–‡æœ¬æŸ¥è¯¢æˆ–å‚è€ƒå›¾åƒæ£€ç´¢å›¾åƒ**

åœ¨æ„å»ºå¥½ FAISS ç´¢å¼•åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨æ–‡æœ¬æŸ¥è¯¢æˆ–å‚è€ƒå›¾åƒæ¥æ£€ç´¢å›¾åƒã€‚å¦‚æœæŸ¥è¯¢æ˜¯å›¾åƒè·¯å¾„ï¼Œåˆ™é€šè¿‡ `PIL Image.open` æ‰“å¼€æŸ¥è¯¢ã€‚æ¥ç€ï¼Œé€šè¿‡ `CLIP model.encode` æå–æŸ¥è¯¢çš„åµŒå…¥å‘é‡ã€‚

```py
def retrieve_similar_images(query, model, index, image_paths, top_k=3):

    # query preprocess:
    if query.endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):
        query = Image.open(query)

    query_features = model.encode(query)
    query_features = query_features.astype(np.float32).reshape(1, -1)

    distances, indices = index.search(query_features, top_k)

    retrieved_images = [image_paths[int(idx)] for idx in indices[0]]

    return query, retrieved_images
```

æ£€ç´¢å‘ç”Ÿåœ¨`index.search`æ–¹æ³•ä¸­ã€‚å®ƒå®ç°äº† k è¿‘é‚»ï¼ˆkNNï¼‰æœç´¢ï¼Œç”¨äºæŸ¥æ‰¾ä¸æŸ¥è¯¢å‘é‡æœ€ç›¸ä¼¼çš„`k`ä¸ªå‘é‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ›´æ”¹`top_k`å‚æ•°æ¥è°ƒæ•´ k çš„å€¼ã€‚åœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼ŒkNN æœç´¢ä½¿ç”¨çš„è·ç¦»åº¦é‡æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦ã€‚è¯¥å‡½æ•°è¿”å›æŸ¥è¯¢å’Œä¸€ç³»åˆ—è·å–çš„å›¾ç‰‡è·¯å¾„ã€‚

**ä½¿ç”¨æ–‡æœ¬æŸ¥è¯¢è¿›è¡Œæœç´¢ï¼š**

ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½æ£€æŸ¥æœç´¢ç»“æœäº†ã€‚è¾…åŠ©å‡½æ•°`visualize_results`å±•ç¤ºäº†è¿™äº›ç»“æœã€‚ä½ å¯ä»¥åœ¨å…³è”çš„ Colab ç¬”è®°æœ¬ä¸­æ‰¾åˆ°å®ƒã€‚è®©æˆ‘ä»¬ä»¥æ–‡æœ¬æŸ¥è¯¢â€œballâ€ä¸ºä¾‹ï¼Œæ¢ç´¢è·å–çš„ä¸‰ä¸ªæœ€ç›¸ä¼¼çš„å›¾ç‰‡ï¼š

```py
query = 'ball'
query, retrieved_images = retrieve_similar_images(query, model, index, image_paths, top_k=3)
visualize_results(query, retrieved_images)
```

![](img/0982e9cc9e59715d51147782f62d60f5.png)

ä½¿ç”¨æŸ¥è¯¢â€œa ballâ€è·å–çš„å›¾ç‰‡

å¯¹äºæŸ¥è¯¢â€œanimalâ€ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ï¼š

![](img/6beffd16ea96ed9928100a9d117bcb0d.png)

ä½¿ç”¨æŸ¥è¯¢â€œanimalâ€è·å–çš„å›¾ç‰‡

**ä½¿ç”¨å‚è€ƒå›¾ç‰‡è¿›è¡Œæœç´¢ï¼š**

```py
query ='/content/drive/MyDrive/Colab Notebooks/my_medium_projects/Image_similarity_search/image_dataset/pexels-w-w-299285-889839.jpg'
query, retrieved_images = retrieve_similar_images(query, model, index, image_paths, top_k=3)
visualize_results(query, retrieved_images)
```

![](img/015aeddcd340d75270dd41904b56d11d.png)

æŸ¥è¯¢å’Œè·å–çš„å›¾ç‰‡

æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬å¯¹ç°æˆçš„é¢„è®­ç»ƒæ¨¡å‹å¾—åˆ°äº†ç›¸å½“ä¸é”™çš„ç»“æœã€‚å½“æˆ‘ä»¬ç”¨ä¸€å¹…çœ¼ç›ç”»ä½œä¸ºå‚è€ƒå›¾ç‰‡è¿›è¡Œæœç´¢æ—¶ï¼Œé™¤äº†æ‰¾åˆ°åŸå§‹å›¾ç‰‡å¤–ï¼Œè¿˜æ‰¾åˆ°äº†ä¸€å¼ çœ¼é•œå’Œä¸€å¼ ä¸åŒç”»ä½œçš„åŒ¹é…ã€‚è¿™å±•ç¤ºäº†æŸ¥è¯¢å›¾ç‰‡çš„è¯­ä¹‰å«ä¹‰çš„ä¸åŒæ–¹é¢ã€‚

ä½ å¯ä»¥åœ¨æä¾›çš„ Colab ç¬”è®°æœ¬ä¸­å°è¯•å…¶ä»–æŸ¥è¯¢ï¼ŒæŸ¥çœ‹æ¨¡å‹åœ¨ä¸åŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥ä¸‹çš„è¡¨ç°ã€‚

# ç»“è¯­

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ CLIP å’Œ FAISS æ„å»ºäº†ä¸€ä¸ªåŸºæœ¬çš„å›¾åƒç›¸ä¼¼æ€§æœç´¢å¼•æ“ã€‚è·å–çš„å›¾ç‰‡ä¸æŸ¥è¯¢å…·æœ‰ç›¸ä¼¼çš„è¯­ä¹‰å«ä¹‰ï¼Œè¡¨æ˜è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å°½ç®¡ CLIP å¯¹é›¶æ ·æœ¬æ¨¡å‹æ˜¾ç¤ºå‡ºä¸é”™çš„ç»“æœï¼Œä½†å®ƒå¯èƒ½åœ¨åˆ†å¸ƒå¤–æ•°æ®ã€ç»†ç²’åº¦ä»»åŠ¡ä¸­è¡¨ç°è¾ƒå·®ï¼Œå¹¶ä¸”ç»§æ‰¿äº†å®ƒæ‰€è®­ç»ƒæ•°æ®çš„è‡ªç„¶åå·®ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œä½ å¯ä»¥å°è¯•ä½¿ç”¨å…¶ä»–ç±»ä¼¼ CLIP çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¦‚åœ¨[OpenClip](https://github.com/mlfoundations/open_clip/tree/main)ä¸­ï¼Œæˆ–è€…åœ¨ä½ è‡ªå·±çš„å®šåˆ¶æ•°æ®é›†ä¸Šå¾®è°ƒ CLIPã€‚

# æ„Ÿè°¢é˜…è¯»ï¼

æ­å–œä½ ä¸€è·¯èµ°åˆ°äº†è¿™é‡Œã€‚ç‚¹å‡»ğŸ‘è¡¨ç¤ºæ„Ÿè°¢ï¼Œæå‡ç®—æ³•çš„è‡ªå°Šå¿ƒğŸ¤“

**æƒ³äº†è§£æ›´å¤šï¼Ÿ**

+   [**æ¢ç´¢**](https://medium.com/@lihigurarie)æˆ‘å†™çš„å…¶ä»–æ–‡ç« 

+   [**è®¢é˜…**](https://medium.com/@lihigurarie/subscribe)ä»¥ä¾¿åœ¨æˆ‘å‘å¸ƒæ–‡ç« æ—¶è·å¾—é€šçŸ¥

+   åœ¨[**Linkedin**](https://www.linkedin.com/in/lihi-gur-arie/)ä¸Šå…³æ³¨æˆ‘

# å®Œæ•´ä»£ç ä½œä¸º Colab ç¬”è®°æœ¬ï¼š

Colab ç¬”è®°æœ¬[é“¾æ¥](https://gist.github.com/Lihi-Gur-Arie/7cac63dbffde55449d2444e402d87bfc)
