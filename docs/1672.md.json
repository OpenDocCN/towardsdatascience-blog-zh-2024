["```py\npip install ultralytics\npip install supervision\npip install opencv-python\n```", "```py\n#**********************************LIBRARIES*********************************#\nfrom ultralytics import YOLO\nimport supervision as sv\nimport pickle\nimport os\nimport cv2\n\n# INPUT-video file\nvideo_path = 'D:/PYTHON/video_input.mp4'\n# OUTPUT-Video File\noutput_video_path = 'D:/PYTHON/output_video.mp4'\n# PICKLE FILE (IF AVAILABLE LOADS IT IF NOT, SAVES IT IN THIS PATH)\npickle_path = 'D:/PYTHON/stubs/track_stubs.pkl'\n```", "```py\n#*********************************TRACKING MECHANISM**************************#\nclass HockeyAnalyzer:\n    def __init__(self, model_path):\n        self.model = YOLO(model_path) \n        self.tracker = sv.ByteTrack()\n\n    def detect_frames(self, frames):\n        batch_size = 20 \n        detections = [] \n        for i in range(0, len(frames), batch_size):\n            detections_batch = self.model.predict(frames[i:i+batch_size], conf=0.1)\n            detections += detections_batch\n        return detections\n\n#********LOAD TRACKS FROM FILE OR DETECT OBJECTS-SAVES PICKLE FILE************#\n\n    def get_object_tracks(self, frames, read_from_stub=False, stub_path=None):\n        if read_from_stub and stub_path is not None and os.path.exists(stub_path):\n            with open(stub_path, 'rb') as f:\n                tracks = pickle.load(f)\n            return tracks\n\n        detections = self.detect_frames(frames)\n\n        tracks = {\"person\": []}\n\n        for frame_num, detection in enumerate(detections):\n            cls_names = detection.names\n            cls_names_inv = {v: k for k, v in cls_names.items()}\n\n            # Tracking Mechanism\n            detection_supervision = sv.Detections.from_ultralytics(detection)\n            detection_with_tracks = self.tracker.update_with_detections(detection_supervision)\n            tracks[\"person\"].append({})\n\n            for frame_detection in detection_with_tracks:\n                bbox = frame_detection[0].tolist()\n                cls_id = frame_detection[3]\n                track_id = frame_detection[4]\n\n                if cls_id == cls_names_inv.get('person', None):\n                    tracks[\"person\"][frame_num][track_id] = {\"bbox\": bbox}\n\n            for frame_detection in detection_supervision:\n                bbox = frame_detection[0].tolist()\n                cls_id = frame_detection[3]\n\n        if stub_path is not None:\n            with open(stub_path, 'wb') as f:\n                pickle.dump(tracks, f)\n\n        return tracks\n\n#***********************BOUNDING BOXES AND TRACK-IDs**************************#\n\n    def draw_annotations(self, video_frames, tracks):\n        output_video_frames = []\n        for frame_num, frame in enumerate(video_frames):\n            frame = frame.copy() \n            player_dict = tracks[\"person\"][frame_num]\n\n            # Draw Players\n            for track_id, player in player_dict.items():\n                color = player.get(\"team_color\", (0, 0, 255))  \n                bbox = player[\"bbox\"]\n                x1, y1, x2, y2 = map(int, bbox)         \n            # Bounding boxes\n                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n            # Track_id \n                cv2.putText(frame, str(track_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n\n            output_video_frames.append(frame)\n\n        return output_video_frames\n```", "```py\n#*************** EXECUTES TRACKING MECHANISM AND OUTPUT VIDEO****************#\n\n# Read the video frames\nvideo_frames = []\ncap = cv2.VideoCapture(video_path)\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    video_frames.append(frame)\ncap.release()\n\n#********************* EXECUTE TRACKING METHOD WITH YOLO**********************#\ntracker = HockeyAnalyzer('D:/PYTHON/yolov8x.pt')\ntracks = tracker.get_object_tracks(video_frames, read_from_stub=True, stub_path=pickle_path)\nannotated_frames = tracker.draw_annotations(video_frames, tracks)\n\n#*********************** SAVES VIDEO FILE ************************************#\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nheight, width, _ = annotated_frames[0].shape\nout = cv2.VideoWriter(output_video_path, fourcc, 30, (width, height))\n\nfor frame in annotated_frames:\n    out.write(frame)\nout.release()\n```", "```py\n#************ Design of Ellipse for tracking players instead of Bounding boxes**************#\n\n    def draw_ellipse(self, frame, bbox, color, track_id=None, team=None):\n        y2 = int(bbox[3])\n        x_center = (int(bbox[0]) + int(bbox[2])) // 2\n        width = int(bbox[2]) - int(bbox[0])\n        color = (255, 0, 0)\n        text_color = (255, 255, 255)\n\n        cv2.ellipse(\n            frame,\n            center=(x_center, y2),\n            axes=(int(width) // 2, int(0.35 * width)),\n            angle=0.0,\n            startAngle=-45,\n            endAngle=235,\n            color=color,\n            thickness=2,\n            lineType=cv2.LINE_4\n        )\n\n        if track_id is not None:\n            rectangle_width = 40\n            rectangle_height = 20\n            x1_rect = x_center - rectangle_width // 2\n            x2_rect = x_center + rectangle_width // 2\n            y1_rect = (y2 - rectangle_height // 2) + 15\n            y2_rect = (y2 + rectangle_height // 2) + 15\n\n            cv2.rectangle(frame,\n                          (int(x1_rect), int(y1_rect)),\n                          (int(x2_rect), int(y2_rect)),\n                          color,\n                          cv2.FILLED)\n\n            x1_text = x1_rect + 12\n            if track_id > 99:\n                x1_text -= 10\n            font_scale = 0.4\n            cv2.putText(\n                frame,\n                f\"{track_id}\",\n                (int(x1_text), int(y1_rect + 15)),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                font_scale,\n                text_color,\n                thickness=2\n            )\n\n        return frame\n```", "```py\n#***********************BOUNDING BOXES AND TRACK-IDs**************************#\n\n    def draw_annotations(self, video_frames, tracks):\n        output_video_frames = []\n        for frame_num, frame in enumerate(video_frames):\n            frame = frame.copy() \n            player_dict = tracks[\"person\"][frame_num]\n\n            # Draw Players\n            for track_id, player in player_dict.items():\n                bbox = player[\"bbox\"]\n\n            # Draw ellipse and tracking IDs\n                self.draw_ellipse(frame, bbox, (0, 255, 0), track_id)\n\n                x1, y1, x2, y2 = map(int, bbox)\n\n            output_video_frames.append(frame)\n\n        return output_video_frames\n```", "```py\n#********************* Border Definition for Frame***********************\nimport cv2\n\nvideo_path = 'D:/PYTHON/video_input.mp4'\ncap = cv2.VideoCapture(video_path)\n\n#**************Read, Define and Draw corners of the frame****************\nret, frame = cap.read()\n\nbottom_left = (0, 720)\nbottom_right = (1280, 720)\nupper_left = (0, 0)\nupper_right = (1280, 0)\n\ncv2.line(frame, bottom_left, bottom_right, (0, 255, 0), 2)\ncv2.line(frame, bottom_left, upper_left, (0, 255, 0), 2)\ncv2.line(frame, bottom_right, upper_right, (0, 255, 0), 2)\ncv2.line(frame, upper_left, upper_right, (0, 255, 0), 2)\n\n#*******************Save the frame with marked corners*********************\noutput_image_path = 'rink_area_marked_VALIDATION.png'\ncv2.imwrite(output_image_path, frame)\nprint(\"Rink area saved:\", output_image_path)\n```", "```py\n#**************YELLOW TEAM OFFENSIVE ZONE****************\nBottom Left Corner: (-450, 710)\nBottom Right Corner: (2030, 710)\nUpper Left Corner: (200, 150)\nUpper Right Corner: (1160, 150)\n\n#**************WHITE TEAM OFFENSIVE ZONE****************\nBottom Left Corner: (180, 150)\nBottom Right Corner: (1100, 150)\nUpper Left Corner: (352, 61)\nUpper Right Corner: (900, 61)\n```", "```py\npip install torch torchvision \npip install matplotlib \npip install scikit-learn\n```", "```py\n# ************CONVOLUTIONAL NEURAL NETWORK-THREE CLASSES DETECTION**************************\n# REFEREE\n# WHITE TEAM (Team_away)\n# YELLOW TEAM (Team_home)\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\n\n#Training and Validation Datasets\n#Download the teams_sample_dataset file from the project's GitHub repository\ndata_dir = 'D:/PYTHON/teams_sample_dataset' \n```", "```py\n#******************************Data transformation***********************************\ntransform = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Load dataset\ntrain_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\nval_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n```", "```py\n#********************************CNN Model Architecture**************************************\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 3)  #Three Classes (Referee, Team_away,Team_home)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 18 * 18)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)  \n        return x\n```", "```py\n#********************************CNN TRAINING**********************************************\n\n# Model-loss function-optimizer\nmodel = CNNModel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n#*********************************Training*************************************************\nnum_epochs = 10\ntrain_losses, val_losses = [], []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        labels = labels.type(torch.LongTensor)  \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    train_losses.append(running_loss / len(train_loader))\n\n    model.eval()\n    val_loss = 0.0\n    all_labels = []\n    all_preds = []\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            outputs = model(inputs)\n            labels = labels.type(torch.LongTensor)  \n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)  \n            all_labels.extend(labels.tolist())\n            all_preds.extend(preds.tolist())\n```", "```py\n#********************************METRICS & PERFORMANCE************************************\n\n    val_losses.append(val_loss / len(val_loader))\n    val_accuracy = accuracy_score(all_labels, all_preds)\n    val_precision = precision_score(all_labels, all_preds, average='macro', zero_division=1)\n    val_recall = recall_score(all_labels, all_preds, average='macro', zero_division=1)\n    val_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=1)\n\n    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n          f\"Loss: {train_losses[-1]:.4f}, \"\n          f\"Val Loss: {val_losses[-1]:.4f}, \"\n          f\"Val Acc: {val_accuracy:.2%}, \"\n          f\"Val Precision: {val_precision:.4f}, \"\n          f\"Val Recall: {val_recall:.4f}, \"\n          f\"Val F1 Score: {val_f1:.4f}\")\n\n#*******************************SHOW METRICS & PERFORMANCE**********************************\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.legend()\nplt.show()\n\n# SAVE THE MODEL FOR THE GH_CV_track_teams CODE\ntorch.save(model.state_dict(), 'D:/PYTHON/hockey_team_classifier.pth')\n```", "```py\n#**************CNN PERFORMANCE ACROSS TRAINING EPOCHS************************\n\nEpoch [1/10], Loss: 1.5346, Val Loss: 1.2339, Val Acc: 47.37%, Val Precision: 0.7172, Val Recall: 0.5641, Val F1 Score: 0.4167\nEpoch [2/10], Loss: 1.1473, Val Loss: 1.1664, Val Acc: 55.26%, Val Precision: 0.6965, Val Recall: 0.6296, Val F1 Score: 0.4600\nEpoch [3/10], Loss: 1.0139, Val Loss: 0.9512, Val Acc: 57.89%, Val Precision: 0.6054, Val Recall: 0.6054, Val F1 Score: 0.5909\nEpoch [4/10], Loss: 0.8937, Val Loss: 0.8242, Val Acc: 60.53%, Val Precision: 0.7222, Val Recall: 0.5645, Val F1 Score: 0.5538\nEpoch [5/10], Loss: 0.7936, Val Loss: 0.7177, Val Acc: 63.16%, Val Precision: 0.6667, Val Recall: 0.6309, Val F1 Score: 0.6419\nEpoch [6/10], Loss: 0.6871, Val Loss: 0.7782, Val Acc: 68.42%, Val Precision: 0.6936, Val Recall: 0.7128, Val F1 Score: 0.6781\nEpoch [7/10], Loss: 0.6276, Val Loss: 0.5684, Val Acc: 78.95%, Val Precision: 0.8449, Val Recall: 0.7523, Val F1 Score: 0.7589\nEpoch [8/10], Loss: 0.4198, Val Loss: 0.5613, Val Acc: 86.84%, Val Precision: 0.8736, Val Recall: 0.8958, Val F1 Score: 0.8653\nEpoch [9/10], Loss: 0.3959, Val Loss: 0.3824, Val Acc: 92.11%, Val Precision: 0.9333, Val Recall: 0.9213, Val F1 Score: 0.9243\nEpoch [10/10], Loss: 0.2509, Val Loss: 0.2651, Val Acc: 97.37%, Val Precision: 0.9762, Val Recall: 0.9792, Val F1 Score: 0.9769 \n```", "```py\n# *************TEST CNN MODEL WITH SAMPLE DATASET***************************\n\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# SAMPLE DATASET FOR VALIDATION\ntest_dir = 'D:/PYTHON/validation_dataset'\n\n# CNN MODEL FOR TEAM PREDICTIONS\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, 3) \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 18 * 18)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)  \n        return x\n\n# CNN MODEL PREVIOUSLY SAVED\nmodel = CNNModel()\nmodel.load_state_dict(torch.load('D:/PYTHON/hockey_team_classifier.pth'))\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n#******************ITERATION ON SAMPLE IMAGES-ACCURACY TEST*****************************\n\nclass_names = ['team_referee', 'team_away', 'team_home']\n\ndef predict_image(image_path, model, transform):\n# LOADS DATASET\n    image = Image.open(image_path)\n    image = transform(image).unsqueeze(0)  \n\n# MAKES PREDICTIONS\n    with torch.no_grad():\n        output = model(image)\n        _, predicted = torch.max(output, 1)  \n        team = class_names[predicted.item()]\n    return team\n\nfor image_name in os.listdir(test_dir):\n    image_path = os.path.join(test_dir, image_name)\n    if os.path.isfile(image_path):  \n        predicted_team = predict_image(image_path, model, transform)\n        print(f'Image {image_name}: The player belongs to {predicted_team}')\n```", "```py\n # *************CNN MODEL TEST - OUTPUT ***********************************#\n\nImage Away_image04.jpg: The player belongs to team_away\nImage Away_image12.jpg: The player belongs to team_away\nImage Away_image14.jpg: The player belongs to team_away\nImage Home_image07.jpg: The player belongs to team_home\nImage Home_image13.jpg: The player belongs to team_home\nImage Home_image16.jpg: The player belongs to team_home\nImage Referee_image04.jpg: The player belongs to team_referee\nImage Referee_image09.jpg: The player belongs to team_referee\nImage Referee_image10.jpg: The player belongs to team_referee\nImage Referee_image11.jpg: The player belongs to team_referee\n```", "```py\n import cv2\nimport numpy as np\nfrom ultralytics import YOLO\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# MODEL INPUTS\nmodel_path = 'D:/PYTHON/yolov8x.pt'\nvideo_path = 'D:/PYTHON/video_input.mp4'\noutput_path = 'D:/PYTHON/output_video.mp4'\ntracks_path = 'D:/PYTHON/stubs/track_stubs.pkl'\nclassifier_path = 'D:/PYTHON/hockey_team_classifier.pth'\n```", "```py\n #*************************** Loads models and rink coordinates********************#\nclass_names = ['Referee', 'Tm_white', 'Tm_yellow']\n\nclass HockeyAnalyzer:\n    def __init__(self, model_path, classifier_path):\n        self.model = YOLO(model_path)\n        self.classifier = self.load_classifier(classifier_path)\n        self.transform = transforms.Compose([\n            transforms.Resize((150, 150)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n        self.rink_coordinates = np.array([[-450, 710], [2030, 710], [948, 61], [352, 61]])\n        self.zone_white = [(180, 150), (1100, 150), (900, 61), (352, 61)]\n        self.zone_yellow = [(-450, 710), (2030, 710), (1160, 150), (200, 150)]\n\n#******************** Detect objects in each frame **********************************#\n    def detect_frames(self, frames):\n        batch_size = 20 \n        detections = [] \n        for i in range(0, len(frames), batch_size):\n            detections_batch = self.model.predict(frames[i:i+batch_size], conf=0.1)\n            detections += detections_batch\n        return detections\n```", "```py\n#*********************** Loads CNN Model**********************************************#\n\n    def load_classifier(self, classifier_path):\n        model = CNNModel()\n        model.load_state_dict(torch.load(classifier_path, map_location=torch.device('cpu')))\n        model.eval()\n        return model\n\n    def predict_team(self, image):\n        with torch.no_grad():\n            output = self.classifier(image)\n            _, predicted = torch.max(output, 1)\n            predicted_index = predicted.item()\n            team = class_names[predicted_index]\n        return team\n```", "```py\n#************ Ellipse for tracking players instead of Bounding boxes*******************#\n    def draw_ellipse(self, frame, bbox, color, track_id=None, team=None):\n        y2 = int(bbox[3])\n        x_center = (int(bbox[0]) + int(bbox[2])) // 2\n        width = int(bbox[2]) - int(bbox[0])\n\n        if team == 'Referee':\n            color = (0, 255, 255)\n            text_color = (0, 0, 0)\n        else:\n            color = (255, 0, 0)\n            text_color = (255, 255, 255)\n\n        cv2.ellipse(\n            frame,\n            center=(x_center, y2),\n            axes=(int(width) // 2, int(0.35 * width)),\n            angle=0.0,\n            startAngle=-45,\n            endAngle=235,\n            color=color,\n            thickness=2,\n            lineType=cv2.LINE_4\n        )\n\n        if track_id is not None:\n            rectangle_width = 40\n            rectangle_height = 20\n            x1_rect = x_center - rectangle_width // 2\n            x2_rect = x_center + rectangle_width // 2\n            y1_rect = (y2 - rectangle_height // 2) + 15\n            y2_rect = (y2 + rectangle_height // 2) + 15\n\n            cv2.rectangle(frame,\n                          (int(x1_rect), int(y1_rect)),\n                          (int(x2_rect), int(y2_rect)),\n                          color,\n                          cv2.FILLED)\n\n            x1_text = x1_rect + 12\n            if track_id > 99:\n                x1_text -= 10\n            font_scale = 0.4\n            cv2.putText(\n                frame,\n                f\"{track_id}\",\n                (int(x1_text), int(y1_rect + 15)),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                font_scale,\n                text_color,\n                thickness=2\n            )\n\n        return frame\n```", "```py\n#******************* Loads Tracked Data (pickle file )**********************************#\n\n    def analyze_video(self, video_path, output_path, tracks_path):\n          with open(tracks_path, 'rb') as f:\n              tracks = pickle.load(f)\n\n          cap = cv2.VideoCapture(video_path)\n          if not cap.isOpened():\n              print(\"Error: Could not open video.\")\n              return\n\n          fps = cap.get(cv2.CAP_PROP_FPS)\n          frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n          frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n          fourcc = cv2.VideoWriter_fourcc(*'XVID')\n          out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\n          frame_num = 0\n          while cap.isOpened():\n              ret, frame = cap.read()\n              if not ret:\n                  break\n\n#***********Checks if the player falls within the rink area**********************************#\n              mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n              cv2.fillConvexPoly(mask, self.rink_coordinates, 1)\n              mask = mask.astype(bool)\n              # Draw rink area\n              #cv2.polylines(frame, [self.rink_coordinates], isClosed=True, color=(0, 255, 0), thickness=2)\n\n              # Get tracks from frame\n              player_dict = tracks[\"person\"][frame_num]\n              for track_id, player in player_dict.items():\n                  bbox = player[\"bbox\"]\n\n              # Check if the player is within the Rink Area\n                  x_center = int((bbox[0] + bbox[2]) / 2)\n                  y_center = int((bbox[1] + bbox[3]) / 2)\n\n                  if not mask[y_center, x_center]:\n                      continue  \n\n#**********************************Team Prediction********************************************#\n                  x1, y1, x2, y2 = map(int, bbox)\n                  cropped_image = frame[y1:y2, x1:x2]\n                  cropped_pil_image = Image.fromarray(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n                  transformed_image = self.transform(cropped_pil_image).unsqueeze(0)\n                  team = self.predict_team(transformed_image)\n\n#************ Ellipse for tracked players and labels******************************************#\n                  self.draw_ellipse(frame, bbox, (0, 255, 0), track_id, team)\n\n                  font_scale = 1  \n                  text_offset = -20  \n\n                  if team == 'Referee':\n                      rectangle_width = 60\n                      rectangle_height = 25\n                      x1_rect = x1\n                      x2_rect = x1 + rectangle_width\n                      y1_rect = y1 - 30\n                      y2_rect = y1 - 5\n                      # Different setup for Referee\n                      cv2.rectangle(frame,\n                                    (int(x1_rect), int(y1_rect)),\n                                    (int(x2_rect), int(y2_rect)),\n                                    (0, 0, 0),  \n                                    cv2.FILLED)\n                      text_color = (255, 255, 255)  \n                  else:\n                      if team == 'Tm_white':\n                          text_color = (255, 215, 0)  # White Team: Blue labels\n                      else:\n                          text_color = (0, 255, 255)  # Yellow Team: Yellow labels\n\n              # Draw Team labels\n                  cv2.putText(\n                      frame,\n                      team,\n                      (int(x1), int(y1) + text_offset), \n                      cv2.FONT_HERSHEY_PLAIN,            \n                      font_scale,\n                      text_color,\n                      thickness=2\n                  )\n\n              # Write output video\n              out.write(frame)\n              frame_num += 1\n\n          cap.release()\n          out.release()\n```", "```py\n #**********************CNN Model Architecture ******************************#\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(512, len(class_names))  \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 18 * 18)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n#*********Execute HockeyAnalyzer/classifier and Save Output************#\nanalyzer = HockeyAnalyzer(model_path, classifier_path)\nanalyzer.analyze_video(video_path, output_path, tracks_path)\n```", "```py\n#*********************Loads models and rink coordinates*****************#\nclass_names = ['Referee', 'Tm_white', 'Tm_yellow']\n\nclass HockeyAnalyzer:\n    def __init__(self, model_path, classifier_path):\n        *\n        *\n        *\n        *\n        *\n        *\n        self.pixel_to_meter_conversion() #<------ Add this utility method\n\n#***********Pixel-based measurements to meters***************************#\n    def pixel_to_meter_conversion(self):\n        #Rink real dimensions in meters\n        rink_width_m = 15\n        rink_height_m = 30\n\n        #Pixel coordinates for rink dimensions\n        left_pixel, right_pixel = self.rink_coordinates[0][0], self.rink_coordinates[1][0]\n        top_pixel, bottom_pixel = self.rink_coordinates[2][1], self.rink_coordinates[0][1]\n\n        #Conversion factors\n        self.pixels_per_meter_x = (right_pixel - left_pixel) / rink_width_m\n        self.pixels_per_meter_y = (bottom_pixel - top_pixel) / rink_height_m\n\n    def convert_pixels_to_meters(self, distance_pixels):\n        #Convert pixels to meters\n        return distance_pixels / self.pixels_per_meter_x, distance_pixels / self.pixels_per_meter_y\n```", "```py\n#*********************Loads models and rink coordinates*****************#\nclass_names = ['Referee', 'Tm_white', 'Tm_yellow']\n\nclass HockeyAnalyzer:\n    def __init__(self, model_path, classifier_path):\n        *\n        *\n        *\n        *\n        *\n        *\n        *\n        self.pixel_to_meter_conversion() \n        self.previous_positions = {} #<------ Add this.Initializes empty dictionary \n        self.team_stats = {\n                    'Tm_white': {'distance': 0, 'speed': [], 'count': 0, 'offensive_pressure': 0},\n                    'Tm_yellow': {'distance': 0, 'speed': [], 'count': 0, 'offensive_pressure': 0}\n                } #<------ Add this.Initializes empty dictionary\n\n#**************** Speed: meters per second********************************#\n    def calculate_speed(self, track_id, x_center, y_center, fps):\n        current_position = (x_center, y_center)\n        if track_id in self.previous_positions:\n            prev_position = self.previous_positions[track_id]\n            distance_pixels = np.linalg.norm(np.array(current_position) - np.array(prev_position))\n            distance_meters_x, distance_meters_y = self.convert_pixels_to_meters(distance_pixels)\n            speed_meters_per_second = (distance_meters_x**2 + distance_meters_y**2)**0.5 * fps\n        else:\n            speed_meters_per_second = 0\n        self.previous_positions[track_id] = current_position\n        return speed_meters_per_second\n\n#******************* Loads Tracked Data (pickle file )**********************************#\n\n    def analyze_video(self, video_path, output_path, tracks_path):\n          with open(tracks_path, 'rb') as f:\n              tracks = pickle.load(f)\n\n        *\n        *\n        *\n        *\n        *\n        *\n        *\n        *\n              # Draw Team label\n                  cv2.putText(\n                      frame,\n                      team,\n                      (int(x1), int(y1) + text_offset), \n                      cv2.FONT_HERSHEY_PLAIN,            \n                      font_scale,\n                      text_color,\n                      thickness=2\n                  )\n\n#**************Add these lines of code --->:\n\n                  speed = self.calculate_speed(track_id, x_center, y_center, fps)\n                  # Speed label \n                  speed_font_scale = 0.8  \n                  speed_y_position = int(y1) + 20\n                  if speed_y_position > int(y1) - 5:\n                      speed_y_position = int(y1) - 5\n\n                  cv2.putText(\n                      frame,\n                      f\"Speed: {speed:.2f} m/s\",  \n                      (int(x1), speed_y_position),  \n                      cv2.FONT_HERSHEY_PLAIN,       \n                      speed_font_scale,\n                      text_color,\n                      thickness=2\n                  )\n\n              # Write output video\n              out.write(frame)\n              frame_num += 1\n\n          cap.release()\n          out.release()\n```", "```py\n #************ Locate player's position in Target Zone***********************#\n\n    def is_inside_zone(self, position, zone):\n          x, y = position\n          n = len(zone)\n          inside = False\n          p1x, p1y = zone[0]\n          for i in range(n + 1):\n              p2x, p2y = zone[i % n]\n              if y > min(p1y, p2y):\n                  if y <= max(p1y, p2y):\n                      if x <= max(p1x, p2x):\n                          if p1y != p2y:\n                              xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x\n                          if p1x == p2x or x <= xinters:\n                              inside = not inside\n              p1x, p1y = p2x, p2y\n          return inside\n```", "```py\n#*******************************Performance metrics*********************************************#\n    def draw_stats(self, frame):\n         avg_speed_white = np.mean(self.team_stats['Tm_white']['speed']) if self.team_stats['Tm_white']['count'] > 0 else 0\n         avg_speed_yellow = np.mean(self.team_stats['Tm_yellow']['speed']) if self.team_stats['Tm_yellow']['count'] > 0 else 0\n         distance_white = self.team_stats['Tm_white']['distance']\n         distance_yellow = self.team_stats['Tm_yellow']['distance']\n\n         offensive_pressure_white = self.team_stats['Tm_white'].get('offensive_pressure', 0)\n         offensive_pressure_yellow = self.team_stats['Tm_yellow'].get('offensive_pressure', 0)\n\n         Pressure_ratio_W = offensive_pressure_white/distance_white   *100  if self.team_stats['Tm_white']['distance'] > 0 else 0\n         Pressure_ratio_Y = offensive_pressure_yellow/distance_yellow *100  if self.team_stats['Tm_yellow']['distance'] > 0 else 0\n\n         table = [\n             [\"\", \"Away_White\", \"Home_Yellow\"],\n             [\"Average Speed\\nPlayer\", f\"{avg_speed_white:.2f} m/s\", f\"{avg_speed_yellow:.2f} m/s\"],\n             [\"Distance\\nCovered\", f\"{distance_white:.2f} m\", f\"{distance_yellow:.2f} m\"],\n             [\"Offensive\\nPressure %\", f\"{Pressure_ratio_W:.2f} %\", f\"{Pressure_ratio_Y:.2f} %\"],\n         ]\n\n         text_color = (0, 0, 0)  \n         start_x, start_y = 10, 590  \n         row_height = 30     # Manage Height between rows\n         column_width = 150  # Manage Width  between rows\n         font_scale = 1  \n\n         def put_multiline_text(frame, text, position, font, font_scale, color, thickness, line_type, line_spacing=1.0):\n             y0, dy = position[1], int(font_scale * 20 * line_spacing)  # Adjust line spacing here\n             for i, line in enumerate(text.split('\\n')):\n                 y = y0 + i * dy\n                 cv2.putText(frame, line, (position[0], y), font, font_scale, color, thickness, line_type)\n\n         for i, row in enumerate(table):\n             for j, text in enumerate(row):\n                 if i in [1,2, 3]:  \n                     put_multiline_text(\n                         frame,\n                         text,\n                         (start_x + j * column_width, start_y + i * row_height),\n                         cv2.FONT_HERSHEY_PLAIN,\n                         font_scale,\n                         text_color,\n                         1,\n                         cv2.LINE_AA,\n                         line_spacing= 0.8 \n                     )\n                 else:\n                     cv2.putText(\n                         frame,\n                         text,\n                         (start_x + j * column_width, start_y + i * row_height),\n                         cv2.FONT_HERSHEY_PLAIN,\n                         font_scale,\n                         text_color,\n                         1,\n                         cv2.LINE_AA,\n                     )       \n\n#****************** Track and update game stats****************************************#\n\n    def update_team_stats(self, team, speed, distance, position):\n        if team in self.team_stats:\n            self.team_stats[team]['speed'].append(speed)\n            self.team_stats[team]['distance'] += distance\n            self.team_stats[team]['count'] += 1\n\n            if team == 'Tm_white':\n                if self.is_inside_zone(position, self.zone_white):\n                    self.team_stats[team]['offensive_pressure'] += distance\n            elif team == 'Tm_yellow':\n                if self.is_inside_zone(position, self.zone_yellow):\n                    self.team_stats[team]['offensive_pressure'] += distance\n```", "```py\n*\n*\n*\n*\n*\n*\n*\n#Speed label \n                  speed_font_scale = 0.8  \n                  speed_y_position = int(y1) + 20\n                  if speed_y_position > int(y1) - 5:\n                      speed_y_position = int(y1) - 5\n\n                  cv2.putText(\n                      frame,\n                      f\"Speed: {speed:.2f} m/s\",  \n                      (int(x1), speed_y_position),  \n                      cv2.FONT_HERSHEY_PLAIN,       \n                      speed_font_scale,\n                      text_color,\n                      thickness=2\n                  )\n#**************Add these lines of code--->:\n\n                  distance = speed / fps\n                  position = (x_center, y_center)\n                  self.update_team_stats(team, speed, distance, position)\n\n              # Write output video\n              out.write(frame)\n              frame_num += 1\n```"]