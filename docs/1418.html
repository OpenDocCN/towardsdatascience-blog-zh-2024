<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Automating Prompt Engineering with DSPy and Haystack</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Automating Prompt Engineering with DSPy and Haystack</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automating-prompt-engineering-with-dspy-and-haystack-926a637a3f43?source=collection_archive---------0-----------------------#2024-06-07">https://towardsdatascience.com/automating-prompt-engineering-with-dspy-and-haystack-926a637a3f43?source=collection_archive---------0-----------------------#2024-06-07</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="be3f" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Teach your LLM how to talk through examples</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@dataqa?source=post_page---byline--926a637a3f43--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Maria Mestre" class="l ep by dd de cx" src="../Images/3e2586487691b731293b1bfa091b651e.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Q9-M2SQ3bIDdOrtcXj5lGw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--926a637a3f43--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@dataqa?source=post_page---byline--926a637a3f43--------------------------------" rel="noopener follow">Maria Mestre</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--926a637a3f43--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 7, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">1</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/da9ea834c6eb33d8ee5a3ba9234bf9f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lsZP76QaylocstY_"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@markuswinkler?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Markus Winkler</a> on <a class="af nc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="60d6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">One of the most frustrating parts of building gen-AI applications is the manual process of optimising prompts. In a <a class="af nc" href="https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product" rel="noopener ugc nofollow" target="_blank">publication</a> made by LinkedIn earlier this year, they described what they learned after deploying an agentic RAG application. One of the main challenges was obtaining consistent quality. They spent 4 months tweaking various parts of the application, including prompts, to mitigate issues such as hallucination.</p><p id="0ae6" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">DSPy is an open-source library that tries to parameterise prompts so that it becomes an optimisation problem. The <a class="af nc" href="https://arxiv.org/abs/2310.03714" rel="noopener ugc nofollow" target="_blank">original paper</a> calls prompt engineering “brittle and unscalable” and compares it to “hand-tuning the weights for a classifier”.</p><p id="f28e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nc" href="https://github.com/deepset-ai/haystack" rel="noopener ugc nofollow" target="_blank">Haystack</a> is an open-source library to build LLM applications, including RAG pipelines. It is platform-agnostic and offers a large number of integrations with different LLM providers, search databases and more. It also has its own <a class="af nc" href="https://docs.haystack.deepset.ai/docs/evaluation" rel="noopener ugc nofollow" target="_blank">evaluation metrics</a>.</p><p id="e40d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In this article, we will briefly go over the internals of DSPy, and show how it can be used to teach an LLM to prefer more concise answers when answering questions over an academic medical dataset.</p><h1 id="68de" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Quick overview of DSPy</h1><p id="6477" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">This <a class="af nc" href="https://medium.com/towards-data-science/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7" rel="noopener">article</a> from TDS provides a great in-depth exploration of DSPy. We will be summarising and using some of their examples.</p><p id="3651" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In order to build a LLM application that can be optimised, DSPy offers two main abstractions: <strong class="nf fr">signatures</strong> and <strong class="nf fr">modules</strong>. A signature is a way to define the input and output of a system that interacts with LLMs. The signature is translated internally into a prompt by DSPy.</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="3b84" class="pe oa fq pb b bg pf pg l ph pi">class Emotion(dspy.Signature):<br/>   # Describe the task<br/>   """Classify emotions in a sentence."""<br/>  <br/>   sentence = dspy.InputField()<br/>   # Adding description to the output field<br/>   sentiment = dspy.OutputField(desc="Possible choices: sadness, joy, love, anger, fear, surprise.")</span></pre><p id="8c71" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When using the DSPy <code class="cx pj pk pl pb b">Predict</code> module (more on this later), this signature is turned into the following prompt:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="ee40" class="pe oa fq pb b bg pf pg l ph pi">Classify emotions in a sentence.<br/><br/>---<br/><br/>Follow the following format.<br/><br/>Sentence: ${sentence}<br/>Sentiment: Possible choices: sadness, joy, love, anger, fear, surprise.<br/><br/>---<br/><br/>Sentence:</span></pre><p id="8efb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Then, DSPy also has <strong class="nf fr">modules</strong> which define the “predictors” that have parameters that can be optimised, such as the selection of few-shot examples. The simplest module is <code class="cx pj pk pl pb b">dspy.Predict</code> which does not modify the signature. Later in this article we will use the module <code class="cx pj pk pl pb b">dspy.ChainOfThought</code> which asks the LLM to provide reasoning.</p><p id="d91c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Things start to get interesting once we try to optimise a module (or as DSPy calls it “compiling” a module). When optimising a module, you typically need to specify 3 things:</p><ul class=""><li id="f94a" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pm pn po bk">the module to be optimised,</li><li id="d84a" class="nd ne fq nf b go pp nh ni gr pq nk nl nm pr no np nq ps ns nt nu pt nw nx ny pm pn po bk">a training set, which might have labels,</li><li id="d452" class="nd ne fq nf b go pp nh ni gr pq nk nl nm pr no np nq ps ns nt nu pt nw nx ny pm pn po bk">and some evaluation metrics.</li></ul><p id="790e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">When using the <code class="cx pj pk pl pb b">dspy.Predict</code> or the <code class="cx pj pk pl pb b">dspy.ChainOfThought</code> modules, DSPy searches through the training set and selects the best examples to add to the prompt as few-shot examples. In the case of RAG, it can also include the context that was used to get the final response. It calls these examples “demonstrations”.</p><p id="af76" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You also need to specify the type of <a class="af nc" href="https://dspy-docs.vercel.app/docs/building-blocks/optimizers" rel="noopener ugc nofollow" target="_blank">optimiser</a> you want to use to search through the parameter space. In this article, we use the <code class="cx pj pk pl pb b">BootstrapFewShot</code> optimiser. How does this algorithm work internally? It is actually very simple and the paper provides some simplified pseudo-code:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="044e" class="pe oa fq pb b bg pf pg l ph pi">class SimplifiedBootstrapFewShot ( Teleprompter ) :<br/>  def __init__ ( self , metric = None ) :<br/>  self . metric = metric<br/><br/>  def compile ( self , student , trainset , teacher = None ) :<br/>    teacher = teacher if teacher is not None else student<br/>    compiled_program = student . deepcopy ()<br/><br/>    # Step 1. Prepare mappings between student and teacher Predict modules .<br/>    # Note : other modules will rely on Predict internally .<br/>    assert student_and_teacher_have_compatible_predict_modules ( student , teacher )<br/>    name2predictor , predictor2name = map_predictors_recursively ( student , teacher )<br/>    <br/>    # Step 2. Bootstrap traces for each Predict module .<br/>    # We ’ll loop over the training set . We ’ll try each example once for simplicity .<br/>    for example in trainset :<br/>      if we_found_enough_bootstrapped_demos () : break<br/>      <br/>      # turn on compiling mode which will allow us to keep track of the traces<br/>      with dspy . setting . context ( compiling = True ) :<br/>        # run the teacher program on the example , and get its final prediction<br/>        # note that compiling = True may affect the internal behavior here<br/>        prediction = teacher (** example . inputs () )<br/>        <br/>        # get the trace of the all interal Predict calls from teacher program<br/>        predicted_traces = dspy . settings . trace<br/>        <br/>      # if the prediction is valid , add the example to the traces<br/>      if self . metric ( example , prediction , predicted_traces ) :<br/>        for predictor , inputs , outputs in predicted_traces :<br/>          d = dspy . Example ( automated = True , ** inputs , ** outputs )<br/>          predictor_name = self . predictor2name [id( predictor ) ]<br/>          compiled_program [ predictor_name ]. demonstrations . append ( d )<br/>  <br/><br/> return compiled_program</span></pre><p id="9631" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The search algorithm goes through every training input in the <code class="cx pj pk pl pb b">trainset</code> , gets a prediction and then checks whether it “passes” the metric by looking at <code class="cx pj pk pl pb b">self.metric(example, prediction, predicted_traces)</code>. If the metric passes, then the examples are added to the <code class="cx pj pk pl pb b">demonstrations</code> of the compiled program.</p><h1 id="961c" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Let’s create a custom Haystack pipeline</h1><p id="756f" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">The entire code can be found in this <a class="af nc" href="https://github.com/deepset-ai/haystack-cookbook/blob/main/notebooks/prompt_optimization_with_dspy.ipynb" rel="noopener ugc nofollow" target="_blank">cookbook with associated colab</a>, so we will only go through some of the most important steps here. For the example, we use a <a class="af nc" href="https://huggingface.co/datasets/vblagoje/PubMedQA_instruction/viewer/default/train?row=0" rel="noopener ugc nofollow" target="_blank">dataset</a> derived from the <a class="af nc" href="https://github.com/pubmedqa/pubmedqa" rel="noopener ugc nofollow" target="_blank">PubMedQA dataset</a> (both under the MIT license). It has questions based on abstracts of medical research papers and their associated answers. Some of the answers provided can be quite long, so we will be using DSPy to “teach” the LLM to prefer more concise answers, while keeping the accuracy of the final answer high.</p><p id="e69c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After adding the first 1000 examples to an in-memory document store (which can be replaced by any number of <a class="af nc" href="https://docs.haystack.deepset.ai/docs/retrievers" rel="noopener ugc nofollow" target="_blank">retrievers</a>), we can now build our RAG pipeline:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="095a" class="pe oa fq pb b bg pf pg l ph pi">from haystack.components.retrievers.in_memory import InMemoryBM25Retriever<br/>from haystack.components.generators import OpenAIGenerator<br/>from haystack.components.builders import PromptBuilder<br/>from haystack import Pipeline<br/><br/><br/>retriever = InMemoryBM25Retriever(document_store, top_k=3)<br/>generator = OpenAIGenerator(model="gpt-3.5-turbo")<br/><br/>template = """<br/>Given the following information, answer the question.<br/><br/>Context:<br/>{% for document in documents %}<br/>    {{ document.content }}<br/>{% endfor %}<br/><br/>Question: {{question}}<br/>Answer:<br/>"""<br/><br/>prompt_builder = PromptBuilder(template=template)<br/><br/><br/>rag_pipeline = Pipeline()<br/>rag_pipeline.add_component("retriever", retriever)<br/>rag_pipeline.add_component("prompt_builder", prompt_builder)<br/>rag_pipeline.add_component("llm", generator)<br/><br/>rag_pipeline.connect("retriever", "prompt_builder.documents")<br/>rag_pipeline.connect("prompt_builder", "llm")</span></pre><p id="afcb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s try it out!</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="fab8" class="pe oa fq pb b bg pf pg l ph pi">question = "What effects does ketamine have on rat neural stem cells?"<br/><br/>response = rag_pipeline.run({"retriever": {"query": question}, "prompt_builder": {"question": question}})<br/><br/>print(response["llm"]["replies"][0])</span></pre><p id="0ab0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The answer to the above question:</p><blockquote class="pu pv pw"><p id="d9b4" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ketamine inhibits the proliferation of rat neural stem cells in a dose-dependent manner at concentrations of 200, 500, 800, and 1000µM. Additionally, ketamine decreases intracellular Ca(2+) concentration, suppresses protein kinase C-α (PKCα) activation, and phosphorylation of extracellular signal-regulated kinases 1/2 (ERK1/2) in rat neural stem cells. These effects do not seem to be mediated through caspase-3-dependent apoptosis.</p></blockquote><p id="80e1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We can see how the answers tend to be very detailed and long.</p><h1 id="3e08" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Use DSPy to get more concise answers</h1><p id="e767" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">We start by creating a DSPy signature of the input and output fields:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="391c" class="pe oa fq pb b bg pf pg l ph pi">class GenerateAnswer(dspy.Signature):<br/>    """Answer questions with short factoid answers."""<br/><br/>    context = dspy.InputField(desc="may contain relevant facts")<br/>    question = dspy.InputField()<br/>    answer = dspy.OutputField(desc="short and precise answer")</span></pre><p id="5ca8" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As we can see, we already specify in our description that we are expecting a short answer.</p><p id="3c21" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Then, we create a DSPy module that will be later compiled:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="bf48" class="pe oa fq pb b bg pf pg l ph pi">class RAG(dspy.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)<br/><br/>    # this makes it possible to use the Haystack retriever<br/>    def retrieve(self, question):<br/>        results = retriever.run(query=question)<br/>        passages = [res.content for res in results['documents']]<br/>        return Prediction(passages=passages)<br/><br/>    def forward(self, question):<br/>        context = self.retrieve(question).passages<br/>        prediction = self.generate_answer(context=context, question=question)<br/>        return dspy.Prediction(context=context, answer=prediction.answer)</span></pre><p id="712a" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We are using the Haystack retriever previously defined to search the documents in the document store <code class="cx pj pk pl pb b">results = retriever.run(query=question)</code>. The prediction step is done with the DSPy module <code class="cx pj pk pl pb b">dspy.ChainOfThought</code> which teaches the LM to think step-by-step before committing to the response.</p><p id="84d1" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">During compilation, the prompt that will be optimised to look like this:</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div class="mj mk py"><img src="../Images/68ebd2d7ccc8136d323e686b67686a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*gV52CWdZjekHJp6bIZNiMg.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">All the bold text is replaced by the examples selected by DSPy and the question-context for the specific query. Made by author.</figcaption></figure><p id="273f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Finally, we have to define the metrics that we would like to optimise. The evaluator will have two parts:</p><ul class=""><li id="96d9" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny pm pn po bk"><code class="cx pj pk pl pb b"><a class="af nc" href="https://docs.haystack.deepset.ai/docs/sasevaluator" rel="noopener ugc nofollow" target="_blank">SASEvaluator</a></code> : The semantic answer similarity metric is a score between 0 and 1 that computes the similarity between the given output and the actual output.</li><li id="4934" class="nd ne fq nf b go pp nh ni gr pq nk nl nm pr no np nq ps ns nt nu pt nw nx ny pm pn po bk">We will apply a penalty for answers that are longer than 20 words that will grow proportionally to the number of words up to a maximum of 0.5.</li></ul><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="1260" class="pe oa fq pb b bg pf pg l ph pi">from haystack.components.evaluators import SASEvaluator<br/><br/>sas_evaluator = SASEvaluator()<br/>sas_evaluator.warm_up()<br/><br/>def mixed_metric(example, pred, trace=None):<br/>    semantic_similarity = sas_evaluator.run(ground_truth_answers=[example.answer], predicted_answers=[pred.answer])["score"]<br/><br/>    n_words=len(pred.answer.split())<br/>    long_answer_penalty=0<br/>    if 20&lt;n_words&lt;40:<br/>      long_answer_penalty = 0.025 * (n_words - 20)<br/>    elif n_words&gt;=40:<br/>      long_answer_penalty = 0.5<br/><br/>    return semantic_similarity - long_answer_penalty</span></pre><p id="601d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Our evaluation dataset is composed of 20 training examples and 50 examples in the devset.</p><p id="4616" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">If we evaluate the current naive RAG pipeline with the code below, we get an average score of 0.49.</p><p id="ebf3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Looking at some examples can give us some intuition on what the score is doing:</p><blockquote class="pu pv pw"><p id="833f" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Question: Is increased time from neoadjuvant chemoradiation to surgery associated with higher pathologic complete response rates in esophageal cancer?</p><p id="e80e" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Predicted answer: Yes, increased time from neoadjuvant chemoradiation to surgery is associated with higher pathologic complete response rates in esophageal cancer.</p><p id="97e1" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Score: 0.78</strong></p></blockquote><p id="00d5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">But</p><blockquote class="pu pv pw"><p id="52bb" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Question: Is epileptic focus localization based on resting state interictal MEG recordings feasible irrespective of the presence or absence of spikes?</p><p id="478d" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Predicted answer: Yes.</p><p id="e9e5" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><strong class="nf fr">Score: 0.089</strong></p></blockquote><p id="98d4" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As we can see from the examples, if the answer is too short, it gets a low score because its similarity with the ground truth answer drops.</p><p id="240f" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">We then compile the RAG pipeline with DSPy:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="255c" class="pe oa fq pb b bg pf pg l ph pi">from dspy.teleprompt import BootstrapFewShot<br/><br/>optimizer = BootstrapFewShot(metric=mixed_metric)<br/><br/>compiled_rag = optimizer.compile(RAG(), trainset=trainset)</span></pre><p id="bc71" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After we do this and re-evaluate the compiled pipeline, the score is now 0.69!</p><p id="82c9" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now it’s time to get the final optimised prompt and add it into our Haystack pipeline.</p><h1 id="f830" class="nz oa fq bf ob oc od gq oe of og gt oh oi oj ok ol om on oo op oq or os ot ou bk">Getting the final prompt-optimised pipeline</h1><p id="28ad" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">We can see the few-shot examples selected by DSPy by looking at the <code class="cx pj pk pl pb b">demos</code> field in the <code class="cx pj pk pl pb b">compiled_rag</code> object:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="641c" class="pe oa fq pb b bg pf pg l ph pi">compiled_rag.predictors()[0].demos</span></pre><p id="9ef5" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">There are 2 types of examples provided in the final prompt: few-shot examples and bootstrapped demos, like in the prompt shown above. The few-shot examples are question-answer pairs:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="e89d" class="pe oa fq pb b bg pf pg l ph pi">Example({'question': 'Does increased Syk phosphorylation lead to overexpression of TRAF6 in peripheral B cells of patients with systemic lupus erythematosus?', 'answer': 'Our results suggest that the activated Syk-mediated TRAF6 pathway leads to aberrant activation of B cells in SLE, and also highlight Syk as a potential target for B-cell-mediated processes in SLE.'})</span></pre><p id="d06e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Whereas the bootstrapped demo has the full trace of the LLM, including the context and reasoning provided (in the <code class="cx pj pk pl pb b">rationale</code> field below):</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="f742" class="pe oa fq pb b bg pf pg l ph pi">Example({'augmented': True, 'context': ['Chronic rhinosinusitis (CRS) …', 'Allergic airway …', 'The mechanisms and ….'], 'question': 'Are group 2 innate lymphoid cells ( ILC2s ) increased in chronic rhinosinusitis with nasal polyps or eosinophilia?', 'rationale': 'produce the answer. We need to consider the findings from the study mentioned in the context, which showed that ILC2 frequencies were associated with the presence of nasal polyps, high tissue eosinophilia, and eosinophil-dominant CRS.', 'answer': 'Yes, ILC2s are increased in chronic rhinosinusitis with nasal polyps or eosinophilia.'})</span></pre><p id="032e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">All we need to do now is extract these examples found by DSPy and insert them in our Haystack pipeline:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="e54a" class="pe oa fq pb b bg pf pg l ph pi">static_prompt = lm.inspect_history(n=1).rpartition("---\n")[0]</span></pre><p id="a633" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Our new pipeline becomes:</p><pre class="mm mn mo mp mq pa pb pc bp pd bb bk"><span id="06cc" class="pe oa fq pb b bg pf pg l ph pi">from haystack.components.retrievers.in_memory import InMemoryBM25Retriever<br/>from haystack.components.generators import OpenAIGenerator<br/>from haystack.components.builders import PromptBuilder, AnswerBuilder<br/>from haystack import Pipeline<br/><br/><br/>template = static_prompt+"""<br/>---<br/><br/>Context:<br/>{% for document in documents %}<br/>    «{{ document.content }}»<br/>{% endfor %}<br/><br/>Question: {{question}}<br/>Reasoning: Let's think step by step in order to<br/>"""<br/><br/>new_prompt_builder = PromptBuilder(template=template)<br/><br/>new_retriever = InMemoryBM25Retriever(document_store, top_k=3)<br/>new_generator = OpenAIGenerator(model="gpt-3.5-turbo")<br/><br/>answer_builder = AnswerBuilder(pattern="Answer: (.*)")<br/><br/><br/>optimized_rag_pipeline = Pipeline()<br/>optimized_rag_pipeline.add_component("retriever", new_retriever)<br/>optimized_rag_pipeline.add_component("prompt_builder", new_prompt_builder)<br/>optimized_rag_pipeline.add_component("llm", new_generator)<br/>optimized_rag_pipeline.add_component("answer_builder", answer_builder)<br/><br/>optimized_rag_pipeline.connect("retriever", "prompt_builder.documents")<br/>optimized_rag_pipeline.connect("prompt_builder", "llm")<br/>optimized_rag_pipeline.connect("llm.replies", "answer_builder.replies")</span></pre><p id="7e6c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Let’s check the same question we tried before.</p><p id="1c74" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Question:</p><blockquote class="pu pv pw"><p id="5d02" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What effects does ketamine have on rat neural stem cells?</p></blockquote><p id="f3c3" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Before:</p><blockquote class="pu pv pw"><p id="95ee" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ketamine inhibits the proliferation of rat neural stem cells in a dose-dependent manner at concentrations of 200, 500, 800, and 1000µM. Additionally, ketamine decreases intracellular Ca(2+) concentration, suppresses protein kinase C-α (PKCα) activation, and phosphorylation of extracellular signal-regulated kinases 1/2 (ERK1/2) in rat neural stem cells. These effects do not seem to be mediated through caspase-3-dependent apoptosis.</p></blockquote><p id="ac0c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After:</p><blockquote class="pu pv pw"><p id="f4f3" class="nd ne px nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Ketamine at higher concentrations inhibits the proliferation of rat neural stem cells, while not affecting apoptosis. Additionally, it decreases intracellular calcium concentration and suppresses PKCα activation and ERK1/2 phosphorylation in these cells.</p></blockquote><p id="5dec" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Job done!</p><h2 id="536b" class="pz oa fq bf ob qa qb qc oe qd qe qf oh nm qg qh qi nq qj qk ql nu qm qn qo qp bk">A few words of conclusion</h2><p id="31e7" class="pw-post-body-paragraph nd ne fq nf b go ov nh ni gr ow nk nl nm ox no np nq oy ns nt nu oz nw nx ny fj bk">In this post, we have used DSPy to optimise the prompt used in a Haystack RAG pipeline. We have done so by using a custom metric based on Haystack’s evaluation framework that penalised the LLM for long answers while keeping the similarity with the correct answer high. With this approach, we have managed to improve our performance by almost 40% without having to do any manual prompt engineering.</p></div></div></div></div>    
</body>
</html>