<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Evaluate RAGs Rigorously or Perish</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Evaluate RAGs Rigorously or Perish</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26">https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="24ba" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Use the RAGAs framework with hyperparameter optimization to boost the quality of your RAG system.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Jarek Grygolec, Ph.D." class="l ep by dd de cx" src="../Images/a7982bd8f5ced5b36d4196f45102e59d.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*D24bU0jg9Zs-VYV8K3swKQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------" rel="noopener follow">Jarek Grygolec, Ph.D.</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">11 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 26, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/63cee95bd64080c5b1373fcf47e8460f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwfvT_JVXD2YnEw95DdWlw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">This is a graphic depicting the idea of “LLMs Evaluating RAGs.” The author generated it using AI in Canva.</figcaption></figure><p id="3a90" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">TL;DR</strong></p><p id="fb95" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">If you develop a RAG system, you must choose between different design options. The ragas library can help you by generating synthetic evaluation data with answers grounded in your documents. This makes possible the rigorous evaluation of a RAG system with the classic split between train/validation/test sets, boosting the quality of your RAG system.</p><p id="563d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Introduction</strong></p><p id="a019" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The development of a Retrieval Augmented Generation (RAG) system in practice involves making many decisions that are consequential for its ultimate quality, i.e., about text splitter, chunk size, overlap size, embedding model, metadata to store, distance metric for semantic search, top-k to rerank, reranker model, top-k to context, prompt engineering, etc.</p><p id="0ba3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Reality:</strong> In most cases, such decisions are not grounded in methodologically sound evaluation practices but rather driven by ad hoc judgments of developers and product owners, who often face deadlines.</p><p id="e64e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Gold Standard:</strong> In contrast, the rigorous evaluation of the RAG system should involve:</p><ul class=""><li id="e60b" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">a large evaluation set so that performance metrics are estimated with low confidence intervals</li><li id="5c37" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">diverse questions in an evaluation set</li><li id="36fd" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">answers specific to the internal documents</li><li id="b0cd" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">separate evaluation of retrieval and generation</li><li id="86ad" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">evaluation of the RAG as the whole</li><li id="ba03" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">train/validation/test split to ensure good generalization ability</li><li id="3025" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">hyperparameter optimization</li></ul><blockquote class="of og oh"><p id="d847" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Most RAG systems are NOT evaluated rigorously up to the Gold Standard due to lack of evaluation sets with answers grounded in the private documents!</p></blockquote><p id="a0b9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The generic Large Language Model (LLM) benchmarks (GLUE, SuperGlue, MMLU, BIG-Bench, HELM, …) are not of much relevance to evaluate RAGs as the essence of RAGs is to extract information from internal documents unknown to LLMs. If you insist on using LLM benchmarks for RAG system evaluation, one route would be to select the task-specific to your domain and quantify the value added to the RAG system on top of the bare-bones LLM for this chosen task.</p><p id="b766" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The alternative to generic LLM benchmarks is to create human annotated test sets based on internal documents, so that the questions require access to these internal documents to answer correctly. Such a solution is generally prohibitively expensive. In addition, outsourcing annotation may be problematic for internal documents, as they are sensitive or contain private information and can’t be shared with outside parties.</p><p id="9b14" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Here comes the <a class="af oj" href="https://arxiv.org/abs/2309.15217" rel="noopener ugc nofollow" target="_blank">RAGAs framework</a> (Retrieval Augmented Generation Assessment) [1] for reference-free RAG evaluation, with Python implementation made available in <strong class="nd fr">ragas </strong>package:</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="1b10" class="oo op fq ol b bg oq or l os ot">pip install ragas</span></pre><p id="82c2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">It provides essential <strong class="nd fr">tools for rigorous RAG evaluation</strong>:</p><ul class=""><li id="bf5d" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">generation of synthetic evaluation sets</li><li id="e43c" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">metrics specialized for RAG evaluation</li><li id="2aa8" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">prompt adaptation to deal with non-English languages</li><li id="39c7" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">integration with LangChain and Llama-Index</li></ul><p id="c972" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Synthetic Evaluation Sets</strong></p><p id="48e9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The LLM enthusiasts, myself included, suggest using LLM as a solution to many problems. Here it means:</p><blockquote class="of og oh"><p id="cee8" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">LLMs are not autonomous, but may be useful. RAGAs employs LLMs to generate synthetic evaluation sets to evaluate RAG systems.</p></blockquote><p id="6d57" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">RAGAs framework follows up on the Evol-Instruct framework, which uses LLM to generate a diverse set of instruction data (i.e. Question — Answer pairs, QA) in the evolutionary process.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ou"><img src="../Images/b5af66112472251a8a853e06f092dc1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15gnnQWW_ICbbbS7OqcMxA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Picture 1: Depicting the evolution of questions in RAGAs. The author created this image in Canva and draw.io.</figcaption></figure><p id="7745" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In the Evol-Instruct framework, LLM starts with an initial set of simple instructions and gradually rewrites them into more complex instructions, creating diverse instruction data. Can Xu et al. [2] argue that instruction data's gradual, incremental evolution produces high-quality results. In RAGAs framework, instruction data generated and evolved by LLM are grounded in available documents. The ragas library currently implements three different types of instruction data evolution by depth, starting from the simple question:</p><ul class=""><li id="bf96" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="nd fr">Reasoning:</strong> Rewrite the question to increase the need for reasoning.</li><li id="06c6" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk"><strong class="nd fr">Conditioning:</strong> Rewrite the question to introduce a conditional element.</li><li id="578d" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk"><strong class="nd fr">Multi-Context:</strong> Rewrite the question to require many documents or chunks to answer it.</li></ul><p id="7654" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In addition, ragas library also provides the option to generate conversations. Now, let’s see ragas in practice.</p><p id="7919" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Examples of Question Evolutions</strong></p><p id="6801" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We will use the Wikipedia page on Large Language Models [3] as the source document for ragas library to generate question — ground truth pairs, one for each evolution type available.</p><blockquote class="of og oh"><p id="999b" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To<strong class="nd fr"><em class="fq"> run the code</em></strong>: You can follow the code snippets in the article or access the notebook with all the related code on Github to run on Colab or locally:</p></blockquote><div class="ov ow ox oy oz pa"><a href="https://github.com/gox6/colab-demos/blob/main/rags/evaluate-rags-rigorously-or-perish.ipynb?source=post_page-----54f790557357--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab ig"><div class="pc ab co cb pd pe"><h2 class="bf fr hw z io pf iq ir pg it iv fp bk">colab-demos/rags/evaluate-rags-rigorously-or-perish.ipynb at main · gox6/colab-demos</h2><div class="ph l"><h3 class="bf b hw z io pf iq ir pg it iv dx">Colab notebooks exploring topics in Data Science and AI, discussed on the blog: https://medium.com/@jgrygolec …</h3></div><div class="pi l"><p class="bf b dy z io pf iq ir pg it iv dx">github.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po lq pa"/></div></div></a></div><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="4dbc" class="oo op fq ol b bg oq or l os ot"># Installing Python packages &amp; hiding<br/>!pip install --quiet \<br/>  chromadb \<br/>  datasets \<br/>  langchain \<br/>  langchain_chroma \<br/>  optuna \<br/>  plotly \<br/>  polars \<br/>  ragas \<br/>  1&gt; /dev/null</span></pre><pre class="pp ok ol om bp on bb bk"><span id="11b5" class="oo op fq ol b bg oq or l os ot"># Importing the packages<br/>from functools import reduce<br/>import json<br/>import os<br/>import requests<br/>import warnings<br/><br/>import chromadb<br/>from chromadb.api.models.Collection import Collection as ChromaCollection<br/>from datasets import load_dataset, Dataset<br/>from getpass import getpass<br/>from langchain_chroma import Chroma<br/>from langchain_core.prompts import ChatPromptTemplate<br/>from langchain_core.output_parsers import StrOutputParser<br/>from langchain_core.runnables import RunnableParallel, RunnablePassthrough<br/>from langchain_core.runnables.base import RunnableSequence<br/>from langchain_community.document_loaders import WebBaseLoader, PolarsDataFrameLoader<br/>from langchain_openai import ChatOpenAI, OpenAIEmbeddings<br/>from langchain_text_splitters import CharacterTextSplitter<br/>from operator import itemgetter<br/>import optuna<br/>import pandas as pd<br/>import plotly.express as px<br/>import polars as pl<br/>from ragas import evaluate<br/>from ragas.metrics import (<br/>    answer_relevancy,<br/>    faithfulness,<br/>    context_recall,<br/>    context_precision,<br/>    answer_correctness<br/>)<br/>from ragas.testset.generator import TestsetGenerator<br/>from ragas.testset.evolutions import simple, reasoning, multi_context, conditional</span></pre><pre class="pp ok ol om bp on bb bk"><span id="6d80" class="oo op fq ol b bg oq or l os ot"># Providing api key for OPENAI<br/>OPENAI_API_KEY = getpass("OPENAI_API_KEY")<br/>os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY</span></pre><pre class="pp ok ol om bp on bb bk"><span id="aad2" class="oo op fq ol b bg oq or l os ot"># Examining question evolution types evailable in ragas library<br/>urls = ["https://en.wikipedia.org/wiki/Large_language_model"]<br/>wikis_loader = WebBaseLoader(urls)<br/>wikis = wikis_loader.load()<br/><br/>llm = ChatOpenAI(model="gpt-3.5-turbo")<br/>generator_llm = llm<br/>critic_llm = llm<br/>embeddings = OpenAIEmbeddings()py<br/><br/>generator = TestsetGenerator.from_langchain(<br/>    generator_llm,<br/>    critic_llm,<br/>    embeddings<br/>)<br/><br/># Change resulting question type distribution<br/>list_of_distributions = [{simple: 1},<br/>                         {reasoning: 1},<br/>                         {multi_context: 1},<br/>                         {conditional: 1}]<br/><br/># This step COSTS $$$ ...<br/>question_evolution_types = list(<br/>    map(lambda x: generator.generate_with_langchain_docs(wikis, 1, x), <br/>        list_of_distributions)<br/>)<br/><br/># Displaying examples<br/>examples = reduce(lambda x, y: pd.concat([x, y], axis=0),<br/>                                     [x.to_pandas() for x in question_evolution_types])<br/>examples = examples.loc[:, ["evolution_type", "question", "ground_truth"]]<br/>examples</span></pre><p id="f9ed" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Running the above code, I received the following synthetic question — answer pairs based on the aforementioned Wikipedia page [3].</p></div></div><div class="mq"><div class="ab cb"><div class="ll pq lm pr ln ps cf pt cg pu ci bh"><figure class="ml mm mn mo mp mq pw px paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/1783cb7ec307e72fbe43b1371ae8015b.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*bB16tuYi55lM51SwX-c9HQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Table 1: Synthetic question — answer pairs generated using ragas library and GPT-3.5-turbo from the Wikipedia page on LLMs [3].</figcaption></figure></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3c0e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The results presented in Table 1 are very appealing. The <em class="oi">simple</em> evolution performs very well. In the case of the reasoning evolution, the first part of the question is answered perfectly, but the second part is left unanswered. Inspecting the Wikipedia page [3], there is no answer to the second part of the question in the document, so it can also be interpreted as the restraint from hallucinations, which is good. The <em class="oi">multi-context</em> question-answer pair seems very good. The conditional evolution type is acceptable if we look at the question-answer pair. One way of looking at these results is that there is always space for better prompt engineering behind evolutions. Another way is to use better LLMs, especially for the critic role, as is the default in the ragas library.</p><p id="7604" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Metrics</strong></p><p id="a99f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The ragas library is able not only to generate the synthetic evaluation sets but also provides us with built-in metrics for component-wise evaluation as well as end-to-end evaluation of RAGs.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj py"><img src="../Images/3d5919921c133036f027312376838865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMpoBYR1RUdFSDny_AATvQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Picture 2: <a class="af oj" href="https://docs.ragas.io/en/latest/concepts/metrics/index.html" rel="noopener ugc nofollow" target="_blank">RAG Evaluation Metrics in RAGAS</a>. Image created by the author in draw.io.</figcaption></figure><p id="cb23" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As of this writing, RAGAS provides eight out-of-the-box metrics for RAG evaluation, see Picture 2, and likely new ones will be added. You are about to choose the metrics most suitable for your use case. However, I recommend to select the one most important metric, i.e.:</p><blockquote class="of og oh"><p id="90cf" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="fq">Answer Correctness</em></strong><em class="fq"> </em>— the end-to-end metric with scores between 0 and 1, the higher the better, measuring the accuracy of the generated answer as compared to the ground truth.</p></blockquote><p id="a564" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Focusing on one end-to-end metric helps to start the optimization of your RAG system as fast as possible. Once you achieve some improvements in quality, you can look at component-wise metrics, focusing on the most important one for each RAG component:</p><blockquote class="of og oh"><p id="445e" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="fq">Faithfulness</em></strong> — the generation metric with scores between 0 and 1, the higher the better, measuring the factual consistency of the generated answer relative to the provided context. It is about grounding the generated answer as much as possible in the provided context, and by doing so prevent hallucinations.</p><p id="f651" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="fq">Context Relevance</em></strong> — the retrieval metric with scores between 0 and 1, the higher the better, measuring the relevancy of retrieved context relative to the question.</p></blockquote><p id="3e40" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">RAG Factory</strong></p><p id="3473" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">OK, so we have a RAG ready for optimisation… not so fast, this is not enough. To optimize RAG, we need the factory function to generate RAG chains with a given set of RAG hyperparameters. Here, we define this factory function in 2 steps:</p><p id="7d1a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Step 1</strong>: A function to store documents in the vector database.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="1cb6" class="oo op fq ol b bg oq or l os ot"># Defining a function to get document collection from vector db with given hyperparemeters<br/># The function embeds the documents only if collection is missing<br/># This development version as for production one would rather implement document level check<br/>def get_vectordb_collection(chroma_client,<br/>                            documents,<br/>                            embedding_model="text-embedding-ada-002",<br/>                            chunk_size=None, overlap_size=0) -&gt; ChromaCollection:<br/><br/>    if chunk_size is None:<br/>      collection_name = "full_text"<br/>      docs_pp = documents<br/>    else:<br/>      collection_name = f"{embedding_model}_chunk{chunk_size}_overlap{overlap_size}"<br/><br/>      text_splitter = CharacterTextSplitter(<br/>        separator=".",<br/>        chunk_size=chunk_size,<br/>        chunk_overlap=overlap_size,<br/>        length_function=len,<br/>        is_separator_regex=False,<br/>      )<br/><br/>      docs_pp = text_splitter.transform_documents(documents)<br/><br/><br/>    embedding = OpenAIEmbeddings(model=embedding_model)<br/><br/>    langchain_chroma = Chroma(client=chroma_client,<br/>                              collection_name=collection_name,<br/>                              embedding_function=embedding,<br/>                              )<br/><br/>    existing_collections = [collection.name for collection in chroma_client.list_collections()]<br/><br/>    if chroma_client.get_collection(collection_name).count() == 0:<br/>      langchain_chroma.from_documents(collection_name=collection_name,<br/>                                        documents=docs_pp,<br/>                                        embedding=embedding)<br/>    return langchain_chroma</span></pre><p id="cfe2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Step 2:</strong> A function to generate RAG in LangChain with document collection or the proper RAG factory function.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="1983" class="oo op fq ol b bg oq or l os ot"># Defininig a function to get a simple RAG as Langchain chain with given hyperparemeters<br/># RAG returns also the context documents retrieved for evaluation purposes in RAGAs<br/><br/>def get_chain(chroma_client,<br/>              documents,<br/>              embedding_model="text-embedding-ada-002",<br/>              llm_model="gpt-3.5-turbo",<br/>              chunk_size=None,<br/>              overlap_size=0,<br/>              top_k=4,<br/>              lambda_mult=0.25) -&gt; RunnableSequence:<br/><br/>    vectordb_collection = get_vectordb_collection(chroma_client=chroma_client,<br/>                                                  documents=documents,<br/>                                                  embedding_model=embedding_model,<br/>                                                  chunk_size=chunk_size,<br/>                                                  overlap_size=overlap_size)<br/><br/>    retriever = vectordb_collection.as_retriever(top_k=top_k, lambda_mult=lambda_mult)<br/><br/>    template = """Answer the question based only on the following context.<br/>    If the context doesn't contain entities present in the question say you don't know.<br/><br/>    {context}<br/><br/>    Question: {question}<br/>    """<br/>    prompt = ChatPromptTemplate.from_template(template)<br/>    llm = ChatOpenAI(model=llm_model)<br/><br/>    def format_docs(docs):<br/>        return "\n\n".join([doc.page_content for doc in docs])<br/><br/>    chain_from_docs = (<br/>      RunnablePassthrough.assign(context=(lambda x: format_docs(x["context"])))<br/>      | prompt<br/>      | llm<br/>      | StrOutputParser()<br/>    )<br/><br/>    chain_with_context_and_ground_truth = RunnableParallel(<br/>      context=itemgetter("question") | retriever,<br/>      question=itemgetter("question"),<br/>      ground_truth=itemgetter("ground_truth"),<br/>    ).assign(answer=chain_from_docs)<br/><br/>    return chain_with_context_and_ground_truth</span></pre><p id="9f4b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The former function <em class="oi">get_vectordb_collection</em> is incorporated into the latter<em class="oi"> </em>function <em class="oi">get_chain</em>, which generates our RAG chain for a given set of parameters, i.e: embedding_model, llm_model, chunk_size, overlap_size, top_k, lambda_mult. With our factory function, we are just scratching the surface of possibilities of what hyperparameters of our RAG system we optimize. Note also that the RAG chain will require 2 arguments: <em class="oi">question</em> and <em class="oi">ground_truth</em>, where the latter is just passed through the RAG chain as required for evaluation using RAGAs.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="9a27" class="oo op fq ol b bg oq or l os ot"># Setting up a ChromaDB client<br/>chroma_client = chromadb.EphemeralClient()<br/><br/># Testing full text rag<br/><br/>with warnings.catch_warnings():<br/>  rag_prototype = get_chain(chroma_client=chroma_client, <br/>                            documents=news, <br/>                            chunk_size=1000, <br/>                            overlap_size=200)<br/><br/>rag_prototype.invoke({"question": 'What happened in Minneapolis to the bridge?',<br/>                      "ground_truth": "x"})["answer"]</span></pre><p id="a758" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">RAG Evaluation</strong></p><p id="c4d0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To evaluate our RAG, we will use the diverse dataset of news articles from CNN and Daily Mail, which is available on Hugging Face [4]. Most articles in this dataset are below 1000 words. In addition, we will use a tiny extract from the dataset of just 100 news articles. This is all done to limit the costs and time needed to run the demo.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="b30a" class="oo op fq ol b bg oq or l os ot"># Getting the tiny extract of CCN Daily Mail dataset<br/>synthetic_evaluation_set_url = "https://gist.github.com/gox6/0858a1ae2d6e3642aa132674650f9c76/raw/synthetic-evaluation-set-cnn-daily-mail.csv"<br/>synthetic_evaluation_set_pl = pl.read_csv(synthetic_evaluation_set_url, separator=",").drop("index")</span></pre><pre class="pp ok ol om bp on bb bk"><span id="e2e8" class="oo op fq ol b bg oq or l os ot"># Train/test split<br/># We need at least 2 sets: train and test for RAG optimization.<br/><br/>shuffled = synthetic_evaluation_set_pl.sample(fraction=1, <br/>                                              shuffle=True, <br/>                                              seed=6)<br/>test_fraction = 0.5<br/><br/>test_n = round(len(synthetic_evaluation_set_pl) * test_fraction)<br/>train, test = (shuffled.head(-test_n), <br/>               shuffled.head( test_n))</span></pre><p id="6e9f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">As we will consider many different RAG prototypes beyond the one defined above we need a function to collect answers generated by the RAG on our synthetic evaluation set:</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="0f29" class="oo op fq ol b bg oq or l os ot"># We create the helper function to generate the RAG ansers together with Ground Truth based on synthetic evaluation set<br/># The dataset for RAGAS evaluation should contain the columns: question, answer, ground_truth, contexts<br/># RAGAs expects the data in Huggingface Dataset format<br/><br/>def generate_rag_answers_for_synthetic_questions(chain,<br/>                                                 synthetic_evaluation_set) -&gt; pl.DataFrame:<br/><br/>  df = pl.DataFrame()<br/><br/>  for row in synthetic_evaluation_set.iter_rows(named=True):<br/>    rag_output = chain.invoke({"question": row["question"], <br/>                               "ground_truth": row["ground_truth"]})<br/>    rag_output["contexts"] = [doc.page_content for doc <br/>                              in rag_output["context"]]<br/>    del rag_output["context"]<br/>    rag_output_pp = {k: [v] for k, v in rag_output.items()}<br/>    df = pl.concat([df, pl.DataFrame(rag_output_pp)], how="vertical")<br/><br/>  return df</span></pre><p id="e191" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">RAG Optimisation with RAGAs and Optuna</strong></p><p id="fe24" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">First, it is worth emphasizing that the proper optimization of the RAG system should involve global optimization, where all parameters are optimized simultaneously. This is in contrast to the sequential or greedy approach, where parameters are optimized one by one. The sequential approach ignores the fact that there can be interactions between the parameters, which can result in a sub-optimal solution.</p><p id="6d54" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Now, we are ready to optimize our RAG system. We will use the hyperparameter optimization framework <a class="af oj" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank">Optuna</a>. To this end, we define the objective function for Optuna’s study, specifying the allowed hyperparameter space and computing the evaluation metric. See the code below:</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="2455" class="oo op fq ol b bg oq or l os ot">def objective(trial):<br/><br/>  embedding_model = trial.suggest_categorical(name="embedding_model",<br/>                                              choices=["text-embedding-ada-002", 'text-embedding-3-small'])<br/><br/>  chunk_size = trial.suggest_int(name="chunk_size",<br/>                                 low=500,<br/>                                 high=1000,<br/>                                 step=100)<br/><br/>  overlap_size = trial.suggest_int(name="overlap_size",<br/>                                   low=100,<br/>                                   high=400,<br/>                                   step=50)<br/><br/>  top_k = trial.suggest_int(name="top_k",<br/>                            low=1,<br/>                            high=10,<br/>                            step=1)<br/><br/><br/>  challenger_chain = get_chain(chroma_client,<br/>                            news,<br/>                            embedding_model=embedding_model,<br/>                            llm_model="gpt-3.5-turbo",<br/>                            chunk_size=chunk_size,<br/>                            overlap_size= overlap_size ,<br/>                            top_k=top_k,<br/>                            lambda_mult=0.25)<br/><br/><br/>  challenger_answers_pl = generate_rag_answers_for_synthetic_questions(challenger_chain , train)<br/>  challenger_answers_hf = Dataset.from_pandas(challenger_answers_pl.to_pandas())<br/><br/>  challenger_result = evaluate(challenger_answers_hf,<br/>                               metrics=[answer_correctness],<br/>                              )<br/><br/>  return challenger_result['answer_correctness']</span></pre><p id="3774" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Finally, with the objective function, we define and run the study to optimize our RAG system in Optuna. We can add our educated guesses of hyperparameters to the study with the method enqueue_trial and limit the study by time or number of trials. See <a class="af oj" href="https://optuna.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">Optuna’s docs</a> for more tips.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="dc37" class="oo op fq ol b bg oq or l os ot">sampler = optuna.samplers.TPESampler(seed=6)<br/>study = optuna.create_study(study_name="RAG Optimisation",<br/>                            direction="maximize",<br/>                            sampler=sampler)<br/>study.set_metric_names(['answer_correctness'])<br/><br/>educated_guess = {"embedding_model": "text-embedding-3-small", <br/>                  "chunk_size": 1000,<br/>                  "overlap_size": 200,<br/>                  "top_k": 3}<br/><br/><br/>study.enqueue_trial(educated_guess)<br/><br/>print(f"Sampler is {study.sampler.__class__.__name__}")<br/>study.optimize(objective, timeout=180)</span></pre><p id="59ef" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In our study, the educated guess wasn’t confirmed, but I’m sure it will get better with a rigorous approach like the one proposed above.</p><pre class="ml mm mn mo mp ok ol om bp on bb bk"><span id="fdd1" class="oo op fq ol b bg oq or l os ot">Best trial with answer_correctness: 0.700130617593832<br/>Hyper-parameters for the best trial: {'embedding_model': 'text-embedding-ada-002', 'chunk_size': 700, 'overlap_size': 400, 'top_k': 9}</span></pre><p id="febf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Limitations of RAGAs</strong></p><p id="b057" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">After experimenting with ragas library to synthesize evaluation sets and evaluate RAGs I have some caveats:</p><ul class=""><li id="6b85" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk">The question may contain the answer.</li><li id="b321" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">The ground truth is just the literal excerpt from the document.</li><li id="8273" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">Issues with RateLimitError as well as network overflows on Colab.</li><li id="1538" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">Built-in evolutions are few, and there is no easy way to add new ones.</li><li id="b945" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk">There is room for improvement in documentation.</li></ul><p id="a587" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The first 2 caveats are quality-related. The root cause may be in the LLM used, and obviously, GPT-4 gives better results than GPT-3.5-Turbo. At the same time, it seems that this could be improved by some prompt engineering for evolutions used to generate synthetic evaluation sets.</p><p id="6dd8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For issues with rate-limiting and network overflows, it is advisable to use 1) checkpointing during the generation of synthetic evaluation sets to prevent loss of created data and 2) exponential backoff to ensure you complete the whole task.</p><p id="063c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Finally, and most importantly, more built-in evolutions would be a welcome addition to the ragas package, not to mention the possibility of creating custom evolutions more easily.</p><p id="d023" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Other Useful Features of RAGAs</strong></p><ul class=""><li id="59be" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz bk"><strong class="nd fr">Custom Prompts. </strong>The Ragas package allows you to change the prompts in the provided abstractions. The docs describe an example of custom prompts for metrics in the evaluation task.</li><li id="efc9" class="nb nc fq nd b go oa nf ng gr ob ni nj nk oc nm nn no od nq nr ns oe nu nv nw nx ny nz bk"><strong class="nd fr">Automatic Language Adaptation. </strong>RAGAs has you covered for non-English languages. It has a great feature called automatic language adaptation supporting RAG evaluation in the languages other than English, see the docs for more info.</li></ul><p id="b1a2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Conclusions</strong></p><p id="0f2a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Despite RAGAs limitations, do NOT miss the most important thing:</p><blockquote class="pz"><p id="638d" class="qa qb fq bf qc qd qe qf qg qh qi nw dx">RAGAs is already very useful tool despite its young age. It enables generation of synthetic evaluation set for rigorous RAG evaluation, a critical aspect for successful RAG development.</p></blockquote></div></div></div><div class="ab cb qj qk ql qm" role="separator"><span class="qn by bm qo qp qq"/><span class="qn by bm qo qp qq"/><span class="qn by bm qo qp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><blockquote class="of og oh"><p id="bab9" class="nb nc oi nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Please clap i</strong>f you enjoyed this reading. I invite You to look at<strong class="nd fr"> </strong><a class="af oj" href="https://medium.com/@jgrygolec" rel="noopener"><strong class="nd fr">my other articles</strong></a> and<strong class="nd fr"> </strong><a class="af oj" href="https://medium.com/@jgrygolec/about" rel="noopener"><strong class="nd fr">f</strong></a><strong class="nd fr">ollow </strong>me to get my new content.</p></blockquote></div></div></div><div class="ab cb qj qk ql qm" role="separator"><span class="qn by bm qo qp qq"/><span class="qn by bm qo qp qq"/><span class="qn by bm qo qp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="bc40" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Acknowledgments</strong></p><p id="122f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This project &amp; article would be impossible if I didn’t stand on the shoulders of giants. It is impossible to mention all influences, but the following were directly related:</p><p id="4e9d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[1] S. Es, J. James, L. Espinosa-Anke, S. Schockaert, RAGAS: Automated Evaluation of Retrieval Augmented Generation (2023), <a class="af oj" href="https://arxiv.org/abs/2309.15217" rel="noopener ugc nofollow" target="_blank"><br/>arXiv:2309.15217</a></p><p id="a17e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[2] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, D. Jiang, WizardLM: Empowering Large Language Models to Follow Complex Instructions (2023), <a class="af oj" href="https://arxiv.org/abs/2304.12244" rel="noopener ugc nofollow" target="_blank">arXiv:2304.12244</a></p><p id="29f9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[3] Community, Large Language Models, Wikipedia (2024), <a class="af oj" href="https://en.wikipedia.org/wiki/Large_language_model" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Large_language_model</a></p><p id="5122" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[4] CNN &amp; Daily Mail Dataset available on Hugging Face, for more info, see: <a class="af oj" href="https://huggingface.co/datasets/cnn_dailymail" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/datasets/cnn_dailymail</a></p></div></div></div></div>    
</body>
</html>