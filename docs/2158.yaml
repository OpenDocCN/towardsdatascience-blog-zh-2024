- en: Monte Carlo Methods for Solving Reinforcement Learning Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/monte-carlo-methods-for-solving-reinforcement-learning-problems-ff8389d46a3e?source=collection_archive---------7-----------------------#2024-09-04](https://towardsdatascience.com/monte-carlo-methods-for-solving-reinforcement-learning-problems-ff8389d46a3e?source=collection_archive---------7-----------------------#2024-09-04)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Dissecting “Reinforcement Learning” by Richard S. Sutton with Custom Python
    Implementations, Episode III
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@hrmnmichaels?source=post_page---byline--ff8389d46a3e--------------------------------)[![Oliver
    S](../Images/b5ee0fa2d5fb115f62e2e9dfcb92afdd.png)](https://medium.com/@hrmnmichaels?source=post_page---byline--ff8389d46a3e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff8389d46a3e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff8389d46a3e--------------------------------)
    [Oliver S](https://medium.com/@hrmnmichaels?source=post_page---byline--ff8389d46a3e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff8389d46a3e--------------------------------)
    ·18 min read·Sep 4, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: We continue our deep dive into Sutton’s great book about RL [1] and here focus
    on Monte Carlo (MC) methods. These are able to learn from experience alone, i.e.
    do not require any kind of model of the environment, as e.g. required by the [Dynamic
    programming (DP) methods we introduced in the previous post](/introducing-markov-decision-processes-setting-up-gymnasium-environments-and-solving-them-via-e806c36dc04f).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is extremely tempting — as often the model is not known, or it is hard
    to model the transition probabilities. Consider the game of [Blackjack](https://en.wikipedia.org/wiki/Blackjack):
    even though we fully understand the game and the rules, solving it via DP methods
    would be very tedious — we would have to compute all kinds of probabilities, e.g.
    given the currently played cards, how likely is a “blackjack”, how likely is it
    that another seven is dealt … Via MC methods, we don’t have to deal with any of
    this, and simply play and learn from experience.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/08c697f6fd32b28f30fd93d741dfe436.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Jannis Lucas](https://unsplash.com/@jannis_lucas?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/white-building-facade-Y4L7b_ilnEc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Due to not using a model, MC methods are unbiased. They are conceptually simple
    and easy to understand, but exhibit a high variance and cannot be solved in iterative
    fashion (bootstrapping).
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, here we will introduce these methods following Chapter 5 of Sutton’s
    book…
  prefs: []
  type: TYPE_NORMAL
