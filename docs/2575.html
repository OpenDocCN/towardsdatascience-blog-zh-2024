<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Discretization, Explained: A Visual Guide with Code Examples for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Discretization, Explained: A Visual Guide with Code Examples for Beginners</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?source=collection_archive---------5-----------------------#2024-10-22">https://towardsdatascience.com/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?source=collection_archive---------5-----------------------#2024-10-22</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="5f34" class="fo fp fq bf b dy fr fs ft fu fv fw dx fx" aria-label="kicker paragraph">DATA PREPROCESSING</h2><div/><div><h2 id="8594" class="pw-subtitle-paragraph gs fz fq bf b gt gu gv gw gx gy gz ha hb hc hd he hf hg hh cq dx">6 fun ways to categorize numbers into bins!</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hi hj hk hl hm ab"><div><div class="ab hn"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@samybaladram?source=post_page---byline--f056af9102fa--------------------------------" rel="noopener follow"><div class="l ho hp by hq hr"><div class="l ed"><img alt="Samy Baladram" class="l ep by dd de cx" src="../Images/715cb7af97c57601966c5d2f9edd0066.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="hs by l dd de em n ht eo"/></div></div></a></div></div><div class="hu ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f056af9102fa--------------------------------" rel="noopener follow"><div class="l hv hw by hq hx"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hy cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hs by l br hy em n ht eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hz ab q"><div class="ab q ia"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ib ic bk"><a class="af ag ah ai aj ak al am an ao ap aq ar id" data-testid="authorName" href="https://medium.com/@samybaladram?source=post_page---byline--f056af9102fa--------------------------------" rel="noopener follow">Samy Baladram</a></p></div></div></div><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span><p class="bf b ib ic dx"><button class="ig ih ah ai aj ak al am an ao ap aq ar ii ij ik" disabled="">Follow</button></p></div></div></span></div></div><div class="l il"><span class="bf b bg z dx"><div class="ab cn im in io"><div class="ip iq ab"><div class="bf b bg z dx ab ir"><span class="is l il">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar id ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f056af9102fa--------------------------------" rel="noopener follow"><p class="bf b bg z it iu iv iw ix iy iz ja bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ie if" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="jb jc l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">Â·</span></span></div><span data-testid="storyPublishDate">Oct 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js"><div class="h k w ea eb q"><div class="ki l"><div class="ab q kj kk"><div class="pw-multi-vote-icon ed is kl km kn"><div class=""><div class="ko kp kq kr ks kt ku am kv kw kx kn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ky kz la lb lc ld le"><p class="bf b dy z dx"><span class="kp">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ko lh li ab q ee lj lk" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lf lg">2</span></p></button></div></div></div><div class="ab q jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="ll k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lm an ao ap ii ln lo lp" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lq cn"><div class="l ae"><div class="ab cb"><div class="lr ls lt lu lv lw ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lm an ao ap ii lx ly lk lz ma mb mc md s me mf mg mh mi mj mk u ml mm mn"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/6561ef28778421d0abf32c496d9cc832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zdy1V7EnPHRDLejx-R83DQ.png"/></div></div></figure><p id="4131" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><code class="cx ny nz oa ob b">â›³ï¸ More <a class="af oc" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4" rel="noopener">DATA PREPROCESSING</a>, explained: <br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb">Missing Value Imputation</a> <br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae">Categorical Encoding</a> <br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb">Data Scaling</a> <br/> â–¶ <a class="af oc" rel="noopener" target="_blank" href="/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86">Discretization</a> <br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091">Oversampling &amp; Undersampling</a> <br/> Â· <a class="af oc" rel="noopener" target="_blank" href="/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7">Data Leakage in Preprocessing</a></code></p><p id="9200" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Most machine learning model requires the data to be numerical â€” all object or categorical data has to be in numerical format first. But, actually, there are times when categorical data comes in handy (itâ€™s more useful to us human than to the machines most of the time). Discretization (or binning) does exactly that â€” converting numerical data into categorical ones!</p><p id="4f04" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Depending on your goal, there are numerous way to categorize your data. Here, weâ€™ll use a simple dataset to show through six different binning methods. From equal-width to clustering-based approaches, weâ€™ll sweep those numerical values into some categorical bins!</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/637e519d208064455494fb6145230db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*impV6L8Uj9bwZs-jfn4PqA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx">All visuals: Author-created using Canva Pro. Optimized for mobile; may appear oversized on desktop.</figcaption></figure><h1 id="1fbb" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">What is Discretization?</h1><p id="c7c6" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Discretization, also known as binning, is the process of transforming continuous numerical variables into discrete categorical features. It involves dividing the range of a continuous variable into intervals (bins) and assigning data points to these bins based on their values.</p><h1 id="a0a7" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Why Do We Need Binning?</h1><ol class=""><li id="4639" class="nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx pj pk pl bk"><strong class="ne ga">Handling Outliers</strong>: Binning can reduce the impact of outliers without removing data points.</li><li id="282c" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Improving Model Performance</strong>: Some algorithms perform better with categorical inputs (such as <a class="af oc" href="https://medium.com/towards-data-science/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6" rel="noopener">Bernoulli Naive Bayes</a>).</li><li id="85e5" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Simplifying Visualization</strong>: Binned data can be easier to visualize and interpret.</li><li id="ad7b" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Reducing Overfitting</strong>: It can prevent models from fitting to noise in high-precision data.</li></ol><h1 id="b1d0" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Which Data Needs Binning?</h1><h2 id="ac1f" class="pr oj fq bf ok ps pt pu on pv pw px oq nl py pz qa np qb qc qd nt qe qf qg fw bk">Data That Often Benefits from Binning:</h2><ol class=""><li id="d39a" class="nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx pj pk pl bk"><strong class="ne ga">Continuous variables with wide ranges</strong>: Variables with a large spread of values can often benefit from grouping.</li><li id="5c64" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Skewed distributions</strong>: Binning can help normalize heavily skewed data.</li><li id="9acd" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Variables with outliers</strong>: Binning can handle the effect of extreme values.</li><li id="832d" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">High-cardinality numerical data</strong>: Variables with many unique values can be simplified through binning.</li></ol><h2 id="c52e" class="pr oj fq bf ok ps pt pu on pv pw px oq nl py pz qa np qb qc qd nt qe qf qg fw bk">Data That Usually Doesnâ€™t Need Binning:</h2><ol class=""><li id="f559" class="nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx pj pk pl bk"><strong class="ne ga">Already categorical data</strong>: Variables that are already in discrete categories donâ€™t need further binning.</li><li id="5ee5" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Discrete numerical data with few unique values</strong>: If a variable only has a small number of possible values, binning might not provide additional benefit.</li><li id="44e3" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Numeric IDs or codes</strong>: These are meant to be unique identifiers, not for analysis.</li><li id="0fe3" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Time series data</strong>: While you can bin time series data, it often requires specialized techniques and careful consideration, but less common overall.</li></ol><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/aee9adcaa9403a05e391d55f4a08f509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BPPLv7ks-OdfZAo5zy6EFA.png"/></div></div></figure><h1 id="6ec7" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">The Dataset</h1><p id="f4e4" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">To demonstrate these binning techniques, weâ€™ll be using this artificial dataset. Say, this is the weather condition in some golf course, collected on 15 different days.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/0d331773e1d05bd2af57d2579c62304b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kVoJhGohGnRPiiN2QzeUA.png"/></div></div><figcaption class="od oe of mo mp og oh bf b bg z dx"><strong class="bf ok">UV Index</strong> (a scale from 0â€“11), <strong class="bf ok">Humidity</strong> (in %), <strong class="bf ok">Wind Speed </strong>(in mph), <strong class="bf ok">Rainfall Amount</strong> (in mm), <strong class="bf ok">Temperature (</strong>in Fahrenheit), <strong class="bf ok">Crowdedness</strong> (0 (empty) to 1 (full))</figcaption></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="e076" class="qk oj fq ob b bg ql qm l qn qo">import pandas as pd<br/>import numpy as np<br/><br/># Create the dataset as a dictionary<br/>data = {<br/>    'UVIndex': [2, 10, 1, 7, 3, 9, 5, 11, 1, 8, 3, 9, 11, 5, 7],<br/>    'Humidity': [15, 95, 10, 98, 18, 90, 25, 80, 95, 40, 20, 30, 85, 92, 12], <br/>    'WindSpeed': [2, 90, 1, 30, 3, 10, 40, 5, 60, 15, 20, 45, 25, 35, 50],<br/>    'RainfallAmount': [5,2,7,3,18,3,0,1,25,0,9,0,18,7,0],    <br/>    'Temperature': [68, 60, 63, 55, 50, 56, 57, 65, 66, 68, 71, 72, 79, 83, 81],  <br/>    'Crowdedness': [0.15, 0.98, 0.1, 0.85, 0.2, 0.9, 0.92, 0.25, 0.12, 0.99, 0.2, 0.8, 0.05, 0.3, 0.95]<br/>}<br/><br/># Create a DataFrame from the dictionary<br/>df = pd.DataFrame(data)</span></pre><p id="722f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Using this dataset, letâ€™s see how various binning techniques can be applied to our columns!</p><h1 id="77de" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 1: Equal-Width Binning</h1><p id="773b" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Equal-width binning divides the range of a variable into a specified number of intervals, all with the same width.</p><p id="2007" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method works well for data with a roughly uniform distribution and when the minimum and maximum values are meaningful.</p><p id="dbbf" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply equal-width binning to our UV Index variable. Weâ€™ll create four bins: Low, Moderate, High, and Very High. We chose this method for UV Index because it gives us a clear, intuitive division of the index range, which could be useful for understanding how different index ranges affect golfing decisions.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/d852fd9590a7de9d5af5d3b3aa020b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUOpm0HtBuR79d8juxG9Cg.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="e93d" class="qk oj fq ob b bg ql qm l qn qo"># 1. Equal-Width Binning for UVIndex<br/>df['UVIndexBinned'] = pd.cut(df['UVIndex'], bins=4, <br/>                             labels=['Low', 'Moderate', 'High', 'Very High'])</span></pre><h1 id="ac52" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 2: Equal-Frequency Binning (Quantile Binning)</h1><p id="efaf" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Equal-frequency binning creates bins that contain approximately the same number of observations.</p><p id="b7bb" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method is particularly useful for skewed data or when you want to make sure a balanced representation across categories.</p><p id="f285" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply equal-frequency binning to our Humidity variable, creating three bins: Low, Medium, and High. We chose this method for Humidity because it ensures we have an equal number of observations in each category, which can be helpful if humidity values are not evenly distributed across their range.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/49950ea927ed58b57b5cfcf244bd9d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NSBbS7m7eW56dBmsJz7kA.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="bb5e" class="qk oj fq ob b bg ql qm l qn qo"># 2. Equal-Frequency Binning for Humidity<br/>df['HumidityBinned'] = pd.qcut(df['Humidity'], q=3, <br/>                               labels=['Low', 'Medium', 'High'])</span></pre><h1 id="e2df" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 3: Custom Binning</h1><p id="c1ff" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Custom binning allows you to define your own bin edges based on domain knowledge or specific requirements.</p><p id="cd31" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method is ideal when you have specific thresholds that are meaningful in your domain or when you want to focus on particular ranges of values.</p><p id="8509" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply custom binning to our Rainfall Amount. We chose this method for this column because there are standardized categories for rain (such as described <a class="af oc" href="https://www.researchgate.net/figure/Classification-of-rainfall-events-based-on-daily-rainfall-amount_tbl1_289849694" rel="noopener ugc nofollow" target="_blank">in this site</a>) that are more meaningful than arbitrary divisions.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/c211f20ccf1f74df9d51d93058fbdf6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NfDszSygmeTVaS3YxR5XDg.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="4044" class="qk oj fq ob b bg ql qm l qn qo"># 3. Custom Binning for RainfallAmount<br/>df['RainfallAmountBinned'] = pd.cut(df['RainfallAmount'], bins=[-np.inf, 2, 4, 12, np.inf], <br/>                                    labels=['No Rain', 'Drizzle', 'Rain', 'Heavy Rain'])</span></pre><h1 id="ae69" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 4: Logarithmic Binning</h1><p id="68d6" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Logarithmic binning creates bins that grow exponentially in size. The method basically applies log transformation first then performs equal-width binning.</p><p id="f699" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method is particularly useful for data that spans several orders of magnitude or follows a power law distribution.</p><p id="cad3" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply logarithmic binning to our Wind Speed variable. We chose this method for Wind Speed because the effect of wind on a golf ballâ€™s trajectory might not be linear. A change from 0 to 5 mph might be more significant than a change from 20 to 25 mph.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/447e1400db2cdde81998ef29e1c3bb00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qB_hpaUqsTo7LuLZHrBw1g.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="154f" class="qk oj fq ob b bg ql qm l qn qo"># 4. Logarithmic Binning for WindSpeed<br/>df['WindSpeedBinned'] = pd.cut(np.log1p(df['WindSpeed']), bins=3, <br/>                               labels=['Light', 'Moderate', 'Strong'])</span></pre><h1 id="023a" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 5: Standard Deviation-based Binning</h1><p id="1658" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Standard Deviation based binning creates bins based on the number of standard deviations away from the mean. This approach is useful when working with normally distributed data or when you want to bin data based on how far values deviate from the central tendency.</p><p id="54d8" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Variations</strong>: The exact number of standard deviations used for binning can be adjusted based on the specific needs of the analysis. The number of bins is typically odd (to have a central bin). Some implementations might use unequal bin widths, with narrower bins near the mean and wider bins in the tails.</p><p id="61d9" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method is well-suited for data that follows a normal distribution or when you want to identify outliers and understand the spread of your data. May not be suitable for highly skewed distributions.</p><p id="bbaf" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply this binning method scaling to our Temperature variable. We chose this method for Temperature because it allows us to categorize temperatures based on how they deviate from the average, which can be particularly useful in understanding weather patterns or climate trends.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/7c740e47c406b24440f075ca4a5884dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSbN70AR1H_PGyBG3ADoUg.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="d46f" class="qk oj fq ob b bg ql qm l qn qo"># 5. Standard Deviation-Based Binning for Temperature<br/>mean_temp, std_dev = df['Temperature'].mean(), df['Temperature'].std()<br/>bin_edges = [<br/>    float('-inf'),  # Ensure all values are captured<br/>    mean_temp - 2.5 * std_dev,<br/>    mean_temp - 1.5 * std_dev,<br/>    mean_temp - 0.5 * std_dev,<br/>    mean_temp + 0.5 * std_dev,<br/>    mean_temp + 1.5 * std_dev,<br/>    mean_temp + 2.5 * std_dev,<br/>    float('inf')   # Ensure all values are captured<br/>]<br/>df['TemperatureBinned'] = pd.cut(df['Temperature'], bins=bin_edges, <br/>                                 labels=['Very Low', 'Low', 'Below Avg', 'Average','Above Avg', 'High', 'Very High'])</span></pre><h1 id="245b" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Method 6: K Means Binning</h1><p id="54e7" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">K-Means binning uses the K-Means clustering algorithm to create bins. It groups data points into clusters based on how similar the data points are to each other, with each cluster becoming a bin.</p><p id="4fd1" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">Common Data Type</strong>: This method is great for finding groups in data that might not be obvious at first. It works well with data that has one peak or several peaks, and it can adjust to the way the data is organized.</p><p id="a198" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne ga">In our Case</strong>: Letâ€™s apply K-Means binning to our Crowdedness variable. We chose this method for Crowdedness because it might reveal natural groupings in how busy the golf course gets, which could be influenced by various factors not captured by simple threshold-based binning.</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/fd0981955f858214f737ef76dc4980ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwnSVJO99FgyDeEjYMEIsQ.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="76ad" class="qk oj fq ob b bg ql qm l qn qo"># 6. K-Means Binning for Crowdedness<br/>kmeans = KMeans(n_clusters=3, random_state=42).fit(df[['Crowdedness']])<br/>df['CrowdednessBinned'] = pd.Categorical.from_codes(kmeans.labels_, categories=['Low', 'Medium', 'High'])</span></pre><h1 id="63a1" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Conclusion</h1><p id="11d1" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">We tried six different ways to â€˜discretizeâ€™ the numbers in our golf data. So, the final dataset now looks like this:</p><figure class="mr ms mt mu mv mw mo mp paragraph-image"><div role="button" tabindex="0" class="mx my ed mz bh na"><div class="mo mp mq"><img src="../Images/0c8083b55c6b1d171f7f5adc0523d5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3XvTH9KSXo5Tcw_cPe4qw.png"/></div></div></figure><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="4896" class="qk oj fq ob b bg ql qm l qn qo"># Print only the binned columns<br/>binned_columns = [col for col in df.columns if col.endswith('Binned')]<br/>print(df[binned_columns])</span></pre><p id="b580" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Letâ€™s review how each binning technique transformed our weather data:</p><ol class=""><li id="168f" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pj pk pl bk"><strong class="ne ga">Equal-Width Binning (UVIndex)</strong>: Divided our UV Index scale into four equal ranges, categorizing exposure levels from â€˜Lowâ€™ to â€˜Very Highâ€™. This gives a straightforward interpretation of UV intensity.</li><li id="7ce4" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Equal-Frequency Binning (Humidity)</strong>: Sorted our Humidity readings into â€˜Lowâ€™, â€˜Mediumâ€™, and â€˜Highâ€™ categories, each containing an equal number of data points. This approach makes sure a balanced representation across humidity levels.</li><li id="af0c" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Logarithmic Binning (WindSpeed)</strong>: Applied to our Wind Speed data, this method accounts for the non-linear impact of wind on weather conditions, categorizing speeds as â€˜Lightâ€™, â€˜Moderateâ€™, or â€˜Strongâ€™.</li><li id="bc49" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Custom Binning (RainfallAmount)</strong>: Used domain knowledge to classify rainfall into meaningful categories from â€˜No Rainâ€™ to â€˜Heavy Rainâ€™. This method directly translates measurements into practical weather descriptions.</li><li id="7f02" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Standard Deviation-Based Binning (Temperature)</strong>: Segmented our Temperature data based on its distribution, ranging from â€˜Very Lowâ€™ to â€˜Very Highâ€™. This approach highlights how temperatures deviate from the average.</li><li id="0edc" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">K-Means Binning (Crowdedness)</strong>: Showed natural groupings in our Crowdedness data, potentially showing patterns.</li></ol><p id="9acb" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Itâ€™s important to avoid applying binning techniques with no thought. The nature of each variable and your analytical goals are always varied and itâ€™s good to keep that in mind when selecting a binning method. In many cases, trying out multiple techniques and comparing their outcomes can provide the most insights into your data!</p></div></div></div><div class="ab cb qp qq qr qs" role="separator"><span class="qt by bm qu qv qw"/><span class="qt by bm qu qv qw"/><span class="qt by bm qu qv"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="e857" class="oi oj fq bf ok ol qx gv on oo qy gy oq or qz ot ou ov ra ox oy oz rb pb pc pd bk">âš ï¸ The Risks of Binning</h1><p id="aa52" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">While performing binning sounds easy, it comes with its own risks:</p><ol class=""><li id="990e" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx pj pk pl bk"><strong class="ne ga">Information Loss</strong>: When you bin data, youâ€™re essentially smoothing over the details. This can be great for spotting trends, but you might miss out on subtle patterns or relationships within the bins.</li><li id="feb7" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Arbitrary Boundaries</strong>: The choice of bin edges can sometimes feel like more art than science. A slight shift in these boundaries can lead to different interpretations of your data.</li><li id="e408" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Model Impact</strong>: Some models, particularly tree-based ones like <a class="af oc" href="https://medium.com/towards-data-science/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e" rel="noopener">Decision Tree</a>, might actually perform worse with binned data. Theyâ€™re pretty good at finding their own â€˜binsâ€™, so to speak.</li><li id="672b" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">False Sense of Security</strong>: Binning can make your data look neater and more manageable, but the underlying complexity is still there. Just hidden.</li><li id="f2c4" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx pj pk pl bk"><strong class="ne ga">Difficulty in Interpretation</strong>: While binning can simplify analysis, it can also make it harder to interpret the magnitude of effects. â€œHighâ€ temperature could mean very different things in different contexts.</li></ol><p id="bf25" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">So, whatâ€™s a data scientist to do? Hereâ€™s my advice:</p><ul class=""><li id="ebb9" class="nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx rc pk pl bk">Always keep a copy of your unbinned data. You might need to go back to it.</li><li id="04a4" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx rc pk pl bk">Try different binning strategies and compare the results. Donâ€™t settle for the first method you try.</li><li id="43a2" class="nc nd fq ne b gt pm ng nh gw pn nj nk nl po nn no np pp nr ns nt pq nv nw nx rc pk pl bk">Look up if thereâ€™s already a standard way in the domain of the dataset to categorize the data (like our â€œRainfall Amountâ€ example above.)</li></ul><h1 id="75c2" class="oi oj fq bf ok ol om gv on oo op gy oq or os ot ou ov ow ox oy oz pa pb pc pd bk">ğŸŒŸ Discretization Summarized</h1><pre class="mr ms mt mu mv qh ob qi bp qj bb bk"><span id="311c" class="qk oj fq ob b bg ql qm l qn qo">import pandas as pd<br/>import numpy as np<br/>from sklearn.cluster import KMeans<br/><br/># Create the dataset<br/>data = {<br/>    'UVIndex': [2, 10, 1, 7, 3, 9, 5, 11, 1, 8, 3, 9, 11, 5, 7],<br/>    'Humidity': [15, 95, 10, 98, 18, 90, 25, 80, 95, 40, 20, 30, 85, 92, 12], <br/>    'WindSpeed': [2, 90, 1, 30, 3, 10, 40, 5, 60, 15, 20, 45, 25, 35, 50],<br/>    'RainfallAmount': [5,2,7,3,18,3,0,1,25,0,9,0,18,7,0],    <br/>    'Temperature': [68, 60, 63, 55, 50, 56, 57, 65, 66, 68, 71, 72, 79, 83, 81],  <br/>    'Crowdedness': [0.15, 0.98, 0.1, 0.85, 0.2, 0.9, 0.92, 0.25, 0.12, 0.99, 0.2, 0.8, 0.05, 0.3, 0.95]<br/>}<br/><br/># Create a DataFrame from the dictionary<br/>df = pd.DataFrame(data)<br/><br/># 1. Equal-Width Binning for UVIndex<br/>df['UVIndexBinned'] = pd.cut(df['UVIndex'], bins=4, <br/>                             labels=['Low', 'Moderate', 'High', 'Very High'])<br/><br/># 2. Equal-Frequency Binning for Humidity<br/>df['HumidityBinned'] = pd.qcut(df['Humidity'], q=3, <br/>                               labels=['Low', 'Medium', 'High'])<br/><br/># 3. Custom Binning for RainfallAmount<br/>df['RainfallAmountBinned'] = pd.cut(df['RainfallAmount'], bins=[-np.inf, 2, 4, 12, np.inf], <br/>                                    labels=['No Rain', 'Drizzle', 'Rain', 'Heavy Rain'])<br/><br/># 4. Logarithmic Binning for WindSpeed<br/>df['WindSpeedBinned'] = pd.cut(np.log1p(df['WindSpeed']), bins=3, <br/>                               labels=['Light', 'Moderate', 'Strong'])<br/><br/># 5. Standard Deviation-Based Binning for Temperature<br/>mean_temp, std_dev = df['Temperature'].mean(), df['Temperature'].std()<br/>bin_edges = [<br/>    float('-inf'),  # Ensure all values are captured<br/>    mean_temp - 2.5 * std_dev,<br/>    mean_temp - 1.5 * std_dev,<br/>    mean_temp - 0.5 * std_dev,<br/>    mean_temp + 0.5 * std_dev,<br/>    mean_temp + 1.5 * std_dev,<br/>    mean_temp + 2.5 * std_dev,<br/>    float('inf')   # Ensure all values are captured<br/>]<br/>df['TemperatureBinned'] = pd.cut(df['Temperature'], bins=bin_edges, <br/>                                 labels=['Very Low', 'Low', 'Below Avg', 'Average','Above Avg', 'High', 'Very High'])<br/><br/># 6. KMeans Binning for Crowdedness<br/>kmeans = KMeans(n_clusters=3, random_state=42).fit(df[['Crowdedness']])<br/>df['CrowdednessBinned'] = pd.Categorical.from_codes(kmeans.labels_, categories=['Low', 'Medium', 'High'])<br/><br/># Print only the binned columns<br/>binned_columns = [col for col in df.columns if col.endswith('Binned')]<br/>print(df[binned_columns])</span></pre></div></div></div><div class="ab cb qp qq qr qs" role="separator"><span class="qt by bm qu qv qw"/><span class="qt by bm qu qv qw"/><span class="qt by bm qu qv"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="6937" class="pr oj fq bf ok ps pt pu on pv pw px oq nl py pz qa np qb qc qd nt qe qf qg fw bk">Technical Environment</h2><p id="1221" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">This article uses Python 3.7 and scikit-learn 1.5. While the concepts discussed are generally applicable, specific code implementations may vary slightly with different versions.</p><h2 id="0390" class="pr oj fq bf ok ps pt pu on pv pw px oq nl py pz qa np qb qc qd nt qe qf qg fw bk">About the Illustrations</h2><p id="25e5" class="pw-post-body-paragraph nc nd fq ne b gt pe ng nh gw pf nj nk nl pg nn no np ph nr ns nt pi nv nw nx fj bk">Unless otherwise noted, all images are created by the author, incorporating licensed design elements from Canva Pro.</p><p id="9d07" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ˜¿ğ™–ğ™©ğ™– ğ™‹ğ™§ğ™šğ™¥ğ™§ğ™¤ğ™˜ğ™šğ™¨ğ™¨ğ™ğ™£ğ™œ ğ™¢ğ™šğ™©ğ™ğ™¤ğ™™ğ™¨ ğ™ğ™šğ™§ğ™š:</p><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Data Preprocessing</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">6 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="" class="dz" src="../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*T1bcJ8sv5Rc1lsOyGS1nig.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="Cartoon illustration of two figures embracing, with letters â€˜Aâ€™, â€˜Bâ€™, â€˜Câ€™ and numbers â€˜1â€™, â€˜2â€™, â€˜3â€™ floating around them. A pink heart hovers above, symbolizing affection. The background is a pixelated pattern of blue and green squares, representing data or encoding. This image metaphorically depicts the concept of encoding categorical data, where categories (ABC) are transformed into numerical representations (123)." class="dz" src="../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2_cXKHvfaBTVpDrmz5r5vQ.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="A cartoon illustration representing data scaling in machine learning. A tall woman (representing a numerical feature with a large range) is shown shrinking into a child (representing the same feature after scaling to a smaller range). A red arrow indicates the shrinking process, and yellow sparkles around the child signify the positive impact of scaling." class="dz" src="../Images/d261b2c52a3cafe266d1962d4dbabdbd.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*MkX5TTTS1oZhY2eW6AdEkg.png"/></div></div></div></div></div><p id="595f" class="pw-post-body-paragraph nc nd fq ne b gt nf ng nh gw ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:</p><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Classification Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">8 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="" class="dz" src="../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*eVxxKT4DKvRVuAHBGknJ7w.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="" class="dz" src="../Images/6ea70d9d2d9456e0c221388dbb253be8.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uFvDKl3iA2_G961vw5QFpg.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="" class="dz" src="../Images/7221f0777228e7bcf08c1adb44a8eb76.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1TbEIdTs_Z8V_TPD9MXxJw.png"/></div></div></div></div></div><div class="rd re rf rg rh"><div role="button" tabindex="0" class="ab bx cp kj it ri rj bp rk lw ao"><div class="rl l"><div class="ab q"><div class="l ed"><img alt="Samy Baladram" class="l ep by rm rn cx" src="../Images/835013c69e08fec04ad9ca465c2adf6c.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*M5J7CK552m9f4z-m1F7vYg.png"/><div class="el by l rm rn em n ay ty"/></div><div class="ro l il"><p class="bf b dy z it iu iv iw ix iy iz ja dx"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@samybaladram?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">Samy Baladram</a></p></div></div><div class="cq rr hp l"><h2 class="bf ga ww ic it wx iv iw wy iy ja fz bk">Regression Algorithms</h2></div><div class="ab q"><div class="l il"><a class="bf b dy z bk wz vy vz wa wb lj wc wd uj ii we wf wg un uo up ep bm uq oe" href="https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----f056af9102fa--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="xa l il"><span class="bf b dy z dx">5 stories</span></div></div></div><div class="sa dz sb it ab sc il ed"><div class="ed ru bx rv rw"><div class="dz l"><img alt="A cartoon doll with pigtails and a pink hat. This â€œdummyâ€ doll, with its basic design and heart-adorned shirt, visually represents the concept of a dummy regressor in machine. Just as this toy-like figure is a simplified, static representation of a person, a dummy regressor is a basic models serve as baselines for more sophisticated analyses." class="dz" src="../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qMSGk19S51CXGl3DiAGuKw.png"/></div></div><div class="ed ru bx kk rx ry"><div class="dz l"><img alt="" class="dz" src="../Images/44e6d84e61c895757ff31e27943ee597.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*nMaPpVdNqCci31YmjfCMRQ.png"/></div></div><div class="ed bx hx rz ry"><div class="dz l"><img alt="" class="dz" src="../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*qTpdMoaZClu-KDV3nrZDMQ.png"/></div></div></div></div></div></div></div></div></div>    
</body>
</html>