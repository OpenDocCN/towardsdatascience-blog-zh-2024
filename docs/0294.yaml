- en: Fine Tuning LLMs on a Single Consumer Graphic Card
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/fine-tuning-llms-on-a-single-consumer-graphic-card-6de1587daddb?source=collection_archive---------2-----------------------#2024-01-31](https://towardsdatascience.com/fine-tuning-llms-on-a-single-consumer-graphic-card-6de1587daddb?source=collection_archive---------2-----------------------#2024-01-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GENERATIVE AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Learnings from fine-tuning a large language model on a single consumer GPU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://tamimi-naser.medium.com/?source=post_page---byline--6de1587daddb--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page---byline--6de1587daddb--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6de1587daddb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6de1587daddb--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page---byline--6de1587daddb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6de1587daddb--------------------------------)
    ·10 min read·Jan 31, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6ec03b837f13b9f080ccff02926db486.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (Midjourney).
  prefs: []
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we think about Large Language Models or any other generative models, the
    first hardware that comes to mind is GPU. Without GPUs, many advancements in Generative
    AI, machine learning, deep learning, and data science would’ve been impossible.
    If 15 years ago, gamers were enthusiastic about the latest GPU technologies, today
    data scientists and machine learning engineers join them and pursue the news in
    this field too. Although usually gamers and ML users are looking at two different
    kinds of GPUs and graphic cards.
  prefs: []
  type: TYPE_NORMAL
- en: Gaming users usually use consumer graphic cards (such as NVIDIA GeForce RTX
    Series GPUs), while ML and AI developers usually follow news about Data Center
    and Cloud Computing GPUs (such as V100, A100, or H100). Gaming graphic cards usually
    have much less GPU memory (at most 24GB as of January 2024) compared to Data Center
    GPUs (in the range of 40GB to 80GB usually). Also, their price is another significant
    difference. While most consumer graphic cards could be up to $3000, most Data
    Center graphic cards start from that price and can go tens of thousands of dollars
    easily.
  prefs: []
  type: TYPE_NORMAL
