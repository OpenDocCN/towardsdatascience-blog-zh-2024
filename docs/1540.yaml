- en: Transforming Next-Token Prediction into Classification with LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/transforming-next-token-prediction-into-classification-with-llms-fb4f33a02637?source=collection_archive---------3-----------------------#2024-06-20](https://towardsdatascience.com/transforming-next-token-prediction-into-classification-with-llms-fb4f33a02637?source=collection_archive---------3-----------------------#2024-06-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'From tokens to labels: Performing classification with large language models'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@yuchengtsai84?source=post_page---byline--fb4f33a02637--------------------------------)[![Yu-Cheng
    Tsai](../Images/c0ec2d4b9fea512040c8e6e0250670fc.png)](https://medium.com/@yuchengtsai84?source=post_page---byline--fb4f33a02637--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--fb4f33a02637--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--fb4f33a02637--------------------------------)
    [Yu-Cheng Tsai](https://medium.com/@yuchengtsai84?source=post_page---byline--fb4f33a02637--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--fb4f33a02637--------------------------------)
    ·6 min read·Jun 20, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7df3c282346bf90d1b8ab34a4d1fd47.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Myles Bloomfield](https://unsplash.com/@loomydoons?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Free [link](https://medium.com/towards-data-science/transforming-next-token-prediction-into-classification-with-llms-fb4f33a02637?sk=c5693c58c60d47d6a1846cbafffd1b8a)!
    Thanks and please enjoy the read. :)
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs), trained on vast amounts of internet data, are
    versatile and can perform a wide range of natural language tasks. One common application
    is classification, a supervised learning task that categorizes subjects into pre-defined
    labels. [Zero-shot](https://huggingface.co/tasks/zero-shot-classification) and
    f[ew-shots classification](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api)
    have become popular techniques, enabling LLMs to perform classification tasks
    with no training data or a few examples. However, for better accuracy, it is demonstrated
    that instruction fine-tuning can improve the performance by tuning LLMs with curated
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Instruction Fine-Tuning LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The common practice for instruction fine-tuning involves constructing a dataset
    consisting of question-and-answer pairs. Pre-trained LLMs are then further fine-tuned
    using these pairs in a supervised manner.
  prefs: []
  type: TYPE_NORMAL
- en: You can check my previous post for this approach.
  prefs: []
  type: TYPE_NORMAL
