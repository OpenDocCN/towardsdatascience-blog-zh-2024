- en: Optimizing Deep Learning Models with Weight Quantization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过权重量化优化深度学习模型
- en: 原文：[https://towardsdatascience.com/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1?source=collection_archive---------4-----------------------#2024-06-07](https://towardsdatascience.com/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1?source=collection_archive---------4-----------------------#2024-06-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1?source=collection_archive---------4-----------------------#2024-06-07](https://towardsdatascience.com/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1?source=collection_archive---------4-----------------------#2024-06-07)
- en: Practical application of weight quantization and its impact on model size and
    performance.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 权重量化的实际应用及其对模型大小和性能的影响。
- en: '[](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)[![Chien
    Vu](../Images/ba70374c28ea91c1941a0a8f1402712f.png)](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)
    [Chien Vu](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)[![Chien
    Vu](../Images/ba70374c28ea91c1941a0a8f1402712f.png)](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)
    [Chien Vu](https://medium.com/@chienvu?source=post_page---byline--c786ffc6d6c1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)
    ·14 min read·Jun 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[数据科学前沿](https://towardsdatascience.com/?source=post_page---byline--c786ffc6d6c1--------------------------------)
    ·阅读时间14分钟·2024年6月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/07929b8bc2ee3b934b4cc36b0248e5f1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07929b8bc2ee3b934b4cc36b0248e5f1.png)'
- en: Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: 📚What is Quantization in Deep Learning?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📚什么是深度学习中的量化？
- en: Why do we need Quantization?
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为什么我们需要量化？
- en: Let’s talk about quantization in deep learning. Have you ever wondered why quantization
    is important, especially in deep learning? Even though deep learning and large
    language models (LLMs) are super powerful, they come with many challenges. As
    these models are large, they can be pretty demanding — they need a lot of computational
    power and memory, making it tough to use them in places with limited resources.
    Moreover, they can even use up a lot of energy when making predictions, which
    makes it become impossible to inference if there is limited computational resource.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈深度学习中的量化。你是否曾经想过，为什么量化在深度学习中如此重要？尽管深度学习和大型语言模型（LLMs）非常强大，但它们也面临许多挑战。由于这些模型非常庞大，它们的计算需求也相当高——需要大量的计算能力和内存，这使得在资源有限的地方使用它们变得十分困难。此外，在进行预测时，它们甚至可能消耗大量能源，这就导致如果计算资源有限，推理变得不可能。
- en: Quantization helps deal with these issues by resizing the model to make it more
    manageable, at the same time be able to reserve almost its performance. This involves
    revising the number of model parameters and the precision of the data types. By
    doing this, the models become lighter and faster, which means they can run in
    more places and use less energy.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 量化通过调整模型大小，使其更加易于管理，同时几乎不影响其性能，帮助解决这些问题。这涉及到修改模型参数的数量和数据类型的精度。通过这种方式，模型变得更轻便、更快速，这意味着它们可以在更多地方运行并消耗更少的能源。
