["```py\ngit clone git@github.com:HamzaG737/legal-code-rag.git\n```", "```py\ncurl -sSL https://install.python-poetry.org | python3 -\n```", "```py\npoetry install\n```", "```py\n{'content': \"Ni le propriétaire, ni l'usufruitier, ne sont tenus de rebâtir ce qui est tombé de vétusté, ou ce qui a été détruit par cas fortuit.\",\n 'num': '607',\n 'livre': 'Des biens et des différentes modifications de la propriété',\n 'titre': \"De l'usufruit, de l'usage et de l'habitation\",\n 'chapitre': \"De l'usufruit\",\n 'section': \"Des obligations de l'usufruitier\"}\n```", "```py\n{\n  \"content\": \"Neither the owner nor the usufructuary are required to rebuild what has fallen into disrepair or what has been destroyed by an act of chance.\",\n  \"num\": \"607\",\n  \"book\": \"Of Property and the Various Modifications of Ownership\",\n  \"title\": \"Of Usufruct, Use and Habitation\",\n  \"chapter\": \"Of Usufruct\",\n  \"section\": \"The Obligations of the Usufructuary\"\n}\n```", "```py\nfrom dataclasses import dataclass\nfrom typing import List\nimport os\nfrom uuid import uuid4\nfrom llama_index.core.schema import TextNode\n\nfrom loguru import logger\n\nfrom utils import load_json\nfrom .preprocess_legifrance_data import get_code_articles\nfrom .constants import path_dir_data\n\n@dataclass\nclass CodeNodes:\n    code_name: str\n    max_words_per_node: int = 4000\n    _n_truncated_articles: int = 0\n    ...\n\n    def __post_init__(self):\n        self.articles = self.try_load_data()\n        self.nodes = self.create_nodes(self.articles)\n        ...\n\n    def create_nodes(self, list_articles: List[dict]):\n        nodes = [\n            TextNode(\n                text=article[\"content\"],\n                id_=str(uuid4()),\n                metadata=self._parse_metadata(article),\n            )\n            for article in list_articles\n        ]\n\n        return nodes\n\n    def try_load_data(self) -> List[dict]:\n        path = os.path.join(path_dir_data, f\"{self.code_name}.json\")\n        try:\n            code_articles = load_json(path=path)\n        except FileNotFoundError:\n            logger.warning(\n                f\"File not found at path {path}. Fetching data from Legifrance.\"\n            )\n            code_articles = get_code_articles(code_name=self.code_name)\n        truncated_articles = self._chunk_long_articles(code_articles)\n        return truncated_articles\n\n    def _parse_metadata(self, article: dict) -> dict:\n        metadata = {k: v for k, v in article.items() if k not in [\"content\", \"num\"]}\n        metadata = {\n            \"Nom du code\": self.code_name,\n            **metadata,\n            \"Article numero\": article[\"num\"],\n        }\n        return metadata\n\n    def _chunk_long_articles(self, articles: List[dict]) -> List[dict]:\n        ...\n```", "```py\nTextNode(\n  id_='c0ee164f-ae58-47c8-8e5b-e82f55ac98a9',\n  embedding=None,\n  metadata={\n    'Nom du code': 'Code civil',\n    'livre': 'Des différentes manières dont on acquiert la propriété',\n    'titre': 'Des libéralités',\n    'chapitre': 'Des dispositions testamentaires.',\n    'section': 'Du legs universel.',\n    'id': '1003',\n    'Article numero': '1003'\n  },\n  excluded_embed_metadata_keys=[],\n  excluded_embed_metadata_keys=[],\n  relationships={},\n  text=\"Le legs universel est la disposition testamentaire par laquelle le testateur donne à une ou plusieurs personnes l'universalité des biens qu'il laissera à son décès.\",\n  start_char_idx=None,\n  end_char_idx=None,\n  text_template='{metadata_str}\\n\\n{content}',\n  metadata_template='{key}: {value}',\n  metadata_seperator='\\n'\n) \n```", "```py\ndocker pull qdrant/qdrant\n```", "```py\ndocker run -p 6333:6333 -p 6334:6334 \\\n    -v $(pwd)/qdrant_storage:/qdrant/storage:z \\\n    qdrant/qdrant\n```", "```py\nfrom qdrant_client import QdrantClient\n\nclient = QdrantClient(\"localhost\", port=6333)\n```", "```py\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.core import StorageContext\nfrom llama_index.embeddings.mistralai import MistralAIEmbedding\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.embeddings.fastembed import FastEmbedEmbedding\nfrom llama_index.vector_stores.qdrant import QdrantVectorStore\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http.exceptions import UnexpectedResponse\nfrom loguru import logger\n\nfrom data_ingestion.nodes_processing import CodeNodes\n\ndef index_given_nodes(\n    code_nodes: CodeNodes,\n    embedding_model: MistralAIEmbedding | OpenAIEmbedding | FastEmbedEmbedding,\n    hybrid_search: bool,\n    recreate_collection: bool = False,\n) -> VectorStoreIndex:\n    \"\"\"\n    Given a list of nodes, create a new index or use an existing one. \n\n    Parameters\n    ----------\n    code_nodes : CodeNodes\n        The nodes to index.\n    embedding_model : MistralAIEmbedding | OpenAIEmbedding | FastEmbedEmbedding\n        The embedding model to use.\n    hybrid_search : bool\n        Whether to enable hybrid search.\n    recreate_collection : bool, optional\n        Whether to recreate the collection, by default False.\n\n    \"\"\"\n\n    collection_name = code_nodes.nodes_config\n    client = QdrantClient(\"localhost\", port=6333)\n    if recreate_collection:\n        client.delete_collection(collection_name)\n\n    try:\n        count = client.count(collection_name).count\n    except UnexpectedResponse:\n        count = 0\n\n    if count == len(code_nodes.nodes):\n        logger.info(f\"Found {count} existing nodes. Using the existing collection.\")\n        vector_store = QdrantVectorStore(\n            collection_name=collection_name,\n            client=client,\n            enable_hybrid=hybrid_search,\n        )\n        return VectorStoreIndex.from_vector_store(\n            vector_store,\n            embed_model=embedding_model,\n        )\n    logger.info(\n        f\"Found {count} existing nodes. Creating a new index with {len(code_nodes.nodes)} nodes. This may take a while.\"\n    )\n    if count > 0:\n        client.delete_collection(collection_name)\n\n    vector_store = QdrantVectorStore(\n        collection_name=collection_name,\n        client=client,\n        enable_hybrid=hybrid_search,\n    )\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n    index = VectorStoreIndex(\n        code_nodes.nodes,\n        storage_context=storage_context,\n        embed_model=embedding_model,\n    )\n    return index\n```", "```py\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\nindex = VectorStoreIndex(\n        code_nodes.nodes,\n        storage_context=storage_context,\n        embed_model=embedding_model,\n    )\n```", "```py\nindex = VectorStoreIndex.from_vector_store(\n            vector_store,\n            embed_model=embedding_model,\n        )\n```", "```py\nfrom llama_index.core.query_engine import BaseQueryEngine\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.core import PromptTemplate\n\ndef get_query_engine_based_on_index(\n    index: VectorStoreIndex,\n    similarity_top_k: int = 5,\n) -> BaseQueryEngine:\n\n    query_engine = index.as_query_engine(similarity_top_k=similarity_top_k)\n\n    query_engine = update_prompts_for_query_engine(query_engine)\n    return query_engine\n```", "```py\ndef update_prompts_for_query_engine(query_engine: BaseQueryEngine) -> BaseQueryEngine:\n\n    new_tmpl_str = (\n        \"Below is the specific context required to answer the upcoming query. You must base your response solely on this context, strictly avoiding the use of external knowledge or assumptions..\\n\"\n        \"---------------------\\n\"\n        \"{context_str}\\n\"\n        \"---------------------\\n\"\n        \"Given this context, please formulate your response to the following query. It is imperative that your answer explicitly mentions any relevant code name and article number by using the format 'according to code X and article Y,...'. Ensure your response adheres to these instructions to maintain accuracy and relevance.\"\n        \"Furthermore, it is crucial to respond in the same language in which the query is presented. This requirement is to ensure the response is directly applicable and understandable in the context of the query provided.\"\n        \"Query: {query_str}\\n\"\n        \"Answer: \"\n    )\n    new_tmpl = PromptTemplate(new_tmpl_str)\n    query_engine.update_prompts({\"response_synthesizer:text_qa_template\": new_tmpl})\n    return query_engine\n```", "```py\nfrom query.query_engine import create_query_engine\n\nquery_engine = create_query_engine()\n\nresponse = query_engine.query(\"What are the conditions required for a marriage to be considered valid ?\")\n\nprint(response)\n```", "```py\nfrom typing import Any, Optional, Sequence\n\nfrom llama_index.core.evaluation import ContextRelevancyEvaluator, EvaluationResult\nfrom llama_index.core.response import Response\nfrom llama_index.core.schema import MetadataMode\n\nclass CustomContextRelevancyEvaluator(ContextRelevancyEvaluator):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n\n    def evaluate_response(\n        self,\n        query: Optional[str] = None,\n        response: Optional[Response] = None,\n        metadata_mode: MetadataMode = MetadataMode.ALL,\n        **kwargs: Any,\n    ) -> EvaluationResult:\n        \"\"\"Run evaluation with query string and generated Response object.\n\n        Subclasses can override this method to provide custom evaluation logic and\n        take in additional arguments.\n        \"\"\"\n        response_str: Optional[str] = None\n        contexts: Optional[Sequence[str]] = None\n        if response is not None:\n            response_str = response.response\n            contexts = [\n                node.get_content(metadata_mode=metadata_mode)\n                for node in response.source_nodes\n            ]\n\n        return self.evaluate(\n            query=query, response=response_str, contexts=contexts, **kwargs\n        )\n```", "```py\nfrom typing import Literal, List\n\nfrom llama_index.core.query_engine import BaseQueryEngine\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core.evaluation import EvaluationResult\nfrom llama_index.core.schema import MetadataMode\nfrom tqdm import tqdm\n\nfrom utils import load_json\nfrom evaluation.custom_evaluators import CustomContextRelevancyEvaluator\n\nPATH_EVAL_CODE_CIVIL = \"./data/questions_code_civil.json\"\nPATH_EVAL_CODE_DE_LA_ROUTE = \"./data/questions_code_de_la_route.json\"\n\ndef evaluate_one_metric(\n    query_engine: BaseQueryEngine,\n    code_name: Literal[\"code_civil\", \"code_de_la_route\"],\n    metadata_mode: MetadataMode,\n    llm_for_eval: str = \"gpt-3.5-turbo\",\n) -> List[EvaluationResult]:\n\n    evaluator = CustomContextRelevancyEvaluator(\n        llm=OpenAI(temperature=0, model=llm_for_eval)\n    )\n\n    eval_data: List[str] = load_json(globals()[f\"PATH_EVAL_{code_name.upper()}\"])\n\n    results = []\n    for question in tqdm(eval_data):\n        response = query_engine.query(question)\n        eval_result = evaluator.evaluate_response(\n            query=question, response=response, metadata_mode=metadata_mode\n        )\n\n        results.append(eval_result)\n\n    return results\n```", "```py\nfrom llama_index.embeddings.fastembed import FastEmbedEmbedding\n\nembeddings_model_name = \"intfloat/multilingual-e5-large\"\nembed_model = FastEmbedEmbedding(model_name=embeddings_model_name)\n```", "```py\nfrom query.query_engine import create_query_engine\nfrom evaluation.eval_with_llamaindex import evaluate_multiple_experiments\n\nquery_engine_fastembed = create_query_engine(embedding_model=\"intfloat/multilingual-e5-large\")\nquery_engine_mistral = create_query_engine(embedding_model=\"mistral-embed\")\nquery_engine_ada = create_query_engine(embedding_model=\"text-embedding-ada-002\")\n\nexp_to_query_engine = {\n    \"mistral_embed\": query_engine_mistral,\n    \"fastembed\": query_engine_fastembed,\n    \"ada\": query_engine_ada,\n}\n\nscores_df, deeps_df = evaluate_multiple_experiments(\n    experiment_to_query_engine=exp_to_query_engine,\n    general_exp_name=\"embeddings\",\n    list_metrics=[\"context_relevancy\"],\n    code_name=\"code_civil\"\n)\n```", "```py\nfrom typing import List\nfrom llama_index.core.schema import TextNode\nfrom tqdm import tqdm\n\nfrom .constants import possible_headers\n\nWINDOW_METADATA_KEY = \"window\"\nORIGINAL_TEXT_METADATA_KEY = \"original_text\"\n\ndef add_window_nodes(nodes: List[TextNode], window_size: int = 3):\n    for i, node in tqdm(\n        enumerate(nodes), total=len(nodes), desc=\"Adding window nodes ...\"\n    ):\n        window_nodes = nodes[\n            max(0, i - window_size) : min(i + window_size + 1, len(nodes))\n        ]\n\n        node.metadata[WINDOW_METADATA_KEY] = \"\\n\".join(\n            [n.get_content(\"llm\") for n in window_nodes]\n        )\n        node.metadata[ORIGINAL_TEXT_METADATA_KEY] = node.text\n\n        # exclude window metadata from embed and llm\n        node.excluded_embed_metadata_keys.extend(\n            [WINDOW_METADATA_KEY, ORIGINAL_TEXT_METADATA_KEY]\n        )\n\n        node.excluded_llm_metadata_keys.extend(\n            [WINDOW_METADATA_KEY, ORIGINAL_TEXT_METADATA_KEY]\n        )\n\n    # since articles metadata (like title, chapter, etc ...) will be incorporated in WINDOW_METADATA_KEY,\n    # we can exclude them from the llm metadata.\n\n    for node in nodes:\n        node.excluded_llm_metadata_keys.extend(possible_headers)\n\n    return nodes\n```", "```py\nfrom dataclasses import dataclass\nfrom typing import List\nfrom llama_index.core.postprocessor import MetadataReplacementPostProcessor\n\nfrom loguru import logger\n\nfrom .window_nodes import add_window_nodes\n\n@dataclass\nclass CodeNodes:\n    code_name: str\n    use_window_nodes: bool\n    nodes_window_size: int = 3\n    max_words_per_node: int = 4000\n    _n_truncated_articles: int = 0\n\n    def __post_init__(self):\n        self.articles = self.try_load_data()\n        self.nodes = self.create_nodes(self.articles)\n        code_name_no_spaces = self.code_name.replace(\" \", \"_\")\n        self.nodes_config = f\"{code_name_no_spaces}_base\"\n        self.post_processors = []\n        if self.use_window_nodes:\n            logger.info(\"Adding window nodes ...\")\n            self.nodes = add_window_nodes(self.nodes, self.nodes_window_size)\n            self.nodes_config = f\"{code_name_no_spaces}_window\"\n            self.post_processors.append(\n                MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n            )\n\n    def create_nodes(self, list_articles: List[dict]): ...\n\n    def try_load_data(self) -> List[dict]: ...\n\n    def _parse_metadata(self, article: dict) -> dict: ...\n\n    def _chunk_long_articles(self, articles: List[dict]) -> List[dict]: ...\n```", "```py\nfrom llama_index.core.query_engine import BaseQueryEngine\nfrom llama_index.core import VectorStoreIndex\n\ndef get_query_engine_based_on_index(\n    index: VectorStoreIndex,\n    postprocessors_list: list,\n    similarity_top_k: int = 5,\n) -> BaseQueryEngine:\n\n    query_engine = index.as_query_engine(\n        similarity_top_k=similarity_top_k, node_postprocessors=postprocessors_list\n    )\n\n    query_engine = update_prompts_for_query_engine(query_engine)\n    return query_engine\n```", "```py\nvector_store = QdrantVectorStore(\n    collection_name=collection_name,\n    client=client,\n    enable_hybrid=True,\n)\n```", "```py\nquery_engine = index.as_query_engine(\n    similarity_top_k=5, \n    sparse_top_k=5, \n    vector_store_query_mode=\"hybrid\", \n    **kwargs\n)\n```", "```py\nquery_engine = index.as_query_engine(\n    similarity_top_k=5, \n    sparse_top_k=5, \n    alpha=0.5,\n    vector_store_query_mode=\"hybrid\", \n    **kwargs\n)\n```", "```py\nfrom llama_index.core.query_engine import BaseQueryEngine, RetrieverQueryEngine\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.core.retrievers import QueryFusionRetriever\n\nfrom query.constants import QUERY_GEN_PROMPT\n\ndef get_query_fusion_retrieval(\n    index: VectorStoreIndex,\n    postprocessors_list: list,\n    similarity_top_k: int = 5,\n    sparse_top_k: int = 0,\n    hybrid_search_alpha: float = 0.5,\n    hybrid_search: bool = False,\n    num_generated_questions: int = 4,\n) -> BaseQueryEngine:\n    kwargs = {\"similarity_top_k\": similarity_top_k}\n    if hybrid_search:\n        kwargs.update(\n            {\n                \"vector_store_query_mode\": \"hybrid\",\n                \"sparse_top_k\": sparse_top_k,\n                \"alpha\": hybrid_search_alpha,\n            }\n        )\n\n    retriever = index.as_retriever(**kwargs)\n\n    retriever = QueryFusionRetriever(\n        [retriever],\n        similarity_top_k=similarity_top_k,\n        num_queries=num_generated_questions,  # set this to 1 to disable query generation\n        mode=\"reciprocal_rerank\",\n        use_async=False,\n        verbose=False,\n        query_gen_prompt=QUERY_GEN_PROMPT,\n    )\n\n    query_engine = RetrieverQueryEngine.from_args(\n        retriever=retriever, node_postprocessors=postprocessors_list\n    )\n    query_engine = update_prompts_for_query_engine(query_engine)\n    return query_engine\n```", "```py\nQUERY_GEN_PROMPT = (\n    \"You are a helpful assistant that generates multiple search queries based on a \"\n    \"single input query. Generate {num_queries} search queries, one on each line, \"\n    \"related to the following input query. The queries must be in French and specifically \"\n    \"adapted to query the French Civil Code, and they must address the ambiguities in the input query:\\n\"\n    \"Query: {query}\\n\"\n    \"Queries:\\n\"\n)\n```", "```py\n[\n    \"C'est quoi un contrat de mariage?\",\n    \"On peut changer de prénom facilement?\",\n    \"Qu'est-ce qui se passe si on trouve un trésor chez quelqu'un d'autre?\",\n    \"Comment on fait pour adopter un enfant?\",\n    \"C'est quoi exactement une servitude?\",\n    \"Si je construis un truc chez le voisin sans faire exprès, je dois le démolir?\",\n]\n```", "```py\n[\n    \"What is a marriage contract?\",\n    \"Can we change our first name easily?\",\n    \"What happens if we find a treasure on someone else's property?\",\n    \"How do we adopt a child?\",\n    \"What exactly is an easement?\",\n    \"If I accidentally build something on the neighbor's property, do I have to demolish it?\",\n]\n```", "```py\n 1 - What are the legal procedures for refusing an inheritance according to the French Civil Code?\n2 - What are the rights and obligations of an heir who wishes to renounce a succession in France?\n3 - How does the renunciation of an inheritance proceed under the French Civil Code?\n```", "```py\ncodes_to_description = {\n    \"Code civil\": \"Code civil: code juridique qui regroupe les lois relatives au droit civil français, c’est-à-dire l'ensemble des règles qui déterminent le statut des personnes (livre Ier), celui des biens (livre II) et celui des relations entre les personnes privées (livres III et IV).\",\n    \"Code général des impôts\": \"Code général des impôts: code juridique qui regroupe les lois relatives aux impôts en France, c’est-à-dire l'ensemble des règles qui déterminent les impôts et les taxes.\",\n    \"Code de la propriété intellectuelle\": \"Code de la propriété intellectuelle: code juridique qui regroupe les lois relatives à la propriété intellectuelle en France, c’est-à-dire l'ensemble des règles qui déterminent les droits des auteurs, des artistes-interprètes, des producteurs de phonogrammes et de vidéogrammes et des entreprises de communication audiovisuelle.\",\n    \"Code de la route\": \"Code de la route: code juridique qui regroupe les lois relatives à la circulation routière en France, c’est-à-dire l'ensemble des règles qui déterminent les droits et les devoirs des usagers de la route.\",\n    \"Code du travail\": \"Code du travail: code juridique qui regroupe les lois relatives au droit du travail en France, c’est-à-dire l'ensemble des règles qui déterminent les droits et les devoirs des employeurs et des salariés.\",\n}\n```", "```py\nfrom llama_index.core.tools import QueryEngineTool\n\nfrom query.query_engine import create_query_engine\n\ndef get_tools():\n    tools = []\n    for code_name, code_description in codes_to_description.items():\n        query_engine = create_query_engine(code_name=code_name)\n        tool = QueryEngineTool.from_defaults(\n            query_engine=query_engine,\n            description=code_description,\n        )\n        tools.append(tool)\n    return tools\n```", "```py\nfrom llama_index.core.query_engine import RouterQueryEngine\nfrom llama_index.core.selectors import LLMMultiSelector\n\ndef create_routing_engine():\n    query_engine_tools = get_tools()\n    query_engine = RouterQueryEngine(\n        selector=LLMMultiSelector.from_defaults(),\n        query_engine_tools=query_engine_tools,\n    )\n    return query_engine\n```", "```py\nQuelles sont les conditions pour bénéficier d'un congé sabbatique \\n Comment sont imposées les plus-values immobilières\n```", "```py\nWhat are the conditions to qualify for a sabbatical leave? \\n How are capital gains on real estate taxed?\n```", "```py\n{\n  \"response\": \"Pour bénéficier d'un congé sabbatique, le salarié doit justifier d'une ancienneté minimale dans l'entreprise, cumulée sur plusieurs périodes non consécutives, ainsi que de six années d'activité professionnelle. De plus, il ne doit pas avoir bénéficié depuis une durée minimale, dans la même entreprise, d'un congé sabbatique, d'un congé pour création d'entreprise ou d'un congé spécifique d'une durée d'au moins six mois.\\n\\nLes plus-values provenant de la cession en cours d'exploitation des éléments de l'actif immobilisé et réalisées avant l'entrée en vigueur des dispositions spécifiques ne sont pas comprises dans le bénéfice imposable si le contribuable s'engage à réinvestir dans des immobilisations dans son entreprise dans un délai de trois ans.\",\n  \"source_nodes\": [\n    {\n      ....\n      \"text\": \"A défaut de convention ou d'accord mentionné à l'article L. 3142-32, le salarié informe l'employeur de la date de départ en congé sabbatique qu'il a choisie et de la durée de ce congé, par tout moyen conférant date certaine, au moins trois mois à l'avance.\"\n    },\n    {\n      ....\n      \"text\": \"L'employeur informe le salarié de son accord sur la date de départ choisie du congé sabbatique ou de son report par tout moyen conférant date certaine.\"\n    },\n    {\n      ....\n      \"text\": \"A défaut de convention ou d'accord mentionné à l'article L. 3142-32, le départ en congé peut être différé par l'employeur dans les conditions mentionnées au premier alinéa de l'article L. 3142-29, de telle sorte que le pourcentage des salariés simultanément absents de l'entreprise au titre du congé sabbatique ne dépasse pas 1,5 % de l'effectif de cette entreprise, jusqu'à la date à laquelle cette condition de taux est remplie ou que le nombre de jours d'absence au titre du congé sabbatique ne dépasse pas 1,5 % du nombre de jours de travail effectués dans les douze mois précédant le départ en congé. Pour permettre le départ en congé d'un salarié, cette période de douze mois est prolongée dans la limite de quarante-huit mois.\"\n    },\n    {\n      ....\n      \"text\": \"Le salarié a droit à un congé sabbatique pendant lequel son contrat de travail est suspendu.\\nLe droit à ce congé est ouvert au salarié justifiant, à la date de départ en congé, d'une ancienneté minimale dans l'entreprise, cumulée, le cas échéant, sur plusieurs périodes non consécutives, ainsi que de six années d'activité professionnelle et n'ayant pas bénéficié depuis une durée minimale, dans la même entreprise, d'un congé sabbatique, d'un congé pour création d'entreprise ou d'un congé spécifique mentionné à l'article L. 6323-17-1 d'une durée d'au moins six mois. L'ancienneté acquise dans toute autre entreprise du même groupe, au sens de l'article L. 2331-1, est prise en compte au titre de l'ancienneté dans l'entreprise.\"\n    }, ...\n  ],\n  \"metadata\": {\n    \"selector_result\": {\n      \"selections\": [\n        {\n          \"index\": 4,\n          \"reason\": \"Le Code du travail regroupe les lois relatives au droit du travail en France, ce qui inclut les conditions pour bénéficier d'un congé sabbatique.\"\n        },\n        {\n          \"index\": 1,\n          \"reason\": \"Le Code général des impôts regroupe les lois relatives aux impôts en France, ce qui inclut les règles sur l'imposition des plus-values immobilières.\"\n        }\n      ]\n    }\n  }\n}\n```"]