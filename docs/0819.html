<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Benchmark and Taxonomy of Categorical Encoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>A Benchmark and Taxonomy of Categorical Encoders</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-benchmark-and-taxonomy-of-categorical-encoders-9b7a0dc47a8c?source=collection_archive---------6-----------------------#2024-03-29">https://towardsdatascience.com/a-benchmark-and-taxonomy-of-categorical-encoders-9b7a0dc47a8c?source=collection_archive---------6-----------------------#2024-03-29</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="b5bb" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">New. Comprehensive. Extendable.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@vadim.arzamasov?source=post_page---byline--9b7a0dc47a8c--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Vadim Arzamasov" class="l ep by dd de cx" src="../Images/70ced2eafa6fc926052979875a0a4265.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*sLla8xXL0qQuaiNDqAnTiw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9b7a0dc47a8c--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@vadim.arzamasov?source=post_page---byline--9b7a0dc47a8c--------------------------------" rel="noopener follow">Vadim Arzamasov</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9b7a0dc47a8c--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 29, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/1468cfa0cf9668807f9c2fa1088108b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bXer7VY3RT9gBppCrhOpQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image created by author with recraft.ai</figcaption></figure><p id="b0fe" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">A large share of datasets contain categorical features. For example, out of 665 datasets on the <a class="af nx" href="https://archive.ics.uci.edu/" rel="noopener ugc nofollow" target="_blank">UC Irvine Machine Learning Repository</a> [1], 42 are fully categorical and 366 are reported as mixed. However, distance-based ML models and almost all <a class="af nx" href="https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features" rel="noopener ugc nofollow" target="_blank">scikit-learn implementations</a> require features in a numerical format. Categorical encoders replace the categories in such features with real numbers.</p><p id="aa9d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">A variety of categorical encoders exist, but there have been few attempts to compare them on many datasets, with various ML models, and in different pipelines. This article is about one of the latest benchmarks of encoders from our <a class="af nx" href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac01e21bb14609416760f790dd8966ae-Abstract-Datasets_and_Benchmarks.html" rel="noopener ugc nofollow" target="_blank">recent publication</a> [2] (<a class="af nx" href="https://nips.cc/media/PosterPDFs/NeurIPS%202023/73555.png?t=1699521284.38544" rel="noopener ugc nofollow" target="_blank">poster</a>, <a class="af nx" href="https://github.com/DrCohomology/EncoderBenchmarking" rel="noopener ugc nofollow" target="_blank">code on GitHub</a>). In this story, I focus on the content that complements the publication and is of practical importance. In particular, beyond the summary of our benchmark results, I will:</p><ul class=""><li id="05e8" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Provide a list of 55 categorical encoders and the links to find their explanations and implementations for most of them.</li><li id="1af9" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Explain that you can also use our code as a supplement to the <code class="cx og oh oi oj b"><a class="af nx" href="https://contrib.scikit-learn.org/category_encoders/" rel="noopener ugc nofollow" target="_blank">Category Encoders</a></code>python module for the encoders not yet implemented there.</li><li id="6160" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Categorize the encoders into families so that you do not have to remember each individual encoder, but instead have an idea of how to build a member of each family.</li><li id="cddd" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Explain how you can reuse the code from [2] and detailed benchmark data to include your encoder, dataset, or ML models in the comparison without having to re-run the existing experiments. Depending on the scope of your experiments and your computational resources, this can save you weeks of computation.</li></ul><h2 id="ef25" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk"><strong class="al">Why another benchmark?</strong></h2><p id="e289" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">There are already several scientific studies comparing categorical encoders [3–12] and at least one categorical encoder <a class="af nx" rel="noopener" target="_blank" href="/benchmarking-categorical-encoders-9c322bd77ee8">benchmark on TDS</a> [13]. The study [2] that I will present here differs mainly in scope: We compared representative encoders in different configurations from a variety of encoder families. We experimented with <strong class="nd fr">5</strong> ML models (decision tree, kNN, SVM, logistic regression, LGBM), <strong class="nd fr">4</strong> quality metrics (AUC, accuracy, balanced accuracy, F1-score), <strong class="nd fr">3</strong> tuning strategies (which I will describe shortly), <strong class="nd fr">50 </strong>datasets, and <strong class="nd fr">32</strong> encoder configurations.</p><p id="a7a8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The following table shows the encoders covered in our benchmark (the dark green column) and in other experimental comparisons (the light green columns). The blue columns show the encoders described in two additional sources: in the article dedicated to contrast encoders [15] and on Medium [14]:</p><div class="pk pl pm pn po pp"><a href="https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe?source=post_page-----9b7a0dc47a8c--------------------------------" rel="noopener follow" target="_blank"><div class="pq ab ig"><div class="pr ab co cb ps pt"><h2 class="bf fr hw z io pu iq ir pv it iv fp bk">Categorical Encoding: Key Insights</h2><div class="pw l"><h3 class="bf b hw z io pu iq ir pv it iv dx">Summarizing 54 Medium Stories</h3></div><div class="px l"><p class="bf b dy z io pu iq ir pv it iv dx">medium.com</p></div></div><div class="py l"><div class="pz l qa qb qc py qd lq pp"/></div></div></a></div><p id="1fce" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The last yellow column shows the encoders covered by the <code class="cx og oh oi oj b"><a class="af nx" href="https://contrib.scikit-learn.org/category_encoders/" rel="noopener ugc nofollow" target="_blank">Category Encoders</a></code> module [16]. Note that the code from [2] implements some encoders — from the similarity, binning, and data constraining families — that are not part of the <code class="cx og oh oi oj b">Category Encoders</code> module. In addition, we have found that the interface to the GLMM encoder implemented in R and used in [2] is much faster than the GLMM encoder from <code class="cx og oh oi oj b">Category Encoders</code>. Therefore, you may find our code useful for these implementations.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qe"><img src="../Images/d08fed9022b8930e1708be3269f919e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BYX8Ac3sphPE_LcWjgHAaQ.jpeg"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Table 1. Encoder families and their coverage by various resources. Author owns copyright</figcaption></figure><p id="b488" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Table 1 already contains a number of encoders, and the list is by no means exhaustive. To navigate the encoder landscape, it is therefore useful to classify encoders in order to understand the principles of encoder design, rather than to memorize a large number of individual encoders.</p><h2 id="87ec" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Families of encoders</h2><p id="07b3" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">In the following, we consider a categorical feature of length <code class="cx og oh oi oj b">n</code> with cardinality <code class="cx og oh oi oj b">k</code>. At the top level, categorical encoders are supervised or unsupervised.</p><p id="94ba" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">1. Unsupervised encoders</strong> do not include the target variable in the encoding process.</p><p id="86ac" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">1.1. Identifier encoders</em></strong> transform categorical variables using a injective function, i.e., they assign each category a unique numeric value or a unique combination of numeric values. They create from 1 up to <code class="cx og oh oi oj b">k</code> new features. For example, One-Hot encoder creates <code class="cx og oh oi oj b">k</code> features, label or ordinal encoders create a single new feature, Base N encoders create ⌈<code class="cx og oh oi oj b">log(k)</code>⌉ new features, where the logarithm is of base N.</p><p id="6cd7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">These encoders are useful for categorical variables that denote unique identifiers, such as product codes or zip codes. Typically, with the exception of ordinal encoder, identifier encoders do not assume that any inherent order in the categories conveys meaningful information for analysis, and thus ignore any such order during the encoding process.</p><p id="8169" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">1.2. Contrast encoders</em></strong> transform categorical variables by assigning numerical values based on comparisons between categories. Typically, a set of <code class="cx og oh oi oj b">k-1</code> new features represents a categorical variable with <code class="cx og oh oi oj b">k </code>categories. Unlike identifier encoders, these encoders are specifically designed to explore the relationships between different levels of a categorical variable in a regression analysis.</p><p id="0a09" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To create a contrast encoder, one has a choice of different <a class="af nx" href="https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#ORTHOGONAL" rel="noopener ugc nofollow" target="_blank">coding schemes</a> [15]. Each contrasts a category with other categories in a particular way to test a related hypothesis about the data. For example, Helmert coding contrasts each level with the mean of subsequent levels, while sum coding contrasts each level with the overall mean.</p><p id="fb76" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">1.3. Frequency encoders</em></strong> replace the categories of a categorical variable with corresponding values that are a function of the frequency of those categories in the data set. Unlike identifier or contrast encoders, frequency encoders create a single new feature and are not necessarily injective functions. They provide a numerical representation of occurrence rates, which can be particularly useful when an ML model benefits from understanding the commonality of category values. All three frequency encoders in Table 1 are monotonically increasing functions of frequency. However, this is not a necessary condition for defining this group.</p><p id="7da0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">1.4. Similarity encoders</em></strong> [5, 8, 18] transform categorical data into numerical form by applying similarity or distance metrics that capture similarities between different categories.</p><p id="31f3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">One group of similarity encoders [8, 18] is based on a morphological comparison between two categories treated as strings. Examples of similarity metrics are Levenshtein’s ratio, Jaro-Winkler similarity, or N-gram similarity. The categorical variable is then encoded as a vector, where each dimension corresponds to a pairwise comparison of a reference category with all categories, and the value represents the computed similarity score (similar to constructing a <a class="af nx" href="https://en.wikipedia.org/wiki/Covariance_matrix" rel="noopener ugc nofollow" target="_blank">variance-covariance</a> matrix). Encoders of this group typically create <code class="cx og oh oi oj b">k</code> new features. This encoding is particularly useful for handling “dirty” categorical datasets that may contain typos and redundancies [18]. One can think of One-Hot encoding as a special case of similarity encoding, where the similarity measure can take only two values, 0 or 1.</p><p id="f533" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Another group of similarity encoders [5], including, e.g. Embeddings, Min-Hash, or Gamma-Poisson matrix factorization, is designed for high cardinality categories (<code class="cx og oh oi oj b">k&gt;&gt;1</code>). They project categorical features into a lower dimensional space. This group is thus similar to binning encoders, which are also particularly useful for large <code class="cx og oh oi oj b">k</code> but do not aim to preserve the morphological similarity of categories.</p><p id="779f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">2. Supervised encoders </strong>use information about the target variable. For regression or binary classification tasks, they typically create a single new feature for each categorical one.</p><p id="c0e2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">2.1.</em></strong><em class="qf"> </em><strong class="nd fr"><em class="qf">Simple target encoders</em></strong> capture the relationship between the categorical characteristic and the target. Constructing a simple target encoder involves calculating a statistic based on the target variable for each level of the categorical variable. Common statistics include the mean, median, or probability ratios of the target variable conditional on each category.</p><p id="aa69" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The procedure is as follows:</p><ul class=""><li id="21ec" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">For each category level, group the data by the categorical variable.</li><li id="7e1c" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Within each group, compute the desired statistic of interest.</li><li id="eef6" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">For each instance in the data, replace the original categorical value with the corresponding statistic.</li></ul><p id="2471" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Simple target encoding runs the risk of overfitting, especially for small data sets and categories with very few observations. Techniques such as smoothing (regularization) and cross-validation, which we describe shortly, can help mitigate this risk.</p><p id="fe7c" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">2.2. Smoothing encoders</em></strong> are generalizations of simple target encoders that introduce a smoothing parameter. The purpose of this smoothing parameter is to prevent overfitting and to improve the generalization of the encoder to new data, especially when there are categories with a small number of observations. A common formula for the smoothed value is</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qg"><img src="../Images/7cd5d3947ecd4f59103ed2ed6c68d6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGrNrAYOW917gQ3JOPgMGA.png"/></div></div></figure><p id="4f9e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">where <code class="cx og oh oi oj b">m</code> is the number of times the category occurs in the data set. It may slightly vary, see [13]. By adjusting the smoothing parameter, you can control the balance between the category statistic and the overall statistic. A larger smoothing parameter makes the encoding less sensitive to the category-specific target statistic. Setting the smoothing parameter to zero in the above formula results in a simple target encoding.</p><p id="1c3f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr"><em class="qf">2.3. Data-constraining encoders</em></strong> use information from a subset of rows in a data set. An example of a data-constraining coder is the leave-one-out coder, which, for a given categorical value, calculates the statistic of the target variable for all other instances in which the category occurs, excluding the current instance. This approach ensures that the encoded value for a given data set does not include its own target value.</p><p id="fc33" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Data-constraining strategies help create encodings that are more representative of the true relationships in the unseen data and less prone to overfitting. The number of unique values in the encoded column may exceed the cardinality of the original categorical column <code class="cx og oh oi oj b">k</code>. One can also introduce smoothing into data-constraining encodings.</p><p id="41db" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">3. Binning encoders </strong>can be both supervised and unsupervised. Often, their work can be divided into two steps. The first step creates an auxiliary categorical feature by sorting the original categories into bins. The second step applies an encoder from one of the other groups discussed above to this auxiliary feature. Both steps can be either unsupervised or supervised independently of each other. For example, in the first step, you can form the bins by grouping rare categories together (unsupervised, e.g., One-Hot MC encoder); alternatively, you can apply a simple target encoder and group the categories with close encoded values together (supervised, e.g., Discretized Target encoder).</p><p id="9fab" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Some binning encoders, e.g. Hashing, do not have this two-stage structure. The number of new features created by binning encoders is usually <code class="cx og oh oi oj b">&lt;k</code>.</p><h2 id="7e4e" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Tuning strategies</h2><p id="3683" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">Before proceeding with the results, I will briefly summarize the tuning strategies from our benchmark. This is important to understand the scope of the following figures and to reuse the data and code from our benchmark. The three tuning strategies are</p><p id="ee74" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">No tuning:</strong></p><ul class=""><li id="d8f0" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Encode the categorical columns of the training data;</li><li id="fa66" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Train an ML model with its default hyperparameters.</li></ul><p id="1aac" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Model tuning:</strong></p><ul class=""><li id="4964" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Encode the categorical columns of the training data;</li><li id="f7de" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Divide the training data into folds;</li><li id="b08e" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Optimize the hyperparameters of an ML model using cross-validation.</li></ul><p id="e243" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Full tuning:</strong></p><ul class=""><li id="9901" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Split training data into folds;</li><li id="f361" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Encode each training fold separately (in case of data constraining encoder family, each fold is further split into the nested folds);</li><li id="1390" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">Optimize the hyperparameters of an ML model with cross-validation.</li></ul><h2 id="1519" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk"><strong class="al">Results</strong></h2><p id="4b58" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">I will name the winning encoders from our experiments, point out which tuning strategy performed best and should be part of your ML pipeline, and present the runtimes for various encoders.</p><p id="99e1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Ranking</strong></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qh"><img src="../Images/4b1bf883b2332d852d6578c9e105c2b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mcC6ohyzWwYI48NBf-9-cA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 1. Performance of encoders in all experiments. Author owns copyright</figcaption></figure><p id="e9ce" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In Figure 1, the boxplots show the distribution of encoder ranks across all datasets, quality metrics, and tuning strategies. That is, each boxplot includes ~50×4×3=600 experiments for individual models and ~50×4×3×5=3000 experiments for all models, excluding the small fraction of experiments that timed out or failed for other reasons. We observed that four encoders: <strong class="nd fr">One-Hot, Binary (</strong>‘Bin’ on the plot<strong class="nd fr">), Sum, and Weight of Evidence</strong> are consistently among the best performing. For logistic regression, the difference of these four from the rest is statistically significant. This result is somewhat surprising since many previous studies (see [13, 14]) have reported drawbacks of unsupervised encoders, especially One-Hot. The exact meanings of all other encoder abbreviations on Figure 1 are not important for the rest, but you can find them in [2].</p><p id="e6b3" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Tuning strategy</strong></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qi"><img src="../Images/6b6e69a811937e2cbecd10bed418b70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-6Jjg3sofGOl3Z-p8NNv6A.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 2. Performance gain of <strong class="bf om">full</strong> tuning over <strong class="bf om">no</strong> tuning. Author owns copyright</figcaption></figure><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qi"><img src="../Images/dd90fae03433f49d0da8b9dcbc423385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8nTMFpAvhPEYpD4eLQ4Uw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 3. Performance gain of <strong class="bf om">full</strong> tuning over <strong class="bf om">model</strong> tuning. Author owns copyright</figcaption></figure><p id="1cd0" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Figure 2 plots the performance difference between full and no tuning strategies (as I described above) for each categorical encoder. Each covers the experiments with different datasets, ML models, and performance metrics. Figure 3 is a similar plot comparing full and model tuning strategies. Note that these plots do not include some of the ML models and datasets because we limited the computational complexity. See [2] for details and more plots.</p><p id="13d8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Based on these results, I would generally recommend sticking to the full tuning strategy, i.e., encoding data for each fold separately when optimizing the hyperparameters of an ML model; this is especially important for data constraining encoders.</p><p id="74ed" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Runtime</strong></p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qj"><img src="../Images/1f192ae7dee9e53c1a7f3aa17f717e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hT-Xy-VYwHsCLBNwiNTN9g.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 4. Runtime of encoders. Author owns copyright</figcaption></figure><p id="7124" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Finally, Figure 4 plots the times required to encode data sets on a logarithmic scale. Simple target and binning encoders are the fastest, while smoothing and data constraining encoders are the slowest. The four best performing encoders — One-Hot, Binary <strong class="nd fr">(</strong>‘Bin’ on the plot<strong class="nd fr">)</strong>, Sum, and Weight of Evidence — take a reasonable amount of time to process data.</p><h2 id="27bf" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Reusing the code and the results</h2><p id="e1a2" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">A nice feature of our benchmark is that you can easily extend it to test your approach to categorical encoding and put it in the context of existing experimental results. For example, you may want to test the encoders from Table 1 that are not part of our benchmark, or you may want to test your custom composite encoder like if <code class="cx og oh oi oj b">n/k&gt;a</code> then One-Hot MC else One-Hot where <code class="cx og oh oi oj b">k</code> is the feature cardinality and <code class="cx og oh oi oj b">n</code> is the size of the dataset, as before. We explain the process on <a class="af nx" href="https://github.com/DrCohomology/EncoderBenchmarking" rel="noopener ugc nofollow" target="_blank">GitHub</a> and share the demonstration of how to do this in the <a class="af nx" href="https://www.kaggle.com/code/derhamcohomology/add-a-custom-encoder-to-the-benchmark" rel="noopener ugc nofollow" target="_blank">kaggle notebook</a> [17]. Below is a short summary of [17].</p><p id="3b42" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For illustrative purposes, we limited the example to a logistic regression model without hyperparameter tuning. The corresponding results of our benchmark are shown in Figure 5 below.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qk"><img src="../Images/d9bc9a5c5f412a80e934529375160241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jV_-nqbdD-IV1jbRFjLbKw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 5. Encoder ranks for logistic regression with <strong class="bf om">no</strong> tuning strategy. Author owns copyright</figcaption></figure><p id="6682" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Now suppose that <a class="af nx" href="https://medium.com/@yurykashnitskiy" rel="noopener">Yury Kashnitsky</a>, who kindly provided feedback on our paper, wonders whether the <a class="af nx" href="https://www.kaggle.com/code/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning" rel="noopener ugc nofollow" target="_blank">hashing</a> encoder is competitive with the encoders we evaluated. In [17], we show how to perform the missing experiments and find that the <a class="af nx" href="https://www.kaggle.com/code/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning" rel="noopener ugc nofollow" target="_blank">hashing</a> encoder performs reasonably well with our choice of its hyperparameter, as Figure 6 shows.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ql"><img src="../Images/639099717759d1f5005308102064a25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fOKkgvGaxbEVg_gRzIT51A.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Figure 6. Encoder ranks with hashing trick encoder added. Author owns copyright</figcaption></figure><h2 id="e971" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Conclusion</h2><p id="d390" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">I summarized our benchmark of categorical encoders and explained how you can benefit from our shared artifacts. You may have learned:</p><ul class=""><li id="e706" class="nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw ny nz oa bk">Categorical encoders, as ML models, can be supervised or unsupervised.</li><li id="1b14" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">I presented eight families of encoders. Some encoders preserve the cardinality of categorical features, others can reduce it (often the case for binning, but also for some other encoders, e.g., Naive Target) or increase it (data constraining).</li><li id="5395" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">One-Hot, Binary, Sum, and Weight of Evidence encoders performed best on average in our experiments, especially with logistic regression.</li><li id="3e74" class="nb nc fq nd b go ob nf ng gr oc ni nj nk od nm nn no oe nq nr ns of nu nv nw ny nz oa bk">See the <a class="af nx" href="https://www.kaggle.com/code/derhamcohomology/add-a-custom-encoder-to-the-benchmark" rel="noopener ugc nofollow" target="_blank">kaggle notebook</a> [17] for a demo of how to add the desired encoders to the benchmark and plot the results; the necessary code is available on <a class="af nx" href="https://github.com/DrCohomology/EncoderBenchmarking" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</li></ul><h2 id="afca" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Acknowledgements</h2><p id="d6b7" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">This story would not exist if <a class="af nx" href="https://github.com/DrCohomology" rel="noopener ugc nofollow" target="_blank">Federico Matteucci</a>, my colleague and first author in [2], had not written the code for the benchmark and for the kaggle notebook [17].</p><h2 id="f2c9" class="ok ol fq bf om on oo op oq or os ot ou nk ov ow ox no oy oz pa ns pb pc pd pe bk">Resources</h2><p id="a567" class="pw-post-body-paragraph nb nc fq nd b go pf nf ng gr pg ni nj nk ph nm nn no pi nq nr ns pj nu nv nw fj bk">[1] <a class="af nx" href="https://archive.ics.uci.edu/" rel="noopener ugc nofollow" target="_blank">UC Irvine Machine Learning Repository</a></p><p id="43d2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[2] Matteucci, F., Arzamasov, V., &amp; Böhm, K. (2024). A benchmark of categorical encoders for binary classification. <em class="qf">Advances in Neural Information Processing Systems</em>, <em class="qf">36</em>. (<a class="af nx" href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/ac01e21bb14609416760f790dd8966ae-Abstract-Datasets_and_Benchmarks.html" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">paper</strong></a><strong class="nd fr">, </strong><a class="af nx" href="https://github.com/DrCohomology/EncoderBenchmarking" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">code on GitHub</strong></a><strong class="nd fr">, </strong><a class="af nx" href="https://nips.cc/media/PosterPDFs/NeurIPS%202023/73555.png?t=1699521284.38544" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">poster</strong></a>)</p><p id="fd7f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[3] Seca, D., &amp; Mendes-Moreira, J. (2021). <a class="af nx" href="https://link.springer.com/chapter/10.1007/978-3-030-72657-7_14" rel="noopener ugc nofollow" target="_blank">Benchmark of encoders of nominal features for regression</a>. In <em class="qf">World Conference on Information Systems and Technologies</em> (pp. 146–155). Cham: Springer International Publishing.</p><p id="355d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[4] Pargent, F., Pfisterer, F., Thomas, J., &amp; Bischl, B. (2022). <a class="af nx" href="https://link.springer.com/article/10.1007/s00180-022-01207-6" rel="noopener ugc nofollow" target="_blank">Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features</a>. <em class="qf">Computational Statistics</em>, <em class="qf">37</em>(5), 2671–2692.</p><p id="1629" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[5] Cerda, P., &amp; Varoquaux, G. (2020). <a class="af nx" href="https://ieeexplore.ieee.org/abstract/document/9086128?casa_token=iHWayCtAoQIAAAAA%3AiqUqhSrqAcCcORtpzRHA589n_vgacNAG_xMFbG7NV5BYk7s7L8Uy46P5NUqDoGJ5E_C8eZ6opQ" rel="noopener ugc nofollow" target="_blank">Encoding high-cardinality string categorical variables</a>. <em class="qf">IEEE Transactions on Knowledge and Data Engineering</em>, <em class="qf">34</em>(3), 1164–1176.</p><p id="a8cf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[6] Potdar, K., Pardawala, T. S., &amp; Pai, C. D. (2017). <a class="af nx" href="https://www.researchgate.net/profile/Kedar-Potdar-2/publication/320465713_A_Comparative_Study_of_Categorical_Variable_Encoding_Techniques_for_Neural_Network_Classifiers/links/59e6f9554585151e5465859c/A-Comparative-Study-of-Categorical-Variable-Encoding-Techniques-for-Neural-Network-Classifiers.pdf" rel="noopener ugc nofollow" target="_blank">A comparative study of categorical variable encoding techniques for neural network classifiers</a>. <em class="qf">International journal of computer applications</em>, <em class="qf">175</em>(4), 7–9.</p><p id="4a0f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[7] Dahouda, M. K., &amp; Joe, I. (2021). <a class="af nx" href="https://ieeexplore.ieee.org/abstract/document/9512057" rel="noopener ugc nofollow" target="_blank">A deep-learned embedding technique for categorical features encoding</a>. <em class="qf">IEEE Access</em>, <em class="qf">9</em>, 114381–114391.</p><p id="7f9a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[8] Cerda, P., Varoquaux, G., &amp; Kégl, B. (2018). <a class="af nx" href="https://link.springer.com/article/10.1007/s10994-018-5724-2" rel="noopener ugc nofollow" target="_blank">Similarity encoding for learning with dirty categorical variables</a>. <em class="qf">Machine Learning</em>, <em class="qf">107</em>(8), 1477–1494.</p><p id="924f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[9] Wright, M. N., &amp; König, I. R. (2019).<a class="af nx" href="https://peerj.com/articles/6339/" rel="noopener ugc nofollow" target="_blank"> Splitting on categorical predictors in random forests</a>. <em class="qf">PeerJ</em>, <em class="qf">7</em>, e6339.</p><p id="1332" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[10] Gnat, S. (2021). <a class="af nx" href="https://www.sciencedirect.com/science/article/pii/S1877050921018664" rel="noopener ugc nofollow" target="_blank">Impact of categorical variables encoding on property mass valuation</a>. <em class="qf">Procedia Computer Science</em>, <em class="qf">192</em>, 3542–3550.</p><p id="6014" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[11] Johnson, J. M., &amp; Khoshgoftaar, T. M. (2021, August). <a class="af nx" href="https://ieeexplore.ieee.org/abstract/document/9599119" rel="noopener ugc nofollow" target="_blank">Encoding techniques for high-cardinality features and ensemble learners</a>. In <em class="qf">2021 IEEE 22nd international conference on information reuse and integration for data science (IRI)</em> (pp. 355–361). IEEE.</p><p id="545b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[12] Valdez-Valenzuela, E., Kuri-Morales, A., &amp; Gomez-Adorno, H. (2021). <a class="af nx" href="https://link.springer.com/chapter/10.1007/978-3-030-89817-5_7" rel="noopener ugc nofollow" target="_blank">Measuring the effect of categorical encoders in machine learning tasks using synthetic data</a>. In <em class="qf">Advances in Computational Intelligence: 20th Mexican International Conference on Artificial Intelligence, MICAI 2021, Mexico City, Mexico, October 25–30, 2021, Proceedings, Part I 20</em> (pp. 92–107). Springer International Publishing.</p><p id="4261" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[13] <a class="af nx" rel="noopener" target="_blank" href="/benchmarking-categorical-encoders-9c322bd77ee8">Benchmarking Categorical Encoders</a> (a story on TDS)</p><p id="3fd8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[14] <a class="af nx" href="https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe" rel="noopener">Categorical Encoding: Key Insights</a> (my story on Medium)</p><p id="2282" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[15] <a class="af nx" href="https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#ORTHOGONAL" rel="noopener ugc nofollow" target="_blank">R Library Contrast Coding Systems for categorical variables</a></p><p id="9178" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[16] <a class="af nx" href="https://contrib.scikit-learn.org/category_encoders/" rel="noopener ugc nofollow" target="_blank">Category Encoders </a>(python module)</p><p id="eb5e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[17] <a class="af nx" href="https://www.kaggle.com/code/derhamcohomology/add-a-custom-encoder-to-the-benchmark" rel="noopener ugc nofollow" target="_blank"><strong class="nd fr">Add a custom encoder to the benchmark</strong></a> (kaggle notebook)</p><p id="a2fa" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">[18] <a class="af nx" rel="noopener" target="_blank" href="/similarity-encoding-for-dirty-categories-using-dirty-cat-d9f0b581a552">Similarity Encoding for Dirty Categories Using dirty_cat</a> (a story on TDS)</p></div></div></div></div>    
</body>
</html>