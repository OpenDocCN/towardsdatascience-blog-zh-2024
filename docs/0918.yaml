- en: 'Moirai: Time Series Foundation Models for Universal Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Moirai：面向通用预测的时间序列基础模型
- en: 原文：[https://towardsdatascience.com/moirai-time-series-foundation-models-for-universal-forecasting-dc93f74b330f?source=collection_archive---------0-----------------------#2024-04-11](https://towardsdatascience.com/moirai-time-series-foundation-models-for-universal-forecasting-dc93f74b330f?source=collection_archive---------0-----------------------#2024-04-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/moirai-time-series-foundation-models-for-universal-forecasting-dc93f74b330f?source=collection_archive---------0-----------------------#2024-04-11](https://towardsdatascience.com/moirai-time-series-foundation-models-for-universal-forecasting-dc93f74b330f?source=collection_archive---------0-----------------------#2024-04-11)
- en: 'The future of predictive analytics: Explore Moirai, Salesforce’s new foundation
    model for advanced time series forecasting'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测分析的未来：探索Moirai，Salesforce推出的用于先进时间序列预测的新基础模型
- en: '[](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page---byline--dc93f74b330f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)
    ·15 min read·Apr 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dc93f74b330f--------------------------------)
    ·15分钟阅读·2024年4月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*This post was co-authored with Rafael Guedes.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由Rafael Guedes和我共同撰写。*'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: The development of time series foundation models has been accelerating over
    the last two quarters, and we have been witnessing the release of a new model
    nearly every month. It started with TimeGPT [1] in the last quarter of 2023, and
    since then, we saw the release of Lag-Llama [2], Google releasing TimesFM [3],
    Amazon releasing Chronos [4], and Salesforce releasing Moirai [5].
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列基础模型的开发在过去两个季度加速推进，我们几乎见证了每个月都有新模型的发布。从2023年最后一个季度的TimeGPT [1]开始，到Lag-Llama
    [2]的发布，再到Google推出TimesFM [3]、Amazon推出Chronos [4]，以及Salesforce发布Moirai [5]，这一过程正在加速。
- en: 'To understand the growing interest in foundation models, we should define their
    core capability: zero-shot inference. It refers to the ability to accurately perform
    tasks or make predictions on data that these models have never encountered during
    their training phase. This ability has been explored for models applied across
    various domains, such as natural language processing (NLP), computer vision, and
    multimodal tasks (combining text, images, etc.). The term “zero-shot” comes from
    the idea that the model sees “zero” examples from a specific task or data domain
    during training yet can “shoot” or aim at performing tasks in that area effectively.
    The term was introduced in the paper “Zero-Shot Learning with Semantic Output
    Codes,” authored by Hinton et al. and presented at the NIPS…'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解对基础模型日益增长的兴趣，我们应该定义它们的核心能力：零-shot推理。零-shot推理指的是这些模型能够在训练过程中从未接触过的数据上准确执行任务或做出预测的能力。这种能力已被探索应用于各个领域的模型，例如自然语言处理（NLP）、计算机视觉以及多模态任务（结合文本、图像等）。术语“零-shot”来自于这样一个概念：模型在训练期间未曾见过来自某个特定任务或数据领域的任何示例，但它能够有效地“射击”或瞄准该领域的任务。这个术语最早出现在Hinton等人发表的论文《Zero-Shot
    Learning with Semantic Output Codes》中，并在NIPS会议上进行了介绍…
