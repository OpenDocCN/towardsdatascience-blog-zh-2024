<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>No GPU, No Party : Fine-Tune BERT for Sentiment Analysis with Vertex AI Custom jobs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>No GPU, No Party : Fine-Tune BERT for Sentiment Analysis with Vertex AI Custom jobs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03">https://towardsdatascience.com/no-gpu-no-party-fine-tune-bert-for-sentiment-analysis-with-vertex-ai-custom-jobs-d8fc410e908b?source=collection_archive---------5-----------------------#2024-06-03</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="e159" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Speed up the training process with serverless jobs</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Benjamin Etienne" class="l ep by dd de cx" src="../Images/cad8bc2d4b900575e76b7cf9debc9eea.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*zgmYQ0PJ0MHXIc5mEYVSMA.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@benjamin_47408?source=post_page---byline--d8fc410e908b--------------------------------" rel="noopener follow">Benjamin Etienne</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--d8fc410e908b--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">13 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 3, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/de04296aee8fcd10eae449ceb2f6d4ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1GlYlGHSejrMJsJl"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Photo by <a class="af nb" href="https://unsplash.com/@ynsplt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">yns plt</a> on <a class="af nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="dbd7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">TL;DR: How to launch a training job with Pytorch with GPUs on Vertex. Code with examples.</em></p><p id="ebd7" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In my <a class="af nb" rel="noopener" target="_blank" href="/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f">previous article</a>, I mentioned the fact that training locally huge models is not always a good practice when you have limited resources. Sometimes you just don’t have a choice, but sometimes you have at your disposal a Cloud provider such as Google Cloud Platform which can significantly speed up your trainings by:</p><ul class=""><li id="f2a8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk">Providing you cutting-edge machines with custom configurations (memory, GPUs, etc.)</li><li id="9340" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Allowing you to launch several jobs simultaneously and choose the best model in the end</li></ul><p id="cb15" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><em class="ny">Not to mention that offloading the training to the cloud will relieve your personal machine. I already saw the battery melt after leaving my personal laptop train a model for 1 week. Back from holidays, my touchpad was literally popping out.</em></p><p id="720c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk"><strong class="ne fr">In this article, we will take a concrete use case where we will fine-tune a BERT model on social media comments to perform sentiment analysis. As we will see, training this kind of model on a CPU is very cumbersome and not optimal. We will therefore see how we can leverage Google Cloud Platform to speed up the process by using a GPU for only 60 cents.</strong></p><h1 id="fd5b" class="oh oi fq bf oj ok ol gq om on oo gt op oq or os ot ou ov ow ox oy oz pa pb pc bk">Summary</h1><ul class=""><li id="0aa9" class="nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx nz oa ob bk">What is BERT</li><li id="eff4" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">What is Sentiment Analysis</li><li id="39b1" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Get and prepare the data</li><li id="ef0e" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Use a small BERT pretrained model</li><li id="0423" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Create the dataloaders</li><li id="aae4" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Write the main script to train the model</li><li id="6b18" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Dockerize the script</li><li id="327f" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Build and push an image to Google Cloud</li><li id="d4f1" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">Create a job on Vertex AI</li></ul></div></div></div><div class="ab cb pi pj pk pl" role="separator"><span class="pm by bm pn po pp"/><span class="pm by bm pn po pp"/><span class="pm by bm pn po"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="a1f6" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">What is BERT ?</h2><p id="c0aa" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">BERT stands for Bidirectional Encoder Representations from Transformers and was open-sourced by Google in 2018. It is mainly used for NLP tasks as it was trained to capture semantics in sentences and provide rich word embeddings (representations). The difference with other models such as Word2Vec and Glove lies in the fact that it uses Transformers to process text. Transformers (refer to my previous article if you want to know more) are a family of neural networks which, a little bit like RNNs, have the ability to process sequences in both directions, therefore able to capture context around a word for example.</p><h2 id="86b6" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">What is Sentiment Analysis ?</h2><p id="ccf9" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Sentiment Analysis is a specific task within the NLP domain which objective is to classify text into categories related to the tonality of it. Tonality is often expressed as <em class="ny">positive</em>, <em class="ny">negative</em>, or <em class="ny">neutral</em>. It is very commonly used to analyze verbatims, posts on social media, product reviews, etc.</p></div></div></div><div class="ab cb pi pj pk pl" role="separator"><span class="pm by bm pn po pp"/><span class="pm by bm pn po pp"/><span class="pm by bm pn po"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="f480" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Fine-tuning a BERT model on social media data</h2><h2 id="a4f2" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Getting and preparing the data</h2><p id="1689" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">The dataset we will use comes from Kaggle, you can download it here : <a class="af nb" href="https://www.kaggle.com/datasets/farisdurrani/sentimentsearch" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets/farisdurrani/sentimentsearch</a> (CC BY 4.0 License). In my experiments, I only chose the datasets from Facebook and Twitter.</p><p id="d68b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The following snippet will take the csv files and save 3 splits (training, validation, and test) to where you want. I recommend saving them in Google Cloud Storage.</p><p id="a18e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can run the script with:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="e09e" class="ql oi fq qi b bg qm qn l qo qp">python make_splits --output-dir gs://your-bucket/</span></pre><pre class="qq qh qi qj bp qk bb bk"><span id="edd4" class="ql oi fq qi b bg qm qn l qo qp">import pandas as pd<br/>import argparse<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/><br/><br/>def make_splits(output_dir):<br/>    df=pd.concat([<br/>        pd.read_csv("data/farisdurrani/twitter_filtered.csv"),<br/>        pd.read_csv("data/farisdurrani/facebook_filtered.csv")<br/>    ])<br/>    df = df.dropna(subset=['sentiment'], axis=0)<br/>    df['Target'] = df['sentiment'].apply(lambda x: 1 if x==0 else np.sign(x)+1).astype(int)<br/><br/>    df_train, df_ = train_test_split(df, stratify=df['Target'], test_size=0.2)<br/>    df_eval, df_test = train_test_split(df_, stratify=df_['Target'], test_size=0.5)<br/><br/>    print(f"Files will be saved in {output_dir}")<br/>    df_train.to_csv(output_dir + "/train.csv", index=False)<br/>    df_eval.to_csv(output_dir + "/eval.csv", index=False)<br/>    df_test.to_csv(output_dir + "/test.csv", index=False)<br/><br/>    print(f"Train : ({df_train.shape}) samples")<br/>    print(f"Val : ({df_eval.shape}) samples")<br/>    print(f"Test : ({df_test.shape}) samples")<br/><br/><br/>if __name__ == '__main__':<br/>    parser = argparse.ArgumentParser()<br/>    parser.add_argument('--output-dir')<br/>    args, _ = parser.parse_known_args()<br/>    make_splits(args.output_dir)</span></pre><p id="4182" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The data should look roughly like this:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qr"><img src="../Images/bd678c8886d35aadd886a31d031ad2ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*Iwp1_8fVAbzTVs4HmkFFIQ.png"/></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(image from author)</figcaption></figure><h2 id="17bb" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Using a small BERT pretrained model</h2><p id="bedf" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">For our model, we will use a lightweight BERT model, BERT-Tiny. This model has already been pretrained on vasts amount of data, but not necessarily with social media data and not necessarily with the objective of doing Sentiment Analysis. This is why we will fine-tune it.</p><p id="ffe2" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">It contains only 2 layers with a 128-units dimension, the full list of models can be seen <a class="af nb" href="https://github.com/google-research/bert" rel="noopener ugc nofollow" target="_blank">here</a> if you want to take a larger one.</p><p id="db07" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s first create a <code class="cx qs qt qu qi b">main.py</code> file, with all necessary modules:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="fb06" class="ql oi fq qi b bg qm qn l qo qp">import pandas as pd<br/>import argparse<br/>import tensorflow as tf<br/>import tensorflow_hub as hub<br/>import tensorflow_text as text<br/>import logging<br/>import os<br/>os.environ["TFHUB_MODEL_LOAD_FORMAT"] = "UNCOMPRESSED"<br/><br/>def train_and_evaluate(**params):<br/>    pass<br/>    # will be updated as we go</span></pre><p id="d679" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s also write down our requirements in a dedicated <code class="cx qs qt qu qi b">requirements.txt</code></p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="63cf" class="ql oi fq qi b bg qm qn l qo qp">transformers==4.40.1<br/>torch==2.2.2<br/>pandas==2.0.3<br/>scikit-learn==1.3.2<br/>gcsfs</span></pre><p id="a7a3" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will now load 2 parts to train our model:</p><ul class=""><li id="8ccb" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk">The <strong class="ne fr"><em class="ny">tokenizer</em></strong>, which will take care of splitting the text inputs into tokens that BERT has been trained with.</li><li id="ea17" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">The <strong class="ne fr"><em class="ny">model</em></strong> itself.</li></ul><p id="610c" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You can obtain both from Huggingface <a class="af nb" href="http://google/bert_uncased_L-2_H-128_A-2" rel="noopener ugc nofollow" target="_blank">here</a>. You can also download them to Cloud Storage. That is what I did, and will therefore load them with:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="d4f7" class="ql oi fq qi b bg qm qn l qo qp"><br/># Load pretrained tokenizers and bert model<br/>tokenizer = BertTokenizer.from_pretrained('models/bert_uncased_L-2_H-128_A-2/vocab.txt')<br/>model = BertModel.from_pretrained('models/bert_uncased_L-2_H-128_A-2')</span></pre><p id="2549" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s now add the following piece to our file:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="373f" class="ql oi fq qi b bg qm qn l qo qp">class SentimentBERT(nn.Module):<br/>    def __init__(self, bert_model):<br/>        super().__init__()<br/>        self.bert_module = bert_model<br/>        self.dropout = nn.Dropout(0.1)<br/>        self.final = nn.Linear(in_features=128, out_features=3, bias=True) <br/>        <br/>        # Uncomment the below if you only want to retrain certain layers.<br/>        # self.bert_module.requires_grad_(False)<br/>        # for param in self.bert_module.encoder.parameters():<br/>        #     param.requires_grad = True<br/>        <br/>    def forward(self, inputs):<br/>        ids, mask, token_type_ids = inputs['ids'], inputs['mask'], inputs['token_type_ids']<br/>        # print(ids.size(), mask.size(), token_type_ids.size())<br/>        x = self.bert_module(ids, mask, token_type_ids)<br/>        x = self.dropout(x['pooler_output'])<br/>        out = self.final(x)<br/>        return out</span></pre><p id="6ce0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">A little break here. We have several options when it comes to reusing an existing model.</p><ul class=""><li id="b5c8" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk"><strong class="ne fr">Transfer learning</strong> : we freeze the weights of the model and use it as a “feature extractor”. We can therefore append additional layers downstream. This is frequently used in Computer Vision where models like VGG, Xception, etc. can be reused to train a custom model on small datasets</li><li id="e151" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><strong class="ne fr">Fine-tuning</strong> : we unfreeze all or part of the weights of the model and retrain the model on a custom dataset. This is the preferred approach when training custom LLMs.</li></ul><p id="6c0b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">More details on Transfer learning and Fine-tuning <a class="af nb" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">here</a>:</p><p id="dc88" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">In the model, we have chosen to unfreeze all the model, but feel free to freeze one or more layers of the pretrained BERT module and see how it influences the performance.</p><p id="2487" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The key part here is to add a fully connected layer after the BERT module to “link” it to our classification task, hence the final layer with 3 units. This will allow us to reuse the pretrained BERT weights and adapt our model to our task.</p><h2 id="c36e" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Creating the dataloaders</h2><p id="af48" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">To create the dataloaders we will need the Tokenizer loaded above. The Tokenizer takes a string as input, and returns several outputs amongst which we can find the tokens (‘input_ids’ in our case):</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj qv"><img src="../Images/894b0cbe3aec033e162d3be5ca1ddc3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ZLt7XaVbHK7GqITy6cDMg.png"/></div></div></figure><p id="2707" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The BERT tokenizer is a bit special and will return several outputs, but the most important one is the <code class="cx qs qt qu qi b">input_ids</code>: they are the tokens used to encode our sentence. They might be words, or parts or words. For example, the word “looking” might be made of 2 tokens, “look” and “##ing”.</p><p id="bdc1" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Let’s now create a dataloader module which will handle our datasets :</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="e3fd" class="ql oi fq qi b bg qm qn l qo qp">class BertDataset(Dataset):<br/>    def __init__(self, df, tokenizer, max_length=100):<br/>        super(BertDataset, self).__init__()<br/>        self.df=df<br/>        self.tokenizer=tokenizer<br/>        self.target=self.df['Target']<br/>        self.max_length=max_length<br/>        <br/>    def __len__(self):<br/>        return len(self.df)<br/>    <br/>    def __getitem__(self, idx):<br/>        <br/>        X = self.df['bodyText'].values[idx]<br/>        y = self.target.values[idx]<br/>        <br/>        inputs = self.tokenizer.encode_plus(<br/>            X,<br/>            pad_to_max_length=True,<br/>            add_special_tokens=True,<br/>            return_attention_mask=True,<br/>            max_length=self.max_length,<br/>        )<br/>        ids = inputs["input_ids"]<br/>        token_type_ids = inputs["token_type_ids"]<br/>        mask = inputs["attention_mask"]<br/><br/>        x = {<br/>            'ids': torch.tensor(ids, dtype=torch.long).to(DEVICE),<br/>            'mask': torch.tensor(mask, dtype=torch.long).to(DEVICE),<br/>            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long).to(DEVICE)<br/>            }<br/>        y = torch.tensor(y, dtype=torch.long).to(DEVICE)<br/>        <br/>        return x, y</span></pre><h2 id="4185" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Writing the main script to train the model</h2><p id="ad66" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Let us define first and foremost two functions to handle the training and evaluation steps:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="20d2" class="ql oi fq qi b bg qm qn l qo qp">def train(epoch, model, dataloader, loss_fn, optimizer, max_steps=None):<br/>    model.train()<br/>    total_acc, total_count = 0, 0<br/>    log_interval = 50<br/>    start_time = time.time()<br/><br/>    for idx, (inputs, label) in enumerate(dataloader):<br/>        optimizer.zero_grad()<br/>        predicted_label = model(inputs)<br/>        <br/>        loss = loss_fn(predicted_label, label)<br/>        loss.backward()<br/>        optimizer.step()<br/>        <br/>        total_acc += (predicted_label.argmax(1) == label).sum().item()<br/>        total_count += label.size(0)<br/>        <br/>        if idx % log_interval == 0:<br/>            elapsed = time.time() - start_time<br/>            print(<br/>                "Epoch {:3d} | {:5d}/{:5d} batches "<br/>                "| accuracy {:8.3f} | loss {:8.3f} ({:.3f}s)".format(<br/>                    epoch, idx, len(dataloader), total_acc / total_count, loss.item(), elapsed<br/>                )<br/>            )<br/>            total_acc, total_count = 0, 0<br/>            start_time = time.time()<br/><br/>        if max_steps is not None:<br/>            if idx == max_steps:<br/>                return {'loss': loss.item(), 'acc': total_acc / total_count}<br/>    <br/>    return {'loss': loss.item(), 'acc': total_acc / total_count}<br/><br/><br/>def evaluate(model, dataloader, loss_fn):<br/>    model.eval()<br/>    total_acc, total_count = 0, 0<br/><br/>    with torch.no_grad():<br/>        for idx, (inputs, label) in enumerate(dataloader):<br/>            predicted_label = model(inputs)<br/>            loss = loss_fn(predicted_label, label)<br/>            total_acc += (predicted_label.argmax(1) == label).sum().item()<br/>            total_count += label.size(0)<br/><br/>    return {'loss': loss.item(), 'acc': total_acc / total_count}</span></pre><p id="2d02" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We are getting closer to getting our main script up and running. Let’s stitch pieces together. We have:</p><ul class=""><li id="ac27" class="nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx nz oa ob bk">A <code class="cx qs qt qu qi b">BertDataset</code> class to handle the loading of the data</li><li id="ae04" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">A <code class="cx qs qt qu qi b">SentimentBERT</code> model which takes our Tiny-BERT model and adds an additional layer for our custom use case</li><li id="d808" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk"><code class="cx qs qt qu qi b">train()</code> and <code class="cx qs qt qu qi b">eval()</code> functions to handle those steps</li><li id="3bd1" class="nc nd fq ne b go oc ng nh gr od nj nk nl oe nn no np of nr ns nt og nv nw nx nz oa ob bk">A <code class="cx qs qt qu qi b">train_and_eval()</code> functions that bundles everything</li></ul><p id="7271" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">We will use <code class="cx qs qt qu qi b">argparse</code> to be able to launch our script with arguments. Such arguments are typically the train/eval/test files to run our model with any datasets, the path where our model will be stored, and parameters related to the training.</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="5b9b" class="ql oi fq qi b bg qm qn l qo qp">import pandas as pd<br/>import time<br/>import torch.nn as nn<br/>import torch<br/>import logging<br/>import numpy as np<br/>import argparse<br/><br/>from torch.utils.data import Dataset, DataLoader<br/>from transformers import BertTokenizer, BertModel<br/><br/>logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG)<br/>logging.getLogger().setLevel(logging.INFO)<br/><br/># --- CONSTANTS ---<br/>BERT_MODEL_NAME = 'small_bert/bert_en_uncased_L-2_H-128_A-2'<br/><br/>if torch.cuda.is_available():<br/>    logging.info(f"GPU: {torch.cuda.get_device_name(0)} is available.")<br/>    DEVICE = torch.device('cuda')<br/>else:<br/>    logging.info("No GPU available. Training will run on CPU.")<br/>    DEVICE = torch.device('cpu')<br/><br/># --- Data preparation and tokenization ---<br/>class BertDataset(Dataset):<br/>    def __init__(self, df, tokenizer, max_length=100):<br/>        super(BertDataset, self).__init__()<br/>        self.df=df<br/>        self.tokenizer=tokenizer<br/>        self.target=self.df['Target']<br/>        self.max_length=max_length<br/>        <br/>    def __len__(self):<br/>        return len(self.df)<br/>    <br/>    def __getitem__(self, idx):<br/>        <br/>        X = self.df['bodyText'].values[idx]<br/>        y = self.target.values[idx]<br/>        <br/>        inputs = self.tokenizer.encode_plus(<br/>            X,<br/>            pad_to_max_length=True,<br/>            add_special_tokens=True,<br/>            return_attention_mask=True,<br/>            max_length=self.max_length,<br/>        )<br/>        ids = inputs["input_ids"]<br/>        token_type_ids = inputs["token_type_ids"]<br/>        mask = inputs["attention_mask"]<br/><br/>        x = {<br/>            'ids': torch.tensor(ids, dtype=torch.long).to(DEVICE),<br/>            'mask': torch.tensor(mask, dtype=torch.long).to(DEVICE),<br/>            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long).to(DEVICE)<br/>            }<br/>        y = torch.tensor(y, dtype=torch.long).to(DEVICE)<br/>        <br/>        return x, y<br/><br/># --- Model definition ---<br/>class SentimentBERT(nn.Module):<br/>    def __init__(self, bert_model):<br/>        super().__init__()<br/>        self.bert_module = bert_model<br/>        self.dropout = nn.Dropout(0.1)<br/>        self.final = nn.Linear(in_features=128, out_features=3, bias=True) <br/>        <br/>    def forward(self, inputs):<br/>        ids, mask, token_type_ids = inputs['ids'], inputs['mask'], inputs['token_type_ids']<br/>        x = self.bert_module(ids, mask, token_type_ids)<br/>        x = self.dropout(x['pooler_output'])<br/>        out = self.final(x)<br/>        return out<br/><br/># --- Training loop ---<br/>def train(epoch, model, dataloader, loss_fn, optimizer, max_steps=None):<br/>    model.train()<br/>    total_acc, total_count = 0, 0<br/>    log_interval = 50<br/>    start_time = time.time()<br/><br/>    for idx, (inputs, label) in enumerate(dataloader):<br/>        optimizer.zero_grad()<br/>        predicted_label = model(inputs)<br/>        <br/>        loss = loss_fn(predicted_label, label)<br/>        loss.backward()<br/>        optimizer.step()<br/>        <br/>        total_acc += (predicted_label.argmax(1) == label).sum().item()<br/>        total_count += label.size(0)<br/>        <br/>        if idx % log_interval == 0:<br/>            elapsed = time.time() - start_time<br/>            print(<br/>                "Epoch {:3d} | {:5d}/{:5d} batches "<br/>                "| accuracy {:8.3f} | loss {:8.3f} ({:.3f}s)".format(<br/>                    epoch, idx, len(dataloader), total_acc / total_count, loss.item(), elapsed<br/>                )<br/>            )<br/>            total_acc, total_count = 0, 0<br/>            start_time = time.time()<br/><br/>        if max_steps is not None:<br/>            if idx == max_steps:<br/>                return {'loss': loss.item(), 'acc': total_acc / total_count}<br/>    <br/>    return {'loss': loss.item(), 'acc': total_acc / total_count}<br/><br/># --- Validation loop ---<br/>def evaluate(model, dataloader, loss_fn):<br/>    model.eval()<br/>    total_acc, total_count = 0, 0<br/><br/>    with torch.no_grad():<br/>        for idx, (inputs, label) in enumerate(dataloader):<br/>            predicted_label = model(inputs)<br/>            loss = loss_fn(predicted_label, label)<br/>            total_acc += (predicted_label.argmax(1) == label).sum().item()<br/>            total_count += label.size(0)<br/><br/>    return {'loss': loss.item(), 'acc': total_acc / total_count}<br/><br/># --- Main function ---<br/>def train_and_evaluate(**params):<br/><br/>    logging.info("running with the following params :")<br/>    logging.info(params)<br/><br/>    # Load pretrained tokenizers and bert model<br/>    # update the paths to whichever you are using<br/>    tokenizer = BertTokenizer.from_pretrained('models/bert_uncased_L-2_H-128_A-2/vocab.txt')<br/>    model = BertModel.from_pretrained('models/bert_uncased_L-2_H-128_A-2')<br/>    <br/>    # Training parameters<br/>    epochs = int(params.get('epochs'))<br/>    batch_size = int(params.get('batch_size'))<br/>    learning_rate = float(params.get('learning_rate'))<br/>    <br/>    #  Load the data<br/>    df_train = pd.read_csv(params.get('training_file'))<br/>    df_eval = pd.read_csv(params.get('validation_file'))<br/>    df_test = pd.read_csv(params.get('testing_file'))<br/><br/>    # Create dataloaders<br/>    train_ds = BertDataset(df_train, tokenizer, max_length=100)<br/>    train_loader = DataLoader(dataset=train_ds,batch_size=batch_size, shuffle=True)<br/>    eval_ds = BertDataset(df_eval, tokenizer, max_length=100)<br/>    eval_loader = DataLoader(dataset=eval_ds,batch_size=batch_size)<br/>    test_ds = BertDataset(df_test, tokenizer, max_length=100)<br/>    test_loader = DataLoader(dataset=test_ds,batch_size=batch_size)<br/>    <br/>    # Create the model<br/>    classifier = SentimentBERT(bert_model=model).to(DEVICE)<br/>    total_parameters = sum([np.prod(p.size()) for p in classifier.parameters()])<br/>    model_parameters = filter(lambda p: p.requires_grad, classifier.parameters())<br/>    params = sum([np.prod(p.size()) for p in model_parameters])<br/>    logging.info(f"Total params : {total_parameters} - Trainable : {params} ({params/total_parameters*100}% of total)")<br/>    <br/>    # Optimizer and loss functions<br/>    optimizer = torch.optim.Adam([p for p in classifier.parameters() if p.requires_grad], learning_rate)<br/>    loss_fn = nn.CrossEntropyLoss()<br/><br/>    # If dry run we only<br/>    logging.info(f'Training model with {BERT_MODEL_NAME}')<br/>    if args.dry_run:<br/>        logging.info("Dry run mode")<br/>        epochs = 1<br/>        steps_per_epoch = 1<br/>    else:<br/>        steps_per_epoch = None<br/>        <br/>    # Action !<br/>    for epoch in range(1, epochs + 1):<br/>        epoch_start_time = time.time()<br/>        train_metrics = train(epoch, classifier, train_loader, loss_fn=loss_fn, optimizer=optimizer, max_steps=steps_per_epoch)<br/>        eval_metrics = evaluate(classifier, eval_loader, loss_fn=loss_fn)<br/>        <br/>        print("-" * 59)<br/>        print(<br/>            "End of epoch {:3d} - time: {:5.2f}s - loss: {:.4f} - accuracy: {:.4f} - valid_loss: {:.4f} - valid accuracy {:.4f} ".format(<br/>                epoch, time.time() - epoch_start_time, train_metrics['loss'], train_metrics['acc'], eval_metrics['loss'], eval_metrics['acc']<br/>            )<br/>        )<br/>        print("-" * 59)<br/>    <br/>    if args.dry_run:<br/>        # If dry run, we do not run the evaluation<br/>        return None<br/>    <br/>    test_metrics = evaluate(classifier, test_loader, loss_fn=loss_fn)<br/>    <br/>    metrics = {<br/>        'train': train_metrics,<br/>        'val': eval_metrics,<br/>        'test': test_metrics,<br/>    }<br/>    logging.info(metrics)<br/>    <br/>    # save model and architecture to single file<br/>    if params.get('job_dir') is None:<br/>        logging.warning("No job dir provided, model will not be saved")<br/>    else:<br/>        logging.info("Saving model to {} ".format(params.get('job_dir')))<br/>        torch.save(classifier.state_dict(), params.get('job_dir'))<br/>    logging.info("Bye bye")<br/>    <br/>    <br/>if __name__ == '__main__':<br/>    # Create arguments here<br/>    parser = argparse.ArgumentParser()<br/>    parser.add_argument('--training-file', required=True, type=str)<br/>    parser.add_argument('--validation-file', required=True, type=str)<br/>    parser.add_argument('--testing-file', type=str)<br/>    parser.add_argument('--job-dir', type=str)<br/>    parser.add_argument('--epochs', type=float, default=2)<br/>    parser.add_argument('--batch-size', type=float, default=1024)<br/>    parser.add_argument('--learning-rate', type=float, default=0.01)<br/>    parser.add_argument('--dry-run', action="store_true")<br/><br/>    # Parse them<br/>    args, _ = parser.parse_known_args()<br/><br/>    # Execute training<br/>    train_and_evaluate(**vars(args))</span></pre><p id="9199" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This is great, but unfortunately, this model will take a long time to train. Indeed, with around 4.7M parameters to train, one step will take around 3s on a 16Gb Macbook Pro with Intel chip.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj qw"><img src="../Images/b5a00cef328f5d4ab3879f010a18ff24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*G9aqdhK_OWr1qZS8AAg6JA.png"/></div></figure><p id="10fb" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">3s per step can be quite long when you have 1238 steps to go and 10 epochs to complete…</p><p id="e0c0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">No GPU, no party.</p></div></div></div><div class="ab cb pi pj pk pl" role="separator"><span class="pm by bm pn po pp"/><span class="pm by bm pn po pp"/><span class="pm by bm pn po"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="18c4" class="oh oi fq bf oj ok qx gq om on qy gt op oq qz os ot ou ra ow ox oy rb pa pb pc bk">How to use Vertex AI and start the party?</h1><p id="ae2f" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk"><em class="ny">Short answer : Docker and gcloud.</em></p><p id="689e" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">If you do not have a powerful GPU on your laptop (as most of us do), and/or want to avoid burning your laptop’s cooling fan, you may want to move your script on a Cloud platform such as Google Cloud (disclaimer: I use Google Cloud at my job).</p><p id="c46a" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The nice thing about Google is it offers 300$ in credits when you open your own project with your Gmail account.</p><p id="98b8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">And as always, when it comes to transferring your code to somewhere else, Docker is usually the go-to solution.</p><h2 id="9da1" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Dockerizing the script</h2><p id="f658" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Let’s write a Docker image with GPU enabled. There are a lot of Docker images you can find on the official Docker repository, I chose the <em class="ny">pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime </em>as I use a Pytorch 2.2.2 version. Be sure to select a version with CUDA, otherwise you will have to install it yourself in your Dockerfile, and trust me, you don’t want to do that, except if you really have to.</p><p id="6265" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This Dockerfile will preinstall necessary CUDA dependencies and drivers and ensure we can use them in a custom training job, and run your python <code class="cx qs qt qu qi b">main.py</code> file with the arguments that you will pass once you call the image.</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="29e8" class="ql oi fq qi b bg qm qn l qo qp">FROM pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime<br/><br/>WORKDIR /src<br/>COPY . .<br/>RUN pip install --upgrade pip &amp;&amp; pip install -r requirements.txt<br/><br/>ENTRYPOINT ["python", "main.py"]</span></pre><h2 id="fa82" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Building and pushing an image to Google Cloud</h2><p id="1424" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Once our image is ready to be built, we need to build it and push it to a registry. It can be on any registry you like, but Google Cloud offers a service for that called Artefact Registry. You will therefore be able to store your images on Google Cloud very easily.</p><p id="2f0b" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Write this little file at the root of your directory, and be sure that the Dockerfile is at the same level:</p><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="7357" class="ql oi fq qi b bg qm qn l qo qp"># build.sh<br/><br/>export PROJECT_ID=&lt;your-project-id&gt;<br/>export IMAGE_REPO_NAME=pt_bert_sentiment<br/>export IMAGE_TAG=dev<br/>export IMAGE_URI=eu.gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG<br/><br/>gcloud builds submit --tag $IMAGE_URI .</span></pre><p id="5da8" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Run the <code class="cx qs qt qu qi b">build.sh </code>file, and after waiting a couple of minutes for the image to build, you should see something like: <br/><strong class="ne fr">eu.gcr.io/&lt;your-project-id&gt;/pt_bert_sentiment:dev SUCCESS</strong></p><h2 id="6441" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Creating a job on Vertex AI</h2><p id="1cf0" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Once your image has been built and pushed to Artefact Registry, we will now be able to tell Vertex AI to run this image on any machine we want, including ones with powerful GPUs ! Google offers a $300 credit when you create your own GCP project, it will be largely sufficient to run our model.</p><p id="8065" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Costs are available <a class="af nb" href="https://cloud.google.com/vertex-ai/pricing#custom-trained_models" rel="noopener ugc nofollow" target="_blank">here</a>. In our case, we will take the <em class="ny">n1-standard-4 </em>machine at $0.24/hr, and attach a <em class="ny">NVIDIA T4</em> GPU at $0.40/hr.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rc"><img src="../Images/8405cc80d311c01147fa5b3ed826a415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p1Sc0D78xW_HgFe04Owj_Q.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(source : Google Cloud)</figcaption></figure><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rd"><img src="../Images/0cd5fc0930e342b345abb1060e0593f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I7ADcxcsSUxZoIcwINoRTQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(source : Google Cloud)</figcaption></figure><p id="e438" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Create a <code class="cx qs qt qu qi b">job.sh</code> file as follows, by specifying which region you are in and what kind of machine you use. Refer to the link above if you are in a different region as costs may vary.</p><blockquote class="re rf rg"><p id="e5ed" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">You’ll also need to pass arguments to your training script. The syntax for the <code class="cx qs qt qu qi b">gcloud ai custom-jobs create</code> consists of 2 parts:</p><p id="71bc" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">- the arguments related to the job itself : <code class="cx qs qt qu qi b">--region</code> , <code class="cx qs qt qu qi b">--display-name</code> , <code class="cx qs qt qu qi b">--worker-pool-spec</code> , <code class="cx qs qt qu qi b">--service-account</code> , and <code class="cx qs qt qu qi b">--args</code></p><p id="1204" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">- the arguments related to the training : <code class="cx qs qt qu qi b">--training-file</code> , <code class="cx qs qt qu qi b">--epochs</code> , etc.</p><p id="465c" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">The latter needs to be preceded by the <code class="cx qs qt qu qi b">--args</code> to indicate that all following arguments are related to the training Python script.</p><p id="76b9" class="nc nd ny ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Ex: supposing our script takes 2 arguments x and y, we would have: <br/><code class="cx qs qt qu qi b">--args=x=1,y=2</code></p></blockquote><pre class="ml mm mn mo mp qh qi qj bp qk bb bk"><span id="00fb" class="ql oi fq qi b bg qm qn l qo qp"># job.sh<br/><br/>export PROJECT_ID=&lt;your-project-id&gt;<br/>export BUCKET=&lt;your-bucket-id&gt;<br/>export REGION="europe-west4"<br/>export SERVICE_ACCOUNT=&lt;your-service-account&gt;<br/>export JOB_NAME="pytorch_bert_training"<br/>export MACHINE_TYPE="n1-standard-4"  # We can specify GPUs here<br/>export ACCELERATOR_TYPE="NVIDIA_TESLA_T4"<br/>export IMAGE_URI="eu.gcr.io/$PROJECT_ID/pt_bert_sentiment:dev"<br/><br/><br/>gcloud ai custom-jobs create \<br/>--region=$REGION \<br/>--display-name=$JOB_NAME \<br/>--worker-pool-spec=machine-type=$MACHINE_TYPE,accelerator-type=$ACCELERATOR_TYPE,accelerator-count=1,replica-count=1,container-image-uri=$IMAGE_URI \<br/>--service-account=$SERVICE_ACCOUNT \<br/>--args=\<br/>--training-file=gs://$BUCKET/data/train.csv,\<br/>--validation-file=gs://$BUCKET/data/eval.csv,\<br/>--testing-file=gs://$BUCKET/data/test.csv,\<br/>--job-dir=gs://$BUCKET/model/model.pt,\<br/>--epochs=10,\<br/>--batch-size=128,\<br/>--learning-rate=0.0001</span></pre><h2 id="d91f" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">Running the job on Vertex AI</h2><p id="42f9" class="pw-post-body-paragraph nc nd fq ne b go pd ng nh gr pe nj nk nl pf nn no np pg nr ns nt ph nv nw nx fj bk">Launch the script, and navigate to your GCP project, in the Training section under the Vertex menu .</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rh"><img src="../Images/d622336b28fc8d7f5f60fbb0431498ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VSmqgPskAaeQb2FPuGv4sA.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(image from author)</figcaption></figure><p id="b956" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Launch the script, and navigate to the console. You should see the job status as “Pending”, and then “Training”.</p><p id="46aa" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">To ensure the GPU is being used, you can check the job and its ressources :</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ri"><img src="../Images/4f18577283659330ba871d2d88baf21b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Os5MCjlrzZ4RuR0MFmnpfQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(image from author)</figcaption></figure><p id="2a73" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">This indicates that we are training with a GPU, we should therefore expect a significant speed-up now ! Let’s have a look at the logs:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj rj"><img src="../Images/959225237e7b4fa03ac158ba31a68e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*qsAamE-BdY2lZ3QcTGvQbQ.png"/></div></figure><p id="f080" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Less than 10 minutes to run 1 epoch, vs 1hr/epoch on CPU ! We have offloaded the training to Vertex and accelerated the training process. We could decide to launch other jobs with different configurations, without overloading our laptop’s capabilities.</p><p id="7cf0" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">What about the final accuracy of the model ? Well after 10 epochs, it is around 94–95%. We could let it run even longer and see if the score improves (we can also add an early stopping callback to avoid overfitting)</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div class="mi mj rk"><img src="../Images/40b37ce0f0bb8c48db7b04e1152a1ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*QHXQq2knoduoRdtYAaf51g.png"/></div></figure><h2 id="f090" class="pq oi fq bf oj pr ps pt om pu pv pw op nl px py pz np qa qb qc nt qd qe qf qg bk">How does our model perform ?</h2><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rl"><img src="../Images/b3808a8189226c3c73eacc46470f071c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*13kcuq9rEO5Pdrqp8MtmvQ.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">(image from author)</figcaption></figure><p id="9c56" class="pw-post-body-paragraph nc nd fq ne b go nf ng nh gr ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx fj bk">Time to party !</p></div></div></div></div>    
</body>
</html>