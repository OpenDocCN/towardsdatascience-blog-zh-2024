["```py\n# IMPORTING DATASET #\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\n\ndataset_dict = {\n    'Rainfall': [0.0, 2.0, 7.0, 18.0, 3.0, 3.0, 0.0, 1.0, 0.0, 25.0, 0.0, 18.0, 9.0, 5.0, 0.0, 1.0, 7.0, 0.0, 0.0, 7.0, 5.0, 3.0, 0.0, 2.0, 0.0, 8.0, 4.0, 4.0],\n    'Temperature': [29.4, 26.7, 28.3, 21.1, 20.0, 18.3, 17.8, 22.2, 20.6, 23.9, 23.9, 22.2, 27.2, 21.7, 27.2, 23.3, 24.4, 25.6, 27.8, 19.4, 29.4, 22.8, 31.1, 25.0, 26.1, 26.7, 18.9, 28.9],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'WindSpeed': [2.1, 21.2, 1.5, 3.3, 2.0, 17.4, 14.9, 6.9, 2.7, 1.6, 30.3, 10.9, 3.0, 7.5, 10.3, 3.0, 3.9, 21.9, 2.6, 17.3, 9.6, 1.9, 16.0, 4.6, 3.2, 8.3, 3.2, 2.2],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\ndf = pd.DataFrame(dataset_dict)\n\n# Set feature matrix X and target vector y\nX, y = df.drop(columns='Play'), df['Play']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5, shuffle=False)\nprint(pd.concat([X_train, y_train], axis=1), end='\\n\\n')\nprint(pd.concat([X_test, y_test], axis=1))\n```", "```py\nfrom sklearn.preprocessing import PowerTransformer\n\n# Initialize and fit the PowerTransformer\npt = PowerTransformer(standardize=True) # Standard Scaling already included\nX_train_transformed = pt.fit_transform(X_train)\nX_test_transformed = pt.transform(X_test)\n```", "```py\nfrom fractions import Fraction\n\ndef calc_target_prob(attr):\n    total_counts = attr.value_counts().sum()\n    prob_series = attr.value_counts().apply(lambda x: Fraction(x, total_counts).limit_denominator())\n    return prob_series\n\nprint(calc_target_prob(y_train))\n```", "```py\ndef calculate_class_probabilities(X_train_transformed, y_train, feature_names):\n    classes = y_train.unique()\n    equations = pd.DataFrame(index=classes, columns=feature_names)\n\n    for cls in classes:\n        X_class = X_train_transformed[y_train == cls]\n        mean = X_class.mean(axis=0)\n        std = X_class.std(axis=0)\n        k1 = 1 / (std * np.sqrt(2 * np.pi))\n        k2 = 2 * (std ** 2)\n\n        for i, column in enumerate(feature_names):\n            equation = f\"{k1[i]:.3f}·exp(-(x-({mean[i]:.2f}))²/{k2[i]:.3f})\"\n            equations.loc[cls, column] = equation\n\n    return equations\n\n# Use the function with the transformed training data\nequation_table = calculate_class_probabilities(X_train_transformed, y_train, X.columns)\n\n# Display the equation table\nprint(equation_table)\n```", "```py\nfrom scipy.stats import norm\n\ndef calculate_class_probability_products(X_train_transformed, y_train, X_new, feature_names, target_name):\n    classes = y_train.unique()\n    n_features = X_train_transformed.shape[1]\n\n    # Create column names using actual feature names\n    column_names = [target_name] + list(feature_names) + ['Product']\n\n    probability_products = pd.DataFrame(index=classes, columns=column_names)\n\n    for cls in classes:\n        X_class = X_train_transformed[y_train == cls]\n        mean = X_class.mean(axis=0)\n        std = X_class.std(axis=0)\n\n        prior_prob = np.mean(y_train == cls)\n        probability_products.loc[cls, target_name] = prior_prob\n\n        feature_probs = []\n        for i, feature in enumerate(feature_names):\n            prob = norm.pdf(X_new[0, i], mean[i], std[i])\n            probability_products.loc[cls, feature] = prob\n            feature_probs.append(prob)\n\n        product = prior_prob * np.prod(feature_probs)\n        probability_products.loc[cls, 'Product'] = product\n\n    return probability_products\n\n# Assuming X_new is your new sample reshaped to (1, n_features)\nX_new = np.array([-1.28, 1.115, 0.84, 0.68]).reshape(1, -1)\n\n# Calculate probability products\nprob_products = calculate_class_probability_products(X_train_transformed, y_train, X_new, X.columns, y.name)\n\n# Display the probability product table\nprint(prob_products)\n```", "```py\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\n# Initialize and train the Gaussian Naive Bayes model\ngnb = GaussianNB()\ngnb.fit(X_train_transformed, y_train)\n\n# Make predictions on the test set\ny_pred = gnb.predict(X_test_transformed)\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Print the accuracy\nprint(f\"Accuracy: {accuracy:.4f}\")\n```", "```py\nimport pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndataset_dict = {\n    'Rainfall': [0.0, 2.0, 7.0, 18.0, 3.0, 3.0, 0.0, 1.0, 0.0, 25.0, 0.0, 18.0, 9.0, 5.0, 0.0, 1.0, 7.0, 0.0, 0.0, 7.0, 5.0, 3.0, 0.0, 2.0, 0.0, 8.0, 4.0, 4.0],\n    'Temperature': [29.4, 26.7, 28.3, 21.1, 20.0, 18.3, 17.8, 22.2, 20.6, 23.9, 23.9, 22.2, 27.2, 21.7, 27.2, 23.3, 24.4, 25.6, 27.8, 19.4, 29.4, 22.8, 31.1, 25.0, 26.1, 26.7, 18.9, 28.9],\n    'Humidity': [85.0, 90.0, 78.0, 96.0, 80.0, 70.0, 65.0, 95.0, 70.0, 80.0, 70.0, 90.0, 75.0, 80.0, 88.0, 92.0, 85.0, 75.0, 92.0, 90.0, 85.0, 88.0, 65.0, 70.0, 60.0, 95.0, 70.0, 78.0],\n    'WindSpeed': [2.1, 21.2, 1.5, 3.3, 2.0, 17.4, 14.9, 6.9, 2.7, 1.6, 30.3, 10.9, 3.0, 7.5, 10.3, 3.0, 3.9, 21.9, 2.6, 17.3, 9.6, 1.9, 16.0, 4.6, 3.2, 8.3, 3.2, 2.2],\n    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes']\n}\n\ndf = pd.DataFrame(dataset_dict)\n\n# Prepare data for model\nX, y = df.drop('Play', axis=1), (df['Play'] == 'Yes').astype(int)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)\n\n# Apply PowerTransformer\npt = PowerTransformer(standardize=True)\nX_train_transformed = pt.fit_transform(X_train)\nX_test_transformed = pt.transform(X_test)\n\n# Train the model\nnb_clf = GaussianNB()\nnb_clf.fit(X_train_transformed, y_train)\n\n# Make predictions\ny_pred = nb_clf.predict(X_test_transformed)\n\n# Check accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n```"]