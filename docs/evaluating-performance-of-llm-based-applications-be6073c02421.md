# 评估基于LLM的应用性能

> 原文：[https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30](https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30)

## **现实世界需求的评估框架**

[](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[![Anurag Bhagat](../Images/3711a1fce6e2a45d649e534f08c3d0ca.png)](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------) [Anurag Bhagat](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)

·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------) ·阅读时长7分钟·2024年9月30日

--

![](../Images/dc652003ac88a941b6097d5613d410b4.png)

*来源：借助AI（OpenAI的Dall-E模型）生成*

# 摘要

自从OpenAI的ChatGPT在2022年11月席卷全球以来，大型语言模型（LLMs）已经彻底改变了各行各业的多种应用，从自然语言理解到文本生成。然而，它们的性能需要严格且多维度的评估指标，以确保它们满足实际世界中准确性、效率、可扩展性和伦理考虑等方面的要求。本文概述了一套广泛的指标和方法，用于衡量基于LLM的应用性能，提供了平衡技术性能与用户体验和业务需求的评估框架的见解。

本文并不是关于衡量LLM应用性能的所有指标的全面指南，而是提供了一个关于需要关注的关键维度的视角，并列出了一些指标示例。这将帮助你理解如何构建评估标准，最终的选择将取决于你的实际应用场景。

尽管本文侧重于基于LLM的应用，但这一点也可以推广到其他领域。

# 1. 引言

## 1.1. LLM基础应用：定义与范围

如今，市面上不乏大型语言模型（LLMs）。像GPT-4、Meta的LLaMA、Anthropic的Claude 3.5 Sonnet，或者亚马逊的Titan Text Premier等LLM，都能够理解并生成类人文本，适用于多种下游应用，如面向客户的聊天机器人、创意内容生成、语言翻译等。

## 1.2. 性能评估的重要性

LLM的评估并不简单，不像传统的机器学习模型，后者有着相对标准化的评估标准和数据集。LLM的“黑箱”特性以及其下游使用案例的多样性，要求在多个考虑因素上进行多维度的性能测量。不充分的评估可能会导致成本超支、用户体验不佳，甚至给部署的组织带来风险。

# 2. LLM性能的四个关键维度

![](../Images/b3710797fed24fa0bee8b89a5044ad97.png)

来源：借助AI（OpenAI的Dall-E模型）生成

有三种关键方式来衡量基于LLM的应用性能——即准确性、成本和延迟。此外，确保拥有一套负责任的AI标准也至关重要，以确保应用不会造成伤害。

就像经典机器学习应用中的偏差与方差权衡一样，对于LLM，我们必须考虑准确性与成本+延迟之间的权衡。通常，这将是一项平衡工作，旨在创建一个“准确”（稍后我们将定义这一点）且足够快速且具有成本效益的应用。LLM的选择以及支持的应用架构将极大地依赖于我们旨在实现的最终用户体验。

## **2.1. 准确性**

我在这里使用“准确性”这一术语时较为宽泛，因为它有一个非常具体的含义，但作为英语单词使用时，能够传达意思，而非数学术语。

应用的准确性取决于实际使用案例——无论是应用进行分类任务，还是创建文本块，或是用于命名实体识别（NER）、检索增强生成（RAG）等专业任务。

**2.1.1. 分类使用案例**

对于情感分析（正面/负面/中性）、主题建模和命名实体识别等分类任务，经典的机器学习评估指标是合适的。它们通过混淆矩阵的各个维度来衡量准确性。典型的度量标准包括精确率、召回率、F1值等。

**2.1.2. 文本生成使用案例——包括摘要和创意内容**

[BLEU](https://en.wikipedia.org/wiki/BLEU)、[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)#:~:text=The%20metrics%20compare%20an%20automatically,produced%20summary%20and%20the%20reference) 和 [METEOR](https://en.wikipedia.org/wiki/METEOR) 分数是常用的文本生成任务评估指标，特别是用于翻译和摘要。为了简化，人们也会通过将BLEU和ROUGE分数结合使用F1分数。还有一些额外的指标，如困惑度（Perplexity），对于评估LLM本身特别有用，但对于评估完整应用的性能则不太有用。上述所有指标的最大挑战在于，它们关注的是文本相似度，而不是语义相似度。根据应用场景，文本相似度可能不足以满足需求，因此还应使用语义接近度的衡量标准，如[SemScore](https://huggingface.co/blog/g-ronimo/semscore)。

**2.1.3\. RAG应用场景 —— 包括摘要和创意内容**

在基于RAG的应用中，评估需要先进的指标来捕捉检索和生成步骤的性能。在检索方面，可以使用召回率（recall）和精准率（precision）来比较相关文档和已检索文档。在生成方面，可以使用额外的指标，如困惑度（Perplexity）、幻觉率（Hallucination Rate）、事实准确性（Factual Accuracy）或语义一致性（Semantic coherence）。[这篇文章](https://medium.com/@daniel.puenteviejo/key-metrics-for-evaluating-a-rag-system-f20b8bcae318)描述了在评估中可能需要包括的关键指标。

## 2.2\. 延迟（和吞吐量）

在许多情况下，应用的延迟和吞吐量决定了其最终的可用性或使用体验。在如今这个网络速度飞快的时代，用户不愿意等待响应，尤其是在执行关键任务时。

延迟越低，用户面对面应用中的用户体验越好，这些应用需要实时响应。对于以批处理方式执行的工作负载（例如，用于后期使用的客户服务电话转录），这可能就不那么重要。通常，通过水平或垂直扩展可以改善延迟和吞吐量，但延迟仍然可能在根本上依赖于整体应用的架构方式，包括LLM（大语言模型）的选择。一个很好的基准工具来测试不同LLM API的速度是[人工分析](https://artificialanalysis.ai/)。这个工具与其他侧重于LLM质量的排行榜互为补充，如LMSYS聊天机器人竞技场、Hugging Face开放LLM排行榜和斯坦福的HELM，这些排行榜更多聚焦于输出质量。

延迟是一个关键因素，它将继续推动我们朝着小型语言模型（Small Language Models）发展，特别是在需要快速响应时间的应用中，部署到边缘设备可能是必需的。

## 2.3\. 成本

我们正在构建LLM应用程序来解决业务问题并提高效率，旨在解决客户问题，同时为我们的业务创造底线影响。所有这些都需要成本，对于生成式AI应用程序来说，这些成本可能会迅速累积。

根据我的经验，当人们考虑LLM应用程序的成本时，通常会讨论推理成本（基于#tokens）、微调成本，甚至LLM预训练成本。然而，对于总拥有成本（包括基础设施和人员成本）的讨论却相对有限。

成本因部署类型（云端、本地、混合）、使用规模和架构的不同而有所不同。它也会根据应用程序开发的生命周期变化很大。

+   **基础设施成本**——包括推理、微调成本，或可能的预训练成本，以及与应用程序相关的基础设施——内存、计算、网络和存储成本。根据构建应用程序的位置，这些成本可能不需要单独管理，或者如果使用如AWS Bedrock等托管服务，则可以将其捆绑为一项成本。

+   **团队和人员成本**——我们有时可能需要一支庞大的团队来构建、监控和改进这些应用程序。这包括构建应用程序的工程师（数据科学家和ML工程师、DevOps和MLOps工程师），以及参与设计和开发的跨职能团队，如产品/项目经理、人力资源、法律和风险人员。我们可能还需要注释和标注团队为我们提供高质量的数据。

+   **其他成本**——可能包括数据获取和管理成本、客户访谈成本、软件和许可证费用、运营成本（MLOps/LLMOps）、安全性和合规性等。

## 2.4\. 伦理与负责任的AI指标

基于LLM的应用程序仍然是新兴的，许多只是概念验证。然而，它们正在成为主流——我看到AI已经集成到我每天使用的许多应用中，包括Google、LinkedIn、亚马逊购物应用、WhatsApp、InstaCart等。随着人类与AI交互的界限变得越来越模糊，我们遵守负责任的AI标准变得更加重要。更大的问题是，这些标准目前并不存在。世界各地（包括[白宫的行政命令](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)）的相关法规仍在制定中。因此，应用程序创建者需要运用最好的判断力。以下是一些需要牢记的关键维度：

+   **公平性和偏见**：衡量模型输出是否在种族、性别、民族和其他维度上不存在偏见和公平性问题。

+   **有害内容**：衡量模型生成或放大有害、冒犯性或贬损内容的程度。

+   **可解释性**：评估模型决策的可解释程度。

+   **幻觉/事实一致性**：确保模型生成事实正确的回应，尤其是在医疗和金融等关键行业中。

+   **隐私**：衡量模型处理个人身份信息（PII）、受保护健康信息（PHI）及其他敏感数据的能力，确保符合如GDPR等法规的要求。

# 3\. 那么这些指标足够吗？

嗯…其实并非如此！虽然我们讨论的四个维度和指标是非常重要的，并且是一个很好的起点，但它们并不总是足以捕捉到上下文或用户的独特偏好。考虑到人类通常是输出的最终消费者，他们最适合评估基于LLM的应用程序的表现，尤其是在复杂或未知场景中。获取人类反馈有两种方式：

+   **直接通过人类参与**：人类评估者对LLM的输出提供定性反馈，关注流畅性、一致性以及与人类期望的一致性。这种反馈对于改进模型的人类化行为至关重要。

+   **间接通过次级指标**：通过终端用户的A/B测试，可以比较次级指标，如用户参与度和满意度。例如，我们可以通过比较点击率和转化率，来评估使用生成式AI的超个性化营销的效果。

# 4\. 结论

作为顾问，大多数问题的答案是“视情况而定”。对于LLM应用的评估标准也是如此。根据不同的使用场景、行业和功能，必须在准确性、延迟、成本和负责任的AI之间找到合适的指标平衡。这应该始终辅以人类评估，以确保我们在实际场景中测试应用程序。例如，医疗和金融场景会重视准确性和安全性，以及来源的可信性，娱乐应用则重视创造力和用户参与度。在构建应用程序的商业案例时，成本将仍然是一个关键因素，尽管LLM推理成本的快速下降可能很快会降低准入门槛。延迟通常是一个限制因素，且需要通过正确的模型选择和基础设施优化来保持性能。

> 本文中的所有观点均为作者个人观点，并不代表对任何产品或服务的支持。
