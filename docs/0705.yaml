- en: AI vs. Human Insight in Financial Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ai-vs-human-insight-in-financial-analysis-89d3408eb6d5?source=collection_archive---------6-----------------------#2024-03-15](https://towardsdatascience.com/ai-vs-human-insight-in-financial-analysis-89d3408eb6d5?source=collection_archive---------6-----------------------#2024-03-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How the Bud Light boycott and SalesForce’s innovation plans confuse the best
    LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mihail.dungarov?source=post_page---byline--89d3408eb6d5--------------------------------)[![Misho
    Dungarov](../Images/c65eb57145dada4f02acbb3f145a9b77.png)](https://medium.com/@mihail.dungarov?source=post_page---byline--89d3408eb6d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--89d3408eb6d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--89d3408eb6d5--------------------------------)
    [Misho Dungarov](https://medium.com/@mihail.dungarov?source=post_page---byline--89d3408eb6d5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--89d3408eb6d5--------------------------------)
    ·10 min read·Mar 15, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f3d40b0e75e91276eebdb39ec53680c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Dall-E 3](https://platform.openai.com/docs/guides/images/)
  prefs: []
  type: TYPE_NORMAL
- en: Can the best AI models today, accurately pick up the most important message
    out of a company earnings call? They can certainly pick up SOME points but how
    do we know if those are the important ones? Can we *prompt* them into to doing
    a better job? To find those answers, we look at what the best journalists in the
    field have done and try to get as close to that with AI
  prefs: []
  type: TYPE_NORMAL
- en: The Challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, I look at 8 recent company earnings calls and ask the current
    contestants for smartest AIs ([Claude 3](https://www.anthropic.com/news/claude-3-family),
    [GPT-4](https://openai.com/gpt-4) and [Mistral Large](https://mistral.ai/news/mistral-large/))
    what they think is important. Then compare the results to what some of the best
    names in Journalism (Reuters, Bloomberg, and Barron’s) have said about those exact
    reports.
  prefs: []
  type: TYPE_NORMAL
- en: Why care about this?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Significance of Earnings Calls
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earnings calls are quarterly events where senior management reviews the company’s
    financial results. They discuss the company’s performance, share commentary, and
    sometimes preview future plans. These discussions can significantly impact the
    company’s stock price. Management explains their future expectations and reasons
    for meeting or surpassing past forecasts. The management team offers invaluable
    insights into the company’s actual condition and future direction.
  prefs: []
  type: TYPE_NORMAL
- en: The Power of Automation in Earnings Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Statista reports that there are just under [4000 companies listed on the NASDAQ](https://www.statista.com/statistics/1330817/nasdaq-number-of-listed-companies-by-domicile/)
    and about [58,000 globally](https://focus.world-exchanges.org/articles/number-listed-companies)
    according to one estimate.
  prefs: []
  type: TYPE_NORMAL
- en: A typical conference call lasts roughly 1 hour. To just listen to all NASDAQ
    companies, one would need at least 10 people working full-time for the entire
    quarter. And this doesn’t even include the more time-consuming tasks like analyzing
    and comparing financial reports.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Large brokerages might manage this workload, but it’s unrealistic for individual
    investors. Automation in this area could level the playing field, making it easier
    for everyone to understand quarterly earnings.
  prefs: []
  type: TYPE_NORMAL
- en: While this may just be within reach of large brokerages, it is not feasible
    for private investors. Therefore, any reliable automation in this space will be
    a boon, especially for democratizing the understanding of quarterly earnings.
  prefs: []
  type: TYPE_NORMAL
- en: The Process of Testing AI as a Financial Analyst
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To test how well the best LLMs of the day can do this job. I decided to compare
    the main takeaways by humans and see how well AI can mimic that. Here are the
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Pick some companies with recent earnings call transcripts and matching news
    articles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide the LLMs with the full transcript as context and ask them to provide
    **the top three bullet points** that seem most impactful for the value of the
    company. This is important as, providing a longer summary becomes progressively
    easier — there are only so many important things to say.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To ensure we maximise the quality of the output, I vary the way I phrase the
    problem to the AI (using different prompts): Ranging from simply asking for a
    summary, adding more detailed instructions, adding previous transcripts and some
    combinations of those.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, compare those with the 3 most important points from the respective
    news article and use the overlap as a measure of success.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary of Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPT-4 shows best performance at 80% when providing it the previous quarter’s
    transcript and using a set of instructions on how to analyse transcripts well
    (Chain of Thought). Notably, just using correct instructions increases GPT-4 performance
    from 51% to 75%.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/64789c98fb1056fbb549b6dbe7a3bd5a.png)'
  prefs: []
  type: TYPE_IMG
- en: GPT-4 shows the best results and responds best to prompting (80%) — i.e. adding
    previous results and dedicated instructions on how to analyse results. Without
    sophisticated prompting, Claude 3 Opus works best (67%). Image and data by the
    author
  prefs: []
  type: TYPE_NORMAL
- en: 'Next best performers are:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Claude 3 Opus (67%) — Without sophisticated prompting, Claude 3 Opus works
    best.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — Mistral Large (66%) when adding supporting instructions (i.e. Chain of Thought)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Chain-of-thought (CoT) and Think Step by Step (SxS) seem to work well for
    GPT-4 but are detrimental for other models.** This suggests there is still a lot
    to be learned about what prompts work for each LLM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chain-of-Thought (CoT) seems almost always outperforms Step-by-step (SxS)**.
    This means tailored financial knowledge of priorities for analysis helps. The
    specific instructions provided are listed at the bottom of the article.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**More data-less sense:** Adding a previous period transcript to the model
    context seems to be at least slightly and at worst significantly detrimental to
    results across the board than just focusing on the latest results (except for
    GPT-4 + CoT). Potentially, there is much irrelevant information introduced from
    a previous transcript and a relatively small amount of specific facts to make
    a quarter-on-quarter comparison. Mistral Large’s performance drops significantly,
    note that its context window is just 32k tokens vs the significantly larger ones
    for the others (2 transcripts + prompt actually just barely fit under 32k tokens).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Claude-3 Opus and Sonnet perform very closely**, with Sonnet actually outperforming
    Opus in some cases. However, this tends to be by a few %-age points and can therefore
    be attributed to the randomness of results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that, as mentioned, results show a high degree of variability and the **range
    of outcomes is within +/-6%**. For that reason, I have **rerun all analysis 3
    times** and am showing the averages. However, the +/-6% range is not sufficient
    to significantly upend any of the above conclusions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What do LLMs get right and wrong?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How the Bud Light Boycott and Salesforce’s AI plans confused the best AIs
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This task offers some easy wins: guessing that results are about the latest
    revenue numbers and next year’s projections is fairly on the nose. Unsurprisingly,
    this is where models get things right most of the time.'
  prefs: []
  type: TYPE_NORMAL
- en: The table below gives an overview of what was mentioned in the news and what
    LLMs chose differently when summarized in just a few words.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb1f72934bbfb2a64ec80c3656f2d44f.png)'
  prefs: []
  type: TYPE_IMG
- en: '“Summarize each bullet with up to 3 words”: The top three themes in the news
    vs themes the LLMs picked that were not on that list. Each model was asked to
    provide a 2–3 word summary of the bullet points. A model will have 6 sets of top
    3 choices (i.e. 24) and these are the 3 that most often were not relevant when
    compared to news summaries. Note that in some cases, comparing the top and bottom
    table may feel like both sound the same, this is mostly because each bullet is
    actually significantly more detailed and may have a lot of additional / contradictory
    information missed in the 2–3 word summary'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, I tried to look for any trends of what the models consistently miss.
    Those generally Fall into a few categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Making sense of changes:** In the above results, LLMs have been able to understand
    fairly reliably what to look for: earnings, sales, dividend, and guidance, however,
    making sense of what is significant is still very elusive. For instance, common-sense
    might suggest that Q4 2023 results will be a key topic for any company and this
    is what the LLMs pick. However, Nordstrom talks about muted revenue and demand
    expectations for 2024 which pushes Q4 2023 results aside in terms of importance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hallucinations:** as is well documented, LLMs tend to make up facts. In this
    case, despite having instructions to “only include facts and metrics from the
    context” some metrics and dates end up being made up. The models unfortunately
    will not be shy about talking about the Q4 2024 earnings by referring to them
    as already available and using the 2023 numbers for them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Significant one-off events:** Unexpected one-off events are surprisingly
    often missed by LLMs. For instance, **the boycott of Bud Light** drove sales of
    the best-selling beer in the US down by 15.9% for *Anheuser-Busch* and is discussed
    at length in the transcripts. The number alone should appear significant, however
    it was missed by all models in the sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Actions speak louder than words:** Both GPT and Claude highlight innovation
    and the commitment to AI as important.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: — Salesforce (CRM) talks at length about a heavy focus on AI and Data Cloud
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: — Snowflake appointed their SVP of AI and former exec of Google Ads as CEO (Sridhar
    Ramaswamy), similarly signaling a focus on leveraging AI technology.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Both signal a shift to innovation & AI. **However, journalists and analysts
    are not as easily tricked into mistaking words for actions.** In the article analyzing
    CRM’s earnings, the subtitle reads Salesforce Outlook Disappoints as AI Fails
    to Spark Growth. However, Salesforce has been trying to tango with AI for a while
    and the forward-looking plans to use AI are not even mentioned. Salesforce’s transcript
    mentions AI 91 times while Snowflake’s less than half of that at 39\. However,
    humans can make the distinction in meaning: Bloomberg’s article [link] on the
    appointment of a new CEO: His elevation underscores a focus on AI for Snowflake.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Experiment design and choices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Why Earnings call transcripts?** The more intuitive choice may be company
    filings, however, I find transcripts to present a more natural and less formal
    discussion of events. I believe transcripts give the LLM as a reasoning engine
    a better chance to glean more natural commentary of events as opposed to the dry
    and highly regulated commentary of earnings. The calls are mostly management presentations,
    which might skew things toward a more positive view. However, my analysis has
    shown the performance of the LLMs seems similar between positive and negative
    narratives.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Choice of Companies:** I chose stocks that have published Q4 2023 earnings
    reports between 25 Feb and 5 March and have been reported on by one of Reuters,
    Bloomberg, or Barron’s. This ensures that the results are timely and that the
    models have not been trained on that data yet. Plus, everyone always talks about
    AAPL and TSLA, so this is something different. Finally, the reputation of these
    journalistic houses ensures a meaningful comparison. The 8 stocks we ended up
    with are: *Autodesk (ADSK), BestBuy (BBY), Anheuser-Busch InBev (BUD), Salesforce
    (CRM), DocuSign (DOCU), Nordstrom (JWN), Kroger (KR), Snowflake (SNOW)*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Variability of results** LLM results can vary between runs so I have run
    all experiments 3 times and show an average. All analysis for all models was done
    using temperature 0 which is commonly used to minimize variation of results. In
    this case, I have observed different runs have as much as 10% difference in performance.
    This is due to the small sample (only 24 data points 8 stocks by 3 statements)
    and the fact that we are basically asking an LLM to choose one of many possible
    statements for the summary, so when this happens with some randomness it can naturally
    lead to picking some of them differently.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Choice of Prompts:** For each of the 3 LLMs in comparison try out 4 different
    prompting approaches:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Naive** — The prompt simply asks the model to determine the most likely impact
    on the share price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chain-of-Thought (CoT)** — where I provide a detailed list of steps to follow
    when choosing a summary. This is inspired and loosely follows [[Wei et. al. 2022]](https://arxiv.org/abs/2201.11903)
    work outlining the Chain of Thought approach, providing reasoning steps as part
    of the prompt dramatically improves results. These additional instructions, in
    the context of this experiment, include typical drivers of price movements: changes
    to expected performance in revenue, costs, earnings, litigation, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step by Step (SxS)** aka Zero-shot CoT, inspired by [Kojima et.al (2022)](https://arxiv.org/abs/2205.11916)
    where they discovered that simply adding the phrase “Let’s think step by step”
    improves performance. I ask the LLMs to think step-by-step and describe their
    logic before answering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Previous transcript** — finally, I run all three of the above prompts once
    more by including the transcript from the previous quarter (in this case Q3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From what we can see above, Journalists’ and Research Analysts’ jobs seem safe
    for now, as most LLMs struggle to get more than two of three answers correctly.
    In most cases, this just means guessing that the meeting was about the latest
    revenue and next year’s projections.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, despite all the limitations of this test, we can still see some clear
    conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy level is fairly low for most models. Even GPT-4’s best performance
    of 80% will be problematic at scale without human supervision — giving wrong advice
    one in five times is not convincing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT4 seems to still be a clear leader in complex tasks it was not specifically
    trained for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are significant gains when correctly prompt engineering the task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most models seem easily confused by extra information as adding the previous
    transcript generally reduces performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where to from here?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have all witnessed that LLM capabilities continuously improve. Will this
    gap be closed and how? We have observed three types of cognitive issues that have
    impacted performance: hallucinations, understanding what is important and what
    isn’t (e.g. really understanding what is *surprising* for a company), more complex
    company causality issues (e.g. like the Bud Light boycott and how important the
    US sales are relative to an overall business):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hallucinations** or scenarios where the LLM cannot correctly reproduce factual
    information are a major stumbling block in applications that require strict adherence
    to factuality. Advanced RAG approaches, combined with research in the area continue
    to make progress, [[Huang et al 2023]](https://arxiv.org/abs/2311.05232) give
    an overview of current progress'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding what is important** — fine-tuning LLM models for the specific
    use case should lead to some improvements. However, those come with much bigger
    requirements on team, cost, data, and infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complex Causality Links** — this one may be a good direction for AI Agents.
    For instance, in the Bud Light boycott case, the model might need to:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1\. the importance of Bud Light to US sales, which is likely peppered through
    many presentations and management commentary
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. The importance of US sales ot the overall company, which could be gleaned
    from company financials
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 3\. Finally stack those impacts to all other impacts mentioned
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Such causal logic is more akin to how a ReAct AI Agent might think instead of
    just a standalone LLM [[Yao, et al 2022]](https://arxiv.org/abs/2210.03629). Agent
    planning is a hot research topic [[Chen, et al 2024]](https://arxiv.org/abs/2402.10890)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Follow me on LinkedIn](https://linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=mihail-misho-dungarov-cfa-a0291a88)'
  prefs: []
  type: TYPE_NORMAL
- en: Disclaimers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*The views, opinions, and conclusions expressed in this article are my own
    and do not reflect the views or positions of any of the entities mentioned or
    any other entities.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*No data was used to model training nor was systematically collected from the
    sources mentioned, all techniques were limited to prompt engineering.*'
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earnings Call Transcripts (Motley Fool)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Anheuser-Busch InBev (BUD) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/02/29/anheuser-busch-inbevnv-bud-q4-2023-earnings-call-t/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Autodesk (ADSK) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/02/29/autodesk-adsk-q4-2024-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Buy (BBY) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/02/29/best-buy-bby-q4-2024-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DocuSign (DOCU) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/03/07/docusign-docu-q4-2024-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kroger (KR) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/03/07/kroger-kr-q4-2023-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nordstrom (JWN) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/03/05/nordstrom-jwn-q4-2023-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Salesforce (CRM) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/02/29/salesforce-crm-q4-2024-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Snowflake (SNOW) Q4 2024](https://www.fool.com/earnings/call-transcripts/2024/02/29/snowflake-snow-q4-2024-earnings-call-transcript/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: News Articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Anheuser-Busch InBev (Reuters)](https://www.reuters.com/business/retail-consumer/brewer-ab-inbev-hikes-annual-dividend-after-q4-sales-estimate-beat-2024-02-29/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Autodesk (Reuters)](https://www.reuters.com/technology/autodesk-forecasts-annual-revenue-above-estimates-shares-jump-2024-02-29/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[BestBuy (Bloomberg)](https://www.bloomberg.com/news/articles/2024-02-29/best-buy-sales-decline-at-slower-pace-as-demand-improves)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DocuSign (Barron’s)](https://www.barrons.com/articles/docusign-shares-earnings-20862b9a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kroger (Barron’s)](https://www.barrons.com/articles/kroger-stock-earnings-9b9bebd6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nordstrom (Bloomberg)](https://www.bloomberg.com/news/articles/2024-03-05/nordstrom-sees-muted-revenue-comparable-sales-in-current-year)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Salesforce (Bloomberg)](https://www.bloomberg.com/news/articles/2024-02-28/salesforce-outlook-disappoints-as-ai-fails-to-spark-growth)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Snowflake (Bloomberg)](https://www.bloomberg.com/news/articles/2024-02-28/snowflake-misses-estimates-says-ceo-slootman-to-step-down)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
