- en: Yes, You Still Need NLP Skills in “the Age of ChatGPT”
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12](https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Large Language Models have their strengths, but for many production problems,
    simpler NLP techniques are faster, cheaper, and just as effective.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Katherine
    Munro](../Images/8013140495c7b9bd25ef08d712f097bf.png)](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    [Katherine Munro](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    ·7 min read·Feb 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c75fdc1a480c2d310bb9cfb150c6ca97.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Large Language Models require new skills, but it’s important not to forget
    the old ones too, like how to prepare the text data the LLM should use. Source:
    [Markus Winkler](https://unsplash.com/@markuswinkler) on Unsplash.'
  prefs: []
  type: TYPE_NORMAL
- en: Back when I started a masters of Computational Linguistics, no-one I knew had
    even the faintest idea what Natural Language Processing (NLP) was. Not even me
    [[1](#footnote-1)]. Fast forward four years, and now when I say I work in NLP,
    I only get blank looks about half of the time [[2](#footnote-2)]. Thanks to masses
    of media hype, most people know that there are things called Large Language Models,
    and they can do a lot of amazing and very useful stuff with text. It’s become
    a lot easier for me to explain my job to people (provided I tell them “it’s basically
    ChatGPT”). But recently, this also gave me pause.
  prefs: []
  type: TYPE_NORMAL
- en: 'I’m the editor of a [Data Science and AI textbook](https://www.amazon.com/Handbook-Data-Science-AI-Analytics/dp/1569908869),
    published waaaay back in 2022 (seriously, in AI years that’s about 20). In preparation
    for the third edition, coming this year, I needed to update my NLP chapter. And
    as I sat down to read what I wrote back then about neural networks, sequence to
    sequence models, and this damn-fangled new technology called “Transformers,” I
    noticed something remarkable: it all felt so *old school*. All that stuff on statistical
    Machine Learning approaches? Quaint. And my little code…'
  prefs: []
  type: TYPE_NORMAL
