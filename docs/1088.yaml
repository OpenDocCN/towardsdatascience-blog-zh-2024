- en: Enhancing Direct Answer Accuracy in RAG Setup with Self-Retrieval Mechanisms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在RAG设置中通过自我检索机制提升直接答案准确性
- en: 原文：[https://towardsdatascience.com/enhancing-direct-answer-accuracy-in-rag-setup-with-self-retrieval-mechanisms-8162c8cc7853?source=collection_archive---------8-----------------------#2024-04-30](https://towardsdatascience.com/enhancing-direct-answer-accuracy-in-rag-setup-with-self-retrieval-mechanisms-8162c8cc7853?source=collection_archive---------8-----------------------#2024-04-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/enhancing-direct-answer-accuracy-in-rag-setup-with-self-retrieval-mechanisms-8162c8cc7853?source=collection_archive---------8-----------------------#2024-04-30](https://towardsdatascience.com/enhancing-direct-answer-accuracy-in-rag-setup-with-self-retrieval-mechanisms-8162c8cc7853?source=collection_archive---------8-----------------------#2024-04-30)
- en: Leveraging the power of LLMs to significantly enhance the quality of document
    context retrieved for direct answer generation in your RAG setup.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用大语言模型（LLM）的强大能力显著提升在RAG设置中直接生成答案时检索到的文档上下文的质量。
- en: '[](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page---byline--8162c8cc7853--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)
    ·26 min read·Apr 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8162c8cc7853--------------------------------)
    ·26分钟阅读·2024年4月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/53adc4aba888bcd3262f20d540412a12.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53adc4aba888bcd3262f20d540412a12.png)'
- en: A robot is searching for information (image generated with Midjourney)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器人正在搜索信息（图像由Midjourney生成）
- en: Overview
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: 'Deploying a Retrieval-Augmented Generation (RAG) workflow into production introduces
    a familiar challenge: a significant drop in recall during the retrieval stage.
    This issue becomes evident when the document context provided to direct answer
    generation lacks essential information, adversely affecting the quality of the
    generated answer. This challenge is magnified when dealing with documents that
    are similar in nature and consist of lengthy articles. In some cases, to answer
    a question, one might need to consider the majority of an article, such as navigating
    through our millions of editorial articles about cars. Here, the implementation
    of self-retrieval RAG, powered by a hybrid search approach, offers a promising
    solution.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 部署检索增强生成（RAG）工作流到生产环境中引入了一个常见的挑战：在检索阶段召回率显著下降。当提供给直接生成答案的文档上下文缺乏关键信息时，这个问题变得尤为明显，进而影响生成答案的质量。当处理类似性质且由长篇文章构成的文档时，这一挑战尤为突出。在某些情况下，为了回答一个问题，可能需要考虑文章的大部分内容，例如在我们关于汽车的数百万篇编辑文章中进行导航。在这种情况下，结合混合搜索方法的自我检索RAG实现提供了一个有前景的解决方案。
- en: RAG is undeniably a potent tool, with frameworks like LangChain or LlamaIndex
    facilitating easy integration. This simplicity may convey the notion that RAG
    is a one-size-fits-all solution. Yet, during our endeavour to enhance our editorial
    article search tool for semantically richer search…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: RAG无疑是一个强大的工具，像LangChain或LlamaIndex这样的框架使其集成变得非常简单。这种简便性可能会给人一种RAG是“一刀切”解决方案的印象。然而，在我们努力提升编辑文章搜索工具以实现更丰富语义的搜索时……
