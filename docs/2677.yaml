- en: A Visual Understanding of the Softmax Function
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 softmax 函数的视觉理解
- en: 原文：[https://towardsdatascience.com/a-visual-understanding-of-the-softmax-function-b4d92fdaccfa?source=collection_archive---------2-----------------------#2024-11-03](https://towardsdatascience.com/a-visual-understanding-of-the-softmax-function-b4d92fdaccfa?source=collection_archive---------2-----------------------#2024-11-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-visual-understanding-of-the-softmax-function-b4d92fdaccfa?source=collection_archive---------2-----------------------#2024-11-03](https://towardsdatascience.com/a-visual-understanding-of-the-softmax-function-b4d92fdaccfa?source=collection_archive---------2-----------------------#2024-11-03)
- en: The math and intuition behind the softmax function and its application in neural
    networks and softmax regression
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: softmax 函数的数学原理与直觉，以及它在神经网络和 softmax 回归中的应用
- en: '[](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[![Reza
    Bagheri](../Images/7c5a7dc9e6e31048ce31c8d49055987c.png)](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)
    [Reza Bagheri](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[![Reza
    Bagheri](../Images/7c5a7dc9e6e31048ce31c8d49055987c.png)](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)
    [Reza Bagheri](https://reza-bagheri79.medium.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)
    ·25 min read·Nov 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b4d92fdaccfa--------------------------------)
    ·阅读时间 25 分钟·2024 年 11 月 3 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7dc6407208970404abdcca81e6affe28.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7dc6407208970404abdcca81e6affe28.png)'
- en: Image generated using DALL.E
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由 DALL.E 生成
- en: The softmax function is one of the most important functions in statistics and
    machine learning. It takes a vector of *K* real numbers and converts it into a
    vector of *K* probabilities that sum to 1\. Softmax is a generalization of the
    logistic function to more than two dimensions, and it can be used in softmax regression
    (also known as multinomial logistic regression) to address classification problems
    with more than two labels. The softmax function can be also used as the last activation
    function of a neural network in a multi-class classification problem. In this
    case, the neural network uses the softmax activation function to compute the probability
    of each possible class for the target.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: softmax 函数是统计学和机器学习中最重要的函数之一。它接收一个 *K* 维实数向量，并将其转换为一个 *K* 维概率向量，这些概率的总和为 1。Softmax
    是 logistic 函数的一个推广，适用于多于两个维度，并且可以用于 softmax 回归（也称为多项式 logistic 回归）来解决具有多个标签的分类问题。softmax
    函数还可以作为神经网络在多分类问题中的最后激活函数。在这种情况下，神经网络使用 softmax 激活函数来计算目标每个可能类别的概率。
- en: This article provides a visual understanding of the softmax function, the intuition
    behind it, and the important mathematical properties that make it valuable in
    machine learning. We also discuss the relationship between the softmax and the
    logistic function and demonstrate how to perform a softmax regression using Python.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提供了对 softmax 函数的视觉理解，包括其背后的直觉，以及使其在机器学习中具有价值的重要数学性质。我们还讨论了 softmax 函数与 logistic
    函数之间的关系，并演示了如何使用 Python 执行 softmax 回归。
- en: '*All the images in this article were created by the author.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文中的所有图像均由作者创建。*'
- en: '**From logistic regression to**…'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**从 logistic 回归到**…'
