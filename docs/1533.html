<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How I Dockerized Apache Flink, Kafka, and PostgreSQL for Real-Time Data Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How I Dockerized Apache Flink, Kafka, and PostgreSQL for Real-Time Data Streaming</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-dockerized-apache-flink-kafka-and-postgresql-for-real-time-data-streaming-c4ce38598336?source=collection_archive---------1-----------------------#2024-06-19">https://towardsdatascience.com/how-i-dockerized-apache-flink-kafka-and-postgresql-for-real-time-data-streaming-c4ce38598336?source=collection_archive---------1-----------------------#2024-06-19</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="13ec" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Integrating pyFlink, Kafka, and PostgreSQL using Docker</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://adenevreze.medium.com/?source=post_page---byline--c4ce38598336--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Augusto de Nevrezé" class="l ep by dd de cx" src="../Images/bd7d6509149ddb447dd7e5af9f09e4b1.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*9HXYZX2rxtZ4kw4c7KBCFQ.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--c4ce38598336--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://adenevreze.medium.com/?source=post_page---byline--c4ce38598336--------------------------------" rel="noopener follow">Augusto de Nevrezé</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--c4ce38598336--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Jun 19, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/11d218990f84e7153933c512352bd704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Q5dfRVwDPbwsg4HFRAKtw.png"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Get your pyFlink applications ready using docker — author generated image using <a class="af nb" href="https://www.dall-efree.com/" rel="noopener ugc nofollow" target="_blank">https://www.dall-efree.com/</a></figcaption></figure><h1 id="d706" class="nc nd fq bf ne nf ng gq nh ni nj gt nk nl nm nn no np nq nr ns nt nu nv nw nx bk">Why Read This?</h1><ul class=""><li id="5db5" class="ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot ou ov ow bk"><strong class="oa fr">Real-World Insights</strong>: Get practical tips from my personal journey of overcoming integration hurdles.</li><li id="b371" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot ou ov ow bk"><strong class="oa fr">Complete Setup</strong>: Learn how to integrate Flink, Kafka, and PostgreSQL seamlessly using Docker-Compose.</li><li id="b123" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot ou ov ow bk"><strong class="oa fr">Step-by-Step Guide</strong>: Perfect for both beginners and experienced developers looking to streamline their data streaming stack.</li></ul></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4f44" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Setting Up the Scene</h1><p id="5bdd" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">I embarked on a mission to integrate Apache Flink with Kafka and PostgreSQL using Docker. What makes this endeavor particularly exciting is the use of pyFlink — the Python flavor of Flink — which is both powerful and relatively rare. This setup aims to handle real-time data processing and storage efficiently. In the following sections, I’ll demonstrate how I achieved this, discussing the challenges encountered and how I overcame them. I’ll conclude with a step-by-step guide so you can build and experiment with this streaming pipeline yourself.</p><p id="782e" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">The infrastructure we’ll build is illustrated below. Externally, there’s a publisher module that simulates IoT sensor messages, similar to what was discussed in a<a class="af nb" href="https://medium.com/dev-genius/detecting-iot-alerts-with-apache-flink-7a2be19ad9dd" rel="noopener"> previous post</a>. Inside the Docker container, we will create two Kafka topics. The first topic, <em class="pu">sensors</em>, will store incoming messages from IoT devices in real-time. A Flink application will then consume messages from this topic, filter those with temperatures above 30°C, and publish them to a second topic, <em class="pu">alerts</em>. Additionally, the Flink application will insert the consumed messages into a PostgreSQL table created specifically for this purpose. This setup allows us to persist sensor data in a structured, tabular format, providing opportunities for further transformation and analysis. Visualization tools like Tableau or Power BI can be connected to this data for real-time plotting and dashboards.</p><p id="5d25" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Moreover, the alerts topic can be consumed by other clients to initiate actions based on the messages it holds, such as activating air conditioning systems or triggering fire safety protocols.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/a1ad055bc5105bf1c170c1d526b9702c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qgdcziiM5J0YJxzE"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Services included in the docker container — image by author</figcaption></figure><p id="081a" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">In order to follow up the tutorial, you can clone the following <a class="af nb" href="https://github.com/augustodn/pyflink-docker" rel="noopener ugc nofollow" target="_blank">repo</a>. A docker-compose.yml is placed in the root of the project so you can initialize the multi-container application. Furthermore, you can find detailed instructions in the README file.</p><h2 id="250b" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Issues With Kafka Ports in docker-compose.yml</h2><p id="3a2b" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Initially, I encountered problems with Kafka’s port configuration when using the confluentinc Kafka Docker image, a popular choice for such setups. This issue became apparent through the logs, emphasizing the importance of not running docker-compose up in detached mode (-d) during initial setup and troubleshooting phases.</p><p id="5b50" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">The reason for the failure was that the internal and external hosts were using the same port, which led to connectivity problems. I fixed this by changing the internal port to 19092. I’ve found <a class="af nb" href="https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/" rel="noopener ugc nofollow" target="_blank">this</a> blog post pretty clarifying.</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="23cc" class="qr nd fq qo b bg qs qt l qu qv">KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:19092,PLAINTEXT_HOST://localhost:9092</span></pre><h2 id="b67c" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Configuring Flink in Session Mode</h2><p id="a234" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">To run Flink in <a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/overview/#session-mode" rel="noopener ugc nofollow" target="_blank">session mode</a> (allowing multiple jobs in a single cluster), I’m using the following directives in the docker-compose.yml.</p><figure class="ml mm mn mo mp mq"><div class="qw io l ed"><div class="qx qy l"/></div></figure><h2 id="1e20" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Custom Docker Image for PyFlink</h2><p id="507f" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Given the limitations of the default Apache Flink Docker image, which doesn’t include Python support, I created a <a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/#using-flink-python-on-docker" rel="noopener ugc nofollow" target="_blank">custom Docker image</a> for pyFlink. This custom image ensures that Flink can run Python jobs and includes the necessary dependencies for integration with Kafka and PostgreSQL. The Dockerfile used for this is located in the pyflink subdirectory.</p><figure class="ml mm mn mo mp mq"><div class="qw io l ed"><div class="qx qy l"/></div></figure><ol class=""><li id="d107" class="ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot qz ov ow bk"><strong class="oa fr">Base Image</strong>: We start with the official Flink image.</li><li id="006f" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk"><strong class="oa fr">Python Installation</strong>: Python and pip are installed, upgrading pip to the latest version.</li><li id="e6d4" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk"><strong class="oa fr">Dependency Management</strong>: Dependencies are installed via requirements.txt. Alternatively, lines are commented to demonstrate how to manually install dependencies from local files, useful for deployment in environments without internet access.</li><li id="7b68" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk"><strong class="oa fr">Connector Libraries</strong>: Connectors for Kafka and PostgreSQL are downloaded directly into the Flink lib directory. This enables Flink to interact with Kafka and PostgreSQL during job execution.</li><li id="9065" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk"><strong class="oa fr">Script Copying</strong>: Scripts from the repository are copied into the /opt/flink directory to be executed by the Flink task manager.</li></ol><p id="fb96" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">With this custom Docker image, we ensure pyFlink can run properly within the Docker container, equipped with the necessary libraries to interact with Kafka and PostgreSQL seamlessly. This approach provides flexibility and is suitable for both development and production environments.</p><p id="99a2" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Note:</strong> Ensure that any network or security considerations for downloading connectors and other dependencies are addressed according to your deployment environment’s policies.</p><h2 id="e033" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Integrating PostgreSQL</h2><p id="65f8" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">To connect Apache Flink to the PostgreSQL database, a proper JDBC connector is required. The custom Docker image for pyFlink downloads the JDBC connector for PostgreSQL, which is compatible with PostgreSQL 16.</p><p id="9022" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">To simplify this process, a download_libs.sh script is included in the repository, mirroring the actions performed in the Flink Docker container. This script automates the download of the necessary libraries, ensuring consistency between the Docker and local environments.</p><p id="fcdb" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Note: </strong>Connectors usually have two versions. In this particular case, since I’m using Flink 1.18, the latest stable version available, I’ve downloaded 3.1.2–1.18. My guess is that the first version tracks JDBC implementation for several databases. They’re available in the <a class="af nb" href="https://mvnrepository.com/artifact/org.apache.flink/flink-connector-jdbc/3.1.2-1.18" rel="noopener ugc nofollow" target="_blank">maven directory</a>.</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="142f" class="qr nd fq qo b bg qs qt l qu qv">env.add_jars(<br/>  f"file://{current_dir}/flink-connector-jdbc-3.1.2–1.18.jar",<br/>  f"file://{current_dir}/postgresql-42.7.3.jar"<br/>)</span></pre><p id="5ede" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Defining JDBC Sink</strong></p><p id="0906" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">In our Flink task, there’s a crucial function named configure_postgre_sink located in the usr_jobs/postgres_sink.py file. This function is responsible for configuring a generic PostgreSQL sink. To use it effectively, you need to provide the SQL Data Manipulation Language (DML) statement and the corresponding value types. The types used in the streaming data are defined as TYPE_INFO … it took me a while to come up with the correct declaration 😅.</p><p id="8d7f" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Notice also that the JdbcSink has an optional parameter to define the ExecutionOptions. For this particular case, I’ll use an update interval of 1 second and limit the amount of rows to 200. You can find more information in the <a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/datastream/jdbc/#jdbc-execution-options" rel="noopener ugc nofollow" target="_blank">official documentation</a>. Yes, you guessed it, since I’m defining an interval, this can be considered a micro-batch ETL. However, due to Flink parallelism you can handle multiple streams at once in a simple script which is at the same time, easy to follow.</p><figure class="ml mm mn mo mp mq"><div class="qw io l ed"><div class="qx qy l"/></div></figure><p id="1476" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Note: </strong>Don’t forget to create the raw_sensors_data table in Postgres, where raw data coming from the IoT sensors will be received. This is covered in the step-by-step guide in the sections below.</p><h2 id="657b" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Sinking Data to Kafka</h2><p id="a970" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">I’ve covered how to consume data from a Kafka topic in <a class="af nb" href="https://medium.com/dev-genius/detecting-iot-alerts-with-apache-flink-7a2be19ad9dd" rel="noopener">a previous discussion</a>. However, I haven’t configured a sink yet and that’s what we’ll do. The configuration has some intricacies and it’s defined in a function, similarly to the Postgres sink. Additionally, you have to define the type for the data stream before sinking it to Kafka. Notice that the alarms_data stream is properly casted as a string with output_type=Types.STRING() before sinking it to Kafka, since I’ve declared the serializer as SimpleStringSchema().</p><figure class="ml mm mn mo mp mq"><div class="qw io l ed"><div class="qx qy l"/></div></figure><p id="fa83" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">I’ll show you how to fetch data from the alerts topic in the following steps.</p><h2 id="2d96" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Local or Containerized configuration</h2><p id="3f6a" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">One of the greatest things about this docker configuration is that you can run Flink from local or inside the container as a managed task. The local Flink setup is depicted in the following figure, where you can see our Flink application detached from the docker container. This may help to troubleshoot Flink, which doesn’t have a good suite of native observability tools. Actually, we would like to give a try to <a class="af nb" href="https://datorios.com/" rel="noopener ugc nofollow" target="_blank">datorios</a> tools for Flink, they are very promising for monitoring purposes.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pv"><img src="../Images/6d8993906980fe9862badc9ecdcad799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LGabCDWfaRV_W89t"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Runing Flink applications in local with other services running inside the container — image by author</figcaption></figure><p id="cc40" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">If you want to try the Flink application locally, you have to correctly define the hosts and ports used by the script which actually are two constants in the usr_jobs/postgres_sink.py file:</p><p id="45e6" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">For container run, use:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="7256" class="qr nd fq qo b bg qs qt l qu qv">KAFKA_HOST = "kafka:19092"<br/>POSTGRES_HOST = "postgres:5432"</span></pre><p id="99cc" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">For local run, use:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="765a" class="qr nd fq qo b bg qs qt l qu qv">KAFKA_HOST = "localhost:9092"<br/>POSTGRES_HOST = "localhost:5432"</span></pre><p id="f0ec" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">By default the repo sets up the Flink application to run inside the container. You can monitor the jobs running using the web UI, accessing from <a class="af nb" href="http://localhost:8081" rel="noopener ugc nofollow" target="_blank">http://localhost:8081</a>. You won’t be able to see it if you choose to run the job locally.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj ra"><img src="../Images/add4733c451e9d50906584d638693caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qsaoHeYzByiqPnxK"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Screenshot of the Flink web UI with the running job — image by author</figcaption></figure><p id="e4bf" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Note</strong>: If you run the job locally, you need to install the Flink dependencies located in the requirements.txt. Also a pyproject.toml file is provided if you like to set up the environment with poetry.</p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="1800" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Step-by-Step Guide to Run the Streaming Pipeline</h1><h2 id="d6ff" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 1: Launch the multi-container application</h2><p id="53f7" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Launch the containers by running docker-compose. I preferred to do it without detached mode to see the logs while the containers are spinning up and then running.</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="1d1d" class="qr nd fq qo b bg qs qt l qu qv">docker-compose up</span></pre><p id="a897" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Check for the logs to see if the services are running properly.</p><h2 id="60da" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 2: Create the Kafka topics</h2><p id="ebc0" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Next, we’re going to create the topics to receive data from the IoT sensors and store the alerts filtered by the Flink application.</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="d6d2" class="qr nd fq qo b bg qs qt l qu qv">docker-compose exec kafka kafka-topics \<br/> -- create - topic sensors \<br/> -- bootstrap-server localhost:9092 \<br/> -- partitions 1 \<br/> -- replication-factor 1<br/><br/>docker-compose exec kafka kafka-topics \<br/> -- create - topic alerts \<br/> -- bootstrap-server localhost:9092 \<br/> -- partitions 1 \<br/> -- replication-factor 1</span></pre><p id="4e16" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">To check if the topics were created correctly you can execute the following command</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="6be4" class="qr nd fq qo b bg qs qt l qu qv">docker-compose exec kafka kafka-topics \<br/> -- bootstrap-server localhost:9092 \<br/> -- list</span></pre><h2 id="4e12" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 3: Create Postgres table</h2><p id="2e1d" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Login to the postgres console</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="6d16" class="qr nd fq qo b bg qs qt l qu qv">psql -h localhost -U flinkuser -d flinkdb</span></pre><p id="43e6" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Enter the password flinkpassword to log into the postgres console, remember this is a local configuration so default access has been configured in the docker-compose.yml. Then create the table</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="10e3" class="qr nd fq qo b bg qs qt l qu qv">CREATE TABLE raw_sensors_data (<br/>message_id VARCHAR(255) PRIMARY KEY,<br/>sensor_id INT NOT NULL,<br/>message TEXT NOT NULL,<br/>timestamp TIMESTAMPTZ NOT NULL<br/>);</span></pre><p id="2214" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">You can check if the table is properly created by doing the following</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="6c61" class="qr nd fq qo b bg qs qt l qu qv">flinkdb=# \d raw_sensors_data</span></pre><p id="54a2" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">This will show you a result similar to the following one:</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rb"><img src="../Images/d60419e34e6e3d6595fb7dabb57d16ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Cap8pHh8HTNXqlSk"/></div></div></figure><h2 id="c388" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 4: Launching the Kafka producer</h2><p id="346d" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Create a local environment with conda or poetry and install python kafka package:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="d21b" class="qr nd fq qo b bg qs qt l qu qv">pip install kafka-python</span></pre><p id="8b20" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Then execute the kafka producer, which mimics IoT sensor messages and publishes messages to the sensors topic.</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="7c0c" class="qr nd fq qo b bg qs qt l qu qv">python pyflink/usr_jobs/kafka_producer.py</span></pre><p id="52b3" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Leave it running for the rest of the tutorial.</p><h2 id="c436" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 5: Initializing the Flink task</h2><p id="fd1a" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">We’re going to launch the Flink application from within the container, so you can monitor it from the web UI through localhost:8081. Run the following command from the repository root:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="b3e9" class="qr nd fq qo b bg qs qt l qu qv">docker-compose exec flink-jobmanager flink run \<br/>  -py /opt/flink/usr_jobs/postgres_sink.py</span></pre><p id="4dbf" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">You’ll see some logging information, additionally alerts will also be displayed in the flink-jobmanager container logs. Also, you can check if the job is running from the Flink web UI <a class="af nb" href="http://localhost:8081/#/job/running" rel="noopener ugc nofollow" target="_blank">http://localhost:8081/#/job/running</a>.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rc"><img src="../Images/61e46067d510dfa78e078de834b3ad0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bJOqB1I0SpW3ABtR"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Details of running job — image by author</figcaption></figure><p id="b16e" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Apparently the monitoring tells that there are no messages going through the Flink job, which is not true, since alerts can be seen in the docker log.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj rc"><img src="../Images/a76525be2f6b2ec01ef7e1d6d89b2518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G7x0YuyXVMtTtxyf"/></div></div></figure><p id="7852" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">We’ll check the messages using the Postgres table and read the alerts topic, which were created for this purpose.</p><h2 id="9b2c" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 6: Read Alerts in Kafka Topic</h2><p id="4d83" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">To read data in the alerts topic, you can execute the following command:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="6b30" class="qr nd fq qo b bg qs qt l qu qv">docker-compose exec kafka kafka-console-consumer \<br/>  -- bootstrap-server localhost:9092 \<br/>  -- topic alerts \<br/>  -- from-beginning</span></pre><p id="f6ee" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">That will bring all the messages that the topic has received so far.</p><h2 id="8966" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 7: Read raw data from Postgres table</h2><p id="8ce3" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Additionally you can query the raw messages from the IoT sensor and even parse the JSON data in PostgreSQL:</p><pre class="ml mm mn mo mp qn qo qp bp qq bb bk"><span id="0c54" class="qr nd fq qo b bg qs qt l qu qv">SELECT<br/>  *,<br/>  (message::json-&gt;&gt;'temperature')::numeric as temperature<br/>FROM raw_sensors_data<br/>LIMIT 10;</span></pre><h2 id="c1d1" class="pw nd fq bf ne px py pz nh qa qb qc nk oh qd qe qf ol qg qh qi op qj qk ql qm bk">Step 8: Stopping Services</h2><p id="2847" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">You can easily stop everything by doing ctrl-c on the docker terminal. If you prefer, to make proper shutdown, proceed with the following steps:</p><ol class=""><li id="e717" class="ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot qz ov ow bk">Cancel the Flink job by clicking in the top right corner of job details in the web UI.</li><li id="5678" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk">Stop the kafka_producer.py script which was running locally.</li><li id="299c" class="ny nz fq oa b go ox oc od gr oy of og oh oz oj ok ol pa on oo op pb or os ot qz ov ow bk">Ctrl-c on the docker terminal to stop the services</li></ol><p id="8d40" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">The information exchanged in the session, while the services were running, is permanently stored. So in the case you want to query the Postgres table or the Kafka topics, the data is going to be there.</p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="5765" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Insights on Using Multiple Sinks in a PyFlink Job</h1><p id="859a" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">In the Flink job used for demonstration, I’m managing 2 data streams simultaneously, in the same task. The one that writes raw data coming from the sensors topic (IoT devices) and the filtered alerts which are set to another topic. This has some advantages and drawbacks, as a simple summary, here are the pros and cons:</p><p id="0633" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Pros of Single Job with Multiple Sinks:</strong></p><p id="9e13" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Simplicity in resource management.</p><p id="2d8d" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Consistency in data flow.</p><p id="bb90" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Cons of Single Job:</strong></p><p id="1325" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Can become complex as logic grows.</p><p id="8478" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Scalability might be an issue.</p><p id="fe53" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Pros of Multiple Jobs:</strong></p><p id="eeb7" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Better fault isolation.</p><p id="b039" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Focused optimization.</p><p id="8829" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Cons of Multiple Jobs:</strong></p><p id="a4f8" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Resource overhead.</p><p id="f28e" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">- Coordination complexity.</p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="ef44" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Conclusion</h1><p id="06c4" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">This setup offers a robust solution for real-time data streaming and processing, integrating Flink, Kafka, and PostgreSQL effectively. The main purpose of using Postgres in the loop is to check the raw messages coming from the IoT devices without relying on queries to the topic itself. It also helped to demonstrate how to sink data using a JDBC connector, which might be pretty standard. The message transformations were done using the DataStream API. I would like to dive further into the SQL API which introduces a friendlier interface. Finally, regarding how to manage data streams, choose between single or multiple jobs based on your specific requirements ensuring scalability and maintainability.</p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="2fae" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Next Steps</h1><p id="99e5" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">1. Use SQL API to make transformations.</p><p id="5cf5" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">2. Optimize resource usage based on job complexity.</p><p id="dbc2" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">3. Explore advanced Flink features for complex data processing tasks.</p><p id="fa92" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk">Happy streaming! 🚀</p><p id="35cc" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><strong class="oa fr">Stay tuned for more tutorials on integrating and scaling data engineering solutions with Docker!</strong></p><p id="b36f" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><em class="pu">Feel free to reach out for any questions or suggestions in the comments below!</em></p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="cc7e" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">Ready to Optimize Your Streaming Data Applications?</h1><p id="10a4" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk">Unlock the full potential of your data with our <a class="af nb" href="https://www.squadralabs.com/" rel="noopener ugc nofollow" target="_blank">expert consulting services</a>, tailored for streaming data applications. Whether you’re looking to enhance real-time analytics, streamline data pipelines, or optimize performance, we’re here to help.</p></div></div></div><div class="ab cb pc pd pe pf" role="separator"><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi pj"/><span class="pg by bm ph pi"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="7abd" class="nc nd fq bf ne nf pk gq nh ni pl gt nk nl pm nn no np pn nr ns nt po nv nw nx bk">References</h1><p id="7ac3" class="pw-post-body-paragraph ny nz fq oa b go ob oc od gr oe of og oh oi oj ok ol om on oo op oq or os ot fj bk"><a class="af nb" href="https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/" rel="noopener ugc nofollow" target="_blank">https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/</a></p><p id="7208" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><a class="af nb" href="https://mvnrepository.com/" rel="noopener ugc nofollow" target="_blank">https://mvnrepository.com/</a></p><p id="adc8" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/datastream/jdbc/" rel="noopener ugc nofollow" target="_blank">https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/datastream/jdbc/</a></p><p id="f206" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/overview/#session-mode" rel="noopener ugc nofollow" target="_blank">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/overview/#session-mode</a></p><p id="3992" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><a class="af nb" href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/#using-flink-python-on-docker" rel="noopener ugc nofollow" target="_blank">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/#using-flink-python-on-docker</a></p><p id="f043" class="pw-post-body-paragraph ny nz fq oa b go pp oc od gr pq of og oh pr oj ok ol ps on oo op pt or os ot fj bk"><a class="af nb" href="https://medium.com/@sant1/flink-docker-kafka-faee9c0f1580" rel="noopener">https://medium.com/@sant1/flink-docker-kafka-faee9c0f1580</a></p></div></div></div></div>    
</body>
</html>