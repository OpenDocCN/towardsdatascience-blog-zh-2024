["```py\nimport os\nfrom dotenv import load_dotenv\nfrom haystack.components.generators.chat import OpenAIChatGenerator\nfrom haystack.utils import Secret\nfrom haystack.dataclasses import ChatMessage\nfrom haystack.components.generators.utils import print_streaming_chunk\n\n# Set your API key as environment variable before executing this\nload_dotenv()\nOPENROUTER_API_KEY = os.environ.get('OPENROUTER_API_KEY')\n\nchat_generator = OpenAIChatGenerator(api_key=Secret.from_env_var(\"OPENROUTER_API_KEY\"),\n  api_base_url=\"https://openrouter.ai/api/v1\",\n  model=\"openai/gpt-4-turbo-preview\",\n        streaming_callback=print_streaming_chunk)\n```", "```py\nchat_generator.run(messages=[ChatMessage.from_user(\"Return this text: 'test'\")])\n```", "```py\n---------- The response should look like this ----------\n{'replies': [ChatMessage(content=\"'test'\", role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'openai/gpt-4-turbo-preview', 'index': 0, 'finish_reason': 'stop', 'usage': {}})]}\n```", "```py\nfrom haystack import Pipeline, Document\nfrom haystack.document_stores.in_memory import InMemoryDocumentStore\nfrom haystack.components.writers import DocumentWriter\nfrom haystack.components.embedders import SentenceTransformersDocumentEmbedder\n\n# Sample documents\ndocuments = [\n    Document(content=\"Coffee shop opens at 9am and closes at 5pm.\"),\n    Document(content=\"Gym room opens at 6am and closes at 10pm.\")\n]\n\n# Create the document store\ndocument_store = InMemoryDocumentStore()\n\n# Create a pipeline to turn the texts into embeddings and store them in the document store\nindexing_pipeline = Pipeline()\nindexing_pipeline.add_component(\n    \"doc_embedder\", SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n)\nindexing_pipeline.add_component(\"doc_writer\", DocumentWriter(document_store=document_store))\n\nindexing_pipeline.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n\nindexing_pipeline.run({\"doc_embedder\": {\"documents\": documents}})\n```", "```py\n{'doc_writer': {'documents_written': 2}}\n```", "```py\nfrom haystack.components.embedders import SentenceTransformersTextEmbedder\nfrom haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\nfrom haystack.components.builders import PromptBuilder\nfrom haystack.components.generators import OpenAIGenerator\n\ntemplate = \"\"\"\nAnswer the questions based on the given context.\n\nContext:\n{% for document in documents %}\n    {{ document.content }}\n{% endfor %}\nQuestion: {{ question }}\nAnswer:\n\"\"\"\nrag_pipe = Pipeline()\nrag_pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\nrag_pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\nrag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n# Note to llm: We are using OpenAIGenerator, not the OpenAIChatGenerator, because the latter only accepts List[str] as input and cannot accept prompt_builder's str output\nrag_pipe.add_component(\"llm\", OpenAIGenerator(api_key=Secret.from_env_var(\"OPENROUTER_API_KEY\"),\n  api_base_url=\"https://openrouter.ai/api/v1\",\n  model=\"openai/gpt-4-turbo-preview\"))\n\nrag_pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\nrag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\nrag_pipe.connect(\"prompt_builder\", \"llm\")\n```", "```py\nquery = “When does the coffee shop open?”\nrag_pipe.run({\"embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}})\n```", "```py\n{'llm': {'replies': ['The coffee shop opens at 9am.'],\n  'meta': [{'model': 'openai/gpt-4-turbo-preview',\n    'index': 0,\n    'finish_reason': 'stop',\n    'usage': {'completion_tokens': 9,\n     'prompt_tokens': 60,\n     'total_tokens': 69,\n     'total_cost': 0.00087}}]}}\n```", "```py\ndef rag_pipeline_func(query: str):\n    result = rag_pipe.run({\"embedder\": {\"text\": query}, \"prompt_builder\": {\"question\": query}})\n\n    return {\"reply\": result[\"llm\"][\"replies\"][0]}\n```", "```py\n# Flask's default local URL, change it if necessary\ndb_base_url = 'http://127.0.0.1:5000'\n\n# Use requests to get the data from the database\nimport requests\nimport json\n\n# get_categories is supplied as part of the prompt, it is not used as a tool\ndef get_categories():\n    response = requests.get(f'{db_base_url}/category')\n    data = response.json()\n    return data\n\ndef get_items(ids=None,categories=None):\n    params = {\n        'id': ids,\n        'category': categories,\n    }\n    response = requests.get(f'{db_base_url}/item', params=params)\n    data = response.json()\n    return data\n\ndef purchase_item(id,quantity):\n\n    headers = {\n    'Content-type':'application/json', \n    'Accept':'application/json'\n    }\n\n    data = {\n        'id': id,\n        'quantity': quantity,\n    }\n    response = requests.post(f'{db_base_url}/item/purchase', json=data, headers=headers)\n    return response.json()\n```", "```py\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_items\",\n            \"description\": \"Get a list of items from the database\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"ids\": {\n                        \"type\": \"string\",\n                        \"description\": \"Comma separated list of item ids to fetch\",\n                    },\n                    \"categories\": {\n                        \"type\": \"string\",\n                        \"description\": \"Comma separated list of item categories to fetch\",\n                    },\n                },\n                \"required\": [],\n            },\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"purchase_item\",\n            \"description\": \"Purchase a particular item\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"id\": {\n                        \"type\": \"string\",\n                        \"description\": \"The given product ID, product name is not accepted here. Please obtain the product ID from the database first.\",\n                    },\n                    \"quantity\": {\n                        \"type\": \"integer\",\n                        \"description\": \"Number of items to purchase\",\n                    },\n                },\n                \"required\": [],\n            },\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"rag_pipeline_func\",\n            \"description\": \"Get information from hotel brochure\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"The query to use in the search. Infer this from the user's message. It should be a question or a statement\",\n                    }\n                },\n                \"required\": [\"query\"],\n            },\n        },\n    }\n]\n```", "```py\n# 1\\. Initial prompt\ncontext = f\"\"\"You are an assistant to tourists visiting a hotel.\nYou have access to a database of items (which includes {get_categories()}) that tourists can buy, you also have access to the hotel's brochure.\nIf the tourist's question cannot be answered from the database, you can refer to the brochure.\nIf the tourist's question cannot be answered from the brochure, you can ask the tourist to ask the hotel staff.\n\"\"\"\nmessages = [\n    ChatMessage.from_system(context),\n    # 2\\. Sample message from user\n    ChatMessage.from_user(\"Can I buy a coffee?\"),\n    ]\n\n# 3\\. Passing the tools list and invoke the chat generator\nresponse = chat_generator.run(messages=messages, generation_kwargs= {\"tools\": tools})\nresponse\n```", "```py\n---------- Response ----------\n{'replies': [ChatMessage(content='[{\"index\": 0, \"id\": \"call_AkTWoiJzx5uJSgKW0WAI1yBB\", \"function\": {\"arguments\": \"{\\\\\"categories\\\\\":\\\\\"Food and beverages\\\\\"}\", \"name\": \"get_items\"}, \"type\": \"function\"}]', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'openai/gpt-4-turbo-preview', 'index': 0, 'finish_reason': 'tool_calls', 'usage': {}})]}\n```", "```py\nfunction_call = json.loads(response[\"replies\"][0].content)[0]\nfunction_name = function_call[\"function\"][\"name\"]\nfunction_args = json.loads(function_call[\"function\"][\"arguments\"])\nprint(\"Function Name:\", function_name)\nprint(\"Function Arguments:\", function_args)\n```", "```py\n---------- Response ----------\nFunction Name: get_items\nFunction Arguments: {‘categories’: ‘Food and beverages’}\n```", "```py\n# Another question\nmessages.append(ChatMessage.from_user(\"Where's the coffee shop?\"))\n\n# Invoke the chat generator, and passing the tools list\nresponse = chat_generator.run(messages=messages, generation_kwargs= {\"tools\": tools})\nfunction_call = json.loads(response[\"replies\"][0].content)[0]\nfunction_name = function_call[\"function\"][\"name\"]\nfunction_args = json.loads(function_call[\"function\"][\"arguments\"])\nprint(\"Function Name:\", function_name)\nprint(\"Function Arguments:\", function_args)\n```", "```py\n---------- Response ----------\nFunction Name: rag_pipeline_func\nFunction Arguments: {'query': \"Where's the coffee shop?\"}\n```", "```py\n## Find the correspoding function and call it with the given arguments\navailable_functions = {\"get_items\": get_items, \"purchase_item\": purchase_item,\"rag_pipeline_func\": rag_pipeline_func}\nfunction_to_call = available_functions[function_name]\nfunction_response = function_to_call(**function_args)\nprint(\"Function Response:\", function_response)\n```", "```py\n---------- Response ----------\nFunction Response: {'reply': 'The provided context does not specify a physical location for the coffee shop, only its operating hours. Therefore, I cannot determine where the coffee shop is located based on the given information.'}\n```", "```py\nmessages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\nresponse = chat_generator.run(messages=messages)\nresponse_msg = response[\"replies\"][0]\n\nprint(response_msg.content)\n```", "```py\n---------- Response ----------\nFor the location of the coffee shop within the hotel, I recommend asking the hotel staff directly. They will be able to guide you to it accurately.\n```", "```py\nimport json\nfrom haystack.dataclasses import ChatMessage, ChatRole\n\nresponse = None\nmessages = [\n    ChatMessage.from_system(context)\n]\n\nwhile True:\n    # if OpenAI response is a tool call\n    if response and response[\"replies\"][0].meta[\"finish_reason\"] == \"tool_calls\":\n        function_calls = json.loads(response[\"replies\"][0].content)\n\n        for function_call in function_calls:\n            ## Parse function calling information\n            function_name = function_call[\"function\"][\"name\"]\n            function_args = json.loads(function_call[\"function\"][\"arguments\"])\n\n            ## Find the correspoding function and call it with the given arguments\n            function_to_call = available_functions[function_name]\n            function_response = function_to_call(**function_args)\n\n            ## Append function response to the messages list using `ChatMessage.from_function`\n            messages.append(ChatMessage.from_function(content=json.dumps(function_response), name=function_name))\n\n    # Regular Conversation\n    else:\n        # Append assistant messages to the messages list\n        if not messages[-1].is_from(ChatRole.SYSTEM):\n            messages.append(response[\"replies\"][0])\n\n        user_input = input(\"ENTER YOUR MESSAGE 👇 INFO: Type 'exit' or 'quit' to stop\\n\")\n        if user_input.lower() == \"exit\" or user_input.lower() == \"quit\":\n            break\n        else:\n            messages.append(ChatMessage.from_user(user_input))\n\n    response = chat_generator.run(messages=messages, generation_kwargs={\"tools\": tools})\n```"]