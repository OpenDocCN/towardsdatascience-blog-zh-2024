["```py\nimport numpy as np\nfrom prophet import Prophet\nfrom sklearn.metrics import accuracy_score\n\n# Initialize model and train it on training data\nmodel = Prophet()\nmodel.fit(train_df)\n\n# Create a dataframe for future predictions covering the test period\nfuture = model.make_future_dataframe(periods=len(test_df), freq='D')\nforecast = model.predict(future)\n\n# Categorize forecasted daily values into quartiles based on the thresholds\nforecast['quartile'] = pd.cut(forecast['yhat'], bins = [-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])\n\n# Extract the forecasted quartiles for the test period\nforecasted_quartiles = forecast.iloc[-len(test_df):]['quartile'].astype(int)\n\n# Categorize actual daily values in the test set into quartiles\ntest_df['quartile'] = pd.cut(test_df['y'], bins=[-np.inf] + list(quartiles) + [np.inf], labels=[1, 2, 3, 4])\nactual_test_quartiles = test_df['quartile'].astype(int)\n\n# Calculate the evaluation metrics\naccuracy = accuracy_score(actual_test_quartiles, forecasted_quartiles)\n\n# Print the evaluation metrics\nprint(f'Accuracy: {accuracy:.4f}')\n>>> 0.4249\n```", "```py\nimport tsfel\nfrom sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n\n# Define tsfresh feature extractor\ntsfresh_trafo = TSFreshFeatureExtractor(default_fc_parameters=\"minimal\")\n\n# Transform the training data using the feature extractor\nX_train_transformed = tsfresh_trafo.fit_transform(X_train)\n\n# Transform the test data using the same feature extractor\nX_test_transformed = tsfresh_trafo.transform(X_test)\n\n# Retrieves a pre-defined feature configuration file to extract all available features\ncfg = tsfel.get_features_by_domain()\n\n# Function to compute tsfel features per day\ndef compute_features(group):\n    # TSFEL expects a DataFrame with the data in columns, so we transpose the input group\n    features = tsfel.time_series_features_extractor(cfg, group, fs=1, verbose=0)\n    return features\n\n# Group by the 'day' level of the index and apply the feature computation\ntrain_features_per_day = X_train.groupby(level='Date').apply(compute_features).reset_index(drop=True)\ntest_features_per_day = X_test.groupby(level='Date').apply(compute_features).reset_index(drop=True)\n\n# Combine each featurization into a set of combined features for our train/test data\ntrain_combined_df = pd.concat([X_train_transformed, train_features_per_day], axis=1)\ntest_combined_df = pd.concat([X_test_transformed, test_features_per_day], axis=1)\n```", "```py\n# Filter out features that are highly correlated with our target variable\ncolumn_of_interest = \"PJME_MW__mean\"\ntrain_corr_matrix = train_combined_df.corr()\ntrain_corr_with_interest = train_corr_matrix[column_of_interest]\nnull_corrs = pd.Series(train_corr_with_interest.isnull())\nfalse_features = null_corrs[null_corrs].index.tolist()\n\ncolumns_to_exclude = list(set(train_corr_with_interest[abs(train_corr_with_interest) > 0.8].index.tolist() + false_features))\ncolumns_to_exclude.remove(column_of_interest)\n\n# Filtered DataFrame excluding columns with high correlation to the column of interest\nX_train_transformed = train_combined_df.drop(columns=columns_to_exclude)\nX_test_transformed = test_combined_df.drop(columns=columns_to_exclude)\n```", "```py\n# Define a function to classify each value into a quartile\ndef classify_into_quartile(value):\n    if value < quartiles[0]:\n        return 1  \n    elif value < quartiles[1]:\n        return 2  \n    elif value < quartiles[2]:\n        return 3  \n    else:\n        return 4  \n\ny_train = X_train_transformed[\"PJME_MW__mean\"].rename(\"daily_energy_level\")\nX_train_transformed.drop(\"PJME_MW__mean\", inplace=True, axis=1)\n\ny_test = X_test_transformed[\"PJME_MW__mean\"].rename(\"daily_energy_level\")\nX_test_transformed.drop(\"PJME_MW__mean\", inplace=True, axis=1)\n\nenergy_levels_train = y_train.apply(classify_into_quartile)\nenergy_levels_test = y_test.apply(classify_into_quartile)\n```", "```py\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier(\n    n_estimators=150,\n    learning_rate=0.1,\n    max_depth=4,\n    min_samples_leaf=20,\n    max_features='sqrt',\n    subsample=0.8,\n    random_state=42\n)\n\ngbc.fit(X_train_transformed, energy_levels_train)\n\ny_pred_gbc = gbc.predict(X_test_transformed)\ngbc_accuracy = accuracy_score(energy_levels_test, y_pred_gbc)\nprint(f'Accuracy: {gbc_accuracy:.4f}')\n>>> 0.8075\n```", "```py\n from cleanlab_studio import Studio\n\nstudio = Studio()\nstudio.create_project(\n    dataset_id=energy_forecasting_dataset,\n    project_name=\"ENERGY-LEVEL-FORECASTING\",\n    modality=\"tabular\",\n    task_type=\"multi-class\",\n    model_type=\"regular\",\n    label_column=\"daily_energy_level\",\n)\n\nmodel = studio.get_model(energy_forecasting_model)\ny_pred_automl = model.predict(test_data, return_pred_proba=True)\n```"]