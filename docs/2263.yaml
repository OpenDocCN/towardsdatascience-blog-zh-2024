- en: 'Vision Mamba: Like a Vision Transformer but Better'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16](https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[üêç Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Part 4 ‚Äî Towards Mamba State Space Models for Images, Videos and Time Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    ¬∑20 min read¬∑Sep 16, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7c83682cee1e25a2932aff0e19416df2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch).
  prefs: []
  type: TYPE_NORMAL
- en: This is part 4 of my new multi-part series [üêç Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The field of computer vision has seen incredible advances in recent years. One
    of the key enablers for this development has been undoubtedly the introduction
    of the Transformer. While the Transformer has revolutionized natural language
    processing, it took us some years to transfer its capabilities to the vision domain.
    Probably the most prominent paper was the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929),
    a model that is still used as the backbone in many of the modern architectures.
  prefs: []
  type: TYPE_NORMAL
- en: 'It‚Äôs again the Transformer‚Äôs *O(L¬≤)* complexity that limits its application
    as the image‚Äôs resolution grows. Being equipped with the [Mamba selective state
    space model](https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb),
    we are now able to let history repeat itself and transfer the success of SSMs
    from sequence data to non-sequence data: Images.'
  prefs: []
  type: TYPE_NORMAL
- en: '‚ùó Spoiler Alert: VisionMamba is 2.8x faster than [DeiT](https://arxiv.org/abs/2012.12877)
    and saves 86.8% GPU memory on high-resolution images (1248x1248) and in this article,
    you‚Äôll see how‚Ä¶'
  prefs: []
  type: TYPE_NORMAL
