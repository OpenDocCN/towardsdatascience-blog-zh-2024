- en: Speech to Text to Speech with AI Using Python ‚Äî a How-To Guide
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11](https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to Create a Speech-to-Text-to-Speech Program
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Naomi
    Kriger](../Images/14839f859e1375965c046912f00df5b9.png)](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    [Naomi Kriger](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    ¬∑8 min read¬∑Feb 11, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9373a2a21c40ba755fe7e692fc61b292.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image](https://unsplash.com/photos/aaujbh59zqI) by [Mariia Shalabaieva](https://unsplash.com/@maria_shalabaieva)
    from [unsplash](http://unsplash.com)'
  prefs: []
  type: TYPE_NORMAL
- en: 'It‚Äôs been exactly a decade since I started attending GeekCon (yes, a geeks‚Äô
    conference üôÇ) ‚Äî a weekend-long hackathon-makeathon in which all projects must
    be useless and just-for-fun, and this year there was an exciting twist: all projects
    were required to incorporate some form of AI.'
  prefs: []
  type: TYPE_NORMAL
- en: 'My group‚Äôs project was a speech-to-text-to-speech game, and here‚Äôs how it works:
    the user selects a character to talk to, and then verbally expresses anything
    they‚Äôd like to the character. This spoken input is transcribed and sent to ChatGPT,
    which responds as if it were the character. The response is then read aloud using
    text-to-speech technology.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that the game is up and running, bringing laughs and fun, I‚Äôve crafted this
    how-to guide to help you create a similar game on your own. Throughout the article,
    we‚Äôll also explore the various considerations and decisions we made during the
    hackathon.
  prefs: []
  type: TYPE_NORMAL
- en: Want to see the full code? [Here is the link](https://github.com/NaomiKriger/speech_to_speech_magician)!
  prefs: []
  type: TYPE_NORMAL
- en: The Program‚Äôs Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the server is running, the user will hear the app ‚Äútalking‚Äù, prompting
    them to choose the figure they want to talk to and start conversing with their
    selected character. Each time they want to talk out loud ‚Äî they should press and
    hold a key on the keyboard while talking. When they finish talking (and release
    the key), their recording will be transcribed by `[Whisper](https://platform.openai.com/docs/guides/speech-to-text/quickstart)`
    (a speech-to-text model by `[OpenAI](https://platform.openai.com/docs/introduction/overview)`),
    and the transcription will be sent to `[ChatGPT](https://platform.openai.com/docs/guides/gpt/chat-completions-api)`
    for a response. The response will be read out loud using a text-to-speech library,
    and the user will hear it.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Disclaimer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Note: The project was developed on a Windows operating system and incorporates
    the `pyttsx3` library, which lacks compatibility with M1/M2 chips. As `pyttsx3`
    is not supported on Mac, users are advised to explore alternative text-to-speech
    libraries that are compatible with macOS environments.'
  prefs: []
  type: TYPE_NORMAL
- en: Openai Integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I utilized two `OpenAI` models: `Whisper`, for speech-to-text transcription,
    and the `ChatGPT` API for generating responses based on the user‚Äôs input to their
    selected figure. While doing so costs money, the pricing model is very cheap,
    and personally, my bill is still under $1 for all my usage. To get started, I
    made an initial deposit of $5, and to date, I have not exhausted this deposit,
    and this initial deposit won‚Äôt expire until a year from now.'
  prefs: []
  type: TYPE_NORMAL
- en: I‚Äôm not receiving any payment or benefits from `OpenAI` for writing this.
  prefs: []
  type: TYPE_NORMAL
- en: Once you get your `OpenAI` API key ‚Äî set it as an environment variable to use
    upon making the API calls. Make sure not to push your key to the codebase or any
    public location, and not to share it unsafely.
  prefs: []
  type: TYPE_NORMAL
- en: Speech to Text ‚Äî Create Transcription
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The implementation of the speech-to-text feature was achieved using `Whisper`,
    an `OpenAI` model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the code snippet for the function responsible for transcription:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This function is marked as asynchronous (async) since the API call may take
    some time to return a response, and we await it to ensure that the program doesn‚Äôt
    progress until the response is received.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the `get_transcript` function also invokes the `print_text_while_waiting_for_transcription`
    function. Why? Since obtaining the transcription is a time-consuming task, we
    wanted to keep the user informed that the program is actively processing their
    request and not stuck or unresponsive. As a result, this text is gradually printed
    as the user awaits the next step.
  prefs: []
  type: TYPE_NORMAL
- en: String Matching Using FuzzyWuzzy for Text Comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After transcribing the speech into text, we either utilized it as is, or attempted
    to compare it with an existing string.
  prefs: []
  type: TYPE_NORMAL
- en: 'The comparison use cases were: selecting a figure from a predefined list of
    options, deciding whether to continue playing or not, and when opting to continue
    - deciding whether to choose a new figure or stick with the current one.'
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, we wanted to compare the user‚Äôs spoken input transcription with
    the options in our lists, and therefore we decided to use the `FuzzyWuzzy` library
    for string matching.
  prefs: []
  type: TYPE_NORMAL
- en: This enabled choosing the closest option from the list, as long as the matching
    score exceeded a predefined threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs a snippet of our function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you want to learn more about the `FuzzyWuzzy` library and its functions ‚Äî
    you can check out an article I wrote about it [here](/string-comparison-is-easy-with-fuzzywuzzy-library-611cc1888d97).
  prefs: []
  type: TYPE_NORMAL
- en: Get ChatGPT Response
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have the transcription, we can send it over to `ChatGPT` to get a response.
  prefs: []
  type: TYPE_NORMAL
- en: For each `ChatGPT` request, we added a prompt asking for a short and funny response.
    We also told `ChatGPT` which figure to pretend to be.
  prefs: []
  type: TYPE_NORMAL
- en: 'So our function looked as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'and the system instructions looked as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Text to Speech
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the text-to-speech part, we opted for a Python library called `pyttsx3`.
    This choice was not only straightforward to implement but also offered several
    additional advantages. It‚Äôs free of charge, provides two voice options ‚Äî male
    and female ‚Äî and allows you to select the speaking rate in words per minute (speech
    speed).
  prefs: []
  type: TYPE_NORMAL
- en: When a user starts the game, they pick a character from a predefined list of
    options. If we couldn‚Äôt find a match for what they said within our list, we‚Äôd
    randomly select a character from our ‚Äúfallback figures‚Äù list. In both lists, each
    character was associated with a gender, so our text-to-speech function also received
    the voice ID corresponding to the selected gender.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what our text-to-speech function looked like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The Main Flow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we‚Äôve more or less got all the pieces of our app in place, it‚Äôs time
    to dive into the gameplay! The main flow is outlined below. You might notice some
    functions we haven‚Äôt delved into (e.g. `choose_figure`, `play_round`), but you
    can explore the full code by [checking out the repo](https://github.com/NaomiKriger/speech_to_speech_magician).
    Eventually, most of these higher-level functions tie into the internal functions
    we‚Äôve covered above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs a snippet of the main game flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The Roads Not Taken
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We had several ideas in mind that we didn‚Äôt get to implement during the hackathon.
    This was either because we did not find an API we were satisfied with during that
    weekend, or due to the time constraints preventing us from developing certain
    features. These are the paths we didn‚Äôt take for this project:'
  prefs: []
  type: TYPE_NORMAL
- en: Matching the Response Voice with the Chosen Figure‚Äôs ‚ÄúActual‚Äù Voice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine if the user chose to talk to Shrek, Trump, or Oprah Winfrey. We wanted
    our text-to-speech library or API to articulate responses using voices that matched
    the chosen figure. However, we couldn‚Äôt find a library or API during the hackathon
    that offered this feature at a reasonable cost. We‚Äôre still open to suggestions
    if you have any =)
  prefs: []
  type: TYPE_NORMAL
- en: Let the Users Talk to ‚ÄúThemselves‚Äù
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another intriguing idea was to prompt users to provide a vocal sample of themselves
    speaking. We would then train a model using this sample and have all the responses
    generated by ChatGPT read aloud in the user‚Äôs own voice. In this scenario, the
    user could choose the tone of the responses (affirmative and supportive, sarcastic,
    angry, etc.), but the voice would closely resemble that of the user. However,
    we couldn‚Äôt find an API that supported this within the constraints of the hackathon.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Frontend to Our Application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our initial plan was to include a frontend component in our application. However,
    due to a last-minute change in the number of participants in our group, we decided
    to prioritize the backend development. As a result, the application currently
    runs on the command line interface (CLI) and doesn‚Äôt have frontend side.
  prefs: []
  type: TYPE_NORMAL
- en: Additional Improvements We Have In Mind
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Latency is what bothers me most at the moment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several components in the flow with a relatively high latency that
    in my opinion slightly harm the user experience. For example: the time it takes
    from finishing providing the audio input and receiving a transcription, and the
    time it takes since the user presses a button until the system actually starts
    recording the audio. So if the user starts talking right after pressing the key
    ‚Äî there will be at least one second of audio that won‚Äôt be recorded due to this
    lag.'
  prefs: []
  type: TYPE_NORMAL
- en: Link to the Repo & Credits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Want to see the whole project? [It‚Äôs right here](https://github.com/NaomiKriger/speech_to_speech_magician)!
  prefs: []
  type: TYPE_NORMAL
- en: Also, warm credit goes to [Lior Yardeni](https://www.linkedin.com/in/lioryardeni),
    my hackathon partner with whom I created this game.
  prefs: []
  type: TYPE_NORMAL
- en: Summing Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we learned how to create a speech-to-text-to-speech game using
    Python, and intertwined it with AI. We‚Äôve used the `Whisper` model by `OpenAI`
    for speech recognition, played around with the `FuzzyWuzzy` library for text matching,
    tapped into `ChatGPT`‚Äôs conversational magic via their developer API, and brought
    it all to life with `pyttsx3` for text-to-speech. While `OpenAI`‚Äôs services (`Whisper`
    and `ChatGPT` for developers) do come with a modest cost, it‚Äôs budget-friendly.
  prefs: []
  type: TYPE_NORMAL
- en: We hope you‚Äôve found this guide enlightening and that it‚Äôs motivating you to
    embark on your projects.
  prefs: []
  type: TYPE_NORMAL
- en: Cheers to coding and fun! üöÄ
  prefs: []
  type: TYPE_NORMAL
