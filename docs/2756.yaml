- en: NER in Czech Documents with XLM-RoBERTa using ü§ó Accelerate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/ner-in-czech-documents-with-xlm-roberta-using-accelerate-32a6baf3e91e?source=collection_archive---------9-----------------------#2024-11-12](https://towardsdatascience.com/ner-in-czech-documents-with-xlm-roberta-using-accelerate-32a6baf3e91e?source=collection_archive---------9-----------------------#2024-11-12)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Decisions I made during the development of a document processing model that
    was successfully deployed*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@bbuso?source=post_page---byline--32a6baf3e91e--------------------------------)[![Bohumir
    Buso](../Images/751ba491a8f5aca31add3dbc850841c5.png)](https://medium.com/@bbuso?source=post_page---byline--32a6baf3e91e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--32a6baf3e91e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--32a6baf3e91e--------------------------------)
    [Bohumir Buso](https://medium.com/@bbuso?source=post_page---byline--32a6baf3e91e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--32a6baf3e91e--------------------------------)
    ¬∑9 min read¬∑Nov 12, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/874a04ed0f94f4a2b3e255bd98e3ae03.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: Although I have over 8 years of experience with ML projects, this was my first
    NLP project. I initially searched for existing resources and code but found limited
    material, particularly for NER in Czech-language documents. This inspired me to
    compile everything I learned during development into one place, hoping to help
    future newcomers progress more efficiently. As such, **this article offers a practical
    introduction rather than an in-depth theoretical analysis**.
  prefs: []
  type: TYPE_NORMAL
- en: Specific numerical results are omitted due to sensitivity considerations.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/36c928f19c6a3344476a2804e0a82cf8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Example of document with entities: *variable symbol of creditor* (red), surname
    (light green), given name (dark green), date of birth (blue). Sensitive information
    is blacked out.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Task** The **main objective was to identify the client(s) associated with
    each document** through one of the following identifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '*variable symbol of creditor* (present in about 20% of documents)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*birth ID* (present in about 60% of documents)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: combination *name* + *surname* + *birth date* (present in about 50% of documents)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approximately 5% of the documents contained no identifying entities.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset** For development, I used 710 ‚Äútrue‚Äù PDF documents, dividing them
    into three sets: 600 for training, 55 for validation, and 55 for testing.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Labels** I received an Excel file with entities extracted as plain text,
    requiring manual labeling of the document text. Using the [BIO](https://natural-language-understanding.fandom.com/wiki/Named_entity_recognition#BIO)
    tagging format, I followed these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open each document (using `extract_text()` function from the `pdfminer.high_level`
    module)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split text into words (using the SpaCy model ‚Äúxx_sent_ud_sm‚Äù with adjustments,
    such as preventing splits on hyphens to handle birth number formats, e.g., ‚Äò84‚Äì12‚Äì10/7869‚Äô)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify entities within the text
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign corresponding labels to entities, using the ‚ÄúO‚Äù label for all other words
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Alternative Approach** Models like LayoutLM, which also consider bounding
    boxes for input tokens, might improve quality. However, I avoided this option
    since, as usual (üòÆ‚Äçüí®), **I had already spent most of the project time on data
    preparation** (e.g., reformatting Excel files, correcting data errors, labeling).
    Pursuing bounding box-based models would have required even more time.'
  prefs: []
  type: TYPE_NORMAL
- en: While regex and heuristics could theoretically work for simple entities like
    these, I believe this approach would be ineffective, as it would require overly
    complex rules to accurately identify the correct ones amidst other potential candidates
    (lawyer name, case number, other participants in the proceedings, etc.). The model,
    on the other hand, is capable of learning to distinguish the relevant entities,
    making the use of heuristics unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: Model (training)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**ü§ó Accelerate**'
  prefs: []
  type: TYPE_NORMAL
- en: Having started in a time when wrappers were less common, **I became accustomed
    to writing my own training loops, which I find easier to debug -** **an approach
    that ü§ó Accelerate supports effectively**. It proved beneficial in this project
    - I wasn‚Äôt entirely certain of the required data and label formats or shapes and
    my data didn‚Äôt match the well-organized examples often shown in tutorials, but
    having full access to intermediate computations during the training loop allowed
    me to iterate quickly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Context Length** Most tutorials suggest using each sentence as a single training
    example. However, in this case, I decided **a longer context would be more suitable
    as documents typically contain references to multiple entities**, many of which
    are irrelevant (e.g. lawyers, other creditors, case numbers). This broader context
    enables the model to better identify the relevant client. I used 512 tokens from
    each document as one training example. This is a common maximum limit for models
    but comfortably accommodates all entities in most of my documents.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Labelling of Subtokens** In the ü§ó token classification tutorial [1], recommended
    approach is:'
  prefs: []
  type: TYPE_NORMAL
- en: Only labeling the first token of a given word. Assign `*-100*` to other subtokens
    from the same word.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'However, I found that the following method suggested in the token classification
    tutorial in their NLP course [2] works much better:'
  prefs: []
  type: TYPE_NORMAL
- en: Each token gets the same label as the token that started the word it‚Äôs inside,
    since they are part of the same entity. For tokens inside a word but not at the
    beginning, we replace the `*B-*` with `*I-*`
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Label ‚Äú-100‚Äù is special label that is ignoredby loss function. Hence, I used
    their functions with minor changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'I also used their `postprocess()`function:'
  prefs: []
  type: TYPE_NORMAL
- en: To simplify its evaluation part, we define this `*postprocess()*` function that
    takes predictions and labels and converts them to lists of strings.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Class Weights'
  prefs: []
  type: TYPE_NORMAL
- en: 'Incorporating class weights into the loss function significantly improved model
    performance.** While this adjustment may seem straightforward ‚Äî without it, the
    model overemphasized the majority ‚ÄúO‚Äù class ‚Äî it‚Äôs surprisingly absent from most
    tutorials. I implemented a custom `compute_weights()` function to address this
    imbalance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Training Loop** I defined two additional functions: PyTorch `DataLoader()`
    to manage batch processing, and a `main()` function to set up distributed training
    objects and execute the training loop.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'With everything prepared, the model is ready for training. I just need to initiate
    the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**I find using** `notebook_launcher()` **convenient, as it allows me to run
    training in the console and easily work with results afterward.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**XLM-RoBERTa base vs large vs Small-E-Czech** I experimented with fine-tuning
    three models. The XLM-RoBERTa base model [3] delivered satisfactory performance,
    but the server capacity also allowed me to try the XLM-RoBERTa large model [3],
    which has twice the parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: XLM-RoBERTa is a multilingual version of RoBERTa. It is pre-trained on 2.5TB
    of filtered CommonCrawl data containing 100 languages.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The large model showed a slight improvement in results, so I ultimately deployed
    it. I also tested Small-E-Czech [4], an Electra-small model pre-trained on Czech
    web data, but its performance was poor.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fine-tuning vs Transfer learning vs Training from scratch** In addition to
    fine-tuning (updating all model weights), I tested transfer learning, as it is
    sometimes suggested that training only the final (classification) layer may suffice..
    However, the performance difference was significant, favoring full fine-tuning.
    I also attempted training from scratch by importing only architecture of the model,
    initializing the weights randomly, and then training, but as expected, this approach
    was ineffective.'
  prefs: []
  type: TYPE_NORMAL
- en: '**RoBERTa vs LLM (Claude 3.5 Sonnet)** I briefly explored zero-shot LLMs, though
    with minimal prompt engineering (so ü•±). The model struggled even with basic requests,
    such as (I used Czech in the actual prompt):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find variable symbol of creditor.This number has exactly 9 consecutive digits
    0‚Äì9 without letters or other special characters. It is usually preceded by one
    of the following abbreviations: ‚Äòev.ƒç.‚Äô, ‚Äòzn. opr‚Äô, ‚ÄòVS. O‚Äô, ‚Äòevid. ƒç. opr.‚Äô.
    On the contrary, I‚Äôm not interested in a transaction number with the abbreviation
    ‚Äòƒç.j.‚Äô. This number does not appear often in documents, it may happen that you
    will not be able to find it, then write ‚Äòcannot find‚Äô. If you‚Äôre not sure, write
    ‚Äònot sure‚Äô.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The model sometimes failed to output the 9-digit format accurately. Post-processing
    would filter out shorter numbers, but there were many false positives 9-digit
    numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally the model inferred incorrect *birth ID*s based solely on birth
    dates (even with temperature set to 0). On the other hand, it excelled at extracting
    *names*, *surnames*, and *birth dates*.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, even in my previous experiments, **I found that LLMs** (at the time
    of writing) **perform better with general tasks but lack accuracy and reliability
    for specific or unconventional tasks.** The performance in identifying the client
    was fairly similar for both approaches. For internal reasons, the RoBERTa model
    was deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Post-processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Notably, implementing **post-processing can significantly reduce false positives**,
    enhancing overall performance. Each entity was subject to customized filtering
    and validation rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '*variable symbol of debtor -* verify 9 digits format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*birth ID -* enforce XXXXXX/XXX(X) format and check divisibility by eleven'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*name* and *surname -* apply lemmatization using MorphoDiTa [5]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*date of birth -* enforce DD.MM.YYYY format'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fine-tuned model was successfully deployed and **performs superbly**, **exceeding
    expectations given the modest dataset** of 710 documents.
  prefs: []
  type: TYPE_NORMAL
- en: While LLMs show promise for general tasks, they lack the accuracy and reliability
    for specialized tasks. That said, it‚Äôs likely that in the near future, even fine-tuning
    will become unnecessary for all but highly specialized cases as LLMs continue
    to improve.
  prefs: []
  type: TYPE_NORMAL
- en: '**Acknowledgments** I would like to thank [Martin](https://www.linkedin.com/in/martin-munch/),
    [Tom√°≈°](https://www.linkedin.com/in/tomas-duricek/) and [Petr](https://www.linkedin.com/in/petr-petras-37b2b0160/)
    for their valuable suggestions for the improvement of this article.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sources** [1] Hugging Face, [Transformers - Token classification](https://huggingface.co/docs/transformers/tasks/token_classification#preprocess)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Hugging Face, [NLP Course ‚Äî Token classification](https://huggingface.co/learn/nlp-course/chapter7/2)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] A. Conneau, K. Khandelwal, N. Goyal, V. Chaudhary, G. Wenzek, F. Guzman,
    E. Grave, M. Ott, L. Zettlemoyer and V. Stoyanov, [Unsupervised Cross-lingual
    Representation Learning at Scale](https://arxiv.org/abs/1911.02116) (2019), CoRR
    abs/1911.02116'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] M. Koci√°n, J. N√°plava, D. ≈†tancl and V. Kadlec, [Siamese BERT-based Model
    for Web Search Relevance Ranking Evaluated on a New Czech Dataset](https://arxiv.org/abs/2112.01810)
    (2021)'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] J. Strakov√°, M. Straka and J. Hajiƒç . [Open-Source Tools for Morphology,
    Lemmatization, POS Tagging and Named Entity Recognition](http://www.aclweb.org/anthology/P/P14/P14-5003.pdf)
    (2014), In Proceedings of 52nd Annual Meeting of the Association for Computational
    Linguistics: System Demonstrations, pages 13‚Äì18, Baltimore, Maryland, June 2014\.
    Association for Computational Linguistics.'
  prefs: []
  type: TYPE_NORMAL
