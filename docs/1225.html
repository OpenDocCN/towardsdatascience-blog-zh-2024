<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Next-Level Agents: Unlocking the Power of Dynamic Context</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Next-Level Agents: Unlocking the Power of Dynamic Context</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/next-level-agents-unlocking-the-power-of-dynamic-context-68b8647eef89?source=collection_archive---------5-----------------------#2024-05-15">https://towardsdatascience.com/next-level-agents-unlocking-the-power-of-dynamic-context-68b8647eef89?source=collection_archive---------5-----------------------#2024-05-15</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="2ec6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx"><em class="hd">How to improve accuracy, speed, and token usage of AI agents</em></h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="he hf hg hh hi ab"><div><div class="ab hj"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@frankw_usa?source=post_page---byline--68b8647eef89--------------------------------" rel="noopener follow"><div class="l hk hl by hm hn"><div class="l ed"><img alt="Frank Wittkampf" class="l ep by dd de cx" src="../Images/3dbd69f8ef648074fa170fac451645fd.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*NKA6NcV6ulN5ingXiivgKQ.png"/><div class="ho by l dd de em n hp eo"/></div></div></a></div></div><div class="hq ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--68b8647eef89--------------------------------" rel="noopener follow"><div class="l hr hs by hm ht"><div class="l ed"><img alt="Towards Data Science" class="l ep by br hu cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ho by l br hu em n hp eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hv ab q"><div class="ab q hw"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hx hy bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hz" data-testid="authorName" href="https://medium.com/@frankw_usa?source=post_page---byline--68b8647eef89--------------------------------" rel="noopener follow">Frank Wittkampf</a></p></div></div></div><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hx hy dx"><button class="ic id ah ai aj ak al am an ao ap aq ar ie if ig" disabled="">Follow</button></p></div></div></span></div></div><div class="l ih"><span class="bf b bg z dx"><div class="ab cn ii ij ik"><div class="il im ab"><div class="bf b bg z dx ab in"><span class="io l ih">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hz ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--68b8647eef89--------------------------------" rel="noopener follow"><p class="bf b bg z ip iq ir is it iu iv iw bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ia ib" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="ix iy l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">May 15, 2024</span></div></span></div></span></div></div></div><div class="ab cp iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo"><div class="h k w ea eb q"><div class="ke l"><div class="ab q kf kg"><div class="pw-multi-vote-icon ed io kh ki kj"><div class=""><div class="kk kl km kn ko kp kq am kr ks kt kj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ku kv kw kx ky kz la"><p class="bf b dy z dx"><span class="kl">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kk ld le ab q ee lf lg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count lb lc">1</span></p></button></div></div></div><div class="ab q jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="lh k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al li an ao ap ie lj lk ll" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lm cn"><div class="l ae"><div class="ab cb"><div class="ln lo lp lq lr ls ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al li an ao ap ie lt lu lg lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mn mo mp mq mr ms mk ml paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml mm"><img src="../Images/7eafdf2106c409b65fc51079a1e7dbcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cot84CsTvC4nC2omybk_Yw.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx"><em class="hd">Most AI agents differ significantly from each other (image generated with MidJourney)</em></figcaption></figure><h1 id="29d6" class="nd ne fq bf nf ng nh gq ni nj nk gt nl nm nn no np nq nr ns nt nu nv nw nx ny bk">Introduction</h1><p id="5712" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">The behavior of an AI agent is defined by two things: (1) the model it runs on and (2) the context that you provide to the model. <strong class="ob fr">How</strong> you provide this context determines the quality of the output of the agent. You can even say that the behavior that distinguishes two AI agents running on the same model is fully defined by their context. So, what do we mean with context for an agent? See the <em class="ov">Types of Context (</em>image) below for examples.</p><p id="a992" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">This article delves into more advanced methods to enhance AI agent efficiency and accuracy by selectively tailoring context according to the needs of an agent. First I will describe 5 tactics, and then some additional implementation tips. The learnings in the article come from extensive experience in working with multi-agent teams in a production environment, but are just as applicable to single agent systems.</p></div></div><div class="ms"><div class="ab cb"><div class="ln pb lo pc lp pd cf pe cg pf ci bh"><figure class="mn mo mp mq mr ms ph pi paragraph-image"><div role="button" tabindex="0" class="mt mu ed mv bh mw"><div class="mk ml pg"><img src="../Images/2aa6eb7cdbbd3b57166431add3fd6662.png" data-original-src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*DQkhkuo6zII49KWH15LxmA.png"/></div></div><figcaption class="my mz na mk ml nb nc bf b bg z dx">Types of Context for AI agents (image by author)</figcaption></figure></div></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="d105" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Understanding Contextual Needs</h1><p id="d68e" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Most online examples and tutorials simplify their approach to context (e.g. applying a fixed cutoff length). Real AI applications need a more sophisticated approach.</p><p id="6e39" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Different agents have different contextual needs depending on the task at hand. Some agents may only require just the prior message, while other agents might need extensive historical data to respond accurately. These differences suggest that a tailored approach to context management for each agent is needed.</p><p id="1b43" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Consider the following example of an ongoing conversation between a user and 2 agents (a SW developer and a SW reviewer):</p><pre class="mn mo mp mq mr pw px py bp pz bb bk"><span id="da9c" class="qa ne fq px b bg qb qc l qd qe">1 <strong class="px fr">User</strong>: “Please improve the sorting function I wrote from the uploaded file”<br/>2 <strong class="px fr">System_prompt_for_coder</strong>: “You are a SW developer, you help the user to <br/>  develop …”<br/>3 <strong class="px fr">Coding_agent</strong>: “read_file_function”<br/>4 <strong class="px fr">Function_response</strong>: “coding snippet: ```some returned code```”<br/>5 <strong class="px fr">System_prompt_for_coder</strong>: “You are a SW developer, you help the user to<br/>  develop …”<br/>6 <strong class="px fr">Coding_agent</strong>: “I’ve improved your code by adding … and … to your code, <br/>  here is the new function …”<br/>7 <strong class="px fr">System_prompt_for_reviewer</strong>: “you are a SW code reviewer, you …”<br/>8 <strong class="px fr">Code_reviewer_agent</strong>: “After reviewing the improved code, there <br/>  are a few more things that I would add to the code …"<br/>9 <strong class="px fr">System_prompt_for_coder</strong>: “you are a SW developer, you help the user to <br/>  develop …”<br/>10 <strong class="px fr">Coding_agent</strong>: “ … ”</span></pre><p id="5395" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">The context, as defined in this example is obviously repetitive and inefficient. Many lines are repeated (e.g. the system prompts), and each agent is getting more context than it needs. Let’s review a few ways to improve the context handling.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="997d" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Tactic 1: Message Labeling</h1><p id="57e9" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Message labeling is a critical tool for managing and optimizing the interaction between AI agents and their tasks. By assigning metadata to each message in the conversation, we can smartly select the information that is most relevant to the agent’s task at hand. This tactic involves several key strategies:</p><p id="638f" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Relevance Labeling</strong>: Each message should be tagged with labels that reflect its relevance to ongoing and future interactions. This process involves analyzing the content of the message and determining its potential utility for the agent’s decision-making processes. For example, messages that contain questions, decisions or insights should be marked as highly relevant.</p><p id="27ac" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Permanence Labeling</strong>: It is vital to categorize messages based on their longevity and usefulness over time. Some messages, such as those containing foundational decisions or milestone communications, hold long-term value and should be retained across sessions. In contrast, system messages might only be needed once in a specific moment. These should be excluded from the agent’s memory once their immediate relevance has passed.</p><p id="dc29" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Source and Association Labeling</strong>: This involves identifying the origin of each message, whether it be from a specific agent, a user, function, or other process. This labeling helps in constructing a structured and easily navigable history that allows agents to efficiently retrieve and reference information based on source or task relevance.</p><p id="65ad" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Applying smart labels to the metadata of a message allows you to use smart selection. Keep reading for some examples.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="52bc" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Tactic 2: Agent-specific context requirements</h1><p id="d533" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Different agents have different requirements. Some agents can operate on very little information, while others need a lot of context to operate correctly. This tactic builds on the labeling we just discussed.</p><p id="dd76" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Critical Context Identification</strong>: It is crucial to identify which messages are critical for each specific agent and focus on these to streamline processing and enhance response accuracy. Let’s look at line 8 in the context above. The code reviewer only needs a limited amount of context to be able to accurately do its work. We can even say with some certainty that it will produce a worse answer if we give it more than the necessary context.</p><p id="be09" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">So what context <em class="ov">does</em> it need? Take a quick look, and you’ll infer that the code reviewer only needs its own system prompt, and it needs the last agent message before it, containing the latest iteration of the code (line 6).</p><p id="827d" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Therefore, each agent should be configured such that it selects only the history that it needs. The code reviewer only looks at the last 2 messages, while the code writer needs a longer history.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="6fb5" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Tactic 3: Optimization of System Prompts</h1><p id="09a6" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk"><strong class="ob fr">Placement:</strong> When you do a quick search on agents and system prompts, it’s clear that placement of a system prompt for an agent matters. Should it be the first message in the chain, the last message? Opinions and results vary, depending on the use case. For example, which gives a better result?</p><pre class="mn mo mp mq mr pw px py bp pz bb bk"><span id="27f4" class="qa ne fq px b bg qb qc l qd qe">1) user: "I visited dr. Fauci on Thursday, and got diagnosed with …"<br/>2) system: "Extract all medically relevant info from the user prompt"</span></pre><p id="69ce" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Or</p><pre class="mn mo mp mq mr pw px py bp pz bb bk"><span id="426e" class="qa ne fq px b bg qb qc l qd qe"><br/>1) system: "Extract all medically relevant info from the user prompt"<br/>2) user: "I visited dr. Fauci on Thursday, and got diagnosed with …"</span></pre><p id="edbf" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">If you test this with a larger and more complex history, you’ll find that different placement of the same instruction produces different results. What is clear is that system prompts should be intentionally placed in a specific position, and that this depends on the agent and use case.</p><p id="9106" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Note: in my experience it depends on the LLM to know if the system prompt should be the last message in the chain. Often putting it as the last message is a good choice (with definite exceptions, e.g. information extraction).</p><p id="51bc" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Permanence:</strong> Secondly, in addition to placement of system prompts, in most use cases you should ensure that a system prompt is labeled as “fleeting”. What I mean with a fleeting message, is that it does not remain in the chat history after it has been used.</p><p id="31d6" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">For example, agent1 might get a prompt that it should step back and reflect on the problem. One turn later, agent1 is asked to use its reflection to find a solution to the problem. In that second turn, the initial prompt (to reflect) will only confuse the agent and result in a worse answer. It would have been better if that initial system prompt was not permanent, and would not have been provided to the agent again. In the example below, this means that line #2 should be removed when you make your second LLM call to the agent.</p><pre class="mn mo mp mq mr pw px py bp pz bb bk"><span id="659d" class="qa ne fq px b bg qb qc l qd qe">#1 <strong class="px fr">User</strong>: <br/>  "What is the meaning of the universe?"<br/>#2 <strong class="px fr">System</strong>: <br/>  "You're a philosopher; before you answer, step back and <br/>  reflect on what the user's question implies."<br/>#3 <strong class="px fr">Agent_philo</strong>: <br/>  "Reflecting on this question, one can consider the universe <br/>  through various philosophical lenses - existentialism views <br/>  it as a canvas for creating personal meaning, while cosmology <br/>  sees it as a playground for understanding physical laws. This <br/>  interplay between human perception and scientific exploration <br/>  is central to understanding our query."<br/>#4 <strong class="px fr">System</strong>: <br/>  "You're a philosopher, and you just reflected deeply on the <br/>  question posed by the user. Use that insightful reflection to <br/>  craft a comprehensive answer."<br/>#5 <strong class="px fr">Agent_philo</strong>: <br/>  "From an existentialist perspective, the meaning of the universe <br/>  is a personal journey, where each individual constructs their own <br/>  meaning through choices and life experiences. In contrast, from a <br/>  cosmological viewpoint, it is about exploring and understanding <br/>  the vast, intricate laws that govern the cosmos. These perspectives <br/>  help us grasp the multifaceted nature of our universe, blending our <br/>  existential quests with scientific inquiry."</span></pre><p id="a681" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">This approach ensures that any old system prompt is removed from the chain, and that each prompt is positioned optimally. Now we have an uncluttered conversation history, allowing for more precise and predictable interactions.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="1367" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Tactic 4: Reducing redundancy in your RAG</h1><p id="d5de" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">We could dedicate a dozen articles to optimizing your agent by improving how you do RAG, but will keep it contained to a few paragraphs here. The sheer volume of tokens that can come from using RAG is so large that we have to mention a few techniques on how to manage it. If you haven’t already, this is a topic you should spend considerable time researching.</p><p id="d295" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Basic tutorials on RAG mostly assume that the documents that you or your user uploads are simple and straightforward. However, in practice most documents are complex and unpredictable. My experience is that a lot of documents have repetitive information. For example, the same information is often repeated in the intro, body, and conclusion of a PDF article. Or a medical file will have repetitive doctor updates with (almost) the same information. Or logs are repeated over and over. Also, especially in production environments, when dealing with retrieval across a large body of files, the content returned by a standard RAG process can be extremely repetitive.</p><p id="eb6a" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Dealing with Duplicates</strong>: A first step to optimize your RAG context, is to identify and remove exact and near duplicates within the retrieved document snippets to prevent redundancy. Exact duplicates are easy to identify. Near duplicates can be detected by semantic similarity, by looking at diversity of vector embeddings (diverse snippets have vectors that have a larger distance from each other), and many other techniques. How you do this will be extremely dependent on your use case. Here are a <a class="af qf" href="https://www.perplexity.ai/search?q=show+me+best+practices+on+how+to+remove+near+duplicates+in+my+RAG+results" rel="noopener ugc nofollow" target="_blank">few examples (by perplexity)</a></p><p id="610b" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Diversity in Responses:</strong> Another way to ensure diversity of RAG responses by smartly grouping content from various files. A very simple, but effective approach is to not just take the top N documents by similarity, but to use a GROUP BY in your retrieval query. Again, if you employ this depends highly on your use case. Here’s an <a class="af qf" href="https://www.perplexity.ai/search?q=show+me+a+query+that+selects+the+top+N+similar+results+from+a+vector+database+but+groups+it+by+file+so+that+you+ensure+the+diversity+of+snippets+come+from+several+files+instead+of+just+one+or+two" rel="noopener ugc nofollow" target="_blank">example (by perplexity)</a></p><p id="2e2c" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Dynamic Retrieval</strong>: So, given that this article is about dynamic context, how do you introduce that philosophy into your RAG process? Most RAG processes retrieve the top N results, e.g. the top 10 most similar document snippets. However, this is not how a human would retrieve results. When you search for information, you go to something like google, and you search until you find the right answer. This could be in the 1st or 2nd search result, or this could be in the 20th. Of course, depending on your luck and stamina ;-). You can model your RAG the same way. We can allow the agent to do a more selective retrieval, only giving it the top few results, and have the agent decide if it wants more information.</p><p id="765b" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Here’s a suggested approach. Don’t just define one similarity cutoff, define a high, medium and low cutoff point. For example, the results of your search could be 11 very similar, 5 medium, and 20 somewhat similar docs. If we say the agent gets 5 docs at a time, now you let the agent itself decide if it wants more or not. You tell the agent that it has seen 5 of the 11 very similar docs, and that there are 25 more beyond that. With some prompt engineering, your agent will quickly start acting much more rationally when looking for data.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="4bf2" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Tactic 5: Advanced Strategies for Context Processing</h1><p id="c095" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">I’ll touch upon a few strategies to take dynamic context even a step further.</p><p id="de6d" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Instant Metadata</strong>: As described in tactic 1, adding metadata to messages can help you to preselect the history that a specific agent needs. For most situations, a simple one word text label should be sufficient. Knowing that something comes from a given function, or a specific agent, or user allows you to add a simple label to the message, but if you deal with very large AI responses and have a need for more optimization, then there is a more advanced way to add metadata to your messages: with AI.</p><p id="bc8a" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">A few examples of this are:</p><ul class=""><li id="5f39" class="nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou qg qh qi bk">A simple way to label a history message, is to make a separate AI call (to a cheaper model), which generates a label for the message. However, now you’re making 2 AI calls each time, and you’re introducing additional complexity in your flow.</li></ul><p id="9faa" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">A more elegant way to generate a label is to have the original author of a message generate a label at the same time as it writes its response.</p><ul class=""><li id="4fc3" class="nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou qg qh qi bk">Have the agent give you a response in JSON, where one element is its normal response, and the other element is a label of the content.</li><li id="d990" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Use multi-function calling, and provide the agent a function that it’s required to call, which defines the message label.</li><li id="1010" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">In any function call that the agent makes, reserve a required parameter which contains a label.<br/>In this way, you instantly generate a label for the function contents.</li></ul><p id="9e6f" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Another advanced strategy to optimize context dynamically is to pre-process your RAG..</p><p id="c577" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Dual processing for RAG: </strong>To optimize your RAG flow, you might consider using a cheaper (and faster) LLM to condense your RAG results before they are provided into your standard LLM. The trick when using this approach, is to use a very simple and non-disruptive prompt that condenses or simplifies the original RAG results into a more digestible form.</p><p id="dc97" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">For example, you might use a cheaper model to strip out specific information, to reduce duplication, or to only select parts of the document that are relevant to the task at hand. This does require that you know what the strengths and weaknesses of the cheaper model are. This approach can save you a lot of cost (and speed) when used in combination with a more powerful model.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="b2dc" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk">Implementation</h1><p id="da21" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">OK, so does all the above mean that each of my agents needs pages and pages of custom code to optimize its performance? How do I generalize these concepts and extend them?</p><p id="47ab" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Agent Architecture</strong>: The answer to these questions is that there are clean ways to set this up. It just requires some foresight and planning. Building a platform that can properly run a variety of agents requires that you have an Agent Architecture. If you start with a set of clear design principles, then it’s not very complicated to make use of dynamic context and have your agents be faster, cheaper, and better. All at the same time.</p><p id="1679" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Dynamic Context Configuration is one of the elements of your Agent Architecture.</p><p id="0cd7" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk"><strong class="ob fr">Dynamic Context Configuration</strong>: As discussed in this article, each agent has unique context needs. And managing these needs can come down to managing a lot of variation across all possible agent contexts (see the image at the top of the article). However, the good news is that these variations can easily be encoded into a few simple dimensions. Let me give you an example that brings together most of the concepts in this article.</p><p id="9f82" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Let’s imagine an agent who is a SW developer who first plans their actions, and then executes that plan. The context configuration for this agent might be:</p><ul class=""><li id="e820" class="nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou qg qh qi bk">Retain the initial user question</li><li id="fd46" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Retain the plan</li><li id="befb" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Forget all history except for the last code revision and the last message in the chain</li><li id="a63f" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Use RAG (on uploaded code files) without RAG condensation</li><li id="b05a" class="nz oa fq ob b go qj od oe gr qk og oh oi ql ok ol om qm oo op oq qn os ot ou qg qh qi bk">Always set system prompt as last message</li></ul><p id="d8b7" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">This configuration is saved in the context configuration of this agent. So now your definition of an AI agent is that it is more than a set of prompt instructions. Your agent also a has a specific context configuration.</p><p id="b0ad" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">You’ll see that across agents, these configurations can be very meaningful and different, and that they allow for a great abstraction of code that otherwise would be very custom.</p></div></div></div><div class="ab cb pj pk pl pm" role="separator"><span class="pn by bm po pp pq"/><span class="pn by bm po pp pq"/><span class="pn by bm po pp"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h1 id="e343" class="nd ne fq bf nf ng pr gq ni nj ps gt nl nm pt no np nq pu ns nt nu pv nw nx ny bk"><em class="hd">Rounding up</em></h1><p id="a016" class="pw-post-body-paragraph nz oa fq ob b go oc od oe gr of og oh oi oj ok ol om on oo op oq or os ot ou fj bk">Properly managing Dynamic context not only enhances the performance of your AI agents but also greatly improves accuracy, speed, and token usage… Your agents are now faster, better, and cheaper, all at the same time.</p><p id="181b" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Your agent should not only be defined by its prompt instructions, it should also have its own context configuration. Using simple dimensions that encode a different configuration for each agent, will greatly enhance what you can achieve with your agents.</p><p id="7e0b" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Dynamic Context is just one element of your Agent Architecture. Invite me to discuss if you want to learn more. Hit me up in the comments section with questions or other insights, and of course, give me a few clicks on the claps or follow me if you got something useful from this article.</p><p id="6acd" class="pw-post-body-paragraph nz oa fq ob b go ow od oe gr ox og oh oi oy ok ol om oz oo op oq pa os ot ou fj bk">Happy coding!</p></div></div></div></div>    
</body>
</html>