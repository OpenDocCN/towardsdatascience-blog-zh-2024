["```py\nimport pandas as pd\nimport fitz  # PyMuPDF\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nimport lancedb\nfrom sentence_transformers import SentenceTransformer\nimport json\nimport pyarrow as pa\nimport numpy as np\nimport re\n```", "```py\ndef create_prompt(question):\n    \"\"\"\n    Create a prompt as per LLAMA 3.2 format.\n    \"\"\"\n    system_message = \"You are a helpful assistant for summarizing text and result in JSON format\"\n    prompt_template = f'''\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>\n{question}<|eot_id|><|start_header_id|>assistant1231231222<|end_header_id|>\n'''\n    return prompt_template\n```", "```py\ndef process_prompt(prompt, model, tokenizer, device, max_length=500):\n    \"\"\"\n    Processes a prompt, generates a response, and extracts the assistant's reply.\n    \"\"\"\n    prompt_encoded = tokenizer(prompt, truncation=True, padding=False, return_tensors=\"pt\")\n    model.eval()\n    output = model.generate(\n        input_ids=prompt_encoded.input_ids.to(device),\n        max_new_tokens=max_length,\n        attention_mask=prompt_encoded.attention_mask.to(device),\n        temperature=0.1  # More deterministic\n    )\n    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n    parts = answer.split(\"assistant1231231222\", 1)\n   if len(parts) > 1:\n        words_after_assistant = parts[1].strip()\n        return words_after_assistant\n    else:\n        print(\"The assistant's response was not found.\")\n        return \"NONE\"\n```", "```py\nmodel_name_long = \"meta-llama/Llama-3.2-1B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name_long)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlog.info(f\"Loading the model {model_name_long}\")\nbf16 = False\nfp16 = True\nif torch.cuda.is_available():\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        log.info(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        bf16 = True\n        fp16 = False\n# Load the model\ndevice_map = {\"\": 0}  # Load on GPU 0\ntorch_dtype = torch.bfloat16 if bf16 else torch.float16\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name_long,\n    torch_dtype=torch_dtype,\n    device_map=device_map,\n)\nlog.info(f\"Model loaded with torch_dtype={torch_dtype}\")\n```", "```py\nfile_path = './data/troubleshooting.pdf'\ndict_pages = {}\n# Open the PDF file\nwith fitz.open(file_path) as pdf_document:\n    for page_number in range(pdf_document.page_count):\n        page = pdf_document.load_page(page_number)\n        page_text = page.get_text()\n        dict_pages[page_number] = page_text\n        print(f\"Processed PDF page {page_number + 1}\")\n```", "```py\n# Initialize the SentenceTransformer model\nsentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n# Connect to LanceDB\ndb = lancedb.connect('./data/my_lancedb')\n# Define the schema using PyArrow\nschema = pa.schema([\n    pa.field(\"page_number\", pa.int64()),\n    pa.field(\"original_content\", pa.string()),\n    pa.field(\"summary\", pa.string()),\n    pa.field(\"keywords\", pa.string()),\n    pa.field(\"vectorS\", pa.list_(pa.float32(), 384)),  # Embedding size of 384\n    pa.field(\"vectorK\", pa.list_(pa.float32(), 384)),\n])\n# Create or connect to a table\ntable = db.create_table('summaries', schema=schema, mode='overwrite')\n```", "```py\n# Loop through each page in the PDF\nfor page_number, text in dict_pages.items():\n    question = f\"\"\"For the given passage, provide a long summary about it, incorporating all the main keywords in the passage.\nFormat should be in JSON format like below:\n{{\n    \"summary\": <text summary>,\n    \"keywords\": <a comma-separated list of main keywords and acronyms that appear in the passage>,\n}}\nMake sure that JSON fields have double quotes and use the correct closing delimiters.\nPassage: {text}\"\"\"\n\n    prompt = create_prompt(question)\n    response = process_prompt(prompt, model, tokenizer, device)\n\n    # Error handling for JSON decoding\n    try:\n        summary_json = json.loads(response)\n    except json.decoder.JSONDecodeError as e:\n        exception_msg = str(e)\n        question = f\"\"\"Correct the following JSON {response} which has {exception_msg} to proper JSON format. Output only JSON.\"\"\"\n        log.warning(f\"{exception_msg} for {response}\")\n        prompt = create_prompt(question)\n        response = process_prompt(prompt, model, tokenizer, device)\n        log.warning(f\"Corrected '{response}'\")\n        try:\n            summary_json = json.loads(response)\n        except Exception as e:\n            log.error(f\"Failed to parse JSON: '{e}' for '{response}'\")\n            continue\n\n    keywords = ', '.join(summary_json['keywords'])\n\n    # Generate embeddings\n    vectorS = sentence_model.encode(summary_json['summary'])\n    vectorK = sentence_model.encode(keywords)\n\n    # Store the data in LanceDB\n    table.add([{\n        \"page_number\": int(page_number),\n        \"original_content\": text,\n        \"summary\": summary_json['summary'],\n        \"keywords\": keywords,\n        \"vectorS\": vectorS,\n        \"vectorK\": vectorK\n    }])\n\n    print(f\"Data for page {page_number} stored successfully.\")\n```", "```py\n# Use the Small LLAMA 3.2 1B model to create summary\nfor page_number, text in dict_pages.items():\n    question = f\"\"\"For the given passage, provide a long summary about it, incorporating all the main keywords in the passage.\n    Format should be in JSON format like below: \n    {{\n        \"summary\": <text summary> example \"Some Summary text\",\n        \"keywords\": <a comma separated list of main keywords and acronyms that appear in the passage> example [\"keyword1\",\"keyword2\"],\n    }}\n    Make sure that JSON fields have double quotes, e.g., instead of 'summary' use \"summary\", and use the closing and ending delimiters.\n    Passage: {text}\"\"\"\n    prompt = create_prompt(question)\n    response = process_prompt(prompt, model, tokenizer, device)\n    try:\n        summary_json = json.loads(response)\n    except json.decoder.JSONDecodeError as e:\n        exception_msg = str(e)\n        # Use the LLM to correct its own output\n        question = f\"\"\"Correct the following JSON {response} which has {exception_msg} to proper JSON format. Output only the corrected JSON.\n        Format should be in JSON format like below: \n        {{\n            \"summary\": <text summary> example \"Some Summary text\",\n            \"keywords\": <a comma separated list of keywords and acronyms that appear in the passage> example [\"keyword1\",\"keyword2\"],\n        }}\"\"\"\n        log.warning(f\"{exception_msg} for {response}\")\n        prompt = create_prompt(question)\n        response = process_prompt(prompt, model, tokenizer, device)\n        log.warning(f\"Corrected '{response}'\")\n        # Try parsing the corrected JSON\n        try:\n            summary_json = json.loads(response)\n        except json.decoder.JSONDecodeError as e:\n            log.error(f\"Failed to parse corrected JSON: '{e}' for '{response}'\")\n            continue\n```", "```py\n{\n    'summary': 'This page explains the installation steps for the product.',\n    'keywords': ['installation', 'setup', 'product']\n}\n```", "```py\nexception_msg = \"Expecting property name enclosed in double quotes\"\nquestion = f\"\"\"Correct the following JSON {response} which has {exception_msg} to proper JSON format. Output only the corrected JSON.\"\"\"\n```", "```py\n{\n    \"summary\": \"This page explains the installation steps for the product.\",\n    \"keywords\": [\"installation\", \"setup\", \"product\"]\n}\n```", "```py\ndef generate_summary_with_agent(text):\n    agent = LLMAgent(model, tokenizer, device)\n    question = f\"\"\"For the given passage, provide a summary and keywords in proper JSON format.\"\"\"\n    prompt = create_prompt(question)\n    response = agent.process_and_correct(prompt)\n    return response\n```", "```py\n# Example usage\nuser_question = \"Not able to manage new devices\"\nresults = search_summary(user_question, sentence_model)\n```", "```py\nsummary_list = []\nfor idx, result in enumerate(results):\n    summary_list.append(f\"{result['page_number']}# {result['summary']}\")\n```", "```py\nquestion = f\"\"\"From the given list of summaries {summary_list}, rank which summary would possibly have \\\nthe answer to the question '{user_question}'. Return only that summary from the list.\"\"\"\nlog.info(question) \n```", "```py\nfor idx, result in enumerate(results):\n    if int(page_number) == result['page_number']:\n        page = result['original_content']\n        question = f\"\"\"Can you answer the query: '{user_question}' \\\nusing the context below?\nContext: '{page}'\n\"\"\"\n        log.info(question)\n        prompt = create_prompt(\n            question,\n            \"You are a helpful assistant that will go through the given query and context, think in steps, and then try to answer the query \\\nwith the information in the context.\"\n        )\n        response = process_prompt(prompt, model, tokenizer, device, temperature=0.01)  # Less freedom to hallucinate\n        log.info(response)\n        print(\"Final Answer:\")\n        print(response)\n        break\n```", "```py\n>>  From the VectorDB Cosine search and Top 3 nearest neighbour search result, \nprepended by linked page numbers\n\n07:04:00 INFO:From the given list of summary [[\n'112# Cannot place newly discovered device in managed state', \n'113# The passage discusses the troubleshooting steps for managing newly discovered devices on the NSF platform, specifically addressing issues with device placement, configuration, and deployment.',\n'116# Troubleshooting Device Configuration Backup Issue']] rank which summary would possibly have the possible answer to the question Not able to manage new devices. Return only that summary from the list\n```", "```py\n>> Asking LLM to Select from the Top N based on context\n\n07:04:01 INFO:Selected Summary ''113# The passage discusses the troubleshooting steps for managing newly discovered devices on the NSF (Network Systems and Functional Requirements) platform, specifically addressing issues with device placement, configuration, and deployment.''\n```", "```py\n07:04:01 INFO:Page number: 113\n07:04:01 INFO:Can you answer the question or query or provide more deatils query:'Not able to manage new devices'         Using the context below\n        context:'3 \nCheck that the server and client platforms are appropriately sized. ...\nFailed SNMP communication between the server and managed device.\nSNMP traps from managed devices are arriving at one server, \nor no SNMP traps are ....\n'\n```", "```py\n07:04:08 INFO:I'll go through the steps and provide more details to answer the query.\n\nThe query is: \"Not able to manage new devices\"\n\nHere's my step-by-step analysis:\n\n**Step 1: Check that the server and client platforms are appropriately sized**\n\nThe context mentions that the NSP Planning Guide is available, which implies that the NSP (Network Service Provider) has a planning process to ensure that the server and client platforms are sized correctly. This suggests that the NSP has a process in place to evaluate the performance and capacity of the server and client platforms to determine if they are suitable for managing new devices.\n\n**Step 2: Check for resynchronization problems between the managed network and the NFM-P**\n\nThe context also mentions that resynchronization problems between the managed network and the NFM-P can cause issues with managing new devices. This implies that there may be a problem with the communication between the server and client platforms, which can prevent new devices from being successfully managed.\n\n**Step 3: Check for failed SNMP communication between the server and managed device**\n\nThe context specifically mentions that failed SNMP communication between the server and managed device can cause issues with managing new devices. This suggests that there may be a problem with the communication between the server and the managed device, which can prevent new devices from being successfully managed.\n\n**Step 4: Check for failed deployment of the configuration request**\n\nThe context also mentions that failed deployment of the configuration request can cause issues with managing new devices. This implies that there may be a problem with the deployment process, which can prevent new devices from being successfully managed.\n\n**Step 5: Perform the following steps**\n\nThe context instructs the user to perform the following steps:\n\n1\\. Choose Administration→NE Maintenance→Deployment from the XXX main menu.\n2\\. The Deployment form opens, listing incomplete deployments, deployer, tag, state, and other information.\n\nBased on the context, it appears that the user needs to review the deployment history to identify any issues that may be preventing the deployment of new devices.\n\n**Answer**\n\nBased on the analysis, the user needs to:\n\n1\\. Check that the server and client platforms are appropriately sized.\n2\\. Check for resynchronization problems between the managed network and the NFM-P.\n3\\. Check for failed SNMP communication between the server and managed device.\n4\\. Check for failed deployment of the configuration request.\n\nBy following these steps, the user should be able to identify and resolve the issues preventing the management of\n```"]