<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>How to Encode Constraints to the Output of Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>How to Encode Constraints to the Output of Neural Networks</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14">https://towardsdatascience.com/how-to-encode-constraints-to-the-output-of-neural-networks-9bce302b9687?source=collection_archive---------2-----------------------#2024-04-14</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="ea39" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A summary of available approaches</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Runzhong Wang" class="l ep by dd de cx" src="../Images/964d8ff22734d69fea6bb7256fe5d84d.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*R5cBJVzk1haFoYJ7SlSU6w.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@runzhong.wang1?source=post_page---byline--9bce302b9687--------------------------------" rel="noopener follow">Runzhong Wang</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--9bce302b9687--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">12 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Apr 14, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj mk"><img src="../Images/5e6583bd3bcbd023d68ee777d90bee66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lPZTNzabqVQc_r86"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image generated by ChatGPT based on this article’s content.</figcaption></figure><p id="af1b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Neural networks are indeed powerful. However, as the application scope of neural networks moves from “standard” classification and regression tasks to more complex decision-making and AI for Science, one drawback is becoming increasingly apparent: the output of neural networks is usually unconstrained, or more precisely, constrained only by simple 0–1 bounds (Sigmoid activation function), non-negative constraints (ReLU activation function), or constraints that sum to one (Softmax activation function). These “standard” activation layers have been used to handle classification and regression problems and have witnessed the vigorous development of deep learning. However, as neural networks started to be widely used for decision-making, optimization solving, and other complex scientific problems, these “standard” activation layers are clearly no longer sufficient. This article will briefly discuss the current methodologies available that can add constraints to the output of neural networks, with some personal insights included. Feel free to critique and discuss any related topics.</p><p id="4d5a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><a class="af nx" href="https://zhuanlan.zhihu.com/p/667124121" rel="noopener ugc nofollow" target="_blank">[中文版本(知乎)]</a></p><h1 id="7aeb" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">If one shot doesn’t work, try multiple shots</h1><p id="9722" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">If you are familiar with reinforcement learning, you may already know what I am talking about. Applying constraints to an n-dimensional vector seems difficult, but you can break an n-dimensional vector into n outputs. Each time an output is generated, you can manually write the code to restrict the action space for the next variable to ensure its value stays within a feasible domain. This so-called “autoregressive” method has obvious advantages: it is simple and can handle a rich variety of constraints (as long as you can write the code). However, its disadvantages are also clear: an n-dimensional vector requires n calls to the network’s forward computation, which is inefficient; moreover, this method usually needs to be modeled as a Markov Decision Process (MDP) and trained through reinforcement learning, so common challenges in reinforcement learning such as large action spaces, sparse reward functions, and long training times are also unavoidable.</p><p id="c4cf" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In the domain of solving combinatorial optimization problems with neural networks, the autoregressive method coupled with reinforcement learning was once mainstream, but it is currently being replaced by more efficient methods.</p><h1 id="66cc" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Perhaps… Let’s learn the constraints?</h1><p id="bed4" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">During training, a penalty term can be added to the objective function, representing the degree to which the current neural network output violates constraints. In the traditional optimization field, the Lagrangian dual method also offers a similar trick. Unfortunately, when applied to neural networks, these methods have so far only been proven on some simple constraints, and it is still unclear whether they are applicable to more complex constraints. One shortcoming is that inevitably some of the model’s capacity is used to learn how to meet corresponding constraints, thereby limiting the model’s ability in other directions (such as optimization solving).</p><p id="2bbd" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For example, <a class="af nx" href="https://proceedings.neurips.cc/paper/2020/file/49f85a9ed090b20c8bed85a5923c669f-Paper.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oz">Karalias and Loukas, NeurIPS’21 “Erdo˝s Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs”</em></a> demonstrated that the so-called “box constraints”, where variable values lie between [a, b], can be learned through a penalty term, and the network can solve some relatively simple combinatorial optimization problems. However, our further study found that this methodology lacks generalization ability. In the training set, the neural network can maintain constraints well; but in the testing set, the constraints are almost completely lost. Moreover, although adding a penalty term in principle can apply to any constraint, it cannot handle more difficult constraints. Our paper <a class="af nx" href="https://openreview.net/pdf?id=h21yJhdzbwz" rel="noopener ugc nofollow" target="_blank"><em class="oz">Wang et al, ICLR’23 “Towards One-Shot Neural Combinatorial Optimization Solvers: Theoretical and Empirical Notes on the Cardinality-Constrained Case”</em></a> discusses the above phenomena and presents the theoretical analysis.</p><p id="5325" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">On the other hand, the design philosophy of generative models, where outputs need to conform to a specific distribution, seems more suited to the “learning constraints” approach. <a class="af nx" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oz">Sun and Yang, NeurIPS’23 “DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization”</em></a> showed that Diffusion models can output solutions that meet the constraints of the Traveling Salesman Problem (i.e., can output a complete route). We further presented <a class="af nx" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/0ba520d93c3df592c83a611961314c98-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oz">Li et al, NeurIPS’23 “T2T: From Distribution Learning in Training to Gradient Search in Testing for Combinatorial Optimization”</em></a>, where the generative model (Diffusion) is responsible for meeting constraints, with another optimizer providing optimization guidance during the gradual denoising process of Diffusion. This strategy performed pretty well in experiments, surpassing all previous neural network solvers.</p><h1 id="c277" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Yet another interesting perspective: Solving a convex optimization problem</h1><p id="d47f" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Maybe you are concerned that autoregressive is too inefficient, and generative models may not solve your problem. You might be thinking about a neural network that does only one forward pass, and the output needs to meet the given constraints — is that possible?</p><p id="3d16" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The answer is yes. We can solve a convex optimization problem to project the neural network’s output into a feasible domain bounded by convex constraints. This methodology utilizes the property that a convex optimization problem is differentiable at its KKT conditions so that this projection step can be regarded as an activation layer, embeddable in an end-to-end neural network. This methodology was proposed and promoted by Zico Kolter’s group at CMU, and they currently offer the <a class="af nx" href="https://github.com/cvxgrp/cvxpylayers" rel="noopener ugc nofollow" target="_blank">cvxpylayers package</a> to ease the implementation steps. The corresponding convex optimization problem is</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="pb pc l"/></div></figure><p id="8ff2" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">where <strong class="nd fr">y</strong> is the unconstrained neural network output, <strong class="nd fr">x</strong> is the constrained neural network output. Because the purpose of this step is just a projection, a linear objective function can achieve this (adding an entropy regularizer is also reasonable). <strong class="nd fr">Ax</strong> ≤ <strong class="nd fr">b</strong> are the linear constraints you need to apply, which can also be quadratic or other convex constraints.</p><p id="d99f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">It is a personal note: there seem to be some <a class="af nx" href="https://github.com/cvxgrp/cvxpylayers/issues/147" rel="noopener ugc nofollow" target="_blank">known issues</a>, and it seems that this repository has not been updated/maintained for a long time (04/2024). I would truly appreciate it if anyone is willing to investigate what is going on.</p><h1 id="4c6d" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">For non-convex problems: Which gradient approximation do you prefer?</h1><p id="6635" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Deriving gradients using KKT conditions is theoretically sound, but it cannot tackle non-convex or non-continuous problems. In fact, for non-continuous problems, when changes in problem parameters cause solution jumps, the real gradient becomes a delta function (i.e., infinite at the jump), which obviously can’t be used in training neural networks. Fortunately, there are some gradient approximation methods that can tackle this problem.</p><p id="4e23" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The Georg Martius group at Max Planck Institute introduced a black-box approximation method <a class="af nx" href="https://openreview.net/pdf?id=BkevoJSYPB" rel="noopener ugc nofollow" target="_blank"><em class="oz">Vlastelica et al, ICLR’2020 “Differentiation of Blackbox Combinatorial Solvers”</em></a>, which views the solver as a black box. It first calls the solver once, then perturbs the problem parameters in a specific direction, and then calls the solver again. The residual between the outputs of the two solver calls serves as the approximate gradient. If this methodology is applied to the output of neural networks to enforce constraints, we can define an optimization problem with a linear objective function:</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="pb pc l"/></div></figure><p id="ca97" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">where <strong class="nd fr">y</strong> is the unconstrained neural network output, and <strong class="nd fr">x</strong> is the constrained neural network output. Your next step is to implement an algorithm to solve the above problem (not necessarily to be optimal), and then it can be integrated into the black-box approximation framework. A drawback of the black-box approximation method is that it can only handle linear objective functions, but a linear objective function just happens to work if you are looking for some methods to enforce constraints; moreover, since it is just a gradient approximation method if the hyperparameters are not well-tuned, it might encounter sparse gradients and convergence issues.</p><p id="5bd8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Another method for approximating gradients involves using a large amount of random noise perturbation, repeatedly calling the solver to estimate a gradient, as discussed in <a class="af nx" href="https://papers.nips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oz">Berthet et al, NeurIPS’2020 “Learning with Differentiable Perturbed Optimizers”</em></a>. Theoretically, the gradient obtained this way should be similar to the gradient obtained through the LinSAT method (which will be discussed in the next section), being the gradient of an entropy-regularized linear objective function; however, in practice, this method requires a large number of random samples, which is kind of impractical (at least on my use cases).</p><h1 id="4ac3" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Self-promotion time: Projection without solving optimization</h1><p id="cc8a" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Whether it’s deriving gradients from KKT conditions for convex problems or approximating gradients for non-convex methods, both require calling/writing a solver, whereby the CPU-GPU communication could be a bottleneck because most solvers are usually designed and implemented for CPUs. Is there a way to project specific constraints directly on the GPU like an activation layer, without solving optimization problems explicitly?</p><p id="6c42" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The answer is yes, and our <a class="af nx" href="https://proceedings.mlr.press/v202/wang23at/wang23at.pdf" rel="noopener ugc nofollow" target="_blank"><em class="oz">Wang et al, ICML’2023 “LinSATNet: The Positive Linear Satisfiability Neural Networks”</em></a> presents a viable path and derives the convergence property of the algorithm. LinSAT stands for <strong class="nd fr">Lin</strong>ear <strong class="nd fr">SAT</strong>isfiability Network.</p><p id="1340" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">LinSAT can be seen as an activation layer, allowing you to apply general positive linear constraints to the output of a neural network.</p><figure class="ml mm mn mo mp mq mi mj paragraph-image"><div role="button" tabindex="0" class="mr ms ed mt bh mu"><div class="mi mj pd"><img src="../Images/103e965ed6105a4a11aafc4e1a58ac6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gZ5F5g4Twa39tWDh"/></div></div><figcaption class="mw mx my mi mj mz na bf b bg z dx">Image by author</figcaption></figure><p id="a619" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The LinSAT layer is fully differentiable, and the real gradients are computed by autograd, just like other activation layers. Our implementation now supports PyTorch.</p><p id="fc9d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">You can install it by</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="6be0" class="pi nz fq pf b bg pj pk l pl pm">pip install linsatnet</span></pre><p id="b9dd" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">And get started with</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="4eb5" class="pi nz fq pf b bg pj pk l pl pm">from LinSATNet import linsat_layer</span></pre><h1 id="43e4" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">A quick example</h1><p id="a6e2" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">If you download and run the source code, you will find a simple example. In this example, we apply doubly stochastic constraints to a 3×3 matrix.</p><p id="ed9e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To run the example, first clone the repo:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="ab7d" class="pi nz fq pf b bg pj pk l pl pm">git clone https://github.com/Thinklab-SJTU/LinSATNet.git</span></pre><p id="9a6f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Go into the repo, and run the example code:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="89f2" class="pi nz fq pf b bg pj pk l pl pm">cd LinSATNet<br/>python LinSATNet/linsat.py</span></pre><p id="8352" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In this example, we try to enforce doubly-stochastic constraints to a 3×3 matrix. The doubly stochastic constraint means that all rows and columns of the matrix should sum to 1.</p><p id="3bb7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The 3x3 matrix is flattened into a vector, and the following positive linear constraints are considered (for <strong class="nd fr">Ex</strong>=<strong class="nd fr">f</strong>):</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="3731" class="pi nz fq pf b bg pj pk l pl pm">E = torch.tensor(<br/>    [[1, 1, 1, 0, 0, 0, 0, 0, 0],<br/>     [0, 0, 0, 1, 1, 1, 0, 0, 0],<br/>     [0, 0, 0, 0, 0, 0, 1, 1, 1],<br/>     [1, 0, 0, 1, 0, 0, 1, 0, 0],<br/>     [0, 1, 0, 0, 1, 0, 0, 1, 0],<br/>     [0, 0, 1, 0, 0, 1, 0, 0, 1]], dtype=torch.float32<br/>)<br/>f = torch.tensor([1, 1, 1, 1, 1, 1], dtype=torch.float32)</span></pre><p id="2ab4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We randomly init <strong class="nd fr">w</strong> and regard it as the output of some neural networks:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="1641" class="pi nz fq pf b bg pj pk l pl pm">w = torch.rand(9) # w could be the output of neural network<br/>w = w.requires_grad_(True)</span></pre><p id="75e1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We also have a “ground-truth target” for the output of linsat_layer, which is a diagonal matrix in this example:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="82c3" class="pi nz fq pf b bg pj pk l pl pm">x_gt = torch.tensor(<br/>    [1, 0, 0,<br/>     0, 1, 0,<br/>     0, 0, 1], dtype=torch.float32<br/>)</span></pre><p id="3108" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The forward/backward passes of LinSAT follow the standard PyTorch style and are readily integrated into existing deep learning pipelines.</p><p id="f079" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The forward pass:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="c1fb" class="pi nz fq pf b bg pj pk l pl pm">linsat_outp = linsat_layer(w, E=E, f=f, tau=0.1, max_iter=10, dummy_val=0)</span></pre><p id="2a1a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The backward pass:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="483e" class="pi nz fq pf b bg pj pk l pl pm">loss = ((linsat_outp — x_gt) ** 2).sum()<br/>loss.backward()</span></pre><p id="3612" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">You can also set E as a sparse matrix to improve the time &amp; memory efficiency (especially for large-sized input). Here is a dumb example (consider to construct E in sparse for the best efficiency):</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="1d54" class="pi nz fq pf b bg pj pk l pl pm">linsat_outp = linsat_layer(w, E=E.to_sparse(), f=f, tau=0.1, max_iter=10, dummy_val=0)</span></pre><p id="79d4" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We can also do gradient-based optimization over w to make the output of linsat_layer closer to x_gt. This is what happens when you train a<br/>neural network.</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="f627" class="pi nz fq pf b bg pj pk l pl pm">niters = 10<br/>opt = torch.optim.SGD([w], lr=0.1, momentum=0.9)<br/>for i in range(niters):<br/> x = linsat_layer(w, E=E, f=f, tau=0.1, max_iter=10, dummy_val=0)<br/> cv = torch.matmul(E, x.t()).t() — f.unsqueeze(0)<br/> loss = ((x — x_gt) ** 2).sum()<br/> loss.backward()<br/> opt.step()<br/> opt.zero_grad()<br/> print(f’{i}/{niters}\n’<br/> f’ underlying obj={torch.sum(w * x)},\n’<br/> f’ loss={loss},\n’<br/> f’ sum(constraint violation)={torch.sum(cv[cv &gt; 0])},\n’<br/> f’ x={x},\n’<br/> f’ constraint violation={cv}’)</span></pre><p id="131f" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">And you are likely to see the loss decreasing during the training steps.</p><p id="21d5" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">For full API references, please check out <a class="af nx" href="https://github.com/Thinklab-SJTU/LinSATNet?tab=readme-ov-file#api-reference" rel="noopener ugc nofollow" target="_blank">the GitHub repository</a>.</p><h1 id="6344" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">How does LinSAT work?</h1><p id="0a09" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Warning, tons of math ahead! You can safely skip this part if you are just using LinSAT.</p><blockquote class="pn po pp"><p id="d36e" class="nb nc oz nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">If you want to learn more details and proofs, please refer to <a class="af nx" href="https://proceedings.mlr.press/v202/wang23at/wang23at.pdf" rel="noopener ugc nofollow" target="_blank">the main paper</a>.</p></blockquote><p id="8da7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Here we introduce the mechanism inside LinSAT. It works by extending the Sinkhorn algorithm to multiple sets of marginals (to our best knowledge, we are the first to study Sinkhorn with multi-sets of marginals). The positive linear constraints are then enforced by transforming the constraints into marginals.</p><h2 id="e7bb" class="pq nz fq bf oa pr ps pt od pu pv pw og nk px py pz no qa qb qc ns qd qe qf qg bk">Classic Sinkhorn with single-set marginals</h2><p id="bcab" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Let’s start with the classic Sinkhorn algorithm. Given non-negative score matrix <strong class="nd fr">S </strong>with size <em class="oz">m×n</em>, and a set of marginal distributions on rows (non-negative vector <strong class="nd fr">v </strong>with size <em class="oz">m</em>) and columns (non-negative vector <strong class="nd fr">u </strong>with size <em class="oz">n</em>), where</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="3c8b" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">the Sinkhorn algorithm outputs a normalized matrix Γ with size <em class="oz">m×n</em> and values in [0,1] so that</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="8cb8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Conceptually, Γᵢ ⱼ means the <strong class="nd fr">proportion </strong>of <em class="oz">u</em>ⱼ moved to <em class="oz">v</em>ᵢ.</p><p id="b7c9" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The algorithm steps are:</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qi pc l"/></div></figure><blockquote class="pn po pp"><p id="c3cf" class="nb nc oz nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Note that the above formulation is modified from the conventional Sinkhorn formulation. Γᵢ ⱼ uⱼ is equivalent to the elements in the “transport” matrix in papers such as <a class="af nx" href="https://arxiv.org/pdf/1306.0895v1.pdf" rel="noopener ugc nofollow" target="_blank">(Cuturi 2013</a>). We prefer this new formulation as it generalizes smoothly to Sinkhorn with multi-set marginals in the following.</p><p id="cf1b" class="nb nc oz nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">To make a clearer comparison, the transportation matrix in <a class="af nx" href="https://arxiv.org/pdf/1306.0895v1.pdf" rel="noopener ugc nofollow" target="_blank">(Cuturi 2013)</a> is <strong class="nd fr">P </strong>with size m×n, and the constraints are</p></blockquote><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><blockquote class="pn po pp"><p id="ed3c" class="nb nc oz nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Pᵢ ⱼ means the <strong class="nd fr">exact mass</strong> moved from uⱼ to vᵢ.</p><p id="6b86" class="nb nc oz nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The algorithm steps are:</p></blockquote><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qj pc l"/></div></figure><h2 id="73f6" class="pq nz fq bf oa pr ps pt od pu pv pw og nk px py pz no qa qb qc ns qd qe qf qg bk">Extended Sinkhorn with multi-set marginals</h2><p id="d675" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">We discover that the Sinkhorn algorithm can generalize to multiple sets of marginals. Recall that Γᵢ ⱼ ∈ [0,1] means the proportion of <em class="oz">u</em>ⱼ moved to <em class="oz">v</em>ᵢ. Interestingly, it yields the same formulation if we simply replace <strong class="nd fr">u</strong>, <strong class="nd fr">v</strong> with another set of marginal distributions, suggesting the potential of extending the Sinkhorn algorithm to multiple sets of marginal distributions. Denote that there are <em class="oz">k</em> sets of marginal distributions that are jointly enforced to fit more complicated real-world scenarios. The sets of marginal distributions are</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="3555" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">and we have:</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="7f46" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">It assumes the existence of a normalized <strong class="nd fr">Z</strong> ∈ [0,1] with size <em class="oz">m×n</em>, s.t.</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="217d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">i.e., the multiple sets of marginal distributions have a non-empty feasible region (you may understand the meaning of “non-empty feasible region” after reading the next section about how to handle positive linear constraints). Multiple sets of marginal distributions could be jointly enforced by traversing the Sinkhorn iterations over <em class="oz">k</em> sets of marginal distributions. The algorithm steps are:</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qk pc l"/></div></figure><p id="1fe8" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In <a class="af nx" href="https://proceedings.mlr.press/v202/wang23at/wang23at.pdf" rel="noopener ugc nofollow" target="_blank">our paper</a>, we prove that the Sinkhorn algorithm for multi-set marginals shares the same convergence pattern with the classic Sinkhorn, and its underlying formulation is also similar to the classic Sinkhorn.</p><h2 id="002a" class="pq nz fq bf oa pr ps pt od pu pv pw og nk px py pz no qa qb qc ns qd qe qf qg bk">Transforming positive linear constraints into marginals</h2><p id="3abb" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Then we show how to transform the positive linear constraints into marginals, which are handled by our proposed multi-set Sinkhorn.</p><p id="7e51" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">Encoding neural network’s output<br/></strong>For an <em class="oz">l</em>-length vector denoted as <strong class="nd fr">y</strong> (which can be the output of a neural network, also it is the input to <strong class="nd fr">linsat_layer</strong>), the following matrix is built</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="ql pc l"/></div></figure><p id="119a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">where <strong class="nd fr">W</strong> is of size 2 × (<em class="oz">l </em>+ 1), and β is the dummy variable, the default is β = 0. <strong class="nd fr">y</strong> is put at the upper-left region of <strong class="nd fr">W</strong>. The entropic regularizer is then enforced to control discreteness and handle potential negative inputs:</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="ebe1" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The score matrix <strong class="nd fr">S</strong> is taken as the input of Sinkhorn for multi-set marginals.</p><p id="7411" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">From linear constraints to marginals</strong></p><p id="d76d" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">1) Packing constraint</strong> <strong class="nd fr">Ax</strong> ≤ <strong class="nd fr">b</strong>. Assuming that there is only one constraint, we rewrite the constraint as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="caff" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Following the “transportation” view of Sinkhorn, the output <strong class="nd fr">x</strong> <em class="oz">moves</em> at most <em class="oz">b</em> unit of mass from <em class="oz">a</em>₁<em class="oz">, a</em>₂<em class="oz">, …, aₗ</em>, and the dummy dimension allows the inequality by <em class="oz">moving</em> mass from the dummy dimension. It is also ensured that the sum of <strong class="nd fr">u</strong><em class="oz">ₚ</em><strong class="nd fr"> </strong>equals the sum of <strong class="nd fr">v</strong><em class="oz">ₚ</em>. The marginal distributions are defined as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="0d3a" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">2 ) Covering constraint</strong> <strong class="nd fr">Cx </strong>≥ <strong class="nd fr">d</strong>. Assuming that there is only one constraint, we rewrite the constraint as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="b7f7" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We introduce the multiplier</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qm pc l"/></div></figure><p id="9b49" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">because we always have</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="6f46" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">(else the constraint is infeasible), and we cannot reach a feasible solution where all elements in <strong class="nd fr">x</strong> are 1s without this multiplier. Our formulation ensures that at least <em class="oz">d</em> unit of mass is <em class="oz">moved</em> from c₁<em class="oz">, c</em>₂<em class="oz">, …, cₗ </em>by <strong class="nd fr">x</strong>, thus representing the covering constraint of “greater than”. It is also ensured that the sum of <strong class="nd fr">u_</strong>c equals the sum of <strong class="nd fr">v</strong>_c. The marginal distributions are defined as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="e8df" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><strong class="nd fr">3) Equality constraint</strong> <strong class="nd fr">Ex </strong>= <strong class="nd fr">f</strong>. Representing the equality constraint is more straightforward. Assuming that there is only one constraint, we rewrite the constraint as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="a452" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The output <strong class="nd fr">x</strong> <em class="oz">moves</em> e₁<em class="oz">, e</em>₂<em class="oz">, …, eₗ</em> to <em class="oz">f</em>, and we need no dummy element in <strong class="nd fr">u</strong>ₑ because it is an equality constraint. It is also ensured that the sum of <strong class="nd fr">u</strong>ₑ equals the sum of <strong class="nd fr">v</strong>ₑ. The marginal distributions are defined as</p><figure class="ml mm mn mo mp mq"><div class="pa io l ed"><div class="qh pc l"/></div></figure><p id="6416" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">After encoding all constraints and stacking them as multiple sets of marginals, we can call the Sinkhorn algorithm for multi-set marginals to encode the constraints.</p><h2 id="ae30" class="pq nz fq bf oa pr ps pt od pu pv pw og nk px py pz no qa qb qc ns qd qe qf qg bk">Experimental Validation of LinSAT</h2><p id="16e4" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">In our ICML paper, we validated the LinSATNet method for routing constraints beyond the general case (used for solving variants of the Traveling Salesman Problem), partial graph matching constraints (used in graph matching where only subsets of graphs match each other), and general linear constraints (used in specific preference with portfolio optimization). All these problems can be represented with positive linear constraints and handled using the LinSATNet method. In experiments, neural networks are capable of learning how to solve all three problems.</p><p id="3a49" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">It should be noted that the LinSATNet method can only handle <strong class="nd fr">positive linear constraints</strong>, meaning that it is unable to handle constraints like <em class="oz">x</em>₁ — <em class="oz">x</em>₂ ≤ 0 which contain negative terms. However, positive linear constraints already cover a vast array of scenarios. For each specific problem, the mathematical modeling is often not unique, and in many cases, a reasonable positive linear formulation could be found. In addition to the examples mentioned above, let the network output organic molecules (represented as graphs, ignoring hydrogen atoms, considering only the skeleton) can consider constraints such as C atoms having no more than 4 bonds, O atoms having no more than 2 bonds.</p><h1 id="be57" class="ny nz fq bf oa ob oc gq od oe of gt og oh oi oj ok ol om on oo op oq or os ot bk">Afterword</h1><p id="d4d0" class="pw-post-body-paragraph nb nc fq nd b go ou nf ng gr ov ni nj nk ow nm nn no ox nq nr ns oy nu nv nw fj bk">Adding constraints to neural networks has a wide range of application scenarios, and so far, several methods are available. It’s important to note that there is no golden standard to judge their superiority over each other — the best method is usually relevant to a certain scenario.</p><p id="1f6e" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Of course, I recommend trying out LinSATNet! Anyway, it is as simple as an activation layer in your network.</p><p id="a239" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">If you found this article helpful, please feel free to cite:</p><pre class="ml mm mn mo mp pe pf pg bp ph bb bk"><span id="6dbe" class="pi nz fq pf b bg pj pk l pl pm">@inproceedings{WangICML23,<br/>  title={LinSATNet: The Positive Linear Satisfiability Neural Networks},<br/>  author={Wang, Runzhong and Zhang, Yunhao and Guo, Ziao and Chen, Tianyi and Yang, Xiaokang and Yan, Junchi},<br/>  booktitle={International Conference on Machine Learning (ICML)},<br/>  year={2023}<br/>}</span></pre><p id="3c08" class="pw-post-body-paragraph nb nc fq nd b go ne nf ng gr nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">All aforementioned content has been discussed in this paper.</p></div></div></div></div>    
</body>
</html>