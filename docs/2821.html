<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Graph Neural Networks: Fraud Detection and Protein Function Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Graph Neural Networks: Fraud Detection and Protein Function Prediction</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-neural-networks-fraud-detection-and-protein-function-prediction-08f9531c98de?source=collection_archive---------0-----------------------#2024-11-21">https://towardsdatascience.com/graph-neural-networks-fraud-detection-and-protein-function-prediction-08f9531c98de?source=collection_archive---------0-----------------------#2024-11-21</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="fc22" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">Understanding AI applications in bio for machine learning engineers</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@meghanheintz?source=post_page---byline--08f9531c98de--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Meghan Heintz" class="l ep by dd de cx" src="../Images/9eaae6d3d8168086d83ff7100329c51f.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*Tespb9SFbU5QAxy8f7bhnA.png"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--08f9531c98de--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@meghanheintz?source=post_page---byline--08f9531c98de--------------------------------" rel="noopener follow">Meghan Heintz</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--08f9531c98de--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Nov 21, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">12</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk ml"><img src="../Images/e56db49516d0f5fd8f3f3c247711da18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wtJOJhzuC9lSaaI_iOAReA.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Photo by <a class="af nc" href="https://unsplash.com/@choys_?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Conny Schneider</a> on <a class="af nc" href="https://unsplash.com/photos/a-blue-background-with-lines-and-dots-xuTJZ7uD7PI?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b42c" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">What do a network of financial transactions and a protein structure have in common? They’re both poorly modeled in Euclidean (x, y) space and require encoding complex, large, and heterogeneous graphs to truly grok.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk nz"><img src="../Images/dd117c6208688bc1d86b447bba16305d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_oDco2v2fJQdi7x_7bYkQ.jpeg"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Left: image in Euclidean Space. Right: graph in non-Euclidean space. <a class="af nc" href="https://www.sciencedirect.com/science/article/pii/S2666651021000012#bib56" rel="noopener ugc nofollow" target="_blank">From Graph neural networks: A review of methods and applications</a></figcaption></figure><p id="d4fb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Graphs are the natural way to represent relational data in financial networks and protein structures. They capture the relationships and interactions between entities, such as transactions between accounts in financial systems or bonds and spatial proximities between amino acids in proteins. However, more widely known deep learning architectures like RNNs/CNNs and Transformers fail to model graphs effectively.</p><p id="4258" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">You might ask yourself why we can’t just map these graphs into 3D space? If we were to force them into a 3D grid:</p><ul class=""><li id="8119" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oa ob oc bk">We would lose edge information, such as bond types in molecular graphs or transaction types.</li><li id="8937" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">Mapping would require padding or resizing, leading to distortions.</li><li id="e41b" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">Sparse 3D data results would result in many unused grid cells, wasting memory and processing power.</li></ul><p id="43bd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Given these limitations, <strong class="nf fr">Graph Neural Networks (GNNs)</strong> serve as a powerful alternative. In this continuation of our series on <a class="af nc" href="https://medium.com/@meghanheintz/list/understanding-ai-applications-in-bio-for-ml-engineers-7b9e9551bb7f" rel="noopener">Machine Learning for Biology applications</a>, we’ll explore how GNNs can address these challenges.</p><p id="aebb" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">As always, we’ll start with the more familiar topic of fraud detection and then learn how similar concepts are applied in biology.</p><h1 id="39ea" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Fraud Detection</h1><p id="6ec0" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">To be crystal clear, let’s first define what a graph is. We remember plotting graphs on x, y axes in grade school but what we were really doing there was <a class="af nc" href="https://en.wikipedia.org/wiki/Graph_of_a_function" rel="noopener ugc nofollow" target="_blank">graphing a function</a> where we plotted the points of f(x)=y. We when talk about a “graph” in the context of GNNs, we mean to model pairwise relations between objects where each object is a node and the relationships are edges.</p><p id="fb04" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In a financial network, the nodes are accounts and the edges are the transactions. The graph would be constructed from related party transactions (RPT) and could be enriched with attributes (e.g. time, amount, currency).</p></div></div><div class="mr"><div class="ab cb"><div class="lm pj ln pk lo pl cf pm cg pn ci bh"><div class="mm mn mo mp mq ab ke"><figure class="lb mr po pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><img src="../Images/287793aa4a3a07394fb807b1a432e099.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*K7YLQZT3aAvTfHQU.png"/></div></figure><figure class="lb mr pt pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><img src="../Images/5f4b41d38a1b7842a1cd0d66ed6792da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/0*evCtOap1zJS_ADz2.png"/></div><figcaption class="mx my mz mj mk na nb bf b bg z dx pu ed pv pw">Left: Graph of a Function (What we are NOT talking about) (2024, March 15). In <em class="px">Wikipedia</em>. <a class="af nc" href="https://en.wikipedia.org/wiki/Graph_of_a_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Graph_of_a_function</a>) Right: A graph with nodes and edges (What we are talking about) (2024, October 25). In <em class="px">Wikipedia</em>. <a class="af nc" href="https://en.wikipedia.org/wiki/Graph_theory" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Graph_theory</a></figcaption></figure></div></div></div></div><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="764e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Traditional rules-based and machine-learning methods often operate on a single transaction or entity. This limitation fails to account for how transactions are connected to the wider network. Because fraudsters often operate across multiple transactions or entities, fraud can go undetected.</p><p id="2184" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">By analyzing a graph, we can capture dependencies and patterns between direct neighbors and more distant connections. This is crucial for detecting laundering where funds are moved through multiple transactions to obscure their origin. GNNs illuminate the dense subgraphs created by laundering methods.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk py"><img src="../Images/6f0353065d78d76bb14b60891d56bfb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*334wH5tC4wAQF03UUYlAwQ.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Example of a related party transfers network from <a class="af nc" href="https://pdf.sciencedirectassets.com/280203/1-s2.0-S1877050922X00173/1-s2.0-S1877050922018956/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEN7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDmpYTBTxDWh1A1%2BpPCyckZYvi2Nibrmgp5emc9oNQXlQIhAJ3wUM5Vj4%2FCTjt6CDrkYO4ph%2FN3On8JBU5MdLhciDxyKrIFCHcQBRoMMDU5MDAzNTQ2ODY1IgwTobTDUoeog6MueskqjwWI8o3mdlZLaJ5z1t5V%2F%2B2ZcfGjr%2FscaRbGl9jWKT%2ByXW2xAxqvWqFTJpVl4l3Zzv7ACPsxVY8RClj6FOe7W32hm5NTaqQq%2BRi42f55tM3hmwQT4WWOPa06zyEiCwBMgRnAX7SWeTpNRBegsGlNvTLa6dPoziPWOzu7HMv3%2Bt%2BrG7o9fPHaP8dBVFlbXorIPwTeicPh3HnCYHMLaKSVMtR76ZjtOwMzzbUfpzPgXzzjMDuEP5UgNsktqQ4lMwj4Z1iuuYVWxaFIlAElm4n17b%2B0uVprUzf7268iDXWTFGZebUYm6YJt%2Fa6y2ycY7gWo4XUnmrN4GHkCLoQNiIcvMhwRtlF6eqib6Eo5JvJRMe1OmQEIdU%2BQq62WYOl3x3Dt1ibe7aQUfVxwrymXUt7HjuVe%2BfKfSbvtRL%2Fd21kgBcA%2F4RnP2Iqv5Tg2NMCXInCJ7EIaw2y1s2ZSPSPKSRt2rcX0YMFHP1vyXDcxONU6Gybp%2B%2B1fRkoXY6AkqfoC5QwVDS68aRYg3S%2FhdaW6zIWGY2vjOc35f3TEPu1mx1nMrdMMrn2ZHtBvdR6hNZG1MkkqbsCJvpqxSivlNR6LFTqQ5C4Wy419YLpv%2Fy%2F26B%2Ftxz8LEbHY9pTd%2BZ7YEKCGXfRs8e0Ju4ALcznreLzJh7mwh85gxkP5US%2Fa1FsbTvZxe5deLjmjBLX%2Fq2wEbOVJDusY8LYkLek%2Fd6kfEu35E1QNCIjKR3YCd7yBlgHZoOSuiVARMeGt4kGdwSMHGU6uuBufZNvCn0diYOxxnywJ45HnEwRzc9IoDildTvj7LBh6jC%2FfIo0OBXwoZkt5m9YkBcWuzNojkOaZSchchqmikcDQLGT05BfDZ4wWKQC5GFawAQGmMNex8rkGOrABqtUDkTpujnzOcs0IpHrAGx01hFPOfDBp6S%2Bq%2B3lmBEG1yhXPDJSebGsHBTYf09fOj9ql6UQGhEaYi%2BkOVzLnFmpmjoNsuw4PgSyVqevV5zGVxVeDqGVbdhQFUqJPXqRRb%2BXmjH%2FYbvxD0o9bfP1HERYS2li2CrE%2BIP5V4DwdVonFuZEfkgzwDNx97GrQI42i44ar2YRIqOO%2FXHFSRifLMpdfgV%2Fq85YvDuYIFOLHOHI%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20241119T144009Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTY4UDBK2ZU%2F20241119%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=42b1ff3fe7f83791b38aa18964428551a53184eaa2759a0389ab51df9d3828fa&amp;hash=728fa1835f0699e9951cc0c2fbe4fb313cffe2740de875b7e60e68a2770188dc&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S1877050922018956&amp;tid=spdf-19095051-fc91-4c7a-ab21-c03e79c4a978&amp;sid=2594d8d573f9514c458af0a5cdffe931090bgxrqa&amp;type=client&amp;tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&amp;ua=10145d00525003565d03&amp;rr=8e50f42a1a8d7d00&amp;cc=us" rel="noopener ugc nofollow" target="_blank">Using GNN to detect financial fraud based on the related party transactions network</a></figcaption></figure><h2 id="69f5" class="pz oj fq bf ok qa qb qc on qd qe qf oq nm qg qh qi nq qj qk ql nu qm qn qo qp bk">Message-passing frameworks</h2><p id="767a" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">Like other deep learning methods, the goal is to create a representation or embedding from the dataset. In GNNs, these node embeddings are created using a message-passing framework. Messages pass between nodes iteratively, enabling the model to learn both the local and global structure of the graph. Each node embedding is updated based on the aggregation of its neighbors’ features.</p><p id="7ebd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">A generalization of the framework works as follows:</p><ul class=""><li id="1005" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oa ob oc bk"><strong class="nf fr">Initialization</strong>: Embeddings <em class="qq">hv(0)</em> are initialized with feature-based embeddings about the node, random embeddings, or pre-trained embeddings (e.g. the account name’s word embedding).</li><li id="6014" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Message Passing: </strong>At each layer <em class="qq">t</em>, nodes exchange messages with their neighbors. Messages are defined as features of the sender node, features of the recipient node, and features of the edge connecting them combined in a function. The combining function can be a simple concatenation with a fixed-weight scheme (used by <a class="af nc" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank">Graph Convolutional Networks</a>, GCNs) or attention-weighted, where weights are learned based on the features of the sender and recipient (and optionally edge features) (used by <a class="af nc" href="https://arxiv.org/abs/1710.10903" rel="noopener ugc nofollow" target="_blank">Graph Attention Networks</a>, GATs).</li><li id="a8ab" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Aggregation: </strong>After the message passing step, each node aggregates the received messages (as simple as mean, max, sum).</li><li id="491e" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Update: </strong>The aggregated messages then update the node’s embedding through an update function (potentially MLPs (Multi-Layer Perceptrons) like ReLU, GRUs (Gated Recurrent Units), or attention mechanisms).</li><li id="3569" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Finalization: </strong>Embeddings are finalized, like other deep learning methods, when the representations stabilize or a maximum number of iterations is reached.</li></ul><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qr"><img src="../Images/5eaee950880ff032dce1a690a4e6ecb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*maSXDLOBMWhiELSs.png"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">Node representation update in a Message Passing Neural Network (MPNN) layer. Node receives messages sent by all of its immediate neighbours to . Messages are computing via the message function , which accounts for the features of both senders and receiver. Graph neural network. (2024, November 14). In <em class="px">Wikipedia</em>. <a class="af nc" href="https://en.wikipedia.org/wiki/Graph_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Graph_neural_network</a></figcaption></figure><p id="c7c0" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">After the node embeddings are learned, a fraud score can be calculated in a few different ways:</p><ul class=""><li id="86c8" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oa ob oc bk"><strong class="nf fr">Classification:</strong> where the final embedding is passed into a classifier like a Multi-Layer Perceptron, which requires a comprehensive labeled historical training set.</li><li id="8184" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Anomaly Detection: </strong>where the embedding is classified as anomalous based on how distinct it is from the others. Distance-based scores or reconstruction errors can be used here for an unsupervised approach.</li><li id="9de5" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Graph-Level Scoring: </strong>where embeddings are pooled into subgraphs and then fed into classifiers to detect fraud rings. (again requiring a label historical dataset)</li><li id="5e88" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk"><strong class="nf fr">Label Propagation: </strong>A semi-supervised approach where label information propagates based on edge weights or graph connectivity making predictions for unlabeled nodes.</li></ul><p id="63ab" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Now that we have a foundational understanding of GNNs for a familiar problem, we can turn to another application of GNNs: predicting the functions of proteins.</p><h1 id="809b" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Protein Function Prediction</h1><p id="8ddf" class="pw-post-body-paragraph nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny fj bk">We’ve seen huge advances in protein folding prediction via AlphaFold <a class="af nc" href="https://medium.com/towards-data-science/alphafold-2-through-the-context-of-bert-78c9494e99af" rel="noopener">2</a> and <a class="af nc" href="https://medium.com/towards-data-science/how-alphafold-3-is-like-dalle-2-and-other-learnings-1f809010afc7" rel="noopener">3</a> and protein design via <a class="af nc" href="https://www.nature.com/articles/s41586-023-06415-8" rel="noopener ugc nofollow" target="_blank">RFDiffusion</a>. However, protein function prediction remains challenging. Function prediction is vital for many reasons but is particularly important in biosecurity to predict if DNA will be parthenogenic before sequencing. Tradional methods like <a class="af nc" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-6-272" rel="noopener ugc nofollow" target="_blank">BLAST</a> rely on sequence similarity searching and do not incoperate any structural data.</p><p id="594e" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Today, GNNs are beginning to make meaningful progress in this area by leveraging graph representations of proteins to model relationships between residues and their interactions. There are considered to be well-suited for protein function prediction as well as, identifying binding sites for small molecules or other proteins and classifying enzyme families based on active site geometry.</p><p id="d1cd" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In many examples:</p><ul class=""><li id="6a3a" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oa ob oc bk">nodes are modeled as amino acid residues</li><li id="ff9a" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">edges as the interactions between them</li></ul><p id="1c3d" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The rational behind this approach is a graph’s inherent ability to capture long-range interactions between residues that are distant in the sequence but close in the folded structure. This is similar to why transformer archicture was so helpful for AlphaFold 2, which allowed for parallelized computation across all pairs in a sequence.</p><p id="c4bc" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">To make the graph information-dense, each node can be enriched with features like residue type, chemical properties, or evolutionary conservation scores. Edges can optionally be enriched with attributes like the type of chemical bonds, proximity in 3D space, and electrostatic or hydrophobic interactions.</p><p id="6f38" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk"><a class="af nc" href="https://github.com/flatironinstitute/DeepFRI/tree/master" rel="noopener ugc nofollow" target="_blank">DeepFRI</a> is a GNN approach for predicting protein functions from structure (specifically a Graph Convolutional Network (GCN)). A GCN is a specific type of GNN that extends the idea of convolution (used in CNNs) to graph data.</p><figure class="mm mn mo mp mq mr mj mk paragraph-image"><div role="button" tabindex="0" class="ms mt ed mu bh mv"><div class="mj mk qs"><img src="../Images/ff53ff24633563fda818cf9677712867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lfaTUrYFVVY7HShk"/></div></div><figcaption class="mx my mz mj mk na nb bf b bg z dx">DeepFRI Diagram: LSTM language model, pretrained on ~2 million Pfam protein sequences, used for extracting residue level features of PDB sequence. (B) GCN with 3 graph convolutional layers for learning complex structure–to–function relationships. from <a class="af nc" href="https://www.biorxiv.org/content/10.1101/786236v1" rel="noopener ugc nofollow" target="_blank">Structure-Based Function Prediction using Graph Convolutional Networks</a></figcaption></figure><p id="a35b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">In DeepFRI, each amino acid residue is a node enriched by attributes such as:</p><ul class=""><li id="c4d4" class="nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny oa ob oc bk">the amino acid type</li><li id="592e" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">physicochemical properties</li><li id="701a" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">evolutionary information from the <a class="af nc" href="https://en.wikipedia.org/wiki/Multiple_sequence_alignment" rel="noopener ugc nofollow" target="_blank">MSA</a></li><li id="e366" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">sequence embeddings from a pretrained LSTM</li><li id="f525" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">structural context such as the solvent accessibility.</li></ul><p id="bac7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Each edge is defined to capture spatial relationships between amino acid residues in the protein structure. An edge exists between two nodes (residues) if their distance is below a certain threshold, typically 10 Å. In this application, there are no attributes to the edges, which serve as unweighted connections.</p><p id="bd3b" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The graph is initialized with node features LSTM-generated sequence embeddings along with the residue-specific features and edge information created from a residue contact map.</p><p id="a081" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Once the graph is defined, message passing occurs through adjacency-based convolutions at each of the three layers. Node features are aggregated from neighbors using the graph’s adjacency matrix. Stacking multiple GCN layers allows embeddings to capture information from increasingly larger neighborhoods, starting with direct neighbors and extending to neighbors of neighbors etc.</p><p id="cd25" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">The final node embeddings are globally pooled to create a protein-level embedding, which is then used to classify proteins into hierarchically related functional classes (GO terms). Classification is performed by passing the protein-level embeddings through fully connected layers (dense layers) with sigmoid activation functions, optimized using a binary cross-entropy loss function. The classification model is trained on data derived from protein structures (e.g., from the Protein Data Bank) and functional annotations from databases like UniProt or Gene Ontology.</p><h1 id="c102" class="oi oj fq bf ok ol om gq on oo op gt oq or os ot ou ov ow ox oy oz pa pb pc pd bk">Final Thoughts</h1><ul class=""><li id="c1b2" class="nd ne fq nf b go pe nh ni gr pf nk nl nm pg no np nq ph ns nt nu pi nw nx ny oa ob oc bk">Graphs are useful for modeling many non-linear systems.</li><li id="21de" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">GNNs capture relationships and patterns that traditional methods struggle to model by incorporating both local and global information.</li><li id="c846" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">There are many variations to GNNs but the most important (currently) are Graph Convolutional Networks and Graph Attention Networks.</li><li id="d872" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">GNNs can be efficient and effective at identifying the multi-hop relationships present in money laundering schemes using supervised and unsupervised methods.</li><li id="145d" class="nd ne fq nf b go od nh ni gr oe nk nl nm of no np nq og ns nt nu oh nw nx ny oa ob oc bk">GNNs can improve on sequence only based protein function prediction tools like BLAST by incorporating structural data. This enables researchers to predict the functions of new proteins with minimal sequence similarity to known ones, a critical step in understanding biosecurity threats and enabling drug discovery.</li></ul><p id="abe7" class="pw-post-body-paragraph nd ne fq nf b go ng nh ni gr nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny fj bk">Cheers and if you liked this post, check out my other articles on <a class="af nc" href="https://medium.com/@meghanheintz/list/understanding-ai-applications-in-bio-for-ml-engineers-7b9e9551bb7f" rel="noopener">Machine Learning and Biology.</a></p></div></div></div></div>    
</body>
</html>