<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Why You Should Not Use Numeric Evals For LLM As a Judge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Why You Should Not Use Numeric Evals For LLM As a Judge</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-you-should-not-use-numeric-evals-for-llm-as-a-judge-bf22424f5379?source=collection_archive---------7-----------------------#2024-03-08">https://towardsdatascience.com/why-you-should-not-use-numeric-evals-for-llm-as-a-judge-bf22424f5379?source=collection_archive---------7-----------------------#2024-03-08</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><figure class="fr fs ft fu fv fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp fq"><img src="../Images/79a5cc98acefd1df47dd89312b5b7ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VGA4e2PfcZdA8SdLs_AfDg.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Image created by author using Dall-E 3</figcaption></figure><div/><div><h2 id="e4a0" class="pw-subtitle-paragraph hh gj gk bf b hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw cq dx">Testing major LLMs on how well they conduct numeric evaluations</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hx hy hz ia ib ab"><div><div class="ab ic"><div><div class="bm" aria-hidden="false"><a href="https://aparnadhinak.medium.com/?source=post_page---byline--bf22424f5379--------------------------------" rel="noopener follow"><div class="l id ie by if ig"><div class="l ed"><img alt="Aparna Dhinakaran" class="l ep by dd de cx" src="../Images/e431ee69563ecb27c86f3428ba53574c.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*VbKXdndNnweCZQQa2TohWw.png"/><div class="ih by l dd de em n ii eo"/></div></div></a></div></div><div class="ij ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--bf22424f5379--------------------------------" rel="noopener follow"><div class="l ik il by if im"><div class="l ed"><img alt="Towards Data Science" class="l ep by br in cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="ih by l br in em n ii eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="io ab q"><div class="ab q ip"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b iq ir bk"><a class="af ag ah ai aj ak al am an ao ap aq ar is" data-testid="authorName" href="https://aparnadhinak.medium.com/?source=post_page---byline--bf22424f5379--------------------------------" rel="noopener follow">Aparna Dhinakaran</a></p></div></div></div><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b iq ir dx"><button class="iv iw ah ai aj ak al am an ao ap aq ar ix iy iz" disabled="">Follow</button></p></div></div></span></div></div><div class="l ja"><span class="bf b bg z dx"><div class="ab cn jb jc jd"><div class="je jf ab"><div class="bf b bg z dx ab jg"><span class="jh l ja">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar is ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--bf22424f5379--------------------------------" rel="noopener follow"><p class="bf b bg z ji jj jk jl jm jn jo jp bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="it iu" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="jq jr l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Mar 8, 2024</span></div></span></div></span></div></div></div><div class="ab cp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh"><div class="h k w ea eb q"><div class="kx l"><div class="ab q ky kz"><div class="pw-multi-vote-icon ed jh la lb lc"><div class=""><div class="ld le lf lg lh li lj am lk ll lm lc"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l ln lo lp lq lr ls lt"><p class="bf b dy z dx"><span class="le">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao ld lu lv ab q ee lw lx" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="ly"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q ki kj kk kl km kn ko kp kq kr ks kt ku kv kw"><div class="lz k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al ma an ao ap ix mb mc md" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep me cn"><div class="l ae"><div class="ab cb"><div class="mf mg mh mi mj gb ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al ma an ao ap ix mk ml lx mm mn mo mp mq s mr ms mt mu mv mw mx u my mz na"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="a3e7" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In addition to generating text for a growing number of industry applications, LLMs are now widely <a class="af nx" href="https://medium.com/towards-data-science/llm-evals-setup-and-the-metrics-that-matter-2cc27e8e35f3" rel="noopener">being used</a> as evaluation tools. Models quantify the relevance of retrieved documents in retrieval systems, gauge the sentiment of comments and posts, and more — evaluating both human and AI-generated text. These evaluations are often either numeric or categorical.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp ny"><img src="../Images/a9e618d9c5f95f5e440d8bd9122805c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QZPVlbYdxoIrZlQzZPPytA.png"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Different types of LLM evals (diagram by author)</figcaption></figure><p id="8e7b" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Numeric evaluations involve an LLM returning a number based on a set of evaluation criteria. For example, a model might be tasked with how relevant a document is to a user query on a scale of one to ten.</p><p id="53a3" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">A categorical evaluation is different in that it allows an LLM to choose from a set of predefined, often text-based options to choose from in its evaluation. For example, a prompt might ask if a passage is “happy,” “sad,” or “neutral” rather than trying to quantify the passage’s happiness level.</p><p id="f63b" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">This piece features results from testing of several major LLMs — OpenAI’s GPT-4, Anthropic’s Claude, and Mistral AI’s Mixtral-8x7b — on how well they conduct numeric evaluations. All code run to complete these tests can be found in <a class="af nx" href="https://github.com/Arize-ai/LLMTest_NeedleInAHaystack" rel="noopener ugc nofollow" target="_blank">this GitHub repository</a>.</p><h1 id="b2b8" class="oe of gk bf og oh oi hk oj ok ol hn om on oo op oq or os ot ou ov ow ox oy oz bk">Takeaways</h1><ul class=""><li id="a127" class="nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw pf pg ph bk">Numeric score evaluations across LLMs are not consistent, and small differences in prompt templates can lead to massive discrepancies in results.</li><li id="f1bb" class="nb nc gk nd b hi pi nf ng hl pj ni nj nk pk nm nn no pl nq nr ns pm nu nv nw pf pg ph bk">Even holding all independent variables (model, prompt template, context) constant can lead to varying results across multiple rounds of testing. LLMs are not deterministic, and some are not at all consistent in their numeric judgements.</li><li id="fc02" class="nb nc gk nd b hi pi nf ng hl pj ni nj nk pk nm nn no pl nq nr ns pm nu nv nw pf pg ph bk">There are good reasons to doubt that GPT-4, Claude, or Mixtral can handle continuous ranges well enough to use them for numeric score evals for real-world use cases yet.</li></ul><h1 id="5fbf" class="oe of gk bf og oh oi hk oj ok ol hn om on oo op oq or os ot ou ov ow ox oy oz bk">Research</h1><h2 id="8740" class="pn of gk bf og po pp pq oj pr ps pt om nk pu pv pw no px py pz ns qa qb qc qd bk">Spelling Corruption Experiment</h2><p id="22b5" class="pw-post-body-paragraph nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw fj bk">The first experiment was designed to assess an LLM’s ability to assign scores between 0 and 10 to documents based on the percentage of words containing spelling errors.</p><p id="6512" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We took a passage of correctly spelled words, edited the text to include misspelled words at varying frequencies, and then fed this corrupted text to an LLM using this prompt template:</p><pre class="nz oa ob oc od qe qf qg bp qh bb bk"><span id="0aee" class="qi of gk qf b bg qj qk l ql qm">SIMPLE_TEMPLATE_SPELLING = """<br/>  You are a helpful AI bot that checks for grammatic, spelling and typing errors in a document context. <br/>  You are going to score the document based on the percent of grammatical and typing errors. The score should be between {templ_high} and {templ_low}. <br/>  A {templ_low} score will be no grammatical errors in any word, a score of {templ_20_perc} will be 20% of words have errors, a {templ_50_perc} score will be 50% errors, a score of {templ_70_perc} is 70%, and a {templ_high} will be all words in context have grammatical errors. <br/>  The following is the document context.<br/><br/>  #CONTEXT<br/>  {context}<br/>  #ENDCONTEXT<br/><br/>  #QUESTION<br/>  Please return a score between {templ_high} and {templ_low}, with a case of {templ_high} being all words have a grammatical error and {templ_low} being no words have grammatical or spelling errors. <br/>  You will return no other text or language besides the score. Only return the score.<br/>  Please</span></pre><p id="900b" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">We then asked the model to return a numeric eval corresponding to the percentage of words in the passage that were misspelled (3 → 30% misspelled, 8 → 80%, etc.). Ideally, a score of 10 would indicate that every word in a document is misspelled, while a score of 0 would mean there are no spelling errors at all. The results of the experiment across three LLMs — GPT-4, Claude, and Mixtral — were less than stellar.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div class="fo fp qn"><img src="../Images/9f13e27577980514ef037a3976255a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*oihZPiRYXyl6x9-0YJ0J9A.jpeg"/></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">GPT-4 spelling corruption results (image by author)</figcaption></figure><p id="d2bb" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Observed results were far from the expected perfect linear range; the scoring system did not consistently reflect the proportion of spelling errors in the documents. In fact, GPT-4 (above) returned 10 (which represents a 100% error rate) for every document with percent of density of corruption at or above 10%. The reported scores were the median of multiple trials conducted at each specified level of error.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qo"><img src="../Images/578fb8279f35a889e0f3a22b679431b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v_9cM43DB5UL7LP1Hpqpag.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">GPT-4, Claude, Mixtral spelling corruption results (image by author)</figcaption></figure><p id="f4b4" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The results from Claude were slightly better, but still not perfect or at a level likely acceptable for deployment. Mixtral, the smallest of these three models, performed best.</p><p id="ccfd" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">So why does this matter? Given interest in using LLMs numeric evaluators in a variety of settings, there are good reasons to believe that use LLMs in this way may run into roadblocks with performance and customer satisfaction.</p><h2 id="3f81" class="pn of gk bf og po pp pq oj pr ps pt om nk pu pv pw no px py pz ns qa qb qc qd bk">Emotional Qualifier Experiments</h2><p id="d441" class="pw-post-body-paragraph nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw fj bk">The second and third experiments conducted were designed to assess an LLM’s ability to assign scores between 0 and 10 to documents based on the amount of sentences within the text that contained words that indicated sadness or frustration.</p><p id="7118" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">In these tests we embedded phrases and words into text that imparted a sense of sadness/frustration within the passage. The model was asked to quantify how prevalent the emotion was in the text, with 1 corresponding to no sentences conveying the emotion and 10 corresponding to 100% of sentences conveying the emotion.</p><p id="2d8f" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">These experiments were conducted alongside the spelling test to determine if shifting the model’s focus from word count to sentence count would impact the results. While the spelling test scored based on the percentage of misspelled words, the sadness/frustration tests scored based on the percentage of emotional sentences.</p><p id="587e" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">The instruction at the beginning of the prompt template varied between tests while everything beginning with the context remained the same, indicated by the ellipses:</p><pre class="nz oa ob oc od qe qf qg bp qh bb bk"><span id="540a" class="qi of gk qf b bg qj qk l ql qm">SIMPLE_TEMPLATE_FRUSTRATION = """<br/>  You are a helpful AI bot that detects frustrated conversations. You are going to score the document based on the percent of sentences where the writer expresses frustration.<br/>  The score should be between {templ_high} and {templ_low}.<br/>  A {templ_low} will indicate almost no frustrated sentences, a score of {templ_20_perc} will be 20% of sentences express frustration, a {templ_50_perc} will be 50% of sentences express frustration, a score of {templ_70_perc} is 70%, and a {templ_high} score will be all the sentences express frustration. <br/><br/>...<br/>"""</span></pre><pre class="qp qe qf qg bp qh bb bk"><span id="c15e" class="qi of gk qf b bg qj qk l ql qm">SIMPLE_TEMPLATE_SADNESS = """<br/>  You are a helpful AI bot that detects sadness and sorrow in writing. You are going to score the document based on the percent of sentences where the writer expresses sadness or sorrow.<br/>  The score should be between {templ_high} and {templ_low}.<br/>  A {templ_low} will indicate almost no sentences that have sadness or sorrow, a score of {templ_20_perc} will be 20% of sentences express sadness or sorrow, a {templ_50_perc} will be 50% of sentences express sadness or sorrow, a score of {templ_70_perc} is 70%, and a {templ_high} score will be all the sentences express sadness or sorrow.<br/><br/>...<br/>"""</span></pre><p id="7dac" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Again, a score of 10 should indicate that every sentence in a document contains sadness or frustration qualifiers, while a score of 0 would mean there are none present. Scores in between correspond to varying degrees of the emotion frequency, with higher scores representing a greater proportion of emotional sentences.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qo"><img src="../Images/3117570eea0e8dd1adbc502217d4db51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Fh1U7U8pDJXmL9qz0AHcQ.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">GPT-4 spelling corruption, sadness, frustration results (image by author)</figcaption></figure><p id="a8bd" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Similar to the spelling corruption experiment, results show a significant discrepancy from the expected outcomes. GPT-4 gives every document with sadness rates above 30% or frustration rates about 70% a score of 10. Remarkably, out of all of the tests run with GPT-4, the only times the median answer satisfies a perfect linear range is when there are no qualifiers or misspelled words present at all.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qo"><img src="../Images/a7aba63433568febddfbb121e92e9071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P77miMmkFJA_7qUzHa-_dQ.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Mixtral spelling corruption, sadness, frustration results (image by author)</figcaption></figure><p id="1d9e" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><a class="af nx" href="https://arize.com/blog/mistral-ai" rel="noopener ugc nofollow" target="_blank">Mixtral AI</a> performs relatively well across the emotional qualifier experiments. While there are good reasons to doubt that these models currently handle continuous ranges well enough to use them for numeric score evals, Mixtral is the closest to accomplishing that feat.</p><p id="e62a" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Based on these results, we do not recommend score evals in production code.</p><h2 id="dc07" class="pn of gk bf og po pp pq oj pr ps pt om nk pu pv pw no px py pz ns qa qb qc qd bk">Variance in Results</h2><p id="7524" class="pw-post-body-paragraph nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw fj bk">It is worth noting that we ran these tests several times for each model and charted the distribution of their responses.</p><figure class="nz oa ob oc od fw fo fp paragraph-image"><div role="button" tabindex="0" class="fx fy ed fz bh ga"><div class="fo fp qo"><img src="../Images/6c52ad659be803faba9ee3b4621a7ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFIm3wpJfHgmlhxtcJEqfQ.jpeg"/></div></div><figcaption class="gd ge gf fo fp gg gh bf b bg z dx">Comparison of evaluation results across many tests with a 1 to 10 range (image by author)</figcaption></figure><p id="80c1" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">An ideal distribution would be tight around the low and high ends (high confidence if all or none of the words/sentences were counted) and perhaps a longer transition region in the middle (e.g. lower confidence differentiating between 4 and 5).</p><p id="ef13" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Two things stand out here. First, the tightness of distributions is quite different across models and tasks. Claude’s distributions range considerably over our trials; we have examples of the model consistently assigning 1–4 at 80% corruption, for example. On the other hand, GPT-4 has much tighter distributions — albeit at values that for the most part did not satisfy reasonable expectations.</p><p id="5e59" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Second, some models are better at handling transitions in continuous ranges than others. Mixtral’s distributions look like they are getting close to where an acceptable performance might be, but all three models seem to have a ways to go before they are ready for production.</p><h1 id="7d1a" class="oe of gk bf og oh oi hk oj ok ol hn om on oo op oq or os ot ou ov ow ox oy oz bk">Implications for LLM Evals</h1><p id="1287" class="pw-post-body-paragraph nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw fj bk">There is currently a lot of research currently being done on <a class="af nx" href="https://arize.com/blog-course/llm-evaluation-the-definitive-guide/" rel="noopener ugc nofollow" target="_blank">LLM evaluations</a>. Microsoft’s GPT Estimation Metric Based Assessment (<a class="af nx" href="https://arxiv.org/pdf/2302.14520.pdf" rel="noopener ugc nofollow" target="_blank">GEMBA</a>), for example, examines the ability of different large language models to evaluate the quality of different translation segments. While some research papers use probabilities and numeric scores as part of evaluation output — with GEMBA and others even reporting promising results — the way we see customers applying score evals in the real world is often much different from current research.</p><p id="2198" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">With that in mind, we attempted to tailor our research to these more practical, real-word applications — and the results highlight why the use of scores directly for decisions can be problematic. Considering GPT-4’s responses in our score evals research, it seems as though the model wants to choose one of two options: 1 or 10, all or nothing.</p><p id="7399" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk">Ultimately, categorical evaluation (either binary or multi-class) likely has a lot of promise and it will be interesting to watch this space.</p><h1 id="bf9f" class="oe of gk bf og oh oi hk oj ok ol hn om on oo op oq or os ot ou ov ow ox oy oz bk">Conclusion</h1><p id="cca0" class="pw-post-body-paragraph nb nc gk nd b hi pa nf ng hl pb ni nj nk pc nm nn no pd nq nr ns pe nu nv nw fj bk">Using LLMs to conduct numeric evals is finicky and unreliable. Switching between models and making small changes in prompt templates can lead to vastly different results, making it hard to endorse LLMs as consistently reliable arbiters of numeric evaluation criteria. Furthermore, large distributions of results across continued testing showcase that these models are often not consistent in their responses, even when independent variables remain unchanged. Readers building with LLM evals would be wise to avoid using numeric evaluations in the manner outlined in <a class="af nx" href="https://arize.com/blog-course/numeric-evals-for-llm-as-a-judge/" rel="noopener ugc nofollow" target="_blank">this piece</a>.</p><p id="4299" class="pw-post-body-paragraph nb nc gk nd b hi ne nf ng hl nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw fj bk"><em class="qq">Questions? Please feel free to reach out on </em><a class="af nx" href="https://twitter.com/aparnadhinak" rel="noopener ugc nofollow" target="_blank"><em class="qq">X</em></a><em class="qq">, </em><a class="af nx" href="https://www.linkedin.com/in/aparnadhinakaran/" rel="noopener ugc nofollow" target="_blank"><em class="qq">LinkedIn</em></a><em class="qq">, or </em><a class="af nx" href="https://join.slack.com/t/arize-ai/shared_invite/zt-26zg4u3lw-OjUNoLvKQ2Yv53EfvxW6Kg" rel="noopener ugc nofollow" target="_blank"><em class="qq">Slack</em></a><em class="qq">!</em></p></div></div></div></div>    
</body>
</html>