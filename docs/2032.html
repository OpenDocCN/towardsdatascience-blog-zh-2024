<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Speaker’s Privacy Protection in DNN-Based Speech Processing Tools</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Speaker’s Privacy Protection in DNN-Based Speech Processing Tools</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20">https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7ac7" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A novel method in privacy-preserving speech processing which anonymizes the speaker attributes using space-filling vector quantization</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Mohammad Hassan Vali" class="l ep by dd de cx" src="../Images/b057aa7bd9e1c629fc3743a7f69f013e.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*zgkovfqgOo7DTgjZy8xoSw.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------" rel="noopener follow">Mohammad Hassan Vali</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 20, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><blockquote class="mi mj mk"><p id="920b" class="ml mm mn mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">This post is a short explanation of our proposed privacy preservation technique called Privacy-PORCUPINE [1] published at Interspeech 2024 conference. The post discusses a potential privacy threat that might happen when using ordinary vector quantization in the bottleneck of DNN-based speech processing tools. For more detail, please look at the paper under <a class="af ni" href="https://www.isca-archive.org/interspeech_2024/vali24_interspeech.pdf" rel="noopener ugc nofollow" target="_blank">this link</a>.</p></blockquote><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt ed nu bh nv"><div class="nj nk nl"><img src="../Images/7b7bc224819148110e096999c192ace4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aD1DuVD7PRr9of4U"/></div></div><figcaption class="nx ny nz nj nk oa ob bf b bg z dx">Photo by <a class="af ni" href="https://unsplash.com/@dtopkin1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Dayne Topkin</a> on <a class="af ni" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cd91" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">Speech is a convenient medium for interacting between humans and with technology, yet evidence demonstrates that it exposes speakers to threats to their privacy. A central issue is that, besides the linguistic content which may be private, speech contains also private side-information such as the speaker’s identity, age, state of health, ethnic background, gender, and emotions. Revealing such sensitive information to a listener may expose the speaker to threats such as price gouging, tracking, harassment, extortion, and identity theft. To protect speakers, privacy-preserving speech processing seeks to anonymize speech signals by stripping away private information that is not required for the downstream task [2].</p><p id="89ea" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">A common operating principle for privacy-preserving speech processing is to pass information through an information bottleneck that is tight enough to allow only the desired information pass through it and prevent transmission of any other private information. Such bottlenecks can be implemented for example as <em class="mn">autoencoders</em>, where a neural network, known as the encoder, compresses information to a bottleneck, and a second network, the decoder, reconstructs the desired output. The information rate of the bottleneck can be quantified absolutely, only if it is quantized, and quantization is thus a required component of any proof of privacy [2]. The figure below shows a vector quantized variational autoencoder (VQ-VAE) architecture, and its bottleneck.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt ed nu bh nv"><div class="nj nk oc"><img src="../Images/7d11ef396bd9ebff33a3d4294d1e5b6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8mnyo5ITi4gRHQUz8TtIw.png"/></div></div><figcaption class="nx ny nz nj nk oa ob bf b bg z dx">Figure 1: Architecture of a vector quantized variational autoencoder (VQ-VAE). (image by author)</figcaption></figure><p id="17b9" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As pointed out in the Privacy ZEBRA framework [3], we need to characterize privacy protections both in terms of average disclosure of private information (in bits) as well as worst-case disclosure (in bits). <a class="af ni" href="https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce" rel="noopener">Vector quantization</a> (VQ) [4] is a constant-bitrate quantizer in the sense that it quantizes the input with a codebook of K elements, and the indices of such a codebook can be expressed with B=log2(K) bits. This B equals to the average disclosure of private information in bits. In terms of the worst-case disclosure, it is obvious that different codebook elements are used with different frequencies (see Fig. 2.1 below). This means that a relatively smaller subset of speakers could be assigned to a particular codebook index, such that any time a speaker is assigned to that codebook index, the range of possible speakers is relatively smaller than for other codebook indices and the corresponding disclosure of private information is larger (for the speakers assigned to this particular codebook index). However, to the best of the authors’ knowledge, this disclosure has not previously been quantified nor do we have prior solutions for compensating for such an increase in disclosure. Hence, our main goal is to modify VQ such that all codebook elements have equal occurrence likelihoods to prevent private information leakage (and thus improve worst-case disclosure).</p><p id="8e7a" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As a solution, we use here our recently proposed modification of VQ known as <a class="af ni" href="https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14" rel="noopener">space-filling vector quantization</a> (SFVQ) [5], which incorporates space-filling curves into VQ. We define the SFVQ as the linear continuation of VQ, such that subsequent codebook elements are connected with a line where inputs can be mapped to any point on that piece-wise continuous line (see Fig. 2.2). To read more about SFVQ, please see <a class="af ni" href="https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14" rel="noopener">this post</a>.</p><p id="da42" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">In our technique, named Privacy PORCUPINE [1], we proposed to use a codebook resampling method together with SFVQ, where a vector quantizer is resampled along the SFVQ’s curve, such that all elements of the resampled codebook have equal occurrence likelihoods (see Fig. 2.3 and 2.4).</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt ed nu bh nv"><div class="nj nk od"><img src="../Images/27c1e3136b235a773683a26aad95fab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_WqFJr20D-IFBL0A0xrtg.png"/></div></div><figcaption class="nx ny nz nj nk oa ob bf b bg z dx">Figure 2: 1. Codebook vectors (blue points) of a 5 bit vector quantization applied on a Gaussian distribution (gray points); Voronoi-regions are shown in green 2. Space-filling vector quantization (SFVQ) with 5 bit applied on the same Gaussian distribution (curve in black with codebook vectors in blue) 3. Same SFVQ curve together with the resampled codebook vectors (red crosses) 4. Same resampled codebook vectors along with their Voronoi-regions (in green). (image by author)</figcaption></figure><h2 id="3a94" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">How we measure the disclosure?</h2><p id="8794" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">Figure 2.1 demonstrates that in areas where inputs are less likely, the Voronoi-regions are larger. Hence, such larger Voronoi-regions contain a smaller number of input samples. Similarly, small Voronoi-regions have a larger number of input samples. Such differences are due to the optimization of the codebook by minimizing the mean square error (MSE) criterion; more common inputs are quantized with a smaller error to minimize the average error. Our objective is to determine how such uneven distribution of inputs to codebook entries influences the disclosure of private information.</p><p id="2074" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">We measure disclosure in terms of how much the population size of possible identities for an unknown speaker is decreased with a new observation. In other words, assume that we have prior knowledge that the speaker belongs to a population of size M. If we have an observation that the speaker is quantized to an index k, we have to evaluate how many speakers L out of M will be quantized to the same index. This decrease can be quantified by the ratio of populations L/M corresponding to the disclosure of B_leak=log2(M/L) bits of information.</p><p id="f756" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">At the extreme, it is possible that only a single speaker may be quantized to a particular index. This means that only one speaker L=1 is quantized to the bin out of an arbitrarily large M, though in practice we can verify results only for finite M. Still, in theory, if M → ∞, then also the disclosure diverges B_leak → ∞ bits. The main objective of our proposed method is to modify vector quantization to prevent such catastrophic leaks.</p><h2 id="dd7c" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Codebook Resampling</h2><p id="d16b" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">After training the space-filling vector quantizer (SFVQ) [5] on the training set comprising speaker embeddings for a population of M speakers (Fig. 2.2), we map all the M embedding vectors onto the learned curve. To normalize the occurrence frequency using K codebook vectors, each codebook element has to represent M/K speaker embeddings. In other words, each Voronoi- region should encompass M/K speaker embeddings. Considering these M mapped embeddings on SFVQ’s curve, we start from the first codebook element (one end of the curve), take the first M/K mapped embeddings, and calculate the average of these vectors. We define this average vector as the new resampled codebook vector (red crosses in Fig. 2.3) representing the first chunk of M/K speaker embeddings. Then similarly, we continue until we compute all K resampled codebook vectors for all K chunks of M/K speaker embeddings.</p><h2 id="c2af" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Experiments</h2><p id="6e00" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">In our experiments, we used <a class="af ni" href="https://commonvoice.mozilla.org/en/datasets" rel="noopener ugc nofollow" target="_blank">Common Voice corpus (version 16.1)</a> to get a large pool of speakers. We selected 10,240 speakers randomly for the test set and 79,984 speakers for the train set. To compute speaker embeddings, we used the pretrained speaker verification model of ECAPA-TDNN [6]. We trained vector quantization (VQ) and space-filling vector quantization (SFVQ) methods on the train set (of speaker embeddings) for different bitrates ranging from 4 bit to 10 bit (16 to 1024 codebook vectors).</p><p id="1503" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">As a showcase to compare VQ and resampled SFVQ, the figure below illustrates the occurrence frequencies for VQ and resampled SFVQ, both with 4 bit of information corresponding to 16 codebook vectors. By informal visual inspection we can see that entries in the proposed method are more uniformly distributed, as desired, but to confirm results we need a proper evaluation. To compare the obtained histograms from VQ and resampled SFVQ, we used different evaluation metrics which are discussed in the next section.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt ed nu bh nv"><div class="nj nk pe"><img src="../Images/43cd12afd0f2d09d9bb42b211cfb76f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysJNITwUJ7Rm8WUiaMV-vA.png"/></div></div><figcaption class="nx ny nz nj nk oa ob bf b bg z dx">Figure 3: Probability of codebook occurrences for VQ and resampled SFVQ in case of 4 bit quantization. (image by author)</figcaption></figure><h2 id="d0a3" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Evaluation Metrics</h2><p id="f9bb" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">Suppose we have K codebook vectors (bins) to quantize a population of M speakers. Our target is to achieve a uniform distribution of samples onto the K codebook vectors, U(1,K), such that every codebook vector is used M/K times. If we sample M integers from the uniform distribution of U(1,K), we will obtain the histogram h(k). Then, if we take the histogram of occurrences in the bins of h(k) (i.e. histogram of histogram), we will see that the new histogram follows a binomial distribution f(k) such that</p><figure class="nm nn no np nq nr"><div class="pf io l ed"><div class="pg ph l"/></div></figure><p id="bb07" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">where the random variable X is the occurrence in each bin, n is the number of trials (n=M), and p is the success probability for each trial which is p=1/K. After obtaining the histogram of codebook indices occurrences g(k) (Figure 3) for both VQ and resampled SFVQ methods, we compute the histogram of occurrences in the bins of g(k) denoted by f_hat(k). The binomial distribution f(k) is the theoretical optimum, to which our observation f_hat(k) should coincide. Hence, we use Kullback-Leibler (KL) divergence between f(k) and f_hat(k) to assess the distance between the observed and the ideal distributions.</p><p id="eebb" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">By having the histogram of occurrences g(k), we calculate the minimum of the histogram divided by the total number of samples (M=Σ g(k)) as the worst-case disclosure. We also compute the average disclosure as entropy of occurrence frequencies g(k)/M. In addition, we use a sparseness measure and standard deviation as heuristic measures of uniformity of the obtained histogram g(k). Here are the evaluation formulas:</p><figure class="nm nn no np nq nr"><div class="pf io l ed"><div class="pi ph l"/></div></figure><h2 id="ad10" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Results</h2><p id="038b" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">Figure 4 shows the performance of VQ and resampled SFVQ as a function of bitrate. In each case and for all bitrates, the proposed method (blue line) is below VQ (red line), indicating that the leakage of private information is smaller for the proposed method. One important point to mention is that as expected, resampled SFVQ makes the average disclosure to be slightly higher than VQ, whereas the average disclosure for both resampled SFVQ and VQ are extremely close to the upper bound of average disclosure where the histogram of occurrence frequencies is perfectly flat.</p><figure class="nm nn no np nq nr nj nk paragraph-image"><div role="button" tabindex="0" class="ns nt ed nu bh nv"><div class="nj nk pj"><img src="../Images/f2f74881c88f2ca40c545d1931dfd991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UP3UNNldI5ajRmhppnp-Aw.png"/></div></div><figcaption class="nx ny nz nj nk oa ob bf b bg z dx">Figure 4: Performance comparison between VQ and resampled SFVQ under evaluation metrics. (image by author)</figcaption></figure><h2 id="38ef" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Conclusions</h2><p id="930a" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">Privacy-preserving speech processing is becoming increasingly important as the usage of speech technology is increasing. By removing superfluous private information from a speech signal by passing it through a quantized information bottleneck, we can gain provable protections for privacy. Such protections however rely on the assumption that quantization levels are used with equal frequency. Our theoretical analysis and experiments demonstrate that vector quantization, optimized with the minimum mean square (MSE) criterion, does generally not provide such uniform occurrence frequencies. In the worst case, some speakers could be uniquely identified even if the quantizer on average provides ample protection.</p><p id="26a3" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">We proposed the resampled SFVQ method to avoid such privacy threats. The protection of privacy is thus achieved by increasing the quantization error for inputs that occur less frequently, while more common inputs gain better accuracy (see Fig. 2.4). This is in line with the theory of differential privacy [7].</p><p id="4405" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">We used speaker identification as an illustrative application, though the proposed method can be used in gaining a provable reduction of private information leakage for any attributes of speech. In summary, resampled SFVQ is a generic tool for privacy-preserving speech processing. It provides a method for quantifying the amount of information passing through an information bottleneck and thus forms the basis of speech processing methods with provable privacy.</p><h1 id="a077" class="pk of fq bf og pl pm gq ok pn po gt oo pp pq pr ps pt pu pv pw px py pz qa qb bk">GitHub Repository</h1><p id="8a1d" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">The code for implementation of our proposed method and the relevant evaluations is publicly available in the following link:</p><div class="qc qd qe qf qg qh"><a href="https://github.com/MHVali/Privacy-PORCUPINE.git?source=post_page-----f446ad1d8871--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qi ab ig"><div class="qj ab co cb qk ql"><h2 class="bf fr hw z io qm iq ir qn it iv fp bk">GitHub - MHVali/Privacy-PORCUPINE</h2><div class="qo l"><h3 class="bf b hw z io qm iq ir qn it iv dx">Contribute to MHVali/Privacy-PORCUPINE development by creating an account on GitHub.</h3></div><div class="qp l"><p class="bf b dy z io qm iq ir qn it iv dx">github.com</p></div></div><div class="qq l"><div class="qr l qs qt qu qq qv lq qh"/></div></div></a></div></div></div></div><div class="ab cb qw qx qy qz" role="separator"><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc rd"/><span class="ra by bm rb rc"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><h2 id="bf0f" class="oe of fq bf og oh oi oj ok ol om on oo mv op oq or mz os ot ou nd ov ow ox oy bk">Acknowledgement</h2><p id="2400" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">Special thanks to my doctoral program supervisor <a class="af ni" href="https://research.aalto.fi/en/persons/tom-bäckström" rel="noopener ugc nofollow" target="_blank">Prof. Tom Bäckström</a>, who supported me and was the other contributor for this work.</p><h1 id="b5c5" class="pk of fq bf og pl pm gq ok pn po gt oo pp pq pr ps pt pu pv pw px py pz qa qb bk">References</h1><p id="cc47" class="pw-post-body-paragraph ml mm fq mo b go oz mq mr gr pa mt mu mv pb mx my mz pc nb nc nd pd nf ng nh fj bk">[1] M.H. Vali, T. Bäckström, “Privacy PORCUPINE: Anonymization of Speaker Attributes Using Occurrence Normalization for Space-Filling Vector Quantization”, in <em class="mn">Proceedings of Interspeech</em>, 2024.</p><p id="a9d3" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[2] T. Bäckström, “Privacy in speech technology”, 2024. [Online] Available at: <a class="af ni" href="https://arxiv.org/abs/2305.05227" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2305.05227</a></p><p id="d45e" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[3] A. Nautsch et. al. , “The Privacy ZEBRA: Zero Evidence Biometric Recognition Assessment,” in <em class="mn">Proceedings of Interspeech</em>, 2020.</p><p id="1d1e" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[4] M. H. Vali and T. Bäckström, “NSVQ: Noise Substitution in Vector Quantization for Machine Learning,” <em class="mn">IEEE Access</em>, 2022.</p><p id="6076" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[5] M.H. Vali, T. Bäckström, “Interpretable Latent Space Using Space-Filling Curves for Phonetic Analysis in Voice Conversion”, in <em class="mn">Proceedings of Interspeech</em>, 2023.</p><p id="4f37" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[6] B. Desplanques, J. Thienpondt, and K. Demuynck, “ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification,” in <em class="mn">Proceedings of Interspeech</em>, 2020.</p><p id="6771" class="pw-post-body-paragraph ml mm fq mo b go mp mq mr gr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh fj bk">[7] C. Dwork, “Differential privacy: A survey of results,” in<br/>International conference on theory and applications of models<br/>of computation. Springer, 2008.</p></div></div></div></div>    
</body>
</html>