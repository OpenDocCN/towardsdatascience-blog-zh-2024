- en: Navigating the New Types of LLM Agents and Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/navigating-the-new-types-of-llm-agents-and-architectures-309382ce9f88?source=collection_archive---------0-----------------------#2024-08-30](https://towardsdatascience.com/navigating-the-new-types-of-llm-agents-and-architectures-309382ce9f88?source=collection_archive---------0-----------------------#2024-08-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/5939b58b0944ef661493ed70b68e1810.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by author using Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: The failure of ReAct agents gives way to a new generation of agents — and possibilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://aparnadhinak.medium.com/?source=post_page---byline--309382ce9f88--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page---byline--309382ce9f88--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--309382ce9f88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--309382ce9f88--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page---byline--309382ce9f88--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--309382ce9f88--------------------------------)
    ·10 min read·Aug 30, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*My thanks to John Gilhuly for his contributions to this piece*'
  prefs: []
  type: TYPE_NORMAL
- en: If 2023 was the year of retrieval augmented generation, 2024 has been the year
    of agents. Companies all over the world are experimenting with chatbot agents,
    tools like MultiOn are growing by connecting agents to outside websites, and frameworks
    like LangGraph and LlamaIndex Workflows are helping developers around the world
    build structured agents.
  prefs: []
  type: TYPE_NORMAL
- en: However, despite their popularity, agents have yet to make a strong splash outside
    of the AI ecosystem. Few agents are taking off among either consumer or enterprise
    users.
  prefs: []
  type: TYPE_NORMAL
- en: How can teams navigate the new frameworks and new agent directions? What tools
    are available, and which should you use to build your next application? As a leader
    at a company that recently built our own complex agent to act as a copilot within
    our product, we have some insights on this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Defining Agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, it helps to define what we mean by an agent. LLM-based agents are software
    systems that string together multiple processing steps, including calls to LLMs,
    in order to achieve a desired end result. Agents typically have some amount of
    conditional logic or decision-making capabilities, as well as a working memory
    they can access between steps.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive into how agents are built today, the current problems with modern
    agents, and some initial solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The Failure of ReAct Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s be honest, the idea of an agent isn’t new. There were countless agents
    launched on AI Twitter over the last year claiming amazing feats of intelligence.
    This first generation were mainly [ReAct](https://arxiv.org/abs/2210.03629) (reason,
    act) agents. They were designed to abstract as much as possible, and promised
    a wide set of outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this first generation of agent architectures really struggled.
    Their heavy abstraction made them hard to use, and despite their lofty promises,
    they turned out to [not do much of anything](https://arxiv.org/html/2405.13966v1).
  prefs: []
  type: TYPE_NORMAL
- en: In reaction to this, many people began to rethink how agents should be structured.
    In the past year we’ve seen great advances, now leading us into the next generation
    of agents.
  prefs: []
  type: TYPE_NORMAL
- en: What is the Second Generation of Agents?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This new generation of agents is built on the principle of defining the possible
    paths an agent can take in a much more rigid fashion, instead of the open-ended
    nature of ReAct. Whether agents use a framework or not, we have seen a trend towards
    smaller solution spaces — aka a reduction in the possible things each agent can
    do. A smaller solution space means an easier-to-define agent, which often leads
    to a more powerful agent.
  prefs: []
  type: TYPE_NORMAL
- en: This second generation covers many different types of agents, however it’s worth
    noting that *most of the agents or assistants we see today are written in code
    without frameworks, have an LLM router stage, and process data in iterative loops.*
  prefs: []
  type: TYPE_NORMAL
- en: What Makes Up An Agent?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many agents have a node or component called a **router,** that decides which
    step the agent should take next. The term router normally refers to an LLM or
    classifier making an intent decision of what path to take. An agent may return
    to this router continuously as they progress through their execution, each time
    bringing some updated information. The router will take that information, combine
    it with its existing knowledge of the possible next steps, and choose the next
    action to take.
  prefs: []
  type: TYPE_NORMAL
- en: The router itself is sometimes powered by a call to an LLM. Most popular LLMs
    at this point support **function calling**, where they can choose a component
    to call from a JSON dictionary of function definitions. This ability makes the
    routing step easy to initially set up. As we’ll see later however, the router
    is often the step that needs the most improvement in an agent, so this ease of
    setup can belie the complexity under the surface.
  prefs: []
  type: TYPE_NORMAL
- en: Each action an agent can take is typically represented by a **component**. Components
    are blocks of code that accomplish a specific small task. These could call an
    LLM, or make multiple LLM calls, make an internal API call, or just run some sort
    of application code. These go by different names in different frameworks. In LangGraph,
    these are nodes. In LlamaIndex Workflows, they’re known as steps. Once the component
    completes its work, it may return to the router, or move to other decision components.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the complexity of your agent, it can be helpful to group components
    together as execution branches or **skills**. Say you have a customer service
    chatbot agent. One of the things this agent can do is check the shipping status
    of an order. To functionally do that, the agent needs to extract an order id from
    the user’s query, create an api call to a backend system, make that api, parse
    the results, and generate a response. Each of those steps may be a component,
    and they can be grouped into the “Check shipping status” skill.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, many agents will track a **shared state** or memory as they execute.
    This allows agents to more easily pass context between various components.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Agent Architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are some common patterns we see across agent deployments today. We’ll
    walk through an overview of all of those architectures in the following pieces
    but the below examples are probably the most common.
  prefs: []
  type: TYPE_NORMAL
- en: In its simplest form an agent or assistant might just be defined with a LLM
    router and a tool call. We call this first example a ***single router with functions***.
    We have a single router, that could be an LLM call, a classifier call, or just
    plain code, that directs and orchestrates which function to call. The idea is
    that the router can decide which tool or functional call to invoke based on input
    from the system. The single router comes from the fact that we are using only
    1 router in this architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11f1778aef2eec4c137a1a670bcc2dca.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram by author
  prefs: []
  type: TYPE_NORMAL
- en: A slightly more complicated assistant we see is a ***single router with skills***.
    In this case, rather than calling a simple tooling or function call, the router
    can call a more complex workflow or skill set that might include many components
    and is an overall deeper set of chained actions. These components (LLM, API, tooling,
    RAG, and code calls) can be looped and chained to form a skill.
  prefs: []
  type: TYPE_NORMAL
- en: This is probably the most common architecture from advanced LLM application
    teams in production today that we see.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75fe8804f273eab573708fd0d9f133ca.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram by author
  prefs: []
  type: TYPE_NORMAL
- en: The general architecture gets more complicated by mixing branches of LLM calls
    with tools and state. In this next case, the router decides which of its skills
    (denoted in red) to call to answer the user’s question. It may update the shared
    state based on this question as well. Each skill may also access the shared state,
    and could involve one or more LLM calls of its own to retrieve a response to the
    user.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eeaa1ebe2277c41c4e42f3e33f2e536c.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram by author
  prefs: []
  type: TYPE_NORMAL
- en: This is still generally straightforward, however, agents are usually far more
    complex. As agents become more complicated, you start to see frameworks built
    to try and reduce that complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Agent Architecture Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangGraph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LangGraph builds on the pre-existing concept of a Pregel graph, but translates
    it over to agents. In LangGraph, you define nodes and edges that your agent can
    travel along. While it is possible to define a router node in LangGraph, it is
    usually unnecessary unless you’re working with multi-agent applications. Instead,
    the same conditional logic that could live in the router now lives in the Nodes
    and Conditional Edges objects that LangGraph introduces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a LangGraph agent that can either respond to a user’s
    greeting, or perform some sort of RAG lookup of information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/862a65a67f7fcea3ce139a3442f0dea2.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the routing logic instead lives within nodes and conditional edges that
    choose to move the user between different nodes depending on a function response.
    In this case, ***is_greeting*** and ***check_rag_response*** are conditional edges.
    Defining one of these edges looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Instead of collecting all of the routing logic in one node, we instead spread
    it between the relevant edges. This can be helpful, especially when you need to
    impose a predefined structure on your agent, and want to keep individual pieces
    of logic separated.
  prefs: []
  type: TYPE_NORMAL
- en: LlamaIndex Workflows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Other frameworks like [LlamaIndex Workflows](https://arize.com/blog/llamaindex-workflows-a-new-way-to-build-cyclical-agents/)
    take a different approach, instead using events and event listeners to move between
    nodes. Like LangGraph, Workflows don’t necessarily need a routing node to handle
    the conditional logic of an agent. Instead, Workflows rely on individual nodes,
    or steps as they call them, to handle incoming events, and broadcast outgoing
    events to be handled by other steps. This results in the majority of Workflows
    logic being handled within each step, as opposed to within both steps and nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/51e53013177ba3f241d11757c1882504.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A reflective SQL generation agent as a LlamaIndex Workflow (diagram by author)*'
  prefs: []
  type: TYPE_NORMAL
- en: CrewAI, Autogen, Swarm, and Others
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are other frameworks that are intended to make agent development easier,
    including some that specialize in handling groups of agents working together.
    This space is rapidly evolving and it’s worth checking out these and other frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Key Questions When Considering An Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Should You Use a Framework To Develop Your Agent?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of the framework you use, the additional structure provided by these
    tools can be helpful in building out agent applications. The question of whether
    using one of these frameworks is beneficial when creating larger, more complicated
    applications is a bit more challenging.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a fairly strong opinion in this area because we built an assistant
    ourselves. Our assistant uses a multi-layer router architecture with branches
    and steps that echo some of the abstractions of the current frameworks. We started
    building our assistant before LangGraph was stable. As a result, we constantly
    ask ourselves: if we were starting from scratch, would we use the current framework
    abstractions? Are they up to the task?'
  prefs: []
  type: TYPE_NORMAL
- en: The current answer is not yet. There is just too much complexity in the overall
    system that doesn’t lend itself to a Pregel-based architecture. If you squint,
    you can map it to nodes and edges but the software abstraction would likely get
    in the way. As it stands, our team tends to prefer code over frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: We do however, see the value in the agent framework approaches. Namely, it does
    force an architecture that has some best practices and good tooling. They are
    also getting better constantly, expanding where they are useful and what you can
    do with them. It is very likely that our answer may change in the near future
    as these frameworks improve.
  prefs: []
  type: TYPE_NORMAL
- en: Do You Actually Need An Agent?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This begs another important question: what types of applications even require
    an agent? After all, agents cover a broad range of systems — and there is so much
    hype about what is “agentic” these days.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are three criteria to determine whether you might need an agent:'
  prefs: []
  type: TYPE_NORMAL
- en: Does your application follow an iterative flow based on incoming data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does your application need to adapt and follow different flows based on previously
    taken actions or feedback along the way?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a state space of actions that can be taken? The state space can be
    traversed in a variety of ways, and is not just restricted to linear pathways.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Are The Common Issues To Expect?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s say that you answer yes to one of these questions and need an agent. Here
    are several known issues to be aware of as you build.
  prefs: []
  type: TYPE_NORMAL
- en: The first is **long-term planning**. While agents are powerful, they still struggle
    to decompose complex tasks into a logical plan. Worse, they can often get stuck
    in loops that block them from finding a solution. Agents also struggle with **malformed
    tooling calls.** This is typically due to the underlying LLMs powering an agent.
    In each case, human intervention is often needed to course correct.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue to be aware is inconsistent performance due to the **vastness
    of the solution space.** The sheer number of possible actions and paths an agent
    can take makes it difficult to achieve consistent results and tends to drive up
    costs. Perhaps this is why the market is tending toward constrained agents that
    can only choose from a set of possible actions, effectively limiting the solution
    space.
  prefs: []
  type: TYPE_NORMAL
- en: What Are Some Tactics for Addressing These Challenges?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As noted, one of the most effective strategies is to **map or narrow the solution
    space beforehand**. By thoroughly defining the range of possible actions and outcomes,
    you can reduce ambiguity. Incorporating **domain and business heuristics** into
    the agent’s guidance system is also an easy win, giving agents the context they
    need to make better decisions. **Being explicit about action intentions** (clearly
    defining what each action is intended to accomplish) and creating **repeatable
    processes** (standardizing the steps and methodologies that agents follow) can
    also enhance reliability and make it easier to identify and correct errors when
    they occur.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, **orchestrating with code and more reliable methods** rather than relying
    solely on LLM planning can dramatically improve agent performance. This involves
    swapping your LLM router for a code-based router where possible. By using code-based
    orchestration, you can implement more deterministic and controllable processes
    and reduce the unpredictability that often comes with LLM-based planning.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With so much hype and the proliferation of new frameworks in a frenzied generative
    AI environment filled with FOMO, it can be easy to lose sight of fundamental questions.
    Taking the time to think about when and where a modern agent framework might —
    and might not — make sense for your use case before diving headlong into an MVP
    is always worthwhile.
  prefs: []
  type: TYPE_NORMAL
- en: '*Questions? Feel free to reach out here or* [*on Slack*](https://join.slack.com/t/arize-ai/shared_invite/zt-26zg4u3lw-OjUNoLvKQ2Yv53EfvxW6Kg)
    *or find me live in one of our bi-weekly* [*AI research papers*](https://arize.com/ai-research-papers/)
    *readings.*'
  prefs: []
  type: TYPE_NORMAL
