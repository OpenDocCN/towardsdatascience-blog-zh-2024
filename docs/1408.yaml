- en: The One Billion Row Challenge in Julia
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Julia 中的 One Billion Row Challenge
- en: 原文：[https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05](https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05](https://towardsdatascience.com/the-one-billion-row-challenge-in-julia-bdd19cde58d5?source=collection_archive---------9-----------------------#2024-06-05)
- en: What can data scientists learn should they choose to accept this mission?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果数据科学家决定接受这个任务，他们能学到什么？
- en: '[](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)[![Vikas
    Negi](../Images/3f5974d44cfdbdecb77e3b4cb3098af0.png)](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)
    [Vikas Negi](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)[![Vikas
    Negi](../Images/3f5974d44cfdbdecb77e3b4cb3098af0.png)](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)
    [Vikas Negi](https://medium.com/@vikas.negi10?source=post_page---byline--bdd19cde58d5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)
    ·8 min read·Jun 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bdd19cde58d5--------------------------------)
    ·阅读时间 8 分钟·2024年6月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dded10279fcf25261adbea5aecf60745.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dded10279fcf25261adbea5aecf60745.png)'
- en: Photo by [Indira Tjokorda](https://unsplash.com/@indiratjokorda?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Indira Tjokorda](https://unsplash.com/@indiratjokorda?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Earlier this year, Gunnar Morling launched the [One Billon Row Challenge](https://www.morling.dev/blog/one-billion-row-challenge/),
    which has since gained a lot of popularity. Although the original challenge was
    meant to be done using Java, the amazing open-source community has since shared
    impressive solutions in different programming languages. I noticed that not many
    people had tried using Julia (or at least not publicly shared results), so decided
    to share my own humble attempt via this article.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今年早些时候，Gunnar Morling 启动了 [One Billon Row Challenge](https://www.morling.dev/blog/one-billion-row-challenge/)，自那以后，它获得了很大的关注。虽然最初的挑战是使用
    Java 完成的，但令人惊叹的开源社区随后分享了多种编程语言下的精彩解决方案。我注意到，使用 Julia 的人并不多（至少没有公开分享过结果），所以决定通过这篇文章分享我自己的尝试。
- en: A question that often came to my mind was what value does this challenge bring
    to a data scientist? Can we learn something more other than just doing a fun exercise?
    After all, the goal of the challenge is to “simply” parse a large dummy data file,
    calculate basic statistics (min, max and mean), and output the data in a specific
    format. This might not be a realistic situation for most if not all projects that
    data scientists usually work on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我常常想一个问题，这个挑战对数据科学家有什么价值？除了做一个有趣的练习之外，我们能学到更多的东西吗？毕竟，这个挑战的目标是“简单地”解析一个大型虚拟数据文件，计算基本统计量（最小值、最大值和均值），并以特定格式输出数据。这对于大多数数据科学家通常从事的项目来说，可能并不是一个现实的情况。
- en: Well, one aspect of the problem has to do with the size of the data versus the
    available RAM. When working locally (laptop or a desktop), for most people, it
    will be difficult to load the data all at once into memory. Dealing with larger
    than memory data sets therefore becomes an essential skill, which might come in
    handy when prototyping big data pipelines or performing big data analysis/visualization
    tasks. The rules of the original challenge also state that use of external libraries/packages
    should be avoided. This forces you to think of novel solutions and provides a
    fascinating opportunity to learn the nuances of the language itself.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，问题的一个方面涉及数据的大小与可用RAM之间的关系。在本地工作（笔记本电脑或桌面）时，对大多数人来说，难以将所有数据一次性加载到内存中。因此，处理比内存更大的数据集成为一项必要的技能，这在原型化大数据管道或进行大数据分析/可视化任务时可能会派上用场。原始挑战的规则也指出应该避免使用外部库/包。这迫使你思考新颖的解决方案，并为学习语言本身的细节提供了一个迷人的机会。
- en: In rest of the article, I will share results from both the approaches — using
    base Julia and also with external packages. This way, we get to compare the pros
    and cons of each. All experiments have been performed on a desktop equipped with
    AMD Ryzen 9 5900X (12 cores, 24 threads), 32 GB RAM and Samsung NVMe SSD. Julia
    1.10.2 is running on Linux (Elementary OS 7.1 Horus). All relevant code is available
    [here](https://github.com/vnegi10/1brc_julia). Do note that the performance in
    this case is also tied to the hardware, so results may vary in case you decide
    to run the scripts on your own system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的文章中，我将分享两种方法的结果——使用基础的Julia以及通过外部包进行的结果。通过这种方式，我们可以比较每种方法的优缺点。所有实验均在配备AMD
    Ryzen 9 5900X（12核心，24线程）、32 GB RAM和三星NVMe SSD的桌面上进行。Julia 1.10.2运行在Linux（Elementary
    OS 7.1 Horus）上。所有相关代码可以在[这里](https://github.com/vnegi10/1brc_julia)找到。请注意，这里的性能也与硬件有关，因此如果你决定在自己的系统上运行脚本，结果可能会有所不同。
- en: Prerequisites
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前提条件
- en: A recent release of [Julia](https://julialang.org/downloads/) such as 1.10 is
    recommended. For those wanting to use a notebook, the [repository](https://github.com/vnegi10/1brc_julia)
    shared above also contains a Pluto file, for which [Pluto.jl](https://github.com/fonsp/Pluto.jl)
    needs to be installed. The input data file for the challenge is unique for everyone
    and needs to be generated using [this Python script](https://github.com/gunnarmorling/1brc/blob/main/src/main/python/create_measurements.py).
    Keep in mind that the file is about 15 GB in size.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐使用最近发布的[Julia](https://julialang.org/downloads/)版本，例如1.10。对于那些想使用笔记本的人，上述[仓库](https://github.com/vnegi10/1brc_julia)还包含一个Pluto文件，使用该文件需要安装[Pluto.jl](https://github.com/fonsp/Pluto.jl)。挑战的输入数据文件是每个人独特的，必须使用[这个Python脚本](https://github.com/gunnarmorling/1brc/blob/main/src/main/python/create_measurements.py)生成。请记住，该文件大约有15
    GB。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Additionally, we will be running benchmarks using the [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl)
    package. Note that this does not impact the challenge, it’s only meant to collect
    proper statistics to measure and quantify the performance of the Julia code.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将使用[BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl)包来运行基准测试。请注意，这不会影响挑战，只是用来收集适当的统计数据，以衡量和量化Julia代码的性能。
- en: Using base Julia
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基础的Julia
- en: 'The structure of the input data file `measurements.txt` is as follows (only
    the first five lines are shown):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据文件`measurements.txt`的结构如下（这里只显示前五行）：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The file contains a billion lines (also known as rows or records). Each line
    has a station name followed by the `;` separator and then the recorded temperature.
    The number of unique stations can be up to 10,000\. This implies that the same
    station appears on multiple lines. We therefore need to collect all the temperatures
    for all distinct stations in the file, and then calculate the required statistics.
    Easy, right?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件包含十亿行（也称为记录或行）。每一行都有一个站点名称，后跟`；`分隔符，然后是记录的温度。唯一的站点数量最多可达10,000。这意味着同一个站点会出现在多行中。因此，我们需要收集文件中所有不同站点的所有温度数据，然后计算所需的统计信息。很简单，对吧？
- en: Let’s start slow but simple
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们从简单但慢慢来开始
- en: My first attempt was to simply parse the file one line at a time, and then collect
    the results in a dictionary where every station name is a key and the temperatures
    are added to a vector of `Float64` to be used as the value mapped to the key.
    I expected this to be slow, but our aim here is to get a number for the baseline
    performance.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我的第一次尝试是简单地逐行解析文件，然后将结果收集到一个字典中，每个站名作为键，温度作为`Float64`类型的向量添加到值中。我预期这会很慢，但我们的目标是获得基准性能的数字。
- en: 'Once the dictionary is ready, we can calculate the necessary statistics:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦字典准备好，我们就可以计算所需的统计数据：
- en: 'The output of all the data processing needs to be displayed in a certain format.
    This is achieved by the following function:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据处理的输出需要以某种特定格式显示。以下函数实现了这一点：
- en: 'Since this implementation is expected to take long, we can run a simple test
    by timing `@time` the following only once:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个实现预计需要较长时间，我们可以通过仅运行一次`@time`来进行简单的测试：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Our poor man’s implementation takes about 526 seconds, so ~ 9 minutes. It’s
    definitely slow, but not that bad at all!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这个简单的实现大约需要526秒，即约9分钟。虽然它确实很慢，但也并没有那么糟糕！
- en: Taking it up a notch — Enter multithreading!
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级一下——进入多线程！
- en: Instead of reading the input file one line at a time, we can try to split it
    into chunks, and then process all the chunks in parallel. Julia makes it quite
    easy to implement a parallel `for` loop. However, we need to take some [precautions](https://docs.julialang.org/en/v1/manual/multi-threading/#Caveats)
    while doing so.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与其一次读取输入文件的一行，不如尝试将文件拆分成多个块，然后并行处理所有块。Julia让实现并行`for`循环变得非常简单。然而，在这样做时，我们需要采取一些[预防措施](https://docs.julialang.org/en/v1/manual/multi-threading/#Caveats)。
- en: Before we get to the loop, we first need to figure out how to split the file
    into chunks. This can be achieved using [memory mapping](https://docs.julialang.org/en/v1/stdlib/Mmap/https://docs.julialang.org/en/v1/stdlib/Mmap/)
    to read the file. Then we need to determine the `start` and `end` positions of
    each chunk. It’s important to note that each line in the input data file ends
    with a new-line character, which has `0x0a` as the byte representation. So each
    chunk should end at that character to ensure that we don’t make any errors while
    parsing the file.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入循环之前，我们首先需要弄清楚如何将文件拆分成多个块。可以通过使用[内存映射](https://docs.julialang.org/en/v1/stdlib/Mmap/https://docs.julialang.org/en/v1/stdlib/Mmap/)来读取文件。然后，我们需要确定每个块的`start`和`end`位置。需要注意的是，输入数据文件中的每一行以换行符结尾，其字节表示为`0x0a`。因此，每个块应该在该字符处结束，以确保在解析文件时不出错。
- en: The following function takes the number of chunks`num_chunks`as an input argument,
    then returns an array with each element as the memory mapped chunk.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数将块的数量`num_chunks`作为输入参数，然后返回一个数组，其中每个元素都是内存映射的块。
- en: 'Since we are parsing station and temperature data from different chunks, we
    also need to combine them in the end. Each chunk will first be processed into
    a dictionary as shown before. Then, we combine all chunks as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们从不同的块中解析站点和温度数据，我们还需要在最后将它们合并。每个块将首先被处理为字典，如前所示。然后，我们按如下方式合并所有块：
- en: Now we know how to split the file into chunks, and how we can combine the parsed
    dictionaries from the chunks at the end. However, the desired speedup can only
    be obtained if we are also able to process the chunks in parallel. This can be
    done in a `for` loop. Note that Julia should be [started with multiple threads](https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads)
    `julia -t 12` for this solution to have any impact.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何将文件拆分成多个块，以及如何在最后将各个块解析出的字典合并。然而，只有在我们能够并行处理这些块时，才能获得所需的加速效果。这可以通过`for`循环来实现。请注意，Julia应该使用[多线程启动](https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads)
    `julia -t 12`，否则这个解决方案不会产生任何影响。
- en: Additionally, we now want to run a proper statistical benchmark. This means
    that the challenge should be executed a certain number of times, and we should
    then be able to visualize the distribution of the results. Thankfully, all of
    this can be easily done with [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl).
    We cap the maximum number of samples to 10, maximum time for the total run to
    be 20 minutes and enable garbage collection (will free up memory) to execute between
    samples. All of this can be brought together in a single script. Note that the
    input arguments are now the name of the file `fname` and the number of chunks
    `num_chunks.`
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们现在希望运行一个正式的统计基准测试。这意味着该挑战应该执行一定次数，然后我们可以可视化结果的分布。幸运的是，所有这些都可以通过[BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl)轻松完成。我们将最大样本数限制为10，整个运行的最大时间设为20分钟，并启用垃圾回收（将在样本之间释放内存）。所有这些都可以在一个脚本中整合。请注意，输入参数现在是文件名`fname`和数据块数`num_chunks`。
- en: Benchmark results along with the inputs used are shown below. Note that we have
    used 12 threads here.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基准测试结果和所用输入。请注意，我们在这里使用了12个线程。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/72ec4e552a082a0938866ae4f1e12de3.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72ec4e552a082a0938866ae4f1e12de3.png)'
- en: 12 threads, number of chunks = 48 (Image by author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 12个线程，数据块数 = 48（图片由作者提供）
- en: Multi-threading provides a big performance boost, we are now down to roughly
    over 2 minutes. Let’s see what else we can improve.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程显著提升了性能，我们现在的时间大约降至2分钟多一点。接下来我们看看还能做什么改进。
- en: Avoiding storing all temperature data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免存储所有温度数据
- en: Until now, our approach has been to store all the temperatures, and then determine
    the required statistics (min, mean and max) at the very end. However, the same
    can already be achieved while we parse every line from the input file. We replace
    existing values each time a new value which is either larger (for maximum) or
    smaller (for minimum) is found. For mean, we sum all the values and keep a separate
    counter as to how many times a temperature for a given station has been found.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的方法是存储所有的温度数据，然后在最后确定所需的统计值（最小值、平均值和最大值）。然而，我们已经可以在解析输入文件的每一行时实现相同的功能。每当找到一个新的值时（如果是更大的值则更新最大值，或更小的值则更新最小值），我们就替换现有的值。对于平均值，我们将所有的值相加，并保持一个单独的计数器，用于记录某个站点的温度出现了多少次。
- en: 'Overall, out new logic looks like the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们的新逻辑如下所示：
- en: The function to combine all the results (from different chunks) also needs to
    be updated accordingly.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 合并所有结果（来自不同数据块）的函数也需要相应地进行更新。
- en: Let’s run a new benchmark and see if this change improves the timing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一个新的基准测试，看看这个改变是否能改善时间表现。
- en: '![](../Images/03e629680c5f7ea6a82d412a8dfd74b9.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03e629680c5f7ea6a82d412a8dfd74b9.png)'
- en: 12 threads, number of chunks = 48 (Image by author)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 12个线程，数据块数 = 48（图片由作者提供）
- en: The median time seems to have improved, but only slightly. It’s a win, nonetheless!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数时间似乎有所改善，但改进幅度很小。不过，依然算是一个胜利！
- en: More performance enhancement
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多性能提升
- en: Our previous logic to calculate and save the mix, max for temperature can be
    further simplified. Moreover, following the suggestion from this [Julia Discourse
    post](https://discourse.julialang.org/t/the-one-billion-row-challenge/109534/24),
    we can make use of views (using `@view` ) when parsing the station names and temperature
    data. This has also been [discussed](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Consider-using-views-for-slices-1)
    in the Julia performance manual. Since we are using a slice expression for parsing
    every line, `@view` helps us avoid the cost of allocation and copying.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的逻辑用于计算和保存温度的最大值和最小值可以进一步简化。此外，按照这个[Julia Discourse帖子](https://discourse.julialang.org/t/the-one-billion-row-challenge/109534/24)中的建议，当解析站点名称和温度数据时，我们可以使用视图（通过`@view`）。这一点在Julia性能手册中也有[讨论](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#Consider-using-views-for-slices-1)。由于我们在解析每一行时使用了切片表达式，`@view`帮助我们避免了分配和复制的开销。
- en: 'Rest of the logic remains the same. Running the benchmark now gives the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的逻辑保持不变。现在运行基准测试得到以下结果：
- en: '![](../Images/f521124dfe4e634f7f0478fcbea99c64.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f521124dfe4e634f7f0478fcbea99c64.png)'
- en: 12 threads, number of chunks = 48 (Image by author)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 12个线程，数据块数 = 48（图片由作者提供）
- en: Whoa! We managed to reach down to almost a minute. It seems switching to a view
    does make a big difference. Perhaps, there are further tweaks that could be made
    to improve performance even further. In case you have any suggestions, do let
    me know in the comments.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！我们成功地将时间缩短到了接近一分钟。看起来切换到不同的视图确实有很大的影响。也许，还有更多的调整可以进一步提高性能。如果你有任何建议，请在评论中告诉我。
- en: Using external packages
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用外部包
- en: Restricting ourselves only to base Julia was fun. However, in the real world,
    we will almost always be using packages and thus making use of existing efficient
    implementations for performing the relevant tasks. In our case, CSV.jl (parsing
    the file in parallel) and DataFrames.jl (performing `groupby` and `combine`) will
    come in handy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 仅限使用基础 Julia 进行限制是很有趣的。然而，在实际应用中，我们几乎总是会使用包，因此可以利用现有的高效实现来执行相关任务。在我们的例子中，CSV.jl（并行解析文件）和
    DataFrames.jl（执行 `groupby` 和 `combine`）将会派上用场。
- en: 'The function below performs the following tasks:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数执行以下任务：
- en: Use `Mmap` to read the large file
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `Mmap` 读取大文件
- en: Split file into a predefined number of chunks
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文件分割成预定义数量的块
- en: Loop through the chunks, read each chunk in parallel using `CSV.read` (12 threads
    passed to `ntasks`) into a DataFrame.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历这些块，使用 `CSV.read`（将 12 个线程传递给 `ntasks`）并行读取每个块到 DataFrame 中。
- en: Use DataFrame `groupby` and `combine` to get the results for each station
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DataFrame 的 `groupby` 和 `combine` 获取每个车站的结果
- en: Concatenate all DataFrames to combine results from all chunks
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有 DataFrame 连接起来，合并所有分块的结果
- en: Once outside the loop, perform a `groupby` and `combine` again to get the final
    set of results for all stations.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环结束后，执行一次 `groupby` 和 `combine`，以获取所有车站的最终结果集。
- en: We can now run the benchmark in the same manner as before.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以以与之前相同的方式运行基准测试。
- en: '![](../Images/72da5f5c1ebda12a8453bd0ddd76df4a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72da5f5c1ebda12a8453bd0ddd76df4a.png)'
- en: 12 threads, number of chunks = 48, using external packages (Image by author)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 12 个线程，分块数 = 48，使用外部包（图片由作者提供）
- en: The performance using CSV.jl and DataFrames.jl is quite good, albeit slower
    than our base Julia implementation. When working on real world projects, these
    packages are an essential part of a data scientist’s toolkit. It would thus be
    interesting to explore if further optimizations are possible using this approach.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CSV.jl 和 DataFrames.jl 的性能相当不错，尽管比我们使用基础 Julia 实现的要慢。在实际项目中，这些包是数据科学家工具包中的重要组成部分。因此，探索使用这种方法是否可以进行进一步优化将是很有趣的。
- en: Conclusion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we tackled the One Billion Row Challenge using Julia. Starting
    from a very naive implementation that took ~ 10 minutes, we managed to gain significant
    performance improvement through iterative changes to the code. The most optimized
    implementation completes the challenge in ~ 1 minute. I am certain that there’s
    still more room for improvement. As an added bonus, we learned some valuable tricks
    on how to deal with larger than memory data sets. This might come in handy when
    doing some big data analysis and visualization using Julia.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们通过 Julia 解决了十亿行挑战。从一个非常简单的实现开始，花费大约 10 分钟，我们通过对代码的迭代修改，成功地大幅提升了性能。最优化的实现可以在约
    1 分钟内完成挑战。我确信仍然有改进的空间。作为额外的收获，我们学到了一些宝贵的技巧，如何处理超出内存的数据集。当使用 Julia 进行大数据分析和可视化时，这可能会派上用场。
- en: I hope you found this exercise useful. Thank you for your time! Connect with
    me on [LinkedIn](https://www.linkedin.com/in/negivikas/) or visit my [Web 3.0
    powered website](https://vikasnegi.eth.limo/).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得这个练习有用。感谢你的时间！可以通过 [LinkedIn](https://www.linkedin.com/in/negivikas/) 与我联系，或者访问我的
    [Web 3.0 网站](https://vikasnegi.eth.limo/)。
- en: References
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[https://www.morling.dev/blog/one-billion-row-challenge/](https://www.morling.dev/blog/one-billion-row-challenge/)'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.morling.dev/blog/one-billion-row-challenge/](https://www.morling.dev/blog/one-billion-row-challenge/)'
- en: '[https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations)'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations)'
