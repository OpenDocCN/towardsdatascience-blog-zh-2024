# 超优化AI工作流的5个支柱

> 原文：[https://towardsdatascience.com/5-pillars-for-a-hyper-optimized-ai-workflow-21fcaefe48ca?source=collection_archive---------3-----------------------#2024-09-03](https://towardsdatascience.com/5-pillars-for-a-hyper-optimized-ai-workflow-21fcaefe48ca?source=collection_archive---------3-----------------------#2024-09-03)

## 创建适用于生产的、可扩展且高度优化的AI工作流的方法论简介

[](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)[![Gilad Rubin](../Images/e98728582365c22c2803d5db0a0f3ca6.png)](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------) [Gilad Rubin](https://medium.com/@giladrubin?source=post_page---byline--21fcaefe48ca--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--21fcaefe48ca--------------------------------) ·阅读时间：7分钟·2024年9月3日

--

![](../Images/c2981f3bf6f6dd818737a86793759b75.png)

*致谢：Google Gemini，作者提供的提示*

# 引言

在过去十年中，每个我参与的项目中，我心里都怀揣着一个深刻的问题：

> **我该如何**（究竟怎么）**构建和开发我的AI和机器学习项目？**

我想知道——是否有一种优雅的方式，以迭代的方式构建**适用于生产的**代码？一种**可扩展、优化、可维护且可重现**的代码库？

那么，这个秘密到底在哪里呢？谁掌握了这门黑暗艺术的知识？

多年来，我一直在全力以赴寻找答案——阅读文章、观看教程，并尝试不同的方法论和框架。但我始终未能找到一个令人满意的答案。每当我觉得自己接近解决方案时，总有某些东西仍然缺失。

经过大约10年的试验与错误，尤其是在过去两年专注努力之后，我认为我终于找到了一个令人满意的答案，结束了我长期以来的追寻。这篇文章是我分享所发现内容的旅程的开始。

我的研究让我识别出了**5个关键支柱**，它们构成了我所称之为**超优化AI工作流**的基础。在这篇文章中，我将简要介绍每个支柱——为你概述即将到来的内容。

我想强调的是，我将介绍的每个支柱都基于实际的方法和工具，我将在未来的文章中详细阐述。如果你已经迫不及待想看到它们的实际应用，可以查看我在Hamilton见面会上的这段视频，现场展示了这些内容：

*注意：在本文及系列文章中，我将交替使用人工智能（AI）、机器学习（ML）和数据科学（DS）这几个术语。我们讨论的概念适用于所有这些领域。*

现在，让我们探索每个支柱。

# 1 — 基于指标的优化

每个AI项目都有一个我们想要实现的目标，理想情况下——还有一组我们想要优化的指标。

这些指标可以包括：

+   **预测质量指标**：准确率、F1-Score、召回率、精确率等……

+   **成本指标**：实际金额、FLOPS、大小（以MB为单位）等……

+   **性能指标**：训练速度、推理速度等……

我们可以选择一个指标作为我们的“北极星”，或者创建一个综合指标。例如：

+   0.7 × F1-Score + 0.3 × (1 / 推理时间（毫秒）)

+   0.6 × AUC-ROC + 0.2 × (1 / 训练时间（小时）) + 0.2 × (1 / 云计算成本（美元）)

*有一个* [*安德鲁·吴的精彩短视频*](https://www.youtube.com/watch?v=sofffBNhVSo) *，在视频中他解释了* ***单一数字评估指标*** *的话题。*

一旦我们确定了一个需要优化的指标并设定了要满足的约束条件，**我们的目标是构建一个在满足约束条件的同时最大化该指标的工作流。**

# 2 — 交互式开发者体验

在数据科学和AI开发的世界里——交互性是关键。

作为AI工程师（或者我们数据科学家现在使用的任何头衔），我们需要编写在不同场景下都能无错运行的代码。

与传统软件工程不同，我们的角色不仅仅是编写“能工作”的代码。我们工作的重要部分是审视数据，检查模型的输出和各个处理步骤的结果。

最常见的交互式探索环境是Jupyter笔记本。

在笔记本环境中工作允许我们**测试不同的实现，尝试新的API，检查工作流的中间结果，并基于我们的观察做出决策。** 这是第二个支柱的核心。

然而，尽管我们在日常工作中享受这些好处，笔记本有时也会包含臭名昭著的坏代码，这些代码只能按非平凡的顺序执行。

此外，笔记本中的一些探索性部分可能与生产环境无关，因此不清楚这些部分如何有效地交付到生产中。

# 3 — 生产就绪代码

“生产就绪”在不同的上下文中可能意味着不同的事情。对于一个组织来说，它可能意味着在指定的时间范围内提供结果。对于另一个组织来说，它可能指的是服务的正常运行时间（SLA）。而对于第三个组织，它可能意味着代码、模型或工作流经过充分测试，以确保其可靠性。

这些都是交付可靠产品的重要方面，具体要求可能因地而异。由于我的探索侧重于构建AI工作流的“元”层面，我想讨论这些定义之间的共同点：**将我们的工作流封装为一个可服务的API，并将其部署到一个可以被外部应用程序或用户查询的环境中。**

这意味着我们需要有一种方法，将代码库的复杂性抽象为一个明确定义的接口，以便在各种用例中使用。让我们考虑一个例子：

想象一下，我们开发了一个复杂的RAG（检索增强生成）系统，运行在PDF文件之上。它可能包含10个不同的部分，每个部分由数百行代码组成。

然而，我们仍然可以将它们包装成一个简单的API，只有两个主要功能：

1.  upload_document(file: PDF) -> document_id: str

1.  query_document(document_id: str, query: str, output_format: str) -> response: str

这种抽象使用户能够：

1.  上传PDF文档并接收一个唯一的标识符。

1.  使用自然语言提问关于文档的问题。

1.  指定所需的响应格式（例如，Markdown、JSON、Pandas DataFrame）。

通过提供这个简洁的接口，我们有效地隐藏了工作流的复杂性和实现细节。

**拥有一种系统化的方式，将任意复杂的工作流程转换为可部署的API，是我们的第三个支柱。**

此外，我们理想中希望建立一种方法，确保我们的**迭代性日常工作与生产代码保持同步**。

这意味着如果我们对工作流进行更改——修复一个bug、添加新的实现，甚至调整一个配置——我们应该能够通过点击一个按钮，将这些更改部署到生产环境中。

# 4 — 模块化和可扩展的代码

我们方法论的另一个关键方面是保持**模块化和可扩展**的代码库。

这意味着我们可以**添加新的实现，并与现有的实现进行对比测试**，这些实现占据了相同的逻辑步骤，而无需修改现有的代码或覆盖其他配置。

这种方法与[**开放-封闭原则**](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle)相一致，其中我们的代码可以扩展，但不能修改。它使我们能够：

1.  在现有实现的基础上引入新实现

1.  容易比较不同方法的性能

1.  维护当前工作解决方案的完整性

1.  在不危及整个系统稳定性的情况下扩展我们工作流的功能

让我们看一个简单的例子：

![](../Images/76759faaabe47220288d951e11385ba8.png)

作者提供的图片

![](../Images/56292fd73a23bbfc6d6dd636de73b554.png)

作者提供的图片

在这个示例中，我们可以看到一段模块化和可配置的（伪）代码。通过这种方式，我们可以轻松地添加新的配置并测试它们的性能：

![](../Images/04c39fc215cbe886f28c8bba50baf51e.png)

作者提供的图片

一旦我们的代码由多个竞争的实现和配置组成，我们进入了一个我称之为**“工作流的叠加态”**的状态。在这种状态下，我们可以使用特定的配置集来实例化和执行工作流。

# 5 — 分层和可视化结构

如果我们进一步推进模块化和可扩展性呢？如果我们将这种方法应用于我们工作流的整个部分呢？

所以现在， instead of configuring **this** LLM or **that** retriever, 我们可以配置整个预处理、训练或评估步骤。

让我们看一个例子：

![](../Images/5425e8ced3cd5f570509c5f16dc98b29.png)

作者图片

这里我们看到整个机器学习工作流。现在，让我们添加一个新的数据准备实现并放大查看：

![](../Images/3fb1f2958404c2d54145cd6abd7dc377.png)

作者图片

当我们以这种分层和可视化的方式工作时，我们可以选择工作流中的某一部分进行改进，并添加一个与现有部分具有相同输入/输出接口的新实现。

然后我们可以“放大”到这个特定部分，专注于它，而不必担心项目的其他部分。一旦我们对实现感到满意——我们就可以开始在工作流中的其他不同配置下进行测试。

这种方法解锁了几个好处：

1.  **减少心理负担：** 每次专注于一个部分，提供清晰度并减少决策时的复杂性。

1.  **更容易的协作：** 模块化结构简化了任务分配给队友或AI助手，并且每个组件都有清晰的接口。

1.  **可重用性：** 这些封装的实现可以在不同的项目中使用，可能无需修改其源代码。

1.  **自我文档化：** 可视化整个工作流及其组件，使得理解项目的结构和逻辑变得更加容易，而无需深入到不必要的细节。

# 总结

这些是我认为构成**“超优化AI工作流”**基础的五大支柱：

1.  **基于指标的优化：** 定义并优化清晰的、项目特定的指标，以指导决策和工作流的改进。

1.  **互动开发者体验：** 使用像Jupyter Notebooks这样的工具进行迭代编码和数据检查。

1.  **生产就绪代码：** 将完整的工作流封装成可部署的API，并同步开发与生产代码。

1.  **模块化和可扩展代码：** 结构化代码，使其能够轻松添加、替换和测试不同的实现。

1.  **分层和可视化结构：** 将项目组织为可视化的分层组件，这些组件可以独立开发，并且在不同的抽象层次上易于理解。

在接下来的博客文章中，我将深入探讨这些支柱，提供更详细的见解、实际示例和工具，帮助你在自己的AI项目中实现这些概念。

具体来说，我打算介绍我在[DAGWorks Inc](https://open.substack.com/users/141841981-dagworks-inc?utm_source=mentions)* Hamilton框架之上构建的方法论和工具，以及我自己的软件包：[Hypster](https://github.com/gilad-rubin/hypster)和[HyperNodes](https://github.com/gilad-rubin/hypernodes)（目前仍处于早期阶段）。

敬请期待更多内容！

*我与DAGWorks Inc没有任何隶属关系，也没有为其工作。
