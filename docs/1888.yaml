- en: 'AI Hallucinations: Can Memory Hold the Answer?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 幻觉：记忆能成为解决之道吗？
- en: 原文：[https://towardsdatascience.com/ai-hallucinations-can-memory-hold-the-answer-5d19fd157356?source=collection_archive---------5-----------------------#2024-08-02](https://towardsdatascience.com/ai-hallucinations-can-memory-hold-the-answer-5d19fd157356?source=collection_archive---------5-----------------------#2024-08-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ai-hallucinations-can-memory-hold-the-answer-5d19fd157356?source=collection_archive---------5-----------------------#2024-08-02](https://towardsdatascience.com/ai-hallucinations-can-memory-hold-the-answer-5d19fd157356?source=collection_archive---------5-----------------------#2024-08-02)
- en: '|LLM|HALLUCINATION| MEMORY|'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '|LLM|幻觉|记忆|'
- en: Exploring How Memory Mechanisms Can Mitigate Hallucinations in Large Language
    Models
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索记忆机制如何缓解大型语言模型中的幻觉问题
- en: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--5d19fd157356--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)
    ·7 min read·Aug 2, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d19fd157356--------------------------------)
    ·阅读时长 7 分钟 ·2024年8月2日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ab04aad53a7622f67a63d9781cf73c1b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab04aad53a7622f67a63d9781cf73c1b.png)'
- en: image created by the author using AI
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图由作者使用 AI 创建
- en: A hallucination is a fact, not an error; what is erroneous is a judgment based
    upon it. — Bertrand Russell
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 幻觉是事实，而非错误；错误的是基于这些事实的判断。—— 伯特兰·罗素
- en: '[Large language models (LLMs)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20a%20Large%20Language%20Model%20(LLM)%3F)
    have shown remarkable performance, but are still plagued by [hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F).
    Especially for sensitive applications this is no small problem, so several solutions
    have been studied. Nevertheless, the problem persists even though some mitigation
    strategies have helped reduce them.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[大型语言模型（LLMs）](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20is%20a%20Large%20Language%20Model%20(LLM)%3F)
    展现了显著的性能，但仍然受到[幻觉](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F)困扰。尤其是在敏感应用中，这并非小问题，因此已经研究了多种解决方案。尽管一些缓解策略有助于减少幻觉问题，但问题仍然存在。'
- en: '[](/a-requiem-for-the-transformer-297e6f14e189?source=post_page-----5d19fd157356--------------------------------)
    [## A Requiem for the Transformer?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-requiem-for-the-transformer-297e6f14e189?source=post_page-----5d19fd157356--------------------------------)
    [## 变压器的挽歌？'
- en: Will be the transformer the model leading us to artificial general intelligence?
    Or will be replaced?
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变压器模型将是引领我们走向人工通用智能的模型吗？还是会被取代？
- en: 'towardsdatascience.com](/a-requiem-for-the-transformer-297e6f14e189?source=post_page-----5d19fd157356--------------------------------)
    [](https://levelup.gitconnected.com/chat-quijote-and-the-windmills-navigating-ai-hallucinations-on-the-path-to-accuracy-0aaecf46354c?source=post_page-----5d19fd157356--------------------------------)
    [## Chat Quijote and the Windmills: Navigating AI Hallucinations on the Path to
    Accuracy'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-requiem-for-the-transformer-297e6f14e189?source=post_page-----5d19fd157356--------------------------------)
    [](https://levelup.gitconnected.com/chat-quijote-and-the-windmills-navigating-ai-hallucinations-on-the-path-to-accuracy-0aaecf46354c?source=post_page-----5d19fd157356--------------------------------)
    [## 聊天基霍特与风车：在通往准确性的道路上应对 AI 幻觉
- en: Strategies and Tools for Enhancing Reliability in Large Language Models
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升大型语言模型可靠性的策略与工具
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/chat-quijote-and-the-windmills-navigating-ai-hallucinations-on-the-path-to-accuracy-0aaecf46354c?source=post_page-----5d19fd157356--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[levelup.gitconnected.com](https://levelup.gitconnected.com/chat-quijote-and-the-windmills-navigating-ai-hallucinations-on-the-path-to-accuracy-0aaecf46354c?source=post_page-----5d19fd157356--------------------------------)'
- en: Why [hallucinations](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F)
    originate is still an open question, although there are some theories about what…
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么[幻觉](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#:~:text=What%20does%20it%20mean%20LLM%27s%20hallucination%3F)会产生仍然是一个未解之谜，尽管有一些关于其产生原因的理论。
