<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Beyond Fine-Tuning: Merging Specialized LLMs Without the Data Burden</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Beyond Fine-Tuning: Merging Specialized LLMs Without the Data Burden</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beyond-fine-tuning-merging-specialized-llms-without-the-data-burden-1c449c2060c4?source=collection_archive---------5-----------------------#2024-08-13">https://towardsdatascience.com/beyond-fine-tuning-merging-specialized-llms-without-the-data-burden-1c449c2060c4?source=collection_archive---------5-----------------------#2024-08-13</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="7736" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">From Model Soup to Automated Evolutionary Merging: Leveraging Specialized LLM Fusion to Reduce Data Requirements and Eliminate Intensive Fine-Tuning.</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@InfiniteLearningLoop?source=post_page---byline--1c449c2060c4--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Elahe Aghapour" class="l ep by dd de cx" src="../Images/47a2023c566d50d8ecfcafdb69bb9bb7.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:88:88/1*DfA3l4L2kLpNaOAUK9Rb4g.jpeg"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--1c449c2060c4--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@InfiniteLearningLoop?source=post_page---byline--1c449c2060c4--------------------------------" rel="noopener follow">Elahe Aghapour</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--1c449c2060c4--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Aug 13, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj la lb ab q ee lc ld" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="le"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lf k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lg an ao ap id lh li lj" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep lk cn"><div class="l ae"><div class="ab cb"><div class="ll lm ln lo lp lq ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lg an ao ap id lr ls ld lt lu lv lw lx s ly lz ma mb mc md me u mf mg mh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="85c2" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">Authors: </strong><span class="ia"><span class="ia" aria-hidden="false"><a class="ne ib nf" href="https://medium.com/u/75214fb27311?source=post_page---user_mention--1c449c2060c4--------------------------------" rel="noopener" target="_blank"><strong class="mk fr">Elahe Aghapour</strong></a></span></span><strong class="mk fr">, </strong><span class="ia"><span class="ia" aria-hidden="false"><a class="ne ib nf" href="https://medium.com/u/6dff1eb2cc9f?source=post_page---user_mention--1c449c2060c4--------------------------------" rel="noopener" target="_blank"><strong class="mk fr">Salar Rahili</strong></a></span></span></p><h1 id="9f51" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">Introduction:</h1><p id="9f2c" class="pw-post-body-paragraph mi mj fq mk b go oc mm mn gr od mp mq mr oe mt mu mv of mx my mz og nb nc nd fj bk">The field of computer vision and natural language processing is evolving rapidly, leading to a growing demand for specialized models fine-tuned for specific downstream tasks. However, having different fine-tuned models has multiple drawbacks:<br/>1. For each task, a separate model must be stored and deployed (this issue can be resolved by applying methods like LoRA for fine-tuning).<br/>2. Independently fine-tuned models cannot benefit from leveraging information from related tasks, which limits their generalization across both in-domain and out-of-domain tasks. However, multi-task learning requires access to datasets for each specific task, and integrating these datasets can be complicated. What if we do not have access to datasets for all downstream tasks, but the fine-tuned models are available? Imagine you need a large language model (LLM) fine-tuned on a set of specific tasks. Instead of collecting extensive datasets for downstream tasks and undergoing the resource-heavy process of fine-tuning, you can find LLMs fine-tuned on each task and merge these models to create the desired one. Note that finding such models is not a difficult task within the large Hugging Face repository, which hosts approximately 0.5 million fine-tuned models. Merging multiple models has recently gained significant attention, primarily because it requires lightweight computation and no training data.</p><figure class="ok ol om on oo op oh oi paragraph-image"><div role="button" tabindex="0" class="oq or ed os bh ot"><div class="oh oi oj"><img src="../Images/25ee63a959506e2d9587b14a354f7621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ef6fYks10un4D2ZT"/></div></div><figcaption class="ov ow ox oh oi oy oz bf b bg z dx">Fig.1 Model ensemble combines outputs from multiple models to boost accuracy but requires more computational resources. Multi-task learning trains one model on several tasks simultaneously, needing access to all datasets and high computational power. Model merging, however, fuses pre-trained models into one, leveraging their strengths with minimal computation and no extra training costs, offering a highly efficient solution (image from <a class="af pa" href="https://arxiv.org/pdf/2212.09849" rel="noopener ugc nofollow" target="_blank">paper</a>).</figcaption></figure><p id="05b1" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">With the growing attention to merging, public libraries such as WEBUI and MergeKit have been developed to facilitate this process. WebUIs enables merging fine-tuned models such as Stable Diffusion using different merging techniques. MergeKit is an open-source, centralized library that offers different merging methods. It facilitates model merging by its efficient implementation of merging techniques, applicable on any hardware.</p><blockquote class="pb pc pd"><p id="14f6" class="mi mj pe mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Here, we categorized merging methods into three main categories:<br/>1. merging models with identical architectures and initializations,<br/>2. merging models with identical architectures but different initializations,<br/>3. merging models with different architectures.<br/>Each category involves different techniques to effectively combine models, which will be explained below.</p></blockquote><h1 id="d5b9" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk"><strong class="al">1. Merging Models with Both Identical Architectures and Initializations:</strong></h1><p id="97f7" class="pw-post-body-paragraph mi mj fq mk b go oc mm mn gr od mp mq mr oe mt mu mv of mx my mz og nb nc nd fj bk"><strong class="mk fr"><em class="pe">1.a Merging With No Data Requirement:</em></strong></p><p id="0f18" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The model merging methods in this section are all based on Linear Mode Connectivity (<a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2019/file/05e97c207235d63ceb1db43c60db7bbb-Paper.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">LMC</strong></a>). LMC suggests that for models with identical architecture and initialization, the loss between their checkpoints can be connected by a low-loss linear path. This means that these models can be combined using linear interpolation.</p><p id="550e" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">To fine-tune a model, various configurations, like different learning rates, random seeds, and data augmentation techniques can be applied which result in different model parameters. <a class="af pa" href="https://proceedings.mlr.press/v162/wortsman22a/wortsman22a.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Model soup</strong></a> proposes averaging these parameters since these models have learned similar representations and are close in parameter space. Weighted model averaging leads to a flat local optimum with better generalization to out-of-distribution tasks [see <a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/69b5534586d6c035a96b49c86dbeece8-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank">13</a>, <a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/995f5e03890b029865f402e83a81c29d-Paper.pdf" rel="noopener ugc nofollow" target="_blank">14</a>]</p><figure class="ok ol om on oo op oh oi paragraph-image"><div role="button" tabindex="0" class="oq or ed os bh ot"><div class="oh oi oj"><img src="../Images/003054738dc6d8ecf7c47c2b93be6c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BlEckRGBZ97Z8Onp"/></div></div><figcaption class="ov ow ox oh oi oy oz bf b bg z dx">Fig. 2 Pl shows the result of model soup merging while Ps presents the result of SLERP merging (image by authors).</figcaption></figure><p id="a540" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr">SLERP</strong> (Spherical Linear Interpolation, first introduced <a class="af pa" href="https://dl.acm.org/doi/pdf/10.1145/325334.325242" rel="noopener ugc nofollow" target="_blank">here</a>) is a technique commonly used in computer graphics and animation for smoothly interpolating between rotations represented by quaternions. SLERP is also applicable in model merging. It merges two sets of model parameters by interpolating along a spherical path instead of a straight line. Fig. 2 shows that for the given two model parameters p1 and p2, SLERP merges these parameters along the globe’s surface, providing a smooth transition. This method is commonly used in merging LLMs. <br/>Assume two MLP models are given, each fine-tuned on a different downstream task. SLERP can merge these two models using the following steps:<br/><strong class="mk fr">Step 1:</strong> For each model parameters, flatten and concatenate them into vectors v1, v2<br/><strong class="mk fr">Step 2</strong>: Normalize the vectors v1​ and v2 to be on the unit hypersphere surface (resulting in v1′​ and v2′​).<br/><strong class="mk fr">Step 3</strong>: Calculate the angle θ (in radians) between these two vectors.<br/><strong class="mk fr">Step 4</strong>: Calculate Vslerp​ using the SLERP formula as:</p><figure class="ok ol om on oo op oh oi paragraph-image"><div class="oh oi pf"><img src="../Images/c155fcd8531a3c30355f80f9cceb40ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/0*9UILZLKdIwcdWVTZ"/></div></figure><p id="4cab" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">where t is the interpolation parameter as t=0 means only Model 1 is used, while t=1 means only Model 2 is used.<br/>Linear weight averaging techniques, such as model soup and SLERP, have been common in the field of computer vision from image processing and classification models to image generation models such as latent diffusion models.</p><p id="29cb" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://arxiv.org/pdf/2212.04089" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Task arithmetic</strong></a> introduces a method based on task vectors. A task vector is calculated by subtracting the weights of a pretrained model (θpre​) from the weights of the same model fine-tuned for a specific task (θft​), as <br/>τ = θft − θpre​. This vector represents a direction in the weight space of the pretrained model where moving in that direction enhances performance on that task. Task vectors can be combined together by arithmetic operations such as negation and addition. Negating a task vector (θpre — τ) reduces the model’s performance on the target task (forgetting) with minimal impact on control tasks. To enhance the performance of the pre-trained model across multiple tasks, we can initially learn a task vector for each task. By then summing these task vectors (θpre+∑τi), we improve the model’s capability to handle multiple tasks simultaneously.</p><p id="bacf" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/1644c9af28ab7916874f6fd6228a9bcf-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">TIES</strong></a> addresses performance drops due to parameter interference when combining task vectors (∑τi​). This issue can be solved through three steps (see Fig. 3):<br/>(1) trim each task vector to the top-k% (usually k=20) largest magnitude values, <br/>(2) for each non-zero parameter, select the sign with the highest total magnitude across all task vectors to avoid conflicting changes, and <br/>(3) merging values only from task vectors with the same sign as the elected one.</p><figure class="ok ol om on oo op oh oi paragraph-image"><div role="button" tabindex="0" class="oq or ed os bh ot"><div class="oh oi pg"><img src="../Images/a397b5a6e7f5ac9b0e37f32f681f01be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UEiYCSk5BcwPQSix"/></div></div><figcaption class="ov ow ox oh oi oy oz bf b bg z dx">Fig. 3 A depiction of the steps involved in TIES. Each parameter in a model is visualized as a square. The arrows depict the update (task vector, τ ) to a parameter produced by fine-tuning on different tasks (coded by colors), with direction denoting sign and length denoting magnitude. 1- Trim the task vector values based on their magnitude, 2- Elect the sign for each parameter (γm, green vector containing +1 or −1) by resolving sign conflicts, 3- Pick only the values that align with the elected sign and take their mean as the final parameter value. (image from <a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/1644c9af28ab7916874f6fd6228a9bcf-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank">paper</a>)</figcaption></figure><p id="9f9c" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://openreview.net/pdf?id=fq0NaiU8Ex" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">DARE</strong></a> is mainly focused on LLM’s model merging and identifies the extreme redundancy in the task vector (τ = θft−θpre). It proposes a three step approach:<br/>1- Randomly drop p% (usually p =90) of the task vector values, <br/>2- Rescale the remaining ones by a factor of 1/(1 − p), and <br/>3- Merge (θpre + λi ∑τi)<br/>where λi is the scaling term, representing the importance of each task vector to be merged.</p><p id="b3ac" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr"><em class="pe">1.b Merging With Data Requirement:</em></strong></p><p id="5de7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The merging methods that we discussed above require no data. However, there are approaches that do need data to determine the optimal weights for merging the parameters. These methods use data to compute the activations and then adjust the weights accordingly.</p><p id="050a" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">One such approach is <a class="af pa" href="https://arxiv.org/pdf/2111.09832" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Fisher Merging</strong></a>. Given K fine-tuned models, each trained on a different downstream task starting from a specific pretrained checkpoint, Fisher Merging performs a weighted summation of each model’s parameters. The weights are calculated using the Fisher information matrix, which requires some data from each task for the matrix construction.</p><p id="4bce" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In a related development, <a class="af pa" href="https://arxiv.org/pdf/2212.09849" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">RegMean</strong></a> significantly outperforms Fisher-weighted merging by recasting the model merging task as a linear regression problem. This method derives closed-form solutions for the weights of linear layers and interpolates other weights (like layer normalization and bias terms) evenly. Given K fine-tuned models and some data Xi i= 1,..,K, for each task, the linear layers of the merged model can be determined as follows:</p><figure class="ok ol om on oo op oh oi paragraph-image"><div class="oh oi ph"><img src="../Images/9ec5319efad0b1e71fc3d9fb24cce6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*VS6NOXdbwt6kem595_RYkw.png"/></div></figure><p id="bdf7" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">Where Wi is the linear layer from the ith fine-tuned model.</p><h1 id="1047" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk"><strong class="al">2. Merging Models with Identical Architectures but Different Initializations</strong></h1><p id="df80" class="pw-post-body-paragraph mi mj fq mk b go oc mm mn gr od mp mq mr oe mt mu mv of mx my mz og nb nc nd fj bk">Given models that have the same architecture and training dataset but different initializations, simple merging methods like linear model combination often fail to perform well. The main reason is that the weights of the models are not aligned. Hence, researchers have developed techniques to leverage the permutation symmetry of neural networks. By reordering the neurons of the models, their weights can align better, which makes the merging process more effective.</p><p id="a7b5" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://arxiv.org/pdf/2209.04836" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Git-Rebasin</strong></a> suggests permuting the weights of one model to match the configuration of another. Assume two models, A and B are given with the same architecture and training dataset, but their initializations and training data orders were different. The weights of each network can be permuted without changing its functionality, which means that swapping neurons in hidden layers can result in functionally equivalent models.</p><p id="75d9" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">They formulated this as an optimization problem to identify the optimal permutations of units across layers that align the two models’ parameters in the weight space. This alignment ensures that the models are in a similar “basin” of the loss landscape, which leads to a smooth and effective merging. To this goal, Git-Rebasin proposed the following three steps: <br/>1. For each layer, the problem of finding the best permutations is formulated as a Linear Assignment Problem (LAP). This step involves computing a matrix of activations and finding the optimal permutation matrix that aligns the activations.<br/>2. Given the optimal permutations for all layers, the weights of model B will be permuted.<br/>3. Linear model combination between the permuted weights of model B and the weights of model A lies within a low-loss basin in the loss landscape, which ensures that the merged model performs well.</p><p id="e75c" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://arxiv.org/pdf/2211.08403" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">REPAIR</strong></a> addresses a critical issue in the Rebasin merging method known as variance collapse, in which the hidden units have significantly smaller activation variance compared to the corresponding units of the original networks before they were interpolated. Therefore, the activations of neurons become nearly constant in deeper layers, hence the network will no longer even be able to differentiate between inputs. REPAIR resolves this issue by rescaling the activations of the interpolated networks to match the statistical properties of the original networks. By adjusting the means and variances of the activations, the interpolated network maintains functional variability throughout its layers. Applying the REPAIR method significantly reduces the interpolation barrier, improving the performance of interpolated models.</p><h1 id="0206" class="ng nh fq bf ni nj nk gq nl nm nn gt no np nq nr ns nt nu nv nw nx ny nz oa ob bk">3. <strong class="al">Merging Models with Different Architectures</strong></h1><p id="342e" class="pw-post-body-paragraph mi mj fq mk b go oc mm mn gr od mp mq mr oe mt mu mv of mx my mz og nb nc nd fj bk">In contrast to the methods discussed so far,<strong class="mk fr"> </strong><a class="af pa" href="https://github.com/arcee-ai/mergekit" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Frankenmerging</strong></a> does not fuse models into a single one, and instead stacks different layers of different models sequentially. Therefore, it is able to merge models with different architectures. <br/>For example, to construct an LLM with 40 layers, one might stack the first 24 layers from one LLM onto layers 25–40 from another LLM. This method has gained significant attention in style transfer in computer vision. Despite requiring a lot of trial and error and experimentation, it has led to impressive LLM models such as Goliath and Solar-10.7B [see <a class="af pa" href="https://huggingface.co/models?sort=downloads&amp;search=franken" rel="noopener ugc nofollow" target="_blank">here</a>].</p><figure class="ok ol om on oo op oh oi paragraph-image"><div role="button" tabindex="0" class="oq or ed os bh ot"><div class="oh oi pi"><img src="../Images/5b75c40130d9085905106d79368ab407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQglcVnNyxGe45HTHI7Wcg.png"/></div></div><figcaption class="ov ow ox oh oi oy oz bf b bg z dx">Fig.4 Overview of EvolutionaryOptimization approach (image from <a class="af pa" href="https://arxiv.org/pdf/2403.13187" rel="noopener ugc nofollow" target="_blank">paper</a>).</figcaption></figure><p id="6598" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><a class="af pa" href="https://arxiv.org/pdf/2403.13187" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">EvolutionaryOptimization</strong></a> proposes a framework to automatically merge a given set of foundation models, such that the merged model outperforms any individual model in the given set. This approach involves two main phases (see Fig. 4):</p><p id="75ae" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the first phase, this method uses TIES-Merging with DARE for layer-wise merging of N foundational models. The process is optimized by using an evolutionary algorithm guided by task-specific metrics (e.g., accuracy for MGSM, ROUGE score for VQA). To find unknown variables such as dropout percentages in DARE and weights of each model’s parameters in merging, the evolutionary optimization begins with a group of possible solutions that evolve over time. Through mutation (small random changes) and crossover (combining parts of two solutions), the best solutions are selected to create a new group of candidates. This iterative process leads to progressively better solutions.</p><p id="2517" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">In the second phase, where a set of N models is given, the goal is to find an optimal model with T layers using Frankenmerging. To reduce the search space and make the optimization tractable, all layers are laid out in sequential order (i.e., all layers in the i-th model followed by those in the i + 1-th model) and repeated r times. In this phase, the goal is to find an optimal indicator which determines the inclusion/exclusion of layers: if Indicator(i)&gt;0, the ith layer is included in the merged model; otherwise, it is excluded.</p><p id="a32b" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">The <strong class="mk fr">EvolutionaryOptimization </strong>process begins with applying the first phase to a collection of models. Then, the merged model from the first step is added to the given collection and the second phase is applied on this enlarged collection to find an optimal indicator which selects T layers for the final merged model. This approach applied to merge a Japanese LLM with an English Math LLM to build a Japanese Math LLM. The merged model achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even outperforming models with significantly more parameters, despite not being trained for such tasks.</p><blockquote class="pj"><p id="878e" class="pk pl fq bf pm pn po pp pq pr ps nd dx">The opinions expressed in this blog post are solely our own and do not reflect those of our employer.</p></blockquote><blockquote class="pb pc pd"><p id="9a84" class="mi mj pe mk b go pt mm mn gr pu mp mq mr pv mt mu mv pw mx my mz px nb nc nd fj bk"><strong class="mk fr"><em class="fq">Also Read Our Previous Post: </em></strong><a class="af pa" rel="noopener" target="_blank" href="/from-open-source-unimodal-to-multimodal-diy-techniques-for-building-foundational-models-e1df92276379">From Unimodals to Multimodality: DIY Techniques for Building Foundational Models</a></p></blockquote><p id="3998" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk"><strong class="mk fr"><em class="pe">References:</em></strong></p><p id="03bf" class="pw-post-body-paragraph mi mj fq mk b go ml mm mn gr mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd fj bk">[1] <a class="af pa" href="https://proceedings.mlr.press/v162/wortsman22a/wortsman22a.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Model soup</strong></a><strong class="mk fr">: </strong>Wortsman, Mitchell, et al. “Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.” <em class="pe">(</em>2022).<br/>[2] <a class="af pa" href="https://arxiv.org/pdf/2212.04089" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Task arithmetic</strong></a><strong class="mk fr">: </strong>Ilharco, Gabriel, et al. “Editing models with task arithmetic.” (2022).<br/>[3] <a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/1644c9af28ab7916874f6fd6228a9bcf-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">TIES</strong></a><strong class="mk fr">: </strong>Yadav, Prateek, et al. “Ties-merging: Resolving interference when merging models.” (2024).<br/>[4] <a class="af pa" href="https://openreview.net/pdf?id=fq0NaiU8Ex" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">DARE</strong></a>: Yu, Le, et al. “Language models are super mario: Absorbing abilities from homologous models as a free lunch.” <em class="pe">(</em>2024).<br/>[5] <a class="af pa" href="https://arxiv.org/pdf/2111.09832" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Fisher Merging</strong></a><strong class="mk fr"> </strong>Matena, Michael S., et al. “Merging models with fisher-weighted averaging.” (2022).<br/>[6] <a class="af pa" href="https://arxiv.org/pdf/2212.09849" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">RegMean</strong></a><strong class="mk fr">:</strong> Jin, Xisen, et al. “Dataless knowledge fusion by merging weights of language models.” (2022).<br/>[7] <a class="af pa" href="https://arxiv.org/pdf/2209.04836" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Git-Rebasin</strong></a><strong class="mk fr">: </strong>Ainsworth, Samuel K., et al. “Git re-basin: Merging models modulo permutation symmetries.” (2022).<br/>[8] <a class="af pa" href="https://arxiv.org/pdf/2211.08403" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">REPAIR</strong></a><strong class="mk fr">: </strong>Jordan, Keller, et al. “Repair: Renormalizing permuted activations for interpolation repair.” (2022).<br/>[9] <a class="af pa" href="https://github.com/arcee-ai/mergekit" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">Frankenmerging</strong></a><strong class="mk fr">: </strong>Charles O. Goddard. 2024. mergekit. <br/>[10] <a class="af pa" href="https://arxiv.org/pdf/2403.13187" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">EvolutionaryOptimization</strong></a><strong class="mk fr">: </strong>Akiba, Takuya, et al. “Evolutionary optimization of model merging recipes.” (2024).<br/>[11] Shoemake, Ken. “<a class="af pa" href="https://dl.acm.org/doi/pdf/10.1145/325334.325242" rel="noopener ugc nofollow" target="_blank">Animating rotation with quaternion curves</a>.” (1985).<br/>[12] <a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2019/file/05e97c207235d63ceb1db43c60db7bbb-Paper.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="mk fr">LMC</strong></a><strong class="mk fr">:</strong> Nagarajan, Vaishnavh, et al. “Uniform convergence may be unable to explain generalization in deep learning.” (2019).<br/>[13] Kaddour, Jean, et al. “<a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/69b5534586d6c035a96b49c86dbeece8-Paper-Conference.pdf" rel="noopener ugc nofollow" target="_blank">When do flat minima optimizers work</a>?.” (2022)<br/>[14] Petzka, Henning, et al. “<a class="af pa" href="https://proceedings.neurips.cc/paper_files/paper/2021/file/995f5e03890b029865f402e83a81c29d-Paper.pdf" rel="noopener ugc nofollow" target="_blank">Relative flatness and generalization</a>.” (2021)</p></div></div></div></div>    
</body>
</html>