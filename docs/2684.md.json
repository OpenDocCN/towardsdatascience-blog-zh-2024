["```py\n$ git clone https://github.com/aws-samples/jira-ticket-classification.git\n\n$ cd jira-ticket-classification/terraform\n```", "```py\n$ terraform init\n\n$ terraform plan\n\n$ terraform apply\n```", "```py\ndef fetch_jira_issues(base_url, project_id, email, api_key):\n    url = f\"{base_url}/rest/api/3/search\"\n\n    # Calculate the date 8 days ago\n    eight_days_ago = (datetime.now() - timedelta(days=8)).strftime(\"%Y-%m-%d\")\n\n    # Create JQL\n    jql = f\"project = {project_id} AND created >= '{eight_days_ago}' ORDER BY created DESC\"\n\n    # Pass into params of request.\n    params = {\n        \"jql\": jql,\n        \"startAt\": 0\n    }\n    all_issues = []\n\n    auth = HTTPBasicAuth(email, api_key)\n    headers = {\"Accept\": \"application/json\"}\n\n    while True:\n        response = requests.get(url, headers=headers, params=params, auth=auth)\n        if response.status_code != 200:\n            raise Exception(f\"Failed to fetch issues for project {project_id}: {response.text}\")\n\n        data = json.loads(response.text)\n        issues = data['issues']\n        all_issues.extend(issues)\n\n        if len(all_issues) >= data['total']:\n            break\n\n        params['startAt'] = len(all_issues)\n\n    return all_issues\n```", "```py\ndef upload_to_s3(csv_string, bucket, key):\n    try:\n        s3_client.put_object(\n            Bucket=bucket,\n            Key=key,\n            Body=csv_string,\n            ContentType='text/csv'\n        )\n    except Exception as e:\n        raise Exception(f\"Failed to upload CSV to S3: {str(e)}\")\n```", "```py\nimport boto3 \n\n# Initialize Boto3 Glue client\nglue_client = boto3.client('glue')\n\ndef handler(event, context):\n    # Print event for debugging\n    print(f\"Received event: {json.dumps(event)}\")\n\n    # Get bucket name and object key (file name) from the S3 event\n    try:\n        s3_event = event['Records'][0]['s3']\n        s3_bucket = s3_event['bucket']['name']\n        s3_key = s3_event['object']['key']\n    except KeyError as e:\n        print(f\"Error parsing S3 event: {str(e)}\")\n        raise\n\n    response = glue_client.start_job_run(\n        JobName=glue_job_name,\n        Arguments={\n            '--S3_BUCKET': s3_bucket,\n            '--NEW_CSV_FILE': s3_key\n        }\n    )\n```", "```py\nSYSTEM_PROMPT = '''\nYou are a support ticket assistant. You are given fields of a Jira ticket and your task is to classify the ticket based on those fields\n\nBelow is the list of potential classifications along with descriptions of those classifications.\n<classifications>\nACCESS_PERMISSIONS_REQUEST: Used when someone doesn't have the write permissions or can't log in to something or they can't get the correct IAM credentials to make a service work.\nBUG_FIXING: Used when something is failing or a bug is found. Often times the descriptions include logs or technical information.\nCREATING_UPDATING_OR_DEPRECATING_DOCUMENTATION: Used when documentation is out of date. Usually references documentation in the text.\nMINOR_REQUEST: This is rarely used. Usually a bug fix but it's very minor. If it seems even remotely complicated use BUG_FIXING.\nSUPPORT_TROUBLESHOOTING: Used when asking for support for some engineering event. Can also look like an automated ticket.\nNEW_FEATURE_WORK: Usually describes a new feature ask or something that isn't operational.\n</classifications>\n\nThe fields available and their descriptions are below.\n<fields>\nSummmary: This is a summary or title of the ticket\nDescription: The description of the issue in natural language. The majority of context needed to classify the text will come from this field\n</fields>\n\n<rules>\n* It is possible that some fields may be empty in which case ignore them when classifying the ticket\n* Think through your reasoning before making the classification and place your thought process in <thinking></thinking> tags. This is your space to think and reason about the ticket classificaiton.\n* Once you have finished thinking, classify the ticket using ONLY the classifications listed above and place it in <answer></answer> tags.\n</rules>'''\n\nUSER_PROMPT = '''\nUsing only the ticket fields below:\n\n<summary_field>\n{summary}\n</summary_field>\n\n<description_field>\n{description}\n</description_field>\n\nClassify the ticket using ONLY 1 of the classifications listed in the system prompt. Remember to think step-by-step before classifying the ticket and place your thoughts in <thinking></thinking> tags.\nWhen you are finished thinking, classify the ticket and place your answer in <answer></answer> tags. ONLY place the classifaction in the answer tags. Nothing else.\n'''\n```", "```py\nimport boto3\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport re\nfrom typing import List, Dict\nfrom prompts import USER_PROMPT, SYSTEM_PROMPT\n\nclass TicketClassifier:\n    SONNET_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n    HAIKU_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n    HYPER_PARAMS = {\"temperature\": 0.35, \"topP\": .3}\n    REASONING_PATTERN = r'<thinking>(.*?)</thinking>'\n    CORRECTNESS_PATTERN = r'<answer>(.*?)</answer>'\n\n    def __init__(self):\n        self.bedrock = boto3.client('bedrock-runtime')\n\n    def classify_tickets(self, tickets: List[Dict[str, str]]) -> List[Dict[str, str]]:\n        prompts = [self._create_chat_payload(t) for t in tickets]\n        responses = self._call_threaded(prompts, self._call_bedrock)\n        formatted_responses = [self._format_results(r) for r in responses]\n        return [{**d1, **d2} for d1, d2 in zip(tickets, formatted_responses)]\n\n    def _call_bedrock(self, message_list: list[dict]) -> str:\n        response = self.bedrock.converse(\n            modelId=self.HAIKU_ID,\n            messages=message_list,\n            inferenceConfig=self.HYPER_PARAMS,\n            system=[{\"text\": SYSTEM_PROMPT}]\n        )\n        return response['output']['message']['content'][0]['text']\n\n    def _call_threaded(self, requests, function):\n        future_to_position = {}\n        with ThreadPoolExecutor(max_workers=5) as executor:\n            for i, request in enumerate(requests):\n                future = executor.submit(function, request)\n                future_to_position[future] = i\n            responses = [None] * len(requests)\n            for future in as_completed(future_to_position):\n                position = future_to_position[future]\n                try:\n                    response = future.result()\n                    responses[position] = response\n                except Exception as exc:\n                    print(f\"Request at position {position} generated an exception: {exc}\")\n                    responses[position] = None\n        return responses\n\n    def _create_chat_payload(self, ticket: dict) -> dict:\n        user_prompt = USER_PROMPT.format(summary=ticket['Summary'], description=ticket['Description'])\n        user_msg = {\"role\": \"user\", \"content\": [{\"text\": user_prompt}]}\n        return [user_msg]\n\n    def _format_results(self, model_response: str) -> dict:\n        reasoning = self._extract_with_regex(model_response, self.REASONING_PATTERN)\n        correctness = self._extract_with_regex(model_response, self.CORRECTNESS_PATTERN)\n        return {'Model Answer': correctness, 'Reasoning': reasoning}\n\n    @staticmethod\n    def _extract_with_regex(response, regex):\n        matches = re.search(regex, response, re.DOTALL)\n        return matches.group(1).strip() if matches else None\n```", "```py\nimport boto3\nimport io\nimport csv\n\ns3 = boto3.client('s3')\n\ndef upload_csv(data: List[Dict[str, str]]) -> None:\n      csv_buffer = io.StringIO()\n      writer = csv.DictWriter(csv_buffer, fieldnames=data[0].keys())\n      writer.writeheader()\n      writer.writerows(data)\n\n      current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n      filename = f\"processed/processed_{current_time}.csv\"\n\n      s3.put_object(\n          Bucket=self.bucket_name,\n          Key=filename,\n          Body=csv_buffer.getvalue()\n      )\n```"]