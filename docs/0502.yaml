- en: Building a Secure and Scalable Data and AI Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/building-a-secure-and-scalable-data-and-ai-platform-074e191b291f?source=collection_archive---------7-----------------------#2024-02-22](https://towardsdatascience.com/building-a-secure-and-scalable-data-and-ai-platform-074e191b291f?source=collection_archive---------7-----------------------#2024-02-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Empowering business through data-driven decision-making
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rizviadil?source=post_page---byline--074e191b291f--------------------------------)[![Adil
    Rizvi](../Images/fd11151beb5f2ff4b4d909c0d7c8c93e.png)](https://medium.com/@rizviadil?source=post_page---byline--074e191b291f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--074e191b291f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--074e191b291f--------------------------------)
    [Adil Rizvi](https://medium.com/@rizviadil?source=post_page---byline--074e191b291f--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--074e191b291f--------------------------------)
    ·7 min read·Feb 22, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5b4d7ee051881df1ffd88ff1f904f35.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Igor Omilaev](https://unsplash.com/@omilaev?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Over the last four years, I had the golden opportunity to lead the strategy,
    design, and implementation of global-scale big data and AI platforms across not
    one but two public cloud platforms — AWS and GCP. Furthermore, my team operationalized
    70+ data science/machine learning (DSML) use cases and 10 digital applications,
    contributing to ~$100M+ in revenue growth.
  prefs: []
  type: TYPE_NORMAL
- en: The journey was full of exciting challenges and a few steep learning curves,
    but the end results were highly impactful. Through this post, I want to share
    my learnings and experiences, which will help fellow technology innovators think
    through their planning process and leapfrog their implementation.
  prefs: []
  type: TYPE_NORMAL
- en: This post will focus mainly on the foundational construct to provide a holistic
    picture of the overall production ecosystem. In later posts, I will discuss the
    technology choices and share more detailed prescriptive.
  prefs: []
  type: TYPE_NORMAL
- en: Let me begin by giving you a view of the building blocks of the data and AI
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86a1dd7bada1866684f12b808c45d4bc.png)'
  prefs: []
  type: TYPE_IMG
- en: End to end block level architecture of data and AI platform
  prefs: []
  type: TYPE_NORMAL
- en: Thinking through the end-to-end architecture is an excellent idea as you can
    avoid the common trap of getting things done quickly and dirty. After all, the
    output of your ML model is as good as the data you are feeding it. And you dont
    want to compromise on data security and integrity.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Data Acquisition and Ingestion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a well-architected DataOps framework is essential to the overall data
    onboarding process. Much depends on the source generating the data (structured
    vs. unstructured) and how you receive it (batch, replication, near real-time,
    real-time).
  prefs: []
  type: TYPE_NORMAL
- en: As you ingest the data, there are different ways to onboard it -
  prefs: []
  type: TYPE_NORMAL
- en: Extract → Load (no transformation needed)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract → Load → Transform (primarily used in batch uploads)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract → Transform → Load (works best for streaming data)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feature engineers must further combine the data to create features (feature
    engineering) for machine learning use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Data Storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Choosing the optimal data storage is essential, and object storage buckets like
    S3, GCS, or Blob Storage are the best options for bringing in raw data, primarily
    for unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: For pure analytics use cases, plus if you are bringing SQL structured data,
    you can land the data directly into a cloud data warehouse (Big Query, etc.) as
    well. Many engineering teams also prefer using a data warehouse store (different
    from object storage). Your choice will depend on the use cases and costs involved.
    Tread wisely!
  prefs: []
  type: TYPE_NORMAL
- en: Typically, you can directly bring the data from internal and external (1st and
    3rd party) sources without any intermediate step.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are a few cases where the data provider will need access to your
    environment for data transactions. Plan a 3rd party landing zone in a DMZ setup
    to prevent exposing your entire data system to vendors.
  prefs: []
  type: TYPE_NORMAL
- en: Also, for compliance-related data like PCI, PII, and regulated data like GDPR,
    MLPS, AAPI, CCPA, etc., create structured storage zones to treat the data sensibly
    right from the get-go.
  prefs: []
  type: TYPE_NORMAL
- en: Remember to plan for retention and backup policies depending on your ML Model
    and Analytics reports’ time-travel or historical context requirements. While storage
    is cheap, accumulating data over time adds to the cost exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Data Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While most organizations are good at bringing and storing data, most engineering
    teams need help to make data consumable for end users.
  prefs: []
  type: TYPE_NORMAL
- en: The main factors leading to poor adoption are —
  prefs: []
  type: TYPE_NORMAL
- en: Inadequate data literacy in the org
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Absence of a well-defined data catalog and data dictionary (metadata)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inaccessibility to the query interface
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data teams must partner with legal, privacy, and security teams to understand
    the national and regional data regulations and compliance requirements for proper
    data governance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several methods that you could use for implementing data governance are:'
  prefs: []
  type: TYPE_NORMAL
- en: Data masking and anonymization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Attribute-based access control
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data localization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Failure to properly secure storage and access to data could expose the organization
    to legal issues and associated penalties.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Data Consumption Patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the data gets transformed and enriched to business KPIs, the presentation
    and consumption of data have different facets.
  prefs: []
  type: TYPE_NORMAL
- en: For pure visualization and dashboarding, simple access to stored data and query
    interface is all you will need.
  prefs: []
  type: TYPE_NORMAL
- en: As requirements become more complex, such as presenting data to machine learning
    models, you have to implement and enhance the feature store. This domain needs
    maturity, and most cloud-native solutions are still in the early stages of production-grade
    readiness.
  prefs: []
  type: TYPE_NORMAL
- en: Also, look for a horizontal data layer where you can present data through APIs
    for consumption by other applications. GraphQL is one good solution to help create
    the microservices layer, which significantly helps with ease of access (data as
    a service).
  prefs: []
  type: TYPE_NORMAL
- en: As you mature this area, look at structuring the data into data product domains
    and finding data stewards within business units who can be the custodians of that
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Post-data processing, there is a two-step approach to Machine Learning — Model
    Development and Model Deployment & Governance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aeaae0f8c47b83ce441d4021957e4aa2.png)'
  prefs: []
  type: TYPE_IMG
- en: Operationalizing the AI Platform
  prefs: []
  type: TYPE_NORMAL
- en: In the Model Development phase, ML Engineers partner closely with the Data Scientists
    until the model is packaged and ready to be deployed. Choosing ML Frameworks and
    Features and partnering with DS on Hyperparameter Tuning and Model Training are
    all part of the development lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: Creating deployment pipelines and choosing the tech stack for operationalizing
    and serving the model fall under MLOps. MLOps Engineers also provide ML Model
    Management, which includes monitoring, scoring, drift detection, and initiating
    the retraining.
  prefs: []
  type: TYPE_NORMAL
- en: Automating all these steps in the ML Model Lifecycle helps with scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget to store all your trained models in a ML model registry and promote
    reuse for efficient operations.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Production Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Serving the model output requires constant collaboration with other functional
    areas. Advanced planning and open communication channels are critical to ensure
    that release calendars are well-aligned. Please do so to avoid missed deadlines,
    technology choice conflicts, and troubles at the integration layer.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the consumption layer and deployment targets, you would publish
    model output (model endpoint) through APIs or have the applications directly fetch
    the inference from the store. Using GraphQL in conjunction with the API Gateway
    is an efficient way to accomplish it.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Security Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Detach the management plane and create a shared services layer, which will be
    your main entry-exit point for the cloud accounts. It will also be your meet-me-room
    for external and internal public/private clouds within your organization.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/66fd8684ad6efe3f6d0072fa65d7d688.png)'
  prefs: []
  type: TYPE_IMG
- en: Shared Services — Google Cloud Platform
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/157f6a0c9d8014462aa3477419aa670b.png)'
  prefs: []
  type: TYPE_IMG
- en: Shared Services — Amazon Web Services
  prefs: []
  type: TYPE_NORMAL
- en: Your service control policies (AWS) or organizational policy constraints (GCP)
    should be centralized and protect resources from being created or hosted without
    proper access controls.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. User-Management Interface / Consumption Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is wise to choose the structure of your cloud accounts in advance. You can
    structure them on lines of business (LOB) OR, product domains OR a mix of both.
    Also, design and segregate your development, staging and production environments.
  prefs: []
  type: TYPE_NORMAL
- en: It would be best if you also centralized your DevOps toolchain. I prefer a cloud-agnostic
    toolset to support the seamless integration and transition between a hybrid multi-cloud
    ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: For developer IDEs, there could be a mix of individual and shared IDEs. Make
    sure developers frequently check code into a code repository; otherwise, they
    risk losing work.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/96e0096a111f2540ccd38d6132fb3b77.png)'
  prefs: []
  type: TYPE_IMG
- en: GCP setup with cloud-agnostic DevSecOps toolchain
  prefs: []
  type: TYPE_NORMAL
- en: '**End-to-End Data Science Process**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Navigating through organizational dynamics and bringing stakeholders together
    on a common aligned goal is vital to successful production deployment and ongoing
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: I am sharing the cross-functional workflows and processes that make this complex
    engine run smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3325cc3d0412a0b644d4a2dceff6779b.png)'
  prefs: []
  type: TYPE_IMG
- en: End to end data science model deployment process
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hopefully, this post triggered your thoughts, sparked new ideas, and helped
    you visualize the complete picture of your undertaking. It is a complex task,
    but with a well-thought-out design, properly planned execution, and a lot of cross-functional
    partnerships, you will navigate it easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'One final piece of advice: Don’t create technology solutions just because it
    seems cool. Start by understanding the business problem and assessing the potential
    return on investment. Ultimately, the goal is to create business value and contribute
    to the company’s revenue growth.'
  prefs: []
  type: TYPE_NORMAL
- en: Good luck with building or maturing your data and AI platform.
  prefs: []
  type: TYPE_NORMAL
- en: Bon Voyage!
  prefs: []
  type: TYPE_NORMAL
- en: ~ Adil {[LinkedIn](https://www.linkedin.com/in/rizviadil/)}
  prefs: []
  type: TYPE_NORMAL
- en: '*<< Unless otherwise noted, all images are by the author>>*'
  prefs: []
  type: TYPE_NORMAL
