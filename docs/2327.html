<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Building an Interactive UI for Llamaindex Workflows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Building an Interactive UI for Llamaindex Workflows</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-an-interactive-ui-for-llamaindex-workflows-842dd7abedde?source=collection_archive---------3-----------------------#2024-09-24">https://towardsdatascience.com/building-an-interactive-ui-for-llamaindex-workflows-842dd7abedde?source=collection_archive---------3-----------------------#2024-09-24</a></blockquote><div><div class="em fe ff fg fh fi"/><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><div/><div><h2 id="4dc6" class="pw-subtitle-paragraph gn fp fq bf b go gp gq gr gs gt gu gv gw gx gy gz ha hb hc cq dx">A guide to integrating human-in-the-loop interactions using Llamaindex, FastAPI, and Streamlit</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="hd he hf hg hh ab"><div><div class="ab hi"><div><div class="bm" aria-hidden="false"><a href="https://medium.com/@lzchen.cs?source=post_page---byline--842dd7abedde--------------------------------" rel="noopener follow"><div class="l hj hk by hl hm"><div class="l ed"><img alt="Lingzhen Chen" class="l ep by dd de cx" src="../Images/9014cbac032238d8a5c9f4708ba6ffcb.png" width="44" height="44" loading="lazy" data-testid="authorPhoto" data-original-src="https://miro.medium.com/v2/da:true/resize:fill:88:88/0*CEIWddUP5Ec9aKCd"/><div class="hn by l dd de em n ho eo"/></div></div></a></div></div><div class="hp ab ed"><div><div class="bm" aria-hidden="false"><a href="https://towardsdatascience.com/?source=post_page---byline--842dd7abedde--------------------------------" rel="noopener follow"><div class="l hq hr by hl hs"><div class="l ed"><img alt="Towards Data Science" class="l ep by br ht cx" src="../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto" data-original-src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg"/><div class="hn by l br ht em n ho eo"/></div></div></a></div></div></div></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="hu ab q"><div class="ab q hv"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b hw hx bk"><a class="af ag ah ai aj ak al am an ao ap aq ar hy" data-testid="authorName" href="https://medium.com/@lzchen.cs?source=post_page---byline--842dd7abedde--------------------------------" rel="noopener follow">Lingzhen Chen</a></p></div></div></div><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span><p class="bf b hw hx dx"><button class="ib ic ah ai aj ak al am an ao ap aq ar id ie if" disabled="">Follow</button></p></div></div></span></div></div><div class="l ig"><span class="bf b bg z dx"><div class="ab cn ih ii ij"><div class="ik il ab"><div class="bf b bg z dx ab im"><span class="in l ig">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar hy ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page---byline--842dd7abedde--------------------------------" rel="noopener follow"><p class="bf b bg z io ip iq ir is it iu iv bk">Towards Data Science</p></a></div></div></div><div class="h k"><span class="hz ia" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div></div><span class="bf b bg z dx"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="iw ix l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z dx">·</span></span></div><span data-testid="storyPublishDate">Sep 24, 2024</span></div></span></div></span></div></div></div><div class="ab cp iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn"><div class="h k w ea eb q"><div class="kd l"><div class="ab q ke kf"><div class="pw-multi-vote-icon ed in kg kh ki"><div class=""><div class="kj kk kl km kn ko kp am kq kr ks ki"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM15.421 1.84l-1.185-.388-.338 2.5zM9.757 1.452l-1.184.389 1.523 2.112zM20.253 11.84 17.75 7.438c-.238-.353-.57-.584-.93-.643a.96.96 0 0 0-.753.183 1.13 1.13 0 0 0-.443.695c.014.019.03.033.044.053l2.352 4.138c1.614 2.95 1.1 5.771-1.525 8.395a7 7 0 0 1-.454.415c.997-.13 1.927-.61 2.773-1.457 2.705-2.704 2.517-5.585 1.438-7.377M12.066 9.01c-.129-.687.08-1.299.573-1.773l-2.062-2.063a1.123 1.123 0 0 0-1.555 0 1.1 1.1 0 0 0-.273.521z" clip-rule="evenodd"/><path fill-rule="evenodd" d="M14.741 8.309c-.18-.267-.446-.455-.728-.502a.67.67 0 0 0-.533.127c-.146.113-.59.458-.199 1.296l1.184 2.503a.448.448 0 0 1-.236.755.445.445 0 0 1-.483-.248L7.614 6.106A.816.816 0 1 0 6.459 7.26l3.643 3.644a.446.446 0 1 1-.631.63L5.83 7.896l-1.03-1.03a.82.82 0 0 0-1.395.577.81.81 0 0 0 .24.576l1.027 1.028 3.643 3.643a.444.444 0 0 1-.144.728.44.44 0 0 1-.486-.098l-3.64-3.64a.82.82 0 0 0-1.335.263.81.81 0 0 0 .178.89l1.535 1.534 2.287 2.288a.445.445 0 0 1-.63.63l-2.287-2.288a.813.813 0 0 0-1.393.578c0 .216.086.424.238.577l4.403 4.403c2.79 2.79 5.495 4.119 8.681.931 2.269-2.271 2.708-4.588 1.342-7.086z" clip-rule="evenodd"/></svg></div></div></div><div class="pw-multi-vote-count l kt ku kv kw kx ky kz"><p class="bf b dy z dx"><span class="kk">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao kj lc ld ab q ee le lf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" class="lb"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"/></svg><p class="bf b dy z dx"><span class="pw-responses-count la lb">2</span></p></button></div></div></div><div class="ab q jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="lg k j i d"/><div class="h k"><div><div class="bm" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ee ah ai aj ak al lh an ao ap id li lj lk" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24" class="av"><path fill="#000" d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4z"/></svg></button></div></div></div><div class="ep ll cn"><div class="l ae"><div class="ab cb"><div class="lm ln lo lp lq lr ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">Share</p></div></button></div></div></div><div class="bm" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ee ah ai aj ak al lh an ao ap id ls lt lf lu lv lw lx ly s lz ma mb mc md me mf u mg mh mi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewbox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.385 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41m5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59s1.02-.2 1.41-.59c.4-.39.59-.86.59-1.41s-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59s-.58.86-.58 1.41m5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59s1.03-.2 1.42-.59.58-.86.58-1.41-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59s-.58.86-.58 1.41" clip-rule="evenodd"/></svg><div class="j i d"><p class="bf b bg z dx">More</p></div></button></div></div></div></div></div></div></div></div></div><p id="b36c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In my last article, I demonstrated how I use LlamaIndex workflows to streamline my research and presentation process. I built a workflow that takes a research topic, finds related articles on arxiv.org, creates summaries for the papers, and generates a PowerPoint slide deck to present the papers. You can read the full walk-through here:</p><div class="nf ng nh ni nj nk"><a rel="noopener follow" target="_blank" href="/how-i-streamline-my-research-and-presentation-with-llamaindex-workflows-3d75a9a10564?source=post_page-----842dd7abedde--------------------------------"><div class="nl ab ig"><div class="nm ab co cb nn no"><h2 class="bf fr hw z io np iq ir nq it iv fp bk">How I Streamline My Research and Presentation with LlamaIndex Workflows</h2><div class="nr l"><h3 class="bf b hw z io np iq ir nq it iv dx">An example of orchestrating AI workflow with robustness, flexibility and controllability</h3></div><div class="ns l"><p class="bf b dy z io np iq ir nq it iv dx">towardsdatascience.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny lr nk"/></div></div></a></div><p id="0a58" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To continue building on the workflow and make it more user-friendly, I implemented a UI with Streamlit to enhance the user experience. The UI displays progress updates of the workflow execution, integrates user input, enables real-time user feedback, and renders the final generated slide deck.</p><figure class="oc od oe of og oh nz oa paragraph-image"><div role="button" tabindex="0" class="oi oj ed ok bh ol"><div class="nz oa ob"><img src="../Images/943a490d724acbf5ce0f3ce0d5b7e379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TS-SXeX_nAyldQhw82L5uw.gif"/></div></div><figcaption class="on oo op nz oa oq or bf b bg z dx">The Streamlit UI (Screen recording by author)</figcaption></figure><p id="5743" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">You can check out the full code on my <a class="af os" href="https://github.com/lz-chen/research-agent" rel="noopener ugc nofollow" target="_blank">Github</a>. In this article, I will walk through some key points on the UI implementation and the integration between the frontend and the backend:</p><p id="953c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Backend enhancements:</strong></p><ul class=""><li id="752a" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ot ou ov bk">Update the workflow to support sending streaming event</li><li id="b21e" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Update the workflow to pause execution and wait for user inputs</li><li id="3a91" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Host several endpoints using FastAPI for running workflow, accepting user inputs, and downloading files, enabling async processes and streaming messages</li></ul><p id="728c" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Frontend UI features:</strong></p><ul class=""><li id="522e" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ot ou ov bk">Send requests to the backend and display event data streamed from the backend in an expander</li><li id="d56b" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Display related information in a container and collect user input, if user input is required</li><li id="2649" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Render the final generated slide deck</li><li id="2dca" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Provide a button for the user to download the final file</li></ul><p id="20e7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk"><strong class="ml fr">Putting it all together:</strong></p><ul class=""><li id="0de3" class="mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne ot ou ov bk">Separate frontend and backend dependencies and build by using distinct <code class="cx pb pc pd pe b">pyproject.toml</code> and <code class="cx pb pc pd pe b">Dockerfile</code></li><li id="8301" class="mj mk fq ml b go ow mn mo gr ox mq mr ms oy mu mv mw oz my mz na pa nc nd ne ot ou ov bk">Use <code class="cx pb pc pd pe b">docker-compose</code> to build launch all services</li></ul></div></div></div><div class="ab cb pf pg ph pi" role="separator"><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="3814" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">When starting the workflow from the terminal, it is straightforward to see which step it is executing and the logging we put in those steps.</p><figure class="oc od oe of og oh nz oa paragraph-image"><div role="button" tabindex="0" class="oi oj ed ok bh ol"><div class="nz oa pn"><img src="../Images/20ff5b34a307eada9bf3fc5771f5eab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Byz7z1brlUSQb64OpxG2Q.png"/></div></div><figcaption class="on oo op nz oa oq or bf b bg z dx">Terminal log for the workflow execution (Screenshot by author)</figcaption></figure><p id="d2ed" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We can also enable the human-in-the-loop interaction by simply using <code class="cx pb pc pd pe b">user_feedback = input()</code>in the workflow. This will pause the workflow and wait for the user input (See the human-in-the-loop example in this official Llamaindex <a class="af os" href="https://docs.llamaindex.ai/en/stable/examples/workflow/human_in_the_loop_story_crafting/" rel="noopener ugc nofollow" target="_blank">notebook</a>). However, to be able to achieve the same functionality in a user-friendly interface, we need additional modifications to the original workflow.</p><h1 id="8827" class="po pp fq bf pq pr ps gq pt pu pv gt pw px py pz qa qb qc qd qe qf qg qh qi qj bk">Sending streaming events from the workflow</h1><p id="3a3a" class="pw-post-body-paragraph mj mk fq ml b go qk mn mo gr ql mq mr ms qm mu mv mw qn my mz na qo nc nd ne fj bk">Workflow can take a long time to execute, so for a better user experience, Llamaindex provided a way to send streaming events to indicate the progress of the workflow, as shown in the notebook <a class="af os" href="https://docs.llamaindex.ai/en/stable/understanding/workflows/stream/" rel="noopener ugc nofollow" target="_blank">here</a>. In my workflow, I define a <code class="cx pb pc pd pe b">WorkflowStreamingEvent</code> class to include useful information about the event message, such as the type of the event, and from which step it is sent:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="f751" class="qs pp fq pe b bg qt qu l qv qw">class WorkflowStreamingEvent(BaseModel):<br/>    event_type: Literal["server_message", "request_user_input"] = Field(<br/>        ..., description="Type of the event"<br/>    )<br/>    event_sender: str = Field(<br/>        ..., description="Sender (workflow step name) of the event"<br/>    )<br/>    event_content: Dict[str, Any] = Field(..., description="Content of the event")</span></pre><p id="7914" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To enable sending streaming events, the workflow step needs to have access to the shared context, which is done by adding <code class="cx pb pc pd pe b">@step(pass_context=True)</code> decorator to the step definition. Then in the step definition, we can send event messages about the progress through the context. For example, in the <code class="cx pb pc pd pe b">tavily_query()</code> step:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="65b5" class="qs pp fq pe b bg qt qu l qv qw">@step(pass_context=True)<br/>async def tavily_query(self, ctx: Context, ev: StartEvent) -&gt; TavilyResultsEvent:<br/>    ctx.data["research_topic"] = ev.user_query<br/>    query = f"arxiv papers about the state of the art of {ev.user_query}"<br/>    ctx.write_event_to_stream(<br/>        Event(<br/>            msg=WorkflowStreamingEvent(<br/>                event_type="server_message",<br/>                event_sender=inspect.currentframe().f_code.co_name,<br/>                event_content={"message": f"Querying Tavily with: '{query}'"},<br/>            ).model_dump()<br/>        )<br/>    )</span></pre><p id="374e" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In this example, we set the <code class="cx pb pc pd pe b">event_type</code> to be <code class="cx pb pc pd pe b">“server_message”</code> . It means that it is an update message and no user action is required. We have another type of event <code class="cx pb pc pd pe b">"request_user_input"</code> that indicates a user input is needed. For example, in the <code class="cx pb pc pd pe b">gather_feedback_outline()</code> step in the workflow, after generating the slide text outlines from the original paper summary, a message is sent to prompt the user to provide approval and feedback on the outline text:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="97de" class="qs pp fq pe b bg qt qu l qv qw">@step(pass_context=True)<br/>    async def gather_feedback_outline(<br/>        self, ctx: Context, ev: OutlineEvent<br/>    ) -&gt; OutlineFeedbackEvent | OutlineOkEvent:<br/>        """Present user the original paper summary and the outlines generated, gather feedback from user"""<br/>        ...<br/><br/>        # Send a special event indicating that user input is needed<br/>        ctx.write_event_to_stream(<br/>            Event(<br/>                msg=json.dumps(<br/>                    {<br/>                        "event_type": "request_user_input",<br/>                        "event_sender": inspect.currentframe().f_code.co_name,<br/>                        "event_content": {<br/>                            "summary": ev.summary,<br/>                            "outline": ev.outline.dict(),<br/>                            "message": "Do you approve this outline? If not, please provide feedback.",<br/>                        },<br/>                    }<br/>                )<br/>            )<br/>        )<br/>        <br/>        ...</span></pre><p id="53a7" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">These events are handled differently in the backend API and the frontend logic, which I will describe in detail in the later sections of this article.</p><h1 id="730a" class="po pp fq bf pq pr ps gq pt pu pv gt pw px py pz qa qb qc qd qe qf qg qh qi qj bk">Pausing the workflow to wait for user input</h1><figure class="oc od oe of og oh nz oa paragraph-image"><div role="button" tabindex="0" class="oi oj ed ok bh ol"><div class="nz oa qx"><img src="../Images/e95ddc55fad1afe523da3672c85e3168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOREQUWO8dmo0Tgz2aMpPg.png"/></div></div><figcaption class="on oo op nz oa oq or bf b bg z dx">Workflow steps that requires user feedback (Image by author)</figcaption></figure><p id="f37a" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">When sending a <code class="cx pb pc pd pe b">"request_user_input"</code> event to the user, we only want to proceed to the next step <strong class="ml fr">after</strong> we have received the user input. As shown in the workflow diagram above, it either proceeds to the <code class="cx pb pc pd pe b">outlines_with_layout()</code>step if the user approves the outline, or to the <code class="cx pb pc pd pe b">summary2outline()</code> step again if the user does not approve.</p><p id="9f81" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">This is achieved using the <code class="cx pb pc pd pe b">Future()</code> object from Python’s <code class="cx pb pc pd pe b">asyncio</code> library. In the <code class="cx pb pc pd pe b">SlideGenerationWorkflow</code> class, we set an attribute <code class="cx pb pc pd pe b">self.user_input_future = asyncio.Future()</code> that can be waited on in the <code class="cx pb pc pd pe b">gather_feedback_outline()</code> step. The subsequent execution of the workflow is conditioned on the content of the user feedback:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="fadc" class="qs pp fq pe b bg qt qu l qv qw">@step(pass_context=True)<br/>async def gather_feedback_outline(<br/>    self, ctx: Context, ev: OutlineEvent<br/>) -&gt; OutlineFeedbackEvent | OutlineOkEvent:<br/>    ...<br/><br/>    # Wait for user input<br/>    if not self.user_input_future.done():<br/>        user_response = await self.user_input_future<br/>        logger.info(f"gather_feedback_outline: Got user response: {user_response}")<br/>    <br/>        # Process user_response, which should be a JSON string<br/>        try:<br/>            response_data = json.loads(user_response)<br/>            approval = response_data.get("approval", "").lower().strip()<br/>            feedback = response_data.get("feedback", "").strip()<br/>        except json.JSONDecodeError:<br/>            # Handle invalid JSON<br/>            logger.error("Invalid user response format")<br/>            raise Exception("Invalid user response format")<br/>    <br/>        if approval == ":material/thumb_up:":<br/>            return OutlineOkEvent(summary=ev.summary, outline=ev.outline)<br/>        else:<br/>            return OutlineFeedbackEvent(<br/>                summary=ev.summary, outline=ev.outline, feedback=feedback<br/>            )</span></pre><h1 id="1452" class="po pp fq bf pq pr ps gq pt pu pv gt pw px py pz qa qb qc qd qe qf qg qh qi qj bk">The FastAPI backend</h1><p id="49f4" class="pw-post-body-paragraph mj mk fq ml b go qk mn mo gr ql mq mr ms qm mu mv mw qn my mz na qo nc nd ne fj bk">We set up the backend using fastAPI, expose a POST endpoint to handle requests, and initiate the workflow run. The asynchronous function <code class="cx pb pc pd pe b">run_workflow_endpoint()</code> takes <code class="cx pb pc pd pe b">ResearchTopic</code> as input. In the function, an asynchronous generator <code class="cx pb pc pd pe b">event_generator()</code> is defined, which creates a task to run the workflow and streams the events to the client as the workflow progresses. When the workflow finishes, it will also stream the final file results to the client.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="d756" class="qs pp fq pe b bg qt qu l qv qw"><br/>class ResearchTopic(BaseModel):<br/>    query: str = Field(..., example="example query")<br/><br/><br/>@app.post("/run-slide-gen")<br/>async def run_workflow_endpoint(topic: ResearchTopic):<br/>    workflow_id = str(uuid.uuid4())<br/><br/>    wf = SummaryAndSlideGenerationWorkflow(wid=workflow_id, timeout=2000, verbose=True)<br/>    wf.add_workflows(<br/>        summary_gen_wf=SummaryGenerationWorkflow(<br/>            wid=workflow_id, timeout=800, verbose=True<br/>        )<br/>    )<br/>    wf.add_workflows(<br/>        slide_gen_wf=SlideGenerationWorkflow(<br/>            wid=workflow_id, timeout=1200, verbose=True<br/>        )<br/>    )<br/><br/>    async def event_generator():<br/>        loop = asyncio.get_running_loop()<br/>        logger.debug(f"event_generator: loop id {id(loop)}")<br/>        yield f"{json.dumps({'workflow_id': workflow_id})}\n\n"<br/><br/>        task = asyncio.create_task(wf.run(user_query=topic.query))<br/>        logger.debug(f"event_generator: Created task {task}")<br/>        try:<br/>            async for ev in wf.stream_events():<br/>                logger.info(f"Sending message to frontend: {ev.msg}")<br/>                yield f"{ev.msg}\n\n"<br/>                await asyncio.sleep(0.1)  # Small sleep to ensure proper chunking<br/>            final_result = await task<br/><br/>            # Construct the download URL<br/>            download_pptx_url = f"http://backend:80/download_pptx/{workflow_id}"<br/>            download_pdf_url = f"http://backend:80/download_pdf/{workflow_id}"<br/><br/>            final_result_with_url = {<br/>                "result": final_result,<br/>                "download_pptx_url": download_pptx_url,<br/>                "download_pdf_url": download_pdf_url,<br/>            }<br/><br/>            yield f"{json.dumps({'final_result': final_result_with_url})}\n\n"<br/>        except Exception as e:<br/>            error_message = f"Error in workflow: {str(e)}"<br/>            logger.error(error_message)<br/>            yield f"{json.dumps({'event': 'error', 'message': error_message})}\n\n"<br/>        finally:<br/>            # Clean up<br/>            workflows.pop(workflow_id, None)<br/><br/>    return StreamingResponse(event_generator(), media_type="text/event-stream")</span></pre><p id="0cae" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In addition to this endpoint, there are endpoints for receiving user input from the client and handling file download requests. Since each workflow is assigned a unique workflow ID, we can map the user input received from the client to the correct workflow. By call the <code class="cx pb pc pd pe b">set_result()</code> on the awaiting <code class="cx pb pc pd pe b">Future</code>, the pending workflow can resume execution.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="ae35" class="qs pp fq pe b bg qt qu l qv qw">@app.post("/submit_user_input")<br/>async def submit_user_input(data: dict = Body(...)):<br/>    workflow_id = data.get("workflow_id")<br/>    user_input = data.get("user_input")<br/>    wf = workflows.get(workflow_id)<br/>    if wf and wf.user_input_future:<br/>        loop = wf.user_input_future.get_loop()  # Get the loop from the future<br/>        logger.info(f"submit_user_input: wf.user_input_future loop id {id(loop)}")<br/>        if not wf.user_input_future.done():<br/>            loop.call_soon_threadsafe(wf.user_input_future.set_result, user_input)<br/>            logger.info("submit_user_input: set_result called")<br/>        else:<br/>            logger.info("submit_user_input: future already done")<br/>        return {"status": "input received"}<br/>    else:<br/>        raise HTTPException(<br/>            status_code=404, detail="Workflow not found or future not initialized"<br/>        )</span></pre><p id="d8ec" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The download endpoint also identifies where the final file is located based on the workflow ID.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="a7ea" class="qs pp fq pe b bg qt qu l qv qw">@app.get("/download_pptx/{workflow_id}")<br/>async def download_pptx(workflow_id: str):<br/>    file_path = (<br/>        Path(settings.WORKFLOW_ARTIFACTS_PATH)<br/>        / "SlideGenerationWorkflow"<br/>        / workflow_id<br/>        / "final.pptx"<br/>    )<br/>    if file_path.exists():<br/>        return FileResponse(<br/>            path=file_path,<br/>            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",<br/>            filename=f"final.pptx",<br/>        )<br/>    else:<br/>        raise HTTPException(status_code=404, detail="File not found")</span></pre><h1 id="7b4d" class="po pp fq bf pq pr ps gq pt pu pv gt pw px py pz qa qb qc qd qe qf qg qh qi qj bk">The Streamlit frontend</h1><p id="f9e9" class="pw-post-body-paragraph mj mk fq ml b go qk mn mo gr ql mq mr ms qm mu mv mw qn my mz na qo nc nd ne fj bk">In the frontend page, after the user submits the research topic through <code class="cx pb pc pd pe b">st.text_input()</code>, a long-running process is started in a background thread in a new event loop for receiving the streamed events from the backend, without interfering with the rest of the page:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="5e48" class="qs pp fq pe b bg qt qu l qv qw">def start_long_running_task(url, payload, message_queue, user_input_event):<br/>    try:<br/>        loop = asyncio.new_event_loop()<br/>        asyncio.set_event_loop(loop)<br/>        loop.run_until_complete(<br/>            get_stream_data(url, payload, message_queue, user_input_event)<br/>        )<br/>        loop.close()<br/>    except Exception as e:<br/>        message_queue.put(("error", f"Exception in background thread: {str(e)}"))<br/><br/>...<br/><br/>def main():<br/><br/>  ...<br/><br/>  with st.sidebar:<br/>      with st.form(key="slide_gen_form"):<br/>          query = st.text_input(<br/>              "Enter the topic of your research:",<br/>          )<br/>          submit_button = st.form_submit_button(label="Submit")<br/><br/>  if submit_button:<br/>      # Reset the workflow_complete flag for a new workflow<br/>      st.session_state.workflow_complete = False<br/>      # Start the long-running task in a separate thread<br/>      if (<br/>          st.session_state.workflow_thread is None<br/>          or not st.session_state.workflow_thread.is_alive()<br/>      ):<br/>          st.write("Starting the background thread...")<br/><br/>          st.session_state.workflow_thread = threading.Thread(<br/>              target=start_long_running_task,<br/>              args=(<br/>                  "http://backend:80/run-slide-gen",<br/>                  {"query": query},<br/>                  st.session_state.message_queue,<br/>                  st.session_state.user_input_event,<br/>              ),<br/>          )<br/>          st.session_state.workflow_thread.start()<br/>          st.session_state.received_lines = []<br/>      else:<br/>          st.write("Background thread is already running.")</span></pre><p id="bb69" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">The event data streamed from the backend is fetched by <code class="cx pb pc pd pe b">httpx.AsyncClient</code> and put into a message queue for further processing. Different information is extracted depending on the event types. For event type <code class="cx pb pc pd pe b">“request_user_input”</code>, the thread is also paused until the user input is provided.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="5e8b" class="qs pp fq pe b bg qt qu l qv qw">async def fetch_streaming_data(url: str, payload: dict = None):<br/>    async with httpx.AsyncClient(timeout=1200.0) as client:<br/>        async with client.stream("POST", url=url, json=payload) as response:<br/>            async for line in response.aiter_lines():<br/>                if line:<br/>                    yield line<br/><br/><br/>async def get_stream_data(url, payload, message_queue, user_input_event):<br/>    # message_queue.put(("message", "Starting to fetch streaming data..."))<br/>    data_json = None<br/>    async for data in fetch_streaming_data(url, payload):<br/>        if data:<br/>            try:<br/>                data_json = json.loads(data)<br/>                if "workflow_id" in data_json:<br/>                    # Send workflow_id to main thread<br/>                    message_queue.put(("workflow_id", data_json["workflow_id"]))<br/>                    continue<br/>                elif "final_result" in data_json:<br/>                    # Send final_result to main thread<br/>                    message_queue.put(("final_result", data_json["final_result"]))<br/>                    continue<br/>                event_type = data_json.get("event_type")<br/>                event_sender = data_json.get("event_sender")<br/>                event_content = data_json.get("event_content")<br/>                if event_type in ["request_user_input"]:<br/>                    # Send the message to the main thread<br/>                    message_queue.put(("user_input_required", data_json))<br/>                    # Wait until user input is provided<br/>                    user_input_event.wait()<br/>                    user_input_event.clear()<br/>                    continue<br/>                else:<br/>                    # Send the line to the main thread<br/>                    message_queue.put(("message", format_workflow_info(data_json)))<br/>            except json.JSONDecodeError:  # todo: is this necessary?<br/>                message_queue.put(("message", data))<br/>        if data_json and "final_result" in data_json or "final_result" in str(data):<br/>            break  # Stop processing after receiving the final result</span></pre><p id="ad36" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">We store the messages in the <code class="cx pb pc pd pe b">st.session_state</code> and use a <code class="cx pb pc pd pe b">st.expander()</code> to display and update these streamed data.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="1d09" class="qs pp fq pe b bg qt qu l qv qw">if st.session_state.received_lines:<br/>    with expander_placeholder.container():<br/>        # Create or update the expander with the latest truncated line<br/>        expander = st.expander(st.session_state.expander_label)<br/>        for line in st.session_state.received_lines:<br/>            expander.write(line)<br/>            expander.divider()</span></pre><p id="d5e9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">To ensure the UI remains responsive and displays the event messages when they are being processed in a background thread, we use a customed <a class="af os" href="https://github.com/kmcgrady/streamlit-autorefresh" rel="noopener ugc nofollow" target="_blank">autorefresh</a> component to refresh the page at a set interval:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="679b" class="qs pp fq pe b bg qt qu l qv qw">if not st.session_state.workflow_complete:<br/>    st_autorefresh(interval=2000, limit=None, key="data_refresh")</span></pre><p id="27a9" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">When the streamed event is of type <code class="cx pb pc pd pe b">“request_user_input”</code>, we will display related information in a separate container and gather user feedback. As there can be multiple events that require user input from one workflow run, we put them in a message queue and make sure to assign a unique key to the <code class="cx pb pc pd pe b">st.feedback()</code>, <code class="cx pb pc pd pe b">st.text_area()</code> and <code class="cx pb pc pd pe b">st.button()</code> that are linked to each event to ensure the widgets don’t interfere with each other:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="52e1" class="qs pp fq pe b bg qt qu l qv qw">def gather_outline_feedback(placeholder):<br/>    container = placeholder.container()<br/>    with container:<br/>        if st.session_state.user_input_required:<br/>            data = st.session_state.user_input_prompt<br/>            event_type = data.get("event_type")<br/>            if event_type == "request_user_input":<br/>                summary = data.get("event_content").get("summary")<br/>                outline = data.get("event_content").get("outline")<br/>                prompt_message = data.get("event_content").get(<br/>                    "message", "Please review the outline."<br/>                )<br/><br/>                # display the content for user input<br/>                st.markdown("## Original Summary:")<br/>                st.text_area("Summary", summary, disabled=True, height=400)<br/>                st.divider()<br/>                st.markdown("## Generated Slide Outline:")<br/>                st.json(outline)<br/>                st.write(prompt_message)<br/><br/>                # Define unique keys for widgets<br/>                current_prompt = st.session_state.prompt_counter<br/>                approval_key = f"approval_state_{current_prompt}"<br/>                feedback_key = f"user_feedback_{current_prompt}"<br/><br/>                # Display the approval feedback widget<br/>                approval = st.feedback("thumbs", key=approval_key)<br/>                st.write(f"Current Approval state is: {approval}")<br/>                logging.info(f"Current Approval state is: {approval}")<br/><br/>                # Display the feedback text area<br/>                feedback = st.text_area(<br/>                    "Please provide feedback if you have any:", key=feedback_key<br/>                )<br/><br/>                # Handle the submission of user response<br/>                if st.button(<br/>                    "Submit Feedback", key=f"submit_response_{current_prompt}"<br/>                ):<br/>                    if not st.session_state.user_response_submitted:<br/>                        # Retrieve approval and feedback using unique keys<br/>                        approval_state = st.session_state.get(approval_key)<br/>                        user_feedback = st.session_state.get(feedback_key, "")<br/><br/>                        # Ensure approval_state is valid<br/>                        if approval_state not in [0, 1]:<br/>                            st.error("Please select an approval option.")<br/>                            return<br/><br/>                        user_response = {<br/>                            "approval": (<br/>                                ":material/thumb_down:"<br/>                                if approval_state == 0<br/>                                else ":material/thumb_up:"<br/>                            ),<br/>                            "feedback": user_feedback,<br/>                        }<br/>                        # Send the user's response to the backend<br/>                     <br/>                        try:<br/>                            response = requests.post(<br/>                                "http://backend:80/submit_user_input",<br/>                                json={<br/>                                    "workflow_id": st.session_state.workflow_id,<br/>                                    "user_input": json.dumps(user_response),<br/>                                },<br/>                            )<br/>                            response.raise_for_status()<br/>                            logging.info(<br/>                                f"Backend response for submitting approval: {response.status_code}"<br/>                            )<br/>                        except requests.RequestException as e:<br/>                            st.error(f"Failed to submit user input: {str(e)}")<br/>                            return<br/><br/>     ...</span></pre><p id="e75b" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">In the end, when the workflow run finally finishes, the frontend client will get a response that contains the path to the final generated files (same slide deck in pdf format for rendering in the UI and pptx format for downloading as the final result). We display the pdf file and create a button for downloading the pptx file:</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="2f5f" class="qs pp fq pe b bg qt qu l qv qw">  if "download_url_pdf" in st.session_state and st.session_state.download_url_pdf:<br/>      download_url_pdf = st.session_state.download_url_pdf<br/>      try:<br/>          # Fetch the PDF content<br/>          pdf_response = requests.get(download_url_pdf)<br/>          pdf_response.raise_for_status()<br/>          st.session_state.pdf_data = pdf_response.content<br/><br/>          st.markdown("### Generated Slide Deck:")<br/>          # Display the PDF using an iframe<br/>          st.markdown(<br/>              f'&lt;iframe src="data:application/pdf;base64,{base64.b64encode(st.session_state.pdf_data).decode()}" width="100%" height="600px" type="application/pdf"&gt;&lt;/iframe&gt;',<br/>              unsafe_allow_html=True,<br/>          )<br/>      except Exception as e:<br/>          st.error(f"Failed to load the PDF file: {str(e)}")<br/><br/>  # Provide the download button for PPTX if available<br/>  if (<br/>      "download_url_pptx" in st.session_state<br/>      and st.session_state.download_url_pptx<br/>  ):<br/>      download_url_pptx = st.session_state.download_url_pptx<br/>      try:<br/>          # Fetch the PPTX content<br/>          pptx_response = requests.get(download_url_pptx)<br/>          pptx_response.raise_for_status()<br/>          pptx_data = pptx_response.content<br/><br/>          st.download_button(<br/>              label="Download Generated PPTX",<br/>              data=pptx_data,<br/>              file_name="generated_slides.pptx",<br/>              mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",<br/>          )<br/>      except Exception as e:<br/>          st.error(f"Failed to load the PPTX file: {str(e)}")</span></pre><h1 id="72b6" class="po pp fq bf pq pr ps gq pt pu pv gt pw px py pz qa qb qc qd qe qf qg qh qi qj bk">Putting everything together with <code class="cx pb pc pd pe b">docker-compose</code></h1><p id="0296" class="pw-post-body-paragraph mj mk fq ml b go qk mn mo gr ql mq mr ms qm mu mv mw qn my mz na qo nc nd ne fj bk">We will create a multi-service Docker application with <code class="cx pb pc pd pe b">docker-compose</code> to run the frontend and backend apps.</p><pre class="oc od oe of og qp pe qq bp qr bb bk"><span id="4c43" class="qs pp fq pe b bg qt qu l qv qw">version: '3.8'<br/><br/>services:<br/>  backend:<br/>    build:<br/>      context: ./backend<br/>      args:<br/>        - --no-cache<br/>    ports:<br/>      - "8000:80"<br/>    networks:<br/>      - app-network<br/>    volumes:<br/>      - .env:/app/.env<br/>      - ./data:/app/data<br/>      - ./workflow_artifacts:/app/workflow_artifacts<br/>      - ~/.azure:/root/.azure<br/><br/>  frontend:<br/>    build:<br/>      context: ./frontend<br/>      args:<br/>        - --no-cache<br/>    ports:<br/>      - "8501:8501"<br/>    networks:<br/>      - app-network<br/><br/>networks:<br/>  app-network:</span></pre><p id="0067" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">That’s it! Just run <code class="cx pb pc pd pe b">docker-compose up</code>, and we now have an app that can run a research workflow based on the user’s input query, prompt the user for feedback during the execution, and display the final result to the user.</p></div></div></div><div class="ab cb pf pg ph pi" role="separator"><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl pm"/><span class="pj by bm pk pl"/></div><div class="fj fk fl fm fn"><div class="ab cb"><div class="ci bh ev ew ex ey"><p id="0a72" class="pw-post-body-paragraph mj mk fq ml b go mm mn mo gr mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne fj bk">Thank you for reading! Check out my <a class="af os" href="https://github.com/lz-chen/research-agent" rel="noopener ugc nofollow" target="_blank">GitHub</a> for the complete implementation. I look forward to hearing your thoughts, input, and feedbacks. I work as a Data Science Consultant at <a class="af os" href="https://inmeta.no/" rel="noopener ugc nofollow" target="_blank">Inmeta</a>, part of <a class="af os" href="https://www.crayon.com/no/" rel="noopener ugc nofollow" target="_blank">Crayon Group</a>. Feel free to connect with me on <a class="af os" href="https://www.linkedin.com/in/lingzhen-chen-76720680/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>.😊</p></div></div></div></div>    
</body>
</html>