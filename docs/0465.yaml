- en: Understanding Principal Component Analysis in PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/differentiable-principal-component-analysis-in-pytorch-using-power-iteration-ee93ac9fa2c4?source=collection_archive---------6-----------------------#2024-02-18](https://towardsdatascience.com/differentiable-principal-component-analysis-in-pytorch-using-power-iteration-ee93ac9fa2c4?source=collection_archive---------6-----------------------#2024-02-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Built-in function vs. numerical methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@nikolaus.correll?source=post_page---byline--ee93ac9fa2c4--------------------------------)[![Nikolaus
    Correll](../Images/948c44fe797b8057e20b39023c30027b.png)](https://medium.com/@nikolaus.correll?source=post_page---byline--ee93ac9fa2c4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ee93ac9fa2c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ee93ac9fa2c4--------------------------------)
    [Nikolaus Correll](https://medium.com/@nikolaus.correll?source=post_page---byline--ee93ac9fa2c4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ee93ac9fa2c4--------------------------------)
    ·8 min read·Feb 18, 2024
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '*PCA is an important tool for dimensionality reduction in data science and
    to compute grasp poses for robotic manipulation from point cloud data. PCA can
    also directly used within a larger machine learning framework as it is differentiable.
    Using the two principal components of a point cloud for robotic grasping as an
    example, we will derive a numerical implementation of the PCA, which will help
    to understand what PCA is and what it does.*'
  prefs: []
  type: TYPE_NORMAL
- en: If you are not a medium subscriber, read this story for free [here](https://medium.com/towards-data-science/differentiable-principal-component-analysis-in-pytorch-using-power-iteration-ee93ac9fa2c4?sk=4a5459e6310ef9ad79a27e93a9dcaf65).
  prefs: []
  type: TYPE_NORMAL
- en: Principal Component Analysis (PCA) is widely used in data analysis and machine
    learning to reduce the dimensionality of a dataset. The goal is to find a set
    of linearly uncorrelated (orthogonal) variables, called *principal components*,
    that capture the maximum variance in the data. The first principal component represents
    the direction of maximum variance, the second principal component is orthogonal
    to the first and represents the direction of the next highest variance, and so
    on. PCA is also used in *robotic manipulation* to find the principal axis of a
    point cloud, which can then be used to orient a gripper.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/706102bd80688e62167884f91e4edd9a.png)'
  prefs: []
  type: TYPE_IMG
- en: Pointcloud of a soda can on a table. Grasping the soda can will require aligning
    a gripper with the principal axes of the soda can. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically, the orthogonality of principal components is achieved by finding
    the eigenvectors of the…
  prefs: []
  type: TYPE_NORMAL
