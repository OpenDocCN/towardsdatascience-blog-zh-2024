# ä½¿ç”¨ Llama 3.2-Vision å¤šæ¨¡æ€ LLM ä¸æ‚¨çš„å›¾ç‰‡è¿›è¡Œå¯¹è¯

> åŸæ–‡ï¼š[`towardsdatascience.com/chat-with-your-images-using-multimodal-llms-60af003e8bfa?source=collection_archive---------3-----------------------#2024-12-05`](https://towardsdatascience.com/chat-with-your-images-using-multimodal-llms-60af003e8bfa?source=collection_archive---------3-----------------------#2024-12-05)

## å­¦ä¹ å¦‚ä½•åœ¨æœ¬åœ°ä»¥ç±»ä¼¼èŠå¤©çš„æ–¹å¼æ„å»º Llama 3.2-Visionï¼Œå¹¶åœ¨ Colab ç¬”è®°æœ¬ä¸­æ¢ç´¢å…¶å¤šæ¨¡æ€æŠ€èƒ½

[](https://medium.com/@lihigurarie?source=post_page---byline--60af003e8bfa--------------------------------)![Lihi Gur Arie, åšå£«](https://medium.com/@lihigurarie?source=post_page---byline--60af003e8bfa--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--60af003e8bfa--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--60af003e8bfa--------------------------------) [Lihi Gur Arie, åšå£«](https://medium.com/@lihigurarie?source=post_page---byline--60af003e8bfa--------------------------------)

Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--60af003e8bfa--------------------------------) Â·é˜…è¯»æ—¶é•¿ï¼š7 åˆ†é’ŸÂ·2024 å¹´ 12 æœˆ 5 æ—¥

--

![](img/ea91d922aefd2e7597a663d07051b804.png)

ä½œè€…æ³¨é‡Šçš„å›¾åƒã€‚åŸå§‹å›¾åƒæ¥è‡ª[Pixabay](https://www.pexels.com/photo/brown-and-white-swallowtail-butterfly-under-white-green-and-brown-cocoon-in-shallow-focus-lens-63643/)ã€‚

# ä»‹ç»

å°†è§†è§‰èƒ½åŠ›ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç›¸ç»“åˆï¼Œé€šè¿‡å¤šæ¨¡æ€ LLMï¼ˆMLLMï¼‰æ­£åœ¨å½»åº•æ”¹å˜è®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚è¿™äº›æ¨¡å‹ç»“åˆäº†æ–‡æœ¬å’Œè§†è§‰è¾“å…¥ï¼Œå±•ç°äº†åœ¨å›¾åƒç†è§£å’Œæ¨ç†æ–¹é¢çš„å‡ºè‰²èƒ½åŠ›ã€‚å°½ç®¡è¿™äº›æ¨¡å‹ä¹‹å‰åªèƒ½é€šè¿‡ API è®¿é—®ï¼Œä½†æœ€è¿‘çš„å¼€æºé€‰é¡¹ç°åœ¨å…è®¸æœ¬åœ°æ‰§è¡Œï¼Œä½¿å®ƒä»¬åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ›´å…·å¸å¼•åŠ›ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å¼€æºçš„ Llama 3.2-Vision æ¨¡å‹ä¸å›¾åƒè¿›è¡Œå¯¹è¯ï¼Œæ‚¨å°†ä¼šæƒŠå¹äºå®ƒçš„ OCRã€å›¾åƒç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚æ‰€æœ‰ä»£ç éƒ½æ–¹ä¾¿åœ°æä¾›åœ¨ä¸€ä¸ªå®ç”¨çš„ Colab ç¬”è®°æœ¬ä¸­ã€‚

*å¦‚æœæ‚¨æ²¡æœ‰ä»˜è´¹çš„ Medium è´¦å·ï¼Œæ‚¨å¯ä»¥å…è´¹é˜…è¯»* *è¿™é‡Œ**ã€‚*

# **Llama 3.2-Vision**

**èƒŒæ™¯**

Llamaï¼Œç¼©å†™ä¸ºâ€œLarge Language Model Meta AIâ€ï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹å…ƒ AIï¼‰ï¼Œæ˜¯ä¸€ç³»åˆ—ç”± Meta å¼€å‘çš„å…ˆè¿› LLMã€‚å®ƒä»¬çš„æœ€æ–°ç‰ˆæœ¬ Llama 3.2ï¼Œæ¨å‡ºäº†å…ˆè¿›çš„è§†è§‰èƒ½åŠ›ã€‚è§†è§‰å˜ä½“æœ‰ä¸¤ç§å‚æ•°å¤§å°ï¼š11B å’Œ 90Bï¼Œèƒ½å¤Ÿåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†ã€‚Llama 3.2 æ‹¥æœ‰å¤šè¾¾ 128k ä¸ª token çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå¹¶æ”¯æŒåˆ†è¾¨ç‡é«˜è¾¾ 1120x1120 åƒç´ çš„å›¾åƒï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚

**æ¶æ„**

Llama ç³»åˆ—æ¨¡å‹æ˜¯ä»…è§£ç å™¨çš„ Transformer æ¨¡å‹ã€‚Llama 3.2-Vision æ„å»ºåœ¨é¢„è®­ç»ƒçš„ Llama 3.1 ä»…æ–‡æœ¬æ¨¡å‹ä¹‹ä¸Šã€‚å®ƒä½¿ç”¨æ ‡å‡†çš„å¯†é›†è‡ªå›å½’ Transformer æ¶æ„ï¼Œä¸å…¶å‰èº« Llama å’Œ Llama 2 ç›¸æ¯”æ²¡æœ‰æ˜¾è‘—åå·®ã€‚

ä¸ºäº†æ”¯æŒè§†è§‰ä»»åŠ¡ï¼ŒLlama 3.2 ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ï¼ˆViT-H/14ï¼‰æå–å›¾åƒè¡¨ç¤ºå‘é‡ï¼Œå¹¶é€šè¿‡è§†è§‰é€‚é…å™¨å°†è¿™äº›è¡¨ç¤ºé›†æˆåˆ°å†»ç»“çš„è¯­è¨€æ¨¡å‹ä¸­ã€‚è¯¥é€‚é…å™¨ç”±ä¸€ç³»åˆ—äº¤å‰æ³¨æ„åŠ›å±‚ç»„æˆï¼Œå…è®¸æ¨¡å‹ä¸“æ³¨äºä¸æ­£åœ¨å¤„ç†çš„æ–‡æœ¬ç›¸å¯¹åº”çš„å›¾åƒç‰¹å®šéƒ¨åˆ† [1]ã€‚

è¯¥é€‚é…å™¨åœ¨æ–‡æœ¬-å›¾åƒå¯¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥å°†å›¾åƒè¡¨ç¤ºä¸è¯­è¨€è¡¨ç¤ºå¯¹é½ã€‚åœ¨é€‚é…å™¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå›¾åƒç¼–ç å™¨çš„å‚æ•°ä¼šæ›´æ–°ï¼Œè€Œè¯­è¨€æ¨¡å‹çš„å‚æ•°ä¿æŒä¸å˜ï¼Œä»¥ä¿ç•™ç°æœ‰çš„è¯­è¨€èƒ½åŠ›ã€‚

![](img/9ce66fc5c8775374b6c44cf1d2fffe0b.png)

Llama 3.2-Vision æ¶æ„ã€‚è§†è§‰æ¨¡å—ï¼ˆç»¿è‰²ï¼‰ä¸å›ºå®šçš„è¯­è¨€æ¨¡å‹ï¼ˆç²‰è‰²ï¼‰é›†æˆã€‚æ­¤å›¾ç”±ä½œè€…åˆ›å»ºã€‚

è¿™ç§è®¾è®¡ä½¿å¾— Llama 3.2 èƒ½åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶ä¿æŒå…¶å¼ºå¤§çš„ä»…æ–‡æœ¬æ€§èƒ½ã€‚æœ€ç»ˆçš„æ¨¡å‹å±•ç¤ºäº†åœ¨éœ€è¦å›¾åƒå’Œè¯­è¨€ç†è§£çš„ä»»åŠ¡ä¸­ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œå¹¶å…è®¸ç”¨æˆ·ä¸å…¶è§†è§‰è¾“å…¥è¿›è¡Œäº’åŠ¨ã€‚

# å¼€å§‹ç¼–ç å§ï¼

åœ¨æˆ‘ä»¬ç†è§£äº† Llama 3.2 çš„æ¶æ„ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥æ·±å…¥åˆ°å®é™…çš„å®ç°ä¸­ã€‚ä½†é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›å‡†å¤‡å·¥ä½œã€‚

## **å‡†å¤‡å·¥ä½œ**

åœ¨ Google Colab ä¸Šè¿è¡Œ Llama 3.2 â€” Vision 11B ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›å‡†å¤‡å·¥ä½œï¼š

1.  GPU è®¾ç½®ï¼š

+   æ¨èä½¿ç”¨è‡³å°‘ 22GB VRAM çš„é«˜ç«¯ GPU ä»¥å®ç°é«˜æ•ˆæ¨ç† [2]ã€‚

+   å¯¹äº Google Colab ç”¨æˆ·ï¼šå¯¼èˆªè‡³ â€˜è¿è¡Œæ—¶â€™ > â€˜æ›´æ”¹è¿è¡Œæ—¶ç±»å‹â€™ > â€˜A100 GPUâ€™ã€‚è¯·æ³¨æ„ï¼Œé«˜ç«¯ GPU å¯èƒ½å¯¹å…è´¹ Colab ç”¨æˆ·ä¸å¯ç”¨ã€‚

2\. æ¨¡å‹æƒé™ï¼š

+   è¯·æ±‚è®¿é—® Llama 3.2 æ¨¡å‹ [è¿™é‡Œ](https://www.llama.com/llama-downloads/)ã€‚

3\. Hugging Face è®¾ç½®ï¼š

+   å¦‚æœä½ è¿˜æ²¡æœ‰ Hugging Face è´¦æˆ·ï¼Œè¯· [è¿™é‡Œ](https://huggingface.co/join) åˆ›å»ºä¸€ä¸ªã€‚

+   å¦‚æœä½ è¿˜æ²¡æœ‰è®¿é—®ä»¤ç‰Œï¼Œè¯·ä»ä½ çš„ Hugging Face è´¦æˆ·ç”Ÿæˆä¸€ä¸ªï¼Œ[è¿™é‡Œ](https://huggingface.co/settings/tokens)ã€‚

+   å¯¹äº Google Colab ç”¨æˆ·ï¼Œè¯·å°† Hugging Face ä»¤ç‰Œè®¾ç½®ä¸ºåä¸ºâ€˜HF_TOKENâ€™çš„ç§˜å¯†ç¯å¢ƒå˜é‡ï¼Œå¹¶æ·»åŠ åˆ° Google Colab Secrets ä¸­ã€‚

4\. å®‰è£…æ‰€éœ€çš„åº“ã€‚

**åŠ è½½æ¨¡å‹**

ä¸€æ—¦æˆ‘ä»¬è®¾ç½®å¥½ç¯å¢ƒå¹¶è·å¾—å¿…è¦çš„æƒé™ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Hugging Face Transformers åº“æ¥å®ä¾‹åŒ–æ¨¡å‹åŠå…¶ç›¸å…³çš„å¤„ç†å™¨ã€‚å¤„ç†å™¨è´Ÿè´£ä¸ºæ¨¡å‹å‡†å¤‡è¾“å…¥å¹¶æ ¼å¼åŒ–è¾“å‡ºã€‚

```py
model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"

model = MllamaForConditionalGeneration.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto")

processor = AutoProcessor.from_pretrained(model_id)
```

**é¢„æœŸçš„èŠå¤©æ¨¡æ¿**

èŠå¤©æ¨¡æ¿é€šè¿‡å­˜å‚¨â€œç”¨æˆ·â€ï¼ˆæˆ‘ä»¬ï¼‰ä¸â€œåŠ©æ‰‹â€ï¼ˆAI æ¨¡å‹ï¼‰ä¹‹é—´çš„å¯¹è¯äº¤æ¢ï¼Œä¿æŒä¸Šä¸‹æ–‡ã€‚å¯¹è¯å†å²ä»¥ä¸€ä¸ªå­—å…¸åˆ—è¡¨çš„å½¢å¼ç»“æ„åŒ–ï¼Œç§°ä¸º`messages`ï¼Œæ¯ä¸ªå­—å…¸ä»£è¡¨ä¸€ä¸ªå•ç‹¬çš„å¯¹è¯è½®æ¬¡ï¼ŒåŒ…æ‹¬ç”¨æˆ·å’Œæ¨¡å‹çš„å›åº”ã€‚ç”¨æˆ·çš„è½®æ¬¡å¯ä»¥åŒ…å«å›¾åƒ-æ–‡æœ¬æˆ–ä»…æ–‡æœ¬è¾“å…¥ï¼Œ`{"type": "image"}`è¡¨ç¤ºå›¾åƒè¾“å…¥ã€‚

ä¾‹å¦‚ï¼Œåœ¨ç»è¿‡å‡ è½®èŠå¤©åï¼Œ`messages`åˆ—è¡¨å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š

```py
messages = [
    {"role": "user",      "content": [{"type": "image"}, {"type": "text", "text": prompt1}]},
    {"role": "assistant", "content": [{"type": "text", "text": generated_texts1}]},
    {"role": "user",      "content": [{"type": "text", "text": prompt2}]},
    {"role": "assistant", "content": [{"type": "text", "text": generated_texts2}]},
    {"role": "user",      "content": [{"type": "text", "text": prompt3}]},
    {"role": "assistant", "content": [{"type": "text", "text": generated_texts3}]}
]
```

è¿™ä¸ªæ¶ˆæ¯åˆ—è¡¨ç¨åä¼šä¼ é€’ç»™`apply_chat_template()`æ–¹æ³•ï¼Œå°†å¯¹è¯è½¬æ¢æˆæ¨¡å‹æœŸæœ›çš„æ ¼å¼ï¼Œä»¥ä¾¿ä½œä¸ºä¸€ä¸ªå•ä¸€çš„å¯æ ‡è®°å­—ç¬¦ä¸²ã€‚

**ä¸»è¦åŠŸèƒ½**

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘æä¾›äº†ä¸€ä¸ª`chat_with_mllm`å‡½æ•°ï¼Œä½¿å¾—å¯ä»¥ä¸ Llama 3.2 MLLM è¿›è¡ŒåŠ¨æ€å¯¹è¯ã€‚è¯¥å‡½æ•°å¤„ç†å›¾åƒåŠ è½½ï¼Œé¢„å¤„ç†å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œç”Ÿæˆæ¨¡å‹å›åº”ï¼Œå¹¶ç®¡ç†å¯¹è¯å†å²ï¼Œä»¥æ”¯æŒèŠå¤©æ¨¡å¼çš„äº¤äº’ã€‚

```py
def chat_with_mllm (model, processor, prompt, images_path=[],do_sample=False, temperature=0.1, show_image=False, max_new_tokens=512, messages=[], images=[]):

    # Ensure list:
    if not isinstance(images_path, list):
        images_path =  [images_path]

    # Load images 
    if len (images)==0 and len (images_path)>0:
            for image_path in tqdm (images_path):
                image = load_image(image_path)
                images.append (image)
                if show_image:
                    display ( image )

    # If starting a new conversation about an image
    if len (messages)==0:
        messages = [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}]

    # If continuing conversation on the image
    else:
        messages.append ({"role": "user", "content": [{"type": "text", "text": prompt}]})

    # process input data
    text = processor.apply_chat_template(messages, add_generation_prompt=True)
    inputs = processor(images=images, text=text, return_tensors="pt", ).to(model.device)

    # Generate response
    generation_args = {"max_new_tokens": max_new_tokens, "do_sample": True}
    if do_sample:
        generation_args["temperature"] = temperature
    generate_ids = model.generate(**inputs,**generation_args)
    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:-1]
    generated_texts = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)

    # Append the model's response to the conversation history
    messages.append ({"role": "assistant", "content": [  {"type": "text", "text": generated_texts}]})

    return generated_texts, messages, images
```

## ä¸ Llama èŠå¤©

1.  **è´è¶å›¾åƒç¤ºä¾‹**

åœ¨æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä¸ Llama 3.2 èŠä¸€ä¸ªå­µåŒ–è´è¶çš„å›¾åƒã€‚ç”±äº Llama 3.2-Vision åœ¨ä½¿ç”¨å›¾åƒæ—¶ä¸æ”¯æŒç³»ç»Ÿæç¤ºçš„è¾“å…¥ï¼Œæˆ‘ä»¬å°†ç›´æ¥æŠŠæŒ‡ä»¤é™„åŠ åˆ°ç”¨æˆ·æç¤ºä¸­ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹çš„å›ç­”ã€‚é€šè¿‡è®¾ç½®`do_sample=True`å’Œ`temperature=0.2`ï¼Œæˆ‘ä»¬åœ¨ä¿æŒå›åº”è¿è´¯æ€§çš„åŒæ—¶å¼•å…¥äº†è½»å¾®çš„éšæœºæ€§ã€‚å¦‚æœéœ€è¦å›ºå®šç­”æ¡ˆï¼Œå¯ä»¥è®¾ç½®`do_sample==False`ã€‚`messages`å‚æ•°ç”¨äºå­˜å‚¨èŠå¤©å†å²ï¼Œæœ€åˆä¸ºç©ºï¼Œä¸`images`å‚æ•°ä¸€æ ·ã€‚

```py
instructions = "Respond concisely in one sentence."
prompt = instructions + "Describe the image."

response, messages,images= chat_with_mllm ( model, processor, prompt,
                                             images_path=[img_path],
                                             do_sample=True,
                                             temperature=0.2,
                                             show_image=True,
                                             messages=[],
                                             images=[])

# Output:  "The image depicts a butterfly emerging from its chrysalis, 
#           with a row of chrysalises hanging from a branch above it."
```

![](img/547d3652bb89e47a8039ddfee8ff7c8b.png)

å›¾ç‰‡ç”±[Pixabay](https://www.pexels.com/photo/brown-and-white-swallowtail-butterfly-under-white-green-and-brown-cocoon-in-shallow-focus-lens-63643/)æä¾›ã€‚

å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¾“å‡ºå‡†ç¡®ç®€æ´ï¼Œå±•ç¤ºäº†æ¨¡å‹æœ‰æ•ˆç†è§£å›¾åƒçš„èƒ½åŠ›ã€‚

å¯¹äºä¸‹ä¸€ä¸ªèŠå¤©è½®æ¬¡ï¼Œæˆ‘ä»¬å°†ä¼ é€’ä¸€ä¸ªæ–°çš„æç¤ºä»¥åŠèŠå¤©å†å²ï¼ˆ`messages`ï¼‰å’Œå›¾åƒæ–‡ä»¶ï¼ˆ`images`ï¼‰ã€‚æ–°æç¤ºæ—¨åœ¨è¯„ä¼° Llama 3.2 çš„æ¨ç†èƒ½åŠ›ï¼š

```py
prompt = instructions + "What would happen to the chrysalis in the near future?"
response, messages, images= chat_with_mllm ( model, processor, prompt,
                                             images_path=[img_path,],
                                             do_sample=True,
                                             temperature=0.2,
                                             show_image=False,
                                             messages=messages,
                                             images=images)

# Output: "The chrysalis will eventually hatch into a butterfly."
```

æˆ‘ä»¬åœ¨æä¾›çš„ Colab ç¬”è®°æœ¬ä¸­ç»§ç»­è¿™ä¸ªå¯¹è¯ï¼Œå¹¶å¾—åˆ°äº†ä»¥ä¸‹å¯¹è¯ï¼š

![](img/a72d924ad8dd280b870dadf9ab7c7224.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

å¯¹è¯çªå‡ºäº†æ¨¡å‹çš„å›¾åƒç†è§£èƒ½åŠ›ï¼Œå‡†ç¡®æè¿°äº†åœºæ™¯ã€‚å®ƒè¿˜å±•ç¤ºäº†å…¶æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡é€»è¾‘åœ°è¿æ¥ä¿¡æ¯ï¼Œæ­£ç¡®åœ°å¾—å‡ºè›¹å°†ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œå¹¶è§£é‡Šäº†ä¸ºä»€ä¹ˆæœ‰äº›è›¹æ˜¯æ£•è‰²çš„ï¼Œè€Œæœ‰äº›æ˜¯ç»¿è‰²çš„ã€‚

**2. è¡¨æƒ…åŒ…å›¾åƒç¤ºä¾‹**

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘å°†å‘æ¨¡å‹å±•ç¤ºæˆ‘è‡ªå·±åˆ¶ä½œçš„ä¸€ä¸ªè¡¨æƒ…åŒ…ï¼Œè¯„ä¼° Llama çš„ OCR èƒ½åŠ›ï¼Œå¹¶åˆ¤æ–­å®ƒæ˜¯å¦èƒ½ç†è§£æˆ‘çš„å¹½é»˜æ„Ÿã€‚

```py
instructions = "You are a computer vision engineer with sense of humor."
prompt = instructions + "Can you explain this meme to me?"

response, messages,images= chat_with_mllm ( model, processor, prompt,
                                             images_path=[img_path,],
                                             do_sample=True,
                                             temperature=0.5,
                                             show_image=True,
                                             messages=[],
                                             images=[])
```

è¿™æ˜¯è¾“å…¥çš„è¡¨æƒ…åŒ…ï¼š

![](img/e196e4c1075cc3f596b4cfa4160b6658.png)

è¡¨æƒ…åŒ…ç”±ä½œè€…åˆ¶ä½œã€‚åŸå§‹ç†Šçš„å›¾åƒç”±[Hans-Jurgen Mager](https://unsplash.com/photos/polar-bear-on-snow-covered-ground-during-daytime-C9Ay328wHgA)æä¾›ã€‚

è¿™æ˜¯æ¨¡å‹çš„å›åº”ï¼š

![](img/92233ad5cc21df183820c16f4e063aae.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›

æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæ¨¡å‹å±•ç¤ºäº†å‡ºè‰²çš„ OCR èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†è§£å›¾åƒä¸­æ–‡å­—çš„å«ä¹‰ã€‚è‡³äºå®ƒçš„å¹½é»˜æ„Ÿâ€”â€”ä½ æ€ä¹ˆçœ‹ï¼Œå®ƒç†è§£äº†å—ï¼Ÿä½ æ˜ç™½äº†å—ï¼Ÿä¹Ÿè®¸æˆ‘ä¹Ÿè¯¥æå‡ä¸€ä¸‹æˆ‘çš„å¹½é»˜æ„Ÿï¼

# ç»“è¯­

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•åœ¨æœ¬åœ°æ„å»º Llama 3.2-Vision æ¨¡å‹ï¼Œå¹¶ç®¡ç†èŠå¤©å¼äº’åŠ¨çš„å¯¹è¯å†å²ï¼Œä»è€Œå¢å¼ºç”¨æˆ·å‚ä¸åº¦ã€‚æˆ‘ä»¬æ¢ç´¢äº† Llama 3.2 çš„é›¶-shot èƒ½åŠ›ï¼Œå¹¶å¯¹å…¶åœºæ™¯ç†è§£ã€æ¨ç†å’Œ OCR æŠ€èƒ½å°è±¡æ·±åˆ»ã€‚

é«˜çº§æŠ€æœ¯å¯ä»¥åº”ç”¨äº Llama 3.2ï¼Œä¾‹å¦‚åœ¨ç‹¬ç‰¹æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œæˆ–ä½¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¥æ”¯æŒé¢„æµ‹å¹¶å‡å°‘å¹»è§‰ã€‚

æ€»çš„æ¥è¯´ï¼Œæœ¬æ•™ç¨‹æä¾›äº†å¯¹å¤šæ¨¡æ€ LLM å¿«é€Ÿå‘å±•çš„é¢†åŸŸä»¥åŠå®ƒä»¬åœ¨å„ç§åº”ç”¨ä¸­çš„å¼ºå¤§èƒ½åŠ›çš„æ´å¯Ÿã€‚

# æ„Ÿè°¢é˜…è¯»ï¼

æ­å–œä½ ä¸€ç›´çœ‹åˆ°è¿™é‡Œã€‚ç‚¹å‡»ğŸ‘x50 è¡¨ç¤ºæ„Ÿè°¢ï¼Œå¹¶æå‡ç®—æ³•çš„è‡ªå°Šå¿ƒğŸ¤“

**æƒ³äº†è§£æ›´å¤šå—ï¼Ÿ**

+   [**æ¢ç´¢**](https://medium.com/@lihigurarie)æˆ‘å†™çš„å…¶ä»–æ–‡ç« 

+   [**è®¢é˜…**](https://medium.com/@lihigurarie/subscribe)ä»¥ä¾¿åœ¨æˆ‘å‘å¸ƒæ–‡ç« æ—¶æ”¶åˆ°é€šçŸ¥

+   åœ¨[**Linkedin**](https://www.linkedin.com/in/lihi-gur-arie/)ä¸Šå…³æ³¨æˆ‘

# å®Œæ•´ä»£ç ä½œä¸º Colab ç¬”è®°æœ¬ï¼š

# å‚è€ƒæ–‡çŒ®

[0] Colab ç¬”è®°æœ¬ä¸Šçš„ä»£ç ï¼š[link](https://gist.github.com/Lihi-Gur-Arie/0e87500813c29bb4c4a6a990795c3aaa)

[1] [Llama 3 æ¨¡å‹ç¾¤ä½“](https://arxiv.org/pdf/2407.21783)

[2] [Llama 3.2 11B Vision è¦æ±‚](https://llamaimodel.com/requirements-3-2/)
