- en: 'Maximizing AI Efficiency in Production with Caching: A Cost-Efficient Performance
    Booster'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过缓存最大化生产中的AI效率：一种成本高效的性能提升方案
- en: 原文：[https://towardsdatascience.com/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?source=collection_archive---------6-----------------------#2024-03-19](https://towardsdatascience.com/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?source=collection_archive---------6-----------------------#2024-03-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?source=collection_archive---------6-----------------------#2024-03-19](https://towardsdatascience.com/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?source=collection_archive---------6-----------------------#2024-03-19)
- en: Unlock the Power of Caching to Scale AI Solutions with LangChain Caching Comprehensive
    Overview
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解锁缓存的力量，以利用LangChain缓存扩展AI解决方案——全面概述
- en: '[](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)[![Han
    HELOIR, Ph.D. ☕️](../Images/53c132b64fda2f1d9ebd6af6d582d24c.png)](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)
    [Han HELOIR, Ph.D. ☕️](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)[![Han
    HELOIR, Ph.D. ☕️](../Images/53c132b64fda2f1d9ebd6af6d582d24c.png)](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)
    [Han HELOIR, Ph.D. ☕️](https://medium.com/@han.heloir?source=post_page---byline--9b8afd200efd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)
    ·14 min read·Mar 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9b8afd200efd--------------------------------)
    ·14分钟阅读·2024年3月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[Free Friend Link](https://medium.com/towards-data-science/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?sk=226f81b015f25d2cb70cb2f4ae859c93)
    — Please help to like [this linkedin post](https://www.linkedin.com/posts/hanheloiryan_maximizing-ai-efficiency-in-production-with-activity-7175898095740694529-yVTD?utm_source=share&utm_medium=member_desktop)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[免费朋友链接](https://medium.com/towards-data-science/maximizing-ai-efficiency-in-production-with-caching-a-cost-efficient-performance-booster-9b8afd200efd?sk=226f81b015f25d2cb70cb2f4ae859c93)
    — 请帮忙点赞[这篇LinkedIn文章](https://www.linkedin.com/posts/hanheloiryan_maximizing-ai-efficiency-in-production-with-activity-7175898095740694529-yVTD?utm_source=share&utm_medium=member_desktop)'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: 'Despite the transformative potential of AI applications, approximately 70%
    never make it to production. The challenges? Cost, performance, security, flexibility,
    and maintainability. In this article, we address two critical challenges: escalating
    costs and the need for high performance — and reveal how caching strategy in AI
    is **THE** solution.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管人工智能应用具有变革性的潜力，但大约70%的应用未能投入生产。挑战是什么？成本、性能、安全性、灵活性和可维护性。本文我们将讨论两个关键挑战：不断上升的成本和对高性能的需求——并揭示如何通过缓存策略解决这些问题，**这就是**解决方案。
- en: '![](../Images/8a0e842217cbf72dce7bdf9fcd66719f.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a0e842217cbf72dce7bdf9fcd66719f.png)'
- en: Photo by [Possessed Photography](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Possessed Photography](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'The Cost Challenge: When Scale Meets Expense'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本挑战：规模与开销的对接
- en: Running AI models, especially at scale, can be prohibitively expensive. Take,
    for example, the GPT-4 model, which costs $30 for processing 1M input tokens and
    $60 for 1M output tokens. These figures can quickly add up, making widespread
    adoption a financial challenge for many projects.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 运行AI模型，特别是在大规模时，可能会变得极其昂贵。以GPT-4模型为例，处理100万输入tokens的费用为30美元，处理100万输出tokens的费用为60美元。这些费用很容易迅速累积，使得许多项目在财务上难以承担广泛的采用。
- en: To put this into perspective, consider a customer service chatbot that processes
    an average of **50,000 user queries** daily. Each query and response pair might
    average 50 tokens for both. In a single day, that translates to 2,500,000 tokens,
    up…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，我们可以考虑一个客服聊天机器人，每天处理大约**50,000个用户查询**。每个查询和回复的平均长度可能是50个标记。一天之内，这就相当于2,500,000个标记，继续…
