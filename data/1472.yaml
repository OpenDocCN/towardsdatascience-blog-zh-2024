- en: Model Interpretability Using Credit Card Fraud Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用信用卡欺诈数据的模型可解释性
- en: 原文：[https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12](https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12](https://towardsdatascience.com/model-interpretability-using-credit-card-fraud-data-f219ff7ec89d?source=collection_archive---------4-----------------------#2024-06-12)
- en: Why model interpretability is important
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么模型可解释性很重要
- en: '[](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Danila
    Morozovskii](../Images/d53b987de52b8c2d4ce264b142b05950.png)](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    [Danila Morozovskii](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Danila
    Morozovskii](../Images/d53b987de52b8c2d4ce264b142b05950.png)](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    [Danila Morozovskii](https://dan-to.medium.com/?source=post_page---byline--f219ff7ec89d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    ·17 min read·Jun 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f219ff7ec89d--------------------------------)
    ·17分钟阅读·2024年6月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Recently, I stumbled upon an online book which describes different tools that
    can be used for machine learning model interpretability ([https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)).
    The idea that machine learning models should not be a black box and can be explained
    fascinated me, and I decided to dive deep into this topic. Previously, when I
    would start working on a new machine learning project, I would follow the same
    procedure: identifying the problem, getting familiar with a dataset, feature engineering,
    selection of a model, training/testing and hyperparameter tuning, and result analysis.
    However, I didn’t realize I was missing the most crucial step: model interpretability.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我偶然发现了一本在线书籍，书中描述了可用于机器学习模型可解释性的不同工具（[https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)）。机器学习模型不应该是黑箱，并且可以解释的这一想法让我非常着迷，我决定深入研究这个话题。之前，当我开始进行一个新的机器学习项目时，我会遵循相同的程序：识别问题、熟悉数据集、特征工程、选择模型、训练/测试和超参数调优，以及结果分析。然而，我没有意识到自己漏掉了最关键的一步：模型可解释性。
- en: What is model interpretability?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是模型可解释性？
- en: Model interpretability is a process of explaining how the black box (model)
    works and how it makes predictions. Let’s imagine a situation where a person applied
    for a credit loan and was denied because the model made a negative prediction.
    Any person would want to know why it was denied and what possibly they can change
    so that the decision would be positive, and all the bank employee can do is point
    at a machine learning model and say “It said so!”. This is not a great scenario
    and damages the bank’s reputation since it looks like it doesn’t have control
    over its product. It would be much better if the bank employee could explain to
    the customer what specific features in…
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可解释性是解释黑箱（模型）如何工作以及如何做出预测的过程。让我们假设一个情况，一个人申请了信用贷款并被拒绝，因为模型做出了负面预测。任何人都会想知道为什么被拒绝，以及他们可能需要改变什么，才能使决定变得积极，而银行员工只能指着机器学习模型说“它是这么说的！”。这种情况并不好，并且会损害银行的声誉，因为看起来银行对其产品没有控制权。如果银行员工能够向客户解释哪些特定特征在做出预测时发挥了作用，那就会好得多。
