- en: Making News Recommendations Explainable with Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用大型语言模型使新闻推荐变得可解释
- en: 原文：[https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30](https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30](https://towardsdatascience.com/making-news-recommendations-explainable-with-large-language-models-74f119c7e036?source=collection_archive---------2-----------------------#2024-11-30)
- en: A prompt-based experiment to improve both accuracy and transparent reasoning
    in content personalization.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过基于提示的实验，提升内容个性化推荐的准确性和透明推理。
- en: '[](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[![Alex
    Held](../Images/be76f042807c4816944531780d14a73d.png)](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    [Alex Held](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[![Alex
    Held](../Images/be76f042807c4816944531780d14a73d.png)](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    [Alex Held](https://medium.com/@helloheld?source=post_page---byline--74f119c7e036--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    ·7 min read·Nov 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--74f119c7e036--------------------------------)
    ·阅读时间：7分钟·2024年11月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ff1026c0fe89bf7dceb16a6d47f1dc3f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff1026c0fe89bf7dceb16a6d47f1dc3f.png)'
- en: Deliver relevant content to readers at the right time. Image by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在合适的时间向读者提供相关内容。图片来自作者。
- en: At [DER SPIEGEL](https://www.spiegel.de/), we are continually exploring ways
    to improve how we recommend news articles to our readers. In our latest (offline)
    experiment, we investigated whether [Large Language Models](https://vickiboykis.com/what_are_embeddings/)
    (LLMs) could effectively predict which articles a reader would be interested in,
    based on their reading history.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [DER SPIEGEL](https://www.spiegel.de/) ，我们不断探索改进如何向读者推荐新闻文章的方法。在我们最新的（离线）实验中，我们研究了
    [大型语言模型](https://vickiboykis.com/what_are_embeddings/)（LLMs）是否能够有效地根据读者的阅读历史预测他们可能感兴趣的文章。
- en: '**Our Approach**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们的方法**'
- en: 'We conducted a study with readers who participated in a survey where they rated
    their interest in various news articles. This gave us a ground truth of reader
    preferences. For each participant, we had two key pieces of information: their
    actual reading history (which articles they had read before taking the survey)
    and their ratings of a set of new articles in the survey. Read more about this
    mixed-methods approach to offline evaluation of news recommender systems here:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项研究，邀请参与者填写调查问卷，评估他们对各种新闻文章的兴趣。这为我们提供了关于读者偏好的真实数据。对于每个参与者，我们有两个关键信息：他们的实际阅读历史（即在填写调查问卷前他们阅读过哪些文章）以及他们在调查中对一组新文章的评分。了解更多关于这种混合方法的离线新闻推荐系统评估方法，请点击这里：
- en: '[](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
    [## A Mixed-Methods Approach to Offline Evaluation of News Recommender Systems'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
    [## 混合方法离线评估新闻推荐系统'
- en: Combining reader feedback from surveys with behavioral click data to optimize
    content personalization.
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结合调查反馈与行为点击数据，优化内容个性化推荐。
- en: towardsdatascience.com](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501?source=post_page-----74f119c7e036--------------------------------)
- en: 'We then used the [Anthropic API](https://github.com/anthropics/anthropic-sdk-python)
    to access [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet),
    a state-of-the-art language model, as our recommendation engine. For each reader,
    we provided the model with their reading history (news title and article summary)
    and asked it to predict how interested they would be in the articles from the
    survey. Here is the prompt we used:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用了[Anthropic API](https://github.com/anthropics/anthropic-sdk-python)来访问[Claude
    3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet)，一个最先进的语言模型，作为我们的推荐引擎。对于每个读者，我们为模型提供了他们的阅读历史（新闻标题和文章摘要），并要求模型预测他们对调查中这些文章的兴趣程度。以下是我们使用的提示：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With this approach, we can now compare the actual ratings from the survey against
    the score predictions from the LLM. This comparison provides an ideal dataset
    for evaluating the language model’s ability to predict reader interests.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方法，我们现在可以将调查中的实际评分与LLM的预测分数进行比较。这一比较提供了一个理想的数据集，用于评估语言模型预测读者兴趣的能力。
- en: '**Results and Key Findings**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果与关键发现**'
- en: 'The findings were impressively strong. To understand the performance, we can
    look at two key metrics. First, the [Precision@5](https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k):
    the LLM achieved a score of 56%, which means that when the system recommended
    its top 5 articles for a user (out of 15), on average (almost) 3 out of these
    5 articles were actually among the articles that user rated highest in our survey.
    Looking at the distribution of these predictions reveals even more impressive
    results: for 24% of users, the system correctly identified at least 4 or 5 of
    their top articles. For another 41% of users, it correctly identified 3 out of
    their top 5 articles.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 研究结果令人印象深刻。为了理解表现，我们可以看两个关键指标。首先是[Precision@5](https://www.evidentlyai.com/ranking-metrics/precision-recall-at-k)：LLM（大语言模型）获得了56%的得分，这意味着当系统向用户推荐前5篇文章时（从15篇中选出），平均（几乎）有3篇是用户在调查中评分最高的文章。查看这些预测的分布可以揭示出更加令人印象深刻的结果：对于24%的用户，系统正确识别出至少4或5篇他们最喜欢的文章；对于另外41%的用户，系统正确识别出他们前5篇文章中的3篇。
- en: To put this in perspective, if we were to recommend articles randomly, we would
    only achieve 38.8% precision (see previous [medium article](https://medium.com/towards-data-science/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501)
    for details). Even recommendations based purely on article popularity (recommending
    what most people read) only reach 42.1%, and our previous approach using an embedding-based
    technique achieved 45.4%.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将其置于正确的视角中，如果我们随机推荐文章，我们的精准度将仅为38.8%（详细信息请参见之前的[medium文章](https://medium.com/towards-data-science/a-mixed-methods-approach-to-offline-evaluation-of-news-recommender-systems-7dc7e9f0b501)）。即使是基于文章流行度的推荐（推荐大多数人阅读的内容）也只有42.1%，而我们之前使用基于嵌入的方法的精准度为45.4%。
- en: '![](../Images/73b93682f37bf1eb4cdc35c9c5a9c262.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73b93682f37bf1eb4cdc35c9c5a9c262.png)'
- en: Graphic by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: 'The graphic below shows the uplift: While having any kind of knowledge about
    the users is better than guessing (random model), the LLM-based approach shows
    the strongest performance. Even compared to our sophisticated embedding-based
    logic, the LLM achieves a significant uplift in prediction accuracy.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了提升效果：尽管了解用户的任何信息比纯粹猜测（随机模型）要好，但基于LLM的方法展示了最强的表现。即使与我们复杂的基于嵌入的逻辑相比，LLM在预测准确性上也实现了显著提升。
- en: '![](../Images/944e6bf25ecad03090641f39d1448a3b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/944e6bf25ecad03090641f39d1448a3b.png)'
- en: Graphic by author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表
- en: As a second evaluation metric, we use [Spearman correlation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html).
    At 0.41, it represents a substantial improvement over our embedding-based approach
    (0.17). This also shows that the LLM is not just better at finding relevant articles,
    but also at understanding how much a reader might prefer one article over another.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二个评估指标，我们使用了[Spearman相关系数](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)。其值为0.41，显著高于我们基于嵌入的方法（0.17）。这也表明，LLM不仅在找到相关文章方面表现更好，还能更好地理解读者可能偏爱某篇文章超过另一篇文章的程度。
- en: '**Beyond Performance: The Power of Explainability**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**超越表现：可解释性的力量**'
- en: 'What sets LLM-based recommendations apart is not just their performance but
    their ability to explain their decisions in natural language. Here is an example
    of how our system analyzes a user’s reading patterns and explains its recommendations
    (prompt not shown):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的推荐与众不同之处不仅在于其表现，还在于它们能够以自然语言解释其决策。以下是我们的系统如何分析用户阅读模式并解释其推荐的一个示例（提示未展示）：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Rather than operating as a black box, the system could articulate why it thinks
    a particular article might be interesting to a reader: *Because you frequently
    read articles about practical advice and economic matters, you might find this
    analysis about the cost-effectiveness of balcony solar storage particularly relevant.*
    This kind of transparent reasoning could make recommendations feel more personal
    and trustworthy.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 系统并非作为一个黑盒运行，而是可以阐明为何认为某篇文章可能对读者感兴趣：*因为你经常阅读关于实用建议和经济问题的文章，你可能会发现这篇关于阳台太阳能储能性价比分析的文章特别相关。*
    这种透明的推理可以让推荐看起来更加个性化和值得信赖。
- en: '**Conclusion**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**结论**'
- en: While our results are promising, several challenges need to be addressed. Due
    to long prompts (hundreds of article summaries per user), the most significant
    is cost. At about $0.21 per user for a single recommendation run, scaling this
    to full readerships would be irresponsibly expensive. Testing high-performing
    [open-source models](https://ai.meta.com/blog/meta-llama-3-1/), could potentially
    reduce these costs. Additionally, the current implementation is relatively slow,
    taking several seconds per user. For a news platform where content updates frequently
    and reader interests evolve sometimes even throughout a single day, we would need
    to run these recommendations multiple times daily to stay relevant.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的结果很有前景，但仍然需要解决若干挑战。由于长篇提示（每个用户包含数百个文章摘要），最大的挑战是成本。每个用户的单次推荐运行费用约为$0.21，若将其扩展到全部读者群体，将变得极为昂贵。测试高效的[开源模型](https://ai.meta.com/blog/meta-llama-3-1/)，可能会减少这些成本。此外，当前的实现相对较慢，每个用户需要几秒钟的时间。对于一个内容更新频繁、读者兴趣可能在一天内发生变化的新闻平台，我们需要每天多次运行这些推荐，才能保持其相关性。
- en: Furthermore, we used a single, straightforward prompt without any prompt engineering
    or optimization. There is likely (significant) room for improvement through systematic
    prompt refinement.[1] Additionally, our current implementation only uses article
    titles and summaries, without leveraging available metadata. We could potentially
    increase the performance by incorporating additional signals such as reading time
    per article (how long users spent reading each piece) or overall article popularity.
    Anyhow, due to high API costs, running iterative evaluation pipelines is currently
    not an option.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们使用了一个简单直接的提示，没有进行任何提示工程或优化。通过系统性的提示优化，可能会有（显著的）提升空间。[1] 此外，我们目前的实现仅使用了文章标题和摘要，未利用现有的元数据。我们可以通过引入其他信号，如每篇文章的阅读时间（用户每篇文章的阅读时长）或整体文章的受欢迎程度，潜在地提高性能。不过，由于高昂的API费用，目前进行迭代评估管道并不是一个可行的选项。
- en: 'All in all, the combination of strong predictive performance and natural language
    explanations suggests that LLMs will be a valuable tool in news recommendation
    systems. And beyond recommendations, they add a new way on how we analyze user
    journeys in digital news. Their ability to process and interpret reading histories
    alongside metadata opens up exciting possibilities: from understanding content
    journeys and topic progressions to creating personalized review summaries.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，强大的预测性能和自然语言解释相结合，表明大型语言模型（LLMs）将在新闻推荐系统中发挥重要作用。而且，除了推荐，它们还为我们分析数字新闻中的用户旅程提供了全新的方式。它们能够处理并解释阅读历史与元数据的结合，打开了令人兴奋的可能性：从理解内容的流向和主题的进展，到创建个性化的回顾总结。
- en: '**Thanks for reading 🙏**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**感谢阅读 🙏**'
- en: I hope you liked it, if so, just make it clap. Please do not hesitate to [connect
    with me on LinkedIn](https://www.linkedin.com/in/alex-held-1193b9234/) for further
    discussion or questions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢它，如果喜欢，就给它点个赞吧。如果有进一步的讨论或问题，请随时通过[LinkedIn与我联系](https://www.linkedin.com/in/alex-held-1193b9234/)。
- en: As a data scientist at [DER SPIEGEL](https://www.spiegel.de/), I have authorized
    access to proprietary user data and click histories, which form the basis of this
    study. This data is not publicly available. All presented results are aggregated
    and anonymized to protect user privacy while showcasing our methodological approach
    to news recommendation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作为[DER SPIEGEL](https://www.spiegel.de/)的 数据科学家，我已获得对专有用户数据和点击历史的授权访问权限，这些数据构成了本研究的基础。此数据不公开。所有展示的结果均已汇总和匿名化，以保护用户隐私，同时展示我们在新闻推荐中的方法论。
- en: References
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Dairui, Liu & Yang, Boming & Du, Honghui & Greene, Derek & Hurley, Neil
    & Lawlor, Aonghus & Dong, Ruihai & Li, Irene. (2024). RecPrompt: A Self-tuning
    Prompting Framework for News Recommendation Using Large Language Models.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Dairui, Liu & Yang, Boming & Du, Honghui & Greene, Derek & Hurley, Neil
    & Lawlor, Aonghus & Dong, Ruihai & Li, Irene. (2024). RecPrompt: 一种自调节提示框架，利用大型语言模型进行新闻推荐。'
