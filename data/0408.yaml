- en: 'Generative AI Design Patterns: A Comprehensive Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式 AI 设计模式：全面指南
- en: 原文：[https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0?source=collection_archive---------1-----------------------#2024-02-13](https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0?source=collection_archive---------1-----------------------#2024-02-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0?source=collection_archive---------1-----------------------#2024-02-13](https://towardsdatascience.com/generative-ai-design-patterns-a-comprehensive-guide-41425a40d7d0?source=collection_archive---------1-----------------------#2024-02-13)
- en: Reference architecture patterns and mental models for working with Large Language
    Models (LLM’s)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）工作中的参考架构模式和思维模型
- en: '[](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)[![Vincent
    Koc](../Images/6cbe2dab3c452384057fbdb7a16506be.png)](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)
    [Vincent Koc](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)[![Vincent
    Koc](../Images/6cbe2dab3c452384057fbdb7a16506be.png)](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)
    [Vincent Koc](https://medium.com/@vincentkoc?source=post_page---byline--41425a40d7d0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)
    ·8 min read·Feb 13, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--41425a40d7d0--------------------------------)
    ·阅读时间 8 分钟 ·2024年2月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/73014627d2049a0d28b92d43000b70f9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73014627d2049a0d28b92d43000b70f9.png)'
- en: '*Note: When I initially published this article back in February it was an early
    thought experiment. Since then I have started working on a book for “Generative
    AI Design Patterns” with a major publisher. Please follow me to keep updated on
    updates to my patterns an ideas in this space.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：当我在二月最初发布这篇文章时，它只是一个初步的思维实验。从那时起，我开始与一家大型出版社合作编写《生成式 AI 设计模式》一书。请关注我，及时了解我在这个领域的模式和想法更新。*'
- en: The Need For AI Patterns
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对 AI 模式的需求
- en: We all anchor to some tried and tested methods, approaches and patterns when
    building something new. This statement is very true for those in software engineering,
    however for generative AI and artificial intelligence itself this may not be the
    case. With emerging technologies such as generative AI we lack well documented
    patterns to ground our solution's.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在构建新事物时，总会依赖一些经过验证的方法、途径和模式。对于软件工程师来说，这一点尤其成立。然而，对于生成式 AI 和人工智能本身来说，情况可能并非如此。随着生成式
    AI 等新兴技术的出现，我们缺乏足够文档化的模式来支撑我们的解决方案。
- en: Here I share a handful of approaches and patterns for generative AI, based on
    my evaluation of countless production implementations of LLM’s in production.
    The goal of these patterns is to help mitigate and overcome some of the challenges
    with generative AI implementations such as cost, latency and hallucinations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我分享了一些生成式 AI 的方法和模式，基于我对无数生产环境中 LLM 实现的评估。这些模式的目标是帮助缓解和克服生成式 AI 实现中的一些挑战，如成本、延迟和幻觉问题。
- en: List of Patterns
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模式列表
- en: '[Layered Caching Strategy Leading To Fine-Tuning](#82c6)'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[分层缓存策略导致微调](#82c6)'
- en: '[Multiplexing AI Agents For A Panel Of Experts](#fc13)'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[多路复用 AI 代理以形成专家小组](#fc13)'
- en: '[Fine-Tuning LLM’s For Multiple Tasks](#a0b9)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[针对多任务微调 LLM](#a0b9)'
- en: '[Blending Rules Based & Generative](#19ee)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[融合基于规则与生成式方法](#19ee)'
- en: '[Utilizing Knowledge Graphs with LLM’s](#1b7b)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[利用知识图谱与 LLM 的结合](#1b7b)'
- en: '[Swarm Of Generative AI Agents](#1575)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[生成式 AI 代理的群体效应](#1575)'
- en: '[Modular Monolith LLM Approach With Composability](#682f)'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[模块化单体 LLM 方法与组合性](#682f)'
- en: '[Approach To Memory Cognition For LLM’s](#07cb)'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[LLM 的记忆认知方法](#07cb)'
- en: '[Red & Blue Team Dual-Model Evaluation](#ee0a)'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[红蓝队双模型评估](#ee0a)'
- en: 1) Layered Caching Strategy Leading To Fine-Tuning
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1) 分层缓存策略导致微调
- en: '![](../Images/72caae095583d50b800b2c7bd846b5a4.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72caae095583d50b800b2c7bd846b5a4.png)'
- en: Here we are solving for a combination of factors from cost, redundancy and training
    data when introducing a caching strategy and service to our large language models.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们需要解决成本、冗余和训练数据等多个因素，当我们为大语言模型引入缓存策略和服务时。
- en: By caching these initial results, the system can serve up answers more rapidly
    on subsequent queries, enhancing efficiency. The twist comes with the fine-tuning
    layer once we have sufficient data, where feedback from these early interactions
    is used to refine a more specialized model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过缓存这些初步结果，系统可以在后续查询中更快速地提供答案，从而提高效率。关键在于一旦我们收集到足够的数据，通过微调层，利用这些早期互动的反馈来优化一个更专业化的模型。
- en: The specialized model not only streamlines the process but also tailors the
    AI’s expertise to specific tasks, making it highly effective in environments where
    precision and adaptability are paramount, like customer service or personalized
    content creation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 专门化的模型不仅简化了流程，还将 AI 的专业能力针对具体任务进行了定制，使其在精确度和适应性至关重要的环境中（如客户服务或个性化内容创作）变得非常有效。
- en: For getting started there are pre-built services such as [GPTCache](https://github.com/zilliztech/GPTCache)
    or roll your own with common caching databases such as [Redis](https://redis.io/),
    [Apache Cassandra](https://cassandra.apache.org/_/index.html), [Memcache](https://memcached.org/)d.
    Be sure you monitor and measure your latency as you add additional services to
    the mix.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，可以选择现成的服务，如 [GPTCache](https://github.com/zilliztech/GPTCache)，或者使用常见的缓存数据库如
    [Redis](https://redis.io/)，[Apache Cassandra](https://cassandra.apache.org/_/index.html)，[Memcache](https://memcached.org/)
    来自己搭建。确保在加入额外服务时，监控并测量延迟。
- en: 2) Multiplexing AI Agents For A Panel Of Experts
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2) 多路复用 AI 代理以构建专家小组
- en: '![](../Images/919dda9001f99d2fe08afcfeb3709264.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/919dda9001f99d2fe08afcfeb3709264.png)'
- en: Imagine an ecosystem where multiple generative AI models orientated to a specific
    task (“agents”), each a specialist within its domain, work in parallel to address
    a query. This *multiplexing* strategy enables a diverse set of responses, which
    are then integrated to provide a comprehensive answer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个生态系统，其中多个面向特定任务的生成式 AI 模型（“代理”），每个模型都是其领域内的专家，平行工作以解决查询。这个*多路复用*策略能够提供多样化的响应，随后将这些响应整合成一个全面的答案。
- en: This setup is ideal for complex problem-solving scenarios where different aspects
    of a problem require different expertise, much like a team of experts each tackling
    a facet of a larger issue.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设置非常适合处理复杂问题的场景，在这些场景中，问题的不同方面需要不同的专业知识，就像一个专家小组每个处理一个更大问题的方面一样。
- en: A larger model such as a GPT-4 is used to understand context and break this
    down into specific tasks or information requests which are passed to smaller agents.
    Agents could be smaller language models such as [Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)
    or [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.1) that
    have been trained on specific tasks, access to specific tools or generalized models
    such as GPT, Llama with specific personality, context prompts and function calls.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的模型，如 GPT-4，用于理解上下文并将其分解为具体任务或信息请求，这些请求随后会传递给较小的代理。代理可以是像 [Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)
    或 [TinyLlama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.1) 这样的较小语言模型，这些模型经过特定任务训练，访问特定工具，或者是像
    GPT、Llama 这样的通用模型，具备特定的个性、上下文提示和功能调用。
- en: 3) Fine-Tuning LLM’s For Multiple Tasks
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3) 对大语言模型进行多任务微调
- en: '![](../Images/b91f9c304476a30834a284178a780f9c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b91f9c304476a30834a284178a780f9c.png)'
- en: Here we fine-tune a large language model on multiple tasks simultaneously instead
    of a single task. It’s an approach that promotes a robust transfer of knowledge
    and skills across different domains, enhancing the model’s versatility.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对一个大语言模型同时进行多个任务的微调，而不是仅针对单一任务进行微调。这是一种促进跨领域知识和技能稳健迁移的方法，增强了模型的多样性。
- en: This multi-task learning is especially useful for platforms that need to handle
    a variety of tasks with a high degree of competence, such as virtual assistants
    or AI-powered research tools. This could potentially simplify workflows for training
    and testing for a complex domain.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种多任务学习对需要处理各种任务且要求高水平能力的平台特别有用，比如虚拟助手或 AI 驱动的研究工具。这有可能简化复杂领域中的训练和测试工作流。
- en: Some resources and packages for training LLM’s include [DeepSpeed](https://github.com/microsoft/DeepSpeed),
    and the training functions on [Hugging Face’s Transformer library](https://huggingface.co/docs/transformers/training).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练大语言模型（LLM）的资源和软件包包括 [DeepSpeed](https://github.com/microsoft/DeepSpeed)，以及
    [Hugging Face的Transformer库](https://huggingface.co/docs/transformers/training)上的训练功能。
- en: 4) Blending Rules Based & Generative
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4) 融合基于规则与生成式方法
- en: '![](../Images/f9978e0ccc8d55999338ae7a942dcbc4.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9978e0ccc8d55999338ae7a942dcbc4.png)'
- en: A number of existing business systems and organizational applications are still
    somewhat rules based. By fusing the generative with the structured precision of
    rule-based logic, this pattern aims to produce solutions that is both creative
    yet compliant.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现有的商业系统和组织应用仍然在某种程度上是基于规则的。通过将生成式方法与基于规则的逻辑的结构化精确性结合，这种模式旨在产生既富有创意又符合要求的解决方案。
- en: It’s a powerful strategy for industries where outputs must adhere to stringent
    standards or regulations, ensuring the AI remains within the bounds of desired
    parameters while still being able to innovate and engage. A good example of this
    is generating intents and message flows for a phone call IVR system or traditional
    (*non-llm based*) chat bots which is rules based.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个强有力的策略，适用于那些要求输出必须符合严格标准或法规的行业，确保AI在创新和参与的同时，仍然保持在预定参数的范围内。一个很好的例子是为电话IVR系统或传统的（*非LLM基础*）基于规则的聊天机器人生成意图和消息流程。
- en: 5) Utilizing Knowledge Graphs with LLM’s
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5) 利用知识图谱与大语言模型（LLM）
- en: '![](../Images/28d31cb2e4735f026c06dd8d980a5118.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28d31cb2e4735f026c06dd8d980a5118.png)'
- en: Integrating knowledge graphs with generative AI models gives them a fact orientated
    super power, allowing for outputs that are not only contextually aware but also
    more factually correct.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 将知识图谱与生成式AI模型结合，赋予它们以事实为导向的超能力，使得输出不仅在语境上具有意识，而且更为准确。
- en: This approach is crucial for applications where truth and accuracy are non-negotiable,
    such as in educational content creation, medical advice, or any field where misinformation
    could have serious consequences.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法对于那些对真理和准确性要求严格的应用至关重要，如教育内容创作、医疗建议或任何可能导致严重后果的误信息领域。
- en: Knowledge graphs and graph ontologies (*set of concepts for a graph*) allow
    for complex topics or organizational problems to be broken into a structured format
    to help ground a large language model with deep context. You can also use a language
    model to generate the ontologies in a format such as JSON or RDF, [example prompt
    I created you can use](https://gist.github.com/koconder/c37806ecc2e0a6d1ed3cdfbe4951b199).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱和图谱本体论（*图谱的概念集合*）允许将复杂的主题或组织问题分解为结构化的格式，以帮助为大语言模型提供深层背景。你还可以使用语言模型生成本体论，格式如JSON或RDF，
    [我为你创建的示例提示可以使用](https://gist.github.com/koconder/c37806ecc2e0a6d1ed3cdfbe4951b199)。
- en: Services you can use for knowledge graphs include graph database services such
    as [ArangoDB](https://arangodb.com/), [Amazon Neptune](https://aws.amazon.com/neptune/),
    [Azure Cosmos DB](https://azure.microsoft.com/en-us/products/cosmos-db) and [Neo4j](https://neo4j.com/).
    There are also wider datasets and services for accessing broader knowledge graphs
    including [Google Enterprise Knowledge Graph API](https://cloud.google.com/enterprise-knowledge-graph/docs/search-api),
    [PyKEEN Datasets](https://github.com/pykeen/pykeen?tab=readme-ov-file#datasets),
    and [Wikidata](https://cloud.google.com/enterprise-knowledge-graph/docs/search-api).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用的一些知识图谱服务包括图数据库服务，如 [ArangoDB](https://arangodb.com/)、[Amazon Neptune](https://aws.amazon.com/neptune/)、[Azure
    Cosmos DB](https://azure.microsoft.com/en-us/products/cosmos-db) 和 [Neo4j](https://neo4j.com/)。还有更广泛的数据集和服务可用于访问更广泛的知识图谱，包括
    [Google企业知识图谱API](https://cloud.google.com/enterprise-knowledge-graph/docs/search-api)、[PyKEEN数据集](https://github.com/pykeen/pykeen?tab=readme-ov-file#datasets)
    和 [Wikidata](https://cloud.google.com/enterprise-knowledge-graph/docs/search-api)。
- en: 6) Swarm Of AI Agents
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6) AI代理群体
- en: '![](../Images/876e65a6bc332cb4a902745b2bb1218e.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/876e65a6bc332cb4a902745b2bb1218e.png)'
- en: Drawing inspiration from natural swarms and heards, this model employs a multitude
    of AI agents that collectively tackle a problem, each contributing a unique perspective.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这一模型汲取了自然界群体和群兽的灵感，采用了多个AI代理共同处理问题，每个代理提供独特的视角。
- en: The resulting aggregated output reflects a form of collective intelligence,
    surpassing what any individual agent could achieve. This pattern is particularly
    advantageous in scenarios that require a breadth of creative solutions or when
    navigating complex datasets.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由此产生的聚合输出体现了一种集体智慧，超越了任何单一代理所能实现的成果。这个模式在需要广泛创意解决方案或在处理复杂数据集时尤为有利。
- en: An example of this could be [reviewing a research paper from a multiple “experts”
    point of view](https://www.fieldstudy.ai/), or assessing customer interactions
    for many use-cases at once from fraud to offers. We take these collective “agents”
    and combine all their inputs together. For high volume swarm’s you can look at
    deploying messaging services such as [Apache Kafka](https://kafka.apache.org/)
    to handle the messages between the agents and services.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个例子是 [从多个“专家”视角审阅研究论文](https://www.fieldstudy.ai/)，或者从多个使用场景同时评估客户互动，从欺诈到优惠。我们将这些集体“代理”结合起来，整合他们的输入。对于高频次的集群，你可以考虑部署消息服务，如
    [Apache Kafka](https://kafka.apache.org/)，来处理代理和服务之间的消息。
- en: 7) Modular Monolith LLM Approach With Composability
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7) 模块化单体LLM方法与可组合性
- en: '![](../Images/dea30f801f0806a78648e20e18d69267.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dea30f801f0806a78648e20e18d69267.png)'
- en: This design champions adaptability, featuring a modular AI system that can dynamically
    reconfigure itself for optimal task performance. It’s akin to having a Swiss Army
    knife, where each module can be selected and activated as needed, making it highly
    effective for businesses that require tailor-made solutions for varying customer
    interactions or product needs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该设计倡导适应性，采用模块化的AI系统，能够动态地重新配置自身，以实现最佳任务性能。它类似于一把瑞士军刀，每个模块可以根据需要选择并激活，使其在需要量身定制解决方案的企业中，针对不同的客户互动或产品需求时尤为高效。
- en: You can deploy the use of various autonomous agent frameworks and architectures
    to develop each of your agents and their tools. Example frameworks include [CrewAI](https://github.com/joaomdmoura/crewAI),
    [Langchain](https://www.langchain.com/), [Microsoft Autogen](https://www.microsoft.com/en-us/research/project/autogen/)
    and [SuperAGI](https://superagi.com/).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以部署各种自主代理框架和架构来开发每个代理及其工具。示例框架包括 [CrewAI](https://github.com/joaomdmoura/crewAI)、[Langchain](https://www.langchain.com/)、[Microsoft
    Autogen](https://www.microsoft.com/en-us/research/project/autogen/) 和 [SuperAGI](https://superagi.com/)。
- en: For a sales modular monolith this could be agents focused on prospecting, one
    handling bookings, one focused on generating messaging, and another updating databases.
    In future as specific services become available from specialized AI companies,
    you can swap out a module for an external or 3rd party service for a given set
    of tasks or domain specific problems.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于销售模块化单体系统，这可能是专注于潜在客户开发的代理，一个负责预订，一个专注于生成消息，另一个更新数据库。未来，随着特定服务的推出，来自专业AI公司的服务，你可以将模块替换为外部或第三方服务，来处理特定任务或领域问题。
- en: 8) Approach To Memory Cognition For LLM’s
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8) LLM的记忆认知方法
- en: '![](../Images/c017d73cd3752af73244a4c348b13038.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c017d73cd3752af73244a4c348b13038.png)'
- en: This approach introduces an element of human-like memory to AI, allowing models
    to recall and build upon previous interactions for more nuanced responses.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法引入了类似人类记忆的元素，使得模型能够回忆并在之前的互动基础上构建，以提供更为细致的回应。
- en: It’s particularly useful for ongoing conversations or learning scenarios, as
    the AI develops a more profound understanding over time, much like a dedicated
    personal assistant or an adaptive learning platform. Memory cognition approaches
    can be developed through summation and storing key events and discussions into
    a vector database over time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它特别适用于持续的对话或学习场景，因为AI随着时间的推移逐渐发展出更深刻的理解，就像一位专注的私人助手或自适应学习平台一样。通过汇总并将关键事件和讨论存储到向量数据库中，可以发展记忆认知方法。
- en: To keep compute of summaries low, you can leverage summation through smaller
    NLP libraries such as [spaCy](https://spacy.io/), or [BART language models](https://huggingface.co/docs/transformers/model_doc/bart)
    if dealing with considerable volumes. Databases used are vector based and retrieval
    during prompt stage to check the short-term memory uses a similarity search to
    locate key “facts”. For those interested on a working solution there is an open-sourced
    solution following a similar pattern called [MemGPT](https://memgpt.readme.io/docs/index).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持摘要的计算成本较低，您可以利用较小的 NLP 库，如 [spaCy](https://spacy.io/) 或 [BART 语言模型](https://huggingface.co/docs/transformers/model_doc/bart)，尤其是在处理大量数据时。所使用的数据库是基于向量的，并且在提示阶段通过相似性搜索来检索短期记忆，定位关键“事实”。对于有兴趣了解工作解决方案的人，可以参考一个开源解决方案，遵循类似模式，名为
    [MemGPT](https://memgpt.readme.io/docs/index)。
- en: 9) Red & Blue Team Dual-Model Evaluation
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9) 红队与蓝队双模型评估
- en: '![](../Images/507fc875124778f3f9319a296b7a3456.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/507fc875124778f3f9319a296b7a3456.png)'
- en: In the Red and Blue team evaluation model, one AI generates content while another
    critically evaluates it, akin to a rigorous peer-review process. This dual-model
    setup is excellent for quality control, making it highly applicable in content
    generation platforms where credibility and accuracy are vital, such as news aggregation
    or educational material production.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在红队与蓝队评估模型中，一个 AI 生成内容，而另一个则对其进行批判性评估，类似于严格的同行评审过程。这种双模型设置非常适合质量控制，因此在内容生成平台中非常适用，特别是在新闻聚合或教育资料制作等需要信誉和准确性的场景中。
- en: This approach can be used to replace parts of human feedback for complex tasks
    with a fine-tuned model to mimic the human review process and refine the results
    for evaluating complex language scenarios and outputs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以用来替代复杂任务中的部分人工反馈，通过一个经过精调的模型模仿人类审阅过程，精炼结果，从而评估复杂的语言场景和输出。
- en: '**Takeaways**'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**要点**'
- en: These design patterns for generative AI are more than mere templates; but the
    frameworks upon which the intelligent systems of tomorrow will grow. As we continue
    to explore and innovate, it’s clear that the architecture we choose will define
    not just the capabilities but the very identity of the AI we create.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些生成性 AI 的设计模式不仅仅是模板；它们是未来智能系统发展的框架。在我们不断探索和创新的过程中，显然我们所选择的架构将不仅定义 AI 的能力，还将定义我们所创造的
    AI 的本质。
- en: By no means this list is final, we will see this space develop as the patterns
    and use cases for generative AI expands. *This write-up was inspired by the* [*AI
    design patterns*](https://tomtunguz.com/ai-design-patterns/) *published by Tomasz
    Tunguz.*
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表绝非最终版本，随着生成性 AI 的模式和应用场景不断扩展，我们将看到这一领域的发展。*这篇文章的灵感来自于Tomasz Tunguz发布的* [*AI设计模式*](https://tomtunguz.com/ai-design-patterns/)
    *。*
- en: Enjoyed This Story?
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 喜欢这个故事吗？
- en: Vincent Koc is a highly accomplished, commercially-focused technologist and
    futurist with a wealth of experience focused in data-driven and digital disciplines.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Vincent Koc 是一位成就卓越、以商业为导向的技术专家和未来学家，拥有丰富的经验，专注于数据驱动和数字化领域。
- en: '[Subscribe for free](https://medium.com/subscribe/@vkoc) to get notified when
    Vincent publishes a new story. Or follow him on [LinkedIn](https://www.linkedin.com/in/koconder/)
    and [X](https://twitter.com/koconder).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[免费订阅](https://medium.com/subscribe/@vkoc) 以便在 Vincent 发布新文章时接收通知。或者在 [LinkedIn](https://www.linkedin.com/in/koconder/)
    和 [X](https://twitter.com/koconder) 上关注他。'
- en: '[](https://medium.com/subscribe/@vkoc?source=post_page-----41425a40d7d0--------------------------------)
    [## Get an email whenever Vincent Koc publishes.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/subscribe/@vkoc?source=post_page-----41425a40d7d0--------------------------------)
    [## 当 Vincent Koc 发布新文章时，您可以通过电子邮件收到通知。'
- en: Get an email whenever Vincent Koc publishes. By signing up, you will create
    a Medium account if you don’t already have…
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 当 Vincent Koc 发布新文章时，您可以通过电子邮件收到通知。通过注册，您将创建一个 Medium 账户（如果您还没有的话）…
- en: medium.com](https://medium.com/subscribe/@vkoc?source=post_page-----41425a40d7d0--------------------------------)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/subscribe/@vkoc?source=post_page-----41425a40d7d0--------------------------------)
- en: '*Unless otherwise noted, all images are by the author*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者提供*'
