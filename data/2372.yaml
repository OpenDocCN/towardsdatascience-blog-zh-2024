- en: Stein’s Paradox
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 斯坦因悖论
- en: 原文：[https://towardsdatascience.com/steins-paradox-ba493f46e181?source=collection_archive---------3-----------------------#2024-09-30](https://towardsdatascience.com/steins-paradox-ba493f46e181?source=collection_archive---------3-----------------------#2024-09-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/steins-paradox-ba493f46e181?source=collection_archive---------3-----------------------#2024-09-30](https://towardsdatascience.com/steins-paradox-ba493f46e181?source=collection_archive---------3-----------------------#2024-09-30)
- en: Why the Sample Mean Isn’t Always the Best
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么样本均值并不总是最优
- en: '[](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)[![Tim
    Sumner](../Images/34225cf53f510e5002042bb1be00f423.png)](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)
    [Tim Sumner](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)[![Tim
    Sumner](../Images/34225cf53f510e5002042bb1be00f423.png)](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)
    [Tim Sumner](https://medium.com/@tim.sumner?source=post_page---byline--ba493f46e181--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)
    ·8 min read·Sep 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ba493f46e181--------------------------------)
    ·阅读时间：8分钟·2024年9月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6b655a6b15a187994596266f9ae44958.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b655a6b15a187994596266f9ae44958.png)'
- en: Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: Averaging is one of the most fundamental tools in statistics, second only to
    counting. While its simplicity might make it seem intuitive, averaging plays a
    central role in many mathematical concepts because of its robust properties. Major
    results in probability, such as the Law of Large Numbers and the Central Limit
    Theorem, emphasize that averaging isn’t just convenient — it’s often optimal for
    estimating parameters. Core statistical methods, like Maximum Likelihood Estimators
    and Minimum Variance Unbiased Estimators (MVUE), reinforce this notion.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值是统计学中最基本的工具之一，仅次于计数。虽然它的简单性可能让人觉得直观，但由于其强大的属性，平均值在许多数学概念中扮演着核心角色。概率论中的重要定理，如大数法则和中心极限定理，都强调了平均值不仅仅是方便——它在估计参数时往往是最优的。核心统计方法，如最大似然估计（MLE）和最小方差无偏估计（MVUE），也进一步证明了这一观点。
- en: However, this long-held belief was upended in 1956[1] when Charles Stein made
    a breakthrough that challenged over 150 years of estimation theory.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这一长期以来的信念在1956年被颠覆[1]，当时查尔斯·斯坦因做出了突破，挑战了超过150年的估计理论。
- en: History
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史
- en: 'Averaging has traditionally been seen as an effective method for estimating
    the central tendency of a random variable’s distribution, particularly in the
    case of a normal distribution. The normal (or Gaussian) distribution is characterized
    by its bell-shaped curve and two key parameters: the mean (θ) and the standard
    deviation (σ). The mean indicates the center of the curve, while the standard
    deviation reflects the spread of the data.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值一直被认为是估计随机变量分布的集中趋势的有效方法，特别是在正态分布的情况下。正态（或高斯）分布的特点是钟形曲线和两个关键参数：均值（θ）和标准差（σ）。均值表示曲线的中心，而标准差反映了数据的分布范围。
- en: Statisticians often work backward, inferring these parameters from observed
    data. Gauss demonstrated that the sample mean maximizes the likelihood of observing
    the data, making it an unbiased estimator — meaning it doesn’t systematically
    overestimate or underestimate the true mean (θ).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家经常是倒推，通过观察数据来推断这些参数。高斯证明了样本均值最大化了观察数据的似然性，因此它是一个无偏估计量——这意味着它不会系统地高估或低估真实均值（θ）。
- en: Further developments in statistical theory confirmed the utility of the sample
    mean, which minimizes the expected squared error when compared to other linear
    unbiased estimators. Researchers like R.A. Fisher and Jerzy Neyman expanded on
    these ideas by introducing risk functions, which measure the average squared error
    for different values of θ. They found that while both the mean and the median
    have constant risk, the mean consistently delivers lower risk, confirming its
    superiority.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 统计理论的进一步发展确认了样本均值的实用性，样本均值在与其他线性无偏估计量比较时，能够最小化预期的平方误差。像 R.A. 费舍尔和杰尔日·内曼这样的研究人员通过引入风险函数扩展了这些思想，风险函数用于衡量不同
    θ 值下的平均平方误差。他们发现，尽管均值和中位数的风险是恒定的，但均值始终提供较低的风险，证明了其优越性。
- en: However, Stein’s theorem showed that when estimating three or more parameters
    simultaneously, the sample mean becomes inadmissible. In these cases, biased estimators
    can outperform the sample mean by offering lower overall risk. Stein’s work revolutionized
    statistical inference, improving accuracy in multi-parameter estimation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，斯坦因定理表明，当同时估计三个或更多参数时，样本均值变得不可接受。在这些情况下，偏倚估计量通过提供更低的整体风险，可以优于样本均值。斯坦因的工作彻底改变了统计推断，提升了多参数估计的准确性。
- en: The James-Stein Estimator
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 詹姆斯-斯坦因估计量
- en: The James-Stein[2] estimator is a key tool in the paradox discovered by Charles
    Stein. It challenges the notion that the sample mean is always the best estimator,
    particularly when estimating multiple parameters simultaneously. The idea behind
    the James-Stein estimator is to “shrink” individual sample means toward a central
    value (the grand mean), which reduces the overall estimation error.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 詹姆斯-斯坦因[2]估计量是查尔斯·斯坦因发现的悖论中的关键工具。它挑战了样本均值总是最佳估计量的观点，尤其是在同时估计多个参数时。詹姆斯-斯坦因估计量的核心思想是将各个样本均值“收缩”向一个中央值（总均值），从而减少整体估计误差。
- en: To clarify this, let’s start by considering a vector **x** representing the
    sample means of several variables (not necessarily independent). If we take the
    average of all these means, we get a single value, denoted by *μ*, which we refer
    to as the grand mean. The James-Stein estimator works by moving each sample mean
    closer to this grand mean, reducing their variance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清这一点，我们首先考虑一个向量 **x**，它表示多个变量的样本均值（不一定独立）。如果我们将这些均值的平均值取出来，我们得到一个单一的值，记作
    *μ*，我们称之为总均值。詹姆斯-斯坦因估计量的工作原理是将每个样本均值向这个总均值靠拢，从而减少它们的方差。
- en: 'The general formula[3] for the James-Stein estimator is:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 詹姆斯-斯坦因估计量的通用公式[3]是：
- en: '![](../Images/b6463074c2b0989a789b4f70b3cd145f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6463074c2b0989a789b4f70b3cd145f.png)'
- en: 'Where:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '**x** is the sample mean vector.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**x** 是样本均值向量。'
- en: '*μ* is the grand mean (the average of the sample means).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*μ* 是总均值（样本均值的平均值）。'
- en: '*c* is a shrinkage factor that lies between 0 and 1\. It determines how much
    we pull the individual means toward the grand mean.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*c* 是一个介于 0 和 1 之间的收缩因子。它决定了我们将各个均值拉向总均值的程度。'
- en: The goal here is to reduce the distance between the individual sample means
    and the grand mean. For example, if one sample mean is far from the grand mean,
    the estimator will shrink it toward the center, smoothing out the variation in
    the data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是减少各个样本均值与总均值之间的距离。例如，如果某个样本均值离总均值很远，估计量会将其收缩向中心，从而平滑数据中的变异性。
- en: 'The value of *c*, the shrinkage factor, depends on the data and what is being
    estimated. A sample mean vector follows a multivariate normal distribution, so
    if this is what we are trying to estimate, the formula becomes:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*c* 的值，即收缩因子，取决于数据和估计的内容。样本均值向量遵循多元正态分布，因此如果我们试图估计的是这个分布，公式变为：'
- en: '![](../Images/845bc8961fa121fa17e89599bfd7566d.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/845bc8961fa121fa17e89599bfd7566d.png)'
- en: 'Where:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*p* is the number of parameters being estimated (the length of **x**).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p* 是正在估计的参数个数（即 **x** 的长度）。'
- en: '*σ*² is the variance of the sample mean vector **x**.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*σ*² 是样本均值向量 **x** 的方差。'
- en: The term (*p* — 2)/**||x||**² adjusts the amount of shrinkage based on the data’s
    variance and the number of parameters.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项 (*p* — 2)/**||x||**² 根据数据的方差和参数的个数调整收缩量。
- en: '**Key Assumptions and Adjustments**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键假设和调整**'
- en: One key assumption for using the James-Stein estimator is that the variance
    *σ*² is the same for all variables, which is often not realistic in real-world
    data. However, this assumption can be mitigated by standardizing the data, so
    all variables have the same variance. Alternatively, you can average the individual
    variances into one pooled estimate. This approach works especially well with larger
    datasets, where the variance differences tend to diminish as sample size increases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用James-Stein估计量的一个关键假设是方差*σ*²对所有变量是相同的，但在实际数据中这一假设通常不成立。然而，可以通过标准化数据来缓解这一假设，使得所有变量具有相同的方差。另一种方法是将各个变量的方差平均化为一个合并估计。这种方法在数据集较大时尤其有效，因为随着样本量的增加，方差差异通常会减小。
- en: Once the data is standardized or pooled, the shrinkage factor can be applied
    to adjust each sample mean appropriately.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被标准化或合并，收缩因子就可以应用，以适当调整每个样本均值。
- en: '**Choosing the Shrinkage Factor**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择收缩因子**'
- en: The shrinkage factor *c* is crucial because it controls how much the sample
    means are pulled toward the grand mean. A value of *c* close to 1 means little
    to no shrinkage, which resembles the behavior of the regular sample mean. Conversely,
    a *c* close to 0 means significant shrinkage, pulling the sample means almost
    entirely toward the grand mean.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩因子*c*至关重要，因为它控制样本均值被拉向总体均值的程度。*c*接近1表示几乎没有收缩，类似于常规样本均值的行为。相反，*c*接近0表示显著的收缩，几乎将样本均值完全拉向总体均值。
- en: The optimal value of *c* depends on the specific data and the parameters being
    estimated, but the general guideline is that the more parameters there are (i.e.,
    larger *p*), the more shrinkage is beneficial, as this reduces the risk of over
    fitting to noisy data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*c*的最优值取决于具体数据和估计的参数，但一般的指导原则是，参数越多（即*p*越大），收缩越有益，因为这减少了对噪声数据的过拟合风险。'
- en: '**Implementing the James-Stein Estimator in Code**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**在代码中实现James-Stein估计量**'
- en: 'Here are the James-Stein estimator functions in R, Python, and Julia:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是James-Stein估计量在R、Python和Julia中的函数：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Example
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: 'To demonstrate the versatility of this technique, I will generate a 6-dimensional
    data set with each column containing numerical data from various random distributions.
    Here are the specific distributions and parameters of each I will be using:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这一技术的多样性，我将生成一个6维的数据集，每一列都包含来自不同随机分布的数值数据。以下是我将使用的每个分布及其参数：
- en: '*X1 ~ t-distribution* (ν = 3) *X2 ~ Binomial* (*n* = 10, *p* = 0.4) *X3 ~ Gamma*
    (*α =* 3, *β =* 2) *X4 ~ Uniform* (*a =* 0, *b* = 1) *X5 ~ Exponential* (*λ* =
    50) *X6 ~ Poisson* (*λ* = 2)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*X1 ~ t分布*（ν = 3） *X2 ~ 二项分布*（*n* = 10, *p* = 0.4） *X3 ~ Gamma分布*（*α =* 3,
    *β =* 2） *X4 ~ 均匀分布*（*a =* 0, *b* = 1） *X5 ~ 指数分布*（*λ* = 50） *X6 ~ 泊松分布*（*λ* =
    2）'
- en: Note each column in this data set contains independent variables, in that no
    column should be correlated with another since they were created independently.
    This is not a requirement to use this method. It was done this way simply for
    simplicity and to demonstrate the paradoxical nature of this result. If you’re
    not entirely familiar with any or all of these distributions, I’ll include a simple
    visual of each of the univariate columns of the randomly generated data. This
    is simply one iteration of 1,000 generated random variables from each of the aforementioned
    distributions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本数据集中的每一列都包含独立变量，即每一列之间不应存在相关性，因为它们是独立创建的。这并不是使用此方法的必要条件，仅仅是为了简化操作并展示此结果的悖论性质。如果你不完全熟悉这些分布中的任何一个或全部，我会附上一张简单的图，展示每个单变量列的随机生成数据。这仅仅是从上述每个分布中生成的1,000个随机变量中的一次迭代。
- en: '![](../Images/9f6c629c812641ed53f6c49971e0cd10.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f6c629c812641ed53f6c49971e0cd10.png)'
- en: It should be clear from the histograms above that not all of these variables
    follow a normal distribution implying the dataset as a whole is not multivariate
    normal.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的直方图中应该可以清楚地看到，并非所有这些变量都遵循正态分布，这意味着整个数据集不是多元正态分布。
- en: Since the true distributions of each are known, we know the true averages of
    each. The average of this multivariate dataset can be expressed in vector form
    with each row entry representing the average of the variable respectively. In
    this example,
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个分布的真实情况已知，我们知道每个分布的真实平均值。该多变量数据集的平均值可以以向量形式表示，每行条目代表相应变量的平均值。在此示例中，
- en: '![](../Images/fb5b2428002e82d4f2bef3b8b086024e.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb5b2428002e82d4f2bef3b8b086024e.png)'
- en: 'Knowing the true averages of each variable will allow us to be able to measure
    how close the sample mean, or James Stein estimator gets implying the closer the
    better. Below is the experiment I ran in R code which generated each of the 6
    random variables and tested against the true averages using the Mean Squared Error.
    This experiment was then ran 10,000 times using four different sample sizes: 5,
    50, 500, and 5,000.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 知道每个变量的真实平均值将帮助我们衡量样本均值或詹姆斯·斯坦估计器的接近程度，这意味着接近真实值越好。以下是我在R代码中进行的实验，该实验生成了6个随机变量，并使用均方误差（Mean
    Squared Error）与真实平均值进行比较。该实验随后进行了10,000次，使用了四种不同的样本大小：5、50、500和5,000。
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: From all 40,000 trails, the total average MSE of each sample size is computed
    by running the last two lines. The results of each can be seen in the table below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有40,000次试验中，通过运行最后两行代码计算了每个样本大小的总平均MSE。每个结果可以在下表中看到。
- en: '![](../Images/b3f8fa5c9d6aece3d817aabd2c0191eb.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3f8fa5c9d6aece3d817aabd2c0191eb.png)'
- en: The results of this of this simulation show that the James-Stein estimator is
    consistently better than the sample mean using the MSE, but that this difference
    decreases as the sample size increases.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这次模拟的结果显示，詹姆斯·斯坦估计器在使用MSE时始终优于样本均值，但这种差异随着样本大小的增加而减小。
- en: '**Conclusion**'
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: 'The James-Stein estimator demonstrates a paradox in estimation: it is possible
    to improve estimates by incorporating information from seemingly independent variables.
    While the difference in MSE might be negligible for large sample sizes, this result
    sparked much debate when it was first introduced. The discovery marked a key turning
    point in statistical theory, and it remains relevant today for multi-parameter
    estimation.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 詹姆斯·斯坦估计器展示了一个估计的悖论：通过结合看似独立的变量的信息，竟然能够改善估计。虽然在样本量较大时，MSE的差异可能微不足道，但这一结果在首次提出时引发了广泛的争议。这一发现标志着统计理论的一个关键转折点，并且在今天的多参数估计中仍然具有重要意义。
- en: If you’d like to explore more, check out [this detailed article on Stein’s paradox](https://joe-antognini.github.io/machine-learning/steins-paradox)
    and other references used to write this document.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步探索，请查看[关于斯坦因悖论的这篇详细文章](https://joe-antognini.github.io/machine-learning/steins-paradox)以及写作本文档时引用的其他资料。
- en: References
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Stein, C. (1956). [**Inadmissibility of the usual estimator for the mean
    of a multivariate normal distribution**](https://www.degruyter.com/document/doi/10.1525/9780520313880-018/html).
    *Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability*,
    1, 197–206.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Stein, C. (1956). [**多元正态分布均值的常用估计量不可接受性**](https://www.degruyter.com/document/doi/10.1525/9780520313880-018/html)。*第三届伯克利数学统计与概率研讨会论文集*，1，197–206。'
- en: '[2] Stein, C. (1961). [**Estimation with quadratic loss**](https://link.springer.com/chapter/10.1007/978-1-4612-0919-5_30).
    *In S. S. Gupta & J. O. Berger (Eds.), Statistical Decision Theory and Related
    Topics* (Vol. 1, pp. 361–379). Academic Press.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Stein, C. (1961). [**带有二次损失的估计**](https://link.springer.com/chapter/10.1007/978-1-4612-0919-5_30)。*在S.
    S. Gupta & J. O. Berger（编），统计决策理论与相关话题*（第1卷，第361–379页）。学术出版社。'
- en: '[3] Efron, B., & Morris, C. (1977). [**Stein’s paradox in statistics**](https://link.springer.com/chapter/10.1007/978-0-387-75692-9_7).
    *Scientific American*, 236(5), 119–127'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Efron, B., & Morris, C. (1977). [**斯坦因悖论在统计学中的应用**](https://link.springer.com/chapter/10.1007/978-0-387-75692-9_7)。*科学美国人*，236(5)，119–127'
