- en: Stop Guessing and Measure Your RAG System to Drive Real Improvements
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止猜测，衡量你的RAG系统以推动真正的改进
- en: 原文：[https://towardsdatascience.com/stop-guessing-and-measure-your-rag-system-to-drive-real-improvements-bfc03f29ede3?source=collection_archive---------1-----------------------#2024-10-04](https://towardsdatascience.com/stop-guessing-and-measure-your-rag-system-to-drive-real-improvements-bfc03f29ede3?source=collection_archive---------1-----------------------#2024-10-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stop-guessing-and-measure-your-rag-system-to-drive-real-improvements-bfc03f29ede3?source=collection_archive---------1-----------------------#2024-10-04](https://towardsdatascience.com/stop-guessing-and-measure-your-rag-system-to-drive-real-improvements-bfc03f29ede3?source=collection_archive---------1-----------------------#2024-10-04)
- en: Key metrics and techniques to elevate your retrieval-augmented generation performance
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提升检索增强生成（RAG）性能的关键指标和技巧
- en: '[](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)[![Abhinav
    Kimothi](../Images/ed5548c99e1910e7dc35bfcac26cb314.png)](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)
    [Abhinav Kimothi](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)[![Abhinav
    Kimothi](../Images/ed5548c99e1910e7dc35bfcac26cb314.png)](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)
    [Abhinav Kimothi](https://medium.com/@abhinavkimothi?source=post_page---byline--bfc03f29ede3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)
    ·24 min read·Oct 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bfc03f29ede3--------------------------------)
    ·阅读时间：24分钟·2024年10月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Advancements in Large Language Models (LLMs) have captured the imagination of
    the world. With the release of [ChatGPT by OpenAI](https://chatgpt.com/), in November,
    2022, previously obscure terms like Generative AI entered the public discourse.
    In a short time LLMs found a wide [applicability in modern language processing
    tasks](https://pixelplex.io/blog/llm-applications/) and even paved the way for
    [autonomous AI agents](https://www.promptingguide.ai/research/llm-agents). Some
    call it a watershed moment in technology and make lofty comparisons with the advent
    of the internet or even the invention of the light bulb. Consequently, a vast
    majority of business leaders, software developers and entrepreneurs are in hot
    pursuit of using LLMs to their advantage.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的进展引起了全世界的关注。随着[OpenAI发布的ChatGPT](https://chatgpt.com/)在2022年11月上线，以前鲜为人知的术语如生成式人工智能（Generative
    AI）进入了公众话语。短短时间内，LLMs在现代语言处理任务中找到了广泛的[应用](https://pixelplex.io/blog/llm-applications/)，甚至为[自主AI代理](https://www.promptingguide.ai/research/llm-agents)铺平了道路。有些人称之为技术的分水岭时刻，并将其与互联网的到来，甚至是电灯泡的发明做出崇高的比较。因此，绝大多数商业领袖、软件开发人员和企业家都在热衷于利用LLMs为自己带来优势。
- en: Retrieval Augmented Generation, or RAG, stands as a pivotal technique shaping
    the landscape of the applied generative AI. A novel concept introduced by Lewis
    et al in their seminal paper [*Retrieval-Augmented Generation for Knowledge-Intensive
    NLP Tasks*](https://arxiv.org/abs/2005.11401), RAG has swiftly emerged as a cornerstone,
    enhancing reliability and trustworthiness in the outputs from Large Language Models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）作为塑造应用生成式人工智能领域的一个关键技术，正在发挥重要作用。RAG是Lewis等人在其开创性论文[*Retrieval-Augmented
    Generation for Knowledge-Intensive NLP Tasks*](https://arxiv.org/abs/2005.11401)中提出的一个新概念，它迅速成为增强大型语言模型输出可靠性和可信度的基石。
- en: In this blog post, we will go into the details of evaluating RAG systems. But
    before that, let us set up the context by understanding the need for RAG and getting
    an overview of the implementation of RAG pipelines.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将深入探讨如何评估RAG系统。但在此之前，让我们通过理解RAG的需求并概述RAG管道的实施来设定背景。
- en: The Curse of the LLMs
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的诅咒
