- en: Deploying LLMs locally with Apple’s MLX framework
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用苹果的MLX框架在本地部署LLM
- en: 原文：[https://towardsdatascience.com/deploying-llms-locally-with-apples-mlx-framework-2b3862049a93?source=collection_archive---------2-----------------------#2024-01-20](https://towardsdatascience.com/deploying-llms-locally-with-apples-mlx-framework-2b3862049a93?source=collection_archive---------2-----------------------#2024-01-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deploying-llms-locally-with-apples-mlx-framework-2b3862049a93?source=collection_archive---------2-----------------------#2024-01-20](https://towardsdatascience.com/deploying-llms-locally-with-apples-mlx-framework-2b3862049a93?source=collection_archive---------2-----------------------#2024-01-20)
- en: A technical deep dive into the new deep learning library MLX
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对新的深度学习库MLX的技术深入探讨
- en: '[](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)[![Heiko
    Hotz](../Images/d08394d46d41d5cd9e76557a463be95e.png)](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)
    [Heiko Hotz](https://heiko-hotz.medium.com/?source=post_page---byline--2b3862049a93--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)
    ·9 min read·Jan 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2b3862049a93--------------------------------)
    ·9分钟阅读·2024年1月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/11ece286cb8fbcacee9ff6dbb426b6b9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11ece286cb8fbcacee9ff6dbb426b6b9.png)'
- en: Image by author (using DALL-E 3)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供（使用DALL-E 3）
- en: What is this about?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这是什么内容？
- en: In December 2023, Apple released their new [MLX deep learning framework](https://github.com/ml-explore/mlx),
    an array framework for machine learning on Apple silicon, developed by their machine
    learning research team. This tutorial will explore the framework and demonstrate
    deploying the Mistral-7B model locally on a MacBook Pro (MBP). We’ll set up a
    local chat interface to interact with the deployed model and test its inference
    performance in terms of tokens generated per second. Additionally, we’ll delve
    into the MLX API to understand the available levers for altering the model’s behaviour
    and influencing the generated text.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年12月，苹果发布了他们的新[MLX深度学习框架](https://github.com/ml-explore/mlx)，这是一个为苹果自家芯片设计的机器学习数组框架，由他们的机器学习研究团队开发。本文将探讨该框架，并演示如何在MacBook
    Pro（MBP）上本地部署Mistral-7B模型。我们将设置一个本地聊天界面，与部署的模型进行交互，并测试其推理性能，即每秒生成的tokens数量。此外，我们还将深入了解MLX
    API，理解可用的控制手段，用于调整模型行为并影响生成的文本。
- en: 'As usual, the code is available in a public GitHub repository: [https://github.com/marshmellow77/mlx-deep-dive](https://github.com/marshmellow77/mlx-deep-dive)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可在公开的GitHub仓库中获取：[https://github.com/marshmellow77/mlx-deep-dive](https://github.com/marshmellow77/mlx-deep-dive)
- en: Why is this important?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这很重要？
- en: Apple’s new machine learning framework, MLX, offers notable advantages over
    other deep learning frameworks with its unified memory architecture for machine
    learning on Apple silicon. Unlike traditional frameworks such as PyTorch and Jax,
    which require costly data copying between CPU and GPU, MLX maintains data in shared
    memory accessible to both. This design eliminates the overhead of data…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果的新机器学习框架MLX，在其统一内存架构方面提供了相较于其他深度学习框架的显著优势，专为苹果自家芯片上的机器学习设计。与传统框架（如PyTorch和Jax）不同，后者需要在CPU和GPU之间进行昂贵的数据复制，MLX则将数据保存在可供两者访问的共享内存中。这个设计消除了数据复制的开销……
