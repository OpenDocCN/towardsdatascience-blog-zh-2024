- en: 'MOIRAI-MOE: Upgrading MOIRAI with Mixture-of-Experts for Enhanced Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MOIRAI-MOE：通过专家混合技术升级MOIRAI以增强预测能力
- en: 原文：[https://towardsdatascience.com/moirai-moe-upgrading-moirai-with-mixture-of-experts-for-enhanced-forecasting-26a38017734f?source=collection_archive---------3-----------------------#2024-11-02](https://towardsdatascience.com/moirai-moe-upgrading-moirai-with-mixture-of-experts-for-enhanced-forecasting-26a38017734f?source=collection_archive---------3-----------------------#2024-11-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/moirai-moe-upgrading-moirai-with-mixture-of-experts-for-enhanced-forecasting-26a38017734f?source=collection_archive---------3-----------------------#2024-11-02](https://towardsdatascience.com/moirai-moe-upgrading-moirai-with-mixture-of-experts-for-enhanced-forecasting-26a38017734f?source=collection_archive---------3-----------------------#2024-11-02)
- en: The popular foundation time-series model just got an update
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这款流行的基础时间序列模型刚刚获得了更新。
- en: '[](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)[![Nikos
    Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)
    [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)[![Nikos
    Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)
    [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page---byline--26a38017734f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)
    ·9 min read·Nov 2, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--26a38017734f--------------------------------)
    ·阅读时间9分钟·2024年11月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c9226dcc182fdd8bd83c8b18f4665da4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9226dcc182fdd8bd83c8b18f4665da4.png)'
- en: '[*Image Source*](https://arxiv.org/pdf/2410.10469)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*图片来源*](https://arxiv.org/pdf/2410.10469)'
- en: '**The race to build the Top foundation forecasting model is on!**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**争夺打造顶级基础预测模型的竞赛已经开始！**'
- en: Salesforce’s ***MOIRAI***, one of the early foundation models, achieved high
    benchmark results and was open-sourced along with its pretraining dataset, LOTSA.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce的***MOIRAI***，作为早期的基础模型之一，达到了高基准结果，并与其预训练数据集LOTSA一起开源。
- en: We extensively analyzed how MOIRAI works [here](https://medium.com/towards-data-science/moirai-salesforces-foundation-model-for-time-series-forecasting-4eff6c34093d)
    — and built an end-to-end project comparing MOIRAI with popular statistical models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[这里](https://medium.com/towards-data-science/moirai-salesforces-foundation-model-for-time-series-forecasting-4eff6c34093d)深入分析了MOIRAI的工作原理——并构建了一个端到端的项目，将MOIRAI与流行的统计模型进行比较。
- en: Salesforce has now released an upgraded version — ***MOIRAI-MOE*** — with significant
    improvements, particularly the addition of **Mixture-of-Experts (MOE)**. We briefly
    discussed MOE when another model, [Time-MOE](https://aihorizonforecast.substack.com/p/time-moe-billion-scale-time-series),
    also used multiple experts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce现在发布了升级版——***MOIRAI-MOE***——具有显著的改进，特别是增加了**专家混合（MOE）**。我们曾在讨论另一个模型时简要提到过MOE，[Time-MOE](https://aihorizonforecast.substack.com/p/time-moe-billion-scale-time-series)也使用了多个专家。
- en: 'In this article, we’ll cover:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将讨论：
- en: How MOIRAI-MOE works and why it’s a powerful model.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOIRAI-MOE如何工作，以及为什么它是一个强大的模型。
- en: Key differences between MOIRAI and MOIRAI-MOE.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOIRAI和MOIRAI-MOE之间的主要区别。
- en: How MOIRAI-MOE’s use of Mixture-of-Experts enhances accuracy.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOIRAI-MOE如何利用专家混合提高预测准确性。
- en: How Mixture-of-Experts generally solves frequency variation issues in foundation
    time-series models.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家混合（Mixture-of-Experts）如何通常解决基础时间序列模型中的频率变化问题。
- en: Let’s get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: ✅ I’ve launched [**AI Horizon Forecast**](https://aihorizonforecast.substack.com/)**,**
    a newsletter focusing on time-series and innovative…
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ✅ 我已推出[**AI Horizon Forecast**](https://aihorizonforecast.substack.com/)**，**这是一个专注于时间序列和创新的新闻通讯……
