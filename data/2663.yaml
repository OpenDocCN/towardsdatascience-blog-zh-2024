- en: Choosing and Implementing Hugging Face Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择与实施Hugging Face模型
- en: 原文：[https://towardsdatascience.com/choosing-and-implementing-hugging-face-models-026d71426fbe?source=collection_archive---------1-----------------------#2024-11-01](https://towardsdatascience.com/choosing-and-implementing-hugging-face-models-026d71426fbe?source=collection_archive---------1-----------------------#2024-11-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/choosing-and-implementing-hugging-face-models-026d71426fbe?source=collection_archive---------1-----------------------#2024-11-01](https://towardsdatascience.com/choosing-and-implementing-hugging-face-models-026d71426fbe?source=collection_archive---------1-----------------------#2024-11-01)
- en: Pulling pre-trained models out of the box for your use case
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将预训练模型应用到你的使用案例中
- en: '[](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page---byline--026d71426fbe--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)
    ·8 min read·Nov 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: · 发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--026d71426fbe--------------------------------)
    · 阅读时长8分钟·2024年11月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d86c2584594995a09bfe18527bc9a2ac.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d86c2584594995a09bfe18527bc9a2ac.png)'
- en: Photo by [Erda Estremera](https://unsplash.com/@erdaest?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Erda Estremera](https://unsplash.com/@erdaest?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: I’ve been having a lot of fun in my daily work recently experimenting with models
    from the Hugging Face catalog, and I thought this might be a good time to share
    what I’ve learned and give readers some tips for how to apply these models with
    a minimum of stress.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我在日常工作中尝试了很多来自Hugging Face目录的模型，觉得这可能是一个不错的时机，分享我所学到的经验，并给读者一些建议，如何以最小的压力应用这些模型。
- en: My specific task recently has involved looking at blobs of unstructured text
    data (think memos, emails, free text comment fields, etc) and classifying them
    according to categories that are relevant to a business use case. There are a
    ton of ways you can do this, and I’ve been exploring as many as I can feasibly
    do, including simple stuff like pattern matching and lexicon search, but also
    expanding to using pre-built neural network models for a number of different functionalities,
    and I’ve been moderately pleased with the results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近的具体任务涉及查看一些无结构的文本数据（比如备忘录、电子邮件、自由文本评论字段等），并根据与业务使用案例相关的类别对其进行分类。有很多方法可以做到这一点，我尽可能多地进行了探索，包括像模式匹配和词汇搜索这样简单的方法，但也扩展到使用预构建的神经网络模型，进行不同功能的应用，结果让我感到比较满意。
- en: I think the best strategy is to incorporate multiple techniques, in some form
    of ensembling, to get the best of the options. I don’t trust these models necessarily
    to get things right often enough (and definitely not consistently enough) to use
    them solo, but when combined with more basic techniques they can add to the signal.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为最佳的策略是结合多种技术，以某种形式的集成方法，来获得各选项的优点。我不完全信任这些模型，不能保证它们足够频繁地正确（而且绝对不能稳定一致地做到这一点），因此不适合单独使用，但当与更基础的技术结合时，它们可以增强信号。
- en: Choosing the use case
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择使用案例
- en: For me, as I’ve mentioned, the task is just to take blobs of text, usually written
    by a human, with no consistent format or schema, and try to figure out what categories
    apply to that text. I’ve taken a few different approaches, outside of the analysis
    methods mentioned earlier, to do that, and these range from very low effort to
    somewhat more work on my part. These are three of the strategies that I’ve tested
    so far.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，正如我之前提到的，任务只是接受一大堆文本块，通常是由人类编写的，没有一致的格式或模式，并尝试弄清楚哪些类别适用于该文本。除了前面提到的分析方法之外，我采取了一些不同的方法来做到这一点，这些方法从非常低的努力到我付出更多努力的程度不等。这是我迄今为止测试过的三种策略。
- en: Ask the model to choose the category (zero-shot classification — I’ll use this
    as an example later on in this article)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求模型选择类别（零样本分类 — 我将在本文后面以此为例）。
- en: Use a named entity recognition model to find key objects referenced in the text,
    and make classification based on that
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命名实体识别模型找到文本中引用的关键对象，并基于此进行分类。
- en: Ask the model to summarize the text, then apply other techniques to make classification
    based on the summary
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求模型总结文本，然后应用其他技术基于总结进行分类。
- en: Finding the models
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找模型
- en: This is some of the most fun — looking through the Hugging Face catalog for
    models! At [https://huggingface.co/models](https://huggingface.co/models) you
    can see a gigantic assortment of the models available, which have been added to
    the catalog by users. I have a few tips and pieces of advice for how to select
    wisely.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最有趣的部分之一 — 浏览 Hugging Face 模型目录！在 [https://huggingface.co/models](https://huggingface.co/models)
    上，您可以看到一个巨大的模型集合，这些模型是由用户添加到目录中的。我有一些建议和建议，告诉您如何明智地进行选择。
- en: Look at the download and like numbers, and don’t choose something that has not
    been tried and tested by a decent number of other users. You can also check the
    Community tab on each model page to see if users are discussing challenges or
    reporting bugs.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看下载和点赞数，不要选择尚未经过足够数量其他用户尝试和测试的内容。您还可以查看每个模型页面上的“社区”选项卡，看看用户是否在讨论挑战或报告错误。
- en: Investigate who uploaded the model, if possible, and determine if you find them
    trustworthy. This person who trained or tuned the model may or may not know what
    they’re doing, and the quality of your results will depend on them!
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查上传模型的人，如果可能的话，并确定您是否信任他们。训练或调整模型的这个人可能知道自己在做什么，也可能不知道，您的结果质量将取决于他们！
- en: Read the documentation closely, and skip models with little or no documentation.
    You’ll struggle to use them effectively anyway.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仔细阅读文档，并跳过文档很少或没有文档的模型。无论如何，您都将难以有效地使用它们。
- en: Use the filters on the side of the page to narrow down to models suited to your
    task. The volume of choices can be overwhelming, but they are well categorized
    to help you find what you need.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用页面侧边的过滤器将模型缩小到适合您任务的模型。选择太多可能会让人感到不知所措，但它们被很好地分类，以帮助您找到所需的内容。
- en: Most model cards offer a quick test you can run to see the model’s behavior,
    but keep in mind that this is just one example and it’s probably one that was
    chosen because the model’s good at that and finds this case pretty easy.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数模型卡提供了一个快速测试，您可以运行以查看模型的行为，但请记住，这只是一个示例，可能是因为模型擅长这个领域并且发现这种情况相当容易。
- en: Incorporating into your code
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将其整合到您的代码中
- en: Once you’ve found a model you’d like to try, it’s easy to get going- click the
    “Use this Model” button on the top right of the Model Card page, and you’ll see
    the choices for how to implement. If you choose the Transformers option, you’ll
    get some instructions that look like this.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您找到一个想尝试的模型，只需点击 Model Card 页面右上角的“使用此模型”按钮，即可开始使用。如果您选择 Transformers 选项，您将看到如下实施方式的选择。如果您选择
    Transformers 选项，您将看到如下实施方式的选择。
- en: '![](../Images/b8cdf8040c61623e5a4129e84a3dd4fb.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8cdf8040c61623e5a4129e84a3dd4fb.png)'
- en: Screenshot taken by author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者拍摄的屏幕截图
- en: If a model you’ve selected is not supported by the Transformers library, there
    may be other techniques listed, like TF-Keras, scikit-learn, or more, but all
    should show instructions and sample code for easy use when you click that button.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择的模型不受 Transformers 库支持，可能会列出其他技术，如 TF-Keras、scikit-learn 等，但当您点击该按钮时，所有这些都应该显示使用说明和示例代码以便轻松使用。
- en: In my experiments, all the models were supported by Transformers, so I had a
    mostly easy time getting them running, just by following these steps. If you find
    that you have questions, you can also look at the deeper documentation and see
    full API details for the Transformers library and the different classes it offers.
    I’ve definitely spent some time looking at these docs for specific classes when
    optimizing, but to get the basics up and running you shouldn’t really need to.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的实验中，所有的模型都得到了Transformers的支持，所以只要按照这些步骤进行，我通常能够顺利运行它们。如果你发现有问题，也可以查看更深入的文档，查看Transformers库的完整API细节以及它提供的不同类。我确实花时间查看过这些文档，尤其是在优化时，针对特定类，但如果只是想让基础部分运行起来，实际上不需要那么做。
- en: Preparing inference data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备推理数据
- en: Ok, so you’ve picked out a model that you want to try. Do you already have data?
    If not, I have been using several publicly available datasets for this experimentation,
    mainly from Kaggle, and you can find lots of useful datasets there as well. In
    addition, Hugging Face also has a dataset catalog you can check out, but in my
    experience it’s not as easy to search or to understand the data contents over
    there (just not as much documentation).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，假设你已经选择了一个你想尝试的模型。你已经有数据了吗？如果没有，我在这次实验中使用了几个公开的可用数据集，主要来自Kaggle，你也可以在那里找到许多有用的数据集。此外，Hugging
    Face也有一个数据集目录供你查看，但根据我的经验，它那里的数据并不像Kaggle那样容易搜索或理解（文档相对较少）。
- en: Once you pick a dataset of unstructured text data, loading it to use in these
    models isn’t that difficult. Load your model and your tokenizer (from the docs
    provided on Hugging Face as noted above) and pass all this to the `pipeline` function
    from the transformers library. You’ll loop over your blobs of text in a list or
    pandas Series and pass them to the model function. This is essentially the same
    for whatever kind of task you’re doing, although for zero-shot classification
    you also need to provide a candidate label or list of labels, as I’ll show below.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了一个非结构化文本数据集，将其加载到这些模型中并不难。加载你的模型和分词器（来自上文提到的Hugging Face文档），然后将这一切传递给transformers库中的`pipeline`函数。你将遍历一个列表或pandas
    Series中的文本块，并将它们传递给模型函数。无论你做什么任务，本质上都是一样的，尽管对于零样本分类，你还需要提供候选标签或标签列表，下面我会展示如何做。
- en: Code Example
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码示例
- en: So, let’s take a closer look at zero-shot classification. As I’ve noted above,
    this involves using a pretrained model to classify a text according to categories
    that it hasn’t been specifically trained on, in the hopes that it can use its
    learned semantic embeddings to measure similarities between the text and the label
    terms.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们更深入地了解零样本分类。如我上面所提到的，这涉及使用一个预训练模型，根据模型没有特别训练过的类别来对文本进行分类，目的是希望它能利用其学到的语义嵌入，衡量文本与标签术语之间的相似度。
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will return you a list of dicts, and each of those dicts will contain keys
    for the possible labels, and the values are the probability of each label. You
    don’t have to use the pipeline as I’ve done here, but it makes multi-label zero
    shot a lot easier than manually writing that code, and it returns results that
    are easy to interpret and work with.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个包含字典的列表，每个字典都包含可能标签的键，而值是每个标签的概率。你不一定要像我这里使用pipeline，但它使得多标签零样本分类比手动编写代码要容易得多，而且它返回的结果更容易理解和处理。
- en: If you prefer to not use the pipeline, you can do something like this instead,
    but you’ll have to run it once for each label. Notice how the processing of the
    logits resulting from the model run needs to be specified so that you get human-interpretable
    output. Also, you still need to load the tokenizer and the model as described
    above.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想使用pipeline，你也可以尝试像这样做，但你需要为每个标签分别运行一次。注意，处理模型运行后输出的logits需要明确指定，以便获得易于人类理解的输出。此外，你仍然需要按照上面描述的方法加载分词器和模型。
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To tune, or not?
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调优，还是不调优？
- en: You probably have noticed that I haven’t talked about fine tuning the models
    myself for this project — that’s true. I may do this in future, but I’m limited
    by the fact that I have minimal labeled training data to work with at this time.
    I can use semisupervised techniques or bootstrap a labeled training set, but this
    whole experiment has been to see how far I can get with straight off-the-shelf
    models. I do have a few small labeled data samples, for use in testing the models’
    performance, but that’s nowhere near the same volume of data I will need to tune
    the models.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我在这个项目中没有谈论过自己对模型进行微调 — 这是真的。我可能会在未来这样做，但我受限于我目前拥有的极少标记的训练数据。我可以使用半监督技术或引导一个带标签的训练集，但整个实验的目的是看看我能用现成的模型走多远。我确实有一些小的带标签数据样本，用于测试模型的性能，但这远远不足以调整模型所需的数据量。
- en: If you do have good training data and would like to tune a base model, Hugging
    Face has some docs that can help. [https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有好的训练数据并且想微调一个基础模型，Hugging Face 有一些文档可以帮助。[https://huggingface.co/docs/transformers/en/training](https://huggingface.co/docs/transformers/en/training)
- en: Computation and speed
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算和速度
- en: Performance has been an interesting problem, as I’ve run all my experiments
    on my local laptop so far. Naturally, using these models from Hugging Face will
    be much more compute intensive and slower than the basic strategies like regex
    and lexicon search, but it provides signal that can’t really be achieved any other
    way, so finding ways to optimize can be worthwhile. All these models are GPU enabled,
    and it’s very easy to push them to be run on GPU. (If you want to try it on GPU
    quickly, review the code I’ve shown above, and where you see “cpu” substitute
    in “cuda” if you have a GPU available in your programming environment.) Keep in
    mind that using GPUs from cloud providers is not cheap, however, so prioritize
    accordingly and decide if more speed is worth the price.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 性能一直是一个有趣的问题，因为到目前为止我所有的实验都是在我的本地笔记本电脑上运行的。自然地，使用这些来自 Hugging Face 的模型将需要更多的计算资源，并且比基本的策略如正则表达式和词典搜索要慢，但它提供了其他方式无法实现的信号，因此找到优化的方法是值得的。所有这些模型都支持
    GPU，并且很容易将它们推送到 GPU 上运行。（如果你想快速在 GPU 上尝试，请查看我上面展示的代码，并在看到“cpu”时替换为“cuda”，如果你的编程环境中有
    GPU 可用。）请记住，从云服务提供商使用 GPU 并不便宜，因此请根据情况设置优先级，并决定更快的速度是否值得这个代价。
- en: Most of the time, using the GPU is much more important for training (keep it
    in mind if you choose to fine tune) but less vital for inference. I’m not digging
    in to more details about optimization here, but you’ll want to consider parallelism
    as well if this is important to you- both data parallelism and actual training/compute
    parallelism.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，使用 GPU 对于训练来说更为重要（如果选择微调，请记住这一点），但对于推断来说不那么重要。我在这里不深入讨论优化的更多细节，但如果这对你很重要，你需要考虑并行性-
    包括数据并行性和实际训练/计算并行性。
- en: Testing and understanding output
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试和理解输出
- en: We’ve run the model! Results are here. I have a few closing tips for how to
    review the output and actually apply it to business questions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经运行了模型！结果在这里。我有一些结束时的提示，关于如何审查输出并实际应用到业务问题上。
- en: Don’t trust the model output blindly, but run rigorous tests and evaluate performance.
    Just because a transformer model does well on a certain text blob, or is able
    to correctly match text to a certain label regularly, doesn’t mean this is generalizable
    result. Use lots of different examples and different kinds of text to prove the
    performance is going to be sufficient.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要盲目相信模型的输出，而是进行严格的测试和评估性能。仅仅因为一个转换器模型在某个文本块上表现良好，或者能够定期正确匹配文本到某个标签，这并不意味着这是可推广的结果。使用大量不同的示例和不同类型的文本来证明性能将是足够的。
- en: If you feel confident in the model and want to use it in a production setting,
    track and log the model’s behavior. This is just good practice for any model in
    production, but you should keep the results it has produced alongside the inputs
    you gave it, so you can continually check up on it and make sure the performance
    doesn’t decline. This is more important for these kinds of deep learning models
    because we don’t have as much interpretability of why and how the model is coming
    up with its inferences. It’s dangerous to make too many assumptions about the
    inner workings of the model.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你对模型有信心，并且想在生产环境中使用它，请跟踪并记录模型的行为。这是任何在生产中的模型的好做法，但你应该将它产生的结果与输入的内容一起保存，这样你就可以不断检查它，确保性能没有下降。对于这些深度学习模型，这一点尤为重要，因为我们对模型如何及为何得出推理的解释性较少。对模型的内部工作机制做过多假设是很危险的。
- en: As I mentioned earlier, I like using these kinds of model output as part of
    a larger pool of techniques, combining them in ensemble strategies — that way
    I’m not only relying on one approach, but I do get the signal those inferences
    can provide.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，我喜欢将这些模型输出作为更大技术池的一部分，结合它们在集成策略中使用——这样我不仅依赖于单一的方法，但确实能获得这些推理提供的信号。
- en: I hope this overview is useful for those of you getting started with pre-trained
    models for text (or other mode) analysis — good luck!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个概述对那些刚开始使用预训练模型进行文本（或其他模式）分析的朋友们有帮助——祝你们好运！
- en: Read more of my work at [www.stephaniekirmer.com](http://www.stephaniekirmer.com).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读更多我的工作，访问[www.stephaniekirmer.com](http://www.stephaniekirmer.com)。
- en: Further Reading
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[](https://huggingface.co/models?source=post_page-----026d71426fbe--------------------------------)
    [## Models - Hugging Face'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://huggingface.co/models?source=post_page-----026d71426fbe--------------------------------)
    [## 模型 - Hugging Face'
- en: We're on a journey to advance and democratize artificial intelligence through
    open source and open science.
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们正在努力推动并民主化人工智能，通过开源和开放科学。
- en: huggingface.co](https://huggingface.co/models?source=post_page-----026d71426fbe--------------------------------)
    [](https://huggingface.co/docs/transformers/v4.13.0/en/parallelism?source=post_page-----026d71426fbe--------------------------------)
    [## Model Parallelism
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[huggingface.co](https://huggingface.co/models?source=post_page-----026d71426fbe--------------------------------)
    [](https://huggingface.co/docs/transformers/v4.13.0/en/parallelism?source=post_page-----026d71426fbe--------------------------------)
    [## 模型并行'
- en: We're on a journey to advance and democratize artificial intelligence through
    open source and open science.
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们正在努力推动并民主化人工智能，通过开源和开放科学。
- en: huggingface.co](https://huggingface.co/docs/transformers/v4.13.0/en/parallelism?source=post_page-----026d71426fbe--------------------------------)  [##
    Find Open Datasets and Machine Learning Projects | Kaggle
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[huggingface.co](https://huggingface.co/docs/transformers/v4.13.0/en/parallelism?source=post_page-----026d71426fbe--------------------------------)
    [## 查找开放数据集和机器学习项目 | Kaggle'
- en: Download Open Datasets on 1000s of Projects + Share Projects on One Platform.
    Explore Popular Topics Like Government…
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载成千上万的开放数据集以及在一个平台上共享项目。探索热门话题，如政府……
- en: www.kaggle.com](https://www.kaggle.com/datasets?source=post_page-----026d71426fbe--------------------------------)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.kaggle.com](https://www.kaggle.com/datasets?source=post_page-----026d71426fbe--------------------------------)'
