- en: Erasing Clouds from Satellite Imagery Using GANs (Generative Adversarial Networks)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GAN（生成对抗网络）去除卫星图像中的云
- en: 原文：[https://towardsdatascience.com/erasing-clouds-from-satellite-imagery-using-gans-generative-adversarial-networks-2d7f8467ef2e?source=collection_archive---------2-----------------------#2024-06-15](https://towardsdatascience.com/erasing-clouds-from-satellite-imagery-using-gans-generative-adversarial-networks-2d7f8467ef2e?source=collection_archive---------2-----------------------#2024-06-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/erasing-clouds-from-satellite-imagery-using-gans-generative-adversarial-networks-2d7f8467ef2e?source=collection_archive---------2-----------------------#2024-06-15](https://towardsdatascience.com/erasing-clouds-from-satellite-imagery-using-gans-generative-adversarial-networks-2d7f8467ef2e?source=collection_archive---------2-----------------------#2024-06-15)
- en: '**Building GANs from scratch in python**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**从零开始在 Python 中构建 GAN**'
- en: '[](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)[![Aleksei
    Rozanov](../Images/748b69bfaccf39c9aa568a9e6f41eec3.png)](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)
    [Aleksei Rozanov](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)[![Aleksei
    Rozanov](../Images/748b69bfaccf39c9aa568a9e6f41eec3.png)](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)
    [Aleksei Rozanov](https://medium.com/@alexroz?source=post_page---byline--2d7f8467ef2e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)
    ·12 min read·Jun 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2d7f8467ef2e--------------------------------)
    ·12 分钟阅读·2024 年 6 月 15 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a8ae5b6d4e446b5af4e38c5c19ed1129.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8ae5b6d4e446b5af4e38c5c19ed1129.png)'
- en: Photo by [Michael & Diane Weidner](https://unsplash.com/@michaelbweidner?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Michael & Diane Weidner](https://unsplash.com/@michaelbweidner?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The idea of Generative Adversarial Networks, or GANs, was introduced by Goodfellow
    and his colleagues [1] in 2014, and shortly after that became extremely popular
    in the field of computer vision and image generation. Despite the last 10 years
    of rapid development within the domain of AI and growth of the number of new algorithms,
    the simplicity and brilliance of this concept are still extremely impressive.
    So today I want to illustrate how powerful these networks can be by attempting
    to remove clouds from satellite RGB (Red, Green, Blue) images.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）的概念由 Goodfellow 和他的同事们在 2014 年提出 [1]，并且很快在计算机视觉和图像生成领域获得了极大关注。尽管在过去的
    10 年里，人工智能领域经历了快速发展并出现了许多新算法，但这个概念的简单性和 brilliance（巧妙之处）依然令人印象深刻。所以今天我想通过尝试从卫星
    RGB（红、绿、蓝）图像中去除云层，来展示这些网络的强大能力。
- en: Preparation of a properly balanced, big enough and correctly pre-processed CV
    dataset takes a solid amount of time, so I decided to explore what Kaggle has
    to offer. The dataset I found the most appropriate for this task is EuroSat [2],
    which has an open license. It comprises **27000** labeled RGB images 64x64 pixels
    from [Sentinel-2](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2)
    and is built for solving the multiclass classification problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 准备一个适当平衡、足够大且经过正确预处理的计算机视觉数据集需要大量时间，因此我决定探索 Kaggle 提供的资源。我发现最适合这个任务的数据集是 EuroSat
    [2]，它具有开放许可。该数据集包含 **27000** 张标注的 RGB 图像，尺寸为 64x64 像素，来自 [Sentinel-2](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2)，并用于解决多类分类问题。
- en: '[](https://www.kaggle.com/datasets/apollo2506/eurosat-dataset/data?source=post_page-----2d7f8467ef2e--------------------------------)
    [## EuroSat Dataset'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/datasets/apollo2506/eurosat-dataset/data?source=post_page-----2d7f8467ef2e--------------------------------)
    [## EuroSat 数据集'
- en: Dataset contains all the RGB and Bands images from Sentinel-2
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集包含来自 Sentinel-2 的所有 RGB 和波段图像
- en: www.kaggle.com](https://www.kaggle.com/datasets/apollo2506/eurosat-dataset/data?source=post_page-----2d7f8467ef2e--------------------------------)
    ![](../Images/78b9510aa3c9c7e3a95911929f732e88.png)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.kaggle.com](https://www.kaggle.com/datasets/apollo2506/eurosat-dataset/data?source=post_page-----2d7f8467ef2e--------------------------------)
    ![](../Images/78b9510aa3c9c7e3a95911929f732e88.png)'
- en: EuroSat dataset imagery example. [License](https://github.com/phelber/eurosat).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: EuroSat数据集的图像示例。[许可](https://github.com/phelber/eurosat)。
- en: We are not interested in classification itself, but one of the main features
    of the EuroSat dataset is that all its images have a clear sky. That‘s exactly
    what we need. Adopting this approach from [3], we will use these Sentinel-2 shots
    as targets and create inputs by adding noise (clouds) to them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对分类本身并不感兴趣，但EuroSat数据集的一个主要特点是，所有图像都有清晰的天空。这正是我们需要的。借用[3]中的方法，我们将这些Sentinel-2影像作为目标，通过向它们添加噪声（云朵）来创建输入。
- en: So let’s prepare our data before actually talking about GANs. Firstly, we need
    to download the data and merge all the classes into one directory.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在真正讨论GANs之前，我们先准备一下数据。首先，我们需要下载数据，并将所有类别合并到一个目录中。
- en: '**🐍The full python code:** [**GitHub**](https://github.com/alexxxroz/Medium/blob/main/GANs%26Clouds.ipynb)**.**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**🐍完整的Python代码：** [**GitHub**](https://github.com/alexxxroz/Medium/blob/main/GANs%26Clouds.ipynb)**.**'
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The second important step is generating noise. Whereas you can use different
    approaches, e.g. randomly masking out some pixels, adding some Gaussian noise,
    in this article I want to try a new thing for me — Perlin noise. It was invented
    in the 80s by Ken Perlin [4] when developing cinematic smoke effects. This kind
    of noise has a more organic appearance compared to regular random noise. Just
    let me prove it.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个重要步骤是生成噪声。虽然你可以使用不同的方法，例如随机遮罩一些像素、添加一些高斯噪声，但在这篇文章中，我想尝试一个对我来说新颖的东西——Perlin噪声。它是由Ken
    Perlin在80年代发明的[4]，用于开发电影中的烟雾效果。这种噪声与普通的随机噪声相比，具有更自然的外观。让我来证明一下。
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/663c3610117fdf1d41c60edb0e5a06e6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/663c3610117fdf1d41c60edb0e5a06e6.png)'
- en: Image by [author](https://medium.com/@alexroz).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[作者](https://medium.com/@alexroz)。
- en: As you can see above, the clouds on the images are very realistic, they have
    different “density” and texture resembling the real ones.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，图像中的云朵非常逼真，它们具有不同的“密度”和类似真实云朵的纹理。
- en: 'If you are intrigued by Perlin noise as I was, here is a really cool video
    on how this noise can be applied in the GameDev industry:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你像我一样对Perlin噪声感兴趣，这里有一个非常酷的视频，展示了这种噪声如何应用于游戏开发行业：
- en: Since now we have a ready-to-use dataset, let’s talk about GANs.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们现在有了一个现成可用的数据集，那么让我们来谈谈生成对抗网络（GANs）。
- en: Generative Adversarial Network
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）
- en: 'To better illustrate this idea, let’s imagine that you’re traveling around
    South-East Asia and find yourself in an urgent need of a hoodie, since it’s too
    cold outside. Coming to the closest street market, you find a small shop with
    some branded clothes. The seller brings you a nice hoodie to try on saying that
    it’s the famous brand ExpensiveButNotWorthIt. You take a closer look and conclude
    that it’s obviously a fake. The seller says: ‘Wait a sec, I have the REAL one.
    He returns with another hoodie, which looks more like the branded one, but still
    a fake. After several iterations like this, the seller brings an indistinguishable
    copy of the legendary ExpensiveButNotWorthIt and you readily buy it. That’s basically
    how the GANs work!'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明这个概念，假设你正在东南亚旅行，突然需要一件连帽衫，因为外面太冷了。你来到最近的街头市场，发现一家小店有一些品牌服装。卖家拿来一件不错的连帽衫让你试穿，并说它是著名品牌ExpensiveButNotWorthIt。你仔细一看，得出结论，这显然是假的。卖家说：“等一下，我有真的。”然后他带着另一件连帽衫回来，看起来更像是品牌的，但依旧是假货。经过几轮这样的尝试后，卖家带来了一件无法分辨的传奇品牌ExpensiveButNotWorthIt的复制品，你便高兴地买下了它。这基本上就是生成对抗网络（GANs）的工作原理！
- en: In the case of GANs, you are called a discriminator (D). The goal of a discriminator
    is to distinguish between a true object and a fake one, or to solve the binary
    classification task. The seller is called a generator (G), since he’s trying to
    generate a high-quality fake. The discriminator and generator are trained independently
    to outperform each other. Hence, in the end we get a high-quality fake.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在GANs的情况下，你被称为判别器（D）。判别器的目标是区分真实物体和虚假物体，或者解决二分类任务。卖家被称为生成器（G），因为他在尝试生成高质量的假货。判别器和生成器是独立训练的，目的是互相超越。因此，最终我们得到一个高质量的假货。
- en: '![](../Images/dd222e2e675a330b6217b13ea4acc8d4.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd222e2e675a330b6217b13ea4acc8d4.png)'
- en: GANs architecture. [License](https://paperswithcode.com/method/gan).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: GANs架构。[许可](https://paperswithcode.com/method/gan)。
- en: 'The training process originally looks like this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程最初看起来是这样的：
- en: Sample input noise (in our case images with clouds).
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采样输入噪声（在我们的案例中是有云的图像）。
- en: Feed the noise to G and collect the prediction.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将噪声输入 G 并收集预测结果。
- en: Calculate the D loss by getting 2 predictions one for G’s output and another
    for the real data.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过获取两个预测值来计算 D 的损失，一个是 G 的输出，另一个是真实数据的预测值。
- en: Update D’s weights.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 D 的权重。
- en: Sample input noise again.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次采样输入噪声。
- en: Feed the noise to G and collect the prediction.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将噪声输入 G 并收集预测结果。
- en: Calculate the G loss by feeding its prediction to D.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将 G 的预测输入到 D 中来计算 G 的损失。
- en: Update G’s weights.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 G 的权重。
- en: '![](../Images/788502677c2e805ddd67f00aa1010601.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/788502677c2e805ddd67f00aa1010601.png)'
- en: 'GANs training loop. Source: [1].'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 训练循环。来源：[1]。
- en: 'In other words we can define a value function V(G,D):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们可以定义一个值函数 V(G,D)：
- en: '![](../Images/ba0147e691508a1cee54eda81aec27ca.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba0147e691508a1cee54eda81aec27ca.png)'
- en: 'Source: [1].'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[1]。
- en: where we want to minimize the term **log(1-D(G(z)))** to train G and maximize
    **log D(x)** to train D (in this notation x — real data sample and z — noise).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们希望最小化项 **log(1-D(G(z)))** 来训练 G，并最大化 **log D(x)** 来训练 D（在此符号中，x 表示真实数据样本，z
    表示噪声）。
- en: Now let’s try to implement it in pytorch!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试在 pytorch 中实现它！
- en: In the original paper authors talk about using Multilayer Perceptron (MLP);
    it’s also often referred simply as ANN, but I want to try a little bit more complicated
    approach — I want to use the UNet [5] architecture as a Generator and ResNet [6]
    as a Discriminator. These are both well-known CNN architectures, so I won’t be
    explaining them here (let me know if I should write a separate article in the
    comments).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始论文中，作者提到使用多层感知器（MLP）；它通常也简称为 ANN，但我想尝试一个更复杂的方法——我想使用 UNet [5] 架构作为生成器，ResNet
    [6] 作为判别器。这两者都是著名的 CNN 架构，所以我不会在这里解释它们（如果需要我写一篇单独的文章，请在评论中告诉我）。
- en: 'Let’s build them. Discriminator:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来构建它们。判别器：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Generator:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we need to split our data into train/test and wrap them into a torch dataset:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将数据划分为训练集和测试集，并将它们封装为 torch 数据集：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Perfect. It’s time to write the training loop. Before doing so, let’s define
    our loss functions and optimizer:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 完美。是时候编写训练循环了。在此之前，让我们定义我们的损失函数和优化器：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see, these losses are different from the picture with the GAN algorithm.
    In particular, I added L1Loss. The idea is that we are not simply generating a
    random image from noise, we want to keep most of the information from the input
    and just remove noise. So G loss will be:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这些损失与 GAN 算法中的图片有所不同。特别是，我加入了 L1Loss。其想法是，我们不仅仅是从噪声中生成一张随机图片，我们还希望保留输入中的大部分信息，只去除噪声。所以
    G 的损失将是：
- en: '**G_loss = log(1 − D(G(z))) + 𝝀 |G(z)-y|**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**G_loss = log(1 − D(G(z))) + 𝝀 |G(z)-y|**'
- en: instead of just
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是仅仅
- en: '**G_loss = log(1 − D(G(z)))**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**G_loss = log(1 − D(G(z)))**'
- en: 𝝀 is an arbitrary coefficient, which balances two components of the losses.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 𝝀 是一个任意系数，用于平衡损失函数的两个部分。
- en: 'Finally, let’s split the data to start the training process:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们划分数据并开始训练过程：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we can run our training loop:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以运行我们的训练循环：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After the code is finished we can plot the losses. This code was partly adopted
    from [this cool website](https://python-graph-gallery.com/web-small-multiple-with-highlights/):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 代码完成后，我们可以绘制损失图。此代码部分来源于[这个酷网站](https://python-graph-gallery.com/web-small-multiple-with-highlights/)：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/413ed7942d93aa8dfd0134cb587b28e8.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/413ed7942d93aa8dfd0134cb587b28e8.png)'
- en: Image by [author](https://medium.com/@alexroz).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[作者](https://medium.com/@alexroz)。
- en: 'And also visualize a random sample from the test dataset:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 同时也可以可视化来自测试数据集的随机样本：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/a16b1e301ecc94fe2928a33cc3216350.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a16b1e301ecc94fe2928a33cc3216350.png)'
- en: Image by [author](https://medium.com/@alexroz).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[作者](https://medium.com/@alexroz)。
- en: As you can see, the results are not perfect and depend a lot on the land cover
    type. Nevertheless, the built model certainly removes the clouds from images and
    its performance can be improved by increasing G and D depth. Another promising
    strategy to test is training separate models for different land cover types. For
    instance, crop fields and water basins are definitely have quite distinct spatial
    features, so it might effect model’s ability to generalize.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，结果并不完美，并且很大程度上依赖于地貌类型。然而，构建的模型肯定能够去除图像中的云层，并且通过增加 G 和 D 的深度可以提高其性能。另一个有前景的策略是为不同的地貌类型训练独立的模型。例如，农田和水域的空间特征差异较大，这可能会影响模型的泛化能力。
- en: I hope this article provided you with a fresh perspective on applying Deep Learning
    algorithms in the geospatial domain. In my opinion, GANs are among the most powerful
    tools a data scientist can utilize, and I hope they become an essential part of
    your toolkit as well!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章能为你提供一种在地理空间领域应用深度学习算法的新视角。在我看来，生成对抗网络（GANs）是数据科学家可以利用的最强大工具之一，我希望它们也能成为你工具箱中的重要组成部分！
- en: ===========================================
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ===========================================
- en: '***References:***'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '***参考文献：***'
- en: 1\. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. “Generative adversarial nets.”
    *Advances in neural information processing systems* 27 (2014). [https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville 和 Yoshua Bengio。“生成对抗网络。” *神经信息处理系统进展* 27（2014年）。[https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)
- en: '2\. Helber, Patrick, Benjamin Bischke, Andreas Dengel, and Damian Borth. “Eurosat:
    A novel dataset and deep learning benchmark for land use and land cover classification.”
    *IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing*
    12, no. 7 (2019): 2217–2226\. [https://arxiv.org/pdf/1709.00029](https://arxiv.org/pdf/1709.00029)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. Helber, Patrick, Benjamin Bischke, Andreas Dengel 和 Damian Borth。“Eurosat：一个用于土地利用和土地覆盖分类的全新数据集和深度学习基准。”
    *IEEE应用地球观测与遥感精选主题期刊* 12卷，第7期（2019年）：2217–2226。[https://arxiv.org/pdf/1709.00029](https://arxiv.org/pdf/1709.00029)
- en: '3\. Wen, Xue, Zongxu Pan, Yuxin Hu, and Jiayin Liu. “Generative adversarial
    learning in YUV color space for thin cloud removal on satellite imagery.” *Remote
    Sensing* 13, no. 6 (2021): 1079\. [https://www.mdpi.com/2072-4292/13/6/1079](https://www.mdpi.com/2072-4292/13/6/1079)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. Wen, Xue, Zongxu Pan, Yuxin Hu 和 Jiayin Liu。“基于YUV颜色空间的生成对抗学习用于卫星图像中的薄云去除。”
    *遥感* 13卷，第6期（2021年）：1079。[https://www.mdpi.com/2072-4292/13/6/1079](https://www.mdpi.com/2072-4292/13/6/1079)
- en: '4\. Perlin, Ken. “An image synthesizer.” *ACM Siggraph Computer Graphics* 19,
    no. 3 (1985): 287–296\. [https://dl.acm.org/doi/pdf/10.1145/325165.325247](https://dl.acm.org/doi/pdf/10.1145/325165.325247)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. Perlin, Ken。“图像合成器。” *ACM Siggraph计算机图形学* 19卷，第3期（1985年）：287–296。[https://dl.acm.org/doi/pdf/10.1145/325165.325247](https://dl.acm.org/doi/pdf/10.1145/325165.325247)
- en: '5\. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional
    networks for biomedical image segmentation.” In *Medical image computing and computer-assisted
    intervention–MICCAI 2015: 18th international conference, Munich, Germany, October
    5–9, 2015, proceedings, part III 18*, pp. 234–241\. Springer International Publishing,
    2015\. [https://arxiv.org/pdf/1505.04597](https://arxiv.org/pdf/1505.04597)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. Ronneberger, Olaf, Philipp Fischer 和 Thomas Brox。“U-net：用于生物医学图像分割的卷积网络。”
    见 *医学图像计算与计算机辅助干预–MICCAI 2015：第18届国际会议，德国慕尼黑，2015年10月5日至9日，会议录，第三部分 18*，第234–241页。施普林格国际出版公司，2015年。[https://arxiv.org/pdf/1505.04597](https://arxiv.org/pdf/1505.04597)
- en: 6\. He, Kaiming, et al. “Deep residual learning for image recognition.” *Proceedings
    of the IEEE conference on computer vision and pattern recognition*. 2016.[https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. He, Kaiming 等人。“深度残差学习用于图像识别。” *IEEE计算机视觉与模式识别会议论文集*。2016。[https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
- en: ===========================================
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ===========================================
- en: '***All my publications on Medium are free and open-access, that’s why I’d really
    appreciate if you followed me here!***'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '***我在Medium上的所有出版物都是免费的并且开放访问的，因此如果你在这里关注我，我将非常感激！***'
- en: P.s. I’m extremely passionate about (Geo)Data Science, ML/AI and Climate Change.
    So if you want to work together on some project pls contact me in [LinkedIn](https://www.linkedin.com/in/alexxxroz/).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: P.s. 我对（地理）数据科学、机器学习/人工智能和气候变化充满热情。如果你想合作进行某些项目，请在[LinkedIn](https://www.linkedin.com/in/alexxxroz/)上联系我。
- en: 🛰️Follow for more🛰️
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 🛰️关注以获取更多信息🛰️
