- en: 'Kolmogorov-Arnold Networks: the latest advance in Neural Networks, simply explained'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kolmogorov-Arnold Networks：神经网络领域的最新进展，简明解释
- en: 原文：[https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=collection_archive---------0-----------------------#2024-05-12](https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=collection_archive---------0-----------------------#2024-05-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=collection_archive---------0-----------------------#2024-05-12](https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=collection_archive---------0-----------------------#2024-05-12)
- en: The new type of network that is making waves in the ML world.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这种新型网络正在机器学习领域掀起波澜。
- en: '[](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)[![Theo
    Wolf](../Images/39e9d886e74e456989eccd60328264c8.png)](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)
    [Theo Wolf](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)[![Theo
    Wolf](../Images/39e9d886e74e456989eccd60328264c8.png)](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)
    [Theo Wolf](https://medium.com/@theo.wolf?source=post_page---byline--f083cf994a85--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)
    ·9 min read·May 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f083cf994a85--------------------------------)
    ·9分钟阅读·2024年5月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e16cf3f974c2c32b49abf83ee0870196.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e16cf3f974c2c32b49abf83ee0870196.png)'
- en: Comparison of the MLP and the KAN. Image from [paper](https://arxiv.org/abs/2404.19756).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: MLP与KAN的比较。图片来自[论文](https://arxiv.org/abs/2404.19756)。
- en: 'In April, a paper appeared on arXiv named: [KAN: Kolmogorov–Arnold Networks](https://arxiv.org/abs/2404.19756).
    The tweet announcing got ~5k likes, which for a paper announcement is pretty viral.
    The accompanying [GitHub repository](https://github.com/KindXiaoming/pykan) already
    has 7.6k stars and counting.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '今年四月，一篇名为：[KAN: Kolmogorov–Arnold Networks](https://arxiv.org/abs/2404.19756)的论文出现在arXiv上。宣布这篇论文的推文获得了大约5千个点赞，对于论文的宣布来说，这已经算是相当火爆了。附带的[GitHub仓库](https://github.com/KindXiaoming/pykan)已经有7.6k个星标，并且还在不断增加。'
- en: The Kolmogorov-Arnold Network (KAN) is a brand-new class of Neural Network building
    block. It aims to be more expressive, less prone to overfitting and more interpretable
    than the Multi-Layer Perceptron (MLP). MLPs are ubiquitous in deep learning models.
    We know for example that they are used in between transformer blocks for models
    such as GPT-2, 3 and (probably) 4\. Making an improvement on the MLP would have
    wide ramifications for the machine learning world.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Kolmogorov-Arnold 网络（KAN）是一种全新的神经网络构建模块。它的目标是比多层感知器（MLP）更具表现力、更不容易过拟合，并且更具可解释性。MLP在深度学习模型中无处不在。例如，我们知道它们被用在像GPT-2、3和（可能）4等模型的Transformer块之间。对MLP的改进将对机器学习领域产生广泛的影响。
- en: MLPs in a nutshell
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLP简述
- en: The MLP is actually a very old architecture that dates back to the 50s. The
    idea was to replicate the structure of the brain; with lots of…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: MLP实际上是一种非常古老的架构，起源于50年代。其思想是复制大脑的结构；有很多……
