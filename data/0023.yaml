- en: Advice on using LLMs wisely
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LLM 明智的建议
- en: 原文：[https://towardsdatascience.com/advice-on-using-llms-wisely-388262b2ff50?source=collection_archive---------10-----------------------#2024-01-04](https://towardsdatascience.com/advice-on-using-llms-wisely-388262b2ff50?source=collection_archive---------10-----------------------#2024-01-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/advice-on-using-llms-wisely-388262b2ff50?source=collection_archive---------10-----------------------#2024-01-04](https://towardsdatascience.com/advice-on-using-llms-wisely-388262b2ff50?source=collection_archive---------10-----------------------#2024-01-04)
- en: Ten of my LinkedIn posts on LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我在 LinkedIn 上关于 LLM 的十篇帖子
- en: '[](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--388262b2ff50--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)
    ·9 min read·Jan 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--388262b2ff50--------------------------------)
    ·阅读时间 9 分钟·2024年1月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 1\. Non-determinism in LLMs
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. LLM 中的非确定性问题
- en: The best LLM use cases are where you use LLM as a tool rather than expose it
    directly. As [Richard Seroter](https://www.linkedin.com/in/seroter/) says, how
    many chatbots do you need?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳的 LLM 用例是将 LLM 作为工具使用，而不是直接暴露它。正如[Richard Seroter](https://www.linkedin.com/in/seroter/)所说，你需要多少个聊天机器人？
- en: '[](https://www.linkedin.com/feed/update/urn:li:activity:7148725035644481536/?source=post_page-----388262b2ff50--------------------------------)
    [## Richard Seroter on LinkedIn: Make Any Catalog-Driven App More Personalized
    to Your Users: How I…'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/feed/update/urn:li:activity:7148725035644481536/?source=post_page-----388262b2ff50--------------------------------)
    [## Richard Seroter 在 LinkedIn 上：如何使任何基于目录的应用程序更具个性化，以便更好地服务于您的用户：我的经验分享…'
- en: Be honest with me, is this a terrible idea? What if generative AI could give
    us more personalized product summaries…
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 诚实告诉我，这是一个糟糕的主意吗？如果生成型人工智能能够为我们提供更个性化的产品总结呢…
- en: www.linkedin.com](https://www.linkedin.com/feed/update/urn:li:activity:7148725035644481536/?source=post_page-----388262b2ff50--------------------------------)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.linkedin.com](https://www.linkedin.com/feed/update/urn:li:activity:7148725035644481536/?source=post_page-----388262b2ff50--------------------------------)'
- en: However, this use case of replacing static product pages by personalized product
    summaries is like many other LLM use cases in that it faces unique risks due to
    non-determinism. Imagine that a customer sues you a year from now, saying that
    they bought the product because your product summary claimed (wrongly) that the
    product was flameproof and their house burned down. The only way to protect yourself
    would be to have a record of every generated summary and the storage costs will
    quickly add up …
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将静态产品页面替换为个性化的产品总结这一用例，与许多其他大型语言模型（LLM）用例一样，由于非确定性，它面临着独特的风险。想象一下，一年后有客户起诉你，声称他们因为你的产品总结错误地说该产品防火，导致他们购买了该产品并且他们的房子烧毁了。保护自己的唯一方法是保留每一个生成的总结记录，而存储成本会迅速增加…
- en: One way to avoid this problem (and what I suggest) is to generate a set of templates
    using LLMs and use an ML model to choose which template to serve. This also has
    the benefit of allowing human oversight of your generated text, so you are not
    at the mercy of prompt engineering. (This is, of course, just a way to use LLMs
    to efficiently create different websites for different customer segments — the
    more things change, the more they rhyme with existing ideas).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 避免这个问题的一种方法（也是我建议的方法）是使用 LLM 生成一组模板，并使用机器学习模型来选择哪个模板进行服务。这还具有允许人工监督生成文本的好处，因此你不至于受制于提示工程。（当然，这仅仅是使用
    LLM 高效地为不同客户群体创建不同网站的一种方法——越是改变，越是与现有的想法产生共鸣）。
- en: 'Many use cases of LLMs are like this: you’ll have to reduce the non-deterministic
    behavior and associated risk through careful architecture.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的许多使用案例是这样的：你需要通过精心的架构来减少非确定性行为及相关风险。
- en: 2\. Copyright issues with LLMs
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. LLM 的版权问题
- en: 'The New York Times is suing OpenAI and Microsoft over their use of the Times’
    articles. This goes well beyond previous lawsuits, claiming that:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 《纽约时报》正在起诉 OpenAI 和微软，指控它们使用《纽约时报》的文章。这一诉讼远超以往的诉讼，声称：
- en: 1\. OpenAI used millions of articles, and weighted them higher thus implicitly
    acknowledging the importance of the Times’ content.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. OpenAI 使用了数百万篇文章，并将其权重设定得更高，从而隐含地承认了《纽约时报》内容的重要性。
- en: 2\. Wirecutter reviews reproduced verbatim, but with the affiliate links stripped
    out. This creates a competitive product.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. Wirecutter 的评论被逐字复制，但附属链接被去除。这创造了一个具有竞争力的产品。
- en: 3\. GenAI mimics the Times’ expressive style leading to trademark dilution.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 生成式人工智能模仿了《纽约时报》的表现风格，导致商标稀释。
- en: 4\. Value of the tech is trillions of dollars for Microsoft and billions of
    dollars for OpenAI based on the increase in their market caps.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 基于微软和 OpenAI 市值的增长，这项技术的价值对微软而言达到数万亿美元，对 OpenAI 则达到数十亿美元。
- en: 5\. Producing close summaries is not transformative given that the original
    work was created at considerable expense.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 由于原作是在相当高的成本下创作的，因此产生紧密总结并不具备变革性。
- en: The lawsuit also goes after the corporate structure of Open AI, the nature of
    the close collaborations with Open AI that Microsoft relied on to build Azure’s
    computing platform and selection of datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此次诉讼还针对 OpenAI 的公司结构，以及微软在构建 Azure 计算平台和选择数据集时与 OpenAI 的紧密合作关系。
- en: '[https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)'
- en: The whole filing is 69 pages, very readable, and has lots of examples. I strongly
    recommend reading the full PDF that’s linked from the article.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 整个诉讼文件长达 69 页，内容非常易读，并包含大量示例。我强烈推荐阅读文章中链接的完整 PDF 文件。
- en: 'I am not a lawyer, so I’m not going to weigh in on the merits of the lawsuit.
    But if the NYTimes wins, I’d expect that:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我不是律师，因此不会对诉讼的利弊发表看法。但如果《纽约时报》胜诉，我预计：
- en: 1\. The cost of LLM APIs will go up as LLM providers will have to pay their
    sources. This lawsuit hits on training and quality of the base service not just
    when NYTimes articles are reproduced during inference. So, costs will go up across
    the board.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. LLM API 的成本将会上升，因为 LLM 提供商需要支付其来源费用。此次诉讼不仅涉及训练和基础服务质量问题，还包括在推理过程中重现《纽约时报》文章。因此，成本将全面上升。
- en: 2\. Open source LLMs will not be able to use Common Crawl (where the NYTimes
    is the 4th most common source). Their dataset quality will degrade, and it will
    be harder for them to match the commercial offerings.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 开源 LLM 将无法使用 Common Crawl（《纽约时报》是该数据源第四大来源）。它们的数据集质量将下降，且它们将更难与商业产品相匹配。
- en: 3\. This protects business models associated with producing unique and high
    quality content.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 这将保护与创作独特且高质量内容相关的商业模式。
- en: 4\. SEO will further privilege being the top 1 or 2 highest authority on a topic.
    It will be hard for others to get organic traffic. Expect customer acquisition
    costs through ads to go up.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. SEO 将更加偏向于在某个主题上成为排名第一或第二的最高权威。其他人将很难获得自然流量。预计通过广告获取客户的成本将会上升。
- en: 3\. Don’t use a LLM directly; Use a bot creation framework
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 不要直接使用 LLM；使用一个机器人创建框架。
- en: A mishap at a Chevy dealership
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 雪佛兰经销商的事故
- en: '[](https://www.threads.net/@documentingmeta/post/C08iWrBudcD/?igshid=NTc4MTIwNjQ2YQ%3D%3D&source=post_page-----388262b2ff50--------------------------------)
    [## Documenting Meta (@documentingmeta) on Threads'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.threads.net/@documentingmeta/post/C08iWrBudcD/?igshid=NTc4MTIwNjQ2YQ%3D%3D&source=post_page-----388262b2ff50--------------------------------)
    [## Documenting Meta (@documentingmeta) 在 Threads 上'
- en: OpenAI hates this one simple trick. Why pay for ChatGPT+ when Chevrolet of Watsonville
    can give it to you for free?
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenAI 讨厌这个简单的技巧。为什么要为 ChatGPT+ 付费，而沃森维尔的雪佛兰公司能免费提供？
- en: www.threads.net](https://www.threads.net/@documentingmeta/post/C08iWrBudcD/?igshid=NTc4MTIwNjQ2YQ%3D%3D&source=post_page-----388262b2ff50--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.threads.net](https://www.threads.net/@documentingmeta/post/C08iWrBudcD/?igshid=NTc4MTIwNjQ2YQ%3D%3D&source=post_page-----388262b2ff50--------------------------------)'
- en: demonstrates why you should never implement the chatbot on your website directly
    on top of an LLM API or with a custom GPT — you will struggle to tame the beast.
    There will also be all kinds of adversarial attacks that you will spend a lot
    of programmer dollars guarding against.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这也说明了为什么你永远不应该直接在你的网站上实施基于 LLM API 或自定义 GPT 的聊天机器人——你将很难驯服这个“怪物”。同时，你还将面临各种对抗性攻击，你需要花费大量的开发成本来防御这些攻击。
- en: What should you do? Use a higher level bot-creation framework such as Google
    Dialogflow or Amazon Lex. Both these have a language model built in, and will
    respond to only a limited number of intents. Thus saving you from an expensive
    lesson.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该怎么做？使用更高级的机器人创建框架，比如 Google Dialogflow 或 Amazon Lex。这些框架内建语言模型，只会回应有限数量的意图，从而让你避免代价高昂的教训。
- en: 4\. Gemini demonstrates Google’s confidence in their research team
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. Gemini 展示了 Google 对其研究团队的信心
- en: '[https://www.linkedin.com/posts/valliappalakshmanan_what-a-lot-of-people-seem-to-be-missing-is-activity-7139380381916545024-Ki3a](https://www.linkedin.com/posts/valliappalakshmanan_what-a-lot-of-people-seem-to-be-missing-is-activity-7139380381916545024-Ki3a?utm_source=share&utm_medium=member_desktop)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.linkedin.com/posts/valliappalakshmanan_what-a-lot-of-people-seem-to-be-missing-is-activity-7139380381916545024-Ki3a](https://www.linkedin.com/posts/valliappalakshmanan_what-a-lot-of-people-seem-to-be-missing-is-activity-7139380381916545024-Ki3a?utm_source=share&utm_medium=member_desktop)'
- en: What a lot of people seem to be missing is the ice-cold confidence Google leadership
    had in their research team.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 很多人似乎忽视了 Google 高层对其研究团队的冷静信心。
- en: Put yourself in the shoes of Google executives a year ago. You’ve lost first-mover
    advantage to startups that have gone to market with tech you deemed too risky.
    And you need to respond.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 把自己放在一年前 Google 高层的角度。你已经失去了先发优势，被一些初创公司赶超，这些公司采用了你认为过于冒险的技术。你需要作出回应。
- en: Would you bet on your research team being able to build a *single* model that
    would outperform OpenAI, Midjourney, etc? Or would you spread your bets and build
    multiple models? [Gemini is a single model that has beat the best text model on
    text, the best image model on images, the best video model on video, and the best
    speech model on speech.]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你会押注于你的研究团队能够构建出一个*单一*模型，超越 OpenAI、Midjourney 等公司吗？还是会分散风险，构建多个模型？[Gemini 是一个单一模型，在文本上超越了最佳文本模型，在图像上超越了最佳图像模型，在视频上超越了最佳视频模型，在语音上超越了最佳语音模型。]
- en: 'Now, imagine that you have two world class labs: Google Brain and Deep Mind.
    Would you combine them and tell 1000 people to work on a single product? Or would
    you hedge the bet by having them work on two different approaches in the hope
    one is successful? [Google combined the two teams calling it Google Deep Mind
    under the leadership of Demis, the head of Deep Mind, and Jeff Dean, the head
    of Brain, became chief scientist.]'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一下你有两个世界级的实验室：Google Brain 和 DeepMind。你会将它们合并，并让 1000 人专注于一个产品吗？还是会通过让他们在两个不同的方向上工作来分散风险，期望其中一个成功？[Google
    将这两个团队合并，命名为 Google DeepMind，在 DeepMind 负责人 Demis 的领导下，Brain 负责人 Jeff Dean 成为首席科学家。]
- en: You have an internally developed custom machine learning chip (the TPU). Meanwhile,
    everyone else is building models on general purpose chips (GPUs). Do you double
    down on your internal chip, or hedge your bets? [Gemini was trained and is being
    served fromTPUs.]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你有一款自主开发的定制机器学习芯片（TPU）。与此同时，其他所有公司都在基于通用芯片（GPU）构建模型。你会继续加大对内部芯片的投入，还是采取保守策略？[Gemini
    是在 TPUs 上训练并服务的。]
- en: On each of these decisions, Google chose to go all-in.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些决策中，Google 选择了全力以赴。
- en: 5\. Who’s actually investing in Gen AI?
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 谁在真正投资于生成式 AI？
- en: 'Omdia estimates of H100 shipments:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Omdia 对 H100 出货量的估算：
- en: '![](../Images/2d28802de6000ed118078846e5fbc36b.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d28802de6000ed118078846e5fbc36b.png)'
- en: A good way to cut past marketing hype in tech is to look at who’s actually investing
    in new capacity. So, the Omdia estimates of H100 shipments is a good indicator
    of who’s winning in Gen AI.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 判断科技营销炒作的一个好方法是看看谁在真正投资于新产能。因此，Omdia 对 H100 出货量的估算是一个很好的指标，能够揭示谁在生成式 AI 领域获胜。
- en: Meta and Microsoft bought 150k H100s apiece in 2023 while Google, Amazon, and
    Oracle bought 50k units each. (Google internal usage and Anthropic are on TPUs,
    so their Gen AI spend is higher than the 50k would indicate.)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 和 Microsoft 在 2023 年分别购买了 15 万个 H100，而 Google、Amazon 和 Oracle 各购买了 5 万个。（Google
    的内部使用和 Anthropic 使用的是 TPUs，因此他们的生成式 AI 支出比 5 万个所表明的要高。）
- en: Surprises?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有惊喜吗？
- en: 1\. Apple is conspicuous by its absence.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 苹果公司明显缺席。
- en: 2\. Very curious what Meta is up to. Look for a big announcement there?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 很好奇 Meta 在做什么。是否有大新闻即将发布？
- en: 3\. Oracle is neck-and-neck with AWS.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. Oracle 与 AWS 不相上下。
- en: Chip speed improvements these days don’t come from packing more transistors
    on a chip (physics limitation). Instead, they come from optimizing for specific
    ML model types.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来芯片速度的提升不再是通过增加芯片上的晶体管数量（物理限制）来实现的。而是通过针对特定机器学习模型类型进行优化。
- en: So, H100 gets 30x inference speedups over A100 (the previous generation) on
    transformer workloads by (1) dynamically switching between 8bit and 16bit representation
    for different layers of a transformer architecture (2) increasing the networking
    speed between GPUs allowing for model parallelism (necessary for LLMs), not just
    data parallelism (sufficient for image workloads). You wouldn’t spend $30,000
    per chip unless your ML models had this specific set of specific need.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，H100在变换器工作负载上，相比A100（上一代）提升了30倍的推理速度，这得益于：（1）在变换器架构的不同层之间动态切换8位和16位表示；（2）提高了GPU之间的网络速度，允许进行模型并行处理（LLM所需），而不仅仅是数据并行处理（足以应对图像工作负载）。除非你的机器学习模型确实有这一特定需求，否则你不会为每个芯片花费30,000美元。
- en: Similarly, the A100 got its improvement over the V100 by using a specially designed
    10-bit precision floating point type that balances speed and accuracy on image
    and text embedding workloads.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，A100相对于V100的提升在于使用了专门设计的10位精度浮点类型，这种类型在图像和文本嵌入任务中平衡了速度和精度。
- en: 'So knowing what chips a company is buying lets you guess what AI workloads
    a company is investing in. (to a first approximation: the H100 also has hardware
    instructions for some genomics and optimization problems, so it’s not 100% clear-cut).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，了解一家公司购买的芯片，可以让你猜测该公司正在投资的AI工作负载。（粗略地说：H100也有硬件指令来处理一些基因组学和优化问题，因此它并不是100%一清二楚的。）
- en: 6\. People like AI-generated content, until you tell them it is AI generated
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 人们喜欢AI生成的内容，直到你告诉他们这是AI生成的
- en: 'Fascinating study from MIT:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 来自MIT的令人着迷的研究：
- en: '[](https://mitsloan.mit.edu/ideas-made-to-matter/study-gauges-how-people-perceive-ai-created-content?source=post_page-----388262b2ff50--------------------------------)
    [## Study gauges how people perceive AI-created content | MIT Sloan'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mitsloan.mit.edu/ideas-made-to-matter/study-gauges-how-people-perceive-ai-created-content?source=post_page-----388262b2ff50--------------------------------)
    [## 研究衡量人们如何看待AI创作的内容 | MIT Sloan'
- en: Companies that intend to use generative artificial intelligence should first
    consider how people regard work created by…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 打算使用生成性人工智能的公司应该首先考虑人们如何看待由AI创作的作品…
- en: mitsloan.mit.edu](https://mitsloan.mit.edu/ideas-made-to-matter/study-gauges-how-people-perceive-ai-created-content?source=post_page-----388262b2ff50--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: mitsloan.mit.edu](https://mitsloan.mit.edu/ideas-made-to-matter/study-gauges-how-people-perceive-ai-created-content?source=post_page-----388262b2ff50--------------------------------)
- en: 1\. If you have content, some AI-generated and some human-generated, people
    prefer the AI one! If you think AI-generated content is bland and mediocre, you
    (and I) are in the minority. This is similar to how the majority of people actually
    prefer the food in chain restaurants — bland works for more people.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 如果你有一些内容，其中一部分是AI生成的，另一部分是人类生成的，人们更喜欢AI生成的！如果你认为AI生成的内容平淡无奇、平庸乏味，那你（和我）就是少数派。这与大多数人其实更喜欢连锁餐厅的食物类似——平淡的口味更适合更多人。
- en: 2\. If you label content as being AI-generated or human-generated, people prefer
    the human one. This is because they now score human-generated content higher while
    keeping scores for AI the same. There is some sort of virtue-signalling or species-favoritism
    going on.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 如果你将内容标注为AI生成的或人类生成的，人们更喜欢人类生成的。这是因为他们现在会更高评价人类生成的内容，同时保持AI生成的评分不变。这有点像是某种“美德信号”或物种偏好。
- en: Based on this, when artists ask for AI-generated art to be labeled or writers
    ask for AI-generated text to be clearly marked, is it just special pleading? Are
    artists and writers lobbying for preferred treatment?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，当艺术家要求对AI生成的艺术作品进行标注，或者作家要求对AI生成的文本进行明确标记时，这只是特殊诉求吗？艺术家和作家是否在游说争取优待？
- en: Not LLM — but my first love in AI — methods in weather forecasting — are having
    their moment
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不是LLM——但我的AI初恋——天气预报中的方法——正迎来它的时刻
- en: '[](https://www.linkedin.com/feed/update/urn:li:activity:7133201476339859456/?source=post_page-----388262b2ff50--------------------------------)
    [## Valliappa Lakshmanan on LinkedIn: ECMWF | Charts'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/feed/update/urn:li:activity:7133201476339859456/?source=post_page-----388262b2ff50--------------------------------)
    [## Valliappa Lakshmanan在LinkedIn上的动态：ECMWF | 图表'
- en: 10-day machine learning forecast of global weather, created by Google Deep Mind&#39;s
    Graphcast model, now available on…
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 由Google Deep Mind的Graphcast模型创建的10天全球天气机器学习预报，现在可以在…上查看
- en: www.linkedin.com](https://www.linkedin.com/feed/update/urn:li:activity:7133201476339859456/?source=post_page-----388262b2ff50--------------------------------)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.linkedin.com](https://www.linkedin.com/feed/update/urn:li:activity:7133201476339859456/?source=post_page-----388262b2ff50--------------------------------)'
- en: 'Besides GraphCast, there are other global machine learning based weather forecasting
    models that are run in real time. [Imme Ebert-Uphoff](https://www.linkedin.com/in/imme-ebert-uphoff-58a65480/)
    ‘s research group shows them side-by-side (with ECMWF and GFS numerical weather
    forecast as control) here:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 GraphCast，还有其他基于机器学习的全球天气预报模型是实时运行的。[Imme Ebert-Uphoff](https://www.linkedin.com/in/imme-ebert-uphoff-58a65480/)
    的研究小组将它们并排展示（与 ECMWF 和 GFS 数值天气预报作为对照），如图所示：
- en: '[https://lnkd.in/gewVAjMy](https://lnkd.in/gewVAjMy)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://lnkd.in/gewVAjMy](https://lnkd.in/gewVAjMy)'
- en: Side-by-side verification in a setting such as the Storm Prediction Center Spring
    Experiment is essential before these forecasts get employed in decision making.
    Not sure what the equivalent would be for global forecasts, but such evaluation
    is needed. So happy to see that CIRA is providing the capability.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在像风暴预测中心春季实验这样的环境中，进行并行验证是至关重要的，只有这样这些预报才能用于决策制定。对于全球预报的等效方法我不太确定，但这样的评估是必要的。很高兴看到CIRA正在提供这一能力。
- en: 7\. LLMs are plateau-ing
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 大型语言模型（LLM）已趋于平稳
- en: '![](../Images/ffaf68d52b03553928a12f84e6267df6.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffaf68d52b03553928a12f84e6267df6.png)'
- en: I was very unimpressed after OpenAI’s Dev day.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenAI 的开发者日活动之后，我感到非常失望。
- en: 8\. Economics of Gen AI software
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 生成型 AI 软件的经济学
- en: '[](https://medium.com/@annamalaipushpavalli/generative-ai-traditional-software-a-take-on-evolving-business-models-in-technology-a5205d9f73a6?source=post_page-----388262b2ff50--------------------------------)
    [## Generative AI != Traditional Software A Take on evolving Business Models in
    Technology'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@annamalaipushpavalli/generative-ai-traditional-software-a-take-on-evolving-business-models-in-technology-a5205d9f73a6?source=post_page-----388262b2ff50--------------------------------)
    [## 生成型 AI ≠ 传统软件：关于技术中不断发展的商业模式的思考'
- en: AI is pretty much seen as the Future of Software. This can possibly be attributed
    to how AI Applications look and feel…
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能几乎被视为软件的未来。这可能归因于人工智能应用的外观和感觉……
- en: medium.com](https://medium.com/@annamalaipushpavalli/generative-ai-traditional-software-a-take-on-evolving-business-models-in-technology-a5205d9f73a6?source=post_page-----388262b2ff50--------------------------------)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@annamalaipushpavalli/generative-ai-traditional-software-a-take-on-evolving-business-models-in-technology-a5205d9f73a6?source=post_page-----388262b2ff50--------------------------------)
- en: There are two unique characteristics associated with Gen AI software —(1) the
    computational cost is high because it needs GPUs for training/inference (2) the
    data moat is low because smaller models finetuned on comparitively little data
    can equal the performance of larger models. Given this, the usual expectation
    that software has low marginal cost and provides huge economies of scale may no
    longer apply.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型 AI 软件有两个独特的特点——（1）计算成本很高，因为训练/推理需要 GPU（2）数据壁垒较低，因为经过少量数据微调的小型模型能够与大型模型的性能相匹敌。鉴于此，软件通常具有低边际成本并能提供巨大的规模经济这一预期可能不再适用。
- en: 9\. Help! My book is part of the training dataset of LLMs
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 帮助！我的书是大型语言模型训练数据集的一部分
- en: '[https://www.linkedin.com/posts/valliappalakshmanan_seems-that-the-training-dataset-for-many-activity-7112508301090705409-McD_/](https://www.linkedin.com/posts/valliappalakshmanan_seems-that-the-training-dataset-for-many-activity-7112508301090705409-McD_/?utm_source=share&utm_medium=member_desktop)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.linkedin.com/posts/valliappalakshmanan_seems-that-the-training-dataset-for-many-activity-7112508301090705409-McD_/](https://www.linkedin.com/posts/valliappalakshmanan_seems-that-the-training-dataset-for-many-activity-7112508301090705409-McD_/?utm_source=share&utm_medium=member_desktop)'
- en: '![](../Images/c15f521ebff23282745744e1f8e7fb48.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c15f521ebff23282745744e1f8e7fb48.png)'
- en: Many of the LLMs on the market include a dataset called Books3 in their training
    corpus. The problem is that this corpus includes pirated copies of books. I used
    a tool created by the author of the Atlantic article
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 市场上的许多大型语言模型（LLMs）在它们的训练语料库中包含了名为 Books3 的数据集。问题在于，这个语料库包括了被盗版的书籍。我使用了由《大西洋月刊》文章的作者创建的工具
- en: '[](https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/?source=post_page-----388262b2ff50--------------------------------)
    [## Revealed: The Authors Whose Pirated Books Are Powering Generative AI'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/?source=post_page-----388262b2ff50--------------------------------)
    [## 揭示：那些被盗版书籍推动的生成型 AI 作者'
- en: Stephen King, Zadie Smith, and Michael Pollan are among thousands of writers
    whose copyrighted works are being used to…
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 斯蒂芬·金、扎迪·史密斯和迈克尔·波伦是成千上万位作家的其中之一，他们的版权作品正在被用来……
- en: www.theatlantic.com](https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/?source=post_page-----388262b2ff50--------------------------------)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.theatlantic.com](https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/?source=post_page-----388262b2ff50--------------------------------)'
- en: to check whether any of my books is in the corpus. And indeed, it seems one
    of the books is.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以检查我的书籍是否包含在语料库中。果然，似乎有一本书在其中。
- en: It was a humorous post, but captures the real dilemma since no one writes technical
    books (entire audience is a few thousands of copies) to make money.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个幽默的帖子，但它捕捉到了真实的困境，因为没有人写技术书籍（整个读者群只有几千本）是为了赚钱。
- en: '**10\. A way to detect Hallucinated Facts in LLM-generated text**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**10\. 检测 LLM 生成文本中的幻觉事实的方法**'
- en: '[https://www.linkedin.com/posts/valliappalakshmanan_bard-just-rolled-out-a-verify-with-google-activity-7109990134770528256-Zzji](https://www.linkedin.com/posts/valliappalakshmanan_bard-just-rolled-out-a-verify-with-google-activity-7109990134770528256-Zzji?utm_source=share&utm_medium=member_desktop)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.linkedin.com/posts/valliappalakshmanan_bard-just-rolled-out-a-verify-with-google-activity-7109990134770528256-Zzji](https://www.linkedin.com/posts/valliappalakshmanan_bard-just-rolled-out-a-verify-with-google-activity-7109990134770528256-Zzji?utm_source=share&utm_medium=member_desktop)'
- en: '![](../Images/724a16033c2fb8c72e1a59048aa5e9e7.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/724a16033c2fb8c72e1a59048aa5e9e7.png)'
- en: Because LLMs are autocomplete machines, they will pick the most likely next
    phrase given the preceding text. But what if there isn’t enough data on a topic?
    Then, the “most likely” next phrase is an average of many different articles in
    the general area, and so the resulting sentence is likely to be factually wrong.
    We say that the LLM has “hallucinated” a fact.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 LLM 是自动补全机器，它们会根据前面的文本选择最可能的下一个短语。但如果某个话题的数据不足怎么办？那么，最“可能”的下一个短语就是该领域中许多不同文章的平均值，因此生成的句子很可能是事实错误。我们说
    LLM “幻觉”了一个事实。
- en: This update from Bard takes advantage of the relationship between frequency
    in the training dataset and hallucination to mark areas of the generated text
    that are likely to be factually incorrect.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Bard 的这一更新利用了训练数据集中的频率与幻觉之间的关系，标记出生成文本中可能在事实上不准确的部分。
- en: '*Follow me on LinkedIn:* [*https://www.linkedin.com/in/valliappalakshmanan/*](https://www.linkedin.com/in/valliappalakshmanan/)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*在 LinkedIn 上关注我:* [*https://www.linkedin.com/in/valliappalakshmanan/*](https://www.linkedin.com/in/valliappalakshmanan/)'
