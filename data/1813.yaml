- en: 9.11 or 9.9 â€” which one is higher?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9.11è¿˜æ˜¯9.9â€”â€”å“ªä¸ªæ›´å¤§ï¼Ÿ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25](https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25](https://towardsdatascience.com/9-11-or-9-9-which-one-is-higher-6efbdbd6a025?source=collection_archive---------7-----------------------#2024-07-25)
- en: Evaluating the uncertainty and brittleness in LLM prompts
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯„ä¼°LLMæç¤ºä¸­çš„ä¸ç¡®å®šæ€§å’Œè„†å¼±æ€§
- en: '[](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[![Armin
    Catovic](../Images/046042098f3fec885e756f7f8ee94e6a.png)](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    [Armin Catovic](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[![Armin
    Catovic](../Images/046042098f3fec885e756f7f8ee94e6a.png)](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    [Armin Catovic](https://medium.com/@armin.catovic?source=post_page---byline--6efbdbd6a025--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    Â·5 min readÂ·Jul 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6efbdbd6a025--------------------------------)
    Â·é˜…è¯»æ—¶é—´5åˆ†é’ŸÂ·2024å¹´7æœˆ25æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'This ChatGPT prompt and its corresponding (incorrect) response were recently
    shared and re-posted on LinkedIn countless times. They were given as a solid proof
    that the AGI is just not there yet. Further re-posts also pointed out that re-arranging
    the prompt to: *â€œWhich one is higher: 9.11 or 9.9?â€,* guarantees a correct answer,
    and further emphasizes the brittleness of LLMs.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªChatGPTæç¤ºåŠå…¶å¯¹åº”çš„ï¼ˆé”™è¯¯çš„ï¼‰å›ç­”æœ€è¿‘åœ¨LinkedInä¸Šè¢«åˆ†äº«å’Œè½¬å‘äº†æ— æ•°æ¬¡ã€‚å®ƒä»¬è¢«ä½œä¸ºè¯æ˜AGIè¿˜è¿œæœªå®ç°çš„æœ‰åŠ›è¯æ®ã€‚è¿›ä¸€æ­¥çš„è½¬å‘è¿˜æŒ‡å‡ºï¼Œå°†æç¤ºæ”¹ä¸ºï¼š*â€œå“ªä¸ªæ›´å¤§ï¼š9.11è¿˜æ˜¯9.9ï¼Ÿâ€*
    å¯ä»¥ä¿è¯å¾—åˆ°æ­£ç¡®ç­”æ¡ˆï¼Œå¹¶è¿›ä¸€æ­¥å¼ºè°ƒäº†LLMçš„è„†å¼±æ€§ã€‚
- en: After evaluating both prompts against a random group of ChatGPT users, we found
    that in both cases the answer is **incorrect about 50%** of the time. As some
    users have correctly pointed out, there is a subtle ambiguity with the question,
    i.e. are we referring to mathematical inequality of two real numbers, or are we
    referring to two dates (e.g. September 11 vs September 9), or two sub-sections
    in a document (e.g. chapter 9.11 or 9.9)?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¯¹ä¸€ç»„éšæœºçš„ChatGPTç”¨æˆ·è¿›è¡Œè¯„ä¼°åï¼Œæˆ‘ä»¬å‘ç°ï¼Œåœ¨ä¸¤ç§æƒ…å†µä¸­ï¼Œç­”æ¡ˆ**å¤§çº¦50%çš„æ—¶é—´æ˜¯é”™è¯¯çš„**ã€‚æ­£å¦‚ä¸€äº›ç”¨æˆ·æ­£ç¡®æŒ‡å‡ºçš„é‚£æ ·ï¼Œè¿™ä¸ªé—®é¢˜å­˜åœ¨å¾®å¦™çš„æ­§ä¹‰ï¼Œå³æˆ‘ä»¬æ˜¯æŒ‡ä¸¤ä¸ªå®æ•°çš„æ•°å­¦ä¸ç­‰å¼ï¼Œè¿˜æ˜¯æŒ‡ä¸¤ä¸ªæ—¥æœŸï¼ˆä¾‹å¦‚9æœˆ11æ—¥ä¸9æœˆ9æ—¥ï¼‰ï¼Œæˆ–è€…æ˜¯æŒ‡æ–‡æ¡£ä¸­çš„ä¸¤ä¸ªå­éƒ¨åˆ†ï¼ˆä¾‹å¦‚ç¬¬9.11ç« æˆ–ç¬¬9.9ç« ï¼‰ï¼Ÿ
- en: We decided to perform a more controlled experiment by using OpenAI APIs. This
    way we have full control over both the system prompt and the user prompt; we can
    also take out the sampling uncertainty out of the equation as far as possible
    by e.g. setting the temperature low.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å†³å®šé€šè¿‡ä½¿ç”¨OpenAI APIè¿›è¡Œæ›´å—æ§çš„å®éªŒã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥å®Œå…¨æ§åˆ¶ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤ºï¼›æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è®¾ç½®ä½æ¸©åº¦ç­‰æ–¹å¼å°½å¯èƒ½åœ°å»é™¤é‡‡æ ·ä¸ç¡®å®šæ€§ã€‚
- en: '**The final results are very interesting!**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€ç»ˆç»“æœéå¸¸æœ‰è¶£ï¼**'
- en: Hypotheses and Experimental Design
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‡è®¾å’Œå®éªŒè®¾è®¡
- en: 'Our hypotheses can be stated as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å‡è®¾å¯ä»¥å¦‚ä¸‹è¡¨è¿°ï¼š
- en: Given the same prompt, without any additional context, and with temperature
    kept close to zero, we should nearly always obtain the same output, with stable
    log probabilities. While people refer to LLMs as â€œstochasticâ€, for a given input,
    LLM should always generate the same output; the â€œhallucinationsâ€ or variance comes
    from the sampling mechanism outside of the LLM, and this we can dampen significantly
    by setting a very low temperature value.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç›¸åŒçš„æç¤ºä¸‹ï¼Œå¦‚æœæ²¡æœ‰é¢å¤–çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”å°†æ¸©åº¦ä¿æŒæ¥è¿‘é›¶ï¼Œæˆ‘ä»¬åº”è¯¥å‡ ä¹æ€»æ˜¯å¾—åˆ°ç›¸åŒçš„è¾“å‡ºï¼Œä¸”æ—¥å¿—æ¦‚ç‡ç¨³å®šã€‚è™½ç„¶äººä»¬å¸¸å°†LLMç§°ä¸ºâ€œéšæœºçš„â€ï¼Œä½†å¯¹äºç»™å®šçš„è¾“å…¥ï¼ŒLLMåº”è¯¥æ€»æ˜¯ç”Ÿæˆç›¸åŒçš„è¾“å‡ºï¼›æ‰€è°“çš„â€œå¹»è§‰â€æˆ–å˜å¼‚æ¥è‡ªLLMä¹‹å¤–çš„é‡‡æ ·æœºåˆ¶ï¼Œè¿™ä¸€ç‚¹æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½®éå¸¸ä½çš„æ¸©åº¦å€¼æ¥æ˜¾è‘—å‡å¼±ã€‚
- en: Based on our random user tests with ChatGPT, we would expect both the original
    prompt, and the re-worded version to give incorrect answer 50% of the time â€” in
    other words, without further disambiguation or context, we wouldnâ€™t expect one
    prompt to perform better than the other.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºæˆ‘ä»¬ä¸ ChatGPT è¿›è¡Œçš„éšæœºç”¨æˆ·æµ‹è¯•ï¼Œæˆ‘ä»¬é¢„æœŸåŸå§‹æç¤ºå’Œé‡æ–°æªè¾åçš„ç‰ˆæœ¬åœ¨ 50% çš„æƒ…å†µä¸‹ç»™å‡ºé”™è¯¯ç­”æ¡ˆâ€”â€”æ¢å¥è¯è¯´ï¼Œè‹¥æ²¡æœ‰è¿›ä¸€æ­¥çš„æ¾„æ¸…æˆ–ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬ä¸è®¤ä¸ºæŸä¸€ä¸ªæç¤ºä¼šæ¯”å¦ä¸€ä¸ªè¡¨ç°å¾—æ›´å¥½ã€‚
- en: 'For our experiment design, we perform the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„å®éªŒè®¾è®¡ï¼Œæˆ‘ä»¬æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
- en: We conduct a number of experiments, starting with the original prompt, followed
    by a series of â€œinterventionsâ€
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒï¼Œä»åŸå§‹æç¤ºå¼€å§‹ï¼Œéšåè¿›è¡Œä¸€ç³»åˆ—çš„â€œå¹²é¢„â€
- en: For each experiment/intervention, we execute 1 000 trials
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯æ¬¡å®éªŒ/å¹²é¢„ï¼Œæˆ‘ä»¬æ‰§è¡Œ 1 000 æ¬¡è¯•éªŒ
- en: We use OpenAIâ€™s most advanced GPT-4o model
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ OpenAI æœ€å…ˆè¿›çš„ GPT-4o æ¨¡å‹
- en: We set the temperature to 0.1 to essentially eliminate the randomness due to
    sampling; we experiment with both random seed as well as fixed seed
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¸©åº¦è®¾ç½®ä¸º 0.1ï¼Œä»¥åŸºæœ¬æ¶ˆé™¤ç”±é‡‡æ ·å¼•èµ·çš„éšæœºæ€§ï¼›æˆ‘ä»¬å®éªŒäº†éšæœºç§å­å’Œå›ºå®šç§å­ä¸¤ç§æƒ…å†µ
- en: To gauge the â€œconfidenceâ€ of the answer, we collect the log probability and
    calculate the linear probability of the answer in each trial; we plot the Kernel
    Density Estimate (KDE) of the linear probabilities across the 1 000 trials for
    each of the experiments
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯„ä¼°ç­”æ¡ˆçš„â€œä¿¡å¿ƒâ€ï¼Œæˆ‘ä»¬æ”¶é›†äº†æ—¥å¿—æ¦‚ç‡å¹¶è®¡ç®—æ¯æ¬¡è¯•éªŒä¸­ç­”æ¡ˆçš„çº¿æ€§æ¦‚ç‡ï¼›æˆ‘ä»¬ç»˜åˆ¶äº†æ¯æ¬¡å®éªŒä¸­ 1000 æ¬¡è¯•éªŒçš„çº¿æ€§æ¦‚ç‡çš„æ ¸å¯†åº¦ä¼°è®¡ï¼ˆKDEï¼‰å›¾
- en: The full code for our experimental design is available [here](https://github.com/acatovic/llm-prompt-uncertainty-test).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å®éªŒè®¾è®¡çš„å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/acatovic/llm-prompt-uncertainty-test)æ‰¾åˆ°ã€‚
- en: Experiment (A) â€” Original Prompt
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®éªŒ (A) â€” åŸå§‹æç¤º
- en: The user prompt is set to *â€œ9.11 or 9.9 â€” which one is higher?â€*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·æç¤ºè®¾ç½®ä¸º*â€œ9.11 è¿˜æ˜¯ 9.9 â€” å“ªä¸ªæ›´å¤§ï¼Ÿâ€*ã€‚
- en: In line with what social media users have reported, **GPT-4o gives the correct
    answer 55% of the time** â˜¹ï¸. The model is also not very certain â€” on large number
    of trials, **its â€œconfidenceâ€ in the answer is ~80%**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç¤¾äº¤åª’ä½“ç”¨æˆ·çš„åé¦ˆä¸€è‡´ï¼Œ**GPT-4o æ­£ç¡®å›ç­”çš„æ¦‚ç‡ä¸º 55%** â˜¹ï¸ã€‚è¯¥æ¨¡å‹çš„â€œä¿¡å¿ƒâ€ä¹Ÿå¹¶ä¸é«˜â€”â€”åœ¨å¤§é‡è¯•éªŒä¸­ï¼Œ**å®ƒå¯¹ç­”æ¡ˆçš„â€œä¿¡å¿ƒâ€çº¦ä¸º 80%**ã€‚
- en: '![](../Images/303e02b6da3e317bb99c38ca028ad4fa.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/303e02b6da3e317bb99c38ca028ad4fa.png)'
- en: Figure 1 â€” Smoothed histogram (KDE) of confidence values (0â€“100%) across 1000
    trials, when the original user prompt is used; image by the author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1 â€” åœ¨ 1000 æ¬¡è¯•éªŒä¸­ï¼Œå½“ä½¿ç”¨åŸå§‹ç”¨æˆ·æç¤ºæ—¶ï¼Œä¿¡å¿ƒå€¼ï¼ˆ0-100%ï¼‰çš„å¹³æ»‘ç›´æ–¹å›¾ï¼ˆKDEï¼‰ï¼›å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Experiment (B) â€” Re-worded User Prompt
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®éªŒ (B) â€” é‡æ–°æªè¾çš„ç”¨æˆ·æç¤º
- en: 'In the re-worded user prompt, no additional context/disambiguation is provided,
    but the wording is slightly changed to: *â€œWhich one is higher, 9.11 or 9.9?â€*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é‡æ–°æªè¾çš„ç”¨æˆ·æç¤ºä¸­ï¼Œæœªæä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡/æ¾„æ¸…ï¼Œä½†æªè¾ç•¥ä½œæ›´æ”¹ä¸ºï¼š*â€œå“ªä¸ªæ›´å¤§ï¼Œ9.11 è¿˜æ˜¯ 9.9ï¼Ÿâ€*
- en: Amazingly, and contrary to our ChatGPT user tests, the **correct answer is reached
    100% of the time** across 1 000 trials. Furthermore, the model exhibits **very
    high confidenc**e in its answer ğŸ¤”.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä¸æˆ‘ä»¬çš„ ChatGPT ç”¨æˆ·æµ‹è¯•ç›¸åï¼Œ**åœ¨ 1000 æ¬¡è¯•éªŒä¸­æ­£ç¡®ç­”æ¡ˆçš„è¾¾æˆç‡ä¸º 100%**ã€‚æ­¤å¤–ï¼Œæ¨¡å‹å¯¹å…¶ç­”æ¡ˆè¡¨ç°å‡º**éå¸¸é«˜çš„ä¿¡å¿ƒ**ğŸ¤”ã€‚
- en: '![](../Images/bd2ac34fa08ee808f5ab358f41a3e665.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd2ac34fa08ee808f5ab358f41a3e665.png)'
- en: Figure 2 â€” Smoothed histogram (KDE) of confidence values (0â€“100%) across 1000
    trials, when the original user prompt is slightly re-worded; image by the author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2 â€” åœ¨ 1000 æ¬¡è¯•éªŒä¸­ï¼Œå½“åŸå§‹ç”¨æˆ·æç¤ºè¢«ç¨å¾®é‡æ–°æªè¾æ—¶ï¼Œä¿¡å¿ƒå€¼ï¼ˆ0-100%ï¼‰çš„å¹³æ»‘ç›´æ–¹å›¾ï¼ˆKDEï¼‰ï¼›å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Experiment (C) â€” Original User Prompt with Reasoning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®éªŒ (C) â€” å¸¦æ¨ç†çš„åŸå§‹ç”¨æˆ·æç¤º
- en: There has been significant work recently in trying to induce improved â€œreasoningâ€
    capabilities in LLMs with chain-of-thought (CoT) prompting being the most popular.
    [Huang et al](https://arxiv.org/pdf/2212.10403) have published a very comprehensive
    survey on LLM reasoning capabilities.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘åœ¨åŠªåŠ›æé«˜å¤§è¯­è¨€æ¨¡å‹â€œæ¨ç†â€èƒ½åŠ›æ–¹é¢åšäº†å¤§é‡å·¥ä½œï¼Œå…¶ä¸­é“¾å¼æ¨ç†ï¼ˆCoTï¼‰æç¤ºæ³•æ˜¯æœ€å—æ¬¢è¿çš„ã€‚[é»„ç­‰](https://arxiv.org/pdf/2212.10403)å‘å¸ƒäº†å…³äº
    LLM æ¨ç†èƒ½åŠ›çš„éå¸¸å…¨é¢çš„è°ƒæŸ¥ã€‚
- en: As such, we modify the original user prompt by also telling the LLM to explain
    its reasoning. Interestingly enough, the **probability of correct answer improves
    to 62%**, however the answers come with **even greater uncertainty**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ä¿®æ”¹äº†åŸå§‹ç”¨æˆ·æç¤ºï¼Œè¦æ±‚å¤§è¯­è¨€æ¨¡å‹åŒæ—¶è§£é‡Šå…¶æ¨ç†ã€‚æœ‰è¶£çš„æ˜¯ï¼Œ**æ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡æé«˜åˆ°äº† 62%**ï¼Œç„¶è€Œç­”æ¡ˆä¼´éšçš„æ˜¯**æ›´å¤§çš„ä¸ç¡®å®šæ€§**ã€‚
- en: '![](../Images/c8d22876d032feec673a6dce588b7c6d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8d22876d032feec673a6dce588b7c6d.png)'
- en: Figure 3 â€” Smoothed histogram (KDE) of confidence values (0â€“100%) across 1000
    trials, when the original user prompt is modified to also â€œexplain its reasoningâ€;
    image by the author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3 â€” åœ¨ 1000 æ¬¡è¯•éªŒä¸­ï¼Œå½“åŸå§‹ç”¨æˆ·æç¤ºè¢«ä¿®æ”¹ä¸ºåŒæ—¶â€œè§£é‡Šå…¶æ¨ç†â€æ—¶ï¼Œä¿¡å¿ƒå€¼ï¼ˆ0-100%ï¼‰çš„å¹³æ»‘ç›´æ–¹å›¾ï¼ˆKDEï¼‰ï¼›å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Experiment (D) â€” Original User Prompt with Reasoning in the System Prompt
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®éªŒï¼ˆDï¼‰â€” åŸå§‹ç”¨æˆ·æç¤ºä¸ç³»ç»Ÿæç¤ºä¸­çš„æ¨ç†
- en: The final experiment is the same as experiment â€œCâ€, however we instead bootstrap
    the **system prompt** by telling the LLM to â€œexplain its reasoningâ€. Incredibly,
    we now see the **correct answer 100% of the time**, with **very high confidence**.
    We see identical results if we use the re-worded user prompt as well.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åçš„å®éªŒä¸å®éªŒâ€œCâ€ç›¸åŒï¼Œä½†æˆ‘ä»¬æ”¹ä¸ºé€šè¿‡å‘Šè¯‰LLMâ€œè§£é‡Šå…¶æ¨ç†è¿‡ç¨‹â€æ¥å¼•å¯¼**ç³»ç»Ÿæç¤º**ã€‚ä»¤äººéš¾ä»¥ç½®ä¿¡çš„æ˜¯ï¼Œæˆ‘ä»¬ç°åœ¨çœ‹åˆ°**100%æ­£ç¡®çš„ç­”æ¡ˆ**ï¼Œå¹¶ä¸”**ä¿¡å¿ƒæé«˜**ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨é‡æ–°è¡¨è¿°çš„ç”¨æˆ·æç¤ºï¼Œç»“æœä¹Ÿå®Œå…¨ç›¸åŒã€‚
- en: '![](../Images/c7fbb5db47568c2f787a98e7d755c7dc.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7fbb5db47568c2f787a98e7d755c7dc.png)'
- en: Figure 4 â€” Smoothed histogram (KDE) of confidence values (0â€“100%) across 1000
    trials, with the original user prompt, and system prompt amended with instructions
    to â€œexplain its reasoningâ€; image by the author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4 â€” ä¿¡å¿ƒå€¼ï¼ˆ0-100%ï¼‰åœ¨1000æ¬¡è¯•éªŒä¸­çš„å¹³æ»‘ç›´æ–¹å›¾ï¼ˆKDEï¼‰ï¼Œä½¿ç”¨åŸå§‹ç”¨æˆ·æç¤ºï¼Œå¹¶ä¸”ç³»ç»Ÿæç¤ºå·²ä¿®æ”¹ï¼Œå¢åŠ äº†â€œè§£é‡Šå…¶æ¨ç†è¿‡ç¨‹â€çš„æŒ‡ç¤ºï¼›å›¾åƒç”±ä½œè€…æä¾›
- en: Conclusion and Takeaways
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®ºä¸æ€»ç»“
- en: 'What started off as a simple experiment to validate some of the statements
    seen on social media, ended up with some very interesting findings. Letâ€™s summarize
    the key takeaways:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åˆæ˜¯ä¸€ä¸ªç®€å•çš„å®éªŒï¼Œæ—¨åœ¨éªŒè¯ç¤¾äº¤åª’ä½“ä¸Šçœ‹åˆ°çš„ä¸€äº›è¯´æ³•ï¼Œç»“æœå´å¾—å‡ºäº†ä¸€äº›éå¸¸æœ‰è¶£çš„å‘ç°ã€‚è®©æˆ‘ä»¬æ€»ç»“ä¸€ä¸‹å…³é”®ç»“è®ºï¼š
- en: '**For an identical prompt, with both temperature set very low (essentially
    eliminating sampling uncertainty), and a fixed seed value, we see very large variance
    in log probabilities**. Slight variance can be explained by hardware precision,
    but variance this large is very difficult to explain. It indicates that either
    (1) sampling mechanism is a LOT more complicated, or (2) there are more layers/models
    upstream beyond our control.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯¹äºç›¸åŒçš„æç¤ºï¼Œå½“æ¸©åº¦è®¾ç½®éå¸¸ä½ï¼ˆåŸºæœ¬æ¶ˆé™¤é‡‡æ ·ä¸ç¡®å®šæ€§ï¼‰å¹¶ä¸”ç§å­å€¼å›ºå®šæ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°å¯¹æ•°æ¦‚ç‡çš„æ–¹å·®éå¸¸å¤§**ã€‚è½»å¾®çš„æ–¹å·®å¯ä»¥é€šè¿‡ç¡¬ä»¶ç²¾åº¦æ¥è§£é‡Šï¼Œä½†å¦‚æ­¤å¤§çš„æ–¹å·®å¾ˆéš¾è§£é‡Šã€‚è¿™è¡¨æ˜ï¼Œå¯èƒ½æœ‰ä¸¤ç§æƒ…å†µï¼šï¼ˆ1ï¼‰é‡‡æ ·æœºåˆ¶å¤æ‚å¾—å¤šï¼Œæˆ–è€…ï¼ˆ2ï¼‰åœ¨æˆ‘ä»¬æ§åˆ¶èŒƒå›´ä¹‹å¤–ï¼Œè¿˜æœ‰æ›´å¤šçš„å±‚çº§/æ¨¡å‹åœ¨ä¸Šæ¸¸ã€‚'
- en: In line with previous literature, **simply instructing the LLM to â€œexplain its
    reasoningâ€ improves its performance**.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ä¹‹å‰çš„æ–‡çŒ®ä¸€è‡´ï¼Œ**ä»…ä»…æŒ‡ç¤ºLLMâ€œè§£é‡Šå…¶æ¨ç†è¿‡ç¨‹â€å°±èƒ½æé«˜å…¶è¡¨ç°**ã€‚
- en: '**There is clearly a distinct handling between the system prompt and the user
    prompt**. Bootstrapping a role in the system prompt as opposed to the user prompt,
    seems to result in significantly better performance.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç³»ç»Ÿæç¤ºä¸ç”¨æˆ·æç¤ºä¹‹é—´æ˜¾ç„¶æœ‰æ˜æ˜¾çš„å·®å¼‚å¤„ç†**ã€‚åœ¨ç³»ç»Ÿæç¤ºä¸­å¼•å¯¼è§’è‰²ï¼Œè€Œéåœ¨ç”¨æˆ·æç¤ºä¸­å¼•å¯¼ï¼Œä¼¼ä¹ä¼šæ˜¾è‘—æé«˜æ€§èƒ½ã€‚'
- en: We can clearly see how brittle the prompts can be. The key takeaway here is
    that we should always aim to provide disambiguation and clear context in our prompts.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°æç¤ºæ˜¯å¤šä¹ˆè„†å¼±ã€‚è¿™é‡Œçš„å…³é”®ç»“è®ºæ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥å§‹ç»ˆåŠªåŠ›åœ¨æç¤ºä¸­æä¾›æ¶ˆæ­§ä¹‰å’Œæ˜ç¡®çš„ä¸Šä¸‹æ–‡ã€‚
- en: '***Disclaimer:*** *due to heavy coverage on social media, it is likely that
    the lovely people at OpenAI have in fact improved the above behaviour, so the
    results may not be directly reproducible. However the key takeaways are still
    very valid!*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '***å…è´£å£°æ˜ï¼š*** *ç”±äºç¤¾äº¤åª’ä½“ä¸Šçš„å¹¿æ³›è®¨è®ºï¼ŒOpenAI çš„å·¥ä½œäººå‘˜å¯èƒ½å·²ç»æ”¹è¿›äº†ä¸Šè¿°è¡Œä¸ºï¼Œå› æ­¤ç»“æœå¯èƒ½æ— æ³•ç›´æ¥é‡ç°ã€‚ä½†å…³é”®çš„ç»“è®ºä»ç„¶æœ‰æ•ˆï¼*'
