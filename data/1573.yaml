- en: Mastering Object Counting in Videos
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è§†é¢‘ä¸­çš„ç‰©ä½“è®¡æ•°
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/mastering-object-counting-in-videos-3d49a9230bd2?source=collection_archive---------3-----------------------#2024-06-25](https://towardsdatascience.com/mastering-object-counting-in-videos-3d49a9230bd2?source=collection_archive---------3-----------------------#2024-06-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/mastering-object-counting-in-videos-3d49a9230bd2?source=collection_archive---------3-----------------------#2024-06-25](https://towardsdatascience.com/mastering-object-counting-in-videos-3d49a9230bd2?source=collection_archive---------3-----------------------#2024-06-25)
- en: Step-by-step guide to counting strolling ants on a tree using detection and
    tracking techniques.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŒ‰æ­¥éª¤æŒ‡å¯¼å¦‚ä½•ä½¿ç”¨æ£€æµ‹å’Œè¿½è¸ªæŠ€æœ¯è®¡æ•°æ ‘ä¸Šè¡Œèµ°çš„èš‚èšã€‚
- en: '[](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)[![Lihi
    Gur Arie, PhD](../Images/7a1eb30725a95159401c3672fa5f43ab.png)](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)
    [Lihi Gur Arie, PhD](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)[![Lihi
    Gur Arie, åšå£«](../Images/7a1eb30725a95159401c3672fa5f43ab.png)](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)
    [Lihi Gur Arie, åšå£«](https://medium.com/@lihigurarie?source=post_page---byline--3d49a9230bd2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)
    Â·7 min readÂ·Jun 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3d49a9230bd2--------------------------------)
    Â·é˜…è¯»æ—¶é—´7åˆ†é’ŸÂ·2024å¹´6æœˆ25æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Ants counting in a video. In and Out counts appear on the upper left corner.
    Each ant is assigned a unique ID and color. Labels by Author, Original video by
    [Lui Lo Franco at Pexels](https://www.pexels.com/video/ants-carrying-leaves-on-tree-trunk-9888614/)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è§†é¢‘ä¸­çš„èš‚èšè®¡æ•°ã€‚å·¦ä¸Šè§’æ˜¾ç¤ºè¿›å…¥å’Œé€€å‡ºçš„è®¡æ•°ã€‚æ¯åªèš‚èšè¢«åˆ†é…ä¸€ä¸ªç‹¬ç‰¹çš„IDå’Œé¢œè‰²ã€‚æ ‡ç­¾ç”±ä½œè€…æä¾›ï¼ŒåŸå§‹è§†é¢‘ç”± [Lui Lo Francoåœ¨Pexels](https://www.pexels.com/video/ants-carrying-leaves-on-tree-trunk-9888614/)
    æä¾›ã€‚
- en: '**Introduction**'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ä»‹ç»**'
- en: Counting objects in videos is a challenging Computer Vision task. Unlike counting
    objects in static images, videos involve additional complexities, since objects
    can move, become occluded, or appear and disappear at different times, which complicates
    the counting process.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è§†é¢‘ä¸­è®¡æ•°ç‰©ä½“æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚ä¸é™æ€å›¾åƒä¸­çš„ç‰©ä½“è®¡æ•°ä¸åŒï¼Œè§†é¢‘åŒ…å«æ›´å¤šçš„å¤æ‚æ€§ï¼Œå› ä¸ºç‰©ä½“å¯ä»¥ç§»åŠ¨ã€è¢«é®æŒ¡æˆ–åœ¨ä¸åŒæ—¶é—´å‡ºç°å’Œæ¶ˆå¤±ï¼Œè¿™ä½¿å¾—è®¡æ•°è¿‡ç¨‹æ›´åŠ å¤æ‚ã€‚
- en: In this tutorial, weâ€™ll demonstrate how to count ants moving along a tree, using
    Object Detection and tracking techniques. Weâ€™ll harness Ultralytics platform to
    integrate YOLOv8 model for detection, BoT-SORT for tracking, and a line counter
    to count the ants.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç‰©ä½“æ£€æµ‹å’Œè¿½è¸ªæŠ€æœ¯è®¡æ•°æ²¿æ ‘æœ¨ç§»åŠ¨çš„èš‚èšã€‚æˆ‘ä»¬å°†åˆ©ç”¨Ultralyticså¹³å°é›†æˆYOLOv8æ¨¡å‹è¿›è¡Œæ£€æµ‹ï¼Œä½¿ç”¨BoT-SORTè¿›è¡Œè¿½è¸ªï¼Œå¹¶é€šè¿‡è®¡æ•°çº¿æ¥è®¡ç®—èš‚èšçš„æ•°é‡ã€‚
- en: If you donâ€™t have a paid Medium account, you can read for free[here](/mastering-object-counting-in-videos-3d49a9230bd2?sk=8ec6a61e5dc66ec0ebc762ba01b6af73).
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ²¡æœ‰ä»˜è´¹çš„Mediumè´¦æˆ·ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](/mastering-object-counting-in-videos-3d49a9230bd2?sk=8ec6a61e5dc66ec0ebc762ba01b6af73)å…è´¹é˜…è¯»ã€‚
- en: Pipeline Overview
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æµç¨‹æ¦‚è¿°
- en: 'In a typical video object counting pipeline, each frame undergoes a sequence
    of processes: detection, tracking, and counting. Hereâ€™s a brief overview of each
    step:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å…¸å‹çš„è§†é¢‘ç‰©ä½“è®¡æ•°æµç¨‹ä¸­ï¼Œæ¯ä¸€å¸§ä¼šç»å†ä¸€ç³»åˆ—çš„å¤„ç†æ­¥éª¤ï¼šæ£€æµ‹ã€è¿½è¸ªå’Œè®¡æ•°ã€‚ä»¥ä¸‹æ˜¯æ¯ä¸ªæ­¥éª¤çš„ç®€è¦æ¦‚è¿°ï¼š
- en: '**Detection:** An object detector identifies and locates objects in each frame,
    producing bounding boxes around them.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ£€æµ‹ï¼š**ä¸€ä¸ªç‰©ä½“æ£€æµ‹å™¨åœ¨æ¯ä¸€å¸§ä¸­è¯†åˆ«å¹¶å®šä½ç‰©ä½“ï¼Œç”Ÿæˆå›´ç»•ç‰©ä½“çš„è¾¹ç•Œæ¡†ã€‚'
- en: '**Tracking**: A tracker follows these objects across frames, assigning unique
    IDs to each object to ensure they are counted only once.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¿½è¸ªï¼š**è¿½è¸ªå™¨åœ¨æ¯ä¸€å¸§ä¹‹é—´è·Ÿè¸ªè¿™äº›ç‰©ä½“ï¼Œç»™æ¯ä¸ªç‰©ä½“åˆ†é…å”¯ä¸€çš„IDï¼Œç¡®ä¿å®ƒä»¬åªè¢«è®¡æ•°ä¸€æ¬¡ã€‚'
- en: '**Counting**: The counting module aggregates this information and adds each
    new object to provide accurate results.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡æ•°ï¼š**è®¡æ•°æ¨¡å—æ±‡æ€»è¿™äº›ä¿¡æ¯ï¼Œå¹¶å°†æ¯ä¸ªæ–°ç‰©ä½“åŠ å…¥ï¼Œä»¥æä¾›å‡†ç¡®çš„ç»“æœã€‚'
- en: '![](../Images/020922d351e2affc484485704545edb2.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/020922d351e2affc484485704545edb2.png)'
- en: Image by Author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Connecting an object detector, a tracker, and a counter might require extensive
    coding. Fortunately, the Ultralytics library [1] simplifies this process by providing
    a convenient pipeline that seamlessly integrates these components.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿æ¥ç‰©ä½“æ£€æµ‹å™¨ã€è¿½è¸ªå™¨å’Œè®¡æ•°å™¨å¯èƒ½éœ€è¦å¤§é‡ç¼–ç ã€‚å¹¸è¿çš„æ˜¯ï¼ŒUltralyticsåº“[1]é€šè¿‡æä¾›ä¸€ä¸ªä¾¿æ·çš„æµæ°´çº¿æ¥ç®€åŒ–è¿™ä¸€è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ— ç¼åœ°é›†æˆè¿™äº›ç»„ä»¶ã€‚
- en: 1\. Detecting Objects with YOLOv8
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. ä½¿ç”¨YOLOv8æ£€æµ‹ç‰©ä½“
- en: The first step is to detect the ants in each frame produce bounding boxes around
    them. In this tutorial, we will use a YOLOv8 detector that I trained in advance
    to detect ants. I used [Grounding DINO](/automatic-labeling-of-object-detection-datasets-using-groundingdino-b66c486656fe?sk=7c98df89b60ea49a6de9efd5278f645e)
    [2] to label the data, and then I used the annotated data to train the YOLOv8
    model. If you want to learn more about training a YOLO model, refer to my previous
    post on [training YOLOv5](/the-practical-guide-for-object-detection-with-yolov5-algorithm-74c04aac4843?sk=00d2a9d6dd84d6ac4de153cab3dba7c0),
    as the concepts are similar. For your application, you can use a pre-trained model
    or train a custom model of your own.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥æ˜¯åœ¨æ¯ä¸€å¸§ä¸­æ£€æµ‹èš‚èšï¼Œå¹¶ä¸ºå®ƒä»¬ç”Ÿæˆè¾¹ç•Œæ¡†ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æˆ‘æå‰è®­ç»ƒçš„YOLOv8æ£€æµ‹å™¨æ¥æ£€æµ‹èš‚èšã€‚æˆ‘ä½¿ç”¨äº†[Grounding DINO](/automatic-labeling-of-object-detection-datasets-using-groundingdino-b66c486656fe?sk=7c98df89b60ea49a6de9efd5278f645e)
    [2]æ¥æ ‡æ³¨æ•°æ®ï¼Œç„¶åä½¿ç”¨è¿™äº›æ ‡æ³¨æ•°æ®è®­ç»ƒYOLOv8æ¨¡å‹ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè®­ç»ƒYOLOæ¨¡å‹çš„ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒæˆ‘ä¹‹å‰çš„æ–‡ç« [è®­ç»ƒYOLOv5](/the-practical-guide-for-object-detection-with-yolov5-algorithm-74c04aac4843?sk=00d2a9d6dd84d6ac4de153cab3dba7c0)ï¼Œå› ä¸ºæ¦‚å¿µæ˜¯ç›¸ä¼¼çš„ã€‚å¯¹äºä½ çš„åº”ç”¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹æˆ–è‡ªå·±è®­ç»ƒä¸€ä¸ªè‡ªå®šä¹‰æ¨¡å‹ã€‚
- en: 'To get started, we need to initialize the detector with the pre-trained weights:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¼€å§‹ä½¿ç”¨ï¼Œæˆ‘ä»¬éœ€è¦ç”¨é¢„è®­ç»ƒçš„æƒé‡åˆå§‹åŒ–æ£€æµ‹å™¨ï¼š
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Later on, we will use the detector to detect ants in each frame within the video
    loop, integrating the detection with the tracking process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ£€æµ‹å™¨åœ¨è§†é¢‘å¾ªç¯ä¸­çš„æ¯ä¸€å¸§ä¸­æ£€æµ‹èš‚èšï¼Œå¹¶å°†æ£€æµ‹ä¸è¿½è¸ªè¿‡ç¨‹ç›¸ç»“åˆã€‚
- en: 2\. Tracking Objects with BoT-SORT
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. ä½¿ç”¨BoT-SORTè¿½è¸ªç‰©ä½“
- en: Since ants appear multiple times across the video frames, it is essential to
    track each ant and assign it a unique ID, to ensure that each ant is counted only
    once. Ultralytics supports both BoT-SORT [3] and ByteTrack [4] for tracking.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºèš‚èšåœ¨è§†é¢‘å¸§ä¸­å‡ºç°å¤šæ¬¡ï¼Œå› æ­¤å¿…é¡»è¿½è¸ªæ¯åªèš‚èšå¹¶åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„IDï¼Œä»¥ç¡®ä¿æ¯åªèš‚èšåªè¢«è®¡æ•°ä¸€æ¬¡ã€‚Ultralyticsæ”¯æŒBoT-SORT [3]å’ŒByteTrack
    [4]è¿›è¡Œè¿½è¸ªã€‚
- en: '**ByteTrack:** Provides a balance between accuracy and speed, with lower computational
    complexity. It may not handle occlusions and camera motion as well as BoT-SORT.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ByteTrackï¼š** æä¾›äº†ç²¾åº¦å’Œé€Ÿåº¦ä¹‹é—´çš„å¹³è¡¡ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒä½çš„è®¡ç®—å¤æ‚åº¦ã€‚å®ƒå¯èƒ½æ— æ³•åƒBoT-SORTé‚£æ ·å¤„ç†é®æŒ¡å’Œæ‘„åƒå¤´è¿åŠ¨ã€‚'
- en: '**BoT-SORT:** Offers improved tracking accuracy and robustness over ByteTrack,
    especially in challenging scenarios with occlusions and camera motion. However,
    it comes at the cost of higher computational complexity and lower frame rates.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BoT-SORTï¼š** åœ¨è¿½è¸ªå‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢ä¼˜äºByteTrackï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é®æŒ¡å’Œæ‘„åƒå¤´è¿åŠ¨çš„æŒ‘æˆ˜æ€§åœºæ™¯ä¸­ã€‚ç„¶è€Œï¼Œå®ƒçš„ä»£ä»·æ˜¯æ›´é«˜çš„è®¡ç®—å¤æ‚åº¦å’Œè¾ƒä½çš„å¸§ç‡ã€‚'
- en: The choice between these algorithms depends on the specific requirements of
    your application.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç®—æ³•çš„é€‰æ‹©å–å†³äºä½ åº”ç”¨çš„å…·ä½“éœ€æ±‚ã€‚
- en: '**How BoT-SORT Works**: BoT-SORT is a multi-object tracker, meaning it can
    track multiple objects at the same time. It combines motion and appearance information
    along with camera motion compensation. The objectsâ€™ positions are predicted using
    a Kalman filter, and the matches to existing tracks are based on both their location
    and visual features. This approach allows BoT-SORT to maintain accurate tracks
    even in the presence of occlusions or when the camera is moving.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**BoT-SORTçš„å·¥ä½œåŸç†ï¼š** BoT-SORTæ˜¯ä¸€ä¸ªå¤šç‰©ä½“è¿½è¸ªå™¨ï¼Œæ„å‘³ç€å®ƒå¯ä»¥åŒæ—¶è¿½è¸ªå¤šä¸ªç‰©ä½“ã€‚å®ƒç»“åˆäº†è¿åŠ¨å’Œå¤–è§‚ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œäº†æ‘„åƒå¤´è¿åŠ¨è¡¥å¿ã€‚ç‰©ä½“çš„ä½ç½®é€šè¿‡å¡å°”æ›¼æ»¤æ³¢å™¨è¿›è¡Œé¢„æµ‹ï¼Œç°æœ‰è½¨è¿¹çš„åŒ¹é…åŸºäºç‰©ä½“çš„ä½ç½®å’Œè§†è§‰ç‰¹å¾ã€‚è¿™ç§æ–¹æ³•ä½¿BoT-SORTå³ä½¿åœ¨æœ‰é®æŒ¡æˆ–æ‘„åƒå¤´è¿åŠ¨çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½ä¿æŒå‡†ç¡®çš„è½¨è¿¹ã€‚'
- en: A well-configured tracker can compensate for the detectorâ€™s mild faults. For
    example if the object detector temporarily fails to detect an ant, the tracker
    can maintain the antâ€™s track using motion and appearance cues.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé…ç½®è‰¯å¥½çš„è¿½è¸ªå™¨å¯ä»¥å¼¥è¡¥æ£€æµ‹å™¨çš„è½»å¾®æ•…éšœã€‚ä¾‹å¦‚ï¼Œå¦‚æœç‰©ä½“æ£€æµ‹å™¨æš‚æ—¶æœªèƒ½æ£€æµ‹åˆ°ä¸€åªèš‚èšï¼Œè¿½è¸ªå™¨å¯ä»¥é€šè¿‡è¿åŠ¨å’Œå¤–è§‚çº¿ç´¢ä¿æŒèš‚èšçš„è½¨è¿¹ã€‚
- en: 'The detector and tracker are used iteratively on each frame within the video
    loop to produce the tracks. This is how you integrate it into your video processing
    loop:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æµ‹å™¨å’Œè¿½è¸ªå™¨åœ¨è§†é¢‘å¾ªç¯ä¸­çš„æ¯ä¸€å¸§ä¸Šéƒ½è¢«è¿­ä»£ä½¿ç”¨ï¼Œä»¥ç”Ÿæˆè½¨è¿¹ã€‚è¿™æ˜¯å°†å…¶é›†æˆåˆ°ä½ çš„è§†é¢‘å¤„ç†å¾ªç¯ä¸­çš„æ–¹æ³•ï¼š
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The tracker configuration is defined in the â€˜botsort.yamlâ€™ file. You can adjust
    these parameters to best fit your needs. To change the tracker to ByteTrack, simply
    pass â€˜bytetrack.yamlâ€™ to the tracker parameter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è·Ÿè¸ªå™¨é…ç½®åœ¨â€˜botsort.yamlâ€™æ–‡ä»¶ä¸­å®šä¹‰ã€‚ä½ å¯ä»¥è°ƒæ•´è¿™äº›å‚æ•°ä»¥æœ€å¥½åœ°é€‚åº”ä½ çš„éœ€æ±‚ã€‚è¦å°†è·Ÿè¸ªå™¨æ›´æ”¹ä¸ºByteTrackï¼Œåªéœ€å°†â€˜bytetrack.yamlâ€™ä¼ é€’ç»™è·Ÿè¸ªå™¨å‚æ•°ã€‚
- en: Ensure that the Intersection Over Union (IoU) value fits your application requirements;
    the IoU threshold (used for non-maximum suppression) determines how close detections
    must be to be considered the same object. The `persist=True` argument tells the
    tracker that the current frame is part of a sequence and to expect tracks from
    the previous frame to persist into the current frame.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ä¿äº¤å¹¶æ¯”ï¼ˆIoUï¼‰å€¼ç¬¦åˆä½ çš„åº”ç”¨éœ€æ±‚ï¼›IoUé˜ˆå€¼ï¼ˆç”¨äºéæœ€å¤§æŠ‘åˆ¶ï¼‰å†³å®šäº†æ£€æµ‹ç»“æœå¿…é¡»å¤šæ¥è¿‘æ‰è¢«è§†ä¸ºåŒä¸€ç‰©ä½“ã€‚`persist=True`å‚æ•°å‘Šè¯‰è·Ÿè¸ªå™¨å½“å‰å¸§æ˜¯åºåˆ—çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶æœŸæœ›ä¸Šä¸€å¸§çš„è½¨è¿¹åœ¨å½“å‰å¸§ä¸­æŒç»­å­˜åœ¨ã€‚
- en: 3\. Counting Objects
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. è®¡æ•°ç‰©ä½“
- en: Now that we have detected and tracked the ants, the final step is to count the
    unique ants that crosses a designated line in the video. The `ObjectCounter` class
    from the Ultralytics library allows us to define a counting region, which can
    be a line or a polygon. For this tutorial, we will use a simple line as our counting
    region. This approach reduces errors by ensuring that an ant is counted only once
    when it crosses the line, even if its unique ID changes due to tracking errors.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ£€æµ‹å¹¶è·Ÿè¸ªäº†èš‚èšï¼Œæœ€åä¸€æ­¥æ˜¯ç»Ÿè®¡åœ¨è§†é¢‘ä¸­ç©¿è¿‡æŒ‡å®šçº¿çš„å”¯ä¸€èš‚èšã€‚æ¥è‡ªUltralyticsåº“çš„`ObjectCounter`ç±»å…è®¸æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè®¡æ•°åŒºåŸŸï¼Œè¯¥åŒºåŸŸå¯ä»¥æ˜¯çº¿æ¡æˆ–å¤šè¾¹å½¢ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€æ¡ç®€å•çš„çº¿ä½œä¸ºè®¡æ•°åŒºåŸŸã€‚è¿™ç§æ–¹æ³•é€šè¿‡ç¡®ä¿æ¯åªèš‚èšåœ¨ç©¿è¿‡çº¿æ—¶åªè¢«è®¡æ•°ä¸€æ¬¡ï¼Œå‡å°‘äº†é”™è¯¯ï¼Œå³ä½¿ç”±äºè·Ÿè¸ªé”™è¯¯å®ƒçš„å”¯ä¸€IDå‘ç”Ÿäº†å˜åŒ–ã€‚
- en: 'First, we initialize the `ObjectCounter` before the video loop:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨è§†é¢‘å¾ªç¯ä¹‹å‰åˆå§‹åŒ–`ObjectCounter`ï¼š
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Inside the video loop, the `ObjectCounter` will count the tracks produced by
    the tracker. The points of the line are passed to the counter at the reg_pts parameter,
    in the [(x1, y1), (x2, y2)] format. When the center point of an antâ€™s bounding
    box crosses the line for the first time, it is added to the count according to
    its trajectory direction. Objects moving in a certain direction counted as â€˜Inâ€™,
    and objects moving to the other direction counted as â€˜Outâ€™.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è§†é¢‘å¾ªç¯å†…éƒ¨ï¼Œ`ObjectCounter`å°†è®¡æ•°ç”±è·Ÿè¸ªå™¨ç”Ÿæˆçš„è½¨è¿¹ã€‚çº¿çš„ç«¯ç‚¹ä½œä¸º`reg_pts`å‚æ•°ä¼ é€’ç»™è®¡æ•°å™¨ï¼Œæ ¼å¼ä¸º[(x1, y1), (x2,
    y2)]ã€‚å½“ä¸€åªèš‚èšçš„è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ç¬¬ä¸€æ¬¡ç©¿è¿‡çº¿æ—¶ï¼Œå®ƒå°†æ ¹æ®å…¶è½¨è¿¹æ–¹å‘åŠ å…¥è®¡æ•°ã€‚å‘æŸä¸€æ–¹å‘ç§»åŠ¨çš„ç‰©ä½“è¢«è®¡ä¸ºâ€˜Inâ€™ï¼Œè€Œå‘å¦ä¸€æ–¹å‘ç§»åŠ¨çš„ç‰©ä½“åˆ™è®¡ä¸ºâ€˜Outâ€™ã€‚
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Full Code
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®Œæ•´ä»£ç 
- en: Now that we have seen the counting components, letâ€™s integrate the code with
    the video loop and save the resulting video.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†è®¡æ•°ç»„ä»¶ï¼Œè®©æˆ‘ä»¬å°†ä»£ç ä¸è§†é¢‘å¾ªç¯é›†æˆå¹¶ä¿å­˜ç»“æœè§†é¢‘ã€‚
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code above integrates object detection and tracking into a video processing
    loop to save the annotated video. Using OpenCV, we open the input video and set
    up a video writer for the output. In each frame, we perform object tracking with
    BoTSORT, count the objects, and annotate the frame. The annotated frames, including
    bounding boxes, unique IDs, trajectories, and â€˜inâ€™ and â€˜outâ€™ counts, are saved
    to the output video. The â€˜inâ€™ and â€˜outâ€™ counts can be retrieved from `counter.in_counts`
    and `counter.out_counts`, respectively, and are also printed on the output video.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ä»£ç å°†ç‰©ä½“æ£€æµ‹å’Œè·Ÿè¸ªé›†æˆåˆ°è§†é¢‘å¤„ç†å¾ªç¯ä¸­ï¼Œä»¥ä¿å­˜å¸¦æ³¨é‡Šçš„è§†é¢‘ã€‚ä½¿ç”¨OpenCVï¼Œæˆ‘ä»¬æ‰“å¼€è¾“å…¥è§†é¢‘å¹¶è®¾ç½®è¾“å‡ºè§†é¢‘çš„å†™å…¥å™¨ã€‚åœ¨æ¯ä¸€å¸§ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨BoTSORTæ‰§è¡Œç‰©ä½“è·Ÿè¸ªï¼Œç»Ÿè®¡ç‰©ä½“æ•°é‡å¹¶æ³¨é‡Šè¯¥å¸§ã€‚å¸¦æ³¨é‡Šçš„å¸§åŒ…æ‹¬è¾¹ç•Œæ¡†ã€å”¯ä¸€IDã€è½¨è¿¹ä»¥åŠâ€˜inâ€™å’Œâ€˜outâ€™è®¡æ•°ï¼Œå¹¶ä¿å­˜åˆ°è¾“å‡ºè§†é¢‘ä¸­ã€‚â€˜inâ€™å’Œâ€˜outâ€™çš„è®¡æ•°å¯ä»¥åˆ†åˆ«ä»`counter.in_counts`å’Œ`counter.out_counts`ä¸­è·å–ï¼Œå¹¶ä¸”ä¹Ÿä¼šæ‰“å°åœ¨è¾“å‡ºè§†é¢‘ä¸­ã€‚
- en: '![](../Images/b7f437e548c99be9e341810585847d79.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7f437e548c99be9e341810585847d79.png)'
- en: An annotated frame. Each ant is assigned with a bounding box and a uniqe ID.
    Ants are counted as they cross the pink line. The counts of ants moving â€˜inâ€™ and
    â€˜outâ€™ are displayed at the corner of the image.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æ³¨é‡Šçš„å¸§ã€‚æ¯åªèš‚èšéƒ½åˆ†é…äº†ä¸€ä¸ªè¾¹ç•Œæ¡†å’Œä¸€ä¸ªå”¯ä¸€IDã€‚èš‚èšåœ¨è¶Šè¿‡ç²‰çº¢è‰²çº¿æ—¶ä¼šè¢«è®¡æ•°ã€‚èš‚èšçš„â€˜inâ€™å’Œâ€˜outâ€™è®¡æ•°æ˜¾ç¤ºåœ¨å›¾åƒçš„è§’è½ã€‚
- en: Concluding Remarks
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In the annotated video, we correctly counted a total of 85 ants, with 34 entering
    and 51 exiting. For precise counts, it is crucial that the detector performs well
    and the tracker is well configured. A well-configured tracker can compensate for
    detector misses, ensuring continuity in tracking.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¸¦æ³¨é‡Šçš„è§†é¢‘ä¸­ï¼Œæˆ‘ä»¬æ­£ç¡®åœ°ç»Ÿè®¡äº†æ€»å…±85åªèš‚èšï¼Œå…¶ä¸­34åªè¿›å…¥ï¼Œ51åªé€€å‡ºã€‚ä¸ºäº†å‡†ç¡®è®¡æ•°ï¼Œæ£€æµ‹å™¨éœ€è¦è¡¨ç°è‰¯å¥½ï¼Œä¸”è·Ÿè¸ªå™¨éœ€è¦é…ç½®å¾—å½“ã€‚é…ç½®è‰¯å¥½çš„è·Ÿè¸ªå™¨èƒ½å¤Ÿå¼¥è¡¥æ£€æµ‹å™¨çš„é—æ¼ï¼Œç¡®ä¿è·Ÿè¸ªçš„è¿ç»­æ€§ã€‚
- en: 'In the annotated video we can see that the tracker handled missing detections
    very well, as evidenced by the disappearance of the bounding box around an ant
    and its return in subsequent frames with the correct ID. Additionally, tracking
    mistakes that assigned different IDs to the same object (e.g., ant #42 turning
    into #48) did not affect the counts since only the ants that cross the line are
    counted.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ³¨é‡Šè§†é¢‘ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è·Ÿè¸ªå™¨å¾ˆå¥½åœ°å¤„ç†äº†ç¼ºå¤±çš„æ£€æµ‹ï¼Œè¿™ä¸€ç‚¹å¯ä»¥é€šè¿‡ä¸€ä¸ªèš‚èšå‘¨å›´çš„è¾¹ç•Œæ¡†æ¶ˆå¤±ä»¥åŠå®ƒåœ¨åç»­å¸§ä¸­ä»¥æ­£ç¡®çš„IDè¿”å›æ¥è¯æ˜ã€‚æ­¤å¤–ï¼Œå°†ä¸åŒIDåˆ†é…ç»™åŒä¸€ç‰©ä½“çš„è·Ÿè¸ªé”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œèš‚èš#42å˜æˆ#48ï¼‰å¹¶æœªå½±å“è®¡æ•°ï¼Œå› ä¸ºåªæœ‰ç©¿è¿‡çº¿çš„èš‚èšæ‰ä¼šè¢«è®¡æ•°ã€‚
- en: In this tutorial, we explored how to count objects in videos using advanced
    object detection and tracking techniques. We utilized YOLOv8 for detecting ants
    and BoT-SORT for robust tracking, all integrated seamlessly with the Ultralytics
    library.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨å…ˆè¿›çš„ç‰©ä½“æ£€æµ‹å’Œè·Ÿè¸ªæŠ€æœ¯è®¡ç®—è§†é¢‘ä¸­çš„ç‰©ä½“ã€‚æˆ‘ä»¬ä½¿ç”¨YOLOv8è¿›è¡Œèš‚èšæ£€æµ‹ï¼Œå¹¶é‡‡ç”¨BoT-SORTè¿›è¡Œç¨³å¥çš„è·Ÿè¸ªï¼Œæ‰€æœ‰æŠ€æœ¯éƒ½æ— ç¼é›†æˆåœ¨Ultralyticsåº“ä¸­ã€‚
- en: Thank you for reading!
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: Congratulations on making it all the way here. Click ğŸ‘ to show your appreciation
    and raise the algorithm self esteem ğŸ¤“
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œä½ å·²ç»å®Œæˆäº†æ•´ä¸ªè¿‡ç¨‹ã€‚ç‚¹å‡»ğŸ‘ä»¥è¡¨ç¤ºæ„Ÿè°¢å¹¶æå‡ç®—æ³•çš„è‡ªå°Šå¿ƒğŸ¤“
- en: '**Want to learn more?**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**æƒ³äº†è§£æ›´å¤šï¼Ÿ**'
- en: '[**Explore**](https://medium.com/@lihigurarie) additional articles Iâ€™ve written'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**æ¢ç´¢**](https://medium.com/@lihigurarie)æˆ‘æ‰€å†™çš„å…¶ä»–æ–‡ç« '
- en: '[**Subscribe**](https://medium.com/@lihigurarie/subscribe)to get notified when
    I publish articles'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**è®¢é˜…**](https://medium.com/@lihigurarie/subscribe)ä»¥ä¾¿åœ¨æˆ‘å‘å¸ƒæ–‡ç« æ—¶æ”¶åˆ°é€šçŸ¥'
- en: Follow me on [**Linkedin**](https://www.linkedin.com/in/lihi-gur-arie/)
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨[**Linkedin**](https://www.linkedin.com/in/lihi-gur-arie/)ä¸Šå…³æ³¨æˆ‘
- en: References
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] [Ultralytics GitHub](https://github.com/ultralytics/ultralytics)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [Ultralytics GitHub](https://github.com/ultralytics/ultralytics)'
- en: '[2] [Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set
    Object Detection](https://arxiv.org/pdf/2303.05499)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Grounding DINO: å°†DINOä¸åŸºäºé¢†åŸŸçš„é¢„è®­ç»ƒç›¸ç»“åˆï¼Œç”¨äºå¼€æ”¾é›†ç‰©ä½“æ£€æµ‹](https://arxiv.org/pdf/2303.05499)'
- en: '[3] [BoT-SORT: Robust Associations Multi-Pedestrian Tracking](https://arxiv.org/pdf/2206.14651)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [BoT-SORT: ç¨³å¥çš„å¤šè¡Œäººè·Ÿè¸ª](https://arxiv.org/pdf/2206.14651)'
- en: '[4] [ByteTrack: Multi-Object Tracking by Associating Every Detection Box](https://arxiv.org/pdf/2110.06864)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [ByteTrack: é€šè¿‡å…³è”æ¯ä¸ªæ£€æµ‹æ¡†è¿›è¡Œå¤šç‰©ä½“è·Ÿè¸ª](https://arxiv.org/pdf/2110.06864)'
