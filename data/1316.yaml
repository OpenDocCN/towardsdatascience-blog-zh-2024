- en: 'Tune In: Decision Threshold Optimization with scikit-learn’s TunedThresholdClassifierCV'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整：使用 scikit-learn 的 TunedThresholdClassifierCV 进行决策阈值优化
- en: 原文：[https://towardsdatascience.com/tune-in-decision-threshold-optimization-with-scikit-learns-tunedthresholdclassifiercv-7de558a2cf58?source=collection_archive---------0-----------------------#2024-05-27](https://towardsdatascience.com/tune-in-decision-threshold-optimization-with-scikit-learns-tunedthresholdclassifiercv-7de558a2cf58?source=collection_archive---------0-----------------------#2024-05-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tune-in-decision-threshold-optimization-with-scikit-learns-tunedthresholdclassifiercv-7de558a2cf58?source=collection_archive---------0-----------------------#2024-05-27](https://towardsdatascience.com/tune-in-decision-threshold-optimization-with-scikit-learns-tunedthresholdclassifiercv-7de558a2cf58?source=collection_archive---------0-----------------------#2024-05-27)
- en: Use cases and code to explore the new class that helps tune decision thresholds
    in scikit-learn
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用案例和代码来探索新类，帮助调整 scikit-learn 中的决策阈值
- en: '[](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)[![Kevin
    Arvai](../Images/8ffd1f1983e911183009c9040f3dbf87.png)](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)
    [Kevin Arvai](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)[![Kevin
    Arvai](../Images/8ffd1f1983e911183009c9040f3dbf87.png)](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)
    [Kevin Arvai](https://medium.com/@arvkevi?source=post_page---byline--7de558a2cf58--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)
    ·10 min read·May 27, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7de558a2cf58--------------------------------)
    ·阅读时间 10 分钟·2024年5月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The 1.5 release of scikit-learn includes a new class, [TunedThresholdClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html),
    making optimizing decision thresholds from scikit-learn classifiers easier. A
    decision threshold is a cut-off point that converts predicted probabilities output
    by a machine learning model into discrete classes. The default decision threshold
    of the `.predict()` method from scikit-learn classifiers in a binary classification
    setting is 0.5\. Although this is a sensible default, it is rarely the best choice
    for classification tasks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 1.5 版本引入了一个新类，[TunedThresholdClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TunedThresholdClassifierCV.html)，使得优化来自
    scikit-learn 分类器的决策阈值变得更加容易。决策阈值是一个临界点，它将机器学习模型输出的预测概率转换为离散类别。对于二分类任务，scikit-learn
    分类器的 `.predict()` 方法的默认决策阈值是 0.5。虽然这是一个合理的默认值，但它很少是分类任务的最佳选择。
- en: This post introduces the TunedThresholdClassifierCV class and demonstrates how
    it can optimize decision thresholds for various binary classification tasks. This
    new class will help bridge the gap between data scientists who build models and
    business stakeholders who make decisions based on the model’s output. By fine-tuning
    the decision thresholds, data scientists can enhance model performance and better
    align with business objectives.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了 TunedThresholdClassifierCV 类，并展示了它如何优化各种二分类任务的决策阈值。这个新类将帮助填补构建模型的数据科学家和根据模型输出做出决策的业务利益相关者之间的鸿沟。通过微调决策阈值，数据科学家可以提高模型性能，并更好地与业务目标对齐。
- en: 'This post will cover the following situations where tuning decision thresholds
    is beneficial:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将涵盖以下几种调整决策阈值有益的情况：
- en: '**Maximizing a metric**: Use this when choosing a threshold that maximizes
    a scoring metric, like the F1 score.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最大化指标**：当选择一个阈值以最大化评分指标时，使用此方法，例如 F1 分数。'
- en: '**Cost-sensitive learning**: Adjust the threshold when the cost of misclassifying
    a false positive is not equal to the cost of misclassifying a false negative,
    and you have an estimate of the costs.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本敏感学习**：当误分类的假阳性成本与误分类的假阴性成本不相等，并且你有成本估计时，调整阈值。'
- en: '**Tuning under constraints**: Optimize the operating point on the ROC or precision-recall
    curve to meet specific performance constraints.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在约束下调优**：在ROC或精确度-召回曲线中优化操作点，以满足特定的性能约束。'
- en: The code used in this post and links to datasets are available on [GitHub](https://github.com/arvkevi/tunein-blog).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的代码及数据集链接可以在[GitHub](https://github.com/arvkevi/tunein-blog)上找到。
- en: Let’s get started! First, import the necessary libraries, read the data, and
    split training and test data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！首先，导入必要的库，读取数据，并划分训练集和测试集。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Maximizing a metric
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最大化一个指标
- en: Before starting the model-building process in any machine learning project,
    it is crucial to work with stakeholders to determine which metric(s) to optimize.
    Making this decision early ensures that the project aligns with its intended goals.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何机器学习项目中开始构建模型之前，与利益相关者一起确定需要优化的指标非常重要。提前做出这个决策能确保项目与其预期目标一致。
- en: Using an accuracy metric in fraud detection use cases to evaluate model performance
    is not ideal because the data is often imbalanced, with most transactions being
    non-fraudulent. The F1 score is the harmonic mean of precision and recall and
    is a better metric for imbalanced datasets like fraud detection. Let’s use the
    `TunedThresholdClassifierCV` class to optimize the decision threshold of a logistic
    regression model to maximize the F1 score.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在欺诈检测应用中使用准确率作为评估模型性能的指标并不理想，因为数据通常是不平衡的，大多数交易是非欺诈性的。F1得分是精确度和召回率的调和平均值，对于像欺诈检测这样的不平衡数据集来说，是一个更好的指标。让我们使用`TunedThresholdClassifierCV`类来优化逻辑回归模型的决策阈值，以最大化F1得分。
- en: We’ll use the [Kaggle Credit Card Fraud Detection dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
    to introduce the first situation where we need to tune a decision threshold. First,
    split the data into train and test sets, then create a scikit-learn pipeline to
    scale the data and train a logistic regression model. Fit the pipeline on the
    training data so we can compare the original model performance with the tuned
    model performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[Kaggle信用卡欺诈检测数据集](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)来介绍我们需要调优决策阈值的第一个场景。首先，将数据划分为训练集和测试集，然后创建一个scikit-learn管道来缩放数据并训练一个逻辑回归模型。将管道拟合在训练数据上，以便我们可以将原始模型的表现与调优后的模型表现进行比较。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: No tuning has happened yet, but it’s coming in the next code block. The arguments
    for `TunedThresholdClassifierCV` are similar to other `CV` classes in scikit-learn,
    such as [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).
    At a minimum, the user only needs to pass the original estimator and `TunedThresholdClassifierCV`
    will store the decision threshold that maximizes balanced accuracy (default) using
    5-fold stratified K-fold cross-validation (default). It also uses this threshold
    when calling `.predict()`. However, any scikit-learn metric (or callable) can
    be used as the `scoring` metric. Additionally, the user can pass the familiar
    `cv` argument to customize the cross-validation strategy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 目前尚未进行调优，但将在下一个代码块中进行。`TunedThresholdClassifierCV`的参数与scikit-learn中的其他`CV`类类似，例如[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)。至少，用户只需传递原始估计器，`TunedThresholdClassifierCV`将使用5折分层K折交叉验证（默认）存储最大化平衡准确率的决策阈值（默认）。在调用`.predict()`时，它也会使用此阈值。然而，任何scikit-learn度量（或可调用对象）都可以作为`scoring`度量。此外，用户可以传递熟悉的`cv`参数来自定义交叉验证策略。
- en: Create the `TunedThresholdClassifierCV` instance and fit the model on the training
    data. Pass the original model and set the scoring to be "f1". We'll also want
    to set `store_cv_results=True` to access the thresholds evaluated during cross-validation
    for visualization.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 创建`TunedThresholdClassifierCV`实例并在训练数据上拟合模型。传递原始模型，并将评分设置为“f1”。我们还需要设置`store_cv_results=True`，以便在交叉验证期间访问评估的阈值，以便可视化。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now that we’ve found the threshold that maximizes the F1 score check `tuned_fraud_model.best_score_`
    to find out what the best average F1 score was across folds in cross-validation.
    We can also see which threshold generated those results using `tuned_fraud_model.best_threshold_`.
    You can visualize the metric scores across the decision thresholds during cross-validation
    using the `objective_scores_` and `decision_thresholds_` attributes:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经找到了最大化F1得分的阈值，可以检查`tuned_fraud_model.best_score_`以了解交叉验证中折叠的最佳平均F1得分。我们还可以使用`tuned_fraud_model.best_threshold_`查看生成这些结果的阈值。您可以使用`objective_scores_`和`decision_thresholds_`属性可视化交叉验证过程中不同决策阈值下的度量得分：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/967d617803ff0bc789b203705c3f0314.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/967d617803ff0bc789b203705c3f0314.png)'
- en: Image created by the author.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建。
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We’ve used the same underlying logistic regression model to evaluate two different
    decision thresholds. The underlying models are the same, evidenced by the coefficient
    equality in the assert statement above. Optimization in `TunedThresholdClassifierCV`
    is achieved using post-processing techniques, which are applied directly to the
    predicted probabilities output by the model. However, it's important to note that
    `TunedThresholdClassifierCV` uses cross-validation by default to find the decision
    threshold to avoid overfitting to the training data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了相同的基础逻辑回归模型来评估两个不同的决策阈值。基础模型是相同的，上面的断言语句证明了系数的相等性。`TunedThresholdClassifierCV`中的优化是通过后处理技术实现的，这些技术直接应用于模型输出的预测概率。然而，值得注意的是，`TunedThresholdClassifierCV`默认使用交叉验证来确定决策阈值，以避免过拟合训练数据。
- en: Cost-sensitive learning
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本敏感学习
- en: Cost-sensitive learning is a type of machine learning that assigns a cost to
    each type of misclassification. This translates model performance into units that
    stakeholders understand, like dollars saved.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 成本敏感学习是一种机器学习方法，它为每种类型的错误分类分配成本。这将模型性能转化为利益相关者能够理解的单位，比如节省的美元。
- en: We will use the [TELCO customer churn dataset](https://accelerator.ca.analytics.ibm.com/bi/?perspective=authoring&pathRef=.public_folders%2FIBM%2BAccelerator%2BCatalog%2FContent%2FDAT00148&id=i9710CF25EF75468D95FFFC7D57D45204&objRef=i9710CF25EF75468D95FFFC7D57D45204&action=run&format=HTML&cmPropStr=%7B%22id%22%3A%22i9710CF25EF75468D95FFFC7D57D45204%22%2C%22type%22%3A%22reportView%22%2C%22defaultName%22%3A%22DAT00148%22%2C%22permissions%22%3A%5B%22execute%22%2C%22read%22%2C%22traverse%22%5D%7D),
    a binary classification dataset, to demonstrate the value of cost-sensitive learning.
    The goal is to predict whether a customer will churn or not, given features about
    the customer’s demographics, contract details, and other technical information
    about the customer’s account. The motivation to use this dataset (and some of
    the code) is from [Dan Becker’s course on decision threshold optimization](https://www.wandb.courses/courses/decision-optimization).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[TELCO客户流失数据集](https://accelerator.ca.analytics.ibm.com/bi/?perspective=authoring&pathRef=.public_folders%2FIBM%2BAccelerator%2BCatalog%2FContent%2FDAT00148&id=i9710CF25EF75468D95FFFC7D57D45204&objRef=i9710CF25EF75468D95FFFC7D57D45204&action=run&format=HTML&cmPropStr=%7B%22id%22%3A%22i9710CF25EF75468D95FFFC7D57D45204%22%2C%22type%22%3A%22reportView%22%2C%22defaultName%22%3A%22DAT00148%22%2C%22permissions%22%3A%5B%22execute%22%2C%22read%22%2C%22traverse%22%5D%7D)，这是一个二分类数据集，来展示成本敏感学习的价值。目标是根据客户的基本信息、合同详情及账户的其他技术信息预测客户是否会流失。使用这个数据集（以及部分代码）的动机来源于[Dan
    Becker的决策阈值优化课程](https://www.wandb.courses/courses/decision-optimization)。
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Set up a basic pipeline for processing the data and generating predicted probabilities
    with a random forest model. This will serve as a baseline to compare to the `TunedThresholdClassifierCV`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个基本的处理管道，使用随机森林模型生成预测概率。这将作为与`TunedThresholdClassifierCV`进行比较的基准。
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The choice of preprocessing and model type is not important for this tutorial.
    The company wants to offer discounts to customers who are predicted to churn.
    During collaboration with stakeholders, you learn that giving a discount to a
    customer who will not churn (a false positive) would cost $80\. You also learn
    that it’s worth $200 to offer a discount to a customer who would have churned.
    You can represent this relationship in a cost matrix:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程来说，预处理和模型类型的选择并不重要。公司希望向预测会流失的客户提供折扣。在与利益相关者的合作中，你了解到，给一个不会流失的客户（假阳性）提供折扣会花费80美元。你还了解到，向一个本来会流失的客户提供折扣价值200美元。你可以通过一个成本矩阵来表示这种关系：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We also wrapped the cost function in a scikit-learn custom scorer. This scorer
    will be used as the `scoring` argument in the TunedThresholdClassifierCV and to
    evaluate profit on the test set.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将成本函数包装在一个scikit-learn自定义评分器中。这个评分器将在TunedThresholdClassifierCV中作为`scoring`参数使用，并用于在测试集上评估利润。
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The profit is higher in the tuned model compared to the original. Again, we
    can plot the objective metric against the decision thresholds to visualize the
    decision threshold selection on training data during cross-validation:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与原始模型相比，调整后的模型的利润更高。同样，我们可以将目标指标与决策阈值进行绘图，以可视化在交叉验证过程中对训练数据的决策阈值选择：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/5d73ef40feb776f93b8e029027e09427.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d73ef40feb776f93b8e029027e09427.png)'
- en: Image created by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建。
- en: In reality, assigning a static cost to all instances that are misclassified
    in the same way is not realistic from a business perspective. There are more advanced
    methods to tune the threshold by assigning a weight to each instance in the dataset.
    This is covered in [scikit-learn’s cost-sensitive learning example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cost_sensitive_learning.html#sphx-glr-auto-examples-model-selection-plot-cost-sensitive-learning-py).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，从业务角度来看，给所有误分类实例分配一个固定的成本是不现实的。通过为数据集中的每个实例分配权重来调整阈值是更先进的方法。这一点在 [scikit-learn
    的成本敏感学习示例](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cost_sensitive_learning.html#sphx-glr-auto-examples-model-selection-plot-cost-sensitive-learning-py)中有介绍。
- en: Tuning under constraints
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 约束下调优
- en: This method is not covered in the scikit-learn documentation currently, but
    is a common business case for binary classification use cases. The tuning under
    constraint method finds a decision threshold by identifying a point on either
    the ROC or precision-recall curves. The point on the curve is the maximum value
    of one axis while constraining the other axis. For this walkthrough, we’ll be
    using the Pima Indians diabetes dataset. This is a binary classification task
    to predict if an individual has diabetes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 目前这个方法在 scikit-learn 文档中没有涉及，但它是二分类应用场景中常见的业务案例。约束下调优方法通过在 ROC 曲线或精确率-召回率曲线中找到一个点来确定决策阈值。曲线上的这个点是一个轴的最大值，同时约束另一个轴。在本次教程中，我们将使用
    Pima 印第安人糖尿病数据集。这是一个二分类任务，用于预测一个人是否患有糖尿病。
- en: Imagine that your model will be used as a screening test for an average-risk
    population applied to millions of people. There are an estimated 38 million people
    with diabetes in the US. This is roughly 11.6% of the population, so the model’s
    specificity should be high so it doesn’t misdiagnose millions of people with diabetes
    and refer them to unnecessary confirmatory testing. Suppose your imaginary CEO
    has communicated that they will not tolerate more than a 2% false positive rate.
    Let’s build a model that achieves this using `TunedThresholdClassifierCV`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您的模型将用于对一个平均风险群体进行筛查，且适用于数百万人。在美国，大约有 3800 万人患有糖尿病，这大约占总人口的 11.6%。因此，模型的特异性应该很高，以避免误诊数百万人患有糖尿病，并将其转诊进行不必要的确认性测试。假设您的虚拟
    CEO 已经表明，他们不会容忍超过 2% 的假阳性率。让我们构建一个使用 `TunedThresholdClassifierCV` 达到这一目标的模型。
- en: For this part of the tutorial, we’ll define a constraint function that will
    be used to find the maximum true positive rate at a 2% false positive rate.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分教程中，我们将定义一个约束函数，用于在 2% 假阳性率下找到最大真正阳性率。
- en: '[PRE12]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Build two models, one logistic regression to serve as a baseline model and the
    other, `TunedThresholdClassifierCV` which will wrap the baseline logistic regression
    model to achieve the goal outlined by the CEO. In the tuned model, set `scoring=max_tpr_at_tnr_scorer`.
    Again, the choice of model and preprocessing is not important for this tutorial.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 构建两个模型，一个是逻辑回归模型作为基线模型，另一个是 `TunedThresholdClassifierCV`，它将包装基线逻辑回归模型，以实现 CEO
    所设定的目标。在调优模型中，设置 `scoring=max_tpr_at_tnr_scorer`。同样，本教程中的模型选择和预处理步骤并不重要。
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Compare the difference between the default decision threshold from scikit-learn
    estimators, 0.5, and one found using the tuning under constraint approach on the
    ROC curve.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 scikit-learn 估计器默认决策阈值 0.5 和使用约束下调优方法在 ROC 曲线中找到的阈值之间的差异。
- en: '[PRE14]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/a6f0205e940bce68a563041a655b45e6.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6f0205e940bce68a563041a655b45e6.png)'
- en: Image created by the author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建。
- en: The tuned under constraint method found a threshold of 0.80, which resulted
    in an average sensitivity of 19.2% during cross-validation of the training data.
    Compare the sensitivity and specificity to see how the threshold holds up in the
    test set. Did the model meet the CEO’s specificity requirement in the test set?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 约束下调优方法找到了一个 0.80 的阈值，这导致在训练数据交叉验证过程中平均灵敏度为 19.2%。比较灵敏度和特异性，看看这个阈值在测试集中的表现如何。该模型在测试集中达到了
    CEO 的特异性要求吗？
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: The new `TunedThresholdClassifierCV` class is a powerful tool that can help
    you become a better data scientist by sharing with business leaders how you arrived
    at a decision threshold. You learned how to use the new scikit-learn `TunedThresholdClassifierCV`
    class to maximize a metric, perform cost-sensitive learning, and tune a metric
    under constraint. This tutorial was not intended to be comprehensive or advanced.
    I wanted to introduce the new feature and highlight its power and flexibility
    in solving binary classification problems. Please check out the scikit-learn documentation,
    user guide, and examples for thorough usage examples.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`TunedThresholdClassifierCV`类是一个强大的工具，可以帮助你通过向商业领导者展示你如何得出决策阈值，成为更好的数据科学家。你学习了如何使用新的scikit-learn
    `TunedThresholdClassifierCV`类来最大化一个指标，执行成本敏感学习，并在约束条件下调整指标。这个教程并不旨在全面或深入。我希望介绍这一新特性，并突出它在解决二分类问题时的强大功能和灵活性。请查阅scikit-learn文档、用户指南和示例，以获取详细的使用示例。
- en: A huge shoutout to [Guillaume Lemaitre](https://github.com/glemaitre) for his
    work on this feature.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢[Guillaume Lemaitre](https://github.com/glemaitre)为此功能所做的工作。
- en: Thanks for reading. Happy tuning.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，祝调优愉快。
- en: 'Data Licenses:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据许可证：
- en: 'Credit card fraud: DbCL'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 信用卡欺诈：DbCL
- en: 'Pima Indians diabetes: CC0'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 皮马印第安人糖尿病数据集：CC0
- en: 'TELCO churn: [commercial use OK](https://developer.ibm.com/terms/download-of-content-agreement/)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 电信客户流失：[商业用途可用](https://developer.ibm.com/terms/download-of-content-agreement/)
