- en: 'Vision Mamba: Like a Vision Transformer but Better'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vision Mambaï¼šåƒVision Transformerï¼Œä½†æ›´å¼ºå¤§
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16](https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16](https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16)
- en: '[ğŸ Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[ğŸ èµ°å‘é©¬å§†å·´çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼šå›¾åƒã€è§†é¢‘ä¸æ—¶é—´åºåˆ—](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
- en: Part 4 â€” Towards Mamba State Space Models for Images, Videos and Time Series
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬4éƒ¨åˆ† â€” èµ°å‘é©¬å§†å·´çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼šå›¾åƒã€è§†é¢‘ä¸æ—¶é—´åºåˆ—
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    Â·20 min readÂ·Sep 16, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    Â·20åˆ†é’Ÿé˜…è¯»Â·2024å¹´9æœˆ16æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7c83682cee1e25a2932aff0e19416df2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c83682cee1e25a2932aff0e19416df2.png)'
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Sascha Kirch](https://medium.com/@SaschaKirch).
- en: This is part 4 of my new multi-part series [ğŸ Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘æ–°ç³»åˆ—æ–‡ç« [ğŸ èµ°å‘é©¬å§†å·´çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼šå›¾åƒã€è§†é¢‘ä¸æ—¶é—´åºåˆ—](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb)çš„ç¬¬4éƒ¨åˆ†ã€‚
- en: The field of computer vision has seen incredible advances in recent years. One
    of the key enablers for this development has been undoubtedly the introduction
    of the Transformer. While the Transformer has revolutionized natural language
    processing, it took us some years to transfer its capabilities to the vision domain.
    Probably the most prominent paper was the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929),
    a model that is still used as the backbone in many of the modern architectures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‘å¹´æ¥ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå–å¾—äº†ä»¤äººéš¾ä»¥ç½®ä¿¡çš„è¿›å±•ã€‚æ¨åŠ¨è¿™ä¸€å‘å±•çš„å…³é”®å› ç´ ä¹‹ä¸€æ— ç–‘æ˜¯Transformerçš„å¼•å…¥ã€‚è™½ç„¶Transformerå½»åº•é©æ–°äº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œä½†æˆ‘ä»¬èŠ±äº†å‡ å¹´æ—¶é—´æ‰å°†å…¶èƒ½åŠ›è½¬ç§»åˆ°è§†è§‰é¢†åŸŸã€‚å¯èƒ½æœ€å…·ä»£è¡¨æ€§çš„è®ºæ–‡æ˜¯[Vision
    Transformer (ViT)](https://arxiv.org/abs/2010.11929)ï¼Œè¿™æ˜¯ä¸€ç§æ¨¡å‹ï¼Œè‡³ä»Šä»è¢«è®¸å¤šç°ä»£æ¶æ„ä½œä¸ºåŸºç¡€æ¨¡å‹ä½¿ç”¨ã€‚
- en: 'Itâ€™s again the Transformerâ€™s *O(LÂ²)* complexity that limits its application
    as the imageâ€™s resolution grows. Being equipped with the [Mamba selective state
    space model](https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb),
    we are now able to let history repeat itself and transfer the success of SSMs
    from sequence data to non-sequence data: Images.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£æ˜¯Transformerçš„*O(LÂ²)*å¤æ‚åº¦é™åˆ¶äº†å…¶åœ¨å›¾åƒåˆ†è¾¨ç‡å¢é«˜æ—¶çš„åº”ç”¨ã€‚å€ŸåŠ©äº[é©¬å§†å·´é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹](https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb)ï¼Œæˆ‘ä»¬ç°åœ¨èƒ½å¤Ÿè®©å†å²é‡æ¼”ï¼Œå¹¶å°†SSMï¼ˆçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼‰åœ¨åºåˆ—æ•°æ®ä¸­çš„æˆåŠŸè½¬ç§»åˆ°éåºåˆ—æ•°æ®ä¸­ï¼šå›¾åƒã€‚
- en: 'â— Spoiler Alert: VisionMamba is 2.8x faster than [DeiT](https://arxiv.org/abs/2012.12877)
    and saves 86.8% GPU memory on high-resolution images (1248x1248) and in this article,
    youâ€™ll see howâ€¦'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: â— å‰§é€æé†’ï¼šVisionMambaæ¯”[DeiT](https://arxiv.org/abs/2012.12877)å¿«2.8å€ï¼Œå¹¶ä¸”åœ¨é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆ1248x1248ï¼‰ä¸ŠèŠ‚çœäº†86.8%çš„GPUå†…å­˜ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œä½ å°†çœ‹åˆ°å¦‚ä½•åšåˆ°â€¦
