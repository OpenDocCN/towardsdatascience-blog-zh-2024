- en: 'Vision Mamba: Like a Vision Transformer but Better'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vision Mamba：像Vision Transformer，但更强大
- en: 原文：[https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16](https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16](https://towardsdatascience.com/vision-mamba-like-a-vision-transformer-but-better-3b2660c35848?source=collection_archive---------5-----------------------#2024-09-16)
- en: '[🐍 Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[🐍 走向马姆巴状态空间模型：图像、视频与时间序列](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
- en: Part 4 — Towards Mamba State Space Models for Images, Videos and Time Series
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4部分 — 走向马姆巴状态空间模型：图像、视频与时间序列
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--3b2660c35848--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    ·20 min read·Sep 16, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3b2660c35848--------------------------------)
    ·20分钟阅读·2024年9月16日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7c83682cee1e25a2932aff0e19416df2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c83682cee1e25a2932aff0e19416df2.png)'
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Sascha Kirch](https://medium.com/@SaschaKirch).
- en: This is part 4 of my new multi-part series [🐍 Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是我新系列文章[🐍 走向马姆巴状态空间模型：图像、视频与时间序列](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb)的第4部分。
- en: The field of computer vision has seen incredible advances in recent years. One
    of the key enablers for this development has been undoubtedly the introduction
    of the Transformer. While the Transformer has revolutionized natural language
    processing, it took us some years to transfer its capabilities to the vision domain.
    Probably the most prominent paper was the [Vision Transformer (ViT)](https://arxiv.org/abs/2010.11929),
    a model that is still used as the backbone in many of the modern architectures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，计算机视觉领域取得了令人难以置信的进展。推动这一发展的关键因素之一无疑是Transformer的引入。虽然Transformer彻底革新了自然语言处理，但我们花了几年时间才将其能力转移到视觉领域。可能最具代表性的论文是[Vision
    Transformer (ViT)](https://arxiv.org/abs/2010.11929)，这是一种模型，至今仍被许多现代架构作为基础模型使用。
- en: 'It’s again the Transformer’s *O(L²)* complexity that limits its application
    as the image’s resolution grows. Being equipped with the [Mamba selective state
    space model](https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb),
    we are now able to let history repeat itself and transfer the success of SSMs
    from sequence data to non-sequence data: Images.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正是Transformer的*O(L²)*复杂度限制了其在图像分辨率增高时的应用。借助于[马姆巴选择性状态空间模型](https://medium.com/towards-data-science/here-comes-mamba-the-selective-state-space-model-435e5d17a451?sk=602b692eda48c19b2b2f4b0a7198bbcb)，我们现在能够让历史重演，并将SSM（状态空间模型）在序列数据中的成功转移到非序列数据中：图像。
- en: '❗ Spoiler Alert: VisionMamba is 2.8x faster than [DeiT](https://arxiv.org/abs/2012.12877)
    and saves 86.8% GPU memory on high-resolution images (1248x1248) and in this article,
    you’ll see how…'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ❗ 剧透提醒：VisionMamba比[DeiT](https://arxiv.org/abs/2012.12877)快2.8倍，并且在高分辨率图像（1248x1248）上节省了86.8%的GPU内存，在这篇文章中，你将看到如何做到…
