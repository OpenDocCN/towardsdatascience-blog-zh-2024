- en: The Math Behind Recurrent Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络背后的数学原理
- en: 原文：[https://towardsdatascience.com/the-math-behind-recurrent-neural-networks-2de4e0098ab8?source=collection_archive---------1-----------------------#2024-04-27](https://towardsdatascience.com/the-math-behind-recurrent-neural-networks-2de4e0098ab8?source=collection_archive---------1-----------------------#2024-04-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-math-behind-recurrent-neural-networks-2de4e0098ab8?source=collection_archive---------1-----------------------#2024-04-27](https://towardsdatascience.com/the-math-behind-recurrent-neural-networks-2de4e0098ab8?source=collection_archive---------1-----------------------#2024-04-27)
- en: Dive into RNNs, the backbone of time series, understand their mathematics, implement
    them from scratch, and explore their applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入了解RNN，这一时间序列的核心，理解它们的数学原理，从零开始实现它们，并探索它们的应用
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--2de4e0098ab8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)
    ·22 min read·Apr 27, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2de4e0098ab8--------------------------------)
    ·22分钟阅读·2024年4月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/86a8ac61de3ca0810a2b5a964dd666a1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86a8ac61de3ca0810a2b5a964dd666a1.png)'
- en: Image generated by DALL-E
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由DALL-E生成
- en: RNNs stand out from other types of neural networks because they handle sequences
    of inputs. This capability allows them to take on tasks that depend on the order
    of the data, such as forecasting stock market trends, monitoring patient health
    over time, or predicting the next word in a sentence. This makes them extremely
    valuable for many cutting-edge AI applications. In this article, we will dive
    into their architecture and math and create them from scratch in Python.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNN）与其他类型的神经网络不同，它们能够处理输入序列。这一能力使得RNN能够执行依赖数据顺序的任务，如预测股票市场趋势、长期监控病人健康状况，或预测句子中的下一个单词。这使得RNN在许多前沿人工智能应用中极为重要。本文将深入探讨其架构与数学原理，并在Python中从零开始实现它们。
- en: '**Index**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录**'
- en: '[**1: Introduction**](#357e)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[**1: 介绍**](#357e)'
- en: '[**2: RNN’s Architecture**](#d214)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[**2: 循环神经网络的架构**](#d214)'
- en: '∘ [2.1: The Structure of RNNs](#a6c0)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [2.1: 循环神经网络的结构](#a6c0)'
- en: '∘ [2.2: Key Operations in RNNs](#2ec6)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [2.2: 循环神经网络中的关键操作](#2ec6)'
- en: '[**3: Challenges in Training RNNs**](#43fa)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[**3: 循环神经网络训练中的挑战**](#43fa)'
- en: '∘ [3.1: Vanishing Gradients](#3d31)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [3.1: 梯度消失](#3d31)'
- en: '∘ [3.2: Exploding Gradients](#5f2b)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [3.2: 梯度爆炸](#5f2b)'
- en: '∘ [3.3: Gradient Clipping](#4563)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [3.3: 梯度裁剪](#4563)'
- en: '∘ [3.4: Adjusted Initialization Strategies](#fffa)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [3.4: 调整后的初始化策略](#fffa)'
- en: '[**4: Building RNN from Scratch**](#8517)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[**4: 从零开始构建循环神经网络**](#8517)'
- en: '∘ [4.1: Defining the RNN Class](#2ed9)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [4.1: 定义RNN类](#2ed9)'
- en: '∘ [4.2: Early Stopping Mechanism](#e81e)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [4.2: 提前停止机制](#e81e)'
- en: '∘ [4.3: RNN Trainer Class:](#01f1)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [4.3: 循环神经网络训练器类:](#01f1)'
- en: '∘ [4.4: Data Loading and](#17c5)…'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '∘ [4.4: 数据加载与](#17c5)…'
