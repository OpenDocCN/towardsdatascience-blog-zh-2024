- en: Graph-Based Prompting and Reasoning with Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图的提示与推理在语言模型中的应用
- en: 原文：[https://towardsdatascience.com/graph-based-prompting-and-reasoning-with-language-models-d6acbcd6b3d8?source=collection_archive---------0-----------------------#2024-01-03](https://towardsdatascience.com/graph-based-prompting-and-reasoning-with-language-models-d6acbcd6b3d8?source=collection_archive---------0-----------------------#2024-01-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/graph-based-prompting-and-reasoning-with-language-models-d6acbcd6b3d8?source=collection_archive---------0-----------------------#2024-01-03](https://towardsdatascience.com/graph-based-prompting-and-reasoning-with-language-models-d6acbcd6b3d8?source=collection_archive---------0-----------------------#2024-01-03)
- en: Understanding graph of thoughts prompting and several variants…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解图形思维提示及其几种变体……
- en: '[](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)
    ·22 min read·Jan 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d6acbcd6b3d8--------------------------------)
    ·阅读时长22分钟·2024年1月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1b6c41b4f07a4b381d9da086ab84a80c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b6c41b4f07a4b381d9da086ab84a80c.png)'
- en: (Photo by [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/low-angle-photography-of-metal-structure-ZiQkhI7417A?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: (图片由[Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)拍摄，来源于[Unsplash](https://unsplash.com/photos/low-angle-photography-of-metal-structure-ZiQkhI7417A?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
- en: Advanced prompting techniques like chain of thought [8] and tree of thought
    [9] prompting have drastically improved the ability of large language models (LLMs)
    to solve complex, reasoning-based tasks. At a high level, forcing the LLM to construct
    a step-by-step response to a problem drastically improves its problem-solving
    capabilities. However, all of such techniques assume that the reasoning process
    should follow a linear patterns that progresses from one thought to the next.
    Notably, the reasoning process followed by humans tends to be quite different,
    following multiple different chains of thought and even combining insights from
    different thoughts to arrive at a final solution. Within this overview, we will
    be studying several prompting techniques that model the reasoning process as a
    graph structure — rather than a chain or tree — that better captures the various
    types of non-linear patterns that may occur when reasoning over a problem.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 高级提示技术，如思维链[8]和思维树[9]，显著提高了大型语言模型（LLM）在解决复杂推理任务中的能力。大体而言，迫使LLM以逐步响应的方式来处理问题，极大地提升了其问题解决能力。然而，这些技术假设推理过程应该遵循一种从一个思维到下一个思维的线性模式。值得注意的是，人类的推理过程往往与此不同，通常遵循多条不同的思维链，甚至将来自不同思维的见解结合起来，从而得出最终解决方案。在本概述中，我们将研究几种将推理过程建模为图结构的提示技术——而不是链式或树形结构——这种方式更好地捕捉到推理过程中的各种非线性模式。
- en: “Human thinking is often characterized by its ability to make sudden leaps and
    connections between seemingly unrelated ideas, which can lead to novel insights
    and solutions. This non-linear, jumping thought process is a hallmark of human
    creativity, reasoning, and problem-solving…
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “人类思维的特点之一是其能够在看似无关的想法之间进行突然的跳跃和连接，这往往能引发新的见解和解决方案。这种非线性的、跳跃性的思维过程是人类创造力、推理和问题解决能力的标志……
