- en: PyTorch Optimizers Aren’t Fast Enough. Try These Instead
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 的优化器不够快。试试这些优化器吧
- en: 原文：[https://towardsdatascience.com/pytorch-optimizers-arent-fast-enough-try-these-instead-61a1350e3eac?source=collection_archive---------1-----------------------#2024-10-14](https://towardsdatascience.com/pytorch-optimizers-arent-fast-enough-try-these-instead-61a1350e3eac?source=collection_archive---------1-----------------------#2024-10-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pytorch-optimizers-arent-fast-enough-try-these-instead-61a1350e3eac?source=collection_archive---------1-----------------------#2024-10-14](https://towardsdatascience.com/pytorch-optimizers-arent-fast-enough-try-these-instead-61a1350e3eac?source=collection_archive---------1-----------------------#2024-10-14)
- en: These 4 advanced optimizers will open your mind.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这四种先进的优化器将开启你的思维。
- en: '[](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)[![Benjamin
    Bodner](../Images/f66d5ba5b80455f8a0cd198499e8f4c2.png)](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)
    [Benjamin Bodner](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)[![Benjamin
    Bodner](../Images/f66d5ba5b80455f8a0cd198499e8f4c2.png)](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)
    [Benjamin Bodner](https://medium.com/@benjybo7?source=post_page---byline--61a1350e3eac--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)
    ·10 min read·Oct 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--61a1350e3eac--------------------------------)
    ·阅读时间10分钟·2024年10月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/bdf3ef0a7f55b35562b754c50d2e50b9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdf3ef0a7f55b35562b754c50d2e50b9.png)'
- en: 'Source: image by author'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者提供的图片
- en: If you’ve been working with deep learning for a while, you’re probably well-acquainted
    with the usual optimizers in PyTorch — `[SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)`,
    `[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)`, maybe
    even `[AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)`.
    *These are some of the go-to tools in every ML engineer’s toolkit.*
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经从事深度学习一段时间了，你可能对 PyTorch 中常见的优化器非常熟悉——`[SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)`、`[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)`，甚至可能还有`[AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)`。*这些是每个机器学习工程师工具箱中的常用工具。*
- en: But what if I told you that there are pleanty of powerful optimization algorithms
    out there, which aren’t part of the standard PyTorch package?
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但是，如果我告诉你，其实有很多强大的优化算法，并不包含在 PyTorch 的标准包中，你会怎么想？
- en: Not just that, the algorithms can sometimes **outperform Adam** for certain
    tasks and help you crack tough optimization problems you’ve been struggling with!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，这些算法有时能够**超越 Adam**，在某些任务中表现得更好，帮助你解决一直困扰你的复杂优化问题！
- en: If that got your attention, great!
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果这引起了你的兴趣，那就太好了！
- en: In this article, we’ll take a look at some ***advanced optimization techniques***
    that you may or may not have heard of and see **how we can apply them to deep
    learning.**
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将介绍一些***先进的优化技术***，你可能听说过也可能没有，并看看**我们如何将这些技术应用到深度学习中**。
- en: Specifically, We’ll be talking about Sequential Least Squares Programming`[SLSQP](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-slsqp.html)`,
    Particle Swarm Optimization `[PSO](https://pyswarms.readthedocs.io/en/latest/)`,
    Covariant Matrix Adaptation Evolution Strategy`[CMA-ES](https://arxiv.org/pdf/1604.00772)`,
    and Simulated Annealing `[SA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.dual_annealing.html#scipy.optimize.dual_annealing)`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将讨论顺序最小二乘法编程`[SLSQP](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-slsqp.html)`、粒子群优化`[PSO](https://pyswarms.readthedocs.io/en/latest/)`、协方差矩阵自适应进化策略`[CMA-ES](https://arxiv.org/pdf/1604.00772)`和模拟退火`[SA](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.dual_annealing.html#scipy.optimize.dual_annealing)`。
- en: Why use these algorithms?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要使用这些算法？
- en: 'There are several key advantages:'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有几个关键优势：
