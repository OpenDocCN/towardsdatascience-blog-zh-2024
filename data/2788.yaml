- en: Data Validation with Pandera in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Pandera è¿›è¡Œ Python æ•°æ®éªŒè¯
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/data-validation-with-pandera-in-python-f07b0f845040?source=collection_archive---------0-----------------------#2024-11-18](https://towardsdatascience.com/data-validation-with-pandera-in-python-f07b0f845040?source=collection_archive---------0-----------------------#2024-11-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/data-validation-with-pandera-in-python-f07b0f845040?source=collection_archive---------0-----------------------#2024-11-18](https://towardsdatascience.com/data-validation-with-pandera-in-python-f07b0f845040?source=collection_archive---------0-----------------------#2024-11-18)
- en: Validating your Dataframes for Production ML Pipelines
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éªŒè¯ä½ çš„æ•°æ®æ¡†ä»¥ç”¨äºç”Ÿäº§æœºå™¨å­¦ä¹ ç®¡é“
- en: '[](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)[![Gabriel
    Furnieles](../Images/710c939d8114ea8a4db16fd9f2c71f8a.png)](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)
    [Gabriel Furnieles](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)[![Gabriel
    Furnieles](../Images/710c939d8114ea8a4db16fd9f2c71f8a.png)](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)
    [Gabriel Furnieles](https://gabrielfurnieles.medium.com/?source=post_page---byline--f07b0f845040--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)
    Â·9 min readÂ·Nov 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f07b0f845040--------------------------------)
    Â·9åˆ†é’Ÿé˜…è¯»Â·2024å¹´11æœˆ18æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/53c2470e3fd017ad184018a7824bc84c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53c2470e3fd017ad184018a7824bc84c.png)'
- en: Image generated with [NightCafe](https://creator.nightcafe.studio/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒç”± [NightCafe](https://creator.nightcafe.studio/) ç”Ÿæˆã€‚
- en: Data validation is a crucial step for production applications. You need to ensure
    the data you are ingesting is compatible with your pipeline and that unexpected
    values arenâ€™t present. Moreover, validating the data is a security measure that
    prevents any corrupted or inaccurate information from being further processed,
    raising a flag on the first steps.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®éªŒè¯æ˜¯ç”Ÿäº§åº”ç”¨ä¸­è‡³å…³é‡è¦çš„ä¸€æ­¥ã€‚ä½ éœ€è¦ç¡®ä¿ä½ è·å–çš„æ•°æ®ä¸ç®¡é“å…¼å®¹ï¼Œå¹¶ä¸”æ²¡æœ‰æ„å¤–çš„å€¼å‡ºç°ã€‚æ­¤å¤–ï¼ŒéªŒè¯æ•°æ®æ˜¯ä¸€ç§å®‰å…¨æªæ–½ï¼Œå¯ä»¥é˜²æ­¢ä»»ä½•æŸåæˆ–ä¸å‡†ç¡®çš„ä¿¡æ¯è¢«è¿›ä¸€æ­¥å¤„ç†ï¼Œå¹¶åœ¨åˆæ­¥æ­¥éª¤ä¸­åŠæ—¶å‘å‡ºè­¦å‘Šã€‚
- en: Python already counts with a great OS project for this task called [Pydantic](https://docs.pydantic.dev/latest/).
    However, when dealing with large dataframe-like objects such as in Machine Learning,
    [Pandera](https://pandera.readthedocs.io/en/stable/index.html) is a much faster
    and scalable way of validating data (check [this article](https://www.union.ai/blog-post/pandera-0-17-adds-support-for-pydantic-v2)
    with public notebooks).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Python å·²ç»æœ‰ä¸€ä¸ªå¾ˆæ£’çš„å¼€æºé¡¹ç›®æ¥å¤„ç†è¿™ä¸ªä»»åŠ¡ï¼Œå«åš [Pydantic](https://docs.pydantic.dev/latest/)ã€‚ç„¶è€Œï¼Œå½“å¤„ç†åƒæœºå™¨å­¦ä¹ ä¸­é‚£æ ·çš„å¤§å‹æ•°æ®æ¡†å¯¹è±¡æ—¶ï¼Œ[Pandera](https://pandera.readthedocs.io/en/stable/index.html)
    æ˜¯ä¸€ç§æ›´å¿«ã€æ›´å¯æ‰©å±•çš„éªŒè¯æ•°æ®æ–¹å¼ï¼ˆè¯·æŸ¥çœ‹[è¿™ç¯‡æ–‡ç« ](https://www.union.ai/blog-post/pandera-0-17-adds-support-for-pydantic-v2)å’Œå…¬å¼€çš„ç¬”è®°æœ¬ï¼‰ã€‚
- en: '![](../Images/eb2c0f75b2f743dedaa7a6fe7b1a33b6.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb2c0f75b2f743dedaa7a6fe7b1a33b6.png)'
- en: Performance comparison between pandera and row-wise validation with Pydantic
    for different-sized pandas.DataFrame objects. Image from [source](https://www.union.ai/blog-post/pandera-0-17-adds-support-for-pydantic-v2#:~:text=%22records%22))-,Benchmarking%20Pandera%E2%80%99s%20row%2Dwise%20validation%20with%20Pydantic,-Because%20Pandera%20validates).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Pandera å’Œ Pydantic çš„é€è¡ŒéªŒè¯æ€§èƒ½æ¯”è¾ƒï¼Œé€‚ç”¨äºä¸åŒå¤§å°çš„ pandas.DataFrame å¯¹è±¡ã€‚å›¾ç‰‡æ¥æºäº [source](https://www.union.ai/blog-post/pandera-0-17-adds-support-for-pydantic-v2#:~:text=%22records%22))-,Benchmarking%20Pandera%E2%80%99s%20row%2Dwise%20validation%20with%20Pydantic,-Because%20Pandera%20validates)ã€‚
- en: In addition, Pandera offers support for a great variety of dataframe libraries
    like `pandas`, `polars`, `dask`, `modin`, and `pyspark.pandas`. For more information
    on these refer to [Panderaâ€™s docsğŸ“„](https://pandera.readthedocs.io/en/stable/index.html).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼ŒPandera æä¾›å¯¹å¤šç§æ•°æ®æ¡†åº“çš„æ”¯æŒï¼Œå¦‚ `pandas`ã€`polars`ã€`dask`ã€`modin` å’Œ `pyspark.pandas`ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ
    [Pandera æ–‡æ¡£ğŸ“„](https://pandera.readthedocs.io/en/stable/index.html)ã€‚
- en: '**Disclaimer.** Pandera is an open-source project licensed under the MIT License.
    I have no affiliation with the Pandera team or Union.ai. This post has no commercial
    interest.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**å…è´£å£°æ˜ã€‚** Panderaæ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œé‡‡ç”¨MITè®¸å¯è¯ã€‚æˆ‘ä¸Panderaå›¢é˜Ÿæˆ–Union.aiæ²¡æœ‰ä»»ä½•å…³ç³»ã€‚æ­¤å¸–å­æ²¡æœ‰å•†ä¸šç›®çš„ã€‚'
- en: Validating data with Pandera
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨PanderaéªŒè¯æ•°æ®
- en: 'Pandera has two ways of defining validators: **Schemas** and **Models**. I
    will focus on the second one because of its similarity with Pydantic models and
    the cleanness of the code.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Panderaæœ‰ä¸¤ç§å®šä¹‰éªŒè¯å™¨çš„æ–¹å¼ï¼š**Schemas**å’Œ**Models**ã€‚æˆ‘å°†ä¸“æ³¨äºç¬¬äºŒç§æ–¹å¼ï¼Œå› ä¸ºå®ƒä¸Pydanticæ¨¡å‹ç›¸ä¼¼ï¼Œå¹¶ä¸”ä»£ç æ›´ç®€æ´ã€‚
- en: 'To define a Pandera model create a child class that inherits from DataframeModel
    and start declaring the columns and dtypes that the dataframe must have:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å®šä¹‰Panderaæ¨¡å‹ï¼Œåˆ›å»ºä¸€ä¸ªç»§æ‰¿è‡ªDataframeModelçš„å­ç±»ï¼Œå¹¶å¼€å§‹å£°æ˜æ•°æ®æ¡†å¿…é¡»å…·æœ‰çš„åˆ—å’Œæ•°æ®ç±»å‹ï¼š
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that to define the userâ€™s creation timestamp I used Pandas native date
    type instead of others like `datetime.datetime`. Pandera only supports built-in
    Python, NumPy, and Pandas data types. You can also create [custom data types](https://pandera.readthedocs.io/en/stable/dtypes.html#logical-data-types),
    but this is an advanced topic and rarely necessary in most cases.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä¸ºäº†å®šä¹‰ç”¨æˆ·åˆ›å»ºæ—¶é—´æˆ³ï¼Œæˆ‘ä½¿ç”¨äº†PandasåŸç”Ÿçš„æ—¥æœŸç±»å‹ï¼Œè€Œä¸æ˜¯åƒ`datetime.datetime`è¿™æ ·çš„å…¶ä»–ç±»å‹ã€‚Panderaä»…æ”¯æŒå†…å»ºçš„Pythonã€NumPyå’ŒPandasæ•°æ®ç±»å‹ã€‚ä½ ä¹Ÿå¯ä»¥åˆ›å»º[è‡ªå®šä¹‰æ•°æ®ç±»å‹](https://pandera.readthedocs.io/en/stable/dtypes.html#logical-data-types)ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªé«˜çº§è¯é¢˜ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¸å¸¸ç”¨ã€‚
- en: Validating column properties
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éªŒè¯åˆ—å±æ€§
- en: 'With Pandera, you can also validate other column properties in addition to
    the type of data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Panderaï¼Œé™¤äº†éªŒè¯æ•°æ®ç±»å‹å¤–ï¼Œä½ è¿˜å¯ä»¥éªŒè¯å…¶ä»–åˆ—å±æ€§ï¼š
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here I am using panderaâ€™s Field just like pydanticsâ€™.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘åƒä½¿ç”¨pydanticä¸€æ ·ä½¿ç”¨Panderaçš„Fieldã€‚
- en: First, I am specifying that the `id` column must not contain duplicated values
    and these have to be greater or equal to 0.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘æŒ‡å®š`id`åˆ—ä¸å¾—åŒ…å«é‡å¤å€¼ï¼Œå¹¶ä¸”è¿™äº›å€¼å¿…é¡»å¤§äºæˆ–ç­‰äº0ã€‚
- en: In `username` and `email` Iâ€™m checking using regex expressions if strings are
    valid. User names must only contain alphanumeric characters and underscore, while
    emails can also contain dashes and dots but always follow the pattern â€œsmth@smth.smthâ€.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨`username`å’Œ`email`ä¸­ï¼Œæˆ‘ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦æœ‰æ•ˆã€‚ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯æ•°å­—å­—ç¬¦å’Œä¸‹åˆ’çº¿ï¼Œè€Œç”µå­é‚®ä»¶åœ°å€è¿˜å¯ä»¥åŒ…å«çŸ­æ¨ªçº¿å’Œç‚¹ï¼Œä½†å¿…é¡»å§‹ç»ˆéµå¾ªâ€œsmth@smth.smthâ€çš„æ¨¡å¼ã€‚
- en: '`membership` can only take a value from the list. A better approach is using
    a StrEnum to define the valid values instead of hardcoding them.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`membership`åªèƒ½å–åˆ—è¡¨ä¸­çš„å€¼ã€‚æ›´å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨StrEnumæ¥å®šä¹‰æœ‰æ•ˆå€¼ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç å®ƒä»¬ã€‚'
- en: 'Finally, `creation_date` must be in nanosecond units and UTC timezone. This
    line can be cleaner using Annotated from typing library `creation_date: Annotated[pd.DatetimeTZDtype,
    "ns", "UTC"]`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'æœ€åï¼Œ`creation_date`å¿…é¡»ä»¥çº³ç§’ä¸ºå•ä½ï¼Œå¹¶ä½¿ç”¨UTCæ—¶åŒºã€‚è¿™è¡Œä»£ç å¯ä»¥æ›´ç®€æ´ï¼Œä½¿ç”¨`typing`åº“ä¸­çš„Annotatedï¼š`creation_date:
    Annotated[pd.DatetimeTZDtype, "ns", "UTC"]`ã€‚'
- en: Check out [the docs](https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.dataframe.model_components.Field.html#pandera.api.dataframe.model_components.Field)
    to read all Field optionsğŸ˜‹
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹[æ–‡æ¡£](https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.dataframe.model_components.Field.html#pandera.api.dataframe.model_components.Field)ï¼Œé˜…è¯»æ‰€æœ‰Fieldé€‰é¡¹ğŸ˜‹
- en: Custom Validations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰éªŒè¯
- en: Sometimes it is necessary to add your own custom validations. Pandera allows
    you to inject [column/index checks](https://pandera.readthedocs.io/en/stable/dataframe_models.html#dataframe-checks:~:text=as%20class%20methods.-,Column/Index%20checks,-%C2%B6)
    (custom checks of single columns) and [dataframe checks](https://pandera.readthedocs.io/en/stable/dataframe_models.html#dataframe-checks:~:text=1%3A%20%3CCheck%20check_means%3E-,DataFrame%20Checks,-%C2%B6)
    (checks between several columns).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶éœ€è¦æ·»åŠ è‡ªå®šä¹‰éªŒè¯ã€‚Panderaå…è®¸ä½ æ³¨å…¥[åˆ—/ç´¢å¼•æ£€æŸ¥](https://pandera.readthedocs.io/en/stable/dataframe_models.html#dataframe-checks:~:text=as%20class%20methods.-,Column/Index%20checks,-%C2%B6)ï¼ˆå•åˆ—çš„è‡ªå®šä¹‰æ£€æŸ¥ï¼‰å’Œ[æ•°æ®æ¡†æ£€æŸ¥](https://pandera.readthedocs.io/en/stable/dataframe_models.html#dataframe-checks:~:text=1%3A%20%3CCheck%20check_means%3E-,DataFrame%20Checks,-%C2%B6)ï¼ˆå¤šä¸ªåˆ—ä¹‹é—´çš„æ£€æŸ¥ï¼‰ã€‚
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Keep in mind that you are working with entire column objects (`Series`) so that
    operations in checks should be vectorized for better performance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œä½ æ­£åœ¨å¤„ç†æ•´ä¸ªåˆ—å¯¹è±¡ï¼ˆ`Series`ï¼‰ï¼Œå› æ­¤æ£€æŸ¥ä¸­çš„æ“ä½œåº”å‘é‡åŒ–ä»¥æé«˜æ€§èƒ½ã€‚
- en: Other Configurations
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…¶ä»–é…ç½®
- en: '**Aliases** When column names canâ€™t be declared as Python variables due to
    the language syntax, Pandera allows setting an alias for the column validator
    to match the dataframe.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**åˆ«å** å½“åˆ—åç”±äºè¯­è¨€è¯­æ³•æ— æ³•å£°æ˜ä¸ºPythonå˜é‡æ—¶ï¼ŒPanderaå…è®¸ä¸ºåˆ—éªŒè¯å™¨è®¾ç½®åˆ«åï¼Œä»¥åŒ¹é…æ•°æ®æ¡†ã€‚'
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Strict and Coerce** When the `strict` option is set to true, it forces the
    validated dataframe to only contain the columns defined in the Pandera DataFrameModel.
    On the other hand, when the `coerce` option is activated, Pandera will try to
    cast the column data to match the modelâ€™s dtype.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¸¥æ ¼å’Œå¼ºåˆ¶** å½“`strict`é€‰é¡¹è®¾ç½®ä¸ºtrueæ—¶ï¼Œå®ƒä¼šå¼ºåˆ¶éªŒè¯çš„æ•°æ®æ¡†ä»…åŒ…å«åœ¨Pandera DataFrameModelä¸­å®šä¹‰çš„åˆ—ã€‚å¦ä¸€æ–¹é¢ï¼Œå½“å¯ç”¨`coerce`é€‰é¡¹æ—¶ï¼ŒPanderaä¼šå°è¯•å°†åˆ—æ•°æ®å¼ºåˆ¶è½¬æ¢ä¸ºä¸æ¨¡å‹çš„æ•°æ®ç±»å‹åŒ¹é…ã€‚'
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The coerce option can be set at the Field level too using `pa.Field(..., coerce=True)`
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`coerce`é€‰é¡¹ä¹Ÿå¯ä»¥åœ¨å­—æ®µçº§åˆ«ä½¿ç”¨ï¼Œæ–¹æ³•æ˜¯`pa.Field(..., coerce=True)`'
- en: '**Lazy validation** By default, pandera raises an error whenever a validation
    check isnâ€™t passed. This can be annoying because it only displays the first validation
    error encountered, and prevents the rest of the data from being checked.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‡’æƒ°éªŒè¯** é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“éªŒè¯æ£€æŸ¥æœªé€šè¿‡æ—¶ï¼ŒPanderaä¼šæŠ›å‡ºé”™è¯¯ã€‚è¿™å¯èƒ½ä¼šä»¤äººçƒ¦æ¼ï¼Œå› ä¸ºå®ƒåªæ˜¾ç¤ºé‡åˆ°çš„ç¬¬ä¸€ä¸ªéªŒè¯é”™è¯¯ï¼Œå¹¶é˜»æ­¢å…¶ä½™æ•°æ®çš„æ£€æŸ¥ã€‚'
- en: In some cases, it is better to let the whole dataframe validate and collect
    all errors in one run, rather than fixing them one by one and waiting for the
    validation to run again. The first is what lazy validation does.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæœ€å¥½è®©æ•´ä¸ªæ•°æ®æ¡†æ¶è¿›è¡ŒéªŒè¯ï¼Œå¹¶åœ¨ä¸€æ¬¡è¿è¡Œä¸­æ”¶é›†æ‰€æœ‰é”™è¯¯ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªä¸ªä¿®å¤å®ƒä»¬å¹¶ç­‰å¾…éªŒè¯å†æ¬¡è¿è¡Œã€‚å‰è€…æ˜¯æ‡’æƒ°éªŒè¯æ‰€åšçš„ã€‚
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: An ML Production Pipeline with Data Validation
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¸¦æœ‰æ•°æ®éªŒè¯çš„æœºå™¨å­¦ä¹ ç”Ÿäº§ç®¡é“
- en: '![](../Images/c9b4dfd55516a8c114ec37de0fc9ae03.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9b4dfd55516a8c114ec37de0fc9ae03.png)'
- en: Image generated with [NightCafe](https://creator.nightcafe.studio/).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[NightCafe](https://creator.nightcafe.studio/)ç”Ÿæˆçš„å›¾åƒã€‚
- en: Because the majority of ML Pipelines are trained in Python with tabular data
    encoded into dataframe structures, **Pandera** is a great and powerful tool to
    validate their Inputs and Outputs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå¤§å¤šæ•°æœºå™¨å­¦ä¹ ç®¡é“æ˜¯åœ¨Pythonä¸­ä½¿ç”¨è¡¨æ ¼æ•°æ®ç¼–ç æˆæ•°æ®æ¡†æ¶ç»“æ„è¿›è¡Œè®­ç»ƒçš„ï¼Œæ‰€ä»¥**Pandera**æ˜¯ä¸€ä¸ªéªŒè¯å…¶è¾“å…¥å’Œè¾“å‡ºçš„å¼ºå¤§å·¥å…·ã€‚
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We want to avoid the model raising an error due to invalid data. That would
    mean that weâ€™ve done all the work of loading the model into memory and processing
    the raw data for nothing, wasting resources and preventing the rest of the data
    points from being evaluated.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›é¿å…æ¨¡å‹å› æ— æ•ˆæ•°æ®è€ŒæŠ›å‡ºé”™è¯¯ã€‚é‚£æ ·æ„å‘³ç€æˆ‘ä»¬å·²ç»åšäº†å°†æ¨¡å‹åŠ è½½åˆ°å†…å­˜ä¸­å’Œå¤„ç†åŸå§‹æ•°æ®çš„æ‰€æœ‰å·¥ä½œï¼Œä½†ç»“æœæ˜¯ç™½è´¹åŠ›æ°”ï¼Œæµªè´¹èµ„æºï¼Œè¿˜é˜»æ­¢äº†å…¶ä½™æ•°æ®ç‚¹çš„è¯„ä¼°ã€‚
- en: Similarly, if the modelâ€™s output has an incorrect structure our postprocessing
    pipeline (uploading results to DB, returning results by RESTful API, etc.) will
    fail.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œå¦‚æœæ¨¡å‹çš„è¾“å‡ºç»“æ„ä¸æ­£ç¡®ï¼Œæˆ‘ä»¬çš„åå¤„ç†ç®¡é“ï¼ˆå°†ç»“æœä¸Šä¼ åˆ°æ•°æ®åº“ï¼Œé€šè¿‡RESTful APIè¿”å›ç»“æœç­‰ï¼‰å°†ä¼šå¤±è´¥ã€‚
- en: After defining the validation models using Pandera, we can leverage its [decorators
    for pipeline integration](https://pandera.readthedocs.io/en/stable/decorators.html#:~:text=Auto%20color%20theme-,Decorators%20for%20Pipeline%20Integration,-%C2%B6)
    to perform I/O validation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨Panderaå®šä¹‰éªŒè¯æ¨¡å‹åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å…¶[ç”¨äºç®¡é“é›†æˆçš„è£…é¥°å™¨](https://pandera.readthedocs.io/en/stable/decorators.html#:~:text=Auto%20color%20theme-,Decorators%20for%20Pipeline%20Integration,-%C2%B6)æ¥æ‰§è¡Œè¾“å…¥/è¾“å‡ºéªŒè¯ã€‚
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Because we are generating an intermediate dataframe object `df_transform` in
    the ML Pipeline, it is a good practice to validate it too to prevent errors. The
    *predict* method input is not validated as it is already done by *transform_data*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ç®¡é“ä¸­ç”Ÿæˆäº†ä¸€ä¸ªä¸­é—´æ•°æ®æ¡†å¯¹è±¡`df_transform`ï¼Œæ‰€ä»¥æœ€å¥½ä¹Ÿå¯¹å®ƒè¿›è¡ŒéªŒè¯ä»¥é˜²æ­¢é”™è¯¯ã€‚*predict*æ–¹æ³•çš„è¾“å…¥ä¸éœ€è¦éªŒè¯ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨*transform_data*ä¸­å®Œæˆäº†ã€‚
- en: Handling invalid rows
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤„ç†æ— æ•ˆè¡Œ
- en: We donâ€™t want our pipeline to break just because some data points have incorrect
    data. In case of a validation error, the strategy should be to set aside the problematic
    data points and continue running the pipeline with the rest of the data. The pipeline
    cannot stop!ğŸ”¥
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸å¸Œæœ›æˆ‘ä»¬çš„ç®¡é“å› ä¸ºæŸäº›æ•°æ®ç‚¹åŒ…å«ä¸æ­£ç¡®çš„æ•°æ®è€Œä¸­æ–­ã€‚å¦‚æœå‘ç”ŸéªŒè¯é”™è¯¯ï¼Œç­–ç•¥åº”è¯¥æ˜¯å°†æœ‰é—®é¢˜çš„æ•°æ®ç‚¹å•ç‹¬å¤„ç†ï¼Œå¹¶ç»§ç»­ä½¿ç”¨å…¶ä½™æ•°æ®è¿è¡Œç®¡é“ã€‚ç®¡é“ä¸èƒ½åœæ­¢ï¼ğŸ”¥
- en: 'Pandera models have the option to automatically remove all invalid rows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Panderaæ¨¡å‹æœ‰è‡ªåŠ¨ç§»é™¤æ‰€æœ‰æ— æ•ˆè¡Œçš„é€‰é¡¹ï¼š
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: However, dropping all invalid rows without logging them can be dangerous. You
    need to know why those data points were invalid so that later you can communicate
    to the client or to the data engineer what was the cause of the error.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸¢å¼ƒæ‰€æœ‰æ— æ•ˆè¡Œè€Œä¸è®°å½•å®ƒä»¬å¯èƒ½æ˜¯å±é™©çš„ã€‚ä½ éœ€è¦çŸ¥é“ä¸ºä»€ä¹ˆè¿™äº›æ•°æ®ç‚¹æ— æ•ˆï¼Œä»¥ä¾¿ç¨åå¯ä»¥å‘å®¢æˆ·æˆ–æ•°æ®å·¥ç¨‹å¸ˆæ²Ÿé€šé”™è¯¯çš„åŸå› ã€‚
- en: 'That is why instead of using pandera decorators I rather create my own validation
    helper functions:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä¸ä½¿ç”¨Panderaè£…é¥°å™¨ï¼Œè€Œæ˜¯åˆ›å»ºæˆ‘è‡ªå·±çš„éªŒè¯è¾…åŠ©å‡½æ•°ï¼š
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Output forcing some errors and removing column `id`:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå¼ºåˆ¶æŸäº›é”™è¯¯å¹¶ç§»é™¤åˆ—`id`ï¼š
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In case of an unresolvable error that involves an entire column, the pipeline
    cannot continue.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå‘ç”Ÿæ— æ³•è§£å†³çš„é”™è¯¯ä¸”æ¶‰åŠæ•´ä¸ªåˆ—ï¼Œåˆ™ç®¡é“æ— æ³•ç»§ç»­ã€‚
- en: Testing
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æµ‹è¯•
- en: Last but not least, Pandera models and schemas also incorporate a method for
    generating sample data according to their definition. You will need to install
    `[hypothesis](https://hypothesis.readthedocs.io/en/latest/)` library to use it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä½†åŒæ ·é‡è¦çš„æ˜¯ï¼ŒPandera æ¨¡å‹å’Œæ¨¡å¼è¿˜åŒ…æ‹¬æ ¹æ®å®šä¹‰ç”Ÿæˆç¤ºä¾‹æ•°æ®çš„æ–¹æ³•ã€‚ä½ éœ€è¦å®‰è£… `[hypothesis](https://hypothesis.readthedocs.io/en/latest/)`
    åº“æ‰èƒ½ä½¿ç”¨å®ƒã€‚
- en: However, after testing it with some examples I do not recommend it. As soon
    as you start adding a few constraints, it takes too long to generate the synthetic
    data and most of the time it isnâ€™t varied (the generated data do not cover the
    entire restriction space and repeats itself) The best alternative I found is to
    add data generators for each model you want to test â€” after all, there arenâ€™t
    so many data frames to validate in a pipeline either â€” .
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨ç”¨ä¸€äº›ç¤ºä¾‹æµ‹è¯•åï¼Œæˆ‘ä¸æ¨èä½¿ç”¨å®ƒã€‚ä¸€æ—¦ä½ å¼€å§‹æ·»åŠ ä¸€äº›çº¦æŸï¼Œç”Ÿæˆåˆæˆæ•°æ®çš„é€Ÿåº¦å°±ä¼šå˜å¾—å¾ˆæ…¢ï¼Œè€Œä¸”å¤§å¤šæ•°æ—¶å€™ç”Ÿæˆçš„æ•°æ®ç¼ºä¹å¤šæ ·æ€§ï¼ˆç”Ÿæˆçš„æ•°æ®æ— æ³•è¦†ç›–æ•´ä¸ªé™åˆ¶ç©ºé—´ï¼Œå¹¶ä¸”ä¼šé‡å¤ï¼‰ã€‚æˆ‘æ‰¾åˆ°çš„æœ€ä½³æ›¿ä»£æ–¹æ³•æ˜¯ä¸ºä½ æƒ³è¦æµ‹è¯•çš„æ¯ä¸ªæ¨¡å‹æ·»åŠ æ•°æ®ç”Ÿæˆå™¨â€”â€”æ¯•ç«Ÿï¼Œåœ¨ç®¡é“ä¸­éœ€è¦éªŒè¯çš„æ•°æ®æ¡†æ¶ä¹Ÿä¸å¤šâ€”â€”ã€‚
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Data validation is vital for every data processing pipeline and especially in
    Machine Learning. Pandera simplifies a lot of this work by providing a flexible,
    and efficient model-based approach to validating data in dataframes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®éªŒè¯å¯¹äºæ¯ä¸ªæ•°æ®å¤„ç†ç®¡é“éƒ½è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨å­¦ä¹ ä¸­ã€‚Pandera é€šè¿‡æä¾›ä¸€ç§çµæ´»ä¸”é«˜æ•ˆçš„åŸºäºæ¨¡å‹çš„æ–¹æ³•æ¥ç®€åŒ–æ•°æ®æ¡†æ¶ä¸­çš„æ•°æ®éªŒè¯å·¥ä½œã€‚
- en: With Pandera, you can define model classes that enforce column types, ranges,
    and even complex conditional constraints. This makes it easy to catch data quality
    issues early in the pipeline, ensuring that the data conforms to expected standards
    before it reaches the next steps.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Panderaï¼Œä½ å¯ä»¥å®šä¹‰å¼ºåˆ¶åˆ—ç±»å‹ã€èŒƒå›´ï¼Œç”šè‡³å¤æ‚æ¡ä»¶çº¦æŸçš„æ¨¡å‹ç±»ã€‚è¿™æ ·å¯ä»¥åœ¨æ•°æ®ç®¡é“çš„æ—©æœŸé˜¶æ®µè½»æ¾å‘ç°æ•°æ®è´¨é‡é—®é¢˜ï¼Œç¡®ä¿æ•°æ®åœ¨åˆ°è¾¾ä¸‹ä¸€æ­¥ä¹‹å‰ç¬¦åˆé¢„æœŸæ ‡å‡†ã€‚
- en: By integrating Pandera into an ML pipeline, you can create robust data checks
    that help prevent errors and improve the reliability of model outputs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°† Pandera é›†æˆåˆ°æœºå™¨å­¦ä¹ ç®¡é“ä¸­ï¼Œä½ å¯ä»¥åˆ›å»ºå¼ºå¤§çš„æ•°æ®æ£€æŸ¥ï¼Œå¸®åŠ©é˜²æ­¢é”™è¯¯å¹¶æé«˜æ¨¡å‹è¾“å‡ºçš„å¯é æ€§ã€‚
- en: 'Final pandera.DataFrameModel used in the tests:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆåœ¨æµ‹è¯•ä¸­ä½¿ç”¨çš„ pandera.DataFrameModelï¼š
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Hi, Iâ€™m Gabriel Furnieles, a Mathematical Engineer specializing in Artificial
    Intelligence, Data Pipelines, and MLOps. I hope you enjoyed the article and found
    it helpful, if so, please consider following me* [*Gabriel Furnieles*](https://medium.com/u/e77c10fd9715?source=post_page---user_mention--f07b0f845040--------------------------------),
    *and subscribing to my newsletter so stories will be sent directly to you ğŸ‘‡*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*å—¨ï¼Œæˆ‘æ˜¯ Gabriel Furnielesï¼Œä¸€åä¸“æ³¨äºäººå·¥æ™ºèƒ½ã€æ•°æ®ç®¡é“å’Œ MLOps çš„æ•°å­¦å·¥ç¨‹å¸ˆã€‚æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« å¹¶è§‰å¾—å®ƒæœ‰å¸®åŠ©ï¼Œå¦‚æœæ˜¯è¿™æ ·ï¼Œè¯·è€ƒè™‘å…³æ³¨æˆ‘*
    [*Gabriel Furnieles*](https://medium.com/u/e77c10fd9715?source=post_page---user_mention--f07b0f845040--------------------------------)ï¼Œ*å¹¶è®¢é˜…æˆ‘çš„é€šè®¯ï¼Œè¿™æ ·æ•…äº‹å°±ä¼šç›´æ¥å‘é€åˆ°ä½ é‚£é‡Œ
    ğŸ‘‡*'
- en: '[](https://medium.com/@gabrielfurnieles?source=post_page-----f07b0f845040--------------------------------)
    [## Gabriel Furnieles - Medium'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@gabrielfurnieles?source=post_page-----f07b0f845040--------------------------------)
    [## Gabriel Furnieles - Medium'
- en: Read writing from Gabriel Furnieles on Medium. Mathematical engineer specializing
    in AI and ML. I write casually onâ€¦
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨ Medium ä¸Šé˜…è¯» Gabriel Furnieles çš„æ–‡ç« ã€‚ä»–æ˜¯ä¸“æ³¨äº AI å’Œæœºå™¨å­¦ä¹ çš„æ•°å­¦å·¥ç¨‹å¸ˆã€‚æˆ‘å¶å°”åœ¨è¿™é‡Œå†™ä½œâ€¦â€¦
- en: medium.com](https://medium.com/@gabrielfurnieles?source=post_page-----f07b0f845040--------------------------------)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@gabrielfurnieles?source=post_page-----f07b0f845040--------------------------------)
