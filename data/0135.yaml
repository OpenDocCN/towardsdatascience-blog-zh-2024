- en: Evaluating Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估大型语言模型
- en: 原文：[https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14](https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14](https://towardsdatascience.com/evaluating-large-language-models-a145b801dce0?source=collection_archive---------1-----------------------#2024-01-14)
- en: Generative AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式人工智能
- en: How do you know how good your LLM is? A complete guide.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何评估你的大型语言模型（LLM）表现如何？一份完整的指南。
- en: '[](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Michał
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    [Michał Oleszak](https://michaloleszak.medium.com/?source=post_page---byline--a145b801dce0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    ·19 min read·Jan 14, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a145b801dce0--------------------------------)
    ·19分钟阅读·2024年1月14日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e5f31c4eb999520c1f49d4d0f136d2d1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5f31c4eb999520c1f49d4d0f136d2d1.png)'
- en: Having gone mainstream over a year ago with the releases of Stable Diffusion
    and ChatGPT, generative AI is developing incredibly fast. New models claiming
    to beat the state-of-the-art are announced almost every week. But how do we know
    if they are actually any good? How do we compare and rank generative models in
    the absence of ground truth, the “correct” solutions? Finally, if the LLM is using
    external data through a Retrieval-Augmented Generation or RAG system, how do we
    judge whether it makes correct use of these data?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自从稳定扩散（Stable Diffusion）和ChatGPT发布超过一年以来，生成式人工智能发展迅速。每周几乎都会有新的模型宣布声称能超越现有最先进的技术。但我们如何知道这些模型是否真有其价值？在缺乏地面真实数据和“正确”解决方案的情况下，如何比较和排名生成式模型？最后，如果大型语言模型（LLM）通过检索增强生成（Retrieval-Augmented
    Generation，简称RAG）系统使用外部数据，我们又如何评判它是否正确使用了这些数据？
- en: In a two-part series, we will explore evaluation protocols for generative AI.
    This post focuses on text generation and Large Language Models. Keep an eye out
    for a follow-up in which we will discuss evaluation methods for image generators.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两部分的系列文章中，我们将探讨生成式人工智能的评估协议。本文重点讨论文本生成和大型语言模型。敬请关注下一篇，我们将讨论图像生成器的评估方法。
- en: Evaluating generated content
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估生成的内容
- en: Let’s start by noting the distinction between generative and discriminative
    models. Generative models generate new data samples, be it text, images, audio,
    video, latent representations, or even tabular data, that are similar to the model’s
    training data. Discriminative models, on the other hand, learn decision boundaries
    through the training data, allowing us to solve…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先注意到生成式模型和判别式模型之间的区别。生成式模型生成与训练数据相似的新数据样本，无论是文本、图像、音频、视频、潜在表示，甚至是表格数据。另一方面，判别式模型通过训练数据学习决策边界，使我们能够解决…
