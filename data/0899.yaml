- en: 'iTransformer: The Latest Breakthrough in Time Series Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: iTransformer：时间序列预测中的最新突破
- en: 原文：[https://towardsdatascience.com/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1?source=collection_archive---------1-----------------------#2024-04-09](https://towardsdatascience.com/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1?source=collection_archive---------1-----------------------#2024-04-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1?source=collection_archive---------1-----------------------#2024-04-09](https://towardsdatascience.com/itransformer-the-latest-breakthrough-in-time-series-forecasting-d538ddc6c5d1?source=collection_archive---------1-----------------------#2024-04-09)
- en: Discover the architecture of iTransformer and apply the model in a small experiment
    using Python.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解 iTransformer 的架构，并使用 Python 在一个小实验中应用该模型。
- en: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page---byline--d538ddc6c5d1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)
    ·9 min read·Apr 9, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d538ddc6c5d1--------------------------------)
    ·9分钟阅读·2024年4月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/59147fdd489a18f62e87a7e649bdd52e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59147fdd489a18f62e87a7e649bdd52e.png)'
- en: Photo by [David Clode](https://unsplash.com/@davidclode?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[David Clode](https://unsplash.com/@davidclode?utm_source=medium&utm_medium=referral)，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The field of forecasting has seen a lot of activity in the realm of foundation
    models, with models like [Lag-LLaMA](/lag-llama-open-source-foundation-model-for-time-series-forecasting-9afdfaf2bd7c),
    [Time-LLM](/time-llm-reprogram-an-llm-for-time-series-forecasting-e2558087b8ac),
    [Chronos](/chronos-the-latest-time-series-forecasting-foundation-model-by-amazon-2687d641705a)
    and Moirai being proposed since the beginning of 2024.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 预测领域在基础模型方面取得了很多进展，自2024年初以来，像[Lag-LLaMA](/lag-llama-open-source-foundation-model-for-time-series-forecasting-9afdfaf2bd7c)、[Time-LLM](/time-llm-reprogram-an-llm-for-time-series-forecasting-e2558087b8ac)、[Chronos](/chronos-the-latest-time-series-forecasting-foundation-model-by-amazon-2687d641705a)和Moirai等模型相继被提出。
- en: However, their performance has been a bit underwhelming (for reproducible benchmarks,
    see [here](https://github.com/Nixtla/nixtla/tree/main/experiments)), and I believe
    that data-specific models are still the optimal solution at the moment.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们的性能略显不足（关于可重复的基准测试，见[这里](https://github.com/Nixtla/nixtla/tree/main/experiments)），我认为目前数据特定的模型仍然是最优解。
- en: To that end, the Transformer architecture has been applied in many forms for
    time series forecasting, with [PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)
    achieving state-of-the-art performance for long-horizon forecasting.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，Transformer 架构已经以多种形式应用于时间序列预测，其中[PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)在长时间范围预测中达到了最先进的性能。
- en: 'Challenging PatchTST comes the **iTransformer** model, proposed in March 2024
    in the paper [iTransformer: Inverted Transformers Are Effective for Time Series
    Forecasting](https://arxiv.org/abs/2310.06625).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '持挑战性的PatchTST迎来了**iTransformer**模型，该模型在2024年3月由论文[iTransformer: Inverted Transformers
    Are Effective for Time Series Forecasting](https://arxiv.org/abs/2310.06625)提出。'
- en: In this article, we discover the strikingly simple concept behind iTransformer
    and explore its architecture. Then, we apply the model in a small experiment and
    compare its performance to [TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb),
    [N-HiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)
    and PatchTST.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们发现了iTransformer背后引人注目的简单概念，并探讨了其架构。接着，我们在一个小实验中应用该模型，并将其表现与[TSMixer](/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb)、[N-HiTS](/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)和PatchTST进行比较。
- en: For more details, make sure to read the [original paper](https://arxiv.org/abs/2310.06625).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多细节，请务必阅读[原始论文](https://arxiv.org/abs/2310.06625)。
- en: Learn the latest time series…
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 了解最新的时间序列…
