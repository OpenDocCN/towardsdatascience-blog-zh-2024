- en: 'Oversampling and Undersampling, Explained: A Visual Guide with Mini 2D Dataset'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过采样与欠采样，详解：带有迷你二维数据集的视觉指南
- en: 原文：[https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26](https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26](https://towardsdatascience.com/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091?source=collection_archive---------1-----------------------#2024-10-26)
- en: DATA PREPROCESSING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Artificially generating and deleting data for the greater good
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人为地生成和删除数据，以实现更大的利益
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--1155577d3091--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    ·9 min read·Oct 26, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1155577d3091--------------------------------)
    ·阅读时间：9分钟·2024年10月26日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d18a47c1be692247ef3ce8e346048f3e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d18a47c1be692247ef3ce8e346048f3e.png)'
- en: '`⛳️ More [DATA PREPROCESSING](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4),
    explained: · [Missing Value Imputation](/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb)
    · [Categorical Encoding](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    · [Data Scaling](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    · [Discretization](/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86)
    ▶ [Oversampling & Undersampling](/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091)
    · [Data Leakage in Preprocessing](/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7)`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`⛳️ 更多的[数据预处理](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4)，详解：·
    [缺失值填补](/missing-value-imputation-explained-a-visual-guide-with-code-examples-for-beginners-93e0726284eb)
    · [分类编码](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    · [数据缩放](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    · [离散化](/discretization-explained-a-visual-guide-with-code-examples-for-beginners-f056af9102fa?gi=c1bf25229f86)
    ▶ [过采样与欠采样](/oversampling-and-undersampling-explained-a-visual-guide-with-mini-2d-dataset-1155577d3091)
    · [数据泄漏在预处理中的影响](/data-leakage-in-preprocessing-explained-a-visual-guide-with-code-examples-33cbf07507b7)`'
- en: Collecting a dataset where each class has exactly the same number of class to
    predict can be a challenge. In reality, things are rarely perfectly balanced,
    and when you are making a classification model, this can be an issue. When a model
    is trained on such dataset, where one class has more examples than the other,
    it has usually become better at predicting the bigger groups and worse at predicting
    the smaller ones. To help with this issue, we can use tactics like oversampling
    and undersampling — creating more examples of the smaller group or removing some
    examples from the bigger group.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 收集一个每个类别的样本数量完全相同的数据集可能是一项挑战。实际上，情况很少是完美平衡的，在构建分类模型时，这可能成为一个问题。当一个模型在这样的数据集上进行训练时，如果某一类的样本比另一类多，通常它会更擅长预测较大的类别，而在预测较小的类别时表现较差。为了解决这个问题，我们可以使用过采样和欠采样等策略——为较小类别创造更多样本，或从较大类别中删除一些样本。
- en: There are many different oversampling and undersampling methods (with intimidating
    names like SMOTE, ADASYN, and Tomek Links) out there but there doesn’t seem to
    be many resources that visually compare how they work. So, here, we will use one
    simple 2D dataset to show the changes that occur in the data after applying those
    methods so we can see how different the output of each method is. You will see
    in the visuals that these various approaches give different solutions, and who
    knows, one might be suitable for your specific machine learning challenge!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的过采样和欠采样方法（如SMOTE、ADASYN和Tomek Links等这些令人害怕的名字），但是似乎没有很多资源可以直观地比较它们的工作方式。所以，在这里，我们将使用一个简单的二维数据集来展示应用这些方法后数据发生的变化，以便我们看到每种方法的输出有多大不同。你将会在可视化中看到，这些不同的方法给出了不同的解决方案，谁知道，也许其中某个方法适合你的具体机器学习挑战！
- en: '![](../Images/27f80579aa059f5392c5e18ce293068a.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27f80579aa059f5392c5e18ce293068a.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可视化：作者使用Canva Pro创建。优化为移动设备使用；在桌面上可能会显得过大。
- en: Definition
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: Oversampling
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过采样
- en: Oversampling make a dataset more balanced when one group has a lot fewer examples
    than the other. The way it works is by making more copies of the examples from
    the smaller group. This helps the dataset represent both groups more equally.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 过采样可以使数据集更平衡，当一个组的样本比另一个组少得多时，它通过增加较小组的样本副本来工作。这有助于数据集更均衡地代表两个组。
- en: Undersampling
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 欠采样
- en: On the other hand, undersampling works by deleting some of the examples from
    the bigger group until it’s almost the same in size to the smaller group. In the
    end, the dataset is smaller, sure, but both groups will have a more similar number
    of examples.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，欠采样通过删除较大组中的一些样本，直到它几乎与较小组的大小相同。最终，数据集确实会变小，但两个组的样本数量会更为相似。
- en: '**Hybrid Sampling**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**混合采样**'
- en: Combining oversampling and undersampling can be called “hybrid sampling”. It
    increases the size of the smaller group by making more copies of its examples
    and also, it removes some of example of the bigger group by removing some of its
    examples. It tries to create a dataset that is more balanced — not too big and
    not too small.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 将过采样和欠采样结合起来，称为“混合采样”。它通过增加较小组样本的副本来增大较小组的规模，同时也通过删除较大组中的一些样本来缩小较大组的规模。它试图创建一个更加平衡的数据集——既不太大也不太小。
- en: '![](../Images/fbfec21238decaadf5e6de9556274a3f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbfec21238decaadf5e6de9556274a3f.png)'
- en: 📊 Dataset Used
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📊 使用的数据集
- en: Let’s use a simple artificial golf dataset to show both oversampling and undersampling.
    This dataset shows what kind of golf activity a person do in a particular weather
    condition.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个简单的人工高尔夫数据集来展示过采样和欠采样。这个数据集展示了在特定天气条件下，一个人做什么类型的高尔夫活动。
- en: '![](../Images/f864e43ec6dfd3779bd2db853fb5dd5d.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f864e43ec6dfd3779bd2db853fb5dd5d.png)'
- en: 'Columns: Temperature (0–3), Humidity (0–3), Golf Activity (A=Normal Course,
    B=Drive Range, or C=Indoor Golf). The training dataset has 2 dimensions and 9
    samples.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列：温度（0–3），湿度（0–3），高尔夫活动（A=标准球场，B=练习场，C=室内高尔夫）。训练数据集有2个维度和9个样本。
- en: ⚠️ Note that while this small dataset is good for understanding the concepts,
    in real applications you’d want much larger datasets before applying these techniques,
    as sampling with too little data can lead to unreliable results.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 请注意，虽然这个小数据集有助于理解概念，但在实际应用中，你应该在应用这些技术之前使用更大的数据集，因为使用过少的数据进行采样可能会导致结果不可靠。
- en: Oversampling Methods
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过采样方法
- en: Random Oversampling
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机过采样
- en: '[Random Oversampling](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)
    is a simple way to make the smaller group bigger. It works by making duplicates
    of the examples from the smaller group until all the classes are balanced.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[随机过采样](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html)是一种简单的方法，通过复制较小组的样本，直到所有类别平衡。'
- en: 👍 Best for very small datasets that need to be balanced quickly
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合需要快速平衡的小型数据集
- en: 👎 Not recommended for complicated datasets
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 不推荐用于复杂的数据集
- en: '![](../Images/13295244f5529177e8d14d031dfa1b8d.png)![](../Images/749fd0b088d2dd48976bbd04f9607668.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13295244f5529177e8d14d031dfa1b8d.png)![](../Images/749fd0b088d2dd48976bbd04f9607668.png)'
- en: Random Oversampling simply duplicates selected samples from the smaller group
    (A) while keeping all samples from the bigger groups (B and C) unchanged, as shown
    by the A×2 markings in the right plot.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随机过采样简单地复制较小组（A）中选定的样本，同时保持较大组（B和C）中的所有样本不变，如右图中的A×2标记所示。
- en: SMOTE
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SMOTE
- en: '[SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)
    (Synthetic Minority Over-sampling Technique) is an oversampling technique that
    makes new examples by interpolating the smaller group. Unlike the random oversampling,
    it doesn’t just copy what’s there but it uses the examples of the smaller group
    to generate some examples between them.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)（合成少数类过采样技术）是一种过采样技术，通过对较小组进行插值来生成新样本。与随机过采样不同，它不仅仅是复制已有的样本，而是利用较小组的样本生成它们之间的样本。'
- en: 👍 Best when you have a decent amount of examples to work with and need variety
    in your data
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合在你有足够的样本并且需要数据多样性的情况
- en: 👎 Not recommended if you have very few examples
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果样本数量非常少，不推荐使用
- en: 👎 Not recommended if data points are too scattered or noisy
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果数据点过于分散或噪声过大，不推荐使用
- en: '![](../Images/dda912677a7737a5f40d61c11f2d2550.png)![](../Images/8bc0e42698c59189fbe66ff91b6dee53.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dda912677a7737a5f40d61c11f2d2550.png)![](../Images/8bc0e42698c59189fbe66ff91b6dee53.png)'
- en: SMOTE creates new A samples by selecting pairs of A points and placing new points
    somewhere along the line between them. Similarly, a new B point is placed between
    pairs of randomly chosen B points
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTE通过选择A点的成对样本，并在它们之间的某个位置生成新样本，从而创建新的A样本。类似地，一个新的B点会在随机选取的B点对之间生成。
- en: ADASYN
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ADASYN
- en: '[ADASYN](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html)
    (Adaptive Synthetic) is like SMOTE but focuses on making new examples in the harder-to-learn
    parts of the smaller group. It finds the examples that are trickiest to classify
    and makes more new points around those. This helps the model better understand
    the challenging areas.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[ADASYN](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.ADASYN.html)（自适应合成）类似于SMOTE，但专注于在较小组的难学部分生成新的样本。它会找到那些最难分类的样本，并在这些样本周围生成更多的新点。这有助于模型更好地理解具有挑战性的区域。'
- en: 👍 Best when some parts of your data are harder to classify than others
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 如果数据的某些部分比其他部分更难分类，最佳选择
- en: 👍 Best for complex datasets with challenging areas
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合处理具有挑战性区域的复杂数据集
- en: 👎 Not recommended if your data is fairly simple and straightforward
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你的数据相对简单直接，不推荐使用
- en: '![](../Images/ef640350be2f8f11175deb868837198d.png)![](../Images/cfd7a6cd64777142b381f64cbd598479.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef640350be2f8f11175deb868837198d.png)![](../Images/cfd7a6cd64777142b381f64cbd598479.png)'
- en: ADASYN creates more synthetic points from the smaller group (A) in ‘difficult
    areas’ where A points are close to other groups (B and C). It also generates new
    B points in similar areas.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ADASYN在较小组（A）的“难学区域”生成更多合成点，这些区域是A点与其他组（B和C）接近的地方。它还会在类似区域生成新的B点。
- en: Undersampling Methods
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 欠采样方法
- en: 'Undersampling shrinks the bigger group to make it closer in size to the smaller
    group. There are some ways of doing this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样通过缩小较大组的大小，使其与较小组的大小更为接近。有几种方法可以做到这一点：
- en: Random Undersampling
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机欠采样
- en: '[Random Undersampling](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html)
    removes examples from the bigger group at random until it’s the same size as the
    smaller group. Just like random oversampling the method is pretty simple, but
    it might get rid of important info that really show how different the groups are.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[随机欠采样](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html)通过随机移除较大组中的样本，直到其大小与较小组相同。与随机过采样一样，这种方法相当简单，但它可能会丢失一些重要信息，这些信息展示了各组之间的差异。'
- en: 👍 Best for very large datasets with lots of repetitive examples
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合处理非常大的数据集，尤其是当样本重复较多时
- en: 👍 Best when you need a quick, simple fix
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 如果你需要一个快速、简单的解决方案，最佳选择
- en: 👎 Not recommended if every example in your bigger group is important
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你较大组中的每个样本都很重要，不推荐使用
- en: 👎 Not recommended if you can’t afford losing any information
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你不能接受丢失任何信息，不推荐使用
- en: '![](../Images/338affc600e93a3b9159cd576d5daa3f.png)![](../Images/1ea3f55adc1079391dcd5d339a331aa4.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/338affc600e93a3b9159cd576d5daa3f.png)![](../Images/1ea3f55adc1079391dcd5d339a331aa4.png)'
- en: Random Undersampling removes randomly chosen points from the bigger groups (B
    and C) while keeping all points from the smaller group (A) unchanged.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随机欠采样通过从较大的组（B和C）中随机删除样本，同时保持较小组（A）中的所有样本不变。
- en: Tomek Links
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tomek链接
- en: '[Tomek Links](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html)
    is an undersampling method that makes the “lines” between groups clearer. It searches
    for pairs of examples from different groups that are really alike. When it finds
    a pair where the examples are each other’s closest neighbors but belong to different
    groups, it gets rid of the example from the bigger group.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tomek Links](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html)是一种欠采样方法，它使得组之间的“边界”更清晰。它搜索来自不同组的非常相似的示例对。当它找到一对示例，这些示例是彼此最接近的邻居但属于不同的组时，它会从较大组中移除这个示例。'
- en: 👍 Best when your groups overlap too much
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 当你的组之间重叠过多时，效果最佳
- en: 👍 Best for cleaning up messy or noisy data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合清理杂乱或噪声数据
- en: 👍 Best when you need clear boundaries between groups
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 当你需要组之间清晰的边界时，效果最佳
- en: 👎 Not recommended if your groups are already well separated
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你的组已经很分开，不推荐使用
- en: '![](../Images/a66c75601482e491f58bfd01f2fbb85b.png)![](../Images/e2a22ee08d0dd985835582298e45af3c.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a66c75601482e491f58bfd01f2fbb85b.png)![](../Images/e2a22ee08d0dd985835582298e45af3c.png)'
- en: Tomek Links identifies pairs of points from different groups (A-B, B-C) that
    are closest neighbors to each other. Points from the bigger groups (B and C) that
    form these pairs are then removed while all points from the smaller group (A)
    are kept.”
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Tomek Links识别来自不同组（A-B，B-C）的点对，这些点对是彼此最接近的邻居。然后，从较大组（B和C）中移除这些点对，而保留所有较小组（A）中的点。
- en: Near Miss
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Near Miss
- en: '[Near Miss](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html)
    is a set of undersampling techniques that works on different rules:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[Near Miss](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.NearMiss.html)是一组基于不同规则的欠采样技术：'
- en: '*Near Miss-1*: Keeps examples from the bigger group that are closest to the
    examples in the smaller group.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Near Miss-1*：保留较大组中与较小组中的示例最接近的示例。'
- en: '*Near Miss-2*: Keeps examples from the bigger group that have the smallest
    average distance to their three closest neighbors in the smaller group.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Near Miss-2*：保留较大组中与较小组中三个最接近邻居的平均距离最小的示例。'
- en: '*Near Miss-3*: Keeps examples from the bigger group that are furthest away
    from other examples in their own group.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Near Miss-3*：保留较大组中距离自己组内其他示例最远的示例。'
- en: The main idea here is to keep the most informative examples from the bigger
    group and get rid of the ones that aren’t as important.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要思想是保留较大组中最具信息量的示例，去除那些不太重要的示例。
- en: 👍 Best when you want control over which examples to keep
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 当你需要控制保留哪些示例时，效果最佳
- en: 👎 Not recommended if you need a simple, quick solution
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你需要一个简单、快速的解决方案，不推荐使用
- en: '![](../Images/3484d2504c3b1c299838a03281e1e89a.png)![](../Images/c2ffc17b3d37927fa513378c6de6a74e.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3484d2504c3b1c299838a03281e1e89a.png)![](../Images/c2ffc17b3d37927fa513378c6de6a74e.png)'
- en: NearMiss-1 keeps points from the bigger groups (B and C) that are closest to
    the smaller group (A), while removing the rest. Here, only the B and C points
    nearest to A points are kept.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: NearMiss-1保留来自较大组（B和C）中与较小组（A）最接近的点，同时去除其他点。这里，仅保留距离A点最近的B和C点。
- en: ENN
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ENN
- en: '[Edited Nearest Neighbors](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html)
    (ENN) method gets rid of examples that are probably noise or outliers. For each
    example in the bigger group, it checks whether most of its closest neighbors belong
    to the same group. If they don’t, it removes that example. This helps create cleaner
    boundaries between the groups.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[Edited Nearest Neighbors](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.EditedNearestNeighbours.html)（ENN）方法去除那些可能是噪声或离群点的示例。对于较大组中的每个示例，它检查其大多数最近邻是否属于同一组。如果不属于同一组，它会移除该示例。这有助于创建更清晰的组边界。'
- en: 👍 Best for cleaning up messy data
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合清理杂乱的数据
- en: 👍 Best when you need to remove outliers
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 当你需要移除离群点时，效果最佳
- en: 👍 Best for creating cleaner group boundaries
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合创建更清晰的组边界
- en: 👎 Not recommended if your data is already clean and well-organized
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果你的数据已经干净且组织良好，不推荐使用
- en: '![](../Images/2c6d1c578f42c121ee08d9d4492a7e95.png)![](../Images/168f72783979a04a0feb28881a6bff14.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c6d1c578f42c121ee08d9d4492a7e95.png)![](../Images/168f72783979a04a0feb28881a6bff14.png)'
- en: ENN removes points from bigger groups (B and C) whose majority of nearest neighbors
    belong to a different group. In the right plot, crossed-out points are removed
    because most of their closest neighbors are from other groups.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ENN从较大组（B和C）中移除其大多数最近邻属于不同组的点。在右侧的图中，划掉的点被移除，因为它们的大多数最近邻来自其他组。
- en: Hybrid sampling methods
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合采样方法
- en: SMOTETomek
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SMOTETomek
- en: '[SMOTETomek](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html)
    works by first creating new examples for the smaller group using SMOTE, then cleaning
    up messy boundaries by removing “confusing” examples using Tomek Links. This helps
    creating a more balanced dataset with clearer boundaries and less noise.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[SMOTETomek](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTETomek.html)的工作原理是，首先使用SMOTE为较小的类别创建新样本，然后通过使用Tomek链接去除“混淆”样本来清理杂乱的边界。这有助于创建一个更加平衡、边界更清晰且噪声更少的数据集。'
- en: 👍 Best for unbalanced data that is really severe
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适用于极度不平衡的数据
- en: 👍 Best when you need both more examples and cleaner boundaries
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合当你需要更多样本并且边界更清晰时
- en: 👍 Best when dealing with noisy, overlapping groups
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合处理噪声较多且重叠的类别
- en: 👎 Not recommended if your data is already clean and well-organized
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果数据已经清理和整理得很好，建议不要使用
- en: 👎 Not recommended for small dataset
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 不推荐用于小型数据集
- en: '![](../Images/711a2e0590e08f16f29cc19029addb27.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/711a2e0590e08f16f29cc19029addb27.png)'
- en: 'SMOTETomek combines two steps: first applying SMOTE to create new A points
    along lines between existing A points (shown in middle plot), then removing Tomek
    Links from bigger groups (B and C). The final result has more balanced groups
    with clearer boundaries between them.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTETomek结合了两个步骤：首先应用SMOTE，在现有A点之间的线段上创建新的A点（如中间图所示），然后从较大类别（B和C）中去除Tomek链接。最终结果是更加平衡的类别，且它们之间的边界更加清晰。
- en: SMOTEENN
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SMOTEENN
- en: '[SMOTEENN](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html)
    works by first creating new examples for the smaller group using SMOTE, then cleaning
    up both groups by removing examples that don’t fit well with their neighbors using
    ENN. Just like SMOTETomek, this helps create a cleaner dataset with clearer borders
    between the groups.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[SMOTEENN](https://imbalanced-learn.org/stable/references/generated/imblearn.combine.SMOTEENN.html)的工作原理是，首先使用SMOTE为较小类别创建新样本，然后通过使用ENN清理两个类别，去除那些与邻近样本不匹配的样本。像SMOTETomek一样，这有助于创建一个更干净的数据集，并使类别之间的边界更加清晰。'
- en: 👍 Best for cleaning up both groups at once
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合同时清理两个类别
- en: 👍 Best when you need more examples but cleaner data
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合当你需要更多样本但又希望数据更干净时
- en: 👍 Best when dealing with lots of outliers
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 👍 最适合处理大量离群点时
- en: 👎 Not recommended if your data is already clean and well-organized
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 如果数据已经清理和整理得很好，建议不要使用
- en: 👎 Not recommended for small dataset
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 👎 不推荐用于小型数据集
- en: '![](../Images/b7c8d78a7ccc58712f284aee986b18d4.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7c8d78a7ccc58712f284aee986b18d4.png)'
- en: 'SMOTEENN combines two steps: first using SMOTE to create new A points along
    lines between existing A points (middle plot), then applying ENN to remove points
    from bigger groups (B and C) whose nearest neighbors are mostly from different
    groups. The final plot shows the cleaned, balanced dataset.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: SMOTEENN结合了两个步骤：首先使用SMOTE在现有A点之间的线段上创建新的A点（如中间图所示），然后应用ENN去除那些邻近点大多来自不同类别的较大类别（B和C）中的点。最终图显示了清理后的平衡数据集。
- en: ⚠️ Risks when using Resampling methods
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ⚠️ 使用重采样方法时的风险
- en: 'Resampling methods can be helpful but there are some potential risks:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 重采样方法可以很有帮助，但也存在一些潜在的风险：
- en: '**Oversampling:**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**过采样：**'
- en: Making artificial samples can **give false patterns** that don’t exist in real
    life.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成人工样本可能会**给出不真实的模式**，这些模式在现实生活中并不存在。
- en: Models can **become too confident** because of the synthetic samples. This will
    lead to serious failures when it is applied to real situation.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可能因为合成样本而**变得过于自信**，这会在应用于实际情况时导致严重失败。
- en: There’s a risk of **data leakage** if resampling is done incorrectly (like before
    splitting the data for cross-validation.)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果重采样操作不当（比如在数据拆分用于交叉验证之前），可能会发生**数据泄漏**的风险。
- en: '**Undersampling:**'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**欠采样：**'
- en: You may **permanently lose important information**.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能会**永久丢失重要信息**。
- en: You can **accidentally destroy important boundaries** between classes, and will
    cause misunderstanding of the problem.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能会**意外地破坏类别之间的重要边界**，从而导致对问题的误解。
- en: You may **create artificial class distributions** that is too different compared
    to real-world conditions.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能会**创建与真实世界条件差异过大的人工类别分布**。
- en: '**Hybrid Methods:**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**混合方法：**'
- en: '**Combining errors** from both methods can **make things worse** instead of
    better.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结合两种方法的错误**可能会**使问题变得更糟**，而不是更好。'
- en: When using resampling methods, it’s hard to find the right balance between getting
    class imbalance without changing the important patterns in your data. In my experience,
    incorrect resampling can actually harm model performance rather than improve it.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用重采样方法时，很难找到在不改变数据中重要模式的情况下，既能解决类别不平衡问题又不影响模型性能的平衡点。根据我的经验，错误的重采样实际上可能会损害模型性能，而不是提高它。
- en: Before turning to resampling, try using models that naturally handle imbalanced
    data better, such as tree-based algorithms. Resampling should be part of a broader
    strategy rather than the only solution to address class imbalance.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行重采样之前，尝试使用那些自然能更好处理不平衡数据的模型，例如基于树的算法。重采样应作为更广泛策略的一部分，而不是解决类别不平衡的唯一方案。
- en: 🌟 Oversampling & Undersampling Code Summarized
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 超采样与欠采样代码总结
- en: 'For the code example, we will use the methods provided by `[imblearn](https://imbalanced-learn.org/stable/index.html)`
    library:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码示例，我们将使用由 `[imblearn](https://imbalanced-learn.org/stable/index.html)` 库提供的方法：
- en: '[PRE0]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Technical Environment
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7, pandas 1.3, and imblearn 1.2\. While the concepts
    discussed are generally applicable, specific code implementations may vary slightly
    with different versions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用 Python 3.7、pandas 1.3 和 imblearn 1.2。虽然讨论的概念普遍适用，但不同版本的具体代码实现可能会有所不同。
- en: About the Illustrations
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者创作，包含了来自 Canva Pro 的授权设计元素。
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘿𝙖𝙩𝙖 𝙋𝙧𝙚𝙥𝙧𝙤𝙘𝙚𝙨𝙨𝙞𝙣𝙜 𝙢𝙚𝙩𝙝𝙤𝙙𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
- en: Data Preprocessing
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: '[View list](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----1155577d3091--------------------------------)6
    stories![](../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png)![Cartoon illustration
    of two figures embracing, with letters ‘A’, ‘B’, ‘C’ and numbers ‘1’, ‘2’, ‘3’
    floating around them. A pink heart hovers above, symbolizing affection. The background
    is a pixelated pattern of blue and green squares, representing data or encoding.
    This image metaphorically depicts the concept of encoding categorical data, where
    categories (ABC) are transformed into numerical representations (123).](../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png)![A
    cartoon illustration representing data scaling in machine learning. A tall woman
    (representing a numerical feature with a large range) is shown shrinking into
    a child (representing the same feature after scaling to a smaller range). A red
    arrow indicates the shrinking process, and yellow sparkles around the child signify
    the positive impact of scaling.](../Images/d261b2c52a3cafe266d1962d4dbabdbd.png)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/data-preprocessing-17a2c49b44e4?source=post_page-----1155577d3091--------------------------------)6
    个故事![](../Images/f7ead0fb9a8dc2823d7a43d67a1c6932.png)![两个人物拥抱的卡通插图，周围漂浮着字母‘A’、‘B’、‘C’以及数字‘1’、‘2’、‘3’，上方悬浮着一个粉色的爱心，象征着情感。背景是由蓝色和绿色方块构成的像素化图案，代表数据或编码。这幅图形象地描绘了对类别数据进行编码的概念，其中类别（ABC）被转化为数值表示（123）。](../Images/72bb3a287a9ca4c5e7a3871e234bcc4b.png)![一幅卡通插图，展示了机器学习中的数据缩放。一个高大的女人（代表具有较大范围的数值特征）被描绘成变矮为一个小女孩（代表该特征经过缩放后变为较小的范围）。一只红色的箭头指示着缩小过程，周围的黄色闪光象征着缩放的积极影响。](../Images/d261b2c52a3cafe266d1962d4dbabdbd.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
- en: Classification Algorithms
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----1155577d3091--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----1155577d3091--------------------------------)8
    个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----1155577d3091--------------------------------)'
- en: Regression Algorithms
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----1155577d3091--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This “dummy” doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----1155577d3091--------------------------------)5
    个故事！[一个戴着粉色帽子、扎着辫子的卡通娃娃。这个“假人”娃娃，凭借其简单的设计和心形图案的衬衫，在视觉上代表了机器学习中的假回归模型（dummy regressor）概念。就像这个玩具般的形象是一个简化的、静态的人物表达，假回归模型是一些基本的模型，用作更复杂分析的基准。](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
