- en: Sparse Autoencoders, Additive Decision Trees, and Other Emerging Topics in AI
    Interpretability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏自编码器、加性决策树以及 AI 可解释性中的其他新兴话题
- en: 原文：[https://towardsdatascience.com/sparse-autoencoders-additive-decision-trees-and-other-emerging-topics-in-ai-interpretability-9ab1eaf14d3e?source=collection_archive---------6-----------------------#2024-06-13](https://towardsdatascience.com/sparse-autoencoders-additive-decision-trees-and-other-emerging-topics-in-ai-interpretability-9ab1eaf14d3e?source=collection_archive---------6-----------------------#2024-06-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/sparse-autoencoders-additive-decision-trees-and-other-emerging-topics-in-ai-interpretability-9ab1eaf14d3e?source=collection_archive---------6-----------------------#2024-06-13](https://towardsdatascience.com/sparse-autoencoders-additive-decision-trees-and-other-emerging-topics-in-ai-interpretability-9ab1eaf14d3e?source=collection_archive---------6-----------------------#2024-06-13)
- en: '[](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[![TDS
    编辑](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    [TDS 编辑](https://towardsdatascience.medium.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    ·4 min read·Jun 13, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    ·以 [时事通讯](/newsletter?source=post_page---byline--9ab1eaf14d3e--------------------------------)
    形式发送 ·阅读时间 4 分钟 ·2024年6月13日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Feeling inspired to write your first TDS post?* [*We’re always open to contributions
    from new authors*](http://bit.ly/write-for-tds)*.*'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*想要写你的第一篇 TDS 文章吗？* [*我们始终欢迎新作者的投稿*](http://bit.ly/write-for-tds)*。*'
- en: As LLMs get bigger and AI applications more powerful, the quest to better understand
    their inner workings becomes harder — and more acute. Conversations around the
    risks of black-box models aren’t exactly new, but as the footprint of AI-powered
    tools continues to grow, and as hallucinations and other suboptimal outputs make
    their way into browsers and UIs with alarming frequency, it’s more important than
    ever for practitioners (and end users) to resist the temptation to accept AI-generated
    content at face value.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大规模语言模型（LLM）变得越来越庞大，AI 应用变得更加强大，理解其内部机制的探索变得更加困难且更加紧迫。关于黑箱模型风险的讨论并不是什么新鲜话题，但随着
    AI 驱动工具的影响力不断扩大，幻觉现象和其他次优输出频繁出现在浏览器和用户界面中，这使得从业者（和最终用户）比以往任何时候都更加重要，必须抵制接受 AI
    生成内容的表面价值。
- en: Our lineup of weekly highlights digs deep into the problem of model interpretability
    and explainability in the age of widespread LLM use. From detailed analyses of
    an influential new paper to hands-on experiments with other recent techniques,
    we hope you take some time to explore this ever-crucial topic.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的每周亮点栏目深入探讨了在广泛使用大规模语言模型时代，模型可解释性和解释性的问题。从对一篇有影响力的新论文的详细分析，到使用其他近期技术的实践实验，我们希望你能花时间探索这一日益重要的话题。
- en: '[**Deep Dive into Anthropic’s Sparse Autoencoders by Hand**](/deep-dive-into-anthropics-sparse-autoencoders-by-hand-️-eebe0ef59709)Within
    a few short weeks, Anthropic’s “Scaling Monosemanticity” paper has attracted a
    lot of attention within the XAI community. [Srijanie Dey, PhD](https://medium.com/u/d60d06fe8655?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    presents a beginner-friendly primer for anyone interested in the researchers’
    claims and goals, and in how they came up with an “innovative approach to understanding
    how different components in a neural network interact with one another and what
    role each component plays.”'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**手动深入探索Anthropic的稀疏自编码器**](/deep-dive-into-anthropics-sparse-autoencoders-by-hand-️-eebe0ef59709)在短短几周内，Anthropic的“单义性扩展”论文吸引了XAI社区的广泛关注。[Srijanie
    Dey博士](https://medium.com/u/d60d06fe8655?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)为任何对研究人员的主张和目标感兴趣的人提供了一份面向初学者的介绍，并展示了他们是如何提出“创新方法来理解神经网络中不同组件如何相互作用以及每个组件的角色”的。'
- en: '[**Interpretable Features in Large Language Models**](/interpretable-features-in-large-language-models-377fb25c72eb)For
    a high-level, well-illustrated explainer on the “Scaling Monosemanticity” paper’s
    theoretical underpinnings, we highly recommend [Jeremi Nuer](https://medium.com/u/7ce320f77bc9?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)’s
    debut TDS article—you’ll leave it with a firm grasp of the researchers’ thinking
    and of this work’s stakes for future model development: “as improvements plateau
    and it becomes more difficult to scale LLMs, it will be important to truly understand
    how they work if we want to make the next leap in performance.”'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**大型语言模型中的可解释特征**](/interpretable-features-in-large-language-models-377fb25c72eb)对于“单义性扩展”论文的理论基础，若想获取一篇高水平、图文并茂的解析文章，我们强烈推荐[Jeremi
    Nuer](https://medium.com/u/7ce320f77bc9?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)的TDS首篇文章——阅读之后，你将对研究人员的思路以及该研究对未来模型发展的意义有一个清晰的了解：“随着改进停滞，且大规模语言模型越来越难以扩展，如果我们希望在性能上实现下一次飞跃，真正理解它们的工作原理将变得至关重要。”'
- en: '[**The Meaning of Explainability for AI**](/the-meaning-of-explainability-for-ai-d8ae809c97fa)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**人工智能可解释性的意义**](/the-meaning-of-explainability-for-ai-d8ae809c97fa)'
- en: Taking a few helpful steps back from specific models and the technical challenges
    they create in their wake, [Stephanie Kirmer](https://medium.com/u/a8dc77209ef3?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    gets “a bit philosophical” in her article about the limits of interpretability;
    attempts to illuminate those black-box models might never achieve full transparency,
    she argues, but are still important for ML researchers and developers to invest
    in.
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[斯蒂芬妮·基尔默](https://medium.com/u/a8dc77209ef3?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)从特定模型及其带来的技术挑战中抽身，稍微“哲学化”了一些，在她关于可解释性局限性的文章中提出；她认为，试图揭示这些黑箱模型的努力可能永远无法实现完全的透明度，但仍然对机器学习研究人员和开发者而言非常重要，值得投入研究。'
- en: '![](../Images/cb75693400faf7951b95020c81f00e96.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb75693400faf7951b95020c81f00e96.png)'
- en: Photo by [Joanna Kosinska](https://unsplash.com/@joannakosinska?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[乔安娜·科辛斯卡](https://unsplash.com/@joannakosinska?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '[**Additive Decision Trees**](/additive-decision-trees-85f2feda2223)In his
    recent work, [W Brett Kennedy](https://medium.com/u/5176dd5e0bcf?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    has been focusing on interpretable predictive models, unpacking their underlying
    math and showing how they work in practice. His recent deep dive on additive decision
    trees is a powerful and thorough introduction to such a model, showing how it
    aims to supplement the limited available options for interpretable classification
    and regression models.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**加性决策树**](/additive-decision-trees-85f2feda2223)在他最近的研究中，[W·布雷特·肯尼迪](https://medium.com/u/5176dd5e0bcf?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)一直专注于可解释的预测模型，剖析其底层数学，并展示它们在实践中的工作原理。他对加性决策树的深入研究是对这种模型的有力且全面的介绍，展示了它如何旨在补充有限的可解释分类和回归模型选项。'
- en: '[**Deep Dive on Accumulated Local Effect Plots (ALEs) with Python**](/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee)To
    round out our selection, we’re thrilled to share [Conor O''Sullivan](https://medium.com/u/4ae48256fb37?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)’s
    hands-on exploration of accumulated local effect plots (ALEs): an older, but dependable
    method for providing clear interpretations even in the presence of multicollinearity
    in your model.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**深度解析累计局部效应图（ALEs）与Python**](/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee)为了丰富我们的内容，我们非常高兴地分享[Conor
    O''Sullivan](https://medium.com/u/4ae48256fb37?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)关于累计局部效应图（ALEs）的动手探索：一种较老但可靠的方法，即使在模型中存在多重共线性的情况下，也能提供清晰的解释。'
- en: Interested in digging into some other topics this week? From quantization to
    Pokémon optimization strategies, we’ve got you covered!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本周有兴趣深入了解其他话题吗？从量化到宝可梦优化策略，我们都有涉及！
- en: In a fascinating project walkthrough, [Parvathy Krishnan](https://medium.com/u/102000f20d44?source=post_page---user_mention--9ab1eaf14d3e--------------------------------),
    Joaquim Gromicho, and Kai Kaiser show [how they’ve combined several geospatial
    datasets and some Python](/an-open-data-driven-approach-to-optimising-healthcare-facility-locations-using-python-397b3ce38185)
    to optimize the process of selecting healthcare-facility locations.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个令人着迷的项目演示中，[Parvathy Krishnan](https://medium.com/u/102000f20d44?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)、Joaquim
    Gromicho和Kai Kaiser展示了[他们如何结合多个地理空间数据集和一些Python](/an-open-data-driven-approach-to-optimising-healthcare-facility-locations-using-python-397b3ce38185)来优化选择医疗设施位置的过程。
- en: Learn [how weight quantization works and how to apply it](/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1)
    in real-world deep learning workflows — [Chien Vu](https://medium.com/u/f2928e8b6c04?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)’s
    tutorial is both thorough and accessible.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习[权重量化如何工作以及如何应用](/optimizing-deep-learning-models-with-weight-quantization-c786ffc6d6c1)于实际的深度学习工作流程中——[Chien
    Vu](https://medium.com/u/f2928e8b6c04?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)的教程既详尽又易懂。
- en: The knapsack problem is a classic optimization challenge; [Maria Mouschoutzi,
    PhD](https://medium.com/u/dce3cb684eae?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    approaches it with a fun new twist, showing how to create the most powerful Pokémon
    team [with the aid of modeling and PuLP, a Python optimization framework](/how-many-pokémon-fit-84f812c0387e).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 背包问题是一个经典的优化挑战；[Maria Mouschoutzi博士](https://medium.com/u/dce3cb684eae?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)为此提出了一个有趣的新角度，展示了如何通过[建模和PuLP，一个Python优化框架](/how-many-pokémon-fit-84f812c0387e)来创建最强大的宝可梦团队。
- en: Squeezing the most value out of RAG systems continues to be a top priority for
    many ML professionals. [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    takes a close look at [potential solutions for measuring context relevance](/the-challenges-of-retrieving-and-evaluating-relevant-context-for-rag-e362f6eaed34).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于许多机器学习专业人士来说，从RAG系统中挤出最大价值仍然是一个重要的优先事项。[Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)仔细分析了[衡量上下文相关性](/the-challenges-of-retrieving-and-evaluating-relevant-context-for-rag-e362f6eaed34)的潜在解决方案。
- en: 'After more than a decade as a data leader at tech giants and high-growth startups,
    [Torsten Walbaum](https://medium.com/u/4e291ce6380c?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    offers the [insights he’s accumulated around a fundamental question](/the-ultimate-guide-to-making-sense-of-data-aaa121db1119):
    how do we make sense of data?'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在作为技术巨头和高速成长初创公司数据领导者十多年后，[Torsten Walbaum](https://medium.com/u/4e291ce6380c?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)分享了[他在一个基本问题上积累的见解](/the-ultimate-guide-to-making-sense-of-data-aaa121db1119)：我们如何理解数据？
- en: Data analysts might not often think of themselves as programmers, but [there’s
    still a lot of room for cross-disciplinary learning](/from-code-to-insights-software-engineering-best-practices-for-data-analysts-0dd6a2aaadfc)—as
    [Mariya Mansurova](https://medium.com/u/15a29a4fc6ad?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)
    demonstrates in a data-focused roundup of software-engineering best practices.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析师可能不常把自己当作程序员，但[跨学科学习仍然有很大的空间](/from-code-to-insights-software-engineering-best-practices-for-data-analysts-0dd6a2aaadfc)—正如[玛丽亚·曼苏罗娃](https://medium.com/u/15a29a4fc6ad?source=post_page---user_mention--9ab1eaf14d3e--------------------------------)在一篇数据聚焦的软件工程最佳实践总结中所展示的。
- en: Thank you for supporting the work of our authors! We love publishing articles
    from new authors, so if you’ve recently written an interesting project walkthrough,
    tutorial, or theoretical reflection on any of our core topics, don’t hesitate
    to [share it with us](http://bit.ly/write-for-tds).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你支持我们作者的工作！我们喜欢发布新作者的文章，所以如果你最近写了一篇有趣的项目教程、教程或关于我们核心主题的理论思考，不要犹豫，[与我们分享](http://bit.ly/write-for-tds)。
- en: Until the next Variable,
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 直到下一个变量，
- en: TDS Team
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: TDS 团队
