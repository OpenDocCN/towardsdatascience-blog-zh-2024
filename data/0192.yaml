- en: Generating Images with Stable Diffusion and OnnxStream on the Raspberry Pi
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在树莓派上使用 Stable Diffusion 和 OnnxStream 生成图像
- en: 原文：[https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20](https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20](https://towardsdatascience.com/generating-images-with-stable-diffusion-and-onnxstream-on-the-raspberry-pi-f126636b6c0c?source=collection_archive---------4-----------------------#2024-01-20)
- en: '**Learn how to use OnnxStream to generate images with Stable Diffusion XL Turbo
    on the Raspberry Pi!**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**学习如何使用 OnnxStream 在树莓派上生成图像，利用 Stable Diffusion XL Turbo！**'
- en: '[](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[![Pye
    Sone Kyaw](../Images/907574a7d2de57a4cc0ce36d73234a7a.png)](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    [Pye Sone Kyaw](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[![Pye
    Sone Kyaw](../Images/907574a7d2de57a4cc0ce36d73234a7a.png)](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    [Pye Sone Kyaw](https://medium.com/@pyesonekyaw?source=post_page---byline--f126636b6c0c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    ·5 min read·Jan 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f126636b6c0c--------------------------------)
    ·5 分钟阅读·2024年1月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9dea536f7bcfc9ad472de762c24c95ad.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9dea536f7bcfc9ad472de762c24c95ad.png)'
- en: 'Images generated using SDXL Turbo on the Raspberry Pi, each taking ~3 minutes
    | Source: Author'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SDXL Turbo 在树莓派上生成的图像，每张大约需要 3 分钟 | 来源：作者
- en: '[In my last article, I shared how to run large language models and vision language
    models on the Raspberry Pi](/running-local-llms-and-vlms-on-the-raspberry-pi-57bd0059c41a).
    This time around, instead of LLMs and VLMs, we shall run an image generation model
    — [Stable Diffusion XL (SDXL) Turbo](https://stability.ai/news/stability-ai-sdxl-turbo)
    — on the Raspberry Pi 5\. It’s another impossible sounding feat, but open-source
    wonders do exist, and running a SDXL Turbo model on a very resource constrained
    environment is one of them.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[在我上一篇文章中，我分享了如何在树莓派上运行大型语言模型和视觉语言模型](/running-local-llms-and-vlms-on-the-raspberry-pi-57bd0059c41a)。这一次，我们不使用
    LLMs 和 VLMs，而是运行一个图像生成模型 —— [Stable Diffusion XL (SDXL) Turbo](https://stability.ai/news/stability-ai-sdxl-turbo)
    —— 在树莓派 5 上。这听起来像是一个不可能完成的壮举，但开源的奇迹确实存在，在资源极为有限的环境中运行 SDXL Turbo 模型就是其中之一。'
- en: '**OnnxStream**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**OnnxStream**'
- en: '[OnnxStream](https://github.com/vitoplantamura/OnnxStream#stable-diffusion-xl-10-base)
    is an open-source project created by Vito Plantamura with the original intention
    of running Stable Diffusion 1.5 (SD1.5) on a Raspberry Pi Zero 2 by minimising
    memory consumption as much as possible, albeit at the cost of increased inference
    latency/throughput.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[OnnxStream](https://github.com/vitoplantamura/OnnxStream#stable-diffusion-xl-10-base)
    是一个由 Vito Plantamura 创建的开源项目，最初的目的是通过尽可能减少内存消耗，在树莓派 Zero 2 上运行 Stable Diffusion
    1.5（SD1.5），尽管这样会以增加推理延迟/吞吐量为代价。'
- en: At the time of writing, it has expanded to support not only Stable Diffusion
    1.5 but also Stable Diffusion XL 1.0 Base (SDXL) and Stable Diffusion XL Turbo
    1.0\. I won’t go into detail about how exactly this amazing feat is being achieved
    since the [GitHub repository](https://github.com/vitoplantamura/OnnxStream) already
    explains it very well.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，它已经扩展到不仅支持 Stable Diffusion 1.5，还支持 Stable Diffusion XL 1.0 Base（SDXL）和
    Stable Diffusion XL Turbo 1.0。我不会详细讲解这个惊人壮举是如何实现的，因为 [GitHub 仓库](https://github.com/vitoplantamura/OnnxStream)
    已经解释得非常清楚了。
- en: Instead, let’s just jump right into getting it working.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们直接进入实际操作。
- en: '**Technical Requirements**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**技术要求**'
- en: 'All you need is the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要以下内容：
- en: Raspberry Pi 5 — Or Raspberry Pi 4 or any other Raspberry Pi, just expect it
    to be slower
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树莓派 5 — 或树莓派 4 或任何其他树莓派，只有预期速度会较慢
- en: SD Card — Minimally 16GB, with Raspbian or some Linux distro already setup.
    The SDXL Turbo weights are around 8GB.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SD 卡 — 至少 16GB，已经设置了 Raspbian 或其他 Linux 发行版。SDXL Turbo 的权重大约为 8GB。
- en: An internet connection
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要互联网连接
- en: '![](../Images/e96b30f0366c093aa74449de91faba28.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e96b30f0366c093aa74449de91faba28.png)'
- en: 'Images generated in a single diffusion step on the Raspberry Pi | Source: Author'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在树莓派上通过单步扩散生成的图像 | 来源：作者
- en: '**Setting Up OnnxStream**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**设置 OnnxStream**'
- en: The instructions here are from the GitHub repository, but I’m breaking it down
    and explaining it a bit more.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的指令来自 GitHub 仓库，但我会将其拆解并稍作解释。
- en: '**1\. Building XNNPack**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. 构建 XNNPack**'
- en: 'First, we have to install [XNNPack](https://github.com/google/XNNPACK), which
    is a library from Google that provides “high-efficiency floating-point neural
    network inference operators”. But we can’t just get the latest version in case
    of any breaking changes. Instead, we shall get the version that the OnnxStream
    creator has verified to be working at the time of writing. In a terminal, run:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装[XNNPack](https://github.com/google/XNNPACK)，这是 Google 提供的一个库，提供“高效的浮点神经网络推理运算符”。但我们不能直接获取最新版本，以防出现不兼容的更改。相反，我们将获取
    OnnxStream 创建者在编写时验证过的版本。在终端中运行：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: XNNPack will take a couple of minutes to build. Go get coffee or something.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 构建 XNNPack 需要几分钟时间。去喝杯咖啡或做点别的吧。
- en: '**2\. Building OnnxStream**'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2\. 构建 OnnxStream**'
- en: 'Next, we have to build OnnxStream. In a terminal, run:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要构建 OnnxStream。在终端中运行：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Make sure to replace <DIRECTORY_WHERE_XNNPACK_WAS_CLONED> with the path at which
    XNNPack was cloned to (not the build folder). In my case, it was at /home/admin/XNNPACK/.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将<DIRECTORY_WHERE_XNNPACK_WAS_CLONED>替换为XNNPack克隆路径（不是构建文件夹）。在我的例子中，它位于 /home/admin/XNNPACK/。
- en: '**3\. Downloading Model Weights**'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3\. 下载模型权重**'
- en: 'Now, we need to download the model weights for SDXL Turbo. In a terminal, run:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要下载 SDXL Turbo 的模型权重。在终端中运行：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you have not installed git-lfs yet, do so first. This will take even longer
    than the step before since the model weights are quite big. Go get lunch!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有安装 git-lfs，先安装它。由于模型权重非常大，这一步比前一步还要耗时。去吃个午饭吧！
- en: You can also run the other two models supported — Stable Diffusion 1.5 and Stable
    Diffusion XL 1.0 Base by downloading their weights from the links provided in
    [OnnxStream’s GitHub repository](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux).
    Make sure your SD card has enough space if you are downloading all these models!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以运行其他两个支持的模型——Stable Diffusion 1.5 和 Stable Diffusion XL 1.0 Base，通过从[OnnxStream
    的 GitHub 仓库](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux)提供的链接下载它们的权重。如果你要下载所有这些模型，请确保你的
    SD 卡有足够的空间！
- en: Once done, that’s it! We are ready to generate images on a Raspberry Pi!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，就可以开始了！我们准备好在树莓派上生成图像了！
- en: '**Generating Images**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**生成图像**'
- en: 'To generate images, run the code block below:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成图像，请运行以下代码块：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Replace the prompt with what you want to generate. I’m just using the go-to
    classic astronaut prompt here. I set steps to just 1 as SDXL Turbo doesn’t need
    many steps to generate a good-looking image.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 将提示词替换为你想要生成的内容。我这里只是使用了经典的宇航员提示词。由于 SDXL Turbo 不需要太多步数就能生成好看的图像，所以我将 steps
    设置为 1。
- en: There are other arguments you can pass too, such as — neg-prompt for negative
    prompts (SDXL Turbo does not support negative prompts but you can use it for the
    other two models), — steps to set the number of generative steps and — seed to
    set the random seed.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以传递其他参数，如 — neg-prompt 用于负向提示（SDXL Turbo 不支持负向提示，但你可以在其他两个模型中使用），— steps
    设置生成步数，— seed 设置随机种子。
- en: The arguments required will change according to the type of model used, so please
    take a look at [OnnxStream’s GitHub repository](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux)
    for the full list of arguments to pass if you’re using something other than SDXL
    Turbo.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的参数将根据使用的模型类型而变化，因此请查看[OnnxStream 的 GitHub 仓库](https://github.com/vitoplantamura/OnnxStream#how-to-build-the-stable-diffusion-example-on-linuxmacwindowstermux)，了解如果你使用的是非
    SDXL Turbo 的模型所需传递的完整参数列表。
- en: '![](../Images/c6bae00f3eaaaede4564ee9063047aad.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6bae00f3eaaaede4564ee9063047aad.png)'
- en: 'You should get an output like this | Source: Author'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会得到类似这样的输出 | 来源：作者
- en: As you can see in the image above, on the Raspberry Pi 5, each diffusion step
    takes around 1 minute, and in total with pre-processing and decoding, it around
    3 minutes to generate a single image.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，在树莓派5上，每个扩散步骤大约需要1分钟，总体加上预处理和解码，生成一张图像大约需要3分钟。
- en: '![](../Images/a016aa96a094a749b8c3aac1a8ac117d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a016aa96a094a749b8c3aac1a8ac117d.png)'
- en: 'Image with 1, 2, 5, and 10 steps respectively, using the same seed and prompt
    | Source: Author'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同种子和提示，分别经过1、2、5和10步生成的图像 | 来源：作者
- en: Here’s a comparison and progression of the same prompt with the same seed from
    step 1 to 10\. You can see that even with a single step with refinement, the generated
    image is already really well-done. This is in contrast to SDXL or SD1.5 which
    requires quite a few steps to reach that quality.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从第1步到第10步，相同种子和提示下生成的图像对比和进展。你可以看到，即使只是经过一步的优化，生成的图像已经非常精美。这与SDXL或SD1.5不同，后者需要更多的步骤才能达到这样的质量。
- en: '**Conclusion**'
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: With it taking around at least a couple of minutes to generate an image, the
    question of use cases for it comes begging.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生成一张图像大约需要几分钟时间，因此关于它的使用场景问题不容忽视。
- en: '![](../Images/b138fcad68e649f781cde62d61d153ab.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b138fcad68e649f781cde62d61d153ab.png)'
- en: 'Obligatory shot of my Raspberry Pi 5 | Source: Author'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 必不可少的我的树莓派5照片 | 来源：作者
- en: The most obvious and fun use case to me is an ever-changing photo frame that
    will generate a new image every few minutes. There is actually a [project along
    this tangent](https://github.com/rvdveen/epaper-slow-generative-art) that uses
    OnnxStream, by rvdveen on GitHub, where he uses OnnxStream on a Raspberry Pi Zero
    2 W to generate images for news articles and shows it on a photo frame using an
    e-ink display. It takes around 5 hours to generate an image on the Pi Zero 2 W
    with what should be SD1.5, but hey it’s not like you need a photo frame to be
    changing what it’s showing in real-time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，最明显和有趣的使用场景是一个不断变化的照片框架，每隔几分钟生成一张新图像。实际上，有一个[类似的项目](https://github.com/rvdveen/epaper-slow-generative-art)，由GitHub上的rvdveen开发，使用OnnxStream，通过树莓派Zero
    2 W生成新闻文章的图像，并通过电子墨水显示器显示在照片框架上。使用SD1.5生成图像大约需要5小时，但嘿，你不需要照片框架实时更换显示的内容。
- en: Or maybe you just want your own locally hosted image generator which can produce
    decent quality images while not hogging any major compute devices on your network.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 或许你只是想要一个本地托管的图像生成器，它可以在不占用网络上主要计算设备的情况下生成高质量的图像。
- en: Have fun playing around with SDXL Turbo on the Raspberry Pi!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在树莓派上玩SDXL Turbo，玩得开心！
- en: '**Disclaimer**: I have no affiliation with OnnxStream or StabilityAI. All views
    and opinions are my own and do not represent any organisation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明**：我与OnnxStream或StabilityAI没有任何关联。所有观点和意见均为我个人的，并不代表任何组织。'
