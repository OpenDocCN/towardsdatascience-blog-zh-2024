- en: Using Generative AI to Automatically Create a Video Talk from an Article
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成式AI从文章中自动创建视频讲座
- en: 原文：[https://towardsdatascience.com/using-generative-ai-to-automatically-create-a-video-talk-from-an-article-6381c44c5fe0?source=collection_archive---------2-----------------------#2024-09-22](https://towardsdatascience.com/using-generative-ai-to-automatically-create-a-video-talk-from-an-article-6381c44c5fe0?source=collection_archive---------2-----------------------#2024-09-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-generative-ai-to-automatically-create-a-video-talk-from-an-article-6381c44c5fe0?source=collection_archive---------2-----------------------#2024-09-22](https://towardsdatascience.com/using-generative-ai-to-automatically-create-a-video-talk-from-an-article-6381c44c5fe0?source=collection_archive---------2-----------------------#2024-09-22)
- en: Using Gemini + Text to Speech + MoviePy to create a video, and what this says
    about what GenAI is becoming rapidly useful for
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Gemini + 文本转语音 + MoviePy创建视频，以及这对生成式AI（GenAI）迅速变得有用的意义
- en: '[](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--6381c44c5fe0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)
    ·10 min read·Sep 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6381c44c5fe0--------------------------------)
    ·10分钟阅读·2024年9月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Like most everyone, I was flabbergasted by [NotebookLM and its ability to generate
    a podcast](https://blog.google/technology/ai/notebooklm-audio-overviews/) from
    a set of documents. And then, I got to thinking: “how do they do that, and where
    can I get some of that magic?” How easy would it be to replicate?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 像大多数人一样，我对[NotebookLM及其生成播客的能力](https://blog.google/technology/ai/notebooklm-audio-overviews/)感到震惊。然后，我开始思考：“他们是怎么做到的？我在哪里可以获得这种魔力？”复制这一过程会有多容易？
- en: 'Goal: Create a video talk from an article'
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标：从文章中创建视频讲座
- en: I don’t want to create a podcast, but I’ve often wished I could generate slides
    and a video talk from my blog posts —some people prefer paging through slides,
    and others prefer to watch videos, and this would be a good way to meet them where
    they are. In this article, I’ll show you how to do this.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想创建播客，但我常常希望能够从我的博客文章中生成幻灯片和视频讲座——有些人喜欢翻阅幻灯片，另一些人则喜欢观看视频，这将是一个很好的方式来满足他们的需求。在本文中，我将展示如何做到这一点。
- en: 'The [full code for this article](https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb)
    is on GitHub — in case you want to follow along with me. And the goal is to create
    this video from [this article](https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的[完整代码](https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb)在GitHub上——如果你想和我一起操作，可以参考。目标是从[这篇文章](https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc)创建视频：
- en: Video created automatically using the code described in this article. Video
    generated by author.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 视频是使用本文描述的代码自动创建的。视频由作者生成。
- en: 1\. Initialize the LLM
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 初始化LLM
- en: I am going to use Google Gemini Flash because (a) it is the least expensive
    frontier LLM today, (b) it’s multimodal in that it can read and understand images
    also, and (c) it supports controlled generation, meaning that we can make sure
    the output of the LLM matches a desired structure.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用Google Gemini Flash，因为（a）它是目前最便宜的前沿LLM，（b）它是多模态的，能够读取和理解图像，（c）它支持受控生成，这意味着我们可以确保LLM的输出符合预期的结构。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that I’m using Google Generative AI and not Google Cloud Vertex AI. The
    two packages are different. The Google one supports Pydantic objects for controlled
    generation; the Vertex AI one only supports JSON for now.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我使用的是 Google Generative AI，而不是 Google Cloud Vertex AI。这两个包是不同的。Google 的那个支持用于受控生成的
    Pydantic 对象；而 Vertex AI 目前只支持 JSON。
- en: 2\. Get a PDF of the article
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 获取文章的 PDF 文件
- en: 'I used Python to download the article as a PDF, and upload it to a temporary
    storage location that Gemini can read:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 Python 下载了文章并保存为 PDF，然后将其上传到 Gemini 可以读取的临时存储位置：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Unfortunately, something about medium prevents pdfkit from getting the images
    in the article (perhaps because they are webm and not png …). So, my slides are
    going to be based on just the text of the article and not the images.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于 Medium 的一些原因，pdfkit 无法获取文章中的图片（可能是因为它们是 webm 格式而不是 png 格式……）。所以，我的幻灯片将仅基于文章的文本，而不包含图片。
- en: 3\. Create lecture notes in JSON
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 创建 JSON 格式的讲义
- en: Here, the data format I want is a set of slides each of which has a title, key
    points, and a set of lecture notes. The lecture as a whole has a title and an
    attribution also.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我需要的数据格式是每一页幻灯片都有一个标题、要点和一组讲义。整个讲座也应该有一个标题和归属。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s tell Gemini what we want it to do:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们告诉 Gemini 我们希望它做什么：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The prompt is pretty straightforward — ask Gemini to read the article, extract
    key points and create lecture notes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示词相当简单——要求 Gemini 阅读文章，提取要点并创建讲义。
- en: 'Now, invoke the model, passing in the PDF file and asking it to populate the
    desired structure:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调用模型，传入 PDF 文件，并要求它填充所需的结构：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A few things to note about the code above:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码需要注意的几点：
- en: We pass in the prompt as the system prompt, so that we don’t need to keep sending
    in the prompt with new inputs.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将提示词作为系统提示传递，这样就不需要在每次输入时都传入新的提示词。
- en: We specify the desired response type as JSON, and the schema to be a Pydantic
    object
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将期望的响应类型指定为 JSON，模式为 Pydantic 对象
- en: We send the PDF file to the model and tell it generate a response. We’ll wait
    for it to complete (no need to stream)
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将 PDF 文件发送给模型，并告诉它生成响应。我们会等待它完成（无需流式传输）。
- en: 'The result is JSON, so extract it into a Python object:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 JSON 格式，因此可以将其提取为一个 Python 对象：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For example, this is what the 3rd slide looks like:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是第三张幻灯片的样子：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 4\. Convert to PowerPoint
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 转换为 PowerPoint
- en: 'We can use the Python package pptx to create a Presentation with notes and
    bullet points. The code to create a slide looks like this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Python 包 pptx 创建带有讲义和要点的演示文稿。创建幻灯片的代码如下：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result is a PowerPoint presentation that looks like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个 PowerPoint 演示文稿，格式如下：
- en: '![](../Images/532193d938ec39c67ae8e4b4c5ca81e8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/532193d938ec39c67ae8e4b4c5ca81e8.png)'
- en: The PowerPoint file that was generated from the keypoints and lecture notes.
    Screenshot by author.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从要点和讲义生成的 PowerPoint 文件。截图由作者提供。
- en: Not very fancy, but definitely a great starting point for editing if you are
    going to give a talk.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 并不复杂，但如果你要做演讲，这绝对是一个很好的起点，可以用于编辑。
- en: 5\. Read the notes aloud and save audio
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 大声朗读笔记并保存音频
- en: Well, we were inspired by a podcast, so let’s see how to create just an audio
    of someone summarizing the article.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们的灵感来源于播客，所以我们来看看如何只制作一个有人总结文章的音频。
- en: We already have the lecture notes, so let’s create audio files of each of the
    slides.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了讲义，所以我们来为每一张幻灯片创建音频文件。
- en: 'Here’s the code to take some text, and have an AI voice read it out. We save
    the resulting audio into an mp3 file:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用来将一些文本转化为 AI 语音并朗读出来的代码。我们将生成的音频保存为 mp3 文件：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: What’s happening in the code above?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码发生了什么？
- en: We are using Google Cloud’s text to speech API
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用的是 Google Cloud 的文字转语音 API
- en: Asking it to use a standard US accent female voice. If you were doing a podcast,
    you’d pass in a “speaker map” here, one voice for each speaker.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求它使用标准的美国口音女性声音。如果你是在做播客，你可以在这里传入一个“说话者映射”，每个说话者对应一种声音。
- en: We then give it in the input text, ask it generate audio
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们将其作为输入文本，要求它生成音频。
- en: Save the audio as an mp3 file. Note that this has to match the audio encoding.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将音频保存为 mp3 文件。请注意，这必须与音频编码匹配。
- en: 'Now, create audio by iterating through the slides, and passing in the lecture
    notes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，遍历幻灯片并传入讲义，生成音频：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result is a bunch of audio files. You can concatenate them if you wish
    using pydub:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一堆音频文件。你可以使用 pydub 将它们连接在一起：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: But it turned out that I didn’t need to. The individual audio files, one for
    each slide, were what I needed to create a video. For a podcast, of course, you’d
    want a single mp3 or wav file.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 但结果是我并不需要这么做。每张幻灯片的单独音频文件，正是我需要用来创建视频的内容。当然，对于播客，你会希望有一个单一的mp3或wav文件。
- en: 6\. Create images of the slides
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 创建幻灯片图像
- en: 'Rather annoyingly, there’s no easy way to render PowerPoint slides as images
    using Python. You need a machine with Office software installed to do that — not
    the kind of thing that’s easily automatable. Maybe I should have used Google Slides
    … Anyway, a simple way to render images is to use the Python Image Library (PIL):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有点烦人的是，使用Python将PowerPoint幻灯片渲染为图像没有简单的办法。你需要一台安装了Office软件的机器来完成这个任务——这不是一种容易自动化的操作。也许我应该使用Google
    Slides…无论如何，渲染图像的简单方法是使用Python图像库（PIL）：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The resulting image is not great, but it is serviceable (you can tell no one
    pays me to write production code anymore):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像效果不算很好，但还算能用（你可以看出来，现在没有人支付我写生产级代码了）：
- en: '![](../Images/417e2c0e11b84caacc8069f9a4e922d8.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/417e2c0e11b84caacc8069f9a4e922d8.png)'
- en: The images used along with the audio clips look like this. Image generated by
    author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与音频片段一起使用的图像是这样的。图像由作者生成。
- en: 7\. Create a Video
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 创建视频
- en: 'Now that we have a set of audio files and a set of image files, we can use
    a Python package moviepy to create a video clip:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一组音频文件和图像文件，可以使用Python包moviepy来创建一个视频片段：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And we can now write it out:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以写出来了：
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'End result? We have four artifacts, all created automatically from the article.pdf:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果？我们从article.pdf自动生成了四个产物：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There’s:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 包括：
- en: a JSON file with keypoints, lecture notes, etc.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含关键点、讲义等内容的JSON文件
- en: A PowerPoint file that you can modify. The slides have the key points, and the
    notes section of the slides has the “lecture notes”
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以修改的PowerPoint文件。幻灯片上有关键点，幻灯片的注释部分则包含“讲义”内容。
- en: An audio file consisting of an AI voice reading out the lecture notes
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个由AI语音朗读讲义的音频文件
- en: A mp4 movie (that I uploaded to YouTube) of the audio + images. This is the
    video talk that I set out to create.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一部mp4电影（我上传到YouTube）包含音频和图像。这就是我打算创建的视频讲座。
- en: Pretty cool, eh?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷吧？
- en: 8\. What this says about the future of software
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 这对软件未来的意义
- en: We are all, as a community, probing around to find what this really cool technology
    (generative AI) can be used for. Obviously, you can use it to create content,
    but the content that it creates is good for brainstorming, but not to use as-is.
    Three years of improvements in the tech have not solved the problem that GenAI
    generates blah content, and not-ready-to-use code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们作为一个社区，正在探索这项非常酷的技术（生成式AI）可以用于什么。显然，你可以用它来创建内容，但它创建的内容适合用于头脑风暴，而不能直接使用。三年的技术进步并没有解决GenAI生成空洞内容和不成熟代码的问题。
- en: That brings us to some of the ancillary capabilities that GenAI has opened up.
    And these turn out to be extremely useful. There are four capabilities of GenAI
    that this post illustrates.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这带我们进入了GenAI所打开的一些辅助功能。而这些功能非常有用。本文展示了GenAI的四个功能。
- en: '**(1) Translating unstructured data to structured data**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**(1) 将非结构化数据转化为结构化数据**'
- en: The Attention paper was written to solve the translation problem, and it turns
    out transformer-based models are really good at translation. We keep discovering
    use cases of this. But not just [Japanese to English](https://mse238blog.stanford.edu/2017/08/jchoi8/machine-learning-transforms-google-translate-overnight/),
    but also [Java 11 to Java 17](https://digiday.com/media/how-amazons-genai-tool-for-developers-is-saving-4500-years-of-work-260-million-annually/),
    of [text to SQL](https://paperswithcode.com/task/text-to-sql), of text to speech,
    between database dialects, …, and now of articles to audio-scripts. This, it turns
    out is the stepping point of using GenAI to create podcasts, lectures, videos,
    etc.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 《Attention》论文是为了解决翻译问题而写的，结果发现基于Transformer的模型在翻译方面表现非常优秀。我们不断发现这个技术的应用场景。但不仅仅是[日语到英语](https://mse238blog.stanford.edu/2017/08/jchoi8/machine-learning-transforms-google-translate-overnight/)，还包括[Java
    11到Java 17](https://digiday.com/media/how-amazons-genai-tool-for-developers-is-saving-4500-years-of-work-260-million-annually/)，[文本到SQL](https://paperswithcode.com/task/text-to-sql)，文本到语音，不同数据库方言之间的转换，……现在，还可以将文章转为音频脚本。事实证明，这就是利用GenAI创建播客、讲座、视频等内容的起点。
- en: All I had to do was to prompt the LLM to construct a series of slide contents
    (keypoints, title, etc.) from the article, and it did. It even returned the data
    to me in structured format, conducive to using it from a computer program. Specifically,
    *GenAI is really good at translating unstructured data to structured data*.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我所要做的就是提示LLM从文章中构建一系列幻灯片内容（关键点、标题等），它就做到了。它甚至以结构化格式返回数据，便于从计算机程序中使用。具体来说，*GenAI在将非结构化数据转化为结构化数据方面非常出色*。
- en: '**(2) Code search and coding assistance are now dramatically better**'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**(2) 代码搜索和编程帮助如今变得更加出色**'
- en: 'The other thing that GenAI turns out to be really good at is at adapting code
    samples dynamically. I don’t write code to create presentations or text-to-speech
    or moviepy everyday. Two years ago, I’d have been using Google search and getting
    Stack Overflow pages and adapting the code by hand. Now, Google search is giving
    me ready-to-incorporate code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个GenAI表现得非常出色的领域是动态适配代码示例。我并不是每天都写代码来创建演示文稿、文本转语音或电影剪辑。两年前，我可能会使用谷歌搜索，查看Stack
    Overflow页面，并手动调整代码。现在，谷歌搜索直接给我提供了可以直接使用的代码：
- en: '![](../Images/318fc9e541190e93ace8486d8dcd05f1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/318fc9e541190e93ace8486d8dcd05f1.png)'
- en: Google Search returning code samples, adapated to my specific query. Screenshot
    by author.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌搜索返回了适应我特定查询的代码示例。截图来自作者。
- en: Of course, had I been using a Python IDE (rather than a Jupyter notebook), I
    could have avoided the search step completely — I could have written a comment
    and gotten the code generated for me. This is hugely helpful, and speeds up development
    using general purpose APIs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果我使用的是Python IDE（而不是Jupyter笔记本），我完全可以避免搜索步骤——我只需写一个注释，系统就会为我生成代码。这非常有帮助，并且加快了使用通用API的开发速度。
- en: '**(3) GenAI web services are robust and easy-to-consume**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**(3) GenAI Web服务既强大又易于使用**'
- en: Let’s not lose track of the fact that I used the Google Cloud Text-to-Speech
    service to turn my audio script into actual audio files. Text-to-speech is itself
    a generative AI model (and another example of the translation superpower). The
    Google TTS service which was [introduced in 2018](https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-text-to-speech-powered-by-deepmind-wavenet-technology)
    (and presumably improved since then) was one of the first generative AI services
    in production and made available through an API.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们不要忘记，我使用了谷歌云文本转语音服务将我的音频脚本转化为实际的音频文件。文本转语音本身就是一个生成式AI模型（也是翻译超级能力的另一个例子）。谷歌的TTS服务于[2018年推出](https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-text-to-speech-powered-by-deepmind-wavenet-technology)（此后可能有所改进），是最早投入生产的生成式AI服务之一，并通过API提供使用。
- en: In this article, I used two generative AI models — TTS and Gemini — that are
    made available as web services. All I had to do was to call their APIs.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我使用了两个生成式AI模型——TTS和Gemini，它们作为Web服务提供。我所需要做的就是调用它们的API。
- en: '**(4) It’s easier than ever to provide end-user customizability**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**(4) 提供最终用户定制化比以往任何时候都更加容易**'
- en: I didn’t do this, but you can squint a little and see where things are headed.
    If I’d wrapped up the presentation creation, audio creation, and movie creation
    code in services, I could have had a prompt create the function call to invoke
    these services as well. And put a request-handling agent that would allow you
    to use text to change the look-and-feel of the slides or the voice of the person
    reading the video.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有这样做，但你可以稍微眯起眼睛，看到未来的方向。如果我将演示创建、音频创建和视频创建的代码封装成服务，那么我本可以让一个提示生成调用这些服务的函数调用。同时，还可以加上一个请求处理代理，允许你通过文本来更改幻灯片的外观或视频中朗读者的声音。
- en: It becomes extremely easy to add open-ended customizability to the software
    you build.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为你构建的软件添加开放式定制化变得极其容易。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Inspired by the NotebookLM podcast feature, I set out to build an application
    that would convert my articles to video talks. The key step is to prompt an LLM
    to produce slide contents from the article, another GenAI model to convert the
    audio script into audio files, and use existing Python APIs to put them together
    into a video.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 受到NotebookLM播客功能的启发，我开始构建一个应用程序，将我的文章转化为视频讲座。关键步骤是提示LLM从文章中生成幻灯片内容，另一个GenAI模型将音频脚本转化为音频文件，并利用现有的Python
    API将它们整合成一个视频。
- en: 'This article illustrates four capabilities that GenAI is unlocking: translation
    of all kinds, coding assistance, robust web services, and end-user customizability.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了GenAI解锁的四项能力：各种类型的翻译、编程帮助、强大的Web服务和最终用户定制化。
- en: I loved being able to easily and quickly create video lectures from my articles.
    But I’m even more excited about the potential that we keep discovering in this
    new tool we have in our hands.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我很喜欢能够轻松快速地从我的文章中创建视频讲座。但我更为兴奋的是，我们在手中拥有的这一新工具中不断发现的潜力。
- en: Further Reading
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Full code for this article: [https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb](https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb)'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本文的完整代码：[https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb](https://github.com/lakshmanok/lakblogs/blob/main/genai_seminar/create_lecture.ipynb)
- en: 'The source article that I converted to a video: [https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc](https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc)'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我将这篇文章转换为视频的源文章：[https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc](https://lakshmanok.medium.com/what-goes-into-bronze-silver-and-gold-layers-of-a-medallion-data-architecture-4b6fdfb405fc)
- en: 'The resulting video: [https://youtu.be/jKzmj8-1Y9Q](https://youtu.be/jKzmj8-1Y9Q)'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的视频：[https://youtu.be/jKzmj8-1Y9Q](https://youtu.be/jKzmj8-1Y9Q)
- en: Turns out [Sascha Heyer wrote up how to use GenAI to generate a podcast](https://medium.com/google-cloud/building-a-dynamic-podcast-generator-inspired-by-googles-notebooklm-and-illuminate-e585cfcd0af1),
    which is the exact Notebook LM usecase. His approach is somewhat similar to mine,
    except that there is no video, just audio. In a cool twist, he uses his own voice
    as one of the podcast speakers!
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果发现[Sascha Heyer写了一篇关于如何使用GenAI生成播客的文章](https://medium.com/google-cloud/building-a-dynamic-podcast-generator-inspired-by-googles-notebooklm-and-illuminate-e585cfcd0af1)，这正是Notebook
    LM的使用场景。他的方法和我有些相似，区别在于没有视频，只有音频。在一个有趣的变化中，他使用了自己的声音作为播客的讲解者之一！
- en: Of course, here’s the video talk of this article created using the technique
    shown in this video. Ideally, we are pulling out code snippets and images from
    the article, but this is a start …
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，这里是用该视频中展示的技术创建的文章视频演讲。理想情况下，我们会从文章中提取代码片段和图片，但这只是一个开始……
