- en: 'A Powerful EDA Tool: Group-By Aggregation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种强大的EDA工具：分组聚合
- en: 原文：[https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04](https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04](https://towardsdatascience.com/a-powerful-eda-tool-group-by-aggregation-696736c5f3a1?source=collection_archive---------5-----------------------#2024-07-04)
- en: '![](../Images/691a811bf777523ac010794feed190fa.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/691a811bf777523ac010794feed190fa.png)'
- en: Photo by [Mourizal Zativa](https://unsplash.com/@mourimoto?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/lego-pieces?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Mourizal Zativa](https://unsplash.com/@mourimoto?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来自[Unsplash](https://unsplash.com/s/photos/lego-pieces?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Learn how to use group-by aggregation to uncover insights from your data
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习如何使用分组聚合从数据中发现洞察
- en: '[](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[![Pararawendy
    Indarjo](../Images/afba0cb7f3af9554a187bbc7a3c00e60.png)](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[![Pararawendy
    Indarjo](../Images/afba0cb7f3af9554a187bbc7a3c00e60.png)](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    [Pararawendy Indarjo](https://medium.com/@pararawendy19?source=post_page---byline--696736c5f3a1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    ·7 min read·Jul 4, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--696736c5f3a1--------------------------------)
    ·阅读时间：7分钟·2024年7月4日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Exploratory Data Analysis (EDA) is the core competency of a data analyst. Every
    day, data analysts are tasked with seeing the “unseen,” or extracting useful insights
    from a vast ocean of data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性数据分析（EDA）是数据分析师的核心能力。每天，数据分析师的任务是看到“未见之事”，或者从浩瀚的数据海洋中提取有用的洞察。
- en: 'In this regard, I’d like share a technique that I find beneficial for extracting
    relevant insights from data: group-by aggregation.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，我想分享一种我认为有助于从数据中提取相关洞察的技巧：分组聚合。
- en: 'To this end, the rest of this article will be arranged as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，本文的其余部分将按以下方式安排：
- en: Explanation of group-by aggregation in Pandas
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Pandas中进行分组聚合的解释
- en: 'The dataset: Metro Interstate Traffic'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集：地铁州际交通
- en: Metro Traffic EDA
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 地铁交通探索性数据分析（EDA）
- en: Group-By Aggregation
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分组聚合
- en: Group-by aggregation is a data manipulation technique that consists of two steps.
    First, we group the data based on the values of specific columns. Second, we perform
    some aggregation operations (e.g., sum, average, median, count unique) on top
    of the grouped data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 分组聚合是一种数据操作技巧，包含两个步骤。首先，我们根据特定列的值对数据进行分组。其次，我们在分组数据上执行一些聚合操作（例如，求和、平均、求中位数、计数唯一值等）。
- en: Group-by aggregation is especially useful when our data is granular, as in typical
    fact tables (transactions data) and time series data with narrow intervals. By
    aggregating at a higher level than raw data granularity, we can represent the
    data in a more compact way — and may distill useful insights in the process.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 分组聚合在数据粒度较细时尤其有用，典型的如事实表（交易数据）和间隔较窄的时间序列数据。通过在比原始数据粒度更高的层次进行聚合，我们可以以更紧凑的方式表示数据——并且可能在此过程中提炼出有用的洞察。
- en: In pandas, we can perform group-by aggregation using the following general syntax
    form.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas中，我们可以使用以下通用语法形式进行分组聚合。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Where `base_col` is the column whose values become the grouping basis, `agg_col`
    is the new column defined by taking `agg_func` aggregation on `ori_col` column.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，`base_col`是作为分组基础的列，`agg_col`是通过对`ori_col`列进行`agg_func`聚合后定义的新列。
- en: For example, consider the infamous Titanic dataset whose five rows are displayed
    below.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑著名的泰坦尼克号数据集，以下显示了其五行数据。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/4868ab3226336b94d70b44529881f531.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4868ab3226336b94d70b44529881f531.png)'
- en: Titanic data’s first 5 rows (Image by Author)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 泰坦尼克号数据的前5行（作者提供的图片）
- en: We can group this data by the `survived` column and then aggregate it by taking
    the median of the `fare` column to get the results below.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`survived`列对这些数据进行分组，然后通过计算`fare`列的中位数来聚合，得到以下结果。
- en: '![](../Images/11515715275245f95bac895b569a7168.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11515715275245f95bac895b569a7168.png)'
- en: Median fare of titanic passengers, by survival status (Image by Author)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 按生存状态划分的泰坦尼克号乘客票价中位数（作者提供的图片）
- en: 'Suddenly, we see an interesting insight: survived passengers have a higher
    fare median, which has more than doubled. This could be related to prioritizing
    safety boats for higher cabin class passengers (i.e., passengers with higher fare
    tickets).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 突然间，我们看到一个有趣的见解：生还的乘客有更高的票价中位数，且几乎翻倍。这可能与优先为高级舱乘客（即票价较高的乘客）提供救生艇有关。
- en: Hopefully, this simple example demonstrates the potential of group by aggregation
    in gathering insights from data. Okay then, let’s try group-by-aggregation on
    a more interesting dataset!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个简单的例子能够展示通过分组聚合从数据中提取见解的潜力。那么，现在让我们在一个更有趣的数据集上尝试一下分组聚合！
- en: The Dataset
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: We will use the Metro Interstate Traffic Volume dataset. It’s a publicly available
    dataset with a [Creative Common 4.0 license](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)
    (which allows for sharing and adaptation of the dataset for any purpose).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用地铁州际交通量数据集。这是一个公开可用的数据集，具有[创意共享4.0许可证](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)（允许以任何目的共享和修改数据集）。
- en: The dataset contains hourly Minneapolis-St Paul, MN traffic volume for westbound
    I-94, which also includes weather details from 2012–2018\. The data dictionary
    information can be found on its [UCI Machine Learning repo](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)
    page.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含2012-2018年间明尼阿波利斯-圣保罗，明尼苏达州I-94西行的每小时交通量数据，同时也包含天气详情。数据字典信息可以在其[UCI机器学习库](https://archive.ics.uci.edu/dataset/492/metro+interstate+traffic+volume)页面找到。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/32fdeb6df51b8acd7fcde2589ae5b6ff.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32fdeb6df51b8acd7fcde2589ae5b6ff.png)'
- en: Traffic data (df) head (Image by Author)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 交通数据（df）头部（作者提供的图片）
- en: For this blog demo, we will only use data from 2016 onwards, as there is missing
    traffic data from earlier periods (try to check yourself for exercise!).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个博客示例，我们将仅使用2016年及之后的数据，因为早期的交通数据缺失（自己尝试检查一下，作为练习！）。
- en: Furthermore, we will add a new column `is_congested`, which will have a value
    of 1 if the `traffic_volume` exceeds 5000 and 0 otherwise.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将添加一个新的列`is_congested`，如果`traffic_volume`超过5000，则值为1，否则为0。
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Metro Traffic EDA
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 地铁交通EDA
- en: Using group-by aggregation as the main weapon, we will try to answer the following
    analysis questions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以分组聚合作为主要方法，我们将尝试回答以下分析问题。
- en: How is the monthly progression of the traffic volume?
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交通量的月度变化如何？
- en: How is the traffic profile of each day in a week (Monday, Tuesday, etc)?
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一周内每天的交通概况如何（星期一、星期二等）？
- en: How are typical hourly traffic volume across 24 hours, broken down by weekday
    vs weekend?
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 典型的24小时交通量是如何变化的，按工作日与周末进行区分？
- en: What are the top weather conditions that correspond to higher congestion rates?
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些天气条件与更高的拥堵率相关？
- en: Monthly progression of traffic volume
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交通量的月度变化
- en: This question requires us to aggregate (sum) traffic volumes at month level.
    Because we don’t have the `month` column, we need to derive one based on `date_time`
    column.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题要求我们按月聚合（求和）交通量数据。由于我们没有`month`列，我们需要基于`date_time`列派生出该列。
- en: With `month`column in place, we can group based on this column, and take the
    sum of `traffic_volume`. The codes are given below.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有了`month`列，我们可以基于该列进行分组，并计算`traffic_volume`的总和。代码如下所示。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/dae775c6786baf7cb6a9c5ecad22263a.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dae775c6786baf7cb6a9c5ecad22263a.png)'
- en: monthly_traffic head (Image by Author)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 月度交通头部（作者提供的图片）
- en: We can draw line plot from this dataframe!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从这个数据框中绘制折线图！
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/6ab9165cf2cfe4d78db6ad1b200f250b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ab9165cf2cfe4d78db6ad1b200f250b.png)'
- en: Monthly traffic volume (Image by Author)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 月度交通量（作者提供的图片）
- en: The above visualization shows that traffic volume has generally increased over
    the months within the considered data period.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的可视化显示，在所考虑的数据期间内，交通量普遍增加。
- en: Daily traffic profile
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每日交通概况
- en: 'To analyze this, we need to create two additional columns: `date` and `dayname`.
    The former is used as the primary group-by basis, whereas the latter is used as
    a breakdown when displaying the data.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析这一点，我们需要创建两个额外的列：`date`和`dayname`。前者用作主要的分组依据，而后者用于在展示数据时进行细分。
- en: In the following codes, we define `date` and `dayname` columns. Later on, we
    group-by based on both columns to get the sum of `traffic_volume`. Note that since
    `dayname` is more coarse (higher aggregation level) than `date` , it effectively
    means we aggregate based on `date` values.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的代码中，我们定义了`date`和`dayname`列。之后，我们基于这两列进行分组，以获取`traffic_volume`的总和。请注意，由于`dayname`比`date`更粗略（聚合层级较高），实际上意味着我们是基于`date`值进行聚合的。
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/276b382c99b6e35b87a65c410af1b682.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/276b382c99b6e35b87a65c410af1b682.png)'
- en: daily_traffic head (Image by Author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: daily_traffic头部数据（图像来源：作者）
- en: The above table contains different realizations of daily total traffic volume
    per day name. Box plot visualizations are appropriate to show those variations
    of traffic volume, allowing us to comprehend how traffic volumes differ on Monday,
    Tuesday, and so on.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上表包含了按星期名称划分的每日总交通量的不同表现形式。箱形图可有效展示这些交通量的变化，让我们能够理解星期一、星期二等的交通量差异。
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/f16f99935a28b55c6b2cb92e791c7921.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f16f99935a28b55c6b2cb92e791c7921.png)'
- en: The above plot shows that all weekdays (Mon-Fri) have roughly the same traffic
    density. Weekends (Saturday and Sunday) have lower traffic, with Sunday having
    the least of the two.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示，所有工作日（周一至周五）的交通密度大致相同。周末（周六和周日）的交通较少，其中周日的交通最少。
- en: Hourly traffic patterns, broken down by weekend status
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按周末状态细分的小时交通模式
- en: Similar as previous questions, we need to engineer two new columns to answer
    this question, i.e., `hour` and `is_weekend`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的问题类似，我们需要创建两个新列来回答这个问题，即`hour`和`is_weekend`。
- en: Using the same trick, we will group by `is_weekend` and `hour` columns to get
    averages of `traffic_volume`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的技巧，我们将按`is_weekend`和`hour`列进行分组，以获取`traffic_volume`的平均值。
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/d375c70aabf7ca5a524c4d0c70828ef4.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d375c70aabf7ca5a524c4d0c70828ef4.png)'
- en: hourly_traffic head (Image by Author)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: hourly_traffic头部数据（图像来源：作者）
- en: For the visualization, we can use bar chart with break down on `is_weekend`
    flag.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对于可视化，我们可以使用条形图，并按照`is_weekend`标志进行细分。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/c34979eebbbc1661a4b9e0f846e0921b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c34979eebbbc1661a4b9e0f846e0921b.png)'
- en: Hourly traffic pattern, by weekend status (Image by Author)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 按周末状态划分的小时交通模式（图像来源：作者）
- en: 'Very interesting and rich visualization! Observations:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 非常有趣且丰富的可视化！观察结果：
- en: Weekday traffic has a bimodal distribution pattern. It reaches its highest traffic
    between 6 and 8 a.m. and 16 and 17 p.m. This is somewhat intuitive because those
    time windows represent people going to work and returning home from work.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作日的交通呈双峰分布模式。它在早上6点到8点和下午4点到5点之间达到交通量的峰值。这是直观的，因为这些时间段代表着人们上下班的时间。
- en: Weekend traffic follows a completely different pattern. It has a unimodal shape
    with a large peak window (12–17). Despite being generally inferior (less traffic)
    to weekday equivalent hours, it is worth noting that weekend traffic is actually
    higher during late-night hours (22–2). This could be because people are staying
    out until late on weekend nights.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 周末的交通遵循完全不同的模式。它呈单峰形状，且有一个较大的高峰区间（12–17点）。尽管总体上（交通量较少）低于工作日的同一时段，但值得注意的是，周末的深夜时段（22–2点）交通实际上更高。这可能是因为人们在周末晚上待得更晚。
- en: Top weather associated with congestion
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与拥堵相关的天气类型
- en: To answer this question, we need to calculate congestion rate for each weather
    condition in the dataset (utilizing `is_congested` column). Can we calculate it
    using group-by aggregation? Yes we can!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们需要计算数据集中每种天气条件下的拥堵率（利用`is_congested`列）。我们能通过分组聚合来计算吗？当然可以！
- en: The key observation to make is that the `is_congested` column is binary. Thus,
    the congestion rate can be calculated by simply averaging this column! Average
    of a binary column equals to `count(rows with value = 1)/count(all rows)` — which
    is the congestion rate definition.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的关键点是，`is_congested`列是二进制的。因此，拥堵率可以通过简单地对该列求平均值来计算！二进制列的平均值等于`count(rows
    with value = 1)/count(all rows)` —— 这就是拥堵率的定义。
- en: Based on this neat observation, all we need to do is taking the average (mean)
    of `is_congested` grouped by `weather_description`. Following that, we sort the
    results descending by `congested_rate`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一精妙的观察，我们所要做的就是按`weather_description`分组，对`is_congested`求平均值（即均值）。接下来，我们按`congested_rate`降序排列结果。
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/dcb0a5842e7936cb2dee5f7fa295da63.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcb0a5842e7936cb2dee5f7fa295da63.png)'
- en: congested_weather head (Image by Author)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 拥堵天气头（图片由作者提供）
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/b7b2ea4c435d20fdc4c0983da5822c05.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7b2ea4c435d20fdc4c0983da5822c05.png)'
- en: Top weather based on congestion rate (Image by Author)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基于拥堵率的天气排行（图片由作者提供）
- en: 'From the graph:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表来看：
- en: The top three weather conditions with the highest congestion rates are sleet,
    light shower snow, and very heavy rain.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拥堵率最高的三种天气情况是冰雹、小阵雪和暴雨。
- en: Meanwhile, light rain and snow, thunderstorms with drizzle, freezing rain, and
    squalls have not caused any congestion. People must be staying indoors during
    such extreme weather!
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与此同时，小雨和雪、带毛毛雨的雷暴、冰冻雨和阵风并未引起任何拥堵。在如此极端的天气下，人们一定都待在室内了！
- en: Closing
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结尾
- en: In this blog post, we covered how to use group-by-aggregation in EDA exercises.
    As we can see, this technique is highly effective in revealing interesting, useful
    insights from data, particularly when dealing with granular data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们介绍了如何在EDA练习中使用分组聚合。正如我们所看到的，这项技术在从数据中揭示有趣且有用的见解时非常有效，尤其是在处理粒度数据时。
- en: I hope you can practice doing group-by aggregation during your next EDA project!
    All in all, thanks for reading, and let’s connect with me on [LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)!
    👋
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你能在下一个EDA项目中练习使用分组聚合！总的来说，感谢你的阅读，欢迎在[LinkedIn](https://www.linkedin.com/in/pararawendy-indarjo/)上与我联系！👋
