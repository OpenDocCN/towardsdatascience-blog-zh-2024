- en: Exploring Public Storage Traces
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索公共存储轨迹
- en: 原文：[https://towardsdatascience.com/exploring-public-storage-traces-16ef7ac9e038?source=collection_archive---------6-----------------------#2024-01-26](https://towardsdatascience.com/exploring-public-storage-traces-16ef7ac9e038?source=collection_archive---------6-----------------------#2024-01-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/exploring-public-storage-traces-16ef7ac9e038?source=collection_archive---------6-----------------------#2024-01-26](https://towardsdatascience.com/exploring-public-storage-traces-16ef7ac9e038?source=collection_archive---------6-----------------------#2024-01-26)
- en: What are they, where are they, and are they right for you?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它们是什么？它们在哪里？它们适合你吗？
- en: '[](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)[![Raluca
    Diaconu](../Images/b7034d375d86616420c15a85b167af26.png)](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)
    [Raluca Diaconu](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)[![Raluca
    Diaconu](../Images/b7034d375d86616420c15a85b167af26.png)](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)
    [Raluca Diaconu](https://medium.com/@raluca.diaconu?source=post_page---byline--16ef7ac9e038--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)
    ·15 min read·Jan 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--16ef7ac9e038--------------------------------)
    ·15分钟阅读·2024年1月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c421b769fc389b95546b6a888076c27d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c421b769fc389b95546b6a888076c27d.png)'
- en: Photo by [Hongwei FAN](https://unsplash.com/@yokonoito0512?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Hongwei FAN](https://unsplash.com/@yokonoito0512?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Input and output (I/O) operations refer to the transfer of data between a computer’s
    main memory and various peripherals. Storage peripherals such as HDDs and SSDs
    have particular performance characteristics in terms of latency, throughput, and
    rate which can influence the performance of the computer system they power. Extrapolating,
    [the performance and design of distributed and cloud based Data Storage depends
    on that of the medium](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44830.pdf).
    This article is intended to be a bridge between Data Science and Storage Systems:
    1/ I am sharing a few datasets of various sources and sizes which I hope will
    be novel for Data Scientists and 2/ I am bringing up the potential for advanced
    analytics in Distributed Systems.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 输入和输出（I/O）操作指的是计算机主内存与各种外部设备之间的数据传输。存储外设如硬盘（HDD）和固态硬盘（SSD）在延迟、吞吐量和速率方面具有特定的性能特征，这些特征可能会影响它们所驱动的计算机系统的性能。推而广之，[分布式和基于云的数据存储的性能和设计取决于介质的性能](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44830.pdf)。本文旨在架起数据科学与存储系统之间的桥梁：1/
    我将分享一些来自不同来源和不同规模的数据集，希望这些数据集能为数据科学家带来新意；2/ 我将探讨分布式系统中高级分析的潜力。
- en: Intro
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Storage access traces are “[a treasure trove of information for optimizing cloud
    workloads](https://www.ibm.com/blog/object-storage-traces/).” They're crucial
    for capacity planning, data placement, or system design and evaluation, suited
    for modern applications. Diverse and up-to-date datasets are particularly needed
    in academic research to study novel and unintuitive access patterns, help the
    design of new hardware architectures, new caching algorithms, or hardware simulations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 存储访问轨迹是“[优化云工作负载的宝贵信息源](https://www.ibm.com/blog/object-storage-traces/)”。它们对于容量规划、数据放置、系统设计和评估至关重要，尤其适用于现代应用程序。在学术研究中，特别需要多样且更新的数据集来研究新颖且不直观的访问模式，这有助于设计新的硬件架构、新的缓存算法或硬件仿真。
- en: Storage traces are notoriously difficult to find. The [SNIA website](http://iotta.snia.org)
    is the best known “repository for storage-related I/O trace files, associated
    tools, and other related information” but many traces don't comply with their
    licensing or upload format. Finding traces becomes a tedious process of scanning
    the academic literature or attempting to generate one's own.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 存储追踪数据很难找到。[SNIA 网站](http://iotta.snia.org)是最著名的“存储相关 I/O 追踪文件、相关工具及其他相关信息的仓库”，但许多追踪数据并不符合它们的许可或上传格式。寻找追踪数据变成了一项繁琐的过程，需要扫描学术文献或尝试自己生成数据。
- en: '[Popular traces](http://iotta.snia.org/traces/block-io/388) which are easier
    to find tend to be outdated and overused. Traces older than 10 years should not
    be used in modern research and development due to changes in application workloads
    and hardware capabilities. Also, an over-use of specific traces can bias the understanding
    of real workloads so it''s recommended to use traces from multiple independent
    sources when possible.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[流行的追踪数据](http://iotta.snia.org/traces/block-io/388)较容易找到，但通常是过时和过度使用的。由于应用工作负载和硬件能力的变化，10
    年以上的追踪数据不应再用于现代的研究和开发。此外，过度使用特定的追踪数据可能会偏离对真实工作负载的理解，因此建议在可能的情况下使用来自多个独立来源的追踪数据。'
- en: This post is an organized collection of recent public traces I found and used.
    In the first part I categorize them by the level of abstraction they represent
    in the IO stack. In the second part I list and discuss some relevant datasets.
    The last part is a summary of all with a personal view on the gaps in storage
    tracing datasets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是我最近找到并使用的公共追踪数据的有组织集合。在第一部分，我按它们在 I/O 堆栈中所代表的抽象级别对它们进行了分类。在第二部分，我列出了并讨论了一些相关的数据集。最后一部分是对所有内容的总结，并提供了我个人对存储追踪数据集中的空白部分的看法。
- en: Type of traces
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 追踪数据类型
- en: I distinguish between three types of traces based on data representation and
    access model. Let me explain. A user, at the application layer, sees data stored
    in files or objects which are accessed by a large range of abstract operations
    such as *open* or *append*. Closer to the media, the data is stored in a continuous
    memory address space and accessed as blocks of fixed size which may only be *read*
    or *written*. At a higher abstraction level, within the application layer, we
    may also have a data presentation layer which may log access to *data presentation
    units*, which may be, for example, rows composing tables and databases, or articles
    and paragraphs composing news feeds. The access may be *create table*, or *post
    article*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我根据数据表示和访问模型将追踪数据分为三种类型。让我解释一下。用户在应用层看到的数据以文件或对象的形式存储，可以通过如*打开*或*追加*等多种抽象操作来访问。接近介质的地方，数据存储在一个连续的内存地址空间中，并作为固定大小的块进行访问，这些块只能*读取*或*写入*。在更高的抽象级别，在应用层内，我们也可能有一个数据表示层，它可以记录对*数据表示单元*的访问，这些单元可能是组成表格和数据库的行，或组成新闻源的文章和段落。访问可能是*创建表*或*发布文章*。
- en: While traces can be taken anywhere in the IO stack and contain information from
    multiple layers, I am choosing to structure the following classification based
    on the [Linux IO stack](https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram)
    depicted below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然追踪数据可以从 I/O 堆栈的任何位置获取，并且包含来自多个层次的信息，但我选择根据下面显示的[Linux I/O 堆栈](https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram)来构建以下分类。
- en: '![](../Images/9bdecfc908b6feecf8151cb0cd072337.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bdecfc908b6feecf8151cb0cd072337.png)'
- en: I/O Stack Diagram (adapted from [[1]](https://www.mimuw.edu.pl/~lichota/09-10/Optymalizacja-open-source/Materialy/10%20-%20Dysk/gelato_ICE06apr_blktrace_brunelle_hp.pdf),
    [[2]](https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram) and [[3]](https://www.researchgate.net/publication/317952281_Host_managed_contention_avoidance_storage_solutions_for_Big_Data))
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: I/O 堆栈图（改编自 [[1]](https://www.mimuw.edu.pl/~lichota/09-10/Optymalizacja-open-source/Materialy/10%20-%20Dysk/gelato_ICE06apr_blktrace_brunelle_hp.pdf)、[[2]](https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram)
    和 [[3]](https://www.researchgate.net/publication/317952281_Host_managed_contention_avoidance_storage_solutions_for_Big_Data)）
- en: '**Block storage traces**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**块存储追踪**'
- en: The data in these traces is representative of the operations at the block layer.
    In Linux, this data is typically collected with [blktrace](https://linux.die.net/man/8/blktrace)
    (and rendered readable with [blkparse](https://linux.die.net/man/1/blkparse)),
    [iostat](https://www.man7.org/linux/man-pages/man1/iostat.1.html), or [dtrace](https://dtrace.org/about/).
    The traces contain information about the operation, the device, CPU, process,
    and storage location accessed. The first trace listed is an example of blktrace
    output.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些追踪数据代表了块层的操作。在Linux中，这些数据通常通过[blktrace](https://linux.die.net/man/8/blktrace)（并通过[blkparse](https://linux.die.net/man/1/blkparse)渲染为可读格式）、[iostat](https://www.man7.org/linux/man-pages/man1/iostat.1.html)或[dtrace](https://dtrace.org/about/)进行收集。追踪数据包含有关操作、设备、CPU、进程和存储位置的信息。列出的第一个追踪示例是blktrace的输出。
- en: The typical information generated by tracing programs may be too detailed for
    analysis and publication purposes and it is often simplified. Typical public traces
    contain *operation*, *offset*, *size*, and sometimes *timing*. At this layer the
    *operations* are only read and write. Each operation accesses the address starting
    at *offset* and is applied to *a continuous size* of memory specified in number
    of blocks (4KiB NTFS). For example, a trace entry for a read operation contains
    the address where the read starts (offset), and the number of blocks read (size).
    The timing information may contain the time the request was issued (*start time*),
    the time it was completed (*end time*), the processing in between (*latency*),
    and the time the request waited (*queuing time*).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 追踪程序生成的典型信息可能对于分析和发布目的来说过于详细，因此通常会进行简化。典型的公共追踪数据包含*操作*、*偏移量*、*大小*，有时还包括*时间信息*。在此层级，*操作*仅限于读写操作。每个操作访问从*偏移量*开始的地址，并应用于指定大小的连续内存（按块数计算，4KiB
    NTFS）。例如，读取操作的追踪条目包含读取开始的地址（偏移量）和读取的块数（大小）。时间信息可能包括请求发起的时间（*开始时间*）、完成时间（*结束时间*）、处理过程中的延迟（*延迟*）和请求等待的时间（*排队时间*）。
- en: Available traces sport different features, have wildly different sizes, and
    are the output of a variety of workloads. Selecting the right one will depend
    on what one’s looking for. For example, trace replay only needs the order of operations
    and their size; For performance analysis timing information is needed.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的追踪数据具有不同的特性，大小差异巨大，并且是各种工作负载的输出。选择合适的追踪数据将取决于你寻找的内容。例如，追踪重放只需要操作的顺序和大小；而性能分析则需要时间信息。
- en: '![](../Images/864226aa3ebb3c6213b5fec32e9ef286.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/864226aa3ebb3c6213b5fec32e9ef286.png)'
- en: Disk access visualization with iowatcher ([source](https://www.heise.de/hintergrund/Kernel-Log-Nvidia-aktualisiert-Grafiktreiber-1677800.html?seite=2))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用iowatcher进行磁盘访问可视化（[来源](https://www.heise.de/hintergrund/Kernel-Log-Nvidia-aktualisiert-Grafiktreiber-1677800.html?seite=2)）
- en: '**Object storage traces**'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**对象存储追踪数据**'
- en: At the application layer, data is located in files and objects which may be
    created, opened, appended, or closed, and then discovered via a tree structure.
    From an user's point of view, the storage media is decoupled, hiding fragmentation,
    and allowing random byte access.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用层，数据位于文件和对象中，可以创建、打开、附加或关闭，然后通过树状结构进行发现。从用户的角度来看，存储介质是解耦的，隐藏了碎片化问题，并且允许随机字节访问。
- en: I’ll group together file and object traces despite a subtle difference between
    the two. Files follow the file system’s naming convention which is structured
    (typically hierarchical). Often the extension suggests the content type and usage
    of the file. On the other hand, objects are used in large scale storage systems
    dealing with vast amounts of diverse data. In object storage systems the structure
    is not intrinsic, instead it is defined externally, by the user, with specific
    metadata files managed by their workload.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管文件和对象追踪数据之间存在微妙的差异，我会将它们归为一类。文件遵循文件系统的命名约定，通常是结构化的（通常是分层的）。文件的扩展名通常会暗示文件的内容类型和用途。另一方面，对象用于处理大量不同数据的大规模存储系统。在对象存储系统中，结构不是固有的，而是由用户通过特定的元数据文件以及他们的工作负载外部定义的。
- en: Being generated within the application space, typically the result of an application
    logging mechanism, object traces are more diverse in terms of format and content.
    The information recorded may be more specific, for example, *operations* can also
    be *delete*, *copy*, or *append*. Objects typically have variable *size* and even
    the same object’s size may vary in time after appends and overwrites. The *object
    identifier* can be a string of variable size. It may encode extra information,
    for example, an extension that tells the content type. Other *meta-information*
    may come from the range accessed, which may tell us, for example, whether the
    header, the footer or the body of an image, parquet, or CSV file was accessed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对象追踪是在应用程序空间内生成的，通常是应用程序日志机制的结果，因此在格式和内容方面更加多样化。记录的信息可能更具体，例如，*操作*还可以是*删除*、*复制*或*追加*。对象通常具有可变的*大小*，即使是同一个对象的大小，经过追加和覆盖后也可能随时间发生变化。*对象标识符*可以是一个大小可变的字符串，可能会编码额外的信息，例如指示内容类型的扩展名。其他*元信息*可能来自访问的范围，例如，它可以告诉我们是访问了图像、Parquet或CSV文件的头部、尾部还是主体。
- en: 'Object storage traces are better suited for understanding user access patterns.
    In terms of block access, a video stream and a sequential read of an entire file
    generate the same pattern: multiple sequential IOs at regular time intervals.
    But these trace entries should be treated differently if we are to replay them.
    Accessing video streaming blocks needs to be done with the same time delta between
    them, regardless of the latency of each individual block, while reading the entire
    file should be asap.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对象存储追踪更适合用于理解用户访问模式。在块访问方面，视频流和对整个文件的顺序读取生成相同的模式：在规律的时间间隔内执行多个顺序IO。但如果我们要重放这些追踪数据，应该对这些追踪项做不同的处理。访问视频流的块需要保持相同的时间间隔，而不管每个块的延迟；而读取整个文件应该尽快完成。
- en: '**Access traces**'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**访问追踪**'
- en: Specific to each application, data may be abstracted further. Data units may
    be instances of a class, records in a database, or ranges in a file. A single
    data access may not even generate a file open or a disk IO if caching is involved.
    I choose to include such traces because they may be used to understand and optimize
    storage access, and in particular cloud storage. For example, the access traces
    from Twitter’s Memcache are useful in understanding popularity distributions and
    therefore may be useful for data formatting and placement decisions. Often they're
    not storage traces per se, but they can be useful in the context of cache simulation,
    IO reduction, or data layout (indexing).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 针对每个应用，数据可能会进一步抽象化。数据单元可以是类的实例、数据库中的记录或文件中的范围。单次数据访问如果涉及缓存，甚至可能不会生成文件打开或磁盘IO。我选择包含这些追踪数据，因为它们可能被用来理解和优化存储访问，特别是云存储。例如，Twitter
    Memcache的访问追踪数据有助于理解流行度分布，因此可能对数据格式化和放置决策有帮助。通常这些并不是存储追踪本身，但在缓存模拟、IO减少或数据布局（索引）等上下文中，它们可以非常有用。
- en: Data format in these traces can be even more diverse due to a new layer of abstraction,
    for example, by tweet identifiers in Memcached.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些追踪数据的格式可以更加多样化，因为引入了新的抽象层，例如，通过Memcached中的推文标识符。
- en: Examples of traces
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 追踪示例
- en: Let's look at a few traces in each of the categories above. The list details
    some of the newer traces — no older than 10 years — and it is by no means exhaustive.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下上述每个类别中的一些追踪数据。该列表详细列出了部分较新的追踪数据——不超过10年——但绝不是详尽无遗的。
- en: '**Block traces**'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**块追踪**'
- en: '**YCSB RocksDB SSD 2020**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**YCSB RocksDB SSD 2020**'
- en: These are SSD traces collected on a 28-core, 128 GB host with *two 512 GB NVMe
    SSD Drives*, running Ubuntu. The dataset is a result of running the [YCSB-0.15.0
    benchmark](https://en.wikipedia.org/wiki/YCSB) with [RocksDB](https://rocksdb.org/docs/support/faq.html).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是收集自一台28核、128 GB主机上的SSD追踪数据，该主机配有*两块512 GB NVMe SSD硬盘*，并运行Ubuntu操作系统。该数据集是通过运行[YCSB-0.15.0基准测试](https://en.wikipedia.org/wiki/YCSB)和[RocksDB](https://rocksdb.org/docs/support/faq.html)生成的。
- en: The first SSD stores all blktrace output, while the second hosts YCSB and RocksDB.
    YCSB Workload A consists of 50% reads and 50% updates of 1B operations on 250M
    records. Runtime is 9.7 hours, which generates over 352M block I/O requests at
    the file system level writing a total of 6.8 TB to the disk, with a read throughput
    of 90 MBps and a write throughput of 196 MBps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 第一块SSD存储所有的blktrace输出，而第二块则托管YCSB和RocksDB。YCSB工作负载A由50%的读取和50%的更新组成，涉及250M条记录的10亿次操作。运行时为9.7小时，生成了超过3.52亿个文件系统级的块I/O请求，总共写入了6.8
    TB数据，读取吞吐量为90 MBps，写入吞吐量为196 MBps。
- en: 'The dataset is small compared to all others in the list, and limited in terms
    of workload, but a great place to start due to its manageable size. Another benefit
    is reproducibility: it uses open source tracing tools and benchmarking beds atop
    a relatively inexpensive hardware setup.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与列表中的所有其他数据集相比，这个数据集较小，工作负载有限，但由于其可管理的大小，是一个很好的起点。另一个优点是可复现性：它使用开源追踪工具和基于相对便宜硬件设置的基准测试平台。
- en: '**Format:** These are SSD traces taken with `blktrace` and have the typical
    format after parsing with `blkparse`: `[Device Major Number,Device Minor Number]
    [CPU Core ID] [Record ID] [Timestamp (in nanoseconds)] [ProcessID] [Trace Action]
    [OperationType] [SectorNumber + I/O Size] [ProcessName]`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式：** 这些是通过`blktrace`捕获的SSD痕迹，在使用`blkparse`解析后具有典型格式：[设备主编号,设备次编号] [CPU核心ID]
    [记录ID] [时间戳（以纳秒为单位）] [进程ID] [追踪操作] [操作类型] [扇区号 + I/O大小] [进程名称]'
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Where to find it:** [http://iotta.snia.org/traces/block-io/28568](http://iotta.snia.org/traces/block-io/28568)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取方式：** [http://iotta.snia.org/traces/block-io/28568](http://iotta.snia.org/traces/block-io/28568)'
- en: '**License:** [SNIA Trace Data Files Download License](http://iotta.snia.org/repository/download_license)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证：** [SNIA追踪数据文件下载许可证](http://iotta.snia.org/repository/download_license)'
- en: '**Alibaba Block Traces 2020**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**阿里巴巴区块痕迹 2020**'
- en: The dataset consists of "block-level I/O requests collected from 1,000 volumes,
    where each has a raw capacity from 40 GiB to 5 TiB. The workloads span diverse
    types of cloud applications. Each collected I/O request specifies the volume number,
    request type, request offset, request size, and timestamp."
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集由“从1000个卷中收集的块级I/O请求组成，每个卷的原始容量从40 GiB到5 TiB不等。工作负载涵盖了多种类型的云应用。每个收集的I/O请求指定了卷号、请求类型、请求偏移、请求大小和时间戳。”
- en: '**Limitations** (from the [academic paper](http://www.cse.cuhk.edu.hk/~pclee/www/pubs/iiswc20.pdf))'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**限制**（来自[学术论文](http://www.cse.cuhk.edu.hk/~pclee/www/pubs/iiswc20.pdf)）'
- en: the traces do not record the response times of the I/O requests, making them
    unsuitable for latency analysis of I/O requests.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些痕迹未记录I/O请求的响应时间，因此不适合进行I/O请求的延迟分析。
- en: the specific applications running atop are not mentioned, so they cannot be
    used to extract application workloads and their I/O patterns.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有提及运行在其上的特定应用，因此无法提取应用工作负载及其I/O模式。
- en: the traces capture the access to virtual devices, so they are not representative
    of performance and reliability (e.g., data placement and failure statistics) for
    physical block storage devices.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些痕迹捕获了对虚拟设备的访问，因此不能代表物理块存储设备的性能和可靠性（例如，数据放置和故障统计）。
- en: A drawback of this dataset is its size. When uncompressed it results in a 751GB
    file which is difficult to store and manage.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的缺点是其大小。解压后生成一个751GB的文件，难以存储和管理。
- en: '**Format:** `device_id,opcode,offset,length,timestamp`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式：** `device_id,opcode,offset,length,timestamp`'
- en: '`device_id`ID of the virtual disk, `uint32`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_id`虚拟磁盘的ID，`uint32`'
- en: '`opcode`Either of ''R'' or ''W'', indicating this operation is read or write'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`opcode`‘R’或‘W’，表示该操作是读取或写入'
- en: '`offset`Offset of this operation, in bytes, `uint64`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offset`此操作的偏移量，单位为字节，`uint64`'
- en: '`length`Length of this operation, in bytes, `uint32`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length`此操作的长度，单位为字节，`uint32`'
- en: '`timestamp`Timestamp of this operation received by server, in microseconds,
    `uint64`'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp`服务器接收到的此操作的时间戳，单位为微秒，`uint64`'
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Additionally, there is an extra file containing each virtual device's id `device_id`
    with its total capacity.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个额外的文件，包含每个虚拟设备的ID `device_id`及其总容量。
- en: '**Where to find it:** [https://github.com/alibaba/block-traces](https://github.com/alibaba/block-traces)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取方式：** [https://github.com/alibaba/block-traces](https://github.com/alibaba/block-traces)'
- en: '**License:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证：** [CC-4.0](https://creativecommons.org/licenses/by/4.0/)。'
- en: '**Tencent Block Storage 2018**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**腾讯区块存储 2018**'
- en: This dataset consists of "216 I/O traces from a warehouse (also called a failure
    domain) of a production cloud block storage system (CBS). The traces are I/O requests
    from 5584 cloud virtual volumes (CVVs) for ten days (from Oct. 1st to Oct. 10th,
    2018). The I/O requests from the CVVs are mapped and redirected to a storage cluster
    consisting of 40 storage nodes (i.e., disks)."
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含“来自一个生产云块存储系统（CBS）仓库（也称为故障域）的216个I/O痕迹。这些痕迹是来自5584个云虚拟卷（CVV）的I/O请求，时间跨度为十天（从2018年10月1日到10月10日）。来自这些CVV的I/O请求被映射并重定向到由40个存储节点（即磁盘）组成的存储集群。”
- en: 'Limitations:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 限制：
- en: Timestamps are in seconds, a granularity too little for determining the order
    of operations. As a consequence many requests appear as if issued at the same
    time. This trace is therefore unsuitable for queuing analysis.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间戳的单位是秒，这对于确定操作的顺序来说粒度过小。因此，许多请求看起来像是同时发出的。因此，此跟踪不适用于排队分析。
- en: There is no latency information about the duration of each operation, making
    the trace unsuitable for latency performance, queuing analytics.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有关于每个操作持续时间的延迟信息，因此该跟踪不适用于延迟性能或排队分析。
- en: No extra information about each volume such as total size.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有关于每个卷的额外信息，例如总大小。
- en: '**Format:** `Timestamp,Offset,Size,IOType,VolumeID`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式:** `Timestamp,Offset,Size,IOType,VolumeID`'
- en: '`Timestamp` is the Unix time the I/O was issued in seconds.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Timestamp`是I/O请求发出的Unix时间戳，单位为秒。'
- en: '`Offset` is the starting offset of the I/O in sectors from the start of the
    logical virtual volume. 1 sector = 512 bytes'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Offset`是逻辑虚拟卷起始位置的I/O偏移量，以扇区为单位。1个扇区 = 512字节'
- en: '`Size` is the transfer size of the I/O request in sectors.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Size`是I/O请求的传输大小，以扇区为单位。'
- en: '`IOType` is “Read(0)”, “Write(1)”.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IOType`表示“读取(0)”或“写入(1)”。'
- en: '`VolumeID` is the ID number of a CVV.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VolumeID`是CVV的ID号。'
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Where to find it:** [http://iotta.snia.org/traces/parallel/27917](http://iotta.snia.org/traces/parallel/27917)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**在哪里找到它:** [http://iotta.snia.org/traces/parallel/27917](http://iotta.snia.org/traces/parallel/27917)'
- en: '**License:** [NIA Trace Data Files Download License](http://iotta.snia.org/repository/download_license)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可协议:** [NIA Trace Data Files Download License](http://iotta.snia.org/repository/download_license)'
- en: '**K5cloud Traces 2018**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**K5cloud 跟踪 2018**'
- en: This dataset contains traces from virtual cloud storage from the FUJITSU K5
    cloud service. The data is gathered during a week, but not continuously because
    “ one day’s IO access logs often consumed the storage capacity of the capture
    system.” There are 24 billion records from 3088 virtual storage nodes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含来自富士通K5云服务的虚拟云存储跟踪数据。数据收集历时一周，但并非连续收集，因为“某一天的I/O访问日志通常会消耗捕获系统的存储容量。”该数据集包含来自3088个虚拟存储节点的240亿条记录。
- en: The data is captured in the TCP/IP network between servers running on hypervisor
    and storage systems in a K5 data center in Japan. The data is split between three
    datasets by each virtual storage volume id. Each virtual storage volume id is
    unique in the same dataset, while each virtual storage volume id is not unique
    between the different datasets.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通过TCP/IP网络在运行在虚拟化平台上的服务器和位于日本K5数据中心的存储系统之间捕获。数据按每个虚拟存储卷ID分为三个数据集。每个数据集中的每个虚拟存储卷ID是唯一的，而不同数据集之间的虚拟存储卷ID并非唯一。
- en: 'Limitations:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 限制：
- en: There is no latency information, so the traces cannot be used for performance
    analysis.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有延迟信息，因此无法用于性能分析。
- en: The total node size is missing, but it can be approximated from the maximum
    offset accessed in the traces.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总节点大小缺失，但可以通过跟踪中访问的最大偏移量来近似估算。
- en: Some applications may require a complete dataset, which makes this one unsuitable
    due to missing data.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些应用程序可能需要完整的数据集，而由于数据缺失，本数据集不适合此类需求。
- en: 'The fields in the IO access log are: `ID,Timestamp,Type,Offset,Length`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: I/O访问日志中的字段包括：`ID,Timestamp,Type,Offset,Length`
- en: '`ID` is the virtual storage volume id.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ID`是虚拟存储卷ID。'
- en: '`Timestamp` is the time elapsed from the first IO request of all IO access
    logs in seconds, but with a microsecond granularity.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Timestamp`是从所有I/O访问日志的第一个I/O请求开始以来的时间，单位为秒，但粒度为微秒。'
- en: '`Type` is R(Read) or (W)Write.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Type`表示读取（R）或写入（W）。'
- en: '`Offset` is the starting offset of the IO access in bytes from the start of
    the virtual storage.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Offset`是虚拟存储起始位置的I/O访问偏移量，以字节为单位。'
- en: '`Length` is the transfer size of the IO request in bytes.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Length`是I/O请求的传输大小，以字节为单位。'
- en: '[PRE3]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Where to find it:** [http://iotta.snia.org/traces/parallel/27917](http://iotta.snia.org/traces/parallel/26663)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**在哪里找到它:** [http://iotta.snia.org/traces/parallel/27917](http://iotta.snia.org/traces/parallel/26663)'
- en: '**License:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可协议:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/)。'
- en: '**Object traces**'
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**对象跟踪**'
- en: '**Server-side I/O request arrival traces 2019**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务器端I/O请求到达跟踪 2019**'
- en: 'This repository contains two datasets for IO block traces with additional file
    identifiers: 1/ parallel file systems (PFS) and 2/ I/O nodes.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该存储库包含两个I/O块跟踪数据集，附加了文件标识符：1/ 并行文件系统（PFS）和2/ I/O节点。
- en: 'Notes:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注：
- en: The access patterns are resulting from [MPI-IO test benchmark](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-mpi-benchmarks.html)
    ran atop of [Grid5000](https://www.grid5000.fr/w/Grid5000:Home), a large scale
    test bed for parallel and High Performance Computing (HPC). These traces are not
    representative of general user or cloud workloads but instead specific to HPC
    and parallel computing.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问模式源自于在 [MPI-IO 测试基准](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-mpi-benchmarks.html)上运行的测试，该基准在
    [Grid5000](https://www.grid5000.fr/w/Grid5000:Home) 上执行，后者是一个大规模的并行和高性能计算（HPC）测试平台。这些追踪数据并不代表一般用户或云端工作负载，而是特定于
    HPC 和并行计算的。
- en: The setup for the PFS scenario uses [Orange FS](https://orangefs.org/) as file
    system and for the IO nodes I/O Forwarding Scalability Layer([IOFSL](https://www.anl.gov/mcs/iofsl-io-forwarding-scalability-layer)).
    In both cases the scheduler was set to AGIOS I/O scheduling library. This setup
    is perhaps too specific for most use cases targeted by this article and has been
    designed to reflect some proposed solutions.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PFS 场景的配置使用 [Orange FS](https://orangefs.org/) 作为文件系统，I/O 节点则使用 I/O 转发可扩展性层
    ([IOFSL](https://www.anl.gov/mcs/iofsl-io-forwarding-scalability-layer))。在这两种情况下，调度器都被设置为
    AGIOS I/O 调度库。此配置可能对于本文所针对的大多数用例来说过于具体，旨在反映一些提出的解决方案。
- en: The hardware setup for PFS consists of our server nodes with 600 GB HDDs each
    and 64 client nodes. For IO nodes, it has four server nodes with similar disk
    configuration in a cluster, and 32 clients in a different cluster.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PFS 的硬件配置由我们服务器节点组成，每个节点配备 600 GB 硬盘和 64 个客户端节点。对于 I/O 节点，它包括四个具有类似磁盘配置的服务器节点组成的集群，以及一个不同集群中的
    32 个客户端节点。
- en: '**Format:** The format is slightly different for the two datasets, an artifact
    of different file systems. For IO nodes, it consists of multiple files, each with
    tab-separated values `Timestamp FileHandle RequestType Offset Size`. A peculiarity
    is that reads and writes are in separate files named accordingly.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式：** 两个数据集的格式略有不同，这是由于不同文件系统的产物。对于 I/O 节点，它由多个文件组成，每个文件包含制表符分隔的值 `Timestamp
    FileHandle RequestType Offset Size`。一个特点是，读取和写入操作被分别存储在命名不同的文件中。'
- en: '`Timestamp` is a number representing the internal timestamp in nanoseconds.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Timestamp` 是表示内部时间戳的纳秒数。'
- en: '`FileHandle` is the file handle in hexadecimal of size 64.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FileHandle` 是 64 位大小的十六进制文件句柄。'
- en: '`RequestType` is the type of the request, inverted, “W” for reads and “R” for
    writes.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RequestType` 是请求类型，反转表示，“W”表示读取，“R”表示写入。'
- en: '`Offset` is a number giving the request offset in bytes'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Offset` 是一个表示请求偏移量的字节数。'
- en: '`Size` is the size of the request in bytes.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Size` 是请求的字节大小。'
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The PFS scenario has two concurrent applications, “app1” and “app2”, and its
    traces are inside a folder named accordingly. Each row entry has the following
    format: `[<Timestamp>] REQ SCHED SCHEDULING, handle:<FileHandle>, queue_element:
    <QueueElement>, type: <RequestType>, offset: <Offset>, len: <Size>` Different
    from the above are:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'PFS 场景中有两个并发应用程序，“app1”和“app2”，其追踪数据位于一个相应命名的文件夹内。每一行条目的格式如下：[<Timestamp>]
    REQ SCHED SCHEDULING, handle:<FileHandle>, queue_element: <QueueElement>, type:
    <RequestType>, offset: <Offset>, len: <Size>。与上述不同的是：'
- en: '`RequestType` is 0 for reads and 1 for writes'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RequestType` 为 0 表示读取，1 表示写入。'
- en: '`QueueElement` is never used and I believe it is an artifact of the tracing
    tool.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`QueueElement` 从未使用过，我认为它是追踪工具的产物。'
- en: '[PRE5]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Where to find it:** [https://zenodo.org/records/3340631#.XUNa-uhKg2x](https://zenodo.org/records/3340631#.XUNa-uhKg2x)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**在哪里可以找到：** [https://zenodo.org/records/3340631#.XUNa-uhKg2x](https://zenodo.org/records/3340631#.XUNa-uhKg2x)'
- en: '**License:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可协议：** [CC-4.0](https://creativecommons.org/licenses/by/4.0/)。'
- en: '**IBM Cloud Object Store 2019**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**IBM Cloud Object Store 2019**'
- en: These are anonymized traces from the IBM Cloud Object Storage service collected
    with the primary goal to study data flows to the object store.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是来自 IBM Cloud Object Storage 服务的匿名化追踪数据，主要用于研究数据流向对象存储的情况。
- en: The dataset is composed of 98 traces containing around 1.6 Billion requests
    for 342 Million unique objects. The traces themselves are about 88 GB in size.
    Each trace contains the REST operations issued against a single bucket in IBM
    Cloud Object Storage during a single week in 2019\. Each trace contains between
    22,000 to 187,000,000 object requests. All the traces were collected during the
    same week in 2019\. The traces contain all data access requests issued over a
    week by a single tenant of the service. Object names are anonymized.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集由98个追踪组成，包含约16亿个请求，涉及342百万个独特的对象。追踪本身约为88GB。每个追踪包含在2019年某一周内针对IBM Cloud
    Object Storage中的单个桶发出的REST操作。每个追踪包含从22,000到187,000,000个对象请求。所有追踪数据均在2019年同一周内收集。追踪数据包含了一个服务租户在一周内发出的所有数据访问请求。对象名称已进行匿名化处理。
- en: 'Some characteristics of the workload have been [published in this paper](https://www.usenix.org/system/files/hotstorage20_paper_eytan.pdf),
    although the dataset used was larger:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载的一些特征已在[本文](https://www.usenix.org/system/files/hotstorage20_paper_eytan.pdf)中发布，尽管使用的数据集更大：
- en: The authors were "able to identify some of the workloads as SQL queries, Deep
    Learning workloads, Natural Language Processing (NLP), Apache Spark data analytic,
    and document and media servers. But many of the workloads’ types remain unknown."
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者“能够识别一些工作负载为SQL查询、深度学习工作负载、自然语言处理（NLP）、Apache Spark数据分析以及文档和媒体服务器。但许多工作负载的类型仍然未知。”
- en: '"A vast majority of the objects (85%) in the traces are smaller'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “追踪中的大多数对象（85%）都较小。”
- en: than a megabyte, Yet these objects only account for 3% of the
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小于1MB，但这些对象仅占总存储容量的3%。
- en: of the stored capacity." This made the data suitable for a cache analysis.
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “存储容量的3%。”这使得该数据适合进行缓存分析。
- en: '**Format:** `<time stamp of request> <request type> <object ID> <optional:
    size of object> <optional: beginning offset> <optional: ending offset>` The timestamp
    is the number of milliseconds from the point where we began collecting the traces.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式**：`<请求时间戳> <请求类型> <对象ID> <可选：对象大小> <可选：起始偏移> <可选：结束偏移>` 时间戳是从开始收集追踪数据的时刻起的毫秒数。'
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Where to find it:** [http://iotta.snia.org/traces/key-value/36305](http://iotta.snia.org/traces/key-value/36305)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取地址**：[http://iotta.snia.org/traces/key-value/36305](http://iotta.snia.org/traces/key-value/36305)'
- en: '**License:** [SNIA Trace Data Files Download License](http://iotta.snia.org/repository/download_license)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证**：[SNIA追踪数据文件下载许可证](http://iotta.snia.org/repository/download_license)'
- en: '**Access traces**'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**访问追踪**'
- en: '**Wiki Analytics Datasets 2019**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**维基分析数据集 2019**'
- en: The wiki dataset contains data for 1/ upload (image) web requests of Wikimedia
    and 2/ text (HTML pageview) web requests from one CDN cache server of Wikipedia.
    The mos recent dataset, from 2019 contains 21 upload data files and 21 text data
    files.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 维基数据集包含了1/ Wikimedia的上传（图片）Web请求数据和2/ Wikipedia的一个CDN缓存服务器的文本（HTML页面浏览）Web请求数据。最新的数据集来自2019年，包含21个上传数据文件和21个文本数据文件。
- en: '**Format**: Each upload data file, denoted `cache-u`, contains exactly 24 hours
    of consecutive data. These files are each roughly 1.5GB in size and hold roughly
    4GB of decompressed data each.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式**：每个上传数据文件，标记为`cache-u`，包含连续24小时的数据。这些文件的大小大约为1.5GB，每个文件解压后的数据大约为4GB。'
- en: This dataset is the result of a single type of workload, which may limit the
    applicability, but it is large and complete, which makes a good testbed.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集来源于单一类型的工作负载，这可能限制其适用性，但由于其数据量大且完整，因此成为一个很好的测试平台。
- en: 'Each decompressed upload data file has the following format: `relative_unix
    hashed_path_query image_type response_size time_firstbyte`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个解压后的上传数据文件具有以下格式：`relative_unix hashed_path_query image_type response_size
    time_firstbyte`
- en: '`relative_unix`: Seconds since start timestamp of dataset, int'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relative_unix`: 自数据集开始时间戳以来的秒数，类型为整数'
- en: '`hashed_path_query`: Salted hash of path and query of request, bigint'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hashed_path_query`: 请求路径和查询的加盐哈希值，类型为大整数'
- en: '`image_type`: Image type from Content-Type header of response, string'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_type`: 响应的Content-Type头中的图片类型，类型为字符串'
- en: '`response_size`: Response size in bytes, int'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response_size`: 响应大小（字节数），类型为整数'
- en: '`time_firstbyte`: Seconds to first byte, double'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_firstbyte`: 第一个字节的时间，单位为秒，类型为双精度浮点数'
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Each text data file, denoted `cache-t`, contains exactly 24 hours of consecutive
    data. These files are each roughly 100MB in size and hold roughly 300MB of decompressed
    data each.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文本数据文件，标记为`cache-t`，包含连续24小时的数据。这些文件的大小大约为100MB，每个文件解压后的数据大约为300MB。
- en: 'Each decompressed upload data file has the following format: `relative_unix
    hashed_host_path_query response_size time_firstbyte`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 每个解压上传的数据文件具有以下格式：`relative_unix hashed_host_path_query response_size time_firstbyte`
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Where to find it:** [https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Caching](https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Caching)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**在哪里可以找到**：[https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Caching](https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Traffic/Caching)'
- en: '**License:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证**：[CC-4.0](https://creativecommons.org/licenses/by/4.0/)。'
- en: Memcached 2020
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Memcached 2020
- en: This dataset contains one-week-long traces from Twitter’s in-memory caching
    ([Twemcache](https://github.com/twitter/twemcache) / [Pelikan](https://github.com/twitter/pelikan))
    clusters. The data comes from 54 largest clusters in Mar 2020, Anonymized Cache
    Request Traces from Twitter Production.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含来自Twitter内存缓存的为期一周的追踪数据（[Twemcache](https://github.com/twitter/twemcache)
    / [Pelikan](https://github.com/twitter/pelikan)）集群。数据来自2020年3月的54个最大集群，来自Twitter生产环境的匿名化缓存请求追踪记录。
- en: '**Format:** Each trace file is a csv with the format: `timestamp,anonymized
    key,key size,value size,client id,operation,TTL`'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式**：每个追踪文件是一个CSV文件，格式为：`timestamp,anonymized key,key size,value size,client
    id,operation,TTL`'
- en: '`timestamp`: the time when the cache receives the request, in sec'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`时间戳`：缓存接收请求的时间，单位为秒'
- en: '`anonymized key`: the original key with anonymization where namespaces are
    preserved; for example, if the anonymized key is `nz:u:eeW511W3dcH3de3d15ec`,
    the first two fields `nz` and `u` are namespaces, note that the namespaces are
    not necessarily delimited by `:`, different workloads use different delimiters
    with different number of namespaces.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`匿名化密钥`：经过匿名化处理的原始密钥，其中命名空间得以保留；例如，如果匿名化后的密钥是`nz:u:eeW511W3dcH3de3d15ec`，那么前两个字段`nz`和`u`是命名空间，注意命名空间不一定以`:`分隔，不同的工作负载使用不同的分隔符，并且命名空间的数量不同。'
- en: '`key size`: the size of key in bytes'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`键大小`：键的大小，单位为字节'
- en: '`value size`: the size of value in bytes'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`值大小`：值的大小，单位为字节'
- en: '`client id`: the anonymized clients (frontend service) who sends the request'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`客户端ID`：发送请求的匿名化客户端（前端服务）'
- en: '`operation`: one of get/gets/set/add/replace/cas/append/prepend/delete/incr/decr'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`操作`：操作类型，包括get/gets/set/add/replace/cas/append/prepend/delete/incr/decr'
- en: '`TTL`: the time-to-live (TTL) of the object set by the client, it is 0 when
    the request is not a write request.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TTL`：客户端设置的对象生存时间（TTL），如果请求不是写入请求，则为0。'
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**License:** [CC-4.0](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证**：[CC-4.0](https://creativecommons.org/licenses/by/4.0/)。'
- en: Conclusion
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'If you’re still here and haven’t gone diving into one of the traces linked
    above it may be because you haven’t found what you’re looking for. There are a
    few gaps that current storage traces have yet to fill:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还在这里，并且没有进入上面链接的某个追踪记录，可能是因为你还没有找到你要寻找的内容。当前存储追踪记录仍然存在一些空白：
- en: '**Multi-tenant Cloud Storage**: Large cloud storage providers store some of
    the most rich datasets out there. Their workload reflects a large scale systems’
    architecture and is the result of a diverse set of applications. Storage providers
    are also extra cautious when it comes to sharing this data. There is little or
    no financial incentive to share data with the public and a fear of [unintended
    customer data leaks](https://arxiv.org/abs/cs/0610105).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多租户云存储**：大型云存储提供商存储了一些最丰富的数据集。它们的工作负载反映了大规模系统的架构，并且是各种应用程序的结果。存储提供商在共享这些数据时也非常谨慎。共享数据给公众的财务激励很小或根本没有，同时也担心[意外客户数据泄露](https://arxiv.org/abs/cs/0610105)。'
- en: '**Full stack**. Each layer in the stack offers a different view on access patterns,
    none alone being enough to understand cause-and-effect relationships in storage
    systems. Optimizing a system to suit modern workloads requires a holistic view
    of the data access which are not publicly available.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完整栈**：栈中的每一层都提供了对访问模式的不同视角，单独看任何一层都不足以理解存储系统中的因果关系。优化一个系统以适应现代工作负载需要全面的视角，涉及数据访问的各个方面，而这些信息并未公开。'
- en: '**Distributed tracing**. Most data is nowadays accessed remotely and managed
    in large scale distributed systems. Many components and layers (such as indexes
    or caching) will alter the access patterns. In such an environment, end-to-end
    means tracing a request across several components in a complex architecture. This
    data can be truly valuable for designing large scale systems but, at the same
    time, may be too specific to the system inspected which, again, limits the incentive
    to publish it.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式追踪**。如今，大多数数据是远程访问的，并且管理在大规模的分布式系统中。许多组件和层次（如索引或缓存）会改变访问模式。在这样的环境下，端到端的追踪意味着在复杂架构中的多个组件之间追踪一个请求。这些数据对于设计大规模系统来说非常有价值，但与此同时，它们可能过于特定于被检查的系统，这又限制了发布数据的动力。'
- en: '**Data quality**. The traces above have limitations due to the level of detail
    they represent. As we have seen, some have missing data, some have large granularity
    time stamps, others are inconveniently large to use. Cleaning data is a tedious
    process which limits the dataset publishing nowadays.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量**。上面的痕迹由于所代表的细节级别存在一定的局限性。如我们所见，有些数据缺失，有些时间戳的粒度较大，其他的则过于庞大，不方便使用。数据清理是一个繁琐的过程，限制了目前数据集的发布。'
