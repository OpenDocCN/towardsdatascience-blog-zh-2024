- en: 'Scaling Monosemanticity: Anthropic’s One Step Towards Interpretable & Manipulable
    LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展单义性：Anthropic迈向可解释和可操控LLMs的一步
- en: 原文：[https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28](https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28](https://towardsdatascience.com/scaling-monosemanticity-anthropics-one-step-towards-interpretable-manipulable-llms-4b9403c4341e?source=collection_archive---------7-----------------------#2024-05-28)
- en: 'GenAI Byte: A Byte a Day Keeps Imposter Syndrome Away'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAI字节：每天一字节，驱走冒名顶替综合症
- en: From prompt engineering to activation engineering for more controllable and
    safer LLMs
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从提示工程到激活工程，为了实现更可控和更安全的LLMs
- en: '[](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[![Jack
    Chih-Hsu Lin](../Images/044c46619ba339417278ec485677c945.png)](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    [Jack Chih-Hsu Lin](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[![Jack
    Chih-Hsu Lin](../Images/044c46619ba339417278ec485677c945.png)](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    [Jack Chih-Hsu Lin](https://medium.com/@jacklingenai?source=post_page---byline--4b9403c4341e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    ·11 min read·May 28, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4b9403c4341e--------------------------------)
    ·阅读时间11分钟·2024年5月28日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Background/Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景/介绍
- en: Monosemanticity vs Polysemanticity
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单义性与多义性
- en: In neural networks (the algorithm type of LLMs inspired by human brains), the
    neurons are usually *polysemantic*, which means their activations respond to multiple
    meanings and concepts. On the other hand, if each neuron represents only one meaning/concept,
    they are *monosemantic.* For example, both phrases “I feel blue” and “I’m heavy-hearted”
    as the LLMs inputs only activate the same set of neurons that represent sadness
    or negative emotion. The sadness neurons are also not activated by other concepts.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中（LLMs的算法类型，灵感来源于人类大脑），神经元通常是*多义性的*，这意味着它们的激活响应多个含义和概念。另一方面，如果每个神经元仅代表一个含义/概念，则它们是*单义性的*。例如，短语“I
    feel blue”和“I’m heavy-hearted”作为LLMs的输入，只激活同一组代表悲伤或负面情绪的神经元。这些悲伤神经元也不会被其他概念激活。
- en: Feature
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特性
- en: In machine learning, “features” refer to the measurable/observable properties
    used as inputs in the machine learning models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，“特性”指的是作为输入使用的可测量/可观察的属性。
- en: To be noted, however, in this work “features*”* mean something different. “Features”
    refer to the high-dimensional layer outputs of the encoding layer in the sparse
    autoencoder trained to predict the LLM intermediate activations. (Check the Approaches/Methods
    section below to understand the details). At a high level, I interpret “features”
    as the…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而需要注意的是，在本研究中，“特性”指的有所不同。“特性”是指在稀疏自编码器的编码层输出的高维层，它被训练用来预测LLM中间的激活。（请参见下面的“方法”部分以了解详细信息）。从高层次看，我将“特性”解释为……
