- en: Reducing the Size of Docker Images Serving Large Language Models (part 1)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少为大语言模型提供服务的Docker镜像大小（第一部分）
- en: 原文：[https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-llm-models-b70ee66e5a76?source=collection_archive---------6-----------------------#2024-05-03](https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-llm-models-b70ee66e5a76?source=collection_archive---------6-----------------------#2024-05-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-llm-models-b70ee66e5a76?source=collection_archive---------6-----------------------#2024-05-03](https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-llm-models-b70ee66e5a76?source=collection_archive---------6-----------------------#2024-05-03)
- en: Have you encountered a problem where a 1 GB transformer-based model increases
    even up to 8 GB when deployed using Docker containerization?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你是否遇到过这样的问题：一个1 GB的基于Transformer的模型在使用Docker容器化部署时，大小竟然增加到了8 GB？
- en: '[](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[![Michał
    Marcińczuk, Ph.D.](../Images/74fb7b0099084be3f7a35a149471ffbd.png)](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)
    [Michał Marcińczuk, Ph.D.](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[![Michał
    Marcińczuk, Ph.D.](../Images/74fb7b0099084be3f7a35a149471ffbd.png)](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)
    [Michał Marcińczuk, Ph.D.](https://czuk.medium.com/?source=post_page---byline--b70ee66e5a76--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)
    ·6 min read·May 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b70ee66e5a76--------------------------------)
    ·6分钟阅读·2024年5月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/817ed50bee602682eb9c094396535e05.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/817ed50bee602682eb9c094396535e05.png)'
- en: Photo by [Dominik Lückmann](https://unsplash.com/@exdigy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Dominik Lückmann](https://unsplash.com/@exdigy?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Transformer-based models like a **BERT**, **RoBERTa**, or **T5** provide a state-of-the-art
    solution for many custom problems in natural language processing. A common way
    to deliver the models on production is to build a Docker image that provides an
    API to the model. The image encapsulates the required dependencies, the model
    itself, and the code to process the input data with the model. Compared to the
    large generative models (GenAI), these models are relatively small, **from 0.5
    to 2 GB**. Nevertheless, when you follow the straightforward way to deploy the
    model as a Docker image, you may be surprised by the size of the image, which
    **can reach 8 GB**. Have you wondered why the target image is so large and if
    there is a way to reduce its size? In this story, I will discuss why the docker
    image might be so large and how to reduce its size.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Transformer的模型，如**BERT**、**RoBERTa**或**T5**，为许多定制的自然语言处理问题提供了最先进的解决方案。在生产环境中交付这些模型的常见方式是构建一个Docker镜像，提供模型的API。该镜像封装了所需的依赖项、模型本身以及处理输入数据的代码。与大型生成模型（GenAI）相比，这些模型相对较小，**从0.5到2
    GB**不等。然而，当你采用直接的方式将模型部署为Docker镜像时，你可能会对镜像的大小感到惊讶，镜像的**大小可能达到8 GB**。你是否曾经想过为什么目标镜像如此庞大，是否有办法减少其大小？在本文中，我将讨论为什么Docker镜像可能如此巨大，以及如何减少其大小。
- en: 'The examples of the Python scripts and Docker files used in the story are also
    available on this repo [1]:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的Python脚本和Docker文件示例也可以在这个仓库中找到 [1]：
