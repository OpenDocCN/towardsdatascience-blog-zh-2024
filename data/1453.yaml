- en: 'Reinforcement Learning, Part 4: Monte Carlo Control'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习，第四部分：蒙特卡洛控制
- en: 原文：[https://towardsdatascience.com/reinforcement-learning-part-4-monte-carlo-control-ae0a7f29920b?source=collection_archive---------4-----------------------#2024-06-11](https://towardsdatascience.com/reinforcement-learning-part-4-monte-carlo-control-ae0a7f29920b?source=collection_archive---------4-----------------------#2024-06-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/reinforcement-learning-part-4-monte-carlo-control-ae0a7f29920b?source=collection_archive---------4-----------------------#2024-06-11](https://towardsdatascience.com/reinforcement-learning-part-4-monte-carlo-control-ae0a7f29920b?source=collection_archive---------4-----------------------#2024-06-11)
- en: Harnessing Monte Carlo algorithms to discover the best strategies
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用蒙特卡洛算法发现最佳策略
- en: '[](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)[![Vyacheslav
    Efimov](../Images/441e600862b2b93564c6cd81abb0092d.png)](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page---byline--ae0a7f29920b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)
    ·13 min read·Jun 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ae0a7f29920b--------------------------------)
    ·阅读时间：13分钟·2024年6月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ccda9eebd2feeb01b4ef59b81b9dabcb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccda9eebd2feeb01b4ef59b81b9dabcb.png)'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: R**einforcement learning** is a domain in machine learning that introduces the
    concept of an agent who must learn optimal strategies in complex environments.
    The agent learns from its actions that result in rewards given the environment’s
    state. Reinforcement learning is a difficult topic and differs significantly from
    other areas of machine learning. That is why it should only be used when a given
    problem cannot be solved otherwise.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**是机器学习中的一个领域，它引入了智能体的概念，智能体必须在复杂的环境中学习最优策略。智能体通过其行为从环境的状态中获得奖励，进而学习。强化学习是一个困难的话题，与机器学习的其他领域有很大的不同。因此，只有在某个问题无法通过其他方式解决时，才应该使用强化学习。'
- en: The incredible thing about reinforcement learning is that the same algorithms
    can be used to make the agent adapt to completely different, unknown, and complex
    conditions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个令人难以置信的地方在于，相同的算法可以用来使智能体适应完全不同、未知且复杂的环境条件。
- en: In particular, Monte Carlo algorithms do not need any knowledge about an environment’s
    dynamics. It is a very useful property, since in real life we do not usually have
    access to such information. Having discussed the basic ideas behind Monte Carlo
    approach in the previous article, this time we will be focusing on special methods
    for improving them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，蒙特卡洛算法不需要任何关于环境动态的知识。这是一个非常有用的特性，因为在现实生活中，我们通常无法获得这些信息。在上一篇文章中，我们讨论了蒙特卡洛方法的基本思想，这次我们将重点介绍一些特殊方法来改进这些算法。
- en: '**Note**. To fully understand the concepts included in this article, it is
    highly recommended to be familiar with the main concepts of Monte Carlo algorithms
    introduced in [part 3](https://medium.com/towards-data-science/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb)
    of this…'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**：为了充分理解本文所涉及的概念，强烈建议先熟悉在[第三部分](https://medium.com/towards-data-science/reinforcement-learning-part-3-monte-carlo-methods-7ce2828a1fdb)中介绍的蒙特卡洛算法的主要概念…'
