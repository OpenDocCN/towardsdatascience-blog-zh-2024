- en: Building an AI Assistant with DSPy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DSPy构建AI助手
- en: 原文：[https://towardsdatascience.com/building-an-ai-assistant-with-dspy-2e1e749a1a95?source=collection_archive---------0-----------------------#2024-03-07](https://towardsdatascience.com/building-an-ai-assistant-with-dspy-2e1e749a1a95?source=collection_archive---------0-----------------------#2024-03-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-an-ai-assistant-with-dspy-2e1e749a1a95?source=collection_archive---------0-----------------------#2024-03-07](https://towardsdatascience.com/building-an-ai-assistant-with-dspy-2e1e749a1a95?source=collection_archive---------0-----------------------#2024-03-07)
- en: A way to program and tune prompt-agnostic LLM agent pipelines
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种编程和调整提示无关的LLM代理流水线的方法
- en: '[](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page---byline--2e1e749a1a95--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)
    ·9 min read·Mar 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2e1e749a1a95--------------------------------)
    ·阅读时间9分钟·2024年3月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: I hate prompt engineering. For one thing, I do not want to prostrate before
    a LLM (“you are the world’s best copywriter … “), bribe it (“I will tip you $10
    if you …”), or nag it (“Make sure to …”). For another, prompts are brittle — small
    changes to prompts can cause major changes to the output. This makes it hard to
    develop repeatable functionality using LLMs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我讨厌提示工程。有一方面，我不想在LLM面前俯首称臣（“你是世界上最棒的文案写手……”）、贿赂它（“如果你……，我会给你10美元小费”）或烦扰它（“确保……”）。另一方面，提示是脆弱的——对提示语做些许更改就能导致输出发生重大变化。这使得使用LLM开发可重复的功能变得困难。
- en: Unfortunately, developing LLM-based applications today involves tuning and tweaking
    prompts. Moving from writing code in a programming language that the computer
    follows precisely to writing ambiguous natural language instructions that are
    imperfectly followed does not seem like progress. That’s why I found working with
    LLMs a frustrating exercise — I prefer writing and debugging computer programs
    that I can actually reason about.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，今天开发基于LLM的应用程序涉及调整和修改提示语。从编写计算机精确执行的编程语言代码，到编写自然语言指令（计算机并不完全遵循）似乎并没有进步。这就是我发现使用LLM进行工作的原因感到沮丧——我更喜欢编写和调试我可以实际推理的计算机程序。
- en: What if, though, you can program on top of LLMs using a high-level programming
    framework, and let the framework write and tune prompts for you? Would be great,
    wouldn’t it? This — the ability to build agent pipelines programmatically without
    dealing with prompts and to tune these pipelines in a data-driven and LLM-agnostic
    way — is the key premise behind [DSPy](https://github.com/stanfordnlp/dspy).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果你能使用一个高级编程框架在LLM之上进行编程，并让框架为你编写和调整提示语呢？那岂不是太好了？这——能够在不处理提示的情况下编程构建代理流水线，并且以数据驱动和与LLM无关的方式调整这些流水线——正是[
    DSPy](https://github.com/stanfordnlp/dspy)背后的关键前提。
- en: An AI Assistant
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个AI助手
- en: To illustrate how DSPy works, I’ll build an AI assistant.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明DSPy是如何工作的，我将构建一个AI助手。
- en: What’s an AI assistant? It’s a computer program that provides assistance to
    a human doing a task. The ideal AI assistant works *proactively* on behalf of
    the user (a chatbot can be a failsafe for functionality that is not easy to find
    in your product or a way end-users can reach out for customer support, but should
    not be the main/only AI assistance in your application). So, designing an AI assistant
    consists of thinking through a workflow and determining how you could want to
    streamline it using AI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是AI助手？它是一个为人类执行任务提供帮助的计算机程序。理想的AI助手会*主动*地代表用户工作（聊天机器人可以作为功能备份，用于查找产品中不易找到的功能或为终端用户提供客户支持，但不应是应用程序中主要/唯一的AI助手）。因此，设计AI助手的过程包括思考工作流程，并确定如何通过AI来简化它。
- en: A typical AI assistant streamlines a workflow by (1) retrieving information
    such as company policies relevant to the task, (2) extracting information from
    documents such as those sent in by customers, (3) filling out forms or checklists
    based on textual analysis of the policies and documents, (4) collecting parameters
    and making function calls on the human’s behalf, and (5) identifying potential
    errors and highlighting risks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的AI助手通过以下方式简化工作流程：（1）检索与任务相关的公司政策等信息，（2）从客户发送的文档中提取信息，（3）根据对政策和文档的文本分析填写表格或检查单，（4）收集参数并代表用户调用函数，（5）识别潜在错误并突出风险。
- en: The use case I will use to illustrate an AI assistant involves the card game
    bridge. Even though I’m building an AI assistant for bridge bidding, you don’t
    need to understand bridge to understand the concepts here. The reason I chose
    bridge is that there is a lot of jargon, quite a bit of human judgement involved,
    and several external tools that an advisor can use. These are the key characteristics
    of the industry problems and backoffice processes that you might want to build
    AI assistants for. But because it’s a game, there is no confidential information
    involved.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用一个桥牌作为例子来说明AI助手的用例。尽管我正在为桥牌叫牌构建AI助手，但你并不需要了解桥牌就能理解这里的概念。我选择桥牌的原因是，桥牌中有大量术语、涉及相当多的人类判断，并且有多个外部工具供顾问使用。这些是你可能想为其构建AI助手的行业问题和后台流程的关键特征。但因为它是一个游戏，所以其中不涉及机密信息。
- en: Agent Framework
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理框架
- en: The assistant, when asked a question like “What is Stayman?”, uses a number
    of backend services to carry out its task. These backend services are invoked
    via agents, which are themselves built using language models. As with microservices
    in software engineering, the use of agents and backend services allows for decoupling
    and specialization — the AI assistant does not need to know how things are done,
    only what it needs done and each agent can know how to do only its own thing.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当被问到类似“什么是Stayman？”的问题时，助手会使用多个后台服务来执行其任务。这些后台服务通过代理进行调用，而这些代理本身是基于语言模型构建的。与软件工程中的微服务类似，使用代理和后台服务允许解耦和专业化——AI助手不需要知道事情是如何完成的，只需要知道需要完成什么，而每个代理只需了解如何做自己的事情。
- en: '![](../Images/a96506f5a47510890f4aa8eae03392ed.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a96506f5a47510890f4aa8eae03392ed.png)'
- en: An agent framework. Image by author. Sketches in the image were generated using
    Gemini.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个代理框架。图片由作者提供。图片中的草图是使用Gemini生成的。
- en: In an agent framework, the agents can often be smaller language models (LMs)
    that need to be accurate, but don’t have world knowledge. The agents will be able
    to “reason” (through chain-of-thought), search (through Retrieval-Augmented-Generation),
    and do non-textual work (by extracting the parameters to pass into a backend function).
    Instead of having disparate capabilities or skills, the entire agent framework
    is fronted by an AI assistant that is an extremely fluent and coherent LLM. This
    LLM will know the intents it needs to handle and how to route those intents. It
    needs to have world knowledge as well. Often, there is a separate policy or guardrails
    LLM that acts as a filter. The AI assistant is invoked when the user makes a query
    (the chatbot use case) or when there is a triggering event (the proactive assistant
    use case).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理框架中，代理通常是较小的语言模型（LMs），这些模型需要准确，但不具备世界知识。代理能够进行“推理”（通过思维链）、搜索（通过检索增强生成）和执行非文本工作（通过提取参数传递给后台函数）。代理框架的前端是一个非常流利且连贯的大型语言模型（LLM）。这个LLM知道它需要处理的意图，以及如何路由这些意图。它还需要具备世界知识。通常，会有一个单独的政策或监管LLM作为过滤器。当用户发起查询时（聊天机器人用例）或发生触发事件时（主动助手用例），AI助手会被调用。
- en: Zero Shot prompting with DSPy
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用DSPy的零样本提示
- en: To build the whole architecture above, I’ll use DSPy. The [entire code is on
    GitHub](https://github.com/lakshmanok/lakblogs/tree/main/bridge_bidding_advisor);
    start with [bidding_advisor.py](https://github.com/lakshmanok/lakblogs/blob/main/bridge_bidding_advisor/bidding_advisor.py)
    in that directory and follow along.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建上述整个架构，我将使用DSPy。[整个代码可以在GitHub上找到](https://github.com/lakshmanok/lakblogs/tree/main/bridge_bidding_advisor)；从该目录下的[bidding_advisor.py](https://github.com/lakshmanok/lakblogs/blob/main/bridge_bidding_advisor/bidding_advisor.py)开始，跟着一起操作。
- en: 'In DSPy, the process of sending a prompt to an LLM and getting a response back
    looks like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在DSPy中，发送提示给LLM并获取响应的过程如下：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There are four things happening in the snippet above:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码段中发生了四个事情：
- en: Write a subclass of dspy.Module
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个dspy.Module的子类
- en: In the init method, set up a LM module. The simplest is dspy.Predict which is
    a single call.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在init方法中，设置一个LM模块。最简单的方式是使用dspy.Predict，它是一个单一的调用。
- en: The Predict constructor takes a signature. Here, I say that there is one input
    (question) and one output (answer).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Predict构造函数接受一个签名。这里，我表示有一个输入（问题）和一个输出（答案）。
- en: 'Write a forward() method that takes the input(s) specified (here: question)
    and returns the what was promised in the signature (here: answer). It does this
    by calling the dspy.Predict object created in the init method.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个forward()方法，接受指定的输入（这里是：问题），并返回签名中承诺的内容（这里是：答案）。它通过调用在init方法中创建的dspy.Predict对象来实现。
- en: I could have just passed the question along as-is, but just to show you that
    I can somewhat affect the prompt, I added a bit of context.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我本可以直接传递问题，但为了展示我可以在某种程度上影响提示，我添加了一些上下文。
- en: Note that the code above is completely LLM-agnostic, and there is no groveling,
    bribery, etc. in the prompt.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，上面的代码完全与LLM无关，且提示中没有任何谄媚、贿赂等内容。
- en: 'To call the above module, you first initialize dspy with an LLM:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要调用上述模块，首先初始化dspy并配置一个LLM：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, you invoke your module:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，调用你的模块：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When I did that, I got:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当我这么做时，得到了：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Want to use a different LLM? Change the settings configuration lines to:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 想要使用不同的LLM？将设置配置行更改为：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Text Extraction
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本提取
- en: If all DSPy were doing was making it easier to call out to LLMs and abstract
    out the LLM, people wouldn’t be this excited about DSPy. Let’s continue to build
    out the AI assistant and tour some of the other advantages as we go along.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果DSPy只是让调用LLMs更容易并且将LLM进行抽象化，那么人们也不会对DSPy如此兴奋。让我们继续构建AI助手，并在过程中展示一些其他的优势。
- en: 'Let’s say that we want to use an LLM to do some entity extraction. We can do
    this by instructing the LLM to identify the thing we want to extract (date, product
    SKU, etc.). Here, we’ll ask it to find bridge jargon:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想使用LLM进行实体提取。我们可以通过指示LLM识别我们要提取的内容（日期、产品SKU等）来实现。在这里，我们会要求它找出桥牌术语：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: While we could have represented the signature of the module as “prompt -> terms”,
    we can also represent the signature as a Python class.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们本可以将模块的签名表示为“提示 -> 条件”，但我们也可以将签名表示为一个Python类。
- en: 'Calling this module on a statement:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个语句上调用此模块：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We’ll get:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note how concise and readable this is.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这段代码是多么简洁和易读。
- en: RAG
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG
- en: 'DSPy comes built-in with several retrievers. But these essentially just functions
    and you can wrap existing retrieval code into a dspy.Retriever. It supports several
    of the more popular ones, including ChromaDB:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: DSPy内置了多个检索器。但这些本质上只是函数，你可以将现有的检索代码封装到dspy.Retriever中。它支持多个流行的检索器，包括ChromaDB：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Of course, I had to get a document on bridge bidding, chunk it, and load it
    into ChromaDB. That code is in the repo if you are interested, but I’ll omit it
    as it’s not relevant to this article.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我得先获取一本关于桥牌叫牌的文档，将其拆分并加载到ChromaDB中。如果你感兴趣，代码在仓库里，但由于与本文无关，我将略过不提。
- en: Orchestration
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编排
- en: So now you have all the agents implemented, each as its own dspy.Module. Now,
    to build the orchestrator LLM, the one that receives the command or trigger and
    invokes the agent modules in some fashion.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经实现了所有的代理，每个代理都是一个独立的dspy.Module。接下来，构建编排LLM，它接收命令或触发器并以某种方式调用代理模块。
- en: 'Orchestration of the modules also happens in a dspy.Module:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的编排也发生在一个dspy.Module中：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Instead of using dspy.Predict for the final step, I’ve used a ChainOfThought
    (COT=3).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有使用dspy.Predict作为最终步骤，而是使用了ChainOfThought（COT=3）。
- en: Optimizer
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化器
- en: Now that we have the entire chain all set up, we can of course, simply call
    the orchestrator module to test it out. But more important, we can have dspy automatically
    tune the prompts for us based on example data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了整个链条，我们当然可以直接调用调度模块来进行测试。但更重要的是，我们可以让dspy根据示例数据自动调整提示。
- en: 'To load in these examples and ask dspy to tune it (this is called a teleprompter,
    but the name will be changed to Optimizer, a much more descriptive name for what
    it does), I do:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载这些示例并让dspy进行调整（这叫做提示器，但这个名称将改为优化器，这更准确地描述了它的功能），我这样做：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: I used just 3 examples in the example above, but obviously, you’d use hundreds
    or thousands of examples to get a properly tuned set of prompts. Worth noting
    is that the tuning is done over the entire pipeline; you don’t have to mess around
    with the modules one by one.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我在上面的示例中只用了3个示例，但显然，你会使用成百上千个示例来获得一个经过适当调优的提示集。值得注意的是，调整是针对整个管道进行的；你不需要一个一个模块地调整。
- en: Is the optimized pipeline better?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 优化后的管道更好吗？
- en: 'While the original pipeline returned the following for this question (intermediate
    outputs are also shown, and Two spades is wrong):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 原始管道对这个问题的返回结果如下（也显示了中间输出，并且“两颗梅花”是错误的）：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The optimized pipeline returns the correct answer of “Smolen”:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 优化后的管道返回了正确答案“Smolen”：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The reason is the prompt that dspy has created. For the question “What is Stayman?”,
    for example, note that it has built a rationale out of the term definitions, and
    several matches in the RAG:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于dspy创建的提示。例如，对于问题“什么是Stayman？”，请注意，它已经根据术语定义和RAG中的多个匹配项构建了一个推理过程：
- en: '![](../Images/2474b11fcd12ed06f0e50c8693631c41.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2474b11fcd12ed06f0e50c8693631c41.png)'
- en: Prompt created by dspy.ChainOfThought based on the term definitions, RAG, etc.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 该提示由dspy.ChainOfThought根据术语定义、RAG等创建。
- en: Again, I didn’t write any of the tuned prompt above. It was all written for
    me. You can also see where this is headed in the future— you might be able to
    fine-tune the entire pipeline to run on a smaller LLM.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我并没有编写上面调整过的提示。这些都是为我编写的。你也可以看到这未来的发展方向——你可能能够微调整个管道，使其在更小的语言模型上运行。
- en: Enjoy!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你愉快！
- en: Next steps
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: Look at my [code in GitHub](https://github.com/lakshmanok/lakblogs/tree/main/bridge_bidding_advisor),
    starting with [bidding_advisor.py](https://github.com/lakshmanok/lakblogs/blob/main/bridge_bidding_advisor/bidding_advisor.py).
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看我的[GitHub代码](https://github.com/lakshmanok/lakblogs/tree/main/bridge_bidding_advisor)，从[bidding_advisor.py](https://github.com/lakshmanok/lakblogs/blob/main/bridge_bidding_advisor/bidding_advisor.py)开始。
- en: 'Read more about DSPy here: [https://dspy-docs.vercel.app/docs/intro](https://dspy-docs.vercel.app/docs/intro)'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里了解更多关于DSPy的信息：[https://dspy-docs.vercel.app/docs/intro](https://dspy-docs.vercel.app/docs/intro)
- en: 'Learn how to play bridge here: [https://www.trickybridge.com/](https://www.trickybridge.com/)
    (sorry, couldn’t resist).'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里学习如何玩桥牌：[https://www.trickybridge.com/](https://www.trickybridge.com/)（抱歉，我忍不住了）。
