- en: 'K Nearest Neighbor Regressor, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K最近邻回归器，解释：带代码示例的视觉指南
- en: 原文：[https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07](https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07](https://towardsdatascience.com/k-nearest-neighbor-regressor-explained-a-visual-guide-with-code-examples-df5052c8c889?source=collection_archive---------1-----------------------#2024-10-07)
- en: REGRESSION ALGORITHM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: Finding the neighbors FAST with KD Trees and Ball Trees
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用KD树和Ball树快速寻找邻居
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--df5052c8c889--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    ·11 min read·Oct 7, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df5052c8c889--------------------------------)
    ·阅读时间11分钟·2024年10月7日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
    [## K Nearest Neighbor Classifier, Explained: A Visual Guide with Code Examples
    for Beginners'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
    [## K近邻分类器，解释：带代码示例的初学者视觉指南'
- en: The friendly neighbor approach to machine learning
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习中的友好邻居方法
- en: towardsdatascience.com](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1?source=post_page-----df5052c8c889--------------------------------)'
- en: Building on our exploration of the [Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1),
    let’s turn to its sibling in the regression world. The Nearest Neighbor Regressor
    applies the same intuitive concept to predicting continuous values. But as our
    datasets get bigger, finding these neighbors efficiently becomes a real pain.
    That’s where KD Trees and Ball Trees come in.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨了[最近邻分类器](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)后，让我们转向回归领域中的“兄弟”——最近邻回归器。最近邻回归器将相同的直观概念应用于预测连续值。但是，随着数据集的增大，如何高效地找到这些邻居变得非常麻烦。这就是KD树和Ball树派上用场的地方。
- en: It’s super frustrating that there’s no clear guide out there that really explains
    what’s going on with these algorithms. Sure, there are some 2D visualizations,
    but they often don’t make it clear how the trees work in multidimensional setting.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 令人沮丧的是，目前没有明确的指南能够真正解释这些算法的运作原理。当然，有一些二维可视化图像，但它们通常无法清楚地展示树在多维环境中的工作方式。
- en: Here, we will explain what’s **actually** going on in these algorithms without
    using the oversimplified 2D representation. We’ll be focusing on the construction
    of the trees itself and see which computation (and numbers) actually matters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将解释这些算法**实际**是如何运作的，而不使用过于简化的二维表示。我们将专注于树的构建过程，并看看哪些计算（和数字）实际上是重要的。
- en: '![](../Images/00c7b6d82e926d5ce08ebc77977eab63.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00c7b6d82e926d5ce08ebc77977eab63.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可视化：作者使用Canva Pro创建，针对移动设备进行了优化；在桌面上可能显示过大。
- en: Definition
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: The Nearest Neighbor Regressor is a straightforward predictive model that estimates
    values by averaging the outcomes of nearby data points. This method builds on
    the idea that similar inputs likely yield similar outputs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻回归器是一个直接的预测模型，通过平均附近数据点的结果来估算值。该方法基于相似输入可能产生相似输出的理念。
- en: '![](../Images/aba12c7b4e3b510a0d187544f9510e12.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aba12c7b4e3b510a0d187544f9510e12.png)'
- en: Nearest Neighbor approaches are among the most basic yet powerful techniques
    in the machine learning toolkit. Their simplicity belies their effectiveness in
    many real-world scenarios.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻方法是机器学习工具包中最基础且强大的技术之一。它们的简单性掩盖了它们在许多实际场景中的有效性。
- en: 📊 Dataset Used
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📊 使用的数据集
- en: To illustrate our concepts, we’ll use [our usual dataset](/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629).
    This dataset helps predict the number of golfers visiting on any given day. It
    includes factors such as weather outlook, temperature, humidity, and wind conditions.
    Our goal is to estimate the daily golfer turnout based on these variables.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明我们的概念，我们将使用[我们通常的数据集](/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)。这个数据集有助于预测每天的高尔夫球手数量。它包括天气状况、温度、湿度和风速等因素。我们的目标是基于这些变量估算每日高尔夫球手的到场人数。
- en: '![](../Images/8f70777fcdcfbe631c352c17a649d816.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f70777fcdcfbe631c352c17a649d816.png)'
- en: 'Columns: ‘Outlook’, ‘Temperature’ (in Fahrenheit), ‘Humidity’ (in %), ‘Wind’
    (Yes/No) and ‘Number of Players’ (numerical, target feature)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 列：‘Outlook’（天气状况），‘Temperature’（温度，单位华氏度），‘Humidity’（湿度，单位%），‘Wind’（风速，是否有风），以及‘Number
    of Players’（玩家数量，数值型，目标特征）
- en: To use Nearest Neighbor Regression effectively, we need to preprocess our data.
    This involves [converting categorical variables into numerical format](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)
    and [scaling numerical features](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地使用最近邻回归，我们需要对数据进行预处理。这包括[将分类变量转换为数值格式](/encoding-categorical-data-explained-a-visual-guide-with-code-example-for-beginners-b169ac4193ae)和[缩放数值特征](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)。
- en: '![](../Images/856bb5024939a0acbe57928f62346faa.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/856bb5024939a0acbe57928f62346faa.png)'
- en: Standard scaling is applied to ‘Temperature’ and ‘Humidity’ while the one-hot
    encoding is applied to ‘Outlook’ and ‘Wind’
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对‘Temperature’（温度）和‘Humidity’（湿度）应用标准缩放，而对‘Outlook’（天气状况）和‘Wind’（风速）应用独热编码。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Main Mechanism
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要机制
- en: 'The Nearest Neighbor Regressor works similarly to its classifier counterpart,
    but instead of voting on a class, it averages the target values. Here’s the basic
    process:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻回归器的工作原理类似于其分类器对等物，但它不是对类别进行投票，而是对目标值进行平均。基本过程如下：
- en: Calculate the distance between the new data point and all points in the training
    set.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算新数据点与训练集中所有点之间的距离。
- en: Select the K nearest neighbors based on these distances.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据这些距离选择K个最近邻居。
- en: Calculate the average of the target values of these K neighbors.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算这些K个邻居的目标值的平均值。
- en: Assign this average as the predicted value for the new data point.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个平均值作为新数据点的预测值。
- en: '![](../Images/250524333fd9efd70666c9f0c773da69.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/250524333fd9efd70666c9f0c773da69.png)'
- en: The approach above, using all data points to find neighbors, is known as the
    **Brute Force** method. It’s straightforward but can be slow for large datasets.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法，即使用所有数据点来寻找邻居，称为**暴力搜索**方法。它简单直接，但对于大规模数据集来说可能比较慢。
- en: 'Here, we’ll explore two more efficient algorithms for finding nearest neighbors:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将探讨两种更高效的寻找最近邻居的算法：
- en: '**KD Tree for KNN Regression**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**KNN回归的KD树**'
- en: KD Tree (K-Dimensional Tree) is a binary tree structure used for organizing
    points in a *k*-dimensional space. It’s particularly useful for tasks like nearest
    neighbor searches and range searches in multidimensional data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: KD树（K维树）是一种二叉树结构，用于在*k*维空间中组织点。它特别适用于诸如最近邻搜索和多维数据范围搜索等任务。
- en: '**Training Steps:**'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**训练步骤：**'
- en: '1\. Build the KD Tree:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 构建KD树：
- en: a. Start with a root node that contains all the points.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: a. 从包含所有点的根节点开始。
- en: '![](../Images/f9eb3bb6d235cd561bf67f214fa3586f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9eb3bb6d235cd561bf67f214fa3586f.png)'
- en: b. Choose a feature to split on. Any random feature should be ok actually, but
    another good way to choose this is by looking which feature has median value closest
    to the midpoint between max and min value.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: b. 选择一个特征进行划分。实际上，选择任何一个随机特征都可以，但另一种较好的选择方式是查看哪个特征的中位数值最接近最大值与最小值之间的中点。
- en: '![](../Images/79a398331b63176a9e9084603cb200e9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79a398331b63176a9e9084603cb200e9.png)'
- en: Temperature has the midpoint line closest to the median line. We can start splitting
    from that dimension.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 温度具有最接近中位线的中点线。我们可以从该维度开始进行拆分。
- en: c. Split the tree in the chosen feature and midpoint.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: c. 在选定的特征和中点处分割树。
- en: '![](../Images/c1a195c9003c18519a00a688f662db95.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1a195c9003c18519a00a688f662db95.png)'
- en: d. Recursively, do step a-c until the stopping criterion, usually minimal leaf
    size (see [“min samples leaf” here](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/))
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: d. 递归地执行步骤a-c，直到达到停止标准，通常是最小叶子节点大小（见[这里的“最小样本叶子”](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)）
- en: '![](../Images/cfad5e8688c34aba173a931f66dbd614.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfad5e8688c34aba173a931f66dbd614.png)'
- en: '2\. Store the target values:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 存储目标值：
- en: Along with each point in the KD Tree, store its corresponding target value.
    The minimum and maximum value for each node are also stored.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在KD树中的每个点旁边存储其对应的目标值。每个节点的最小值和最大值也被存储。
- en: '![](../Images/3cf4c4165760cabc63946fa1328de2c8.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cf4c4165760cabc63946fa1328de2c8.png)'
- en: '**Regression/Prediction Steps:**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**回归/预测步骤：**'
- en: '1\. Traverse the KD Tree:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 遍历KD树：
- en: a. Start at the root node.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: a. 从根节点开始。
- en: b. Compare the query point (test point) with the splitting dimension and value
    at each node.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: b. 比较查询点（测试点）与每个节点处的分割维度和值。
- en: c. Recursively traverse left or right based on this comparison.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: c. 根据比较结果递归地向左或向右遍历。
- en: d. When reaching a leaf node, add its points to the candidate set.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: d. 当到达叶子节点时，将其点添加到候选集。
- en: '![](../Images/b6ac7ebb18046966c3e7886af47a307e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6ac7ebb18046966c3e7886af47a307e.png)'
- en: '2\. Refine the search:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 精细化搜索：
- en: a. Backtrack through the tree, checking if there could be closer points in other
    branches.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: a. 回溯树结构，检查其他分支是否有更接近的点。
- en: b. Use distance calculations to the maximum and minimum of the unexplored branches
    to determine if exploring is necessary.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: b. 使用未探索分支的最大值和最小值进行距离计算，以确定是否需要继续探索。
- en: '![](../Images/d7b70deaeed99a10b64698e7be1c231e.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7b70deaeed99a10b64698e7be1c231e.png)'
- en: We backtrack to the branches that has not been visited and check the distance
    to the minimum and maximum of those node.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回溯到未访问的分支，并检查那些节点的最小值和最大值的距离。
- en: '![](../Images/dfb1b7b1b636bee05aa2c2ce53805785.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfb1b7b1b636bee05aa2c2ce53805785.png)'
- en: As both the minimum and maximum of those nodes are further than kth distance,
    no need to check the distance to the data points in those nodes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些节点的最小值和最大值都比第k个距离远，因此无需检查这些节点中数据点的距离。
- en: '3\. Find K nearest neighbors:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 查找K个最近邻：
- en: a. Among the candidate points found, select the K points closest to the query
    point.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: a. 在找到的候选点中，选择与查询点最接近的K个点。
- en: '4\. Perform regression:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 执行回归：
- en: a. Calculate the average of the target values of the K nearest neighbors.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: a. 计算K个最近邻的目标值的平均值。
- en: b. This average is the predicted value for the query point.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: b. 这个平均值即为查询点的预测值。
- en: '![](../Images/73271b1d2aa3434168ed7b3c7b85b162.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73271b1d2aa3434168ed7b3c7b85b162.png)'
- en: By using a KD Tree, the average time complexity for finding nearest neighbors
    can be reduced from *O*(*n*) in the brute force method to *O*(log *n*) in many
    cases, where *n* is the number of points in the dataset. This makes KNN Regression
    much more efficient for large datasets.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用KD树，找到最近邻的平均时间复杂度可以从暴力搜索法中的*O*(*n*)减少到在许多情况下的*O*(log *n*)，其中*n*是数据集中的点数。这使得KNN回归在大数据集中的效率大大提高。
- en: '**Ball Tree for KNN Regression**'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**KNN回归中的球树**'
- en: Ball Tree is another space-partitioning data structure that organizes points
    in a series of nested hyperspheres. It’s particularly effective for high-dimensional
    data where KD Trees may become less efficient.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 球树是另一种空间划分数据结构，它通过一系列嵌套的超球面组织点。在高维数据中，KD树可能变得低效，而球树在这种情况下尤为有效。
- en: '**Training Steps:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练步骤：**'
- en: '1\. Build the Ball Tree:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 构建球树：
- en: a. Calculate the centroid of all points in the node (the mean). This becomes
    the **pivot point**.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: a. 计算节点中所有点的重心（均值）。这将成为**枢纽点**。
- en: '![](../Images/f4e68143b7ec7469a2c23cc8f59c3d50.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4e68143b7ec7469a2c23cc8f59c3d50.png)'
- en: 'b. Make the first branch:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: b. 构建第一个分支：
- en: '- **Finding the first center:** Choose the furthest point from the pivot point
    as the first center with its distance as the **radius**.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '- **找到第一个中心：** 选择距离枢纽点最远的点作为第一个中心，并将其距离作为**半径**。'
- en: '- **Finding the second center:** From the first center, select the furthest
    point as the second center.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '- **寻找第二个中心：** 从第一个中心出发，选择最远的点作为第二个中心。'
- en: '- **Partitioning:** Divide the remaining points into two child nodes based
    on which center they are closer to.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '- **分区：** 根据点更接近哪个中心将剩余的点分成两个子节点。'
- en: '![](../Images/3f318c1ad3e5909f1299034607cbb9d7.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f318c1ad3e5909f1299034607cbb9d7.png)'
- en: d. Recursively apply steps a-b to each child node until a stopping criterion
    is met, usually minimal leaf size (see [“min samples leaf” here](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 递归地对每个子节点应用步骤a-b，直到满足停止标准，通常是最小叶子节点大小（请参见[“最小样本叶子”](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e/)）。
- en: '![](../Images/7a2c7c38531c763643bd4d7f179f03e4.png)![](../Images/466452b8a11ac4c4308f57d663d4c728.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a2c7c38531c763643bd4d7f179f03e4.png)![](../Images/466452b8a11ac4c4308f57d663d4c728.png)'
- en: '2\. Store the target values:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 存储目标值：
- en: Along with each point in the Ball Tree, store its corresponding target value.
    The radius and centroid for each node are also stored.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每个Ball Tree中的点，存储其对应的目标值。每个节点的半径和质心也会被存储。
- en: '![](../Images/9883a4e7158dce6fa0413c88d60c6432.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9883a4e7158dce6fa0413c88d60c6432.png)'
- en: '**Regression/Prediction Steps:**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归/预测步骤：**'
- en: '1\. Traverse the Ball Tree:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 遍历Ball Tree：
- en: a. Start at the root node.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: a. 从根节点开始。
- en: b. At each node, calculate the distance between the unseen data and the center
    of each child hypersphere.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: b. 在每个节点上，计算未见数据与每个子超球中心之间的距离。
- en: c. Traverse into the closest hypersphere first.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: c. 首先遍历到最接近的超球。
- en: d. When reaching a leaf node, add its points to the candidate set.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: d. 当到达叶节点时，将其点添加到候选集。
- en: '![](../Images/85e4feaae0d4811c3cc6f20839783835.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85e4feaae0d4811c3cc6f20839783835.png)'
- en: '2\. Refine the search:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 精细化搜索：
- en: a. Determine if other branches need to be explored.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: a. 确定是否需要探索其他分支。
- en: b. If the distance to a hypersphere plus its radius is greater than the current
    Kth nearest distance, that branch can be safely ignored.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: b. 如果到超球的距离加上其半径大于当前第K个最近距离，则可以安全忽略该分支。
- en: '![](../Images/a55da95adf34346e7d47fb4f5f316f47.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a55da95adf34346e7d47fb4f5f316f47.png)'
- en: For those branches that we considered before, add the radius to the distance.
    If it is greater than the kth distance, no need to explore those balls.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于之前考虑过的分支，将半径加到距离上。如果该距离大于当前的第K个距离，则无需探索这些球。
- en: '![](../Images/0b1dfe1b420ff207edb0a413d4f3f131.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b1dfe1b420ff207edb0a413d4f3f131.png)'
- en: '3\. Find K nearest neighbors:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 查找K个最近邻：
- en: a. Among the candidate points found, select the K points closest to the query
    point.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: a. 从找到的候选点中，选择与查询点最接近的K个点。
- en: '4\. Perform regression:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 执行回归：
- en: a. Calculate the average of the target values of the K nearest neighbors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: a. 计算K个最近邻的目标值平均值。
- en: b. This average is the predicted value for the query point.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: b. 这个平均值就是查询点的预测值。
- en: '![](../Images/e2b2f49da2d913d67e259e3e5fa857fb.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2b2f49da2d913d67e259e3e5fa857fb.png)'
- en: Ball Trees can be more efficient than KD Trees for high-dimensional data or
    when the dimensionality is greater than the log of the number of samples. They
    maintain good performance even when the number of dimensions increases, making
    them suitable for a wide range of datasets.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Ball Tree对于高维数据或维度大于样本数量对数的情况比KD Tree更高效。即使维度增加，它们也能保持良好的性能，适用于广泛的数据集。
- en: The time complexity for querying in a Ball Tree is O(log *n*) on average, similar
    to KD Trees, but Ball Trees often perform better in higher dimensions where KD
    Trees may degrade to linear time complexity.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ball Tree中查询的时间复杂度通常是O(log *n*)，与KD Tree相似，但在高维度下，Ball Tree通常表现得更好，而KD Tree可能退化为线性时间复杂度。
- en: Evaluation Step (Brute Force, KD Tree, Ball Tree)
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估步骤（暴力法、KD树、Ball树）
- en: 'Regardless of the algorithm we choose, all of them give the same following
    result:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们选择哪种算法，它们都会给出相同的结果：
- en: '![](../Images/ac80599b3efec37df8746639217d7aea.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac80599b3efec37df8746639217d7aea.png)'
- en: Compared to [the result of the dummy regressor,](https://medium.com/towards-data-science/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)
    there is a major improvement for the value of RMSE.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与[虚拟回归器的结果](https://medium.com/towards-data-science/dummy-regressor-explained-a-visual-guide-with-code-examples-for-beginners-4007c3d16629)相比，RMSE值有了显著改善。
- en: Which Algorithm to Choose?
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择哪种算法？
- en: 'You can follow this simple rule for choosing the best one:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以遵循这个简单的规则来选择最优的算法：
- en: '- For small datasets (< 1000 samples), ‘brute’ might be fast enough and guarantees
    finding the exact nearest neighbors.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '- 对于小型数据集（< 1000样本），‘brute’可能足够快，并保证找到精确的最近邻。'
- en: '- For larger datasets with few features (< 20), ‘kd_tree’ is usually the fastest.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '- 对于特征较少的大型数据集（< 20），‘kd_tree’通常是最快的。'
- en: '- For larger datasets with many features, ‘ball_tree’ often performs best.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '- 对于具有许多特征的大型数据集，‘ball_tree’通常表现最佳。'
- en: 'The ‘auto’ option in scikit-learn typically follow the following chart:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn中的‘auto’选项通常遵循以下图表：
- en: '![](../Images/cdea807e4c32673c58a2daa66594870a.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cdea807e4c32673c58a2daa66594870a.png)'
- en: Key Parameters
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键参数
- en: While KNN regression has many other parameter, other than the algorithm we just
    discussed (brute force, kd tree, ball tree), you mainly need to consider
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然KNN回归有许多其他参数，除了我们刚刚讨论的算法（暴力法、kd树、ball树），但你主要需要考虑的是
- en: '**Number of Neighbors (K).**'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**邻居数（K）**'
- en: '- Smaller K: More sensitive to local patterns, but may lead to overfitting.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 较小的K：对局部模式更敏感，但可能导致过拟合。'
- en: '- Larger K: Smoother predictions, but might miss important local variations.'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 较大的K：平滑的预测，但可能错过重要的局部变化。'
- en: Unlike classification, **even numbers are fine** in regression as we’re averaging
    values.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与分类不同，**回归中偶数也可以**，因为我们是在对值进行平均。
- en: '**Leaf Size**'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**叶节点大小**'
- en: This is the stopping condition for building kd tree or ball tree. Generally,
    It affects the speed of construction and query, as well as the memory required
    to store the tree.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是构建kd树或ball树的停止条件。通常，它会影响构建和查询的速度，以及存储树所需的内存。
- en: Pros & Cons
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优缺点
- en: 'Pros:'
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点：
- en: '**Simplicity and Versatility**: Easy to understand and implement; can be used
    for both classification and regression tasks.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简洁性和多功能性**：易于理解和实现；可以用于分类和回归任务。'
- en: '**No Assumptions**: Doesn’t assume anything about the data distribution, making
    it suitable for complex datasets.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无假设**：不对数据分布做任何假设，使其适用于复杂数据集。'
- en: '**No Training Phase**: Can quickly incorporate new data without retraining.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无训练阶段**：可以快速纳入新数据，而无需重新训练。'
- en: '**Interpretability**: Predictions can be explained by examining nearest neighbors.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可解释性**：通过检查最近邻，可以解释预测结果。'
- en: '**Cons:**'
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**缺点：**'
- en: '**Computational Complexity**: Prediction time can be slow, especially with
    large datasets, though optimized algorithms (KD-Tree, Ball Tree) can help for
    lower dimensions.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算复杂度**：预测时间可能较慢，尤其是对于大数据集，尽管优化算法（KD-Tree、Ball Tree）在低维情况下能有所帮助。'
- en: '**Curse of Dimensionality**: Performance degrades in high-dimensional spaces,
    affecting both accuracy and efficiency.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**维度灾难**：在高维空间中，性能会下降，影响准确性和效率。'
- en: '**Memory Intensive**: Requires storing all training data.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内存密集型**：需要存储所有训练数据。'
- en: '**Sensitive to Feature Scaling and Irrelevant Features**: Can be biased by
    features on larger scales or those unimportant to the prediction.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对特征缩放和无关特征敏感**：可能会受到较大尺度特征或对预测无关特征的偏倚。'
- en: Final Remarks
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终备注
- en: The K-Nearest Neighbors (KNN) regressor is a basic yet powerful tool in machine
    learning. Its straightforward approach makes it great for beginners, and its flexibility
    ensures it’s useful for experts too.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: K最近邻（KNN）回归器是机器学习中一个基本而强大的工具。它简单直观，非常适合初学者，而且其灵活性确保它对专家同样有用。
- en: As you learn more about data analysis, use KNN to understand the basics of regression
    before exploring more advanced methods. By mastering KNN and how to compute the
    nearest neighbors, you’ll build a strong foundation for tackling more complex
    challenges in data analysis.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你对数据分析的了解逐渐深入，可以使用KNN来理解回归的基础知识，然后再探索更高级的方法。通过掌握KNN和如何计算最近邻，你将为处理更复杂的数据分析挑战打下坚实的基础。
- en: 🌟 k Nearest Neighbor Regressor Code Summarized
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 K最近邻回归器代码概述
- en: '[PRE1]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Further Reading
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For a detailed explanation of the [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html),
    [KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html),
    [BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html),
    and its implementation in scikit-learn, readers can refer to their official documentation.
    It provides comprehensive information on their usage and parameters.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 有关[KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)、[KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html)、[BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html)及其在scikit-learn中的实现的详细说明，读者可以参考其官方文档。它提供了关于这些工具的使用及参数的全面信息。
- en: Technical Environment
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的是Python 3.7和scikit-learn 1.5版本。虽然讨论的概念普遍适用，但不同版本之间的具体代码实现可能会略有不同。
- en: About the Illustrations
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者创建，并融合了来自Canva Pro的授权设计元素。
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙍𝙚𝙜𝙧𝙚𝙨𝙨𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝙍𝙚𝙜𝙧𝙚𝙨𝙨𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
- en: Regression Algorithms
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----df5052c8c889--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This “dummy” doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----df5052c8c889--------------------------------)5篇故事![一只扎着辫子戴着粉红色帽子的卡通娃娃。这个“假人”娃娃，凭借其基本设计和心形装饰的衬衫，形象地展示了机器学习中的假回归器概念。就像这个玩具般的形象是一个简化的、静态的人物表达一样，假回归器也是一个基本模型，用作更复杂分析的基准。](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----df5052c8c889--------------------------------)'
- en: Classification Algorithms
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----df5052c8c889--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----df5052c8c889--------------------------------)8篇故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
