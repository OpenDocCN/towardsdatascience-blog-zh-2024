- en: Improving Generalization in Survival Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高生存模型的泛化能力
- en: 原文：[https://towardsdatascience.com/improving-generalization-in-survival-models-bb7bc045bfc6?source=collection_archive---------8-----------------------#2024-04-05](https://towardsdatascience.com/improving-generalization-in-survival-models-bb7bc045bfc6?source=collection_archive---------8-----------------------#2024-04-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/improving-generalization-in-survival-models-bb7bc045bfc6?source=collection_archive---------8-----------------------#2024-04-05](https://towardsdatascience.com/improving-generalization-in-survival-models-bb7bc045bfc6?source=collection_archive---------8-----------------------#2024-04-05)
- en: Suggestions for estimating and enhancing predictive accuracy for the employee
    attrition case
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于估算和提高员工流失预测准确性的建议
- en: '[](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)[![Nicolas
    Lupi](../Images/7f0735890a77b9ef601dc6cd54a9a861.png)](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)
    [Nicolas Lupi](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)[![Nicolas
    Lupi](../Images/7f0735890a77b9ef601dc6cd54a9a861.png)](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)
    [Nicolas Lupi](https://medium.com/@nicolupi.2?source=post_page---byline--bb7bc045bfc6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)
    ·10 min read·Apr 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bb7bc045bfc6--------------------------------)
    ·阅读时长 10 分钟·2024年4月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dfd4bd0b1d93bed1196e1eee0d262947.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfd4bd0b1d93bed1196e1eee0d262947.png)'
- en: Photo by [Israel Andrade](https://unsplash.com/@israelandrxde?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Israel Andrade](https://unsplash.com/@israelandrxde?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Recently, I’ve come up with a particular issue when dealing with survival analysis:
    many models I fitted performed well in theory, with strong test metrics, but then
    failed to predict the true outcomes that were observed in practice. In this article,
    I want to discuss ways to better estimate the performance of our survival models,
    and a practical tip to help with extrapolation. Note: the main assumption here
    is that **we count with several observations of our individuals over time** (e.g.,
    monthly observations for all the employees in a company).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我在进行生存分析时遇到了一个问题：我拟合的许多模型在理论上表现良好，测试指标很强，但在实际操作中却未能准确预测观察到的真实结果。在本文中，我将讨论如何更好地估算生存模型的表现，并分享一个帮助外推的实用技巧。注意：这里的主要假设是**我们在一段时间内对个体进行了多次观察**（例如，公司中所有员工的月度观察数据）。
- en: The problem I was dealing with was the employee attrition case. I had information
    about several employees in a company, and I was interested in predicting which
    of them were most likely to leave in the future. If you want to explore the employee
    attrition topic further, make sure to check out this helpful [article](/cracking-the-employee-attrition-problem-with-machine-learning-6ee751ec4aae).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我处理的问题是员工流失的案例。我拥有一家公司若干员工的信息，目标是预测哪些员工在未来最有可能离职。如果你想深入了解员工流失问题，确保查看这篇有用的[文章](/cracking-the-employee-attrition-problem-with-machine-learning-6ee751ec4aae)。
- en: Traditional Approach
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统方法
- en: 'Many existing implementations on survival analysis start off with a dataset
    containing **one observation per individual** (patients in a health study, employees
    in the attrition case, clients in the client churn case, and so on). For these
    individuals we typically have two key variables: one signaling the event of interest
    (an employee quitting) and another measuring time (how long they’ve been with
    the company, up to either today or their departure). Together with these two variables,
    we then have explanatory variables with which we aim to predict the risk of each
    individual. These features can include the job role, age or compensation of the
    employee, for example.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现有的生存分析实现从包含**每个个体一条观察数据**的数据集开始（如健康研究中的患者、员工流失案例中的员工、客户流失案例中的客户等）。对于这些个体，我们通常有两个关键变量：一个表示感兴趣事件的发生（员工辞职），另一个测量时间（他们在公司工作的时长，直到今天或他们的离职时间）。结合这两个变量，我们接着有一些解释变量，用来预测每个个体的风险。这些特征可以包括员工的职位、年龄或薪酬等。
- en: Moving on, most implementations out there take a survival model (from simpler
    estimators such as Kaplan Meier to more complex ones like ensemble models or even
    neural networks), fit them over a train set and then evaluate over a test set.
    This train-test split is usually performed over the individual observations, generally
    making a stratified split.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，大多数现有的实现都会采用一个生存模型（从简单的估计器，如Kaplan Meier，到更复杂的模型，如集成模型甚至神经网络），将其在训练集上拟合，然后在测试集上评估。通常，这种训练-测试拆分是基于个体观察数据进行的，通常会进行分层拆分。
- en: 'In my case, I started with a dataset that followed several employees in a company
    monthly until December 2023 (in case the employee was still at the company), or
    until the month they left the company — the event date:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的案例中，我从一个数据集开始，数据集记录了几名员工在公司每月的情况，直到2023年12月（如果该员工仍在公司），或者直到他们离职的月份——即事件日期：
- en: '![](../Images/b83d30874eb025f12a3959b6542b2014.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b83d30874eb025f12a3959b6542b2014.png)'
- en: Taking the last record of each employee — Image by author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 采用每个员工的最后记录 — 图片来源：作者
- en: 'In order to adapt my data to the survival case, I took the last observation
    of each employee as shown in the picture above (the blue dots for active employees,
    and the red crosses for employees who left). At that point for each employee,
    I recorded whether the event had occurred at that date or not (if they were active
    or if they had left), their tenure in months at that time, and all their explanatory
    variables. I then performed a stratified train-test split over this data, like
    this:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我的数据适配到生存分析的案例中，我采集了每个员工的最后一次观察，如上图所示（蓝色点表示在职员工，红色叉表示离职员工）。在这一时刻，对于每个员工，我记录了该事件是否发生（即他们是否仍在职或已经离职），他们当时的在职时长（按月计算），以及他们的所有解释变量。然后，我在这些数据上进行了分层的训练-测试拆分，过程如下：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After performing the split, I proceeded to fit a model. In this case, I chose
    to experiment with a **Random Survival Forest** using the [scikit-survival](https://scikit-survival.readthedocs.io/en/stable/)
    library.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 拆分完成后，我开始拟合一个模型。在这种情况下，我选择了使用[scikit-survival](https://scikit-survival.readthedocs.io/en/stable/)库进行**随机生存森林**的实验。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After a quick run using the default settings of the model, I was thrilled with
    the test metrics I saw. First of all, I was getting a **concordance index** above
    0.90 in the test set. The concordance index is a measure of how well the model
    predicts the order of events: it reflects whether employees predicted to be at
    high risk were indeed the ones leaving the company first. An index of 1 corresponds
    to perfect prediction accuracy, while an index of 0.5 indicates a prediction no
    better than random chance.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用模型默认设置快速运行后，我对测试集上看到的度量结果感到非常兴奋。首先，我在测试集中获得了**一致性指数**高于0.90。一致性指数是衡量模型预测事件顺序的准确度：它反映了是否预测为高风险的员工确实是首先离开公司的员工。指数为1表示完美的预测准确性，而0.5则表示预测与随机猜测一样糟糕。
- en: I was particularly interested in seeing if the employees who left in the test
    set matched with the most risky employees according to the model. In the case
    of the Random Survival Forest, the model returns the risk scores of each observation.
    I took the percentage of employees who left the company in the test set, and used
    it to filter the most risky employees according to the model. The results were
    very solid, with the employees flagged with the most risk matching almost perfectly
    with the actual leavers, with an F1 score above 0.90 in the minority class.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别感兴趣的是，测试集中离职的员工是否与模型认为风险最高的员工相匹配。在随机生存森林模型的情况下，模型返回了每个观察值的风险分数。我取了测试集中离职员工的比例，并用它来筛选模型认为最有风险的员工。结果非常可靠，风险最高的员工几乎完全与实际离职员工匹配，少数类的F1得分超过了0.90。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/74122d67e23cd850b485539e7e9f5dd3.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74122d67e23cd850b485539e7e9f5dd3.png)'
- en: 'Getting +0.9 metrics on the first run should set off an alarm: was the model
    really able to predict whether an employee was going to stay or leave with such
    confidence? Imagine this: we submit our predictions saying which employees are
    most likely to leave. However, a couple months go by, and HR then reaches us worried,
    saying that the people who left during the last period, did not exactly match
    with our predictions, at least at the rate it was expected from our test metrics.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次运行时获得+0.9的指标应该引起警觉：模型真的能如此自信地预测一个员工是否会留下吗？想象一下：我们提交了预测结果，指出哪些员工最有可能离职。然而，几个月后，人力资源部门联系了我们，表示他们对上个周期离职的员工与我们的预测结果并不完全匹配，至少从我们的测试指标来看，并没有达到预期的离职率。
- en: 'We have two main problems here: the first one is that our model isn’t extrapolating
    quite as well as we thought. The second one, and even worse, is that we weren’t
    able to measure this lack of performance. First, I’ll show a simple way we can
    estimate how well our model is truly extrapolating, and then I’ll talk about one
    potential reason it may be failing to do so, and how to mitigate it.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里有两个主要问题：第一个问题是我们的模型的外推能力没有我们想象的那么好。第二个问题，更糟糕的是，我们无法衡量这种性能缺失。首先，我将展示一种简单的方法，用来估计我们的模型究竟外推得怎么样，然后我将讨论一个可能的原因，为什么它可能没有做到这一点，并且如何缓解这个问题。
- en: Estimating Generalization Capabilities
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 估计泛化能力
- en: 'The key here is having access to panel data, that is, several records of our
    individuals over time, up until the time of event or the time the study ended
    (the date of our snapshot, in the case of employee attrition). Instead of discarding
    all this information and keeping only the last record of each employee, we could
    use it to create a test set that will better reflect how the model performs in
    the future. The idea is quite simple: suppose we have monthly records of our employees
    up until December 2023\. We could move back, say, 6 months, and pretend we took
    the snapshot in June instead of December. Then, we would take the last observation
    for employees who left the company before June 2023 as positive events, and the
    June 2023 record of employees who survived beyond that date as negative events,
    even if we already know some of them eventually left afterwards. We are pretending
    we don’t know this yet.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键是拥有面板数据，也就是我们在一段时间内记录的多个个体的记录，直到事件发生时或研究结束时（在员工流失的情况下，指的是快照的日期）。我们可以利用这些信息，而不是仅仅丢弃这些数据，只保留每个员工的最后一条记录，从而创建一个更能反映模型未来表现的测试集。这个想法很简单：假设我们有员工直到2023年12月的每月记录。我们可以往回推，比如6个月，假装我们是在六月而不是十二月拍摄了快照。然后，我们将之前离职的员工的最后一条记录（即2023年6月之前离职的员工）作为正事件，而2023年6月之后仍然留在公司员工的记录则作为负事件，即使我们已经知道其中一些员工之后离职了。我们假装我们现在还不知道这一点。
- en: '![](../Images/357382f4ce299d98ec4b62b23be4ddfb.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/357382f4ce299d98ec4b62b23be4ddfb.png)'
- en: We take a snapshot in June 2023 and use the following period as our test set
    — Image by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在2023年6月拍摄了一张快照，并使用接下来的时间段作为我们的测试集——图像来源：作者
- en: 'As the picture above shows, I take a snapshot in June, and all employees who
    were active at that time are taken as active. The test dataset takes all those
    active employees at June with their explanatory variables as they were on that
    date, and takes the latest tenure they achieved by December:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，我在六月拍摄了一张快照，所有当时活跃的员工都被视为活跃员工。测试数据集使用了这些六月时活跃的员工，以及他们在那一天的解释变量，并且使用了他们到十二月为止的最新任期：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We fit our model again on this new train data, and once we finish we make our
    predictions for all employees who were active on June. We then compare these predictions
    to the actual outcome of July — December 2023 — this is our test set. If those
    employees we marked as having the most risk left during the semester, and those
    we marked as having the lowest risk didn’t leave, or left rather late in the period,
    then our model is extrapolating well. By shifting our analysis back in time and
    leaving the last period for evaluation, we can have a better understanding of
    how well our model is generalizing. Of course, we could take this one step further
    and perform some type of time-series cross validation. For example, we could iterate
    this process many times, each time moving 6 months back in time, and evaluating
    the model’s accuracy over several time frames.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次在这组新的训练数据上训练模型，完成后我们为所有在六月份仍然活跃的员工做出预测。然后，我们将这些预测与2023年7月至12月的实际结果进行比较——这就是我们的测试集。如果我们标记为风险最高的员工在学期中离开，而标记为风险最低的员工没有离开，或者在较晚的时间离开，那么我们的模型在推断方面表现良好。通过将分析回溯到过去一段时间，并将最后一段时间用于评估，我们可以更好地理解模型的泛化能力。当然，我们还可以进一步采取一些时间序列交叉验证。例如，我们可以多次迭代这个过程，每次将时间向后移动6个月，并评估模型在多个时间段上的准确性。
- en: 'After training our model once again, we now see a drastic decrease in performance.
    First of all, the concordance index is now around 0.5 — equivalent to that of
    a random predictor. Also, if we try to match the ‘n’ most risky employees according
    to the model with the ‘n’ employees who left in the test set, we see a very poor
    classification with a 0.15 F1 for the minority class:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 经过再次训练我们的模型后，我们现在看到性能出现了显著下降。首先，协和指数现在大约为0.5——相当于一个随机预测器的表现。而且，如果我们根据模型将“n”个最具风险的员工与测试集中离职的“n”个员工进行匹配，我们会看到非常差的分类效果，少数类的F1值为0.15：
- en: '![](../Images/71f02778139d87f07c0cdcdbe1f7e231.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71f02778139d87f07c0cdcdbe1f7e231.png)'
- en: So clearly there is something wrong, but at least we are now able to detect
    it instead of being misled. The main takeaway here is that our model performs
    well with a traditional split, but doesn’t extrapolate when doing a time-based
    split. This is a clear sign that some time bias may be present. In short, time-dependent
    information is being leaked and our model is overfitting over it. This is common
    in cases like our employee attrition problem, when the dataset comes from a snapshot
    taken at some date.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以显然存在一些问题，但至少现在我们能够检测到这一点，而不是被误导。这里的主要结论是，我们的模型在传统的训练/测试集划分下表现良好，但在时间基础的划分下却无法进行良好的推断。这明显表明可能存在某种时间偏差。简而言之，时间依赖性信息正在泄露，导致我们的模型对其过拟合。这在像员工流失问题这样的情况下很常见，当数据集来自某个时间点的快照时。
- en: Time Bias
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间偏差
- en: 'The problem cuts down to this: all our positive observations (employees who
    left) belong to past dates, and all our negative observations (currently active
    employees) are all measured on the same date — today. If there is a single feature
    that reveals this to the model, then **instead of predicting risk we will be predicting
    if an employee was recorded in December 2023 or before**. This could be very subtle.
    For example, one feature we could be using is the engagement score of the employees.
    This feature could well show some seasonal patterns, and measuring it at the same
    time for active employees will surely introduce some bias in the model. Maybe
    in December, during the holiday season, this engagement score tends to decrease.
    The model will see a low score associated with all active employees, so it may
    learn to predict that whenever the engagement runs low, the churn risk also goes
    down, when in fact it should be the opposite!'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 问题归结为这一点：我们所有的正向观测（离职的员工）都属于过去的日期，而所有的负向观测（当前活跃的员工）都在同一个日期上进行测量——今天。如果有一个特征能够揭示这一点给模型，那么**我们将预测的不是风险，而是在预测一个员工是否在2023年12月或之前被记录下来**。这可能是非常微妙的。例如，我们可能使用的一个特征是员工的参与度评分。这个特征可能会表现出某些季节性模式，而在同一时间测量所有活跃员工的参与度评分，肯定会引入一些偏差。比如在12月，假期季节时，参与度评分可能会下降。模型会看到所有活跃员工的低评分，因此它可能学会预测每当参与度低时，流失风险也会下降，然而实际上应该是相反的！
- en: 'By now, a simple yet quite effective solution for this problem should be clear:
    instead of taking the last observation for each active employee, we could just
    pick a random month from all their history within the company. This will strongly
    reduce the chances of the model picking on any temporal patterns that we do not
    want it to overfit on:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，一个简单而有效的解决方案应该已经很清楚：我们可以不再取每个活跃员工的最后一次观察记录，而是从他们在公司里的所有历史中随机选择一个月。这样可以大大减少模型过拟合任何我们不希望它拟合的时间模式的可能性。
- en: '![](../Images/91f71a2a045d65eb1a5ea1334e4ac4a5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91f71a2a045d65eb1a5ea1334e4ac4a5.png)'
- en: For the active employees, we take random records rather than their last one
    — Image by author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于活跃员工，我们选择随机记录，而不是他们的最后一条记录——图片由作者提供
- en: 'In the picture above we can see that we are now spanning a broader set of dates
    for the active employees. Instead of using their blue dots at June 2023, we take
    the random orange dots instead, and record their variables at the time, and the
    tenure they had so far in the company:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图片中，我们可以看到现在对于活跃员工，我们涵盖了更广泛的日期范围。我们不再使用2023年6月的蓝点，而是使用随机的橙点，并记录当时的变量以及他们在公司的任期：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We then train our model once again, and evaluate it over the same test set we
    had before. We now see a concordance index of around 0.80\. This isn’t the +0.90
    we had earlier, but it definitely is a step up from the random-chance level of
    0.5\. Regarding our interest in classifying employees, we are still very far off
    the +0.9 F1 we had before, but we do see a slight increase compared to the previous
    approach, especially for the minority class.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们再次训练模型，并在之前相同的测试集上评估它。我们现在看到的协调指数大约为0.80。虽然没有之前的+0.90，但它确实比随机机会水平0.5有所提升。就我们对员工分类的兴趣而言，尽管仍远未达到之前的+0.9
    F1分数，但与之前的方法相比，我们确实看到了一些提高，尤其是在少数类别上。
- en: '![](../Images/20c597ea36649a8d8a34dc2d1c9c132b.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20c597ea36649a8d8a34dc2d1c9c132b.png)'
- en: Closing Remarks
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束语
- en: 'To sum up, here are the main takeaways from our discussion:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是我们讨论的主要要点：
- en: It’s important to pay attention to the dates the observations were recorded
    — there is a high chance some sort of time bias is present, especially if all
    the observations of one of the event classes share the same date
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要的是要注意观察记录的日期——如果所有某一事件类别的观察记录共享相同的日期，那么很可能存在某种时间偏差。
- en: If we have past observations for our individuals, we can better estimate the
    performance of our models by setting aside a time period for testing, instead
    of performing a traditional train-test split over the individual observations
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们拥有个体的过去观察记录，我们可以通过预留一段时间用于测试，而不是对个体观察记录进行传统的训练-测试拆分，从而更好地评估模型的表现。
- en: If there is a strong performance decrease between the traditional approach and
    the time-based test split, this could be a sign of time bias
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果传统方法与基于时间的测试集拆分之间存在明显的性能下降，这可能是时间偏差的一个迹象。
- en: One simple way to mitigate this, at least in part, is to randomly choose observations
    for each individual, instead of taking their last record for each
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种简单的缓解方法（至少部分缓解）是随机选择每个个体的观察记录，而不是取他们的最后一次记录。
- en: I hope this walkthrough was useful. If you’ve been dealing with similar issues
    in survival analysis, I’d love to hear whether this approach works for you too.
    Thanks for reading!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这次讲解对你有所帮助。如果你在生存分析中遇到类似的问题，我很想知道这种方法是否对你也有效。感谢阅读！
