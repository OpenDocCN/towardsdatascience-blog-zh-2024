- en: Exploring Object Detection with R-CNN Models â€” A Comprehensive Beginnerâ€™s Guide
    (Part 2)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¢ç´¢ä½¿ç”¨R-CNNæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹â€”â€”å…¨é¢çš„åˆå­¦è€…æŒ‡å—ï¼ˆç¬¬2éƒ¨åˆ†ï¼‰
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/exploring-object-detection-with-r-cnn-models-a-comprehensive-beginners-guide-part-2-685bc89775e2?source=collection_archive---------5-----------------------#2024-02-17](https://towardsdatascience.com/exploring-object-detection-with-r-cnn-models-a-comprehensive-beginners-guide-part-2-685bc89775e2?source=collection_archive---------5-----------------------#2024-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/exploring-object-detection-with-r-cnn-models-a-comprehensive-beginners-guide-part-2-685bc89775e2?source=collection_archive---------5-----------------------#2024-02-17](https://towardsdatascience.com/exploring-object-detection-with-r-cnn-models-a-comprehensive-beginners-guide-part-2-685bc89775e2?source=collection_archive---------5-----------------------#2024-02-17)
- en: Object detection models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ£€æµ‹æ¨¡å‹
- en: '[](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)[![Raghav
    Bali](../Images/49fea68f38f59d0bc39dab484b55684f.png)](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)
    [Raghav Bali](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)[![Raghav
    Bali](../Images/49fea68f38f59d0bc39dab484b55684f.png)](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)
    [Raghav Bali](https://medium.com/@Rghv_Bali?source=post_page---byline--685bc89775e2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)
    Â·7 min readÂ·Feb 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--685bc89775e2--------------------------------)
    Â·é˜…è¯»æ—¶é—´ï¼š7åˆ†é’ŸÂ·2024å¹´2æœˆ17æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/77bfdeb62b64a50add93691e90b907d5.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77bfdeb62b64a50add93691e90b907d5.png)'
- en: Photo by [liam siegel](https://unsplash.com/@datalore?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ‘„å½±ï¼š [liam siegel](https://unsplash.com/@datalore?utm_source=medium&utm_medium=referral)
    æ¥è‡ª[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Object Detection Models
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ£€æµ‹æ¨¡å‹
- en: Object detection is an involved process which helps in localization and classification
    of objects in a given image. In [part 1](/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78),
    we developed an understanding of the basic concepts and the general framework
    for object detection. In this article, we will briefly cover a number of important
    object detection models with a focus on understanding their key contributions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ£€æµ‹æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹ï¼Œå¸®åŠ©åœ¨ç»™å®šå›¾åƒä¸­è¿›è¡Œç›®æ ‡çš„å®šä½å’Œåˆ†ç±»ã€‚åœ¨[ç¬¬1éƒ¨åˆ†](/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78)ä¸­ï¼Œæˆ‘ä»¬ç†è§£äº†ç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œä¸€èˆ¬æ¡†æ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ç®€è¦ä»‹ç»ä¸€äº›é‡è¦çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œé‡ç‚¹ç†è§£å®ƒä»¬çš„å…³é”®è´¡çŒ®ã€‚
- en: The general object detection framework highlights the fact that there are a
    few interim steps to perform object detection. Building on the same thought process,
    researchers have come up with a number of innovative architectures which solve
    this task of object detection. One of the ways of segregating such models is in
    the way they tackle the given task. Object detection models which leverage multiple
    models and/or steps to solve this task as called as multi-stage object detectors.
    The Region based CNN (RCNN) family of models are a prime example of **multi-stage
    object detectors**. Subsequently, a number of improvements led to model architectures
    that solve this task using a single model itself. Such models are called as **single-stage
    object detectors**. We will cover single-stage models in a subsequent article.
    For now, let us now have a look under the hood for some of these multi-stage object
    detectors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶çªå‡ºäº†ç›®æ ‡æ£€æµ‹è¿‡ç¨‹ä¸­éœ€è¦æ‰§è¡Œçš„ä¸€äº›ä¸­é—´æ­¥éª¤ã€‚åœ¨è¿™ä¸ªæ€ç»´æ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œç ”ç©¶äººå‘˜æå‡ºäº†è®¸å¤šåˆ›æ–°çš„æ¶æ„æ¥è§£å†³ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚å°†è¿™äº›æ¨¡å‹è¿›è¡Œåˆ†ç±»çš„ä¸€ç§æ–¹å¼æ˜¯æ ¹æ®å®ƒä»¬å¤„ç†ä»»åŠ¡çš„æ–¹å¼ã€‚åˆ©ç”¨å¤šä¸ªæ¨¡å‹å’Œ/æˆ–æ­¥éª¤æ¥è§£å†³æ­¤ä»»åŠ¡çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹è¢«ç§°ä¸ºå¤šé˜¶æ®µç›®æ ‡æ£€æµ‹å™¨ã€‚åŸºäºåŒºåŸŸçš„CNNï¼ˆRCNNï¼‰æ¨¡å‹å®¶æ—æ˜¯**å¤šé˜¶æ®µç›®æ ‡æ£€æµ‹å™¨**çš„å…¸å‹ä¾‹å­ã€‚éšåï¼Œè®¸å¤šæ”¹è¿›å¯¼è‡´äº†ä½¿ç”¨å•ä¸€æ¨¡å‹æœ¬èº«æ¥è§£å†³æ­¤ä»»åŠ¡çš„æ¨¡å‹æ¶æ„ã€‚è¿™äº›æ¨¡å‹è¢«ç§°ä¸º**å•é˜¶æ®µç›®æ ‡æ£€æµ‹å™¨**ã€‚æˆ‘ä»¬å°†åœ¨åç»­çš„æ–‡ç« ä¸­è®¨è®ºå•é˜¶æ®µæ¨¡å‹ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™äº›å¤šé˜¶æ®µç›®æ ‡æ£€æµ‹å™¨çš„ä¸€äº›å†…éƒ¨å·¥ä½œåŸç†ã€‚
- en: Region Based Convolutional Neural Networks
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŸºäºåŒºåŸŸçš„å·ç§¯ç¥ç»ç½‘ç»œ
- en: Region based Convolutional Neural Networks (R-CNNs) were initially presented
    by Girshick et. al. in their paper titled â€œ[Rich feature hierarchies for accurate
    object detection and semantic segmentation](https://arxiv.org/abs/1311.2524)â€
    in 2013\. R-CNN is a multi-stage object detection models which became the starting
    point for faster and more sophisticated variants in following years. Letâ€™s get
    started with this base idea before we understand the improvements achieved through
    **Fast R-CNN** and **Faster R-CNN** models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºåŒºåŸŸçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆR-CNNï¼‰æœ€åˆç”± Girshick ç­‰äººäº 2013 å¹´åœ¨ä»–ä»¬çš„è®ºæ–‡ â€œ[Rich feature hierarchies for
    accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524)â€
    ä¸­æå‡ºã€‚R-CNN æ˜¯ä¸€ç§å¤šé˜¶æ®µç‰©ä½“æ£€æµ‹æ¨¡å‹ï¼Œæˆä¸ºåç»­æ›´å¿«ã€æ›´å¤æ‚çš„å˜ç§çš„èµ·ç‚¹ã€‚åœ¨ç†è§£é€šè¿‡ **Fast R-CNN** å’Œ **Faster R-CNN**
    æ¨¡å‹å–å¾—çš„æ”¹è¿›ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆä»è¿™ä¸ªåŸºç¡€æ€æƒ³å¼€å§‹ã€‚
- en: 'The R-CNN model is made up of four main components:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: R-CNN æ¨¡å‹ç”±å››ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†æ„æˆï¼š
- en: '**Region Proposal**: The extraction of regions of interest is the first and
    foremost step in this pipeline. The R-CNN model makes use of an algorithm called
    Selective Search for region proposal. Selective Search is a greedy search algorithm
    proposed by [Uijlings et. al](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf).
    in 2012\. Without going into too many details, selective search makes use of a
    bottoms-up multi-scale iterative approach to identify ROIs. In every iteration
    the algorithm groups similar regions until the whole image is a single region.
    Similarity between regions is calculated based on color, texture, brightness etc.
    Selective search generates a lot of false positive (background) ROIs but has a
    high recall. The list of ROIs is passed onto the next step for processing.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŒºåŸŸæè®®**ï¼šæå–æ„Ÿå…´è¶£åŒºåŸŸæ˜¯è¯¥æµç¨‹ä¸­çš„ç¬¬ä¸€æ­¥ä¹Ÿæ˜¯æœ€é‡è¦çš„ä¸€æ­¥ã€‚R-CNN æ¨¡å‹ä½¿ç”¨åä¸ºé€‰æ‹©æ€§æœç´¢ï¼ˆSelective Searchï¼‰çš„ç®—æ³•è¿›è¡ŒåŒºåŸŸæè®®ã€‚é€‰æ‹©æ€§æœç´¢æ˜¯ç”±
    [Uijlings ç­‰äºº](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) äº
    2012 å¹´æå‡ºçš„ä¸€ç§è´ªå¿ƒæœç´¢ç®—æ³•ã€‚ç®€å•æ¥è¯´ï¼Œé€‰æ‹©æ€§æœç´¢åˆ©ç”¨è‡ªåº•å‘ä¸Šçš„å¤šå°ºåº¦è¿­ä»£æ–¹æ³•æ¥è¯†åˆ« ROIã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œç®—æ³•å°†ç›¸ä¼¼çš„åŒºåŸŸè¿›è¡Œåˆ†ç»„ï¼Œç›´åˆ°æ•´å¼ å›¾åƒè¢«å½’ä¸ºä¸€ä¸ªåŒºåŸŸã€‚åŒºåŸŸä¹‹é—´çš„ç›¸ä¼¼æ€§æ˜¯åŸºäºé¢œè‰²ã€çº¹ç†ã€äº®åº¦ç­‰è®¡ç®—çš„ã€‚é€‰æ‹©æ€§æœç´¢ä¼šç”Ÿæˆå¤§é‡çš„å‡é˜³æ€§ï¼ˆèƒŒæ™¯ï¼‰ROIï¼Œä½†å…·æœ‰è¾ƒé«˜çš„å¬å›ç‡ã€‚ROI
    åˆ—è¡¨å°†ä¼ é€’åˆ°ä¸‹ä¸€æ­¥è¿›è¡Œå¤„ç†ã€‚'
- en: '**Feature Extraction**: The R-CNN network makes use of pre-trained CNNs such
    as VGGs or ResNets for extracting features from each of the ROIs identified in
    the previous step. Before the regions/crops are passed as inputs to the pre-trained
    network these are reshaped or warped to the required dimensions (each pretrained
    network requires inputs in specific dimensions only). The pre-trained network
    is used without the final classification layer. The output of this stage is a
    long list of tensors, one for each ROI from the previous stage.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾æå–**ï¼šR-CNN ç½‘ç»œä½¿ç”¨é¢„è®­ç»ƒçš„ CNNï¼ˆå¦‚ VGG æˆ– ResNetï¼‰ä»å‰ä¸€æ­¥ä¸­è¯†åˆ«çš„æ¯ä¸ª ROI ä¸­æå–ç‰¹å¾ã€‚åœ¨å°†åŒºåŸŸ/è£å‰ªä¼ é€’åˆ°é¢„è®­ç»ƒç½‘ç»œä½œä¸ºè¾“å…¥ä¹‹å‰ï¼Œè¿™äº›åŒºåŸŸä¼šè¢«é‡æ–°è°ƒæ•´æˆ–æ‰­æ›²ä¸ºæ‰€éœ€çš„å°ºå¯¸ï¼ˆæ¯ä¸ªé¢„è®­ç»ƒç½‘ç»œä»…è¦æ±‚ç‰¹å®šå°ºå¯¸çš„è¾“å…¥ï¼‰ã€‚é¢„è®­ç»ƒç½‘ç»œåœ¨æ²¡æœ‰æœ€ç»ˆåˆ†ç±»å±‚çš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚æ­¤é˜¶æ®µçš„è¾“å‡ºæ˜¯ä¸€é•¿ä¸²å¼ é‡ï¼Œæ¯ä¸ªå¼ é‡å¯¹åº”å‰ä¸€é˜¶æ®µçš„ä¸€ä¸ª
    ROIã€‚'
- en: '**Classification Head**: The original R-CNN paper made use of Support Vector
    Machines (SVMs) as the classifier to identify the class of object in the ROI.
    SVM is a traditional supervised algorithm widely used for classification purposes.
    The output from this step is a classification label for every ROI.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åˆ†ç±»å¤´**ï¼šåŸå§‹çš„ R-CNN è®ºæ–‡ä½¿ç”¨æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ä½œä¸ºåˆ†ç±»å™¨æ¥è¯†åˆ« ROI ä¸­ç‰©ä½“çš„ç±»åˆ«ã€‚SVM æ˜¯ä¸€ç§ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œå¹¿æ³›ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚æ­¤æ­¥éª¤çš„è¾“å‡ºæ˜¯æ¯ä¸ª
    ROI çš„åˆ†ç±»æ ‡ç­¾ã€‚'
- en: '**Regression Head**: This module takes care of the localization aspect of the
    object detection task. As discussed in the previous section, bounding boxes can
    be uniquely identified using 4 coordinates (top-left (x, y) coordinates along
    with width and height of the box). The regressor outputs these 4 values for every
    ROI.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å›å½’å¤´**ï¼šæ­¤æ¨¡å—å¤„ç†ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸­çš„å®šä½éƒ¨åˆ†ã€‚å¦‚å‰ä¸€èŠ‚æ‰€è¿°ï¼Œè¾¹ç•Œæ¡†å¯ä»¥é€šè¿‡ 4 ä¸ªåæ ‡å”¯ä¸€ç¡®å®šï¼ˆå·¦ä¸Šè§’ï¼ˆxï¼Œyï¼‰åæ ‡ä»¥åŠæ¡†çš„å®½åº¦å’Œé«˜åº¦ï¼‰ã€‚å›å½’å™¨ä¸ºæ¯ä¸ª
    ROI è¾“å‡ºè¿™ 4 ä¸ªå€¼ã€‚'
- en: This pipeline is visually depicted in figure 1 for reference. As shown in the
    figure, the network requires multiple independent forward passes (one of each
    ROI) using the pretrained network. This is one of the primary reasons which slows
    down the R-CNN model, both for training as well as inference. The authors of the
    paper mention that it requires 80+ hours to train the network and an immense amount
    of disk space. The second bottleneck is the selective search algorithm itself.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æµç¨‹åœ¨å›¾1ä¸­è¿›è¡Œäº†è§†è§‰å±•ç¤ºï¼Œä¾›å‚è€ƒã€‚å¦‚å›¾æ‰€ç¤ºï¼Œç½‘ç»œéœ€è¦ä½¿ç”¨é¢„è®­ç»ƒç½‘ç»œå¯¹æ¯ä¸ªROIè¿›è¡Œå¤šæ¬¡ç‹¬ç«‹çš„å‰å‘ä¼ æ’­ã€‚è¿™æ˜¯R-CNNæ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­å˜æ…¢çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚è®ºæ–‡çš„ä½œè€…æåˆ°ï¼Œè®­ç»ƒè¯¥ç½‘ç»œéœ€è¦è¶…è¿‡80å°æ—¶ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„ç£ç›˜ç©ºé—´ã€‚ç¬¬äºŒä¸ªç“¶é¢ˆæ˜¯é€‰æ‹©æ€§æœç´¢ç®—æ³•æœ¬èº«ã€‚
- en: '![](../Images/bc1576d845aac3e157ff3d86511e95fc.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc1576d845aac3e157ff3d86511e95fc.png)'
- en: 'Figure 1: Components of the R-CNN model. Region proposal component is based
    on selective search followed by a pre-trained network such as VGG for feature
    extraction. Classification head makes use of SVMs and a separate regression head.
    Source: Author'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ï¼šR-CNNæ¨¡å‹çš„ç»„æˆéƒ¨åˆ†ã€‚åŒºåŸŸæè®®ç»„ä»¶åŸºäºé€‰æ‹©æ€§æœç´¢ï¼Œéšåé€šè¿‡é¢„è®­ç»ƒçš„ç½‘ç»œï¼ˆå¦‚VGGï¼‰è¿›è¡Œç‰¹å¾æå–ã€‚åˆ†ç±»å¤´éƒ¨ä½¿ç”¨æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œä¸€ä¸ªå•ç‹¬çš„å›å½’å¤´éƒ¨ã€‚æ¥æºï¼šä½œè€…
- en: The R-CNN model is a good example of how different ideas can be leveraged as
    building blocks to solve a complex problem. While we will have a detailed hands-on
    exercise to see object detection in context of transfer learning, in its original
    setup itself R-CNN makes use of transfer learning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: R-CNNæ¨¡å‹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†ä¸åŒçš„æ€æƒ³ä½œä¸ºæ„å»ºå—æ¥è§£å†³å¤æ‚çš„é—®é¢˜ã€‚è™½ç„¶æˆ‘ä»¬å°†åœ¨å®è·µä¸­è¯¦ç»†æ¼”ç¤ºå¦‚ä½•åœ¨è¿ç§»å­¦ä¹ çš„èƒŒæ™¯ä¸‹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œä½†åœ¨å…¶åŸå§‹è®¾ç½®ä¸­ï¼ŒR-CNNå·²ç»åˆ©ç”¨äº†è¿ç§»å­¦ä¹ ã€‚
- en: The R-CNN model was slow, but it provided a good base for object detection models
    to come down the line. The computationally expensive and slow feature extraction
    step was mainly addressed in the **Fast R-CNN** implementation. The [Fast R-CNN](https://arxiv.org/abs/1504.08083)
    was presented by Ross Grishick in 2015\. This implementation boasts of not just
    faster training and inference but also improved mAP on [PASCAL VOC 2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/)
    dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: R-CNNæ¨¡å‹è™½ç„¶è¾ƒæ…¢ï¼Œä½†ä¸ºåæ¥çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹æä¾›äº†è‰¯å¥½çš„åŸºç¡€ã€‚è®¡ç®—ä¸Šæ˜‚è´µä¸”ç¼“æ…¢çš„ç‰¹å¾æå–æ­¥éª¤åœ¨**Fast R-CNN**å®ç°ä¸­å¾—åˆ°äº†ä¸»è¦è§£å†³ã€‚[Fast
    R-CNN](https://arxiv.org/abs/1504.08083)ç”±Ross Grishickäº2015å¹´æå‡ºã€‚è¯¥å®ç°ä¸ä»…åœ¨è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ä¸Šæ›´å¿«ï¼Œè¿˜åœ¨[PASCAL
    VOC 2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/)æ•°æ®é›†ä¸Šæé«˜äº†mAPã€‚
- en: 'The key contributions from the **Fast R-CNN** paper can be summarized as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fast R-CNN**è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å¯ä»¥æ€»ç»“å¦‚ä¸‹ï¼š'
- en: '**Region Proposal**: For the base R-CNN model, we discussed how selective search
    algorithm is applied on the input image to generate thousands of ROIs upon which
    a pretrained network works to extract features. The Fast R-CNN changes this step
    to derive maximum impact. Instead of applying the feature extraction step using
    the pretrained network thousands of times, the Fast R-CNN network does it only
    once. In other words, we first process the whole input image through the pretrained
    network just once. The output features are then used as input for the selective
    search algorithm for identification of ROIs. This change in order of components
    reduces the computation requirements and performance bottleneck to a good extent.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŒºåŸŸæè®®**ï¼šå¯¹äºåŸºç¡€çš„R-CNNæ¨¡å‹ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•å°†é€‰æ‹©æ€§æœç´¢ç®—æ³•åº”ç”¨äºè¾“å…¥å›¾åƒï¼Œç”Ÿæˆæ•°åƒä¸ªROIï¼Œå¹¶é€šè¿‡é¢„è®­ç»ƒç½‘ç»œæå–ç‰¹å¾ã€‚Fast R-CNNæ”¹å˜äº†è¿™ä¸€è¿‡ç¨‹ï¼Œä»¥è·å¾—æ›´å¤§çš„å½±å“ã€‚å®ƒä¸å†ä½¿ç”¨é¢„è®­ç»ƒç½‘ç»œå¯¹ç‰¹å¾æå–æ­¥éª¤è¿›è¡Œæ•°åƒæ¬¡å¤„ç†ï¼Œè€Œæ˜¯ä»…æ‰§è¡Œä¸€æ¬¡ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡é¢„è®­ç»ƒç½‘ç»œå¤„ç†æ•´ä¸ªè¾“å…¥å›¾åƒï¼Œä»…è¿›è¡Œä¸€æ¬¡ã€‚ç„¶åï¼Œå°†è¾“å‡ºç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œä¾›é€‰æ‹©æ€§æœç´¢ç®—æ³•è¯†åˆ«ROIã€‚è¿™ä¸€ç»„ä»¶é¡ºåºçš„æ”¹å˜åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå‡å°‘äº†è®¡ç®—éœ€æ±‚å’Œæ€§èƒ½ç“¶é¢ˆã€‚'
- en: '**ROI Pooling Layer**: The ROIs identified in the previous step can be arbitrary
    size (as identified by the selective search algorithm). But the fully connected
    layers after the ROIs have been extracted take only fixed size feature maps as
    inputs. The ROI pooling layer is thus a fixed size filter (the paper mentions
    a size of 7x7) which helps transform these arbitrary sized ROIs into fixed size
    output vectors. This layer works by first dividing the ROI into equal sized sections.
    It then finds the largest value in each section (similar to Max-Pooling operation).
    The output is just the max values from each of equal sized sections. The ROI pooling
    layer speeds up the inference and training times considerably.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ROIæ± åŒ–å±‚**ï¼šåœ¨å‰ä¸€æ­¥ä¸­è¯†åˆ«å‡ºçš„ROIå¯ä»¥æ˜¯ä»»æ„å¤§å°ï¼ˆç”±é€‰æ‹©æ€§æœç´¢ç®—æ³•ç¡®å®šï¼‰ã€‚ä½†æ˜¯ï¼ŒROIæå–åçš„å…¨è¿æ¥å±‚åªèƒ½æ¥å—å›ºå®šå¤§å°çš„ç‰¹å¾å›¾ä½œä¸ºè¾“å…¥ã€‚å› æ­¤ï¼ŒROIæ± åŒ–å±‚æ˜¯ä¸€ä¸ªå›ºå®šå¤§å°çš„æ»¤æ³¢å™¨ï¼ˆè®ºæ–‡ä¸­æåˆ°å¤§å°ä¸º7x7ï¼‰ï¼Œå®ƒå¸®åŠ©å°†è¿™äº›ä»»æ„å¤§å°çš„ROIè½¬åŒ–ä¸ºå›ºå®šå¤§å°çš„è¾“å‡ºå‘é‡ã€‚è¯¥å±‚çš„å·¥ä½œæ–¹å¼æ˜¯é¦–å…ˆå°†ROIåˆ’åˆ†ä¸ºå¤§å°ç›¸ç­‰çš„åŒºåŸŸï¼Œç„¶ååœ¨æ¯ä¸ªåŒºåŸŸä¸­æ‰¾åˆ°æœ€å¤§å€¼ï¼ˆç±»ä¼¼äºæœ€å¤§æ± åŒ–æ“ä½œï¼‰ã€‚è¾“å‡ºæ˜¯æ¥è‡ªæ¯ä¸ªç­‰å¤§å°åŒºåŸŸçš„æœ€å¤§å€¼ã€‚ROIæ± åŒ–å±‚æ˜¾è‘—åŠ å¿«äº†æ¨ç†å’Œè®­ç»ƒæ—¶é—´ã€‚'
- en: '**Multi-task Loss**: As opposed to two different components (SVM and bounding
    box regressor) in R-CNN implementation, Faster R-CNN makes use of a multi-headed
    network. This setup enables the network to be trained jointly for both the tasks
    using a multi-task loss function. The multi-task loss is a weighted sum of classification
    and regression losses for object classification and bounding box regression tasks
    respectively. The loss function is given as:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šä»»åŠ¡æŸå¤±**ï¼šä¸R-CNNå®ç°ä¸­çš„ä¸¤ä¸ªä¸åŒç»„ä»¶ï¼ˆSVMå’Œè¾¹ç•Œæ¡†å›å½’å™¨ï¼‰ä¸åŒï¼ŒFaster R-CNNä½¿ç”¨äº†ä¸€ä¸ªå¤šå¤´ç½‘ç»œã€‚è¿™ç§è®¾ç½®ä½¿å¾—ç½‘ç»œå¯ä»¥é€šè¿‡å¤šä»»åŠ¡æŸå¤±å‡½æ•°åŒæ—¶è®­ç»ƒä¸¤ä¸ªä»»åŠ¡ã€‚å¤šä»»åŠ¡æŸå¤±æ˜¯åˆ†ç±»æŸå¤±å’Œå›å½’æŸå¤±çš„åŠ æƒå’Œï¼Œåˆ†åˆ«ç”¨äºç‰©ä½“åˆ†ç±»å’Œè¾¹ç•Œæ¡†å›å½’ä»»åŠ¡ã€‚æŸå¤±å‡½æ•°è¡¨ç¤ºä¸ºï¼š'
- en: Lâ‚˜â‚œ = Lâ‚’ + ğ›¾Láµ£
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Lâ‚˜â‚œ = Lâ‚’ + ğ›¾Láµ£
- en: where ğ›¾ â‰¥ 1 if the ROI contains an object (objectness score), 0 otherwise. Classification
    loss is simply a negative log loss while the regression loss used in the original
    implementation is the smooth L1 loss.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œğ›¾ â‰¥ 1å¦‚æœROIåŒ…å«ç‰©ä½“ï¼ˆç‰©ä½“å¾—åˆ†ï¼‰ï¼Œå¦åˆ™ä¸º0ã€‚åˆ†ç±»æŸå¤±æ˜¯ä¸€ä¸ªç®€å•çš„è´Ÿå¯¹æ•°æŸå¤±ï¼Œè€ŒåŸå§‹å®ç°ä¸­ä½¿ç”¨çš„å›å½’æŸå¤±æ˜¯å¹³æ»‘L1æŸå¤±ã€‚
- en: The original paper details a number of experiments which highlight performance
    improvements based on various combinations of hyper-parameters and layers fine-tuned
    in the pre-trained network. The original implementation made use of pretrained
    VGG-16 as the feature extraction network. A number of faster and improved implementation
    such as MobileNet, ResNet, etc. have come up since the Fast R-CNNâ€™s original implementation.
    These networks can also be swapped in place of VGG-16 to improve the performance
    further.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹è®ºæ–‡è¯¦ç»†æè¿°äº†å¤šé¡¹å®éªŒï¼Œçªå‡ºåŸºäºä¸åŒè¶…å‚æ•°ç»„åˆå’Œåœ¨é¢„è®­ç»ƒç½‘ç»œä¸­å¾®è°ƒçš„å±‚æ¬¡çš„æ€§èƒ½æå‡ã€‚åŸå§‹å®ç°ä½¿ç”¨äº†é¢„è®­ç»ƒçš„VGG-16ä½œä¸ºç‰¹å¾æå–ç½‘ç»œã€‚ä»Fast
    R-CNNçš„åŸå§‹å®ç°ä»¥æ¥ï¼Œå‡ºç°äº†å¤šä¸ªæ›´å¿«ä¸”æ”¹è¿›çš„å®ç°ï¼Œå¦‚MobileNetã€ResNetç­‰ã€‚è¿™äº›ç½‘ç»œä¹Ÿå¯ä»¥æ›¿æ¢VGG-16ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- en: '**Faster R-CNN** is the final member of this family of multi-stage object detectors.
    This is by far the most complex and fastest variant of them all. While Fast R-CNN
    improved training and inference times considerably it was still getting penalized
    due to the selective search algorithm. The Faster R-CNN model presented in 2016
    by Ren et. al. in their paper titled â€œ[Faster R-CNN: Towards Real-Time Object
    Detection with Region Proposal Networks](https://papers.nips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf)â€
    addresses the regional proposal aspect primarily. This network builds on top of
    Fast R-CNN network by introducing a novel component called **Region Proposal Network
    (RPN)**. The overall Faster R-CNN network is depicted in figure 2 for reference.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Faster R-CNN**æ˜¯è¿™ä¸€ç³»åˆ—å¤šé˜¶æ®µç‰©ä½“æ£€æµ‹å™¨ä¸­çš„æœ€ç»ˆæˆå‘˜ã€‚è¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¤æ‚ä¸”æœ€å¿«çš„å˜ä½“ã€‚è™½ç„¶Fast R-CNNæ˜¾è‘—æ”¹å–„äº†è®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼Œä½†ç”±äºé€‰æ‹©æ€§æœç´¢ç®—æ³•ï¼Œå®ƒä»ç„¶å—åˆ°äº†ä¸€å®šçš„æƒ©ç½šã€‚2016å¹´ï¼ŒRenç­‰äººåœ¨å…¶è®ºæ–‡ã€Š[Faster
    R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://papers.nips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf)ã€‹ä¸­æå‡ºçš„Faster
    R-CNNæ¨¡å‹ä¸»è¦è§£å†³äº†åŒºåŸŸæè®®çš„é—®é¢˜ã€‚è¯¥ç½‘ç»œåœ¨Fast R-CNNçš„åŸºç¡€ä¸Šå¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç»„ä»¶ï¼Œç§°ä¸º**åŒºåŸŸæè®®ç½‘ç»œï¼ˆRPNï¼‰**ã€‚æ•´ä½“Faster R-CNNç½‘ç»œå¦‚å›¾2æ‰€ç¤ºï¼Œä¾›å‚è€ƒã€‚'
- en: '![](../Images/317b48c82e252b5db04dbe89c0ba9aca.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/317b48c82e252b5db04dbe89c0ba9aca.png)'
- en: 'Figure 2: Faster R-CNN is composed of two main components: 1) a Region Proposal
    Network (RPN) to identify ROIs and 2) a Fast R-CNN like multi-headed network with
    ROI pooling layer. Source: Author'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2ï¼šFaster R-CNNç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼š1) åŒºåŸŸæè®®ç½‘ç»œï¼ˆRPNï¼‰ç”¨äºè¯†åˆ«ROIï¼Œ2) ç±»ä¼¼Fast R-CNNçš„å¤šå¤´ç½‘ç»œï¼ŒåŒ…å«ROIæ± åŒ–å±‚ã€‚æ¥æºï¼šä½œè€…
- en: RPN is a fully convolutional network (FCN) that helps in generating ROIs. As
    shown in figure 3.12, RPN consists of two layers only. The first being a 3x3 convolutional
    layer with 512 filters followed by two parallel 1x1 convolutional layers (one
    each for classification and regression respectively). The 3x3 convolutional filter
    is applied onto the feature map output of the pre-trained network (the input to
    which is the original image). Please note that the classification layer in RPN
    is a binary classification layer for determination of objectness score (not the
    object class). The bounding box regression is performed using 1x1 convolutional
    filters on anchor boxes. The proposed setup in the paper uses 9 anchor boxes per
    window, thus the RPN generates 18 objectness scores (2xK) and 36 location coordinates
    (4xK), where K=9 is the number of anchor boxes. The use of RPN (instead of selective
    search) improves the training and inference times by orders of magnitudes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: RPN æ˜¯ä¸€ä¸ªå®Œå…¨å·ç§¯ç½‘ç»œï¼ˆFCNï¼‰ï¼Œç”¨äºç”Ÿæˆ ROIã€‚å¦‚å›¾ 3.12 æ‰€ç¤ºï¼ŒRPN ä»…ç”±ä¸¤å±‚ç»„æˆã€‚ç¬¬ä¸€å±‚æ˜¯ä¸€ä¸ª 3x3 çš„å·ç§¯å±‚ï¼Œå…·æœ‰ 512 ä¸ªè¿‡æ»¤å™¨ï¼Œåé¢æ˜¯ä¸¤ä¸ªå¹¶è¡Œçš„
    1x1 å·ç§¯å±‚ï¼ˆåˆ†åˆ«ç”¨äºåˆ†ç±»å’Œå›å½’ï¼‰ã€‚3x3 çš„å·ç§¯è¿‡æ»¤å™¨åº”ç”¨äºé¢„è®­ç»ƒç½‘ç»œçš„ç‰¹å¾å›¾è¾“å‡ºï¼ˆå…¶è¾“å…¥ä¸ºåŸå§‹å›¾åƒï¼‰ã€‚è¯·æ³¨æ„ï¼ŒRPN ä¸­çš„åˆ†ç±»å±‚æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»å±‚ï¼Œç”¨äºç¡®å®šç‰©ä½“æ€§å¾—åˆ†ï¼ˆè€Œä¸æ˜¯ç‰©ä½“ç±»åˆ«ï¼‰ã€‚è¾¹ç•Œæ¡†å›å½’æ˜¯é€šè¿‡åœ¨é”šæ¡†ä¸Šä½¿ç”¨
    1x1 çš„å·ç§¯è¿‡æ»¤å™¨æ¥è¿›è¡Œçš„ã€‚è®ºæ–‡ä¸­æè®®çš„è®¾ç½®åœ¨æ¯ä¸ªçª—å£ä½¿ç”¨ 9 ä¸ªé”šæ¡†ï¼Œå› æ­¤ RPN ç”Ÿæˆ 18 ä¸ªç‰©ä½“æ€§å¾—åˆ†ï¼ˆ2xKï¼‰å’Œ 36 ä¸ªä½ç½®åæ ‡ï¼ˆ4xKï¼‰ï¼Œå…¶ä¸­
    K=9 æ˜¯é”šæ¡†çš„æ•°é‡ã€‚ä½¿ç”¨ RPNï¼ˆè€Œä¸æ˜¯é€‰æ‹©æ€§æœç´¢ï¼‰å¯ä»¥å°†è®­ç»ƒå’Œæ¨ç†æ—¶é—´æé«˜æ•°é‡çº§ã€‚
- en: The Faster R-CNN network is an end-to-end object detection network. Unlike the
    base R-CNN and Fast R-CNN models which made use of a number of independent components
    for training, Faster R-CNN can be trained as a whole.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Faster R-CNN ç½‘ç»œæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç›®æ ‡æ£€æµ‹ç½‘ç»œã€‚ä¸åŸºç¡€çš„ R-CNN å’Œ Fast R-CNN æ¨¡å‹ä¸åŒï¼Œåè€…ä½¿ç”¨äº†å¤šä¸ªç‹¬ç«‹ç»„ä»¶è¿›è¡Œè®­ç»ƒï¼Œè€Œ
    Faster R-CNN å¯ä»¥ä½œä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œè®­ç»ƒã€‚
- en: This concludes our discussion on the R-CNN family of object detectors. We discussed
    key contributions to better understand how these networks work.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬å…³äº R-CNN å®¶æ—ç›®æ ‡æ£€æµ‹å™¨çš„è®¨è®ºæ€»ç»“ã€‚æˆ‘ä»¬è®¨è®ºäº†å…³é”®çš„è´¡çŒ®ï¼Œä»¥æ›´å¥½åœ°ç†è§£è¿™äº›ç½‘ç»œæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
