- en: Extending PAC Learning to a Strategic Classification Setting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将PAC学习扩展到战略分类设置
- en: 原文：[https://towardsdatascience.com/extending-pac-learning-to-a-strategic-classification-setting-6c374935dde2?source=collection_archive---------3-----------------------#2024-04-04](https://towardsdatascience.com/extending-pac-learning-to-a-strategic-classification-setting-6c374935dde2?source=collection_archive---------3-----------------------#2024-04-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/extending-pac-learning-to-a-strategic-classification-setting-6c374935dde2?source=collection_archive---------3-----------------------#2024-04-04](https://towardsdatascience.com/extending-pac-learning-to-a-strategic-classification-setting-6c374935dde2?source=collection_archive---------3-----------------------#2024-04-04)
- en: A case study of the meeting point between game theory and fundamental concepts
    in machine learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 博弈论与机器学习基本概念交汇点的案例研究
- en: '[](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)[![Jonathan
    Yahav](../Images/30c3293a94be9258a65c38afd58bb521.png)](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)
    [Jonathan Yahav](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)[![Jonathan
    Yahav](../Images/30c3293a94be9258a65c38afd58bb521.png)](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)
    [Jonathan Yahav](https://jhyahav.medium.com/?source=post_page---byline--6c374935dde2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)
    ·10 min read·Apr 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6c374935dde2--------------------------------)
    ·10分钟阅读·2024年4月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Last semester, I took a seminar in *Incentives and Learning.* The papers we
    discussed throughout the course dealt with the overlap between the fields of game
    theory and machine learning. I had very little familiarity with formal game theory
    beforehand, and I thought finding out more about it through the lens of its intersection
    with machine learning was fascinating. By the end of this article, I hope you’ll
    think so, too!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上学期，我参加了一个关于*激励与学习*的研讨会。我们在课程中讨论的论文涉及博弈论与机器学习领域的交集。之前我对正式的博弈论几乎没有了解，但我觉得通过机器学习与博弈论的交集来深入了解它是非常有趣的。在本文的结尾，我希望你也能产生这样的想法！
- en: The paper my group chose to present was [***PAC-Learning for Strategic Classification***](https://arxiv.org/abs/2012.03310)(Sundaram,
    Vullikanti, Xu, & Yao, 2021). It generalizes the basic machine learning notion
    of [PAC learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)
    to work in a **strategic** [binary classification](https://en.wikipedia.org/wiki/Binary_classification)
    setting. The word “strategic” here signifies that the data points we want to classify
    aren’t just data points, but rather **represent rational agents with their own
    individual preferences.**
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们小组选择的论文是[***PAC-Learning for Strategic Classification***](https://arxiv.org/abs/2012.03310)(Sundaram,
    Vullikanti, Xu, & Yao, 2021)。它将基本的机器学习概念——[PAC学习](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning)——扩展到**战略**[二分类](https://en.wikipedia.org/wiki/Binary_classification)设置中。“战略”一词在这里意味着我们想要分类的数据点不仅仅是数据点，而是**代表具有自己个人偏好的理性主体**。
- en: '**This will be a three-part series on my takeaways from the paper.** **In this
    article, I’ll lay the intuitive and formal foundations required to understand
    the strategic classification model and setup.** In the next one, I’ll cover the
    concept of strategic VC dimension as a generalization of the canonical notion
    of [VC dimension](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension).
    The final post will be a walkthrough of my favorite proof in the paper, which
    will tie together the definitions and ideas introduced in the first two.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**这将是我从论文中总结的三部分系列文章。** **在本文中，我将阐述理解战略分类模型和设置所需的直观和形式化基础。** 在下一篇中，我将讨论战略VC维度的概念，作为[VC维度](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension)的一个泛化。最后一篇文章将详细讲解我最喜欢的论文证明，它将把前两篇中介绍的定义和思路串联起来。'
- en: An understanding the idea of binary classification and the basic notation used
    for it in the context of machine learning should be all you need to understand
    the articles in this series. **Ultimately, the goal is to present the concepts
    in a way that makes them as approachable as possible, regardless of your background.**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 理解二分类的概念以及在机器学习中使用的基本符号应该是理解本系列文章的全部所需。**最终的目标是以一种尽可能接近读者的方式呈现这些概念，无论你的背景如何。**
- en: 'Why Strategic Classification Is Useful: Motivation'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么战略分类有用：动机
- en: '**Binary classification is a cornerstone of machine learning.** It was the
    first topic I was taught when I took an introductory course on the subject; the
    real-world example we examined back then was the problem of classifying emails
    as either *spam* or *not spam*. Other common examples include diagnosing a disease
    and screening resumes for a job posting.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**二分类是机器学习的基石。** 它是我在参加机器学习入门课程时学到的第一个主题；当时我们探讨的现实世界例子是将电子邮件分类为*垃圾邮件*或*非垃圾邮件*。其他常见的例子包括疾病诊断和简历筛选。'
- en: The basic binary classification setup is intuitive and easily applicable to
    our day-to-day lives, andit can serve as a helpful demonstration of **the ways
    we can leverage machine learning to solve *human* problems.** But how often do
    we stop to consider the fact that **people usually have a vested interest in the
    classification outcome of such problems?** Spammers want their emails to make
    it through spam filters, not everyone wants their COVID test to come back positive,
    and job seekers may be willing to stretch the truth to score an interview. **The
    data points aren’t just data points — they’re active participants in the classification
    process, often aiming to game the system to their own benefit.**
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的二分类设定直观且容易应用于我们的日常生活，并且它可以作为一个有用的示范，展示**我们如何利用机器学习来解决*人类*问题**。但是，我们多久停下来考虑这样一个事实：**人们通常对此类问题的分类结果有既得利益？**
    垃圾邮件发送者希望他们的邮件能够通过垃圾邮件过滤器，而不是每个人都希望他们的COVID测试呈阳性，求职者可能会愿意稍微歪曲事实以获得面试机会。**数据点不仅仅是数据点——它们是分类过程中的活跃参与者，常常试图通过操作系统来获得自己的利益。**
- en: In light of this, the canonical binary classification setup seems a bit simplistic.
    However, the complexity of reexamining binary classification while tossing out
    the implicit assumption that the objects we wish to classify are uninfluenced
    by external stakes sounds unmanageable. **The preferences that could affect the
    classification process come in so many different forms — how could we possibly
    take all of them into account?**
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，经典的二分类设定显得有些过于简化。然而，重新审视二分类并抛弃隐含假设——我们希望分类的对象不受外部利益的影响——似乎是不可行的。**影响分类过程的偏好表现形式多种多样——我们怎么可能把所有这些都考虑进去呢？**
- en: '**It turns out that, under certain assumptions, we can.** Through a clever
    generalization of the canonical binary classification model, the paper’s authors
    demonstrate the feasibility of designing computationally-tractable, gaming-resistant
    classification algorithms.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**事实证明，在某些假设下，我们是可以做到的。** 通过巧妙地推广经典的二分类模型，论文的作者展示了设计计算上可处理、抗操控的分类算法的可行性。'
- en: 'From Data Points to Rational Agents: Preference Classes'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从数据点到理性代理人：偏好类别
- en: First, if we want to be as realistic as possible, we have to properly consider
    the wide breadth of forms that real-world preferences can take among rational
    agents. The paper mentions five increasingly general categories of preferences
    (which I’ll call *preference classes*). The names I’ll use for them are my own,
    but are based on the terminology used in the paper.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果我们想尽可能现实地反映问题，就必须恰当地考虑现实世界中理性代理人可能表现出的各种偏好形式。论文提到了五种逐渐通用的偏好类别（我将其称为*偏好类别*）。我为它们取的名字是我自己的，但基于论文中使用的术语。
- en: '**Impartial**: No preferences, just like in canonical binary classification.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**公正：** 没有偏好，就像经典二分类中的情形一样。'
- en: '**Homogeneous:** Identical preferences across all the agents involved. For
    example, within the set of people who are willing to fill out the paperwork necessary
    to apply for a tax refund, we can reasonably expect that everyone is equally motivated
    to get their money back (i.e., to be classified positively).'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同质性：** 所有相关代理人的偏好一致。例如，在愿意填写申请退税所需的表格的人群中，我们可以合理地预期每个人都有相同的动机来拿回他们的钱（即被积极分类）。'
- en: '**Adversarial:** Equally-motivated agents aim to induce the opposite of their
    true labels. Think of bluffing in poker — a player with a weak hand (negatively
    classified) wants their opponents to think they have a strong hand (positively
    classified), and vice versa. For the “equally-motivated” part, imagine all players
    bet the same amount.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对抗性：** 动机相等的代理试图诱导与其真实标签相反的分类。可以将其与扑克牌中的虚张声势进行类比——一个手牌较弱的玩家（被负向分类）希望对手认为自己有一手强牌（被正向分类），反之亦然。对于“动机相等”的部分，可以想象所有玩家投注相同的金额。'
- en: '**Generalized Adversarial:** Unequally-motivated agents aim to induce the opposite
    of their true labels. This isn’t too different from the plain *Adversarial* case.
    Still, it should be easy to understand how a player with $100 dollars on the line
    would be willing to go to greater lengths to deceive their opponents than a player
    betting $1.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**广义对抗性：** 动机不相等的代理试图诱导与其真实标签相反的分类。这与普通的 *对抗性* 情况并无太大区别。不过，应该容易理解，若一个玩家赌注为100美元，他将比一个赌注为1美元的玩家更愿意采取更极端的手段来欺骗对手。'
- en: '**General Strategic:** *“*Anything goes.*”* This preference class aims to encompass
    any set of preferences imaginable. All four of the previously mentioned preference
    classes are strict subsets of this one. Naturally, this class is the main focus
    of the paper, and most of the results demonstrated in the paper apply to it. The
    authors give the wonderful example of college applications, where “*students [who]
    have heterogeneous preferences over universities […] may manipulate their application
    materials during the admission process.*”'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一般战略：** *“*任何事情都可以。”* 这个偏好类别旨在涵盖任何可以想象的偏好集。之前提到的四个偏好类别都是这个类别的严格子集。显然，这个类别是本文的主要关注点，文章中大多数展示的结果适用于它。作者提供了一个精彩的例子，关于大学申请，“*学生们对大学有异质化的偏好
    […] 在录取过程中可能会操控他们的申请材料。*”'
- en: 'How can the canonical classification setup be modified to account for such
    rich agent preferences? The answer is astoundingly simple. Instead of limiting
    our scope to (*x*, *y*) ∈ *X* × { -1, 1 }, **we consider data points of the form
    (*x*, *y*, *r*) ∈ *X* × { -1, 1 } × *R*.** A point’s *r* value represents its
    preference, which we can break down into two equally important components:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如何修改经典分类设置以考虑如此丰富的代理偏好？答案出奇简单。我们不再将范围限制于 (*x*, *y*) ∈ *X* × { -1, 1 }，**而是考虑形如
    (*x*, *y*, *r*) ∈ *X* × { -1, 1 } × *R* 的数据点。** 一个点的 *r* 值表示它的偏好，我们可以将其分解为两个同等重要的组件：
- en: The **sign** of *r* indicates **whether the data point wants to be positively
    or negatively classified** (*r* > 0 or *r* < 0, respectively).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**符号** *r* 表示**数据点是想被正向分类还是负向分类**（*r* > 0 或 *r* < 0）。'
- en: The **absolute value** of *r* specifies **how strong the data point’s preference
    is.** For example, a data point with *r* = 10 would be much more strongly motivated
    to manipulate its feature vector *x* to ensure it ends up being positively classified
    than a data point with *r* = 1.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**绝对值** *r* 指定了**数据点的偏好强度**。例如，一个 *r* = 10 的数据点会比 *r* = 1 的数据点更强烈地倾向于操控其特征向量
    *x*，以确保它最终被正向分类。'
- en: '**What determines the preference class we operate within is the set *R*.**
    We can formally define each of the aforementioned preference classes in terms
    of *R* and see how the formal definitions align with their intuitive descriptions
    and examples:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们操作的偏好类别由集合 *R* 决定。** 我们可以正式地根据 *R* 定义上述每个偏好类别，并查看这些正式定义如何与它们的直观描述和示例一致：'
- en: '**Impartial**: *R* = { 0 }. *(This makes it abundantly clear that the strategic
    setup is just a generalization of the canonical setup.)*'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**公正的：** *R* = { 0 }。*(这清楚地表明战略设置只是经典设置的一种推广。)*'
- en: '**Homogeneous:** *R* = { 1 }.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同质的：** *R* = { 1 }。'
- en: '**Adversarial:** *R* = { -1, 1 }, with the added requirement that all data
    points prefer to be classified as the opposite of their true labels.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对抗性：** *R* = { -1, 1 }，并且有一个附加要求，即所有数据点都倾向于被分类为与其真实标签相反的类别。'
- en: '**Generalized Adversarial:** *R* ⊆ ℝ (and all data points prefer to be classified
    as the opposite of their true labels.)'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**广义对抗性：** *R* ⊆ ℝ（且所有数据点都倾向于被分类为与其真实标签相反的类别。）'
- en: '**General Strategic:** *R* ⊆ ℝ.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一般战略：** *R* ⊆ ℝ。'
- en: 'Giving Preference Magnitude Meaning: Cost Functions'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 给予偏好大小意义：成本函数
- en: Clearly, though, *R* on its own isn’t enough to construct an entire general
    strategic framework. The very idea of a data point’s preference having a certain
    magnitude is meaningless without tying it to **the cost the data point incurs
    in manipulating its feature vector.** Otherwise, any data point with a positive
    *r*, no matter how small, would have no reason not to manipulate its feature vector
    *ad infinitum*. This is where the concept of **cost functions** comes into play.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，很明显，仅仅*R*本身不足以构建一个完整的通用战略框架。如果不将数据点的偏好与**数据点在操作其特征向量时所承担的代价**联系起来，那么数据点偏好具有某种大小的概念就毫无意义。否则，任何具有正*
    r *的data point，无论其多么微小，都没有理由不对其特征向量进行**无限制地**操作。这就是**代价函数**概念发挥作用的地方。
- en: 'Let *c*: *X* × *X* → ℝ⁺. For simplicity, we will assume (as the paper’s authors
    do) that *c* is induced by [seminorms](https://en.wikipedia.org/wiki/Seminorm).
    We say that a **test data point** (*x*, *y*, *r*) may transform its feature vector
    *x* into *z* ∈ *X* with **cost** *c*(*z*; *x*). It’s important to note in this
    context that the paper assumes that the training data is unmanipulated.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '设*c*: *X* × *X* → ℝ⁺。为简便起见，我们假设（正如论文作者所做的那样）*c*是由[半范数](https://en.wikipedia.org/wiki/Seminorm)引起的。我们可以说，一个**测试数据点**（*x*,
    *y*, *r*）可能将其特征向量*x*转换为*z* ∈ *X*，其**代价**为*c*(*z*; *x*)。在这个背景下，需要注意的是，论文假设训练数据是未经操作的。'
- en: 'We can divide cost functions into two categories, with the former being a subset
    of the latter. An **instance-invariant cost function** is the same across all
    data points. To put it more formally:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将代价函数分为两类，前者是后者的一个子集。**实例不变的代价函数**在所有数据点上都是相同的。更正式地说：
- en: '*∃ℓ:* X *×* X *→ ℝ⁺ . ∀(*x*,* y*,* r*) ∈* X *× { -1, 1 } ×* R *. ∀*z *∈* X
    *.* c*(*z*;* x*) = ℓ(*z *-* x*)*'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*∃ℓ:* X *×* X *→ ℝ⁺ 。∀(*x*,* y*,* r*) ∈* X *× { -1, 1 } ×* R *。∀*z *∈* X *。c*(*z*;*
    x*) = ℓ(*z *-* x*)*'
- en: I.e., there exists a function ℓ such that for all data points and all potential
    manipulated feature vectors, *c*(*z ; x*) simply takes the value of ℓ(*z* - *x*).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 即，存在一个函数ℓ，使得对于所有数据点和所有潜在的被操作特征向量，*c*(*z ; x*)只是取值为ℓ(*z* - *x*)。
- en: 'An **instance-wise cost function** may vary between data points. Formally:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**逐实例的代价函数**可能在数据点之间有所不同。形式化地说：
- en: '*∀(*x*,* y*,* r*) ∈* X *× { -1, 1 } ×* R . *∃ℓ*ₓ*:* X *×* X *→ ℝ⁺* .*∀*z *∈*
    X . c*(*z*;* x*) = ℓ*ₓ*(*z - x*)*'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*∀(*x*,* y*,* r*) ∈* X *× { -1, 1 } ×* R 。*∃ℓ*ₓ*:* X *×* X *→ ℝ⁺* 。∀*z *∈*
    X 。c*(*z*;* x*) = ℓ*ₓ*(*z - x*)*'
- en: I.e., **each data point can have its own function,** ℓ*ₓ*, and *c*(*z; x*) takes
    the value of ℓ*ₓ*(*z - x*) for each individual data point.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 即，**每个数据点可以有其自己的函数，** ℓ*ₓ*，并且*c*(*z; x*)对于每个单独的数据点取值为ℓ*ₓ*(*z - x*)。
- en: As we will see in the final article in this series, while the difference between
    the two types of cost functions may seem subtle, **instance-wise cost functions
    are significantly more expressive and harder to learn.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在本系列的最后一篇文章中看到的那样，尽管这两种类型的代价函数之间的区别看起来微妙，**逐实例的代价函数具有显著更强的表现力，并且更难学习。**
- en: 'Preference Classes and Cost Functions in Action: An Example'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏好类和代价函数的应用：一个例子
- en: Let’s take a look at an example given in the paper to help hammer home the aspects
    of the setup we’ve covered so far.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下论文中给出的一个例子，帮助我们深入理解到目前为止所涵盖的设置方面。
- en: '![](../Images/96133e26aa9ea534a03de2dbdc10646e.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96133e26aa9ea534a03de2dbdc10646e.png)'
- en: Image by *R. Sundaram, A. Vullikanti, H. Xu, F. Yao from* [**PAC-Learning for
    Strategic Classification**](https://arxiv.org/abs/2012.03310) *(use under* [*CC-BY
    4.0 license*](https://creativecommons.org/licenses/by/4.0/)*).*
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由 *R. Sundaram, A. Vullikanti, H. Xu, F. Yao* 提供，来自 [**PAC-Learning for Strategic
    Classification**](https://arxiv.org/abs/2012.03310)（使用 [*CC-BY 4.0 许可证*](https://creativecommons.org/licenses/by/4.0/)）。
- en: In this example, we have a decision boundary induced by a linear binary classifier
    and four data points with individual preferences. *General strategic* is the only
    applicable preference class in this case.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们有一个由线性二分类器引起的决策边界，以及四个具有个别偏好的数据点。在这种情况下，*General strategic*是唯一适用的偏好类别。
- en: The dotted perimeter around each *xᵢ* shows the manipulated feature vectors
    *z* to which it would cost the point exactly 1 to move. Since we assume the cost
    function is induced by seminorms, everything inside a perimeter has a cost of
    less than 1 for the corresponding data point to move to. We can easily tell that
    the cost function in this example varies from data point to data point, which
    means it is instance-wise.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每个*xᵢ*周围的虚线边界展示了被操作的特征向量*z*，对于它来说，移动到该点的代价正好是1。由于我们假设代价函数是由半范数引起的，边界内的每个点移动到相应的数据点的代价都小于1。我们可以很容易看出，在这个例子中，代价函数在不同数据点之间有所不同，这意味着它是逐实例的。
- en: As we can see, **the leftmost data point (*x*₁, -1, -1) has no incentive to
    cross the decision boundary** since it is on the negative side of the decision
    boundary while also having a negative preference. (*x*₄, -1, 2), however, wants
    to be positively classified, and since the **reward for manipulating *x*₄** to
    cross the boundary (which is 2) **outweighs the cost** of doing so (which is less
    than 1), **it makes sense to go through with the manipulation.** (*x*₃, 1, -2)
    is symmetric to (*x*₄, -1, 2), also deciding to manipulate its feature to achieve
    its desired classification outcome. Lastly, **(*x*₂, -1, 1),** the cost function
    of which we can see is based on [taxicab distance](https://en.wikipedia.org/wiki/Taxicab_geometry),
    **opts to stay put regardless of its preference to be positively classified.**
    This is because **the cost of manipulating *x*₂ to cross the decision boundary
    would be greater than 1,** surpassing the reward the data point would stand to
    gain by doing so.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，**最左边的数据点 (*x*₁, -1, -1) 没有动机跨越决策边界**，因为它位于决策边界的负侧，并且具有负的偏好。然而，(*x*₄,
    -1, 2) 却希望被正向分类，且由于**操纵 *x*₄** 以跨越边界的**奖励（2）**大于**操作成本**（小于1），**因此进行操作是合理的。**
    (*x*₃, 1, -2) 对称于 (*x*₄, -1, 2)，同样决定操控其特征以实现期望的分类结果。最后，**(*x*₂, -1, 1)**，其成本函数基于
    [曼哈顿距离](https://en.wikipedia.org/wiki/Taxicab_geometry)，**选择保持原状，尽管它希望被正向分类。**
    这是因为**操纵 *x*₂ 跨越决策边界的成本会大于1，**超出该数据点通过此操作可能获得的奖励。
- en: Assuming the agents our data points represent are rational, **we can very easily
    tell when a data point should manipulate its feature vector** (benefits outweigh
    costs) and when it shouldn’t (costs outweigh benefits). **The next step is to
    turn our intuitive understanding into something more formal.**
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们数据点代表的代理是理性的，**我们可以非常容易地判断一个数据点何时应该操控其特征向量**（收益大于成本）和何时不应该（成本大于收益）。**下一步是将我们的直观理解转化为更正式的形式。**
- en: 'Balancing Costs & Benefits: Defining *Data Point Best Response*'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平衡成本与收益：定义 *数据点最佳响应*
- en: This leads us to define the ***data point best response*:**
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这引导我们定义***数据点最佳响应*：**
- en: '![](../Images/ebefb39d8e7565f868bb6dd8bf791b7b.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebefb39d8e7565f868bb6dd8bf791b7b.png)'
- en: So we’re looking for the feature vector(s) *z* ∈ *X* that maximize… what exactly?
    **Let’s break down the expression we’re aiming to maximize into more manageable
    parts.**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们要寻找哪个特征向量 *z* ∈ *X* 来最大化...到底是什么？**让我们将我们要最大化的表达式分解成更易管理的部分。**
- en: '***h*:** A given binary classifier (*h*: *X* → { -1, 1 }).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***h*:** 一个给定的二分类器 (*h*: *X* → { -1, 1 })。'
- en: '***c*(*z*; *x*):** As stated above, this expresses the **cost** of modifying
    the feature vector *x* to be *z*.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***c*(*z*; *x*):** 如上所述，这表示**修改特征向量 *x* 为 *z* 的成本。**'
- en: '**𝕀(*h*(*z*) = 1):** Here, 𝕀(*p*) is the indicator function, returning 1 if
    the predicate *p* is upheld or 0 if it isn’t. The predicate *h*(*z*) = 1is true
    if the vector *z* under consideration is positively classified by *h*. Putting
    that together, we find that 𝕀(*h*(*z*) = 1) evaluates to 1 for any *z* that is
    positively classified. If *r* is positive, that’s good. If it’s negative, that’s
    bad.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**𝕀(*h*(*z*) = 1):** 这里，𝕀(*p*) 是指示函数，当谓词 *p* 得到满足时返回1，否则返回0。谓词 *h*(*z*) = 1
    表示如果向量 *z* 被 *h* 正向分类时成立。将这些组合在一起，我们发现，𝕀(*h*(*z*) = 1) 对于任何正向分类的 *z* 都会返回1。如果
    *r* 为正，那就好。如果为负，那就不好。'
- en: '**The bottom-line is that we want to find vector(s) *z* for which** 𝕀(*h*(*z*)
    = 1) ⋅ *r*, which we can call t**he *realized reward*, outweighs the cost of manipulating
    the original *x* into *z* by as much as possible.** To put it in game theoretic
    terms, **the data point best response maximizes the *utility* of its corresponding
    agent in the context of the binary classification under consideration.**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**底线是我们想找到特征向量 *z*，使得** 𝕀(*h*(*z*) = 1) ⋅ *r*，我们可以称之为*实际奖励*，尽可能超过将原始 *x* 转变为
    *z* 的成本。** 用博弈论的术语来说，**数据点最佳响应最大化其对应代理在所考虑的二分类背景下的*效用*。**'
- en: 'Putting It All Together: A Formal Definition of the Strategic Classification
    Problem'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 综合起来：战略分类问题的正式定义
- en: Finally, we’ve laid all the necessary groundwork to formally define **the strategic
    classification problem.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们已经铺垫好了所有必要的基础，来正式定义**战略分类问题。**
- en: '![](../Images/054a8278559f7e6cf18b9579939c3925.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/054a8278559f7e6cf18b9579939c3925.png)'
- en: A diagram illustrating the formal definition of the strategic classification
    problem. Image by author.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个展示战略分类问题正式定义的图表。图像由作者提供。
- en: Given a hypothesis class *H*, a preference class *R*, a cost function *c*, and
    a set of *n* data points drawn from a distribution *D*, we want to find a binary
    classifier *h*’ that minimizes the loss as defined in the diagram above. Note
    that the loss is simply a modification of the canonical zero-one loss, plugging
    in the data point best response instead of *h*(*x*).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个假设类*H*，一个偏好类*R*，一个成本函数*c*，以及从分布*D*中抽取的*n*个数据点，我们希望找到一个二元分类器*h*'，使其最小化上图所定义的损失。注意，损失只是经典零一损失的修改，使用数据点的最佳响应替代*h*(*x*)。
- en: Conclusion
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Starting from the canonical binary classification setup, we introduced the notion
    of ***preference classes***. Next, we saw how to formalize that notion using an
    ***r* value** for each data point. We then saw how ***cost functions*** complement
    data point preferences. After that, we broke down an example before defining the
    key concept of ***data point best response*** based on the ideas we explored beforehand.
    Lastly, we used the data point best response to define the ***modified zero-one
    loss* used in the definition of the strategic classification problem.**
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从经典的二元分类设置开始，我们引入了***偏好类***的概念。接下来，我们看到了如何使用每个数据点的***r*值**来形式化这一概念。然后我们看到如何通过***成本函数***来补充数据点的偏好。之后，我们通过一个例子来分解这一概念，并基于之前探讨的思路定义了***数据点最佳响应***的关键概念。最后，我们使用数据点最佳响应来定义用于战略分类问题定义的***修改版零一损失*。**
- en: '**Join me next time as I define and explain the strategic VC dimension, which
    is the natural next step from where we left off this time.**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**下次加入我，看看我如何定义和解释战略VC维度，这是我们这次讨论后自然的下一步。**'
- en: '[](/quantifying-the-complexity-and-learnability-of-strategic-classification-problems-fd04cbfdd4b9?source=post_page-----6c374935dde2--------------------------------)
    [## Quantifying the Complexity and Learnability of Strategic Classification Problems'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/quantifying-the-complexity-and-learnability-of-strategic-classification-problems-fd04cbfdd4b9?source=post_page-----6c374935dde2--------------------------------)
    [## 定量分析战略分类问题的复杂性和可学习性'
- en: How generalizing the notion of VC dimension to a strategic setting can help
    us understand whether or not a problem is…
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过将VC维度的概念推广到战略环境，我们可以帮助我们理解一个问题是否…
- en: towardsdatascience.com](/quantifying-the-complexity-and-learnability-of-strategic-classification-problems-fd04cbfdd4b9?source=post_page-----6c374935dde2--------------------------------)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/quantifying-the-complexity-and-learnability-of-strategic-classification-problems-fd04cbfdd4b9?source=post_page-----6c374935dde2--------------------------------)
- en: References
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] R. Sundaram, A. Vullikanti, H. Xu, F. Yao. [PAC-Learning for Strategic
    Classification](https://arxiv.org/abs/2012.03310) (2021), International Conference
    on Machine Learning.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] R. Sundaram, A. Vullikanti, H. Xu, F. Yao. [PAC学习与战略分类](https://arxiv.org/abs/2012.03310)
    (2021)，国际机器学习大会。'
