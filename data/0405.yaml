- en: Yes, You Still Need NLP Skills in “the Age of ChatGPT”
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 是的，你在“ChatGPT时代”依然需要NLP技能
- en: 原文：[https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12](https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12](https://towardsdatascience.com/yes-you-still-need-old-school-nlp-skills-in-the-age-of-chatgpt-a26a47dc23d7?source=collection_archive---------9-----------------------#2024-02-12)
- en: Large Language Models have their strengths, but for many production problems,
    simpler NLP techniques are faster, cheaper, and just as effective.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型有其优势，但对于许多生产问题，简单的NLP技术更快、更便宜，且同样有效。
- en: '[](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Katherine
    Munro](../Images/8013140495c7b9bd25ef08d712f097bf.png)](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    [Katherine Munro](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Katherine
    Munro](../Images/8013140495c7b9bd25ef08d712f097bf.png)](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    [Katherine Munro](https://katherineamunro.medium.com/?source=post_page---byline--a26a47dc23d7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    ·7 min read·Feb 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a26a47dc23d7--------------------------------)
    ·7分钟阅读·2024年2月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c75fdc1a480c2d310bb9cfb150c6ca97.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c75fdc1a480c2d310bb9cfb150c6ca97.png)'
- en: 'Large Language Models require new skills, but it’s important not to forget
    the old ones too, like how to prepare the text data the LLM should use. Source:
    [Markus Winkler](https://unsplash.com/@markuswinkler) on Unsplash.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型需要新的技能，但同样重要的是不要忘记那些老技能，比如如何准备LLM需要使用的文本数据。来源：[Markus Winkler](https://unsplash.com/@markuswinkler)
    在 Unsplash。
- en: Back when I started a masters of Computational Linguistics, no-one I knew had
    even the faintest idea what Natural Language Processing (NLP) was. Not even me
    [[1](#footnote-1)]. Fast forward four years, and now when I say I work in NLP,
    I only get blank looks about half of the time [[2](#footnote-2)]. Thanks to masses
    of media hype, most people know that there are things called Large Language Models,
    and they can do a lot of amazing and very useful stuff with text. It’s become
    a lot easier for me to explain my job to people (provided I tell them “it’s basically
    ChatGPT”). But recently, this also gave me pause.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始攻读计算语言学硕士时，我认识的任何人都不知道什么是自然语言处理（NLP）。就连我自己也不清楚 [[1](#footnote-1)]。四年后，当我说我从事NLP工作时，只有一半的时间能得到一些理解
    [[2](#footnote-2)]。得益于媒体的广泛宣传，大多数人知道有一种叫做大型语言模型的东西，它们可以用文本做很多惊人的有用的事情。现在，我向别人解释我的工作变得容易多了（前提是我告诉他们“它基本上就是ChatGPT”）。但最近，这也让我陷入了沉思。
- en: 'I’m the editor of a [Data Science and AI textbook](https://www.amazon.com/Handbook-Data-Science-AI-Analytics/dp/1569908869),
    published waaaay back in 2022 (seriously, in AI years that’s about 20). In preparation
    for the third edition, coming this year, I needed to update my NLP chapter. And
    as I sat down to read what I wrote back then about neural networks, sequence to
    sequence models, and this damn-fangled new technology called “Transformers,” I
    noticed something remarkable: it all felt so *old school*. All that stuff on statistical
    Machine Learning approaches? Quaint. And my little code…'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一本 [数据科学与人工智能教科书](https://www.amazon.com/Handbook-Data-Science-AI-Analytics/dp/1569908869)的编辑，这本书早在2022年就已出版（说真的，在人工智能领域，那大约有20年的历史了）。为了准备今年出版的第三版，我需要更新我的自然语言处理章节。当我坐下来阅读自己当时写的关于神经网络、序列到序列模型以及这个叫做“Transformers”的新技术时，我注意到一件值得注意的事：这一切都显得如此*老派*。那些关于统计机器学习方法的内容？真是过时了。而我写的小段代码……
