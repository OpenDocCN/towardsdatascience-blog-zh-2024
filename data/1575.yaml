- en: Llama Is Open-Source, But Why?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Llama 是开源的，但为什么？
- en: 原文：[https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25](https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25](https://towardsdatascience.com/llama-is-open-source-but-why-3f87d290d0d5?source=collection_archive---------5-----------------------#2024-06-25)
- en: OPINION
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观点
- en: An analysis of Meta’s open-source large model strategy
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Meta 开源大模型战略分析
- en: '[](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Haifeng
    Jin](../Images/705d6ecaed975b6376fac19087f2c02c.png)](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)
    [Haifeng Jin](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Haifeng
    Jin](../Images/705d6ecaed975b6376fac19087f2c02c.png)](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)
    [Haifeng Jin](https://haifeng-jin.medium.com/?source=post_page---byline--3f87d290d0d5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)
    ·6 min read·Jun 25, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3f87d290d0d5--------------------------------)
    ·6分钟阅读·2024年6月25日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9f9d46a904ceb1062f3aa0c3d67d63d6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f9d46a904ceb1062f3aa0c3d67d63d6.png)'
- en: Image by the author using DALL-E
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 DALL-E 创建
- en: Training a large language model can cost millions of dollars. Why would Meta
    spend so much money training a model and letting everyone use it for free?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个大语言模型可能花费数百万美元。Meta 为什么会花这么多钱训练一个模型，并且让所有人免费使用？
- en: This article analyzes Meta’s GenAI and large model strategy to understand the
    considerations of open-sourcing their large models. We also discuss how this wave
    of open-source models is similar to and different from traditional open-source
    software.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分析了 Meta 的 GenAI 和大模型战略，旨在理解开源大模型的考虑因素。我们还讨论了这波开源模型如何与传统开源软件相似，又有何不同。
- en: 'DISCLAIMER: Whether the Llama models are genuinely open-source falls outside
    the scope of this article. All information is from public sources.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 免责声明：Llama 模型是否真正开源超出了本文的讨论范围。所有信息均来自公开来源。
- en: The illusion of proprietary models
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 专有模型的幻象
- en: If Meta open-sources its models, wouldn’t people just build their own services
    instead of paying for the service (e.g., the chatbot on [Meta AI](https://www.meta.ai/),
    an API based on Llama, or helping you fine-tune the model and serve it efficiently)
    provided by Meta?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Meta 开源它的模型，难道人们不会选择自己构建服务，而不是付费使用 Meta 提供的服务（例如，基于 Llama 的 [Meta AI](https://www.meta.ai/)
    聊天机器人，API，或者帮助你微调模型并高效提供服务）吗？
- en: Preventing people from building their own solutions by keeping the models proprietary
    is just an illusion. Regardless of whether you open-source your models, others,
    like [Mistral AI](https://docs.mistral.ai/#open-source), [Alibaba](https://github.com/QwenLM/Qwen2),
    and even [Google](https://blog.google/technology/developers/gemma-open-models/),
    open-sourced their models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将模型保持为专有，来阻止人们构建自己的解决方案，这不过是一个幻象。无论是否开源你的模型，其他公司，如 [Mistral AI](https://docs.mistral.ai/#open-source)、[阿里巴巴](https://github.com/QwenLM/Qwen2)，甚至
    [谷歌](https://blog.google/technology/developers/gemma-open-models/)，都已开源了他们的模型。
- en: For now, OpenAI, Anthropic, and Google have not open-sourced their largest/best
    models because they still think they are in a realm that no open-source models
    can reach regarding capabilities and quality. Open-sourcing their models would
    hurt their business.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，OpenAI、Anthropic 和谷歌并没有开源它们最大/最好的模型，因为它们仍然认为自己处于一个开源模型无法企及的领域，无论是能力还是质量。开源这些模型将对他们的业务造成损害。
- en: Unless your model is better than any other open-source models by several orders
    of magnitude, whether you open-source your model wouldn’t affect the quality of
    the applications the users can build upon open-source models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你的模型比其他任何开源模型好几个数量级，否则是否开源你的模型不会影响用户在开源模型上构建应用程序的质量。
- en: Your only choices are to be the first and the leader of open-source models or
    to be a follower by releasing your models later.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你唯一的选择是成为开源模型的首创者和领导者，或者成为一个追随者，在稍后发布你的模型。
- en: Why be the leader of open-source models?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要成为开源模型的领导者？
- en: Being the leader of open-source models has many benefits, but the most important
    is attracting talent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 成为开源模型的领导者有许多好处，但最重要的就是吸引人才。
- en: The war of GenAI is a talent competition bottlenecked by computing power. How
    much computing power you get largely depends on the cash flow relationship with
    Nvidia, [except Google](/tpus-are-not-for-sale-but-why-5964f87f7a15). However,
    how many talents you have is another story.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI 的战争是被计算能力瓶颈限制的人才竞争。你获得多少计算能力在很大程度上取决于你与 Nvidia 的现金流关系，[除了谷歌](/tpus-are-not-for-sale-but-why-5964f87f7a15)。然而，拥有多少人才则是另一个问题。
- en: According to [Elon Musk](https://youtu.be/2BfMuHDfGJI?t=2748), Google had two-thirds
    of the AI talent, and to counter Google’s power, they founded OpenAI. Then, some
    of the best people left OpenAI and founded Anthropic to focus on AI safety. So,
    these three companies have the best and the most AI experts right now in the market.
    Everyone else is super hungry for more AI experts.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[埃隆·马斯克](https://youtu.be/2BfMuHDfGJI?t=2748)的说法，谷歌拥有三分之二的 AI 人才，为了对抗谷歌的力量，他们创办了
    OpenAI。随后，一些最顶尖的人才离开了 OpenAI，创办了 Anthropic，专注于 AI 安全。因此，目前市场上这三家公司拥有最优秀、最多的 AI
    专家。其他公司都急需更多的 AI 专家。
- en: Being the leader of open-source models would help Meta bridge this gap of AI
    experts. Open-source models attract talent in two different ways.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 成为开源模型的领导者将帮助 Meta 弥合 AI 专家的差距。开源模型通过两种方式吸引人才。
- en: First, the AI experts want to work for Meta. It is super cool to have the whole
    world use the model you built. It gives you so much exposure for your work, amplifies
    your professional impact, and benefits your future career. So, many talented people
    would like to work for them.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，AI 专家们想为 Meta 工作。让全世界都使用你构建的模型是超级酷的。这会为你的工作带来大量曝光，扩大你的专业影响力，并且对你未来的职业生涯有好处。所以，许多有才华的人愿意为他们工作。
- en: Second, the AI experts in the community do the work for Meta for free. Right
    after the release of Llama, people started to experiment with it. They help you
    develop new serving technologies to reduce costs, fine-tune your models to discover
    new applications and scrutinize your model to discover vulnerabilities to make
    it safer. For example, according to [this article](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither),
    they did instruction tuning, quantization, quality improvements, human evals,
    multimodality, and RLHF for Llama within a month after its initial release. Delegating
    this work to the community saves Meta huge amounts of computing and human resources.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，社区中的 AI 专家们为 Meta 做了免费的工作。在 Llama 发布后不久，人们开始对其进行实验。他们帮助你开发新的服务技术以降低成本，微调模型以发现新应用，并仔细审查模型以发现漏洞，提升其安全性。例如，根据[这篇文章](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)，他们在
    Llama 最初发布后一个月内进行了指令调优、量化、质量改进、人类评估、多模态和 RLHF。将这项工作交给社区，帮助 Meta 节省了大量的计算和人力资源。
- en: Iterate fast with the community.
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与社区快速迭代。
- en: With open-source models, Meta can iterate quickly with the community by directly
    incorporating their newly developed methods.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用开源模型，Meta 可以通过直接将其新开发的方法融入其中，迅速与社区一起进行迭代。
- en: 'How much would it cost Google to adopt a new method from the community? The
    process consists of two phases: implementation and evaluation. First, they need
    to reimplement the method for Gemini. This involves rewriting the code in JAX,
    which requires a fair amount of engineering resources. During the evaluation,
    they need to run a list of benchmarks on it, which requires a lot of computing
    power. Most importantly, it takes time. It stopped them from iterating on the
    latest technologies when they were first available.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果谷歌要采用社区的新方法，成本会有多高？这个过程分为两个阶段：实现和评估。首先，他们需要重新实现该方法以适配 Gemini。这涉及到用 JAX 重写代码，需要大量的工程资源。在评估阶段，他们需要对其进行一系列基准测试，这又需要大量的计算能力。最重要的是，这需要时间。当最新技术首次可用时，它们无法立即进行迭代。
- en: Conversely, if Meta wants to adopt a new method from the community, it will
    cost them nothing. The community has done the experiments and benchmarks on the
    Llama model directly, so not much further evaluation is needed. The code is written
    in PyTorch. They can just copy and paste it into their system.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果 Meta 想要采纳社区的一个新方法，对他们来说几乎没有成本。社区已经直接对 Llama 模型做了实验和基准测试，因此不需要进一步评估。代码是用
    PyTorch 编写的，他们可以直接复制并粘贴到自己的系统中。
- en: Llama built a flywheel between Meta and the community. Meta brings in the latest
    technology from the community and rolls out its next-generation model to the community.
    PyTorch is the common language they speak.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 在 Meta 和社区之间建立了一个飞轮。Meta 从社区引入最新技术，并将其下一代模型推向社区。PyTorch 是他们共同使用的语言。
- en: Can they still make money?
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 他们还能赚钱吗？
- en: The model is open-source. Wouldn’t people just build their own service? Why
    would they want to pay Meta for a service built on an open-source model? Of course,
    they will. The service is difficult to build even with an open-source model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是开源的。人们不会直接建立自己的服务吗？为什么他们还要为一个建立在开源模型上的服务付费给 Meta 呢？当然会。即使是开源模型，构建服务依然很困难。
- en: How do you fine-tune and align the model to your specific application? How do
    you balance between the service cost and the model quality? Are you aware of all
    the tricks to fully utilize your GPUs?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何微调和调整模型以适应你的特定应用？你如何平衡服务成本和模型质量？你是否了解所有技巧，能够充分利用你的 GPU？
- en: The people who know the answers to these questions are expensive to hire. Even
    with enough people, it is hard to get the computing power to fine-tune and serve
    the model. Imagine how hard it is to build [Meta AI](https://www.meta.ai/) from
    the open-source Llama model. I would expect hundreds of employees and GPUs to
    be involved.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 知道这些问题答案的人很难找到，且招聘成本高。即使有足够的人力，想要获得足够的计算能力来微调和服务模型也很难。试想一下，如何从开源的 Llama 模型构建
    [Meta AI](https://www.meta.ai/)。我预计需要数百名员工和大量 GPU 参与其中。
- en: So, it is likely that people will still pay for Meta’s GenAI service if they
    have any in the future.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果将来有任何类似的 Meta GenAI 服务，人们仍然可能会为其付费。
- en: It’s just like open-source software, but not quite.
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这就像开源软件，但又不完全是。
- en: The situation is very similar to traditional open-source software. The “[free
    code paid service](/tensorflow-is-open-source-but-why-512d849f59d2)” framework
    still applies. The code or the model is free to attract more users to the ecosystem.
    With a larger ecosystem, the owner collects more benefits. The service built upon
    the free code is for profit.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 情况与传统的开源软件非常相似。"[免费代码，付费服务](/tensorflow-is-open-source-but-why-512d849f59d2)"
    这一框架依然适用。代码或模型是免费的，用来吸引更多用户加入生态系统。随着生态系统的扩大，拥有者能收获更多的利益。建立在免费代码之上的服务则是为了盈利。
- en: However, it is also NOT like open-source software. The main difference can be
    summarized as low user retention and a new type of ecosystem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它也并不像开源软件。主要的区别可以总结为低用户留存率和一种新型的生态系统。
- en: Low user retention
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户留存率低
- en: Open-source models have lower user retention. Migrating to a new model is much
    easier than to new software.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型的用户留存率较低。迁移到新模型比迁移到新软件要容易得多。
- en: It is hard to migrate software. PyTorch and HuggingFace have established a strong
    ecosystem for deep learning frameworks and model pools. Imagine how hard it would
    be to shift their dominance even slightly if you created a new deep learning framework
    or model pool to compete with them.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移软件很困难。PyTorch 和 HuggingFace 为深度学习框架和模型池建立了强大的生态系统。试想一下，如果你创建一个新的深度学习框架或模型池来与他们竞争，想要稍微改变他们的主导地位有多么困难。
- en: A good example is JAX. It has better support for large-scale distributed training,
    but it is hard to onboard users to JAX because it has a smaller ecosystem and
    community. It lacks a helpful community to support users with issues. Moreover,
    the engineering cost of migrating the entire infra to a new framework is too high
    for most companies.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的例子是 JAX。它对大规模分布式训练提供了更好的支持，但由于生态系统和社区较小，很难吸引用户使用 JAX。它缺乏一个能帮助用户解决问题的有力社区。而且，将整个基础设施迁移到新的框架的工程成本对大多数公司来说太高了。
- en: Open-source models do not have these problems. They are easy to migrate and
    require almost no user support. Therefore, it is easy for people to shift to the
    latest and best models. To maintain your leadership in open-source models, you
    must constantly release new models at the top of the leaderboard. This is also
    noted as a downside or challenge to be the leader in open-source models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型没有这些问题。它们易于迁移，几乎不需要用户支持。因此，人们可以轻松转向最新和最好的模型。要在开源模型中保持领导地位，你必须不断发布位于排行榜顶部的新模型。这也是成为开源模型领导者的一大挑战或缺点。
- en: A new type of ecosystem
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种新型的生态系统
- en: Open-source models create a new type of ecosystem. Unlike open-source software,
    which creates ecosystems of contributors and new software built upon them, open-source
    models create ecosystems of fine-tuned and quantized models, which can be seen
    as forks of the original model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型创造了一种新型的生态系统。与开源软件创造贡献者和新软件生态系统不同，开源模型创造了微调和量化模型的生态系统，这些模型可以看作是原始模型的分支。
- en: As a result, an open-source foundational model doesn’t have to be super good
    at every specific task because users would fine-tune it for their applications
    with domain-specific data. The most important feature of a foundational model
    is to meet the deployment requirements of the users, such as low latency in inferencing
    or being small enough to fit an end device.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个开源基础模型不必在每个具体任务上都表现得非常优秀，因为用户可以通过领域特定的数据对其进行微调以适应他们的应用需求。基础模型最重要的特点是能够满足用户的部署要求，例如推理时的低延迟，或者足够小以适应终端设备。
- en: 'This is why Llama has multiple sizes for each version. For example, Llama-3
    has three versions: 8B, 70B, and 400B. They want to ensure they cover all deployment
    scenarios.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么 Llama 为每个版本提供多个尺寸的原因。例如，Llama-3 有三个版本：8B、70B 和 400B。他们希望确保涵盖所有的部署场景。
- en: Summary
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Even if Meta did not open-source their model, others would. So, it would be
    wise for Meta to open-source it early and lead the open-source models. Then, Meta
    can iterate quickly with the community to improve its models and catch up with
    OpenAI and Google.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 即使 Meta 不开源他们的模型，其他公司也会开源。所以，Meta 提前开源并领导开源模型将是明智之举。然后，Meta 可以与社区快速迭代，改进其模型，赶上
    OpenAI 和 Google。
- en: When open-sourcing your model, there is no need to worry about people not using
    your service since there is still a huge gap between the foundational model and
    a well-built service.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在开源你的模型时，不必担心人们不使用你的服务，因为基础模型与构建良好的服务之间仍然存在巨大的差距。
- en: Open-source models are similar to open-source software in that they all follow
    the “free code paid service” framework but differ in user retention rate and the
    type of ecosystem they create.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型类似于开源软件，它们都遵循“自由代码付费服务”框架，但在用户留存率和所创建的生态系统类型上有所不同。
- en: In the future, I would expect to see more open-source models from more companies.
    Unlike the deep learning frameworks converged on PyTorch, open-source models will
    remain diverse and competitive for a long time.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，我预计会看到更多来自更多公司的开源模型。与已集中在 PyTorch 上的深度学习框架不同，开源模型将在很长一段时间内保持多样性和竞争力。
