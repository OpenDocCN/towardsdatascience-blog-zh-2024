- en: 'Blending Text and Symbols: A Path to Robust LLM Reasoning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合文本与符号：通向强大LLM推理能力的道路
- en: 原文：[https://towardsdatascience.com/blending-text-and-symbols-a-path-to-robust-llm-reasoning-607ceebbf958?source=collection_archive---------13-----------------------#2024-01-17](https://towardsdatascience.com/blending-text-and-symbols-a-path-to-robust-llm-reasoning-607ceebbf958?source=collection_archive---------13-----------------------#2024-01-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/blending-text-and-symbols-a-path-to-robust-llm-reasoning-607ceebbf958?source=collection_archive---------13-----------------------#2024-01-17](https://towardsdatascience.com/blending-text-and-symbols-a-path-to-robust-llm-reasoning-607ceebbf958?source=collection_archive---------13-----------------------#2024-01-17)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page---byline--607ceebbf958--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)
    ·8 min read·Jan 17, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--607ceebbf958--------------------------------)
    ·8分钟阅读·2024年1月17日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件被用来增强本文文本的语法、流畅度和可读性。*'
- en: Large language models (LLMs) have demonstrated immense capabilities in natural
    language processing. They can generate remarkably human-like text, hold conversations,
    summarize long passages, and even attempt rudimentary reasoning.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在自然语言处理方面展示了巨大的能力。它们能够生成极其逼真的文本，进行对话，总结长篇内容，甚至尝试进行初步的推理。
- en: However, despite their exceptional advances in semantic understanding of text,
    LLMs still face profound limitations when complex logical reasoning is required.
    Their comprehension remains surface-level, often missing deeper connections or
    failing at deductions requiring mathematical logic.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管LLM在语义理解方面取得了卓越的进展，但当需要复杂的逻辑推理时，它们仍面临深刻的局限性。它们的理解仍然停留在表面，常常缺乏更深层次的联系，或者在需要数学逻辑的推理中失败。
- en: Two domains that expose these LLM reasoning deficiencies are tabular data and
    knowledge graphs. Tables containing structured statistics, relations, and properties
    abound in business analysis, science, and public policy contexts. Knowledge graphs
    assemble concepts, real-world entities, and their interrelations in intricate
    networks of facts modeled as graph nodes and edges.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 两个暴露这些大型语言模型（LLM）推理不足之处的领域是表格数据和知识图谱。表格包含结构化的统计数据、关系和属性，这些在商业分析、科学研究和公共政策等领域中随处可见。知识图谱将概念、现实世界实体及其相互关系汇集成复杂的事实网络，以图节点和边的形式呈现。
- en: Reasoning with such structured data requires subtly balancing context with symbolic
    logic. For example, identifying statistical insights within tables benefits from
    understanding the semantics to contextualize what the numbers signify. Or solving
    analytical graph queries relies on manipulating logical graph patterns while tracking
    real-world entities.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些结构化数据进行推理需要在上下文与符号逻辑之间微妙地平衡。例如，在表格中识别统计信息时，理解语义有助于将数字的含义放入上下文中。又如，解决分析图查询则依赖于操作逻辑图模式，同时追踪现实世界的实体。
