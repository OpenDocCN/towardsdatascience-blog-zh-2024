- en: 'Don’t Crash Your App: Load Records from the Database in Batches for Better
    Performance'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 别让你的应用崩溃：以批次的形式从数据库加载记录以提升性能
- en: 原文：[https://towardsdatascience.com/dont-crash-your-app-load-records-from-the-databse-in-batches-for-better-performance-ab09f3598d96?source=collection_archive---------6-----------------------#2024-04-18](https://towardsdatascience.com/dont-crash-your-app-load-records-from-the-databse-in-batches-for-better-performance-ab09f3598d96?source=collection_archive---------6-----------------------#2024-04-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dont-crash-your-app-load-records-from-the-databse-in-batches-for-better-performance-ab09f3598d96?source=collection_archive---------6-----------------------#2024-04-18](https://towardsdatascience.com/dont-crash-your-app-load-records-from-the-databse-in-batches-for-better-performance-ab09f3598d96?source=collection_archive---------6-----------------------#2024-04-18)
- en: Save your Python app’s performance by efficiently loading query
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过高效加载查询来提升你的 Python 应用性能
- en: '[](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)[![Mike
    Huls](../Images/8f9f55a0d25db00799c5d37383b7f5b6.png)](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)
    [Mike Huls](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)[![Mike
    Huls](../Images/8f9f55a0d25db00799c5d37383b7f5b6.png)](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)
    [Mike Huls](https://mikehuls.medium.com/?source=post_page---byline--ab09f3598d96--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)
    ·7 min read·Apr 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ab09f3598d96--------------------------------)
    ·7 分钟阅读·2024年4月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5f4bed285bcfbe44453241b68a82e675.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f4bed285bcfbe44453241b68a82e675.png)'
- en: Python transporting small batches of data (image generated by ChatGPT)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Python 传输小批量数据（由 ChatGPT 生成的图像）
- en: 'This article is about optimizing the communication between your Python app
    and a database so that your app runs smoothly and your database server doesn’t
    melt. This article addresses a common **inefficiency: the habit of loading all
    data from a query at once.**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文讨论了优化 Python 应用与数据库之间通信的技巧，以确保应用流畅运行，同时避免数据库服务器的过载。本文关注一个常见的**低效问题：一次性加载所有查询结果。**
- en: 'When faced with queries that returns a lot of records it’s **often impractical
    or even impossible to load all returned records.** Instead of loading *all* results
    in memory and then processing row-by-row, in this article we’ll find out how to
    **load many small chunks**. Instead of loading 1 million records and processing
    we’ll load a 400 batches of 2.500 records each! This way your app doesn’t have
    to load all results in memory which has clear benefits:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当面对返回大量记录的查询时，**一次性加载所有返回的记录往往既不实际也不可能。** 我们不再将*所有*结果加载到内存中并逐行处理，而是通过本文的方法来**分批加载多个小块数据**。我们不再一次性加载
    100 万条记录并处理，而是分批加载 400 次，每次加载 2500 条记录！这样，应用就不必将所有结果加载到内存中，带来了明显的好处：
- en: Enhanced memory usage
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增强的内存使用
- en: Better perceived response times
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的响应时间感知
- en: Reduces database stress
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少数据库压力
- en: We will also take a look under the hood and dive into the technical details
    of this technique, showing you exactly how it works behind the scenes. Let’s code!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将深入了解这一技术的原理，展示它在幕后是如何工作的。让我们开始编码吧！
- en: Why use fetchmany
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用 fetchmany
