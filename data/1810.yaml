- en: Multimodal RAG — Intuitively and Exhaustively Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态RAG — 直观且详尽的解释
- en: 原文：[https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25](https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25](https://towardsdatascience.com/multimodal-rag-intuitively-and-exhaustively-explained-5713d8069eb0?source=collection_archive---------4-----------------------#2024-07-25)
- en: Artificial Intelligence | Retrieval Augmented Generation | Multimodality
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能 | 检索增强生成 | 多模态
- en: Modern RAG for modern models.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代RAG适用于现代模型。
- en: '[](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page---byline--5713d8069eb0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    ·10 min read·Jul 25, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5713d8069eb0--------------------------------)
    ·10分钟阅读·2024年7月25日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/439b5f04f55575e85c358964da8b2e91.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/439b5f04f55575e85c358964da8b2e91.png)'
- en: “Multicolored Team” by Daniel Warfield using Midjourney. All images by the author
    unless otherwise specified. Article originally made available on [Intuitively
    and Exhaustively Explained](https://iaee.substack.com/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “多彩团队”由Daniel Warfield使用Midjourney创作。除非另有说明，所有图片均由作者提供。文章最初发布于[直观且详尽的解释](https://iaee.substack.com/)。
- en: Multimodal Retrieval Augmented Generation is an emerging design paradigm that
    allows AI models to interface with stores of text, images, video, and more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态检索增强生成（Multimodal Retrieval Augmented Generation，简称RAG）是一种新兴的设计范式，它使得AI模型能够与文本、图像、视频等多种信息存储库进行交互。
- en: In exploring this topic we’ll first cover what retrieval augmented generation
    (RAG) is, the idea of multimodality, and how the two are being combined to make
    modern multimodal RAG systems. Once we understand the fundamental concepts of
    multimodal RAG, we’ll build a multimodal RAG system ourselves using Google Gemini
    and a CLIP style model for encoding.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在探讨这个话题时，我们将首先介绍什么是检索增强生成（RAG）、多模态的概念，以及这两者如何结合在一起，构建现代的多模态RAG系统。一旦我们理解了多模态RAG的基本概念，就可以使用Google
    Gemini和CLIP风格模型进行编码，亲自构建一个多模态RAG系统。
- en: '**Who is this useful for?** Anyone interested in modern AI.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 任何对现代人工智能感兴趣的人。'
- en: '**How advanced is this post?** Even though multimodal RAG is at the forefront
    of AI, it’s intuitively simple and accessible. This article should be interesting
    to senior AI researchers, while simple enough for a beginner.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章的难度如何？** 尽管多模态RAG处于人工智能的前沿，但它直观简单且易于接触。本文应该对资深AI研究人员有趣，同时对于初学者来说也足够简单。'
- en: '**Pre-requisites:** None'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件：** 无'
- en: A Brief Introduction to Retrieval Augmented Generation
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索增强生成简介
- en: Before we get into Multimodal RAG, let’s briefly go over traditional Retrieval
    Augmented Generation (RAG). Basically, the idea…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解多模态RAG之前，先简要回顾一下传统的检索增强生成（RAG）。基本概念是……
