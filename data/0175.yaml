- en: Building an LLMOPs Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建LLMOPs管道
- en: 原文：[https://towardsdatascience.com/building-an-llmops-pipeline-08d367b36d64?source=collection_archive---------4-----------------------#2024-01-18](https://towardsdatascience.com/building-an-llmops-pipeline-08d367b36d64?source=collection_archive---------4-----------------------#2024-01-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-an-llmops-pipeline-08d367b36d64?source=collection_archive---------4-----------------------#2024-01-18](https://towardsdatascience.com/building-an-llmops-pipeline-08d367b36d64?source=collection_archive---------4-----------------------#2024-01-18)
- en: Utilize SageMaker Pipelines, JumpStart, and Clarify to Fine-Tune and Evaluate
    a Llama 7B Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker管道、JumpStart和Clarify微调和评估Llama 7B模型
- en: '[](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page---byline--08d367b36d64--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)
    ·10 min read·Jan 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page---byline--08d367b36d64--------------------------------)
    ·10分钟阅读·2024年1月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c4f943f8d3c72ddb5cd475429d4efef2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4f943f8d3c72ddb5cd475429d4efef2.png)'
- en: Image from [Unsplash](https://unsplash.com/photos/black-and-gray-metal-pipe-4CNNH2KEjhc)
    by [Sigmund](https://unsplash.com/@sigmund)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Unsplash](https://unsplash.com/photos/black-and-gray-metal-pipe-4CNNH2KEjhc)
    由[Sigmund](https://unsplash.com/@sigmund)提供
- en: 2023 was the year that witnessed the rise of various Large Language Models (LLMs)
    in the Generative AI space. LLMs have incredible power and potential, but productionizing
    them has been a consistent challenge for users. An especially prevalent problem
    is what LLM should one use? Even more specifically, how can one evaluate an LLM
    for accuracy? This is especially challenging when there’s a large number of models
    to choose from, different datasets for fine-tuning/RAG, and a variety of prompt
    engineering/tuning techniques to consider.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年是各种大型语言模型（LLMs）在生成式AI领域崛起的一年。LLM具有强大的能力和潜力，但将其投入生产一直是用户面临的持续挑战。一个特别普遍的问题是，应该使用哪个LLM？更具体地说，如何评估一个LLM的准确性？当可以选择的模型数量众多，存在不同的用于微调/RAG的数据集，并且需要考虑多种提示工程/调优技术时，这个问题尤为具有挑战性。
- en: 'To solve this problem we need to establish [DevOps](https://aws.amazon.com/devops/what-is-devops/#:~:text=DevOps%20is%20the%20combination%20of,development%20and%20infrastructure%20management%20processes.)
    best practices for LLMs. Having a workflow or pipeline that can help one evaluate
    different models, datasets, and prompts. This field is starting to get known as
    [LLMOPs/FMOPs](https://aws.amazon.com/blogs/machine-learning/fmops-llmops-operationalize-generative-ai-and-differences-with-mlops/).
    Some of the parameters that can be considered in LLMOPs are shown below, in a
    (extremely) simplified flow:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要为LLM建立[DevOps](https://aws.amazon.com/devops/what-is-devops/#:~:text=DevOps%20is%20the%20combination%20of,development%20and%20infrastructure%20management%20processes.)最佳实践。建立一个可以帮助评估不同模型、数据集和提示的工作流或管道。这个领域开始被称为[LLMOPs/FMOPs](https://aws.amazon.com/blogs/machine-learning/fmops-llmops-operationalize-generative-ai-and-differences-with-mlops/)。以下是LLMOPs中可以考虑的一些参数，展示了一个（极度）简化的流程：
- en: '![](../Images/09d38bebfc8fd0563afadb93fe8d73dd.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09d38bebfc8fd0563afadb93fe8d73dd.png)'
- en: LLM Evaluation Consideration (By Author)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: LLM评估考虑因素（作者）
- en: In this article, we’ll try to tackle this problem by building a pipeline that
    fine-tunes, deploys, and evaluates a [Llama 7B model](https://huggingface.co/meta-llama/Llama-2-7b).
    You can also scale this example, by…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将尝试通过构建一个管道来解决这个问题，该管道可以微调、部署并评估一个[Llama 7B模型](https://huggingface.co/meta-llama/Llama-2-7b)。你还可以通过…来扩展这个示例。
