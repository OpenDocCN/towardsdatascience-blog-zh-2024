- en: A Simple Recipe to Boost the Performance of MLLMs on Your Custom Use Case
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升 MLLMs 在自定义使用场景中性能的简单方法
- en: 原文：[https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11](https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11](https://towardsdatascience.com/a-simple-recipe-to-boost-the-performance-of-mllms-on-your-custom-use-case-6014440f5373?source=collection_archive---------14-----------------------#2024-06-11)
- en: An MLLM QLoRA fine-tuning tutorial using the newest pocket-sized Mini-InternVL
    model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份使用最新口袋大小 Mini-InternVL 模型的 MLLM QLoRA 微调教程
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--6014440f5373--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    ·6 min read·Jun 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6014440f5373--------------------------------)
    ·阅读时长 6 分钟·2024 年 6 月 11 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ac67a9c7e6007446e729e1c9c26e9c26.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac67a9c7e6007446e729e1c9c26e9c26.png)'
- en: Photo by [Maarten van den Heuvel](https://unsplash.com/@mvdheuvel?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Maarten van den Heuvel](https://unsplash.com/@mvdheuvel?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The world of large language models (LLMs) is constantly evolving, with new advancements
    emerging rapidly. One exciting area is the development of multi-modal LLMs (MLLMs),
    capable of understanding and interacting with both texts and images. This opens
    up a world of possibilities for tasks like document understanding, visual question
    answering, and more.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的世界在不断发展，新的技术进步层出不穷。一个令人兴奋的领域是多模态 LLM（MLLM）的发展，它能够理解并与文本和图像进行交互。这为文档理解、视觉问答等任务带来了无限可能。
- en: 'I recently wrote a general post about one such model that you can check out
    here:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近写了一篇关于这种模型的一般性文章，您可以在这里查看：
- en: '[](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
    [## 6 Real-World Uses of Microsoft’s Newest Phi-3 Vision-Language Model'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
    [## 微软最新的 Phi-3 视觉语言模型的 6 个现实世界应用'
- en: Exploring possible use cases of Phi-3-Vision, a small yet powerful MLLM that
    can be run locally (with code examples)
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索 Phi-3-Vision 的可能应用场景，这是一个小巧而强大的 MLLM，可以本地运行（附代码示例）
- en: towardsdatascience.com](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/6-real-world-uses-of-microsofts-newest-phi-3-vision-language-model-8ebbfa317fe8?source=post_page-----6014440f5373--------------------------------)
- en: 'But in this one, we’ll explore a powerful combination: the InternVL model and
    the QLoRA fine-tuning technique. **We will focus on how we can easily customize
    such models for any specific use-case.** We’ll use these tools to create a receipt
    understanding pipeline that extracts key information like company name, address,
    and total amount of purchase with high accuracy.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这篇文章中，我们将探索一个强大的组合：InternVL 模型和 QLoRA 微调技术。**我们将重点讨论如何轻松定制这些模型以适应任何特定的使用场景。**我们将使用这些工具创建一个收据理解流水线，能够高精度地提取诸如公司名称、地址和总购金额等关键信息。
- en: Understanding the Task and Dataset
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解任务和数据集
