- en: Perception-Inspired Graph Convolution for Music Understanding Tasks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 受感知启发的图卷积用于音乐理解任务
- en: 原文：[https://towardsdatascience.com/perception-inspired-graph-convolution-for-music-understanding-tasks-4d2ba1be48e7?source=collection_archive---------3-----------------------#2024-07-09](https://towardsdatascience.com/perception-inspired-graph-convolution-for-music-understanding-tasks-4d2ba1be48e7?source=collection_archive---------3-----------------------#2024-07-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/perception-inspired-graph-convolution-for-music-understanding-tasks-4d2ba1be48e7?source=collection_archive---------3-----------------------#2024-07-09](https://towardsdatascience.com/perception-inspired-graph-convolution-for-music-understanding-tasks-4d2ba1be48e7?source=collection_archive---------3-----------------------#2024-07-09)
- en: This article discusses MusGConv, a perception-inspired graph convolution block
    for symbolic musical applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这篇文章讨论了**MusGConv**，一种受感知启发的图卷积模块，适用于符号音乐应用。
- en: '[](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[![Emmanouil
    Karystinaios](../Images/120d889f330aa7b433a0668a1224e1c8.png)](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)
    [Emmanouil Karystinaios](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[![Emmanouil
    Karystinaios](../Images/120d889f330aa7b433a0668a1224e1c8.png)](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)
    [Emmanouil Karystinaios](https://manoskary.medium.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)
    ·10 min read·Jul 9, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4d2ba1be48e7--------------------------------)
    ·阅读时间10分钟·2024年7月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/38ce2a0126823d36efafd032cdd049bc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38ce2a0126823d36efafd032cdd049bc.png)'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the field of Music Information Research (MIR), the challenge of understanding
    and processing musical scores has continuously been introduced to new methods
    and approaches. Most recently many graph-based techniques have been proposed as
    a way to target music understanding tasks such as voice separation, cadence detection,
    composer classification, and Roman numeral analysis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在音乐信息研究（MIR）领域，理解和处理乐谱的挑战一直在不断引入新的方法和途径。最近，许多基于图的技术被提出，作为解决音乐理解任务的方法，如声音分离、拍子检测、作曲家分类和罗马数字分析。
- en: This blog post covers one of my recent papers in which I introduced a new graph
    convolutional block, called **MusGConv**, designed specifically for processing
    music score data. **MusGConv** takes advantage of music perceptual principles
    to improve the efficiency and the performance of graph convolution in Graph Neural
    Networks applied to music understanding tasks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文讨论了我最近的一篇论文，其中我介绍了一种新的图卷积模块，名为**MusGConv**，专门用于处理乐谱数据。**MusGConv**利用音乐感知原理，提升了图卷积在应用于音乐理解任务中的效率和性能。
- en: Understanding the Problem
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解问题
- en: Traditional approaches in MIR often rely on audio or symbolic representations
    of music. While audio captures the intensity of sound waves over time, symbolic
    representations like MIDI files or musical scores encode discrete musical events.
    Symbolic representations are particularly valuable as they provide higher-level
    information essential for tasks such as music analysis and generation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的MIR方法通常依赖于音乐的音频或符号表示。音频能够捕捉声音波的强度随时间变化，而符号表示如MIDI文件或乐谱则编码了离散的音乐事件。符号表示特别有价值，因为它们提供了更高层次的信息，这对于音乐分析和生成等任务至关重要。
- en: However, existing techniques based on symbolic music representations often borrow
    from computer vision (CV) or natural language processing (NLP) methodologies.
    For instance, representing music as a “pianoroll” in a matrix format and treating
    it similarly to an image, or, representing music as a series of tokens and treating
    it with sequential models or transformers. These approaches, though effective,
    could fall short in fully capturing the complex, multi-dimensional nature of music,
    which includes hierarchical note relation and intricate pitch-temporal relationships.
    Some recent approaches have been proposed to model the musical score as a graph
    and apply Graph Neural Networks to solve various tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现有的基于符号音乐表示的技术通常借鉴计算机视觉（CV）或自然语言处理（NLP）方法。例如，将音乐表示为矩阵格式的“钢琴卷轴”并将其类似于图像，或将音乐表示为一系列符号并通过序列模型或变换器处理。这些方法虽然有效，但可能无法完全捕捉到音乐的复杂多维特性，包括音符的层次关系和复杂的音高-时间关系。一些最新的方法已经提出将音乐乐谱建模为图，并应用图神经网络来解决各种任务。
- en: The Musical Score as a Graph
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将音乐乐谱作为图
- en: 'The fundamental idea of GNN-based approaches to musical scores is to model
    a musical score as a graph where notes are the vertices and edges are built from
    the temporal relations between the notes. To create a graph from a musical score
    we can consider four types of edges (see Figure below for a visualization of the
    graph on the score):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图神经网络（GNN）的方法在音乐乐谱中的基本思想是将音乐乐谱建模为一个图，其中音符是顶点，边是基于音符之间的时间关系构建的。为了从音乐乐谱创建图，我们可以考虑四种类型的边（请参见下图以查看乐谱上图的可视化）：
- en: '*onset edges*: connect notes that share the same onset;'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*起始边*：连接具有相同起始时间的音符；'
- en: '*consecutive edges* (or *next edges*): connect a note x to a note y if the
    offset of x corresponds to the onset of y;'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连续边*（或*下一个边*）：如果音符x的偏移量与音符y的起始时间对应，则连接音符x和音符y；'
- en: '*during edges:* connect a note x to a note y if the onset of y falls within
    the onset and offset of x;'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*期间边*：如果音符y的起始时间落在音符x的起始时间和结束时间之间，则连接音符x和音符y；'
- en: '*rest edges* (or *silence edges*): connect the last notes before a rest to
    the first ones after it.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*休止边*（或*静音边*）：连接休止符前的最后一个音符和其后的第一个音符。'
- en: '![](../Images/6987757e6a0d20c7eb72defcf27a721e.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6987757e6a0d20c7eb72defcf27a721e.png)'
- en: A GNN can treat the graph created from the notes and these four types of relations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GNN可以处理从音符和这四种类型关系中创建的图。
- en: Introducing MusGConv
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍MusGConv
- en: 'MusGConv is designed to leverage music score graphs and enhance them by incorporating
    principles of music perception into the graph convolution process. It focuses
    on two fundamental dimensions of music: pitch and rhythm, considering both their
    relative and absolute representations.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: MusGConv旨在利用音乐乐谱图并通过将音乐感知原理融入图卷积过程来增强这些图。它专注于音乐的两个基本维度：音高和节奏，考虑它们的相对表示和绝对表示。
- en: '![](../Images/2dd885f5d8623cb8a5d42c7a43098506.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2dd885f5d8623cb8a5d42c7a43098506.png)'
- en: Absolute representations refer to features that can be attributed to each note
    individually such as the note’s pitch or spelling, its duration or any other feature.
    On the other hand, relative features are computed between pairs of notes, such
    as the music interval between two notes, their onset difference, i.e. the time
    on which they occur, etc.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对表示指的是可以归属于每个音符的特征，例如音符的音高或拼写、持续时间或任何其他特征。另一方面，相对特征是通过音符对之间计算的，例如两个音符之间的音程、它们的起始时间差，即它们发生的时间等。
- en: Key Features of MusGConv
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusGConv的主要特征
- en: '**Edge Feature Computation**: MusGConv computes edge features based on the
    distances between notes in terms of onset, duration, and pitch. The edge features
    can be normalized to ensure they are more effective for Neural Network computations.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**边特征计算**：MusGConv基于音符之间的起始时间、持续时间和音高计算边特征。可以对边特征进行归一化，以确保它们在神经网络计算中更加有效。'
- en: '**Relative and Absolute Representations**: By considering both relative features
    (distance between pitches as edge features) and absolute values (actual pitch
    and timing as node features), MusGConv can adapt and use the representation that
    is more relevant depending on the occasion.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相对和绝对表示**：通过同时考虑相对特征（作为边特征的音高之间的距离）和绝对值（作为节点特征的实际音高和时间），MusGConv可以根据实际情况调整和使用更相关的表示。'
- en: '**Integration with Graph Neural Networks**: The MusGConv block integrates easily
    with existing GNN architectures with almost no additional computational cost and
    can be used to improve musical understanding tasks such as voice separation, harmonic
    analysis, cadence detection, or composer identification.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**与图神经网络的集成**：MusGConv模块可以轻松与现有的GNN架构集成，几乎不增加额外的计算成本，并且可以用于改进音乐理解任务，例如声部分离、和声分析、节奏检测或作曲家识别。'
- en: The importance and coexistence of the relative and absolute representations
    can be understood from a transpositional perspective in music. Imagine the same
    music content transposed. Then, the intervalic relations between notes stay the
    same but the pitch of each note is altered.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 相对表示和绝对表示的重要性与共存，可以从音乐中的移调角度理解。想象一下相同的音乐内容被移调。那么，音符之间的音程关系保持不变，但每个音符的音高发生了变化。
- en: '![](../Images/0cf1ef46a42f17b5c98c0178aeb597d7.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cf1ef46a42f17b5c98c0178aeb597d7.png)'
- en: Same content transposed by a major third. The relation between the notes between
    the top and the bottom are the same but the absolute pitch is changed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 相同内容通过大三度移调。顶部和底部音符之间的关系相同，但绝对音高发生了变化。
- en: Understanding Message Passing in Graph Neural Networks (GNNs)
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解图神经网络（GNNs）中的消息传递
- en: To fully understand the inner workings of the MusGConv convolution block it
    is important to first explain the principles of Message Passing.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分理解MusGConv卷积模块的内部工作原理，首先需要解释消息传递的原理。
- en: What is Message Passing?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是消息传递？
- en: In the context of GNNs, message passing is a process where vertices within a
    graph exchange information with their neighbors to update their own representations.
    This exchange allows each node to gather contextual information from the graph,
    which is then used to for predictive tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在GNN的上下文中，消息传递是一个过程，其中图中的顶点与它们的邻居交换信息，以更新自身的表示。这种交换使每个节点能够从图中收集上下文信息，然后用于预测任务。
- en: 'The message passing process is defined by the following steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递过程通过以下步骤定义：
- en: '**Initialization**: Each node is assigned to a feature vector, which can include
    some important properties. For example in a musical score, this could include
    pitch, duration, and onset time for each node/note.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化**：每个节点被分配一个特征向量，其中可以包含一些重要的属性。例如，在乐谱中，这可能包括每个节点/音符的音高、时值和起始时间。'
- en: '**Message Generation**: Each node generates a message to send to its neighbors.
    The message typically includes the node’s current feature vector and any edge
    features that describe the relationship between the nodes. A message can be for
    example a linear transformation of the neighbor’s node features.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**消息生成**：每个节点生成一条消息发送给它的邻居。消息通常包含节点的当前特征向量以及描述节点之间关系的任何边特征。消息可以是邻居节点特征的线性变换。'
- en: '**Message Aggregation**: Each node collects messages from its neighbors. The
    aggregation function is usually a permutation invariant function such as sum,
    mean, or max and it combines these messages into a single vector, ensuring that
    the node captures information from its entire neighborhood.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**消息聚合**：每个节点从其邻居处收集消息。聚合函数通常是一个置换不变的函数，例如求和、平均值或最大值，它将这些消息合并成一个单一的向量，确保节点能够捕获来自其整个邻域的信息。'
- en: '**Node Update**: The aggregated message is used to update the node’s feature
    vector. This update often involves applying a neural network layer (like a fully
    connected layer) followed by a non-linear activation function (such as ReLU).'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**节点更新**：聚合后的消息用于更新节点的特征向量。此更新通常涉及应用神经网络层（如全连接层），然后是非线性激活函数（如ReLU）。'
- en: '**Iteration**: Steps 2–4 are repeated for a specified number of iterations
    or layers, allowing information to propagate through the graph. With each iteration,
    nodes incorporate information from progressively larger neighborhoods.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代**：步骤2至步骤4会根据指定的迭代次数或层数重复执行，从而使信息能够在图中传播。每次迭代时，节点会将来自越来越大邻域的信息整合进来。'
- en: Message Passing in MusGConv
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusGConv中的消息传递
- en: MusGConv alters the standard message passing process mainly by incorporating
    both absolute features as node features and relative musical features as edge
    features. This design is tailored to fit the nature of musical data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: MusGConv通过将绝对特征作为节点特征以及相对音乐特征作为边特征来改变标准的消息传递过程。这个设计是为了适应音乐数据的特点。
- en: 'The MusGConv convolution is defined by the following steps:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MusGConv卷积通过以下步骤定义：
- en: '**Edge Features Computation**: In MusGConv, edge features are computed as the
    difference between notes in terms of onset, duration, and pitch. Additionally,
    pitch-class intervals (distances between notes without considering the octave)
    are included, providing an reductive but effective method to quantify music intervals.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**边缘特征计算**：在 MusGConv 中，边缘特征通过音符的起始时间、持续时间和音高的差异来计算。此外，还包括音高类间隔（不考虑八度的音符间距离），提供了一种简化但有效的方法来量化音乐间隔。'
- en: '**Message Computation**: The message within the MusGConv includes the source
    node’s current feature vector but also the afformentioned edge features from the
    source to the destination node, allowing the network to leverage both absolute
    and relative information of the neighbors during message passing.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**消息计算**：MusGConv 中的消息不仅包括源节点的当前特征向量，还包括从源节点到目标节点的上述边缘特征，使得网络在消息传递过程中能够利用邻居的绝对和相对信息。'
- en: '**Aggregation and Update**: MusGConv uses sum as the aggregation function,
    however, it concatenates the current node representation with the sum of its neighbor
    messages.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚合与更新**：MusGConv 使用求和作为聚合函数，然而，它将当前节点的表示与其邻居信息的总和进行连接。'
- en: '![](../Images/8fbdc41387d6265bde062a84600ceedd.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fbdc41387d6265bde062a84600ceedd.png)'
- en: The MusGConv graph convolutional block.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: MusGConv 图卷积模块。
- en: By designing the message passing mechanism in this way, MusGConv attempts to
    preserve the relative perceptual properties of music (such as intervals and rhythms),
    leading to more meaningful representations of musical data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样设计消息传递机制，MusGConv 试图保持音乐的相对感知特性（如音程和节奏），从而产生更有意义的音乐数据表示。
- en: Should edge features are absent or deliberately not provided then MusGConv computes
    the edge features between two nodes as the absolute difference between their node
    features. The version of MusGConv with the edges features is named MusGConv(+EF)
    in the experiments.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺少边缘特征或故意不提供，则 MusGConv 计算两个节点之间的边缘特征为它们节点特征的绝对差异。带有边缘特征的 MusGConv 版本在实验中被称为
    MusGConv(+EF)。
- en: Applications and Experiments
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用与实验
- en: To demonstrate the potential of MusGConv I discuss below the tasks and the experiments
    conducted in the paper. All models independent of the task are designed with the
    pipeline shown in the figure below. When MusGConv is employed the GNN blocks are
    replaced by MusGConv blocks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示 MusGConv 的潜力，我将在下面讨论论文中进行的任务和实验。所有模型无论任务如何，都按下图所示的管道设计。当使用 MusGConv 时，GNN
    模块被 MusGConv 模块替代。
- en: 'I decided to apply MusGConv to four tasks: voice separation, composer classification,
    Roman numeral analysis, and cadence detection. Each one of these tasks presents
    a different taxonomy from a graph learning perspective. Voice separation is a
    link prediction task, composer classification is a global classification task,
    cadence detection is a node classification task, and Roman numeral analysis can
    be viewed as a subgraph classification task. Therefore we are exploring the suitability
    of MusGConv not only from a musical analysis perspective but through out the spectrum
    of graph deep learning task taxonomy.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定将 MusGConv 应用于四个任务：声音分离、作曲家分类、罗马数字分析和和弦进行检测。这些任务从图学习的角度呈现了不同的分类。声音分离是一个链路预测任务，作曲家分类是一个全局分类任务，和弦进行检测是一个节点分类任务，而罗马数字分析可以看作是一个子图分类任务。因此，我们不仅从音乐分析的角度，而且从整个图深度学习任务分类的范围来探索
    MusGConv 的适用性。
- en: '![](../Images/e30351b46580c8dd2b21e7e34d8e00f2.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e30351b46580c8dd2b21e7e34d8e00f2.png)'
- en: Example of a general graph pipeline for symbolic music understanding tasks
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一般图形管道在符号音乐理解任务中的示例
- en: Voice Separation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声音分离
- en: Voice separation is the detection of individual monophonic streams within a
    polyphonic music excerpt. Previous methods had employed GNNs to solve this task.
    From a GNN perspective, voice separation can be viewed as link prediction task,
    i.e. for every pair of notes we predict if they are connected by an edge or not.
    The product the link prediction process should be a graph where consecutive notes
    in the same voice are ought to be connected. Then voices are the connected components
    of the predicted graph. I point the readers to [this paper](https://arxiv.org/abs/2304.14848)
    for more information on voice separation using GNNs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 声音分离是从多声部音乐片段中检测出各个单声部流的方法。以往的方法采用了GNN来解决这个任务。从GNN的角度来看，声音分离可以视为一个链路预测任务，即对于每一对音符，我们预测它们是否被一条边连接。链路预测的结果应当是一个图，其中在同一声部中的连续音符应该是连接在一起的。然后，声部就是预测图的连通分量。关于使用GNN进行声音分离的更多信息，请参考[这篇论文](https://arxiv.org/abs/2304.14848)。
- en: For voice separation the pipeline of the above figure applies to the GNN encoder
    part of the architecture. The link prediction part takes place as the task specific
    module of the pipeline. To use MusGConv it is sufficient to replace the convolution
    blocks of the GNN encoder with MusGConv. This simple substitution results in more
    accurate prediction making less mistakes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于声音分离，上述图中的流程适用于架构中的GNN编码器部分。链路预测部分则作为任务特定模块进行处理。使用MusGConv时，只需将GNN编码器中的卷积块替换为MusGConv。这个简单的替换使得预测更加准确，错误更少。
- en: Since the interpretation of deep learning systems is not exactly trivial, it
    is not easy to pinpoint the reason for the improved performance. From a musical
    perspective consecutive notes in the same voice should tend to have smaller relative
    pitch difference. The design of MusGConv definitely outlines the pitch differences
    with the relative edge features. However, I would need to also say, from individual
    observations that music does not strictly follow any rules.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习系统的解释并非易事，因此很难准确指出性能提升的原因。从音乐的角度来看，同一声部中的连续音符通常具有较小的相对音高差异。MusGConv的设计确实通过相对边特征突出了音高差异。然而，我还需要补充说，从个别观察来看，音乐并不严格遵循任何规则。
- en: Composer Classification
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作曲家分类
- en: Composer classification is the process of identifying a composer based on some
    music excerpt. Previous GNN-based approaches for this task receive a score graph
    as input similarly to the pipeline shown above and then they include some global
    pooling layer that collapses the graph of the music excerpt to a vector. From
    that vector then the classification process applied where classes are the predefined
    composers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作曲家分类是根据某些音乐片段识别作曲家的过程。以前基于GNN的方法处理此任务时，类似于上面展示的流程，它们接收一个分数图作为输入，然后包含一些全局池化层，将音乐片段的图转化为一个向量。然后，从该向量进行分类处理，类别即为预定义的作曲家。
- en: Yet again, MusGConv is easy to implement by replacing the GNN convolutional
    blocks. In the experiments, using MusGConv was indeed very beneficial in solving
    this task. My intuition is that relative features in combination with the absolute
    give better insights to compositional style.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，MusGConv通过替换GNN卷积块，易于实现。在实验中，使用MusGConv确实在解决这个任务中非常有益。我的直觉是，相对特征与绝对特征相结合，能为作曲风格的组成提供更好的洞察。
- en: Roman Numeral Analysis
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 罗马数字分析
- en: Roman numeral analysis is a method for harmonic analysis where chords are represented
    as Roman numerals. The task for predicting the Roman numerals is a fairly complex
    one. Previous architectures used a mixture of GNNs and Sequential models. Additionally,
    Roman numeral analysis is a multi-task classification problem, typically a Roman
    numeral is broken down to individual simpler tasks in order to reduce the class
    vocabulary of unique Roman numerals. Finally, the graph-based architecture of
    Roman numeral analysis also includes a onset contraction layer after the graph
    convolution that transforms the graph to an ordered sequence. This onset contraction
    layer, contracts groups of notes that occur at the same time and they are assigned
    to the same label during classification. Therefore, it can be viewed as a subgraph
    classification task. I would reckon that the explication of this model would merit
    its own post, therefore, I would suggest reading [the paper](https://arxiv.org/abs/2307.03544)
    for more insights.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 罗马数字分析是一种和声分析方法，其中和弦用罗马数字表示。预测罗马数字的任务相当复杂。先前的架构使用了GNN和顺序模型的混合。此外，罗马数字分析是一个多任务分类问题，通常一个罗马数字会被分解成更简单的单独任务，以减少独特罗马数字的类别词汇量。最后，罗马数字分析的图形化架构还包括在图卷积之后的一个起始收缩层，该层将图转换为有序序列。这个起始收缩层收缩同时发生的音符组，并在分类时将它们分配到相同的标签。因此，这可以视为一个子图分类任务。我认为这个模型的解释值得单独写一篇文章，因此，我建议阅读[这篇论文](https://arxiv.org/abs/2307.03544)以获取更多见解。
- en: Nevertheless, the general graph pipeline in the figure is still applicable.
    The sequential models together with the multitask classification process and the
    onset contraction module entirely belong to the task-specific box. However, replacing
    the Graph Convolutional Blocks with MusGConv blocks does not seem to have an effect
    on this task and architecture. I attribute this to the fact that the task and
    the model architecture are simply too complex.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，图中的一般图形管道仍然适用。顺序模型与多任务分类过程以及起始收缩模块完全属于任务特定的部分。然而，用MusGConv模块替换图卷积块似乎对这个任务和架构没有影响。我将此归因于任务和模型架构本身过于复杂。
- en: Cadence Detection
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 终止式检测
- en: Finally, let’s discuss cadence detection. Detecting cadences can be viewed as
    similar to detecting phrase endings and it is an important aspect of music analysis.
    Previous methods for cadence detection employed GNNs with an encoder-decoder GNN
    architecture. Each note which by now we know that also corresponds to one node
    in the graph is classified to being a cadence note or not. The cadence detection
    task includes a lot of peculiarities such as very heavy class imbalances as well
    as annotation ambiguities. If you are interested I would again suggest to check
    out [this paper](https://arxiv.org/abs/2208.14819).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们讨论终止式检测。检测终止式可以视为与检测乐句结尾相似，它是音乐分析中的一个重要方面。之前的终止式检测方法采用了带有编码器-解码器GNN架构的GNN。每个音符，直到现在我们知道它也对应图中的一个节点，被分类为终止式音符或非终止式音符。终止式检测任务包括许多特殊情况，如非常严重的类别不平衡以及注释歧义。如果你感兴趣，我再次建议查阅[这篇论文](https://arxiv.org/abs/2208.14819)。
- en: The use of MusGConv convolution in the encoder of can be beneficial for detecting
    cadences. I believe that the combination of relative and absolute features and
    the design of MusGConv can keep track of voice leading patterns that often occur
    around cadences.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码器中使用MusGConv卷积有助于检测终止式。我认为，相对和绝对特征的结合以及MusGConv的设计能够追踪在终止式附近经常发生的声部连接模式。
- en: Results and Evaluation
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果与评估
- en: 'Extensive experiments have shown that MusGConv can outperform state-of-the-art
    models across the aforementioned music understanding tasks. The table below summarizes
    the improvements:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛的实验表明，MusGConv在上述音乐理解任务中能够超越最先进的模型。下表总结了这些改进：
- en: '![](../Images/d72d396c9948e25565c95504855c632a.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d72d396c9948e25565c95504855c632a.png)'
- en: (F1) stands for macro F1 score otherwise simple Accuracy score is shown.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: (F1)表示宏F1得分，其他情况下显示的是简单的准确率得分。
- en: However soulless a table can be, I would prefer not to fully get into any more
    details in the spirit of keeping this blog post lively and towards a discussion.
    Therefore, I invite you to check out the original [paper](https://arxiv.org/pdf/2405.09224)
    for more details on the results and datasets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，不管表格多么没有生气，我更倾向于不深入探讨更多细节，以保持这篇博客的生动性和讨论的方向。因此，我邀请你查看原始[论文](https://arxiv.org/pdf/2405.09224)，以获取有关结果和数据集的更多细节。
- en: Summary and Discussion
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结与讨论
- en: '**MusGConv** is a graph convolutional block for music. It offers a simple perception-inspired
    approach to graph convolution that results to performance improvement of GNNs
    when applied to music understanding tasks. Its simplicity is the key to its effectiveness.
    In some tasks, it is very beneficial is some others not so much. The inductive
    bias of the relative and absolute features in music is a neat trick to magically
    improve your GNN results but my advice is to always take it with a pinch of salt.
    Try out MusGConv by all means but also do not forget about all the other cool
    graph convolutional block possibilities.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**MusGConv** 是一个用于音乐的图卷积模块。它提供了一种简单的、受感知启发的图卷积方法，当应用于音乐理解任务时，能够提高 GNN（图神经网络）的表现。它的简洁性是其有效性的关键。在某些任务中，它非常有益，而在其他任务中则不那么明显。音乐中相对和绝对特征的归纳偏向是一个巧妙的技巧，可以神奇地提升你的
    GNN 结果，但我的建议是始终保持一些保留意见。尽管可以尝试 MusGConv，但也不要忘记探索其他所有有趣的图卷积模块可能性。'
- en: If you are interested in trying **MusGConv**, the code and models are available
    on [**GitHub**](https://github.com/manoskary/musgconv).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣尝试 **MusGConv**，相关代码和模型可以在 [**GitHub**](https://github.com/manoskary/musgconv)
    上找到。
- en: '**Notes and Acknowledgments**'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**备注与致谢**'
- en: All images in this post are by the author. I would like to thank Francesco Foscarin
    my co-author of the original paper for his contributions to this work.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中的所有图片均由作者提供。我想感谢我的共同作者 Francesco Foscarin，他为这项工作的贡献。
