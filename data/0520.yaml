- en: Time Series Forecasting with TensorFlow and Visualization Techniques to Perform
    Predictions Beyond the Validation Period
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow进行时间序列预测和通过可视化技术进行验证期外预测
- en: 原文：[https://towardsdatascience.com/time-series-forecasting-with-tensorflow-neural-networks-and-visualization-techniques-06ad14fd082b?source=collection_archive---------11-----------------------#2024-02-24](https://towardsdatascience.com/time-series-forecasting-with-tensorflow-neural-networks-and-visualization-techniques-06ad14fd082b?source=collection_archive---------11-----------------------#2024-02-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/time-series-forecasting-with-tensorflow-neural-networks-and-visualization-techniques-06ad14fd082b?source=collection_archive---------11-----------------------#2024-02-24](https://towardsdatascience.com/time-series-forecasting-with-tensorflow-neural-networks-and-visualization-techniques-06ad14fd082b?source=collection_archive---------11-----------------------#2024-02-24)
- en: How to Extend Your Predictions Beyond Validation Period
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何将预测扩展到验证期之外
- en: '[](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)[![Paula
    Maranon](../Images/40b163c740105e0d7506eea3335aa268.png)](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)
    [Paula Maranon](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)[![Paula
    Maranon](../Images/40b163c740105e0d7506eea3335aa268.png)](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)
    [Paula Maranon](https://medium.com/@paulamaranon?source=post_page---byline--06ad14fd082b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)
    ·8 min read·Feb 24, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--06ad14fd082b--------------------------------)
    ·阅读时长8分钟·2024年2月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/947426607d6525714baa868ba36c92e6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/947426607d6525714baa868ba36c92e6.png)'
- en: Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: In this article, I’ll guide you through the process of building time series
    models using TensorFlow, a powerful framework for constructing and training neural
    networks. I’ll show you a variety of neural network architectures for time series
    forecasting, ranging from simple models like SimpleRNN to more complex ones such
    as LSTM. Additionally, I’ll present advanced visualization techniques to I’ve
    used to make and visualize predictions beyond the validation period.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将带领你通过使用TensorFlow构建时间序列模型的过程。TensorFlow是一个强大的框架，用于构建和训练神经网络。我将展示多种用于时间序列预测的神经网络架构，从简单的模型如SimpleRNN到更复杂的模型如LSTM。此外，我还将介绍我用来进行验证期外预测的高级可视化技术。
- en: Setting up the Environment
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: 'I’ve used the following libraries: TensorFlow with Keras for building neural
    networks, Matplotlib for visualization, NumPy for numerical operations, and Scikit-Learn
    for data preprocessing.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了以下库：TensorFlow与Keras用于构建神经网络，Matplotlib用于可视化，NumPy用于数值计算，Scikit-Learn用于数据预处理。
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data Preparation
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: Data preparation is fundamental for the success of any machine learning model.
    In this section, I will perform several steps to prepare the data for training
    and validation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备对任何机器学习模型的成功至关重要。在这一部分，我将执行几个步骤，为训练和验证准备数据。
- en: Separating Data and Time Steps
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分离数据和时间步
- en: The first step is to separate the time steps from the actual data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将时间步从实际数据中分离出来。
- en: '**For Short Time Series Data (data stored in an array):** we can create an
    array of time steps using ‘np.arange()’:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于短时间序列数据（存储在数组中的数据）：**我们可以使用‘np.arange()’创建一个时间步数组：'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**For Larger Datasets Stored in Files (e.g., CSV Files):** we can read the
    data and corresponding time steps from the file:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于存储在文件中的大型数据集（例如CSV文件）：**我们可以从文件中读取数据及其对应的时间步：'
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Splitting Data into Training and Validation Sets
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据划分为训练集和验证集
- en: After obtaining the time steps and data, we split them into training and validation
    sets to train and evaluate the model’s performance.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取时间步和数据后，我们将其划分为训练集和验证集，以训练和评估模型的性能。
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Generating windowed datasets
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成窗口数据集
- en: After that, I’ve created a function to generate windowed datasets for both training
    and validation. Each window consists of a fixed number of data points. For instance,
    with a window size of 4, I use the last four data points in each window to predict
    the next one.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我创建了一个函数，用于生成用于训练和验证的窗口化数据集。每个窗口由固定数量的数据点组成。例如，使用窗口大小为 4 时，我会使用每个窗口中的最后四个数据点来预测下一个数据点。
- en: The windowed dataset produceses two-dimensional batches of windows on the data
    (batch size and timestamps).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口化的数据集生成了两维的数据批次（批次大小和时间戳）。
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After following these steps the data is properly prepared for ingestion into
    the model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在遵循这些步骤后，数据已被适当准备好以便导入模型中。
- en: Defining the Model
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义模型
- en: Keras provides many time series models that can be used for time-series forecasting.
    I’ll briefly describe some of the models I’ve used, starting with simpler structures
    and gradually increasing in complexity. It’s important to note that these structures
    are just examples. The number of units and the number of layers need to be fine-tuned
    according to the dataset being used.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 提供了许多可以用于时间序列预测的模型。我将简要描述我使用过的一些模型，从较简单的结构开始，逐渐增加复杂性。值得注意的是，这些结构仅仅是示例，单元数量和层数需要根据所使用的数据集进行微调。
- en: Simple Recurrent Neural Network
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单的递归神经网络
- en: RNNs are neural networks used for processing sequences of data while retaining
    information from earlier time steps. However, they may fail in remembering information
    over long sequences.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 是用于处理数据序列的神经网络，能够保留来自早期时间步的信息。然而，它们可能无法记住长序列中的信息。
- en: In each time step, different batches of input data are fed into the RNN cell.
    The output of the RNN cell at each time step dependS not only on the current input
    batch but also on the previous state of the cell, which captures information from
    earlier time steps.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间步，不同批次的输入数据被送入 RNN 单元。每个时间步的 RNN 单元输出不仅依赖于当前的输入批次，还依赖于单元的前一个状态，而前一个状态捕捉了早期时间步的信息。
- en: '![](../Images/bab7657e545017b31a99ad53b7947bd7.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bab7657e545017b31a99ad53b7947bd7.png)'
- en: Image from the author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Here’s a simple example of an RNN model with two recurrent layers and a final
    output layer. When using RNNs, the input data needs to be shaped because RNNs
    typically expect input data in a 3D tensor. [1]
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的 RNN 模型示例，包含两个递归层和一个最终输出层。在使用 RNN 时，输入数据需要进行调整，因为 RNN 通常期望输入数据为 3D 张量。[1]
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Long Short-Term Memory networks
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 长短期记忆网络
- en: LSTMs networks are a type of recurrent neural network known for their ability
    to retain information over multiple time steps. LSTMs achieve this by incorporating
    a memory cell that passes information from one cell to another and from one time
    step to another within the network.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 网络是一种递归神经网络，以能够在多个时间步内保留信息而闻名。LSTM 通过结合一个记忆单元，使信息能够从一个单元传递到另一个单元，并在网络内从一个时间步传递到另一个时间步来实现这一点。
- en: '![](../Images/e4eb866a9f2085b0f0ded5f9d7eec462.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4eb866a9f2085b0f0ded5f9d7eec462.png)'
- en: Image by the author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Additionally, LSTMs can be bidirectional, allowing them to analyze input data
    not only in the forward direction but also in reverse.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LSTM 可以是双向的，允许它们不仅分析输入数据的正向方向，还能分析反向方向。
- en: Here’s an example of an LSMT model with two bidirectional LSTM layers. In my
    experience, using multiple layers in LSTMs tends to outperform single-layer models
    by capturing both low-level and high-level features. [2]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个包含两个双向 LSTM 层的 LSTM 模型示例。根据我的经验，在 LSTM 中使用多个层通常比单层模型表现更好，因为它能够同时捕捉低层次和高层次的特征。[2]
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Adjusting the Learning Rate
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整学习率
- en: These architectures need to be adapted according to each dataset. However, what
    works for me is to adjust the learning rate first and then experimenting with
    other number of layers and of units.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构需要根据每个数据集进行调整。然而，适合我的方法是先调整学习率，然后再尝试其他层数和单元数的组合。
- en: 'Have a look to the code for adjusting the learning rate and the number of layers
    in this article: [Optimizing Neural Network Performance through Learning Rate
    Tuning and Hidden Layer Unit Selection](https://medium.com/@paulamaranon/optimizing-neural-network-performance-through-learning-rate-tuning-and-hidden-layer-unit-selection-ed6acc00f9a6).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看这篇文章中的代码，了解如何调整学习率和层数：[通过调整学习率和隐藏层单元选择优化神经网络性能](https://medium.com/@paulamaranon/optimizing-neural-network-performance-through-learning-rate-tuning-and-hidden-layer-unit-selection-ed6acc00f9a6)。
- en: 'Important Note: A very useful piece of advice I wish I had known a long time
    ago: apart from experimenting with different numbers of layers and units, I advise
    you to always adjust the weights while training the model. For more detailed information
    and coding, check out my article titled [Achieving Reproducibility in Neural Network
    Predictions](https://medium.com/@paulamaranon/achieving-reproducibility-in-neural-network-predictions-71bf6bfbadf6).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：我希望很久以前就知道的一个非常有用的建议：除了实验不同的层数和单元数外，我建议你在训练模型时始终调整权重。有关更多详细信息和代码，请查看我名为[Achieving
    Reproducibility in Neural Network Predictions](https://medium.com/@paulamaranon/achieving-reproducibility-in-neural-network-predictions-71bf6bfbadf6)的文章。
- en: Evaluate the model on the validation dataset
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在验证数据集上评估模型
- en: To be able to visualize the performance of the model and the predictions, let’s
    compile and train the model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够可视化模型的性能和预测结果，让我们编译并训练该模型。
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In time series forecasting, it’s common to use the Mean Squared Error (MSE)
    or the Mean Absolute Error (MAE) to validate the performance of the models. Unlike
    MSE, MAE does not square the errors but instead uses their absolute values. This
    approach does not overly penalize large errors, making it suitable for scenarios
    where all errors should be treated equally.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列预测中，通常使用均方误差（MSE）或平均绝对误差（MAE）来验证模型的性能。与MSE不同，MAE不对误差进行平方处理，而是使用误差的绝对值。这种方法不会对较大的误差进行过度惩罚，因此适用于那些需要平等对待所有误差的场景。
- en: Visualizing training and validation loss
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化训练和验证损失
- en: Let’s now create two plots showing the Loss and MAE curves over epochs for both
    training and validation data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建两个图表，展示训练和验证数据的损失（Loss）和平均绝对误差（MAE）曲线。
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This is an example of the plots which can be obtained:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是可以得到的图表示例：
- en: '![](../Images/d084eaafc808a0e2290818a0ae08743c.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d084eaafc808a0e2290818a0ae08743c.png)'
- en: Image by the author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Making Predictions on the Validation Dataset
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在验证数据集上进行预测
- en: Now that I’ve trained the model and validated its performance using MSE metric,
    it’s time to apply the model to the validation dataset to make predictions.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经训练了模型，并使用MSE指标验证了其性能，是时候将模型应用于验证数据集进行预测了。
- en: Below is the code to make predictions on the validation dataset. Additionally,
    I’ve included how to print the predictions beyond the validation period along
    the actual data for each time step.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对验证数据集进行预测的代码。此外，我还包括了如何打印验证期之外的预测结果，并将其与实际数据在每个时间步骤进行对比。
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can also visualize the predictions beyond the validation period in a plot.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在图表中可视化验证期之外的预测结果。
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is an example of an image from the code above, based on a dummy dataset.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基于虚拟数据集的示例，展示了上面代码生成的图像。
- en: '![](../Images/601fa0cb259e516bb75d316fdbfe1ed1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/601fa0cb259e516bb75d316fdbfe1ed1.png)'
- en: Image by the author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Visualizing time series data and model predictions is basic for understanding
    the performance of your model. In this article I solved a problem I faced several
    times which was how to perform and visualize time series predictions beyond the
    validation period, which may be useful for checking the model on actual data afterward.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化时间序列数据和模型预测是理解模型性能的基础。本文中，我解决了一个我曾多次遇到的问题：如何在验证期之外进行时间序列预测并可视化，这在事后检查模型在实际数据上的表现时可能很有用。
- en: Bibliography
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1]SimpleRNN:[https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN#call_arguments](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]SimpleRNN:[https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN#call_arguments](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)'
- en: '[2]LSTM:[https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]LSTM:[https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)'
