- en: Can Large Language Models (LLMs) Be Used to Label Data?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）能否用于数据标注？
- en: 原文：[https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02](https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02](https://towardsdatascience.com/can-large-language-models-llms-label-data-2a8334e70fb8?source=collection_archive---------5-----------------------#2024-04-02)
- en: A brief overview
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简要概述
- en: '[](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)[![Maja
    Pavlovic](../Images/a3b8a94c236519bc86c5c6319db5bc66.png)](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)
    [Maja Pavlovic](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)[![Maja
    Pavlovic](../Images/a3b8a94c236519bc86c5c6319db5bc66.png)](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)
    [Maja Pavlovic](https://medium.com/@majapavlo?source=post_page---byline--2a8334e70fb8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)
    ·9 min read·Apr 2, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2a8334e70fb8--------------------------------)
    ·9分钟阅读·2024年4月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article is meant to provide a simple approachable summary of studies that
    explored labelling data with LLMs[**¹**](#9b7e)**.** We will cover current views
    on annotating textual data with LLMs and also things to consider for your own
    projects.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在提供一个简单易懂的总结，概述了通过大型语言模型（LLMs）进行数据标注的研究[**¹**](#9b7e)**。** 我们将讨论目前关于使用LLMs标注文本数据的观点，并且提出一些在自己的项目中需要考虑的事项。
- en: '**Overview:**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**概述：**'
- en: '[Why even use LLMs?](#1525)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么要使用LLM？](#1525)'
- en: '[Current Views](#7740)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[当前观点](#7740)'
- en: '[Things to Consider when using LLMs as Annotators](#13fd)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用LLMs作为标注工具时需要考虑的事项](#13fd)'
- en: '[Summary | ***TL;DR***](#4a23)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[总结 | ***简而言之***](#4a23)'
- en: '![](../Images/eb85d873b755934ed4cb4b9ae8915e2d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb85d873b755934ed4cb4b9ae8915e2d.png)'
- en: 'Source: Pexels'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Pexels
- en: Why even use an LLM for labelling?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用LLM进行标注？
- en: High quality labelled data creates the foundation for training and evaluating
    machine learning models across diverse tasks. The most common approach to annotating
    datasets right now is to hire crowd-workers *(e.g. Amazon Mechanical Turk)* or
    domain experts if specialised knowledge is required.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 高质量的标注数据为训练和评估机器学习模型在不同任务中的表现奠定了基础。目前，标注数据集的最常见方法是雇佣人群工人*(例如亚马逊机械土耳其人)*，或者在需要专业知识时雇佣领域专家。
- en: These approaches can be rather expensiveand time-consuming, which is why a lot
    of people are now wondering if LLMs can handle data labelling well enough. Businesses
    with limited budgets could benefit from this by building specialised models that
    address their particular needs. In more sensitive domains like medicine, there’s
    potential to speed up the labelling process by having experts review and correct
    LLM labels rather than starting from scratch.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法通常既昂贵又耗时，这也是为什么许多人现在在思考LLMs是否足够胜任数据标注的原因。预算有限的企业可以通过构建专门的模型来满足其特定需求，从中受益。在医疗等敏感领域，通过让专家审核和修正LLM标签，而不是从零开始，可能有助于加速标注过程。
- en: Additionally, researchers at Carnegie Mellon & Google find that people are motivated
    by the possibility of protecting human annotators from psychological harm caused
    during the labelling process *(e.g hate-speech)* as well as the diversification
    of opinions in the data*.*
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，卡内基梅隆大学和谷歌的研究人员发现，人们受到保护人工标注者免受标注过程中可能造成的心理伤害*(例如仇恨言论)*以及数据中观点多样性的动机，可能有助于推动这一领域的发展。
- en: Current views across different studies
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 各个研究中的当前观点
- en: Opinions are somewhat split amongst studies regarding the potential of LLMs
    as annotators. While some studies are optimistic about their capabilities, others
    remain sceptical. Table 1 provides an overview of the approach and results from
    twelve studies. You can find the source of these studies in the References *(see
    end of this article)*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 关于LLMs作为注释员的潜力，研究之间的意见有所分歧。尽管一些研究对其能力持乐观态度，但也有其他研究仍然保持怀疑。表1提供了来自12项研究的方法和结果概述。您可以在参考文献中找到这些研究的来源（*见本文末尾*）。
- en: '![](../Images/79bc9b2ff8ff92d0ee358b024f25a71f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79bc9b2ff8ff92d0ee358b024f25a71f.png)'
- en: '**Table 1** — z: zero-shot, f: few-shot, z&f: zero&few-shot; en+: predominantly
    English | image by author'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1** — z:零样本，f:少样本，z&f:零样本&少样本；en+:主要为英语 | 图片由作者提供'
- en: Model[²](#a37b)
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Model[²](#a37b)
- en: The **Number of Model Families** highlights that most of the studies only test
    one model family and when we look at which model they used, we can see that almost
    all except for 2 studies **used GPT**. Study [7] is the only one which solely
    focuses on the exploration of open-source LLMs (Table 2).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型家族的数量**突出了大多数研究仅测试一个模型家族，且当我们查看它们使用了哪些模型时，可以看到几乎所有的研究（除了2项）**都使用了GPT**。研究[7]是唯一专注于探索开源LLM的研究（表2）。'
- en: '![](../Images/3fff610c6de85ad358c8b378fca9f6ff.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fff610c6de85ad358c8b378fca9f6ff.png)'
- en: '**Table 2** | image by author'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**表2** | 图片由作者提供'
- en: Datasets
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: The third column of [Table 1](#4ca9) contains the **Number of Datasets** that
    were used for labelling purposes. The different studies explore different tasks
    and thereby also a variety of datasets. Most explore the performance on more than
    one dataset. Study [3] stands out by testing LLM classification performance across
    20 different datasets. More details on which datasets were used are shown in Table
    3 below, and could help youspot the studies most relevant to you.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[表1](#4ca9)的第三列包含了用于标注目的的**数据集数量**。不同的研究探索了不同的任务，从而也涉及了多种数据集。大多数研究探索了多个数据集上的表现。研究[3]特别突出，因为它测试了LLM在20个不同数据集上的分类性能。更多关于使用了哪些数据集的详细信息请见下方的表3，这可以帮助您找到与您最相关的研究。'
- en: '![](../Images/03cdf5b34f7dda8b4d5fe27aa3809e46.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03cdf5b34f7dda8b4d5fe27aa3809e46.png)'
- en: '**Table 3** | image by author'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**表3** | 图片由作者提供'
- en: '**If you’re starting out with no labelled data at hand:** Have a look at existing
    **labelled** datasets for tasks that are similar to your own use case and label
    the data with an LLM. Compare the LLM generated labels with the human labels by
    investigating the errors and potential issues in detail. This should give you
    an indication of how well the LLM will perform on your task and whether the time
    & cost savinngs can be justified.'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**如果您手头没有标注数据：** 请查看现有的**标注**数据集，选择与您的任务相似的任务，并使用LLM对数据进行标注。通过详细检查错误和潜在问题，将LLM生成的标签与人工标签进行对比。这将帮助您了解LLM在您的任务中表现如何，以及时间和成本节省是否能够得到合理的证明。'
- en: Perspectivist Approach
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观点主义方法
- en: 'A **Perspectivist Approach** simply means recognising that there is no one
    “right” way to understand a dataset or solve a problem. Different perspectives
    can reveal different insights or solutions. Whereas traditionally, most datasets
    are labelled using a majority voting approach, meaning that the most commonly
    chosen label is viewed as the ground truth:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**观点主义方法**意味着认识到理解数据集或解决问题没有唯一的“正确”方式。不同的视角可以揭示不同的见解或解决方案。与此相对，传统上，大多数数据集是使用多数投票方法进行标注的，即视为“地面真相”的是最常被选择的标签：'
- en: '![](../Images/134e765061c32993d940b03ea01b0776.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/134e765061c32993d940b03ea01b0776.png)'
- en: Majority Voting Vs. Perspectivist Approach | image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 多数投票与观点主义方法 | 图片由作者提供
- en: In [Table 1](#4ca9), the labelling approach is categorised based on whether
    the study uses a majority voting or perspectivist mindset. We can see that most
    of the studies take a majority voting approach towards their labelling efforts.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表1](#4ca9)中，标注方法根据研究是否使用多数投票或观点主义思维方式进行分类。我们可以看到，大多数研究在标注工作中采取了多数投票方法。
- en: LLM as Annotator?
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM作为注释员？
- en: The last column summarises each study’s findings, with a check-mark indicating
    a tendency towards believing that LLMs can be helpful in the annotation process.
    While some are quite optimistic about their potential and suggest the replacement
    of human annotators, others see them more as a support tool rather than a substitute
    for humans. Regardless, even amongst these studies with a positive outlook, there
    are *some tasks* on which LLMs don’t perform well enough.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一列总结了每项研究的发现，勾选的标记表示倾向于认为LLM在标注过程中可以发挥作用。虽然有些人对其潜力相当乐观，建议替代人工标注员，但也有一些人认为它们更像是一种支持工具，而非人类的替代品。无论如何，即使是在这些对LLM持积极态度的研究中，仍有*某些任务*是LLM表现不佳的。
- en: Additionally, three studies, two of which follow the perspectivist approach,
    conclude that they are not suited for labelling data. Another study *(not included
    in the table)* takes a different approach and shows that the current method of
    aligning LLMs via a single reward function doesn’t capture the diversity of preferences
    among different human subgroups, especially minority views.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，三项研究中有两项采用视角主义方法，得出的结论是它们不适合用于数据标注。另有一项研究（*未包含在表格中*）采用了不同的方法，并显示当前通过单一奖励函数对大语言模型（LLM）进行对齐的方式并未能捕捉到不同人类子群体之间的偏好差异，尤其是少数群体的观点。
- en: Things to Consider when Using LLMs as Annotators
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLM作为标注者时需要考虑的事项
- en: 'Prompting: Zero vs. Few-shot'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示：零样本与少样本
- en: 'Obtaining meaningful responses from LLMs can be a bit of a challenge. How do
    you then best prompt an LLM to label your data? As we can see from [Table 1](#4ca9),
    the above studies explored either zero-shot or few-shot prompting, or both. **Zero-shot**
    prompting expects an answer from the LLM without having seen any examples in the
    prompt. Whereas **few-shot** prompting includes multiple examples in the prompt
    itself so that the LLM knows what a desired response looks like:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从大语言模型（LLM）中获得有意义的回答可能会有些挑战。那么，如何最佳地提示一个LLM来标注数据呢？正如我们从[表格 1](#4ca9)中看到的，上述研究探讨了零样本提示、少样本提示或两者结合的方式。**零样本**提示是在没有提供任何示例的情况下期望LLM给出答案。而**少样本**提示则在提示中包含多个示例，使LLM知道期望的回答是什么样子的：
- en: '![](../Images/37392df9567b3466d7f3ec16c74c5dea.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37392df9567b3466d7f3ec16c74c5dea.png)'
- en: Zero Vs Few-Shot Prompting | [source of example (amitsangani)](https://github.com/amitsangani/Llama-2/blob/main/Building_Using_Llama.ipynb)
    | image by author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本与少样本提示 | [示例来源 (amitsangani)](https://github.com/amitsangani/Llama-2/blob/main/Building_Using_Llama.ipynb)
    | 图片由作者提供
- en: The studies differ in their views on which approach returns better results.
    Some resort to few-shot prompting on their tasks, others to zero-shot prompting.
    So you might want to explore what works best for your particular use case and
    model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 各项研究在关于哪种方法能获得更好结果的问题上存在分歧。有些在他们的任务中使用了少样本提示，另一些则使用了零样本提示。因此，你可能需要探索哪种方法最适合你的特定用例和模型。
- en: If you are wondering how to even start with good prompting [Sander Schulhoff](https://medium.com/u/94d7839def70?source=post_page---user_mention--2a8334e70fb8--------------------------------)
    & [Shyamal H Anadkat](https://medium.com/u/e3a305374f9a?source=post_page---user_mention--2a8334e70fb8--------------------------------)
    have created [**LearnPrompting**](https://learn-prompting.webflow.io/testimonials)
    which can help you with basics and also more advanced techniques.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你还在想如何开始进行有效的提示，[Sander Schulhoff](https://medium.com/u/94d7839def70?source=post_page---user_mention--2a8334e70fb8--------------------------------)
    和 [Shyamal H Anadkat](https://medium.com/u/e3a305374f9a?source=post_page---user_mention--2a8334e70fb8--------------------------------)创建了[**LearnPrompting**](https://learn-prompting.webflow.io/testimonials)，它可以帮助你掌握基础知识，也能教你一些更高级的技巧。
- en: 'Prompting: Sensitivity'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示：敏感性
- en: LLMs are sensitive to minor modifications in the prompt. Changing one word of
    your prompt can affect the response. If you want to account for that variability
    to some degree you could approach it as in study [3]. First, they let a task expert
    provide the initial prompt. Then, using GPT, they generate 4 more with similar
    meaning and average the results over all 5 prompts. Or you could also explore
    moving away from hand-written prompts and try replacing them with [signatures](/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9#7029)
    leaving it to [DSPy](/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9)
    to optimise the prompt for you as shown in [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--2a8334e70fb8--------------------------------)’s
    blog post.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs对提示的微小修改非常敏感。改变提示中的一个单词可能会影响回应。如果你希望在某种程度上考虑这种变化，可以参考研究[3]中的方法。首先，让任务专家提供初始提示。然后，使用GPT生成4个具有相似意义的提示，并对这5个提示的结果进行平均。或者，你也可以尝试远离手写提示，替换为[签名](/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9#7029)，由[DSPy](/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9)来优化提示，正如[Leonie
    Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page---user_mention--2a8334e70fb8--------------------------------)的博客文章中所示。
- en: Model Choice
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型选择
- en: '![](../Images/47c78f3eb88071c5102e84d4fb571100.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47c78f3eb88071c5102e84d4fb571100.png)'
- en: 'Which model should you choose for labelling your dataset? There are a few factors
    to consider. Let’s briefly touch on some key considerations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该选择哪个模型来标注你的数据集？这里有几个因素需要考虑。我们简要讨论一些关键的考量点：
- en: '**Open Source vs. Closed Source:** Do you go for the latest best performing
    model? Or is open-source customisation more important to you? You’ll need to think
    about things such as your budget, performance requirements, customization and
    ownership preferences, security needs, and community support requirements.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源与闭源：** 你是选择最新的、表现最好的模型吗？还是更重视开源定制？你需要考虑预算、性能要求、定制和拥有权偏好、安全需求以及社区支持需求等因素。'
- en: '**Guardrails:** LLMs have guardrails in place to prevent them from responding
    with undesirable or harmful content. If your task involves sensitive content,
    models might refuse to label your data. Also, LLMs vary in the strength of their
    safeguards, so you should explore and compare them to find the most suitable one
    for your task.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全防护：** LLMs内置了安全防护机制，以防止它们生成不良或有害内容。如果你的任务涉及敏感内容，模型可能会拒绝标注你的数据。此外，LLMs在安全防护的强度上有所不同，因此你应该进行探索和比较，以找到最适合你任务的模型。'
- en: '**Model Size:** LLMs come in different sizes and bigger models might perform
    better but they also require more compute resources. If you prefer to use open-source
    LLMs and have limited compute, you could consider [quantisation](/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34).
    In the case of closed-source models, the larger models currently have higher costs
    per prompt associated with them. But is bigger always better?'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型大小：** LLMs有不同的规模，更大的模型可能表现更好，但也需要更多的计算资源。如果你倾向于使用开源LLMs且计算资源有限，可以考虑[量化](/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34)。对于封闭源模型，目前较大的模型每次提示的费用更高。但更大就一定更好吗？'
- en: Model Bias
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型偏见
- en: According to study [3] larger, instruction-tuned[**³**](#30fc) models show superior
    labelling performance. However, the study doesn’t evaluate bias in their results.
    Another research effort shows that bias tends to increase with both scale and
    ambiguous contexts. Several studies also warn about left-leaning tendencies and
    the limited capability to accurately represent the opinions of minority groups
    (e.g. older individuals or underrepresented religions). All in all, current LLMs
    show considerable cultural biases and respond with stereotyped views of minority
    individuals. Depending on your task and its aims, these are things to consider
    across every timeline in your project.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 根据研究[3]，较大的、经过指令调优的[**³**](#30fc)模型在标注表现上更为出色。然而，研究并未评估其结果中的偏见。另一项研究表明，偏见随着规模的增大和模糊上下文的增加而增加。多项研究也警告，模型可能存在偏左倾向，并且在准确表达少数群体（例如老年人或代表性不足的宗教群体）的观点时能力有限。总的来说，当前的大型语言模型（LLMs）展示了显著的文化偏见，并且回应通常带有对少数群体的刻板印象。根据你的任务及其目标，这些都是在项目的每个阶段需要考虑的因素。
- en: '![](../Images/73ffb7e66f0c8310862a2da6c31096c1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73ffb7e66f0c8310862a2da6c31096c1.png)'
- en: “By default, LLM responses tend to be more similar to the opinions of certain
    populations, such as those from the USA, and some European and South American
    countries” *— quote from study [2]*
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “默认情况下，LLM的回答往往更接近某些人群的观点，例如来自美国以及一些欧洲和南美国家的观点” *——摘自研究[2]*
- en: 'Model Parameter: Temperature'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型参数：温度
- en: A commonly mentioned parameter across most studies in [Table 1](#4ca9) is the
    temperature parameter, which adjusts the *“creativity”* of the LLMs outputs. Studies
    [5] and [6] experiment with both higher and lower temperatures, and find that
    LLMs have higher consistency in responses with lower temperatures without sacrificing
    accuracy; therefore they recommend ***lower values for annotation tasks***.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在[表格 1](#4ca9)中的大多数研究中，常提到的一个参数是温度参数，它调整LLMs输出的*“创造性”*。研究[5]和[6]实验了较高和较低的温度，发现LLMs在较低温度下的回答一致性更高，并且没有牺牲准确性；因此，他们建议***在标注任务中使用较低值***。
- en: Language Limitations
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言限制
- en: 'As we can see in [Table 1](#4ca9), most of the studies measure the LLMs labelling
    performance on English datasets. Study [7] explores French, Dutch and English
    tasks and sees a considerable decline in performance with the non-English languages.
    Currently, **LLMs perform better in English**, but alternatives are underway to
    extend their benefits to non-English users. Two such initiatives include: YugoGPT
    *(for Serbian, Croatian, Bosnian, Montenegrin)* by [Aleksa Gordić](https://medium.com/u/37f02ae83e8c?source=post_page---user_mention--2a8334e70fb8--------------------------------)
    & Aya (101 different languages) by [*Cohere for AI*](https://cohere.com/research/aya)*.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[表格 1](#4ca9)中看到的，大多数研究测量了LLMs在英语数据集上的标注表现。研究[7]探讨了法语、荷兰语和英语任务，发现非英语语言的表现显著下降。目前，**LLMs在英语中表现更好**，但正在进行替代方案的研究，以将其好处扩展到非英语用户。其中两个项目包括：由[阿列克萨·戈尔季奇](https://medium.com/u/37f02ae83e8c?source=post_page---user_mention--2a8334e70fb8--------------------------------)发起的YugoGPT（适用于塞尔维亚语、克罗地亚语、波斯尼亚语、黑山语）和由[*Cohere
    for AI*](https://cohere.com/research/aya)*.*发起的Aya（支持101种不同语言）。
- en: Human Reasoning & Behaviour (Natural Language Explanations)
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人类推理与行为（自然语言解释）
- en: Apart from simply requesting a label from the LLM, we can also ask it to provide
    an explanation for the chosen label. One of the studies [10] finds that GPT returns
    explanations that are comparable, if not more clear than those produced by humans.
    However, we also have researchers from Carnegie Mellon & Google highlighting that
    LLMs are not yet capable of [simulating human decision making](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#9e13)
    and don’t show [human-like behavior](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#fb0c)
    in their choices. They find that instruction-tuned models show even less human-like
    behaviour and say that LLMs should not be used to substitute humans in the annotation
    pipeline. I would also caution the use of natural language explanations at this
    stage in time.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单地要求LLM提供标签外，我们还可以要求它提供所选标签的解释。研究[10]发现，GPT返回的解释与人类提供的解释相当，甚至可能更清晰。然而，卡内基梅隆大学和谷歌的研究人员也指出，LLMs目前尚不能[模拟人类决策](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#9e13)，也没有表现出[类似人类的行为](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86#fb0c)。他们发现，经过指令调优的模型表现出更少的人类行为，并表示LLMs不应被用来替代人类在标注流程中的作用。我也建议在这个阶段谨慎使用自然语言解释。
- en: '“Substitution undermines three values: the representation of participants’
    interests; participants’ inclusion and empowerment in the development process”
    *— quote from Agnew (2023)*'
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “替代削弱了三个价值：参与者利益的代表性；参与者在开发过程中的包容性和赋权” *——摘自阿格纽（2023）*
- en: Summary | TL;DR
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要 | TL;DR
- en: '![](../Images/484758ee333481ef8e1fb3568793d07c.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/484758ee333481ef8e1fb3568793d07c.png)'
- en: Benefits & Drawbacks | image by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 优势与劣势 | 作者提供的图片
- en: LLMs can be an option for those with limited budgetsand relatively objective
    tasks, where you care about the most likely label. Be careful with subjective
    tasks where opinions about the correct label might differ considerably!
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于预算有限且任务相对客观的情况，LLMs可能是一个选择，在这些任务中，你关心的是最可能的标签。对于那些关于正确标签的意见可能有很大分歧的主观任务要小心！
- en: Avoid using LLMs to simulate human reasoning and behaviour.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免使用LLMs来模拟人类推理和行为。
- en: For more critical tasks *(e.g. healthcare)* you could use LLMs to speed up the
    labelling process by having humans correct the labelled data; but don’t remove
    humans from the labelling process entirely!
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于更关键的任务（*例如医疗健康*），你可以使用LLM来加速标注过程，通过让人类修正已标注的数据；但不要完全去除人类在标注过程中的角色！
- en: Evaluate your results critically for biases & other problems and consider if
    the cost of the errors are worth the trouble they might cause.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批判性地评估你的结果，识别偏见和其他问题，并考虑错误的代价是否值得他们可能带来的麻烦。
- en: This review is by no means an exhaustive comparison. If you have [other sources](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86)
    that can contribute to the discussion or personal experience with LLM data labelling,
    please do share in the comments.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本评论绝不是一个详尽的比较。如果你有[其他来源](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86)可以为讨论提供贡献，或者有关于LLM数据标注的个人经验，请在评论中分享。
- en: '**References**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: 'If you want to look at the studies and other resources individually here is
    a list of all the papers used to create this blog post: [**Blog References**](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86)**.**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想单独查看这些研究和其他资源，这里有一个列出所有用于创建此博客文章的论文的清单：[**博客参考文献**](https://medium.com/@majapavlo/references-for-llms-as-annotators-1c2886b50b86)**。**
- en: If you want more insights on *Table 1 and the studies*, here is the [*link to
    NLPerspectives workshop paper*](https://aclanthology.org/2024.nlperspectives-1.11.pdf)
    from LREC-COLING
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想获得更多关于*表1和研究*的见解，以下是[LREC-COLING的[*NLPerspectives工作坊论文*](https://aclanthology.org/2024.nlperspectives-1.11.pdf)]的链接
- en: '*Footnotes*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*脚注*'
- en: '**¹***This is not a comprehensive review on all the literature out there but
    covers only papers I found whilst doing reading on this topic. Additionally, my
    focus was mostly on classification tasks.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**¹***这不是一篇关于所有文献的全面综述，而只覆盖了我在进行该主题阅读时找到的论文。此外，我的重点主要是分类任务。*'
- en: '**²***Given the pace of development in LLMs, there are now a lot more powerful
    models available compared to the ones tested in these studies.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**²***鉴于LLM发展的速度，现在有比这些研究中测试的模型更强大的模型可用。*'
- en: '**³***Instruction-tuned models are trained with a focus on understanding and
    generating accurate and coherent responses based on given instructions/prompts.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**³***指令调优模型是通过关注理解和生成基于给定指令/提示的准确且连贯的回应进行训练的。*'
