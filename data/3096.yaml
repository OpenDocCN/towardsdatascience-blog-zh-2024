- en: How to Build a Graph RAG App
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建一个Graph RAG应用
- en: 原文：[https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=collection_archive---------0-----------------------#2024-12-30](https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=collection_archive---------0-----------------------#2024-12-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=collection_archive---------0-----------------------#2024-12-30](https://towardsdatascience.com/how-to-build-a-graph-rag-app-b323fc33ba06?source=collection_archive---------0-----------------------#2024-12-30)
- en: '![](../Images/9b638603daca1683e032a6df6bef86ee.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b638603daca1683e032a6df6bef86ee.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Using knowledge graphs and AI to retrieve, filter, and summarize medical journal
    articles
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用知识图谱和人工智能检索、筛选和总结医学期刊文章
- en: '[](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)[![Steve
    Hedden](../Images/af7bec4a191ab857eccd885dd89e88b4.png)](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)
    [Steve Hedden](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)[![Steve
    Hedden](../Images/af7bec4a191ab857eccd885dd89e88b4.png)](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)
    [Steve Hedden](https://stevehedden.medium.com/?source=post_page---byline--b323fc33ba06--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)
    ·25 min read·6 days ago
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b323fc33ba06--------------------------------)
    ·阅读时间：25分钟·6天前
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*The accompanying code for the app and notebook are* [*here.*](https://github.com/SteveHedden/kg_llm/tree/main/graphRAGapp)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*该应用和笔记本的附带代码* [*在这里。*](https://github.com/SteveHedden/kg_llm/tree/main/graphRAGapp)'
- en: Knowledge graphs (KGs) and Large Language Models (LLMs) are a match made in
    heaven. My [previous](https://medium.com/towards-data-science/how-to-implement-knowledge-graphs-and-large-language-models-llms-together-at-the-enterprise-level-cf2835475c47)
    [posts](https://medium.com/towards-data-science/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759)
    discuss the complementarities of these two technologies in more detail but the
    short version is, “some of the main weaknesses of LLMs, that they are black-box
    models and struggle with factual knowledge, are some of KGs’ greatest strengths.
    KGs are, essentially, collections of facts, and they are fully interpretable.”
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱（KGs）和大型语言模型（LLMs）是天作之合。我在[之前的文章](https://medium.com/towards-data-science/how-to-implement-knowledge-graphs-and-large-language-models-llms-together-at-the-enterprise-level-cf2835475c47)和[另一篇文章](https://medium.com/towards-data-science/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759)中更详细地讨论了这两种技术的互补性，简而言之就是，“LLMs的主要弱点之一是它们是黑箱模型，且在事实知识方面存在困难，而这正是知识图谱的优势。知识图谱本质上是事实的集合，并且它们是完全可解释的。”
- en: This article is all about building a simple Graph RAG app. What is RAG? RAG,
    or Retrieval-Augmented Generation, is about **retrieving** relevant information
    to **augment** a prompt that is sent to an LLM, which **generates** a response.
    Graph RAG is RAG that uses a knowledge graph as part of the retrieval portion.
    If you’ve never heard of Graph RAG, or want a refresher, I’d watch [this video](https://www.youtube.com/watch?v=knDDGYHnnSI).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文全部内容是关于构建一个简单的Graph RAG应用。那么，什么是RAG呢？RAG，或者说检索增强生成（Retrieval-Augmented Generation），是通过**检索**相关信息来**增强**发送给LLM的提示，从而**生成**响应。Graph
    RAG是将知识图谱作为检索部分的一部分的RAG。如果你从未听说过Graph RAG，或者想复习一下，我建议观看[这个视频](https://www.youtube.com/watch?v=knDDGYHnnSI)。
- en: The basic idea is that, rather than sending your prompt directly to an LLM,
    which was not trained on your data, you can supplement your prompt with the relevant
    information needed for the LLM to answer your prompt accurately. The example I
    use often is copying a job description and my resume into ChatGPT to write a cover
    letter. The LLM is able to provide a much more relevant response to my prompt,
    ‘write me a cover letter,’ if I give it my resume and the description of the job
    I am applying for. Since knowledge graphs are built to store knowledge, they are
    a perfect way to store internal data and supplement LLM prompts with additional
    context, improving the accuracy and contextual understanding of the responses.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的想法是，与其将提示直接发送给没有经过您数据训练的LLM，不如用相关信息补充您的提示，以便LLM能够准确回答您的问题。我常用的一个例子是将职位描述和我的简历复制到ChatGPT中，以撰写求职信。如果我给它我的简历和我申请的职位描述，那么LLM能够为我的提示“写一封求职信”提供一个更加相关的回应。由于知识图谱是用来存储知识的，它们是存储内部数据并通过额外的上下文补充LLM提示的完美方式，从而提高响应的准确性和上下文理解能力。
- en: This technology has many, many, applications such [customer service bots](https://arxiv.org/pdf/2404.17723),
    [drug](https://academic.oup.com/bioinformatics/article/40/6/btae353/7687047) [discovery](https://blog.biostrand.ai/integrating-knowledge-graphs-and-large-language-models-for-next-generation-drug-discovery),
    [automated regulatory report generation in life sciences](https://www.weave.bio/),
    [talent acquisition and management for HR](https://beamery.com/resources/news/beamery-announces-talentgpt-the-world-s-first-generative-ai-for-hr),
    [legal research and writing](https://legal.thomsonreuters.com/blog/retrieval-augmented-generation-in-legal-tech/),
    and [wealth advisor assistants](https://www.cnbc.com/amp/2023/03/14/morgan-stanley-testing-openai-powered-chatbot-for-its-financial-advisors.html).
    Because of the wide applicability and the potential to improve the performance
    of LLM tools, Graph RAG (that’s the term I’ll use here) has been blowing up in
    popularity. Here is a graph showing interest over time based on Google searches.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术有许多应用，如[客户服务机器人](https://arxiv.org/pdf/2404.17723)、[药物](https://academic.oup.com/bioinformatics/article/40/6/btae353/7687047)
    [发现](https://blog.biostrand.ai/integrating-knowledge-graphs-and-large-language-models-for-next-generation-drug-discovery)、[生命科学中的自动化监管报告生成](https://www.weave.bio/)、[HR的人才招聘和管理](https://beamery.com/resources/news/beamery-announces-talentgpt-the-world-s-first-generative-ai-for-hr)、[法律研究与写作](https://legal.thomsonreuters.com/blog/retrieval-augmented-generation-in-legal-tech/)以及[财富顾问助手](https://www.cnbc.com/amp/2023/03/14/morgan-stanley-testing-openai-powered-chatbot-for-its-financial-advisors.html)。由于其广泛的适用性以及提升LLM工具性能的潜力，Graph
    RAG（这是我在这里使用的术语）在受欢迎度上呈现爆炸式增长。以下是一个基于Google搜索的图表，展示了这一趋势。
- en: '![](../Images/ad71566165f3051525068ae4b36fe3b9.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad71566165f3051525068ae4b36fe3b9.png)'
- en: 'Source: [https://trends.google.com/](https://trends.google.com/)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://trends.google.com/](https://trends.google.com/)
- en: Graph RAG has experienced a surge in search interest, even surpassing terms
    like knowledge graphs and retrieval-augmented generation. Note that Google Trends
    measures *relative* search interest, not absolute number of searches. The spike
    in July 2024 for searches of Graph RAG coincides with the week Microsoft [announced](https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/)
    that their GraphRAG application would be available on [GitHub](https://github.com/microsoft/graphrag).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Graph RAG的搜索兴趣激增，甚至超越了“知识图谱”和“检索增强生成”这样的术语。请注意，Google Trends衡量的是*相对*的搜索兴趣，而不是搜索的绝对数量。2024年7月Graph
    RAG搜索量的激增与微软[宣布](https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/)其GraphRAG应用将在[GitHub](https://github.com/microsoft/graphrag)上线的那一周恰好重合。
- en: The excitement around Graph RAG is broader than just Microsoft, however. Samsung
    acquired RDFox, a knowledge graph company, in July of 2024\. The [article announcing
    that acquisition](https://news.samsung.com/global/samsung-electronics-announces-acquisition-of-oxford-semantic-technologies-uk-based-knowledge-graph-startup)
    did not mention Graph RAG explicitly, but in [this article in Forbes](https://www.forbes.com/sites/zakdoffman/2024/11/09/samsung-confirms-new-upgrade-choice-millions-of-galaxy-owners-must-now-decide/)
    published in November 2024, a Samsung spokesperson stated, “We plan to develop
    knowledge graph technology, one of the main technologies of personalized AI, and
    organically connect with generated AI to support user-specific services.”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，围绕Graph RAG的兴奋并不仅仅限于微软。三星在2024年7月收购了知识图谱公司RDFox。该[收购公告文章](https://news.samsung.com/global/samsung-electronics-announces-acquisition-of-oxford-semantic-technologies-uk-based-knowledge-graph-startup)并未明确提到Graph
    RAG，但在2024年11月发表的[《福布斯》文章](https://www.forbes.com/sites/zakdoffman/2024/11/09/samsung-confirms-new-upgrade-choice-millions-of-galaxy-owners-must-now-decide/)中，一位三星发言人表示：“我们计划开发知识图谱技术，作为个性化AI的核心技术之一，并与生成式AI有机结合，以支持面向用户的服务。”
- en: In October 2024, Ontotext, a leading graph database company, and Semantic Web
    company, the maker of PoolParty, a knowledge graph curation platform, merged to
    form [Graphwise](https://graphwise.ai/). According to [the press release](https://www.prnewswire.com/news-releases/semantic-web-company-and-ontotext-merge-to-create-knowledge-graph-and-ai-powerhouse-graphwise-302283427.html?utm_source=chatgpt.com),
    the merger aims to “democratize the evolution of Graph RAG as a category.”
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年10月，领先的图数据库公司Ontotext与语义网公司Semantic Web公司合并，成立了[Graphwise](https://graphwise.ai/)。根据[新闻稿](https://www.prnewswire.com/news-releases/semantic-web-company-and-ontotext-merge-to-create-knowledge-graph-and-ai-powerhouse-graphwise-302283427.html?utm_source=chatgpt.com)，此次合并的目标是“使图谱RAG作为一个类别的演进更加普及”。
- en: While some of the buzz around Graph RAG may come from the broader excitement
    surrounding chatbots and generative AI, it reflects a genuine evolution in how
    knowledge graphs are being applied to solve complex, real-world problems. One
    example is that LinkedIn [applied Graph RAG](https://arxiv.org/pdf/2404.17723)
    to improve their customer service technical support. Because the tool was able
    to retrieve the relevant data (like previously solved similar tickets or questions)
    to feed the LLM, the responses were more accurate and the mean resolution time
    dropped from 40 hours to 15 hours.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管围绕Graph RAG的一些热议可能源于人们对聊天机器人和生成式AI的广泛兴奋，但它反映了知识图谱在解决复杂的现实问题方面的真正演进。一个例子是LinkedIn
    [应用了Graph RAG](https://arxiv.org/pdf/2404.17723)来改善其客户服务技术支持。由于该工具能够检索相关数据（如先前解决的类似工单或问题）供LLM使用，回答更加准确，平均解决时间从40小时减少到了15小时。
- en: This post will go through the construction of a pretty simple, but I think illustrative,
    example of how Graph RAG can work in practice. The end result is an app that a
    non-technical user can interact with. Like my last post, I will use a dataset
    consisting of medical journal articles from PubMed. The idea is that this is an
    app that someone in the medical field could use to do literature review. The same
    principles can be applied to many use cases however, which is why Graph RAG is
    so exciting.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将通过构建一个相当简单，但我认为具有代表性的例子，展示Graph RAG如何在实践中工作。最终结果是一个非技术用户可以交互的应用程序。像我上一篇文章一样，我将使用由PubMed的医学期刊文章组成的数据集。这个应用程序的目的是让医学领域的人可以用来进行文献综述。然而，同样的原则也可以应用于许多其他用例，这就是Graph
    RAG如此令人兴奋的原因。
- en: 'The structure of the app, along with this post is as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序的结构，以及本文的内容如下：
- en: 'Step zero is preparing the data. I will explain the details below but the overall
    goal is to vectorize the raw data and, separately, turn it into an RDF graph.
    As long as we keep URIs tied to the articles before we vectorize, we can navigate
    across a graph of articles and a vector space of articles. Then, we can:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第零步是准备数据。下面我将详细解释，但总体目标是将原始数据向量化，并单独将其转化为RDF图谱。只要在向量化之前我们保持与文章的URI关联，我们就可以在文章图谱和文章向量空间之间进行导航。然后，我们可以：
- en: '**Search Articles:** use the power of the vector database to do an initial
    search of relevant articles given a search term. I will use vector similarity
    to retrieve articles with the most similar vectors to that of the search term.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**搜索文章：**利用向量数据库的强大功能，根据搜索词初步搜索相关的文章。我将使用向量相似度来检索与搜索词最相似的文章。'
- en: '**Refine Terms:** explore the [Medical Subject Headings (MeSH) biomedical vocabulary](https://id.nlm.nih.gov/mesh/)
    to select terms to use to filter the articles from step 1\. This controlled vocabulary
    contains medical terms, alternative names, narrower concepts, and many other properties
    and relationships.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**细化术语：** 探索[医学主题词（MeSH）生物医学词汇表](https://id.nlm.nih.gov/mesh/)以选择用于过滤步骤1中文章的术语。这个控制词汇表包含医学术语、替代名称、更窄的概念以及许多其他属性和关系。'
- en: '**Filter & Summarize:** use the MeSH terms to filter the articles to avoid
    ‘context poisoning’. Then send the remaining articles to an LLM along with an
    additional prompt like, “summarize in bullets.”'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**过滤与总结：** 使用MeSH术语来过滤文章，以避免“上下文污染”。然后将剩余的文章与附加提示一起发送给LLM，比如：“用要点总结。”'
- en: 'Some notes on this app and tutorial before we get started:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，有一些关于此应用和教程的说明：
- en: This set-up uses knowledge graphs exclusively for metadata. This is only possible
    because each article in my dataset has already been tagged with terms that are
    part of a rich controlled vocabulary. I am using the graph for structure and semantics
    and the vector database for similarity-based retrieval, ensuring each technology
    is used for what it does best. Vector similarity can tell us “esophageal cancer”
    is semantically similar to “mouth cancer”, but knowledge graphs can tell us the
    details of the relationship between “esophageal cancer” and “mouth cancer.”
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个设置仅使用知识图谱来处理元数据。这之所以可行，是因为我数据集中的每篇文章已经被标注上了属于丰富控制词汇的术语。我使用图谱来处理结构和语义，使用向量数据库来进行基于相似度的检索，确保每项技术都用于它最擅长的领域。向量相似度可以告诉我们“食管癌”与“口腔癌”在语义上相似，但知识图谱可以告诉我们“食管癌”和“口腔癌”之间关系的详细信息。
- en: The data I used for this app is a collection of medical journal articles from
    PubMed (more on the data below). I chose this dataset because it is structured
    (tabular) but also contains text in the form of abstracts for each article, and
    because it is already tagged with topical terms that are aligned with a well-established
    controlled vocabulary (MeSH). Because these are medical articles, I have called
    this app ‘Graph RAG for Medicine.’ But this same structure can be applied to any
    domain and is not specific to the medical field.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我用于此应用的数据集来自PubMed的医学期刊文章（数据详情见下文）。我选择这个数据集是因为它是结构化的（表格形式），但也包含每篇文章的摘要文本，并且已经用与公认的控制词汇（MeSH）对齐的主题术语进行了标注。由于这些是医学文章，我将这个应用命名为“医学图谱RAG”。但这种结构可以应用于任何领域，并不限于医学领域。
- en: 'What I hope this tutorial and app demonstrate is that you can improve the results
    of your RAG application in terms of accuracy and explainability by incorporating
    a knowledge graph into the retrieval step. I will show how KGs can improve the
    accuracy of RAG applications in two ways: by giving the user a way of filtering
    the context to ensure the LLM is only being fed the most relevant information;
    and by using domain specific controlled vocabularies with dense relationships
    that are maintained and curated by domain experts to do the filtering.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我希望本教程和应用程序展示的是，通过在检索步骤中加入知识图谱，你可以提高RAG应用的准确性和可解释性。我将展示知识图谱如何通过两种方式提高RAG应用的准确性：一种是为用户提供过滤上下文的方式，确保LLM只接收到最相关的信息；另一种是通过使用由领域专家维护和策划的、具有密切关系的特定领域控制词汇来进行过滤。
- en: 'What this tutorial and app don’t directly showcase are two other significant
    ways KGs can enhance RAG applications: governance, access control, and regulatory
    compliance; and efficiency and scalability. For governance, KGs can do more than
    filter content for relevancy to improve accuracy — they can enforce data governance
    policies. For instance, if a user lacks permission to access certain content,
    that content can be excluded from their RAG pipeline. On the efficiency and scalability
    side, KGs can help ensure RAG applications don’t die on the shelf. While it’s
    easy to create an impressive one-off RAG app (that’s literally the purpose of
    this tutorial), many companies struggle with a proliferation of disconnected POCs
    that lack a cohesive framework, structure, or platform. That means many of those
    apps are not going to survive long. A metadata layer powered by KGs can break
    down data silos, providing the foundation needed to build, scale, and maintain
    RAG applications effectively. Using a rich controlled vocabulary like MeSH for
    the metadata tags on these articles is a way of ensuring this Graph RAG app can
    be integrated with other systems and reducing the risk that it becomes a silo.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本教程和应用程序没有直接展示的两个重要方面是知识图谱（KGs）如何增强RAG应用程序：治理、访问控制和合规性；以及效率和可扩展性。在治理方面，KGs不仅可以过滤相关内容以提高准确性——它们还可以执行数据治理政策。例如，如果用户没有权限访问某些内容，那么这些内容可以从他们的RAG流程中排除。在效率和可扩展性方面，KGs可以帮助确保RAG应用程序不会被“搁置”。虽然创建一个令人印象深刻的单一RAG应用程序很容易（这正是本教程的目的），但许多公司却在大量孤立的POC（概念验证）中挣扎，这些POC缺乏一个统一的框架、结构或平台。这意味着这些应用程序中的许多可能难以长期生存。由KGs驱动的元数据层可以打破数据孤岛，提供建立、扩展和有效维护RAG应用程序所需的基础。使用像MeSH这样丰富的受控词汇作为这些文章的元数据标签，是确保该图形RAG应用程序能够与其他系统集成并减少成为孤岛风险的方式。
- en: 'Step 0: Prepare the data'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 0：准备数据
- en: '*The code to prepare the data is in* [*this*](https://github.com/SteveHedden/kg_llm/blob/main/graphRAGapp/VectorVsKG_updated.ipynb)
    *notebook.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*准备数据的代码在* [*这个*](https://github.com/SteveHedden/kg_llm/blob/main/graphRAGapp/VectorVsKG_updated.ipynb)
    *笔记本中。*'
- en: 'As mentioned, I’ve again decided to use [this](https://www.kaggle.com/datasets/owaiskhan9654/pubmed-multilabel-text-classification)
    dataset of 50,000 research articles from the PubMed repository (License [CC0:
    Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)). This dataset
    contains the title of the articles, their abstracts, as well as a field for metadata
    tags. These tags are from the Medical Subject Headings (MeSH) controlled vocabulary
    thesaurus. The PubMed articles are really just metadata on the articles — there
    are abstracts for each article but we don’t have the full text. The data is already
    in tabular format and tagged with MeSH terms.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '如前所述，我再次决定使用[这个](https://www.kaggle.com/datasets/owaiskhan9654/pubmed-multilabel-text-classification)来自PubMed库的50,000篇研究文章数据集（许可证[CC0:
    公共领域](https://creativecommons.org/publicdomain/zero/1.0/)）。该数据集包含文章的标题、摘要以及一个元数据标签字段。这些标签来自医学主题词表（MeSH）受控词汇库。PubMed文章实际上只是文章的元数据——每篇文章都有摘要，但我们没有完整的文本。数据已经是表格格式，并附有MeSH术语的标签。'
- en: We can vectorize this tabular dataset directly. We could turn it into a graph
    (RDF) before we vectorize, but I didn’t do that for this app and I don’t know
    that it would help the final results for this kind of data. The most important
    thing about vectorizing the raw data is that we add [Unique Resource Identifiers](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)
    (URIs) to each article first. A URI is a unique ID for navigating RDF data and
    it is necessary for us to go back and forth between vectors and entities in our
    graph. Additionally, we will create a separate collection in our vector database
    for the MeSH terms. This will allow the user to search for relevant terms without
    having prior knowledge of this controlled vocabulary. Below is a diagram of what
    we are doing to prepare our data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接对这个表格数据集进行向量化。我们本可以在向量化之前将其转换为图（RDF），但我在这个应用程序中没有这样做，而且我不确定对这种数据类型最终结果是否有帮助。向量化原始数据最重要的一点是，我们首先为每篇文章添加[统一资源标识符](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier)（URI）。URI是用于导航RDF数据的唯一标识符，它对于在向量和图中的实体之间来回切换是必需的。此外，我们将为MeSH术语在向量数据库中创建一个单独的集合。这将使用户能够在不事先了解受控词汇的情况下搜索相关术语。下面是我们为准备数据所做工作的示意图。
- en: '![](../Images/13719b544747a36938663e2a3e3239fa.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13719b544747a36938663e2a3e3239fa.png)'
- en: Image by Author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'We have two collections in our vector database to query: articles and terms.
    We also have the data represented as a graph in RDF format. Since MeSH has an
    API, I am just going to query the API directly to get alternative names and narrower
    concepts for terms.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在向量数据库中有两个可以查询的集合：文章和术语。我们还有以 RDF 格式表示的数据作为图。由于 MeSH 有一个 API，我将直接查询该 API 以获取术语的替代名称和更窄的概念。
- en: Vectorize data in Weaviate
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Weaviate 中向量化数据
- en: 'First import the required packages and set up the Weaviate client:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入所需的包并设置 Weaviate 客户端：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Read in the PubMed journal articles. I am using [Databricks](https://www.databricks.com/)
    to run this notebook so you may need to change this, depending on where you run
    it. The goal here is just to get the data into a pandas DataFrame.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 读取 PubMed 期刊文章。我使用的是[Databricks](https://www.databricks.com/)来运行这个笔记本，因此根据你运行的环境，可能需要进行更改。这里的目标只是将数据加载到
    pandas DataFrame 中。
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you’re running this locally, just do:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是在本地运行，只需执行以下操作：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then clean the data up a bit:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后稍微清理一下数据：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now we need to create a URI for each article and add that in as a new column.
    This is important because the URI is the way we can connect the vector representation
    of an article with the knowledge graph representation of the article.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要为每篇文章创建一个 URI，并将其作为新列添加。这非常重要，因为 URI 是将文章的向量表示与文章的知识图谱表示相连接的方式。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We also want to create a DataFrame of all of the MeSH terms that are used to
    tag the articles. This will be helpful later when we want to search for similar
    MeSH terms.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要创建一个包含所有用于标记文章的 MeSH 术语的 DataFrame。稍后在搜索相似的 MeSH 术语时，这将非常有用。
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Vectorize the articles DataFrame:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对文章 DataFrame 进行向量化：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now vectorize the MeSH terms:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对 MeSH 术语进行向量化：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can, at this point, run semantic search, similarity search, and RAG directly
    against the vectorized dataset. I won’t go through all of that here but you can
    look at the code in my [accompanying notebook](https://github.com/SteveHedden/kg_llm/tree/main/graphRAGapp)
    to do that.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以直接对向量化数据集运行语义搜索、相似性搜索和 RAG。我在这里不会详细讲解这些，但你可以查看我[随附的笔记本](https://github.com/SteveHedden/kg_llm/tree/main/graphRAGapp)中的代码来实现这些功能。
- en: Turn data into a knowledge graph
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据转化为知识图谱
- en: I am just using the same code we used in the [last post](https://medium.com/towards-data-science/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759)
    to do this. We are basically turning every row in the data into an “Article” entity
    in our KG. Then we are giving each of these articles properties for title, abstract,
    and MeSH terms. We are also turning every MeSH term into an entity as well. This
    code also adds random dates to each article for a property called date published
    and a random number between 1 and 10 to a property called access. We won’t use
    those properties in this demo. Below is a visual representation of the graph we
    are creating from the data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我只是使用了我们在[上一篇文章](https://medium.com/towards-data-science/how-to-implement-graph-rag-using-knowledge-graphs-and-vector-databases-60bb69a22759)中使用的相同代码来实现这一点。我们基本上是将数据中的每一行转化为我们知识图谱中的“文章”实体。然后，我们为这些文章提供标题、摘要和
    MeSH 术语等属性。我们还将每个 MeSH 术语也转化为一个实体。此代码还为每篇文章添加了随机的发布日期（作为名为 date published 的属性）和介于
    1 到 10 之间的随机数字（作为名为 access 的属性）。我们在这个演示中不会使用这些属性。下面是我们从数据中创建的图的可视化表示。
- en: '![](../Images/2390e2c00105e19f3f794a8c78acaf7a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2390e2c00105e19f3f794a8c78acaf7a.png)'
- en: Image by Author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'Here is how to iterate through the DataFrame and turn it into RDF data:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何遍历 DataFrame 并将其转化为 RDF 数据：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: OK, so now we have a vectorized version of the data, and a graph (RDF) version
    of the data. Each vector has a URI associated with it, which corresponds to an
    entity in the KG, so we can go back and forth between the data formats.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们已经有了数据的向量化版本和图（RDF）版本。每个向量都有一个与之关联的 URI，URI 对应于知识图谱中的一个实体，因此我们可以在数据格式之间来回转换。
- en: Build an app
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建应用
- en: I decided to use [Streamlit](https://streamlit.io/) to build the interface for
    this graph RAG app. Similar to the last blog post, I have kept the user flow the
    same.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定使用[Streamlit](https://streamlit.io/)来构建这个图 RAG 应用的界面。与上一篇博客文章类似，我保持了相同的用户流程。
- en: '**Search Articles:** First, the user searches for articles using a search term.
    This relies exclusively on the vector database. The user’s search term(s) is sent
    to the vector database and the ten articles nearest the term in vector space are
    returned.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**搜索文章：** 首先，用户使用搜索词进行文章搜索。这完全依赖于向量数据库。用户的搜索词会被发送到向量数据库，返回与该词在向量空间中最接近的十篇文章。'
- en: '**Refine Terms:** Second, the user decides the MeSH terms to use to filter
    the returned results. Since we also vectorized the MeSH terms, we can have the
    user enter a natural language prompt to get the most relevant MeSH terms. Then,
    we allow the user to expand these terms to see their alternative names and narrower
    concepts. The user can select as many terms as they want for their filter criteria.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**优化术语：** 第二，用户决定使用哪些MeSH术语来过滤返回的结果。由于我们也对MeSH术语进行了向量化处理，因此用户可以输入自然语言提示，以获得最相关的MeSH术语。接着，我们允许用户展开这些术语，查看它们的替代名称和更窄的概念。用户可以选择任意数量的术语作为过滤条件。'
- en: '**Filter & Summarize:** Third, the user applies the selected terms as filters
    to the original ten journal articles. We can do this since the PubMed articles
    are tagged with MeSH terms. Finally, we let the user enter an additional prompt
    to send to the LLM along with the filtered journal articles. This is the generative
    step of the RAG app.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**过滤与总结：** 第三，用户将选择的术语应用为过滤条件，作用于原始的十篇期刊文章。由于PubMed文章已经标注了MeSH术语，我们可以实现这一功能。最后，我们允许用户输入额外的提示，并将其与过滤后的期刊文章一起发送给LLM。这是RAG应用中的生成步骤。'
- en: 'Let’s go through these steps one at a time. You can see the full app and code
    on my GitHub, but here is the structure:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步完成这些操作。你可以在我的GitHub上查看完整的应用和代码，但以下是其结构：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Search Articles
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索文章
- en: First, want to do is implement Weaviate’s [vector similarity search](https://weaviate.io/developers/weaviate/search/similarity).
    Since our articles are vectorized, we can send a search term to the vector database
    and get similar articles back.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们要做的是实现Weaviate的[向量相似性搜索](https://weaviate.io/developers/weaviate/search/similarity)。由于我们的文章已被向量化，我们可以将搜索词发送到向量数据库，并返回相似的文章。
- en: '![](../Images/d4a996d6b04a9058f4313cf481470501.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4a996d6b04a9058f4313cf481470501.png)'
- en: Image by Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: 'The main function that searches for relevant journal articles in the vector
    database is in app.py:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在app.py中，搜索相关期刊文章的主要函数如下所示：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This function uses the queries stored in weaviate_queries to establish the Weaviate
    client (initialize_weaviate_client) and search for articles (query_weaviate_articles).
    Then we display the returned articles in a table, along with their abstracts,
    distance (how close they are to the search term), and the MeSH terms that they
    are tagged with.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 该功能使用存储在weaviate_queries中的查询来建立Weaviate客户端（initialize_weaviate_client），并搜索文章（query_weaviate_articles）。然后，我们将返回的文章以表格形式展示，包括它们的摘要、距离（与搜索词的接近程度）以及它们所标记的MeSH术语。
- en: 'The function to query Weaviate in weaviate_queries.py looks like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在weaviate_queries.py中查询Weaviate的函数如下所示：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, I put a limit of ten results here just to make it simpler, but
    you can change that. This is just using vector similarity search in Weaviate to
    return relevant results.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我在这里将结果限制为十个，以简化操作，但你可以更改这个限制。这只是使用Weaviate中的向量相似性搜索来返回相关结果。
- en: 'The end result in the app looks like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 应用中的最终结果如下所示：
- en: '![](../Images/d18988b667f6edfe53393d752ef9b6c1.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d18988b667f6edfe53393d752ef9b6c1.png)'
- en: Image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: As a demo, I will search the term “treatments for mouth cancer”. As you can
    see, 10 articles are returned, mostly relevant. This demonstrates both the strengths
    and weaknesses of vector based retrieval.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作为演示，我将搜索“口腔癌治疗方法”这一术语。如你所见，返回了10篇文章，且大多相关。这展示了基于向量的检索的优点与局限性。
- en: The strength is that we can build a semantic search functionality on our data
    with minimal effort. As you can see above, all we did was set up the client and
    send the data to a vector database. Once our data has been vectorized, we can
    do semantic searches, similarity searches, and even RAG. I have put some of that
    in the notebook accompanying this post, but there’s a lot more in Weaviate’s [official
    docs](https://weaviate.io/developers/weaviate).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 优势在于，我们可以用最少的努力，在数据上构建语义搜索功能。如上所示，我们所做的只是设置客户端并将数据发送到向量数据库。一旦数据被向量化，我们就可以进行语义搜索、相似性搜索，甚至是RAG。我已经将部分内容放入了与本文配套的笔记本中，但在Weaviate的[官方文档](https://weaviate.io/developers/weaviate)中有更多详细信息。
- en: The weakness of vector based retrieval, as I mentioned above are that they are
    black-box and struggle with factual knowledge. In our example, it looks like most
    of the articles are about some kind of treatment or therapy for some kind of cancer.
    Some of the articles are about mouth cancer specifically, some are about a sub-type
    of mouth cancer like gingival cancer (cancer of the gums), and palatal cancer
    (cancer of the palate). But there are also articles about nasopharyngeal cancer
    (cancer of the upper throat), mandibular cancer (cancer of the jaw), and esophageal
    cancer (cancer of the esophagus). None of these (upper throat, jaw, or esophagus)
    are considered mouth cancer. It is understandable why an article about a specific
    cancer radiation therapy for nasopharyngeal neoplasms would be considered similar
    to the prompt “treatments for mouth cancer” but it may not be relevant if you
    are only looking for treatments for mouth cancer. If we were to plug these ten
    articles directly into our prompt to the LLM and ask it to “summarize the different
    treatment options,” we would be getting incorrect information.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前所提到的，基于向量的检索的弱点是它们是黑盒模型，并且在处理事实性知识时存在困难。在我们的示例中，看起来大多数文章都是关于某种癌症治疗或疗法的。有些文章专门讨论口腔癌，有些则讨论口腔癌的亚型，如牙龈癌（牙龈癌）和腭癌（腭癌）。但也有关于鼻咽癌（上咽部癌症）、下颌癌（下颌癌）和食管癌（食管癌）的文章。所有这些（上咽部、下颌或食管癌）都不被认为是口腔癌。可以理解，关于针对鼻咽肿瘤的特定癌症放疗的文章可能会与“口腔癌治疗”这一提示相关，但如果你仅仅是想寻找口腔癌的治疗方法，它可能并不相关。如果我们将这十篇文章直接输入到LLM的提示中并要求它“总结不同的治疗选项”，我们将得到错误的信息。
- en: The purpose of RAG is to give an LLM a very specific set of additional information
    to better answer your question — if that information is incorrect or irrelevant,
    it can lead to misleading responses from the LLM. This is often referred to as
    “context poisoning”. What is especially dangerous about context poisoning is that
    the response isn’t necessarily factually inaccurate (the LLM may accurately summarize
    the treatment options we feed it), and it isn’t necessarily based on an inaccurate
    piece of data (presumably the journal articles themselves are accurate), it’s
    just using the wrong data to answer your question. In this example, the user could
    be reading about how to treat the wrong kind of cancer, which seems very bad.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: RAG的目的是为大语言模型（LLM）提供一组非常具体的附加信息，以便更好地回答您的问题——如果这些信息不正确或不相关，可能会导致LLM给出误导性回答。这通常被称为“上下文污染”。上下文污染特别危险的一点是，回答不一定是事实不准确的（LLM可能准确地总结了我们提供的治疗选项），也不一定是基于不准确的数据（假设期刊文章本身是准确的），只是使用了错误的数据来回答您的问题。在这个例子中，用户可能正在阅读如何治疗错误类型癌症的文章，这看起来是非常糟糕的。
- en: Refine Terms
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精炼术语
- en: KGs can help improve the accuracy of responses and reduce the likelihood of
    context poisoning by refining the results from the vector database. The next step
    is for selecting what MeSH terms we want to use to filter the articles. First,
    we do another vector similarity search against the vector database but on the
    Terms collection. This is because the user may not be familiar with the MeSH controlled
    vocabulary. In our example above, I searched for, “therapies for mouth cancer”,
    but “mouth cancer” is not a term in MeSH — they use “Mouth Neoplasms”. We want
    the user to be able to start exploring the MeSH terms without having a prior understanding
    of them — this is good practice regardless of the metadata used to tag the content.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱（KGs）可以通过精炼来自向量数据库的结果，帮助提高回答的准确性，并减少上下文污染的可能性。下一步是选择我们希望使用的MeSH术语来筛选文章。首先，我们在术语集合中对向量数据库进行另一次向量相似度搜索。这样做是因为用户可能不熟悉MeSH控制词汇。在我们上面的示例中，我搜索了“口腔癌的治疗方法”，但是“口腔癌”不是MeSH中的术语——他们使用的是“口腔肿瘤”（Mouth
    Neoplasms）。我们希望用户能够在没有事先了解这些术语的情况下开始探索MeSH术语——无论使用什么元数据来标记内容，这都是一种良好的实践。
- en: '![](../Images/e18e44bd8931abf6ec9b70a67d17cdad.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e18e44bd8931abf6ec9b70a67d17cdad.png)'
- en: Image by Author
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: 'The function to get relevant MeSH terms is nearly identical to the previous
    Weaviate query. Just replace Article with term:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 获取相关MeSH术语的功能与之前的Weaviate查询几乎相同。只需要将文章替换为术语：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is what it looks like in the app:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在应用程序中的样子：
- en: '![](../Images/b518eb952de2b3ad25305e1d144d2006.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b518eb952de2b3ad25305e1d144d2006.png)'
- en: Image by Author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: As you can see, I searched for “mouth cancer” and the most similar terms were
    returned. Mouth cancer was not returned, as that is not a term in MeSH, but Mouth
    Neoplasms is on the list.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我搜索了“口腔癌”（mouth cancer），返回了最相似的术语。口腔癌没有被返回，因为这不是MeSH中的术语，但口腔肿瘤（Mouth Neoplasms）在列表中。
- en: The next step is to allow the user to expand the returned terms to see alternative
    names and narrower concepts. This requires querying the [MeSH API](https://id.nlm.nih.gov/mesh/).
    This was the trickiest part of this app for a number of reasons. The biggest problem
    is that Streamlit requires that everything has a unique ID but MeSH terms can
    repeat — if one of the returned concepts is a child of another, then when you
    expand the parent you will have a duplicate of the child. I think I took care
    of most of the big issues and the app should work, but there are probably bugs
    to find at this stage.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是允许用户展开返回的术语，以查看替代名称和更具体的概念。这需要查询[MeSH API](https://id.nlm.nih.gov/mesh/)。这是这个应用中最棘手的部分，原因有很多。最大的问题是Streamlit要求每个项目都有唯一的ID，而MeSH术语可能会重复——如果返回的某个概念是另一个概念的子概念，那么当你展开父概念时，会出现重复的子概念。我认为我已经解决了大部分问题，应用应该能正常运行，但这个阶段可能还会有bug。
- en: 'The functions we rely on are found in rdf_queries.py. We need one to get the
    alternative names for a term:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们依赖的函数可以在rdf_queries.py中找到。我们需要一个来获取术语的替代名称：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We also need functions to get the narrower (child) concepts for a given term.
    I have two functions that achieve this — one that gets the immediate children
    of a term and one recursive function that returns all children of a given depth.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一些功能来获取给定术语的更具体（子概念）概念。我有两个函数实现了这一点——一个获取术语的直接子概念，另一个递归函数返回给定深度的所有子概念。
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The other important part of step 2 is to allow the user to select terms to
    add to a list of “Selected Terms”. These will appear in the sidebar on the left
    of the screen. There are a lot of things that can improve this step like:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第2步的另一个重要部分是允许用户选择术语并将其添加到“已选择术语”列表中。这些术语将出现在屏幕左侧的侧边栏中。有很多方法可以改进这一步，例如：
- en: There is no way to clear all but you can clear the cache or refresh the browser
    if needed.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有办法清除所有内容，但你可以清除缓存或刷新浏览器（如果需要的话）。
- en: There is no way to ‘select all narrower concepts’ which would be helpful.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前没有办法“选择所有更具体的概念”，这将会很有帮助。
- en: There is no option to add rules for filtering. Right now, we are just assuming
    that the article must contain term A OR term B OR term C etc. The rankings at
    the end are based on the number of terms the articles are tagged with.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前没有添加过滤规则的选项。现在我们只是简单地假设文章必须包含术语A或术语B或术语C等。最后的排名是基于文章被标记的术语数量。
- en: 'Here is what it looks like in the app:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在应用中看到的样子：
- en: '![](../Images/92e6f9744b8b568b723112f82f41339b.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92e6f9744b8b568b723112f82f41339b.png)'
- en: Image by Author
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: I can expand Mouth Neoplasms to see the alternative names, in this case, “Cancer
    of Mouth”, along with all of the narrower concepts. As you can see, most of the
    narrower concepts have their own children, which you can expand as well. For the
    purposes of this demo, I am going to select all children of Mouth Neoplasms.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以展开口腔肿瘤（Mouth Neoplasms）来查看替代名称，在这种情况下是“口腔癌”，以及所有更具体的概念。如你所见，大多数更具体的概念都有自己的子概念，你也可以展开这些子概念。为了这个演示的目的，我将选择口腔肿瘤的所有子概念。
- en: '![](../Images/587f3974e8d7406677192e774d96824b.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/587f3974e8d7406677192e774d96824b.png)'
- en: Image by Author
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: This step is important not just because it allows the user to filter the search
    results, but also because it is a way for the user to explore the MeSH graph itself
    and learn from it. For example, this would be the place for the user to learn
    that nasopharyngeal neoplasms are not a subset of mouth neoplasms.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步很重要，不仅因为它允许用户过滤搜索结果，还因为它为用户提供了探索MeSH图谱并从中学习的方式。例如，在这里用户可以学到鼻咽肿瘤并不是口腔肿瘤的子集。
- en: Filter & Summarize
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过滤和总结
- en: Now that you’ve got your articles and your filter terms, you can apply the filter
    and summarize the results. This is where we bring the original 10 articles returned
    in step one together with the refined list of MeSH terms. We allow the user to
    add additional context to the prompt before sending it to the LLM.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了文章和过滤条件，可以应用过滤器并总结结果。在这一步中，我们将第一步返回的原始10篇文章与精炼后的MeSH术语列表结合在一起。我们允许用户在将提示发送给LLM之前添加额外的上下文。
- en: '![](../Images/755f10265aed07b0b49c8a86f6fe1d67.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/755f10265aed07b0b49c8a86f6fe1d67.png)'
- en: Image by Author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: The way we do this filtering is that we need to get the URIs for the 10 articles
    from the original search. Then we can query our knowledge graph for which of those
    articles have been tagged with the associated MeSH terms. Additionally, we save
    the abstracts of these articles for use in the next step. This would be the place
    where we could filter based on access control or other user-controlled parameters
    like author, filetype, date published, etc. I didn’t include any of that in this
    app but I did add in properties for access control and date published in case
    we want to add that in this UI later.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行过滤的方法是，我们需要从原始搜索中获取这10篇文章的URI。然后，我们可以查询知识图谱，看看这些文章中哪些被标记了相关的MeSH术语。此外，我们保存这些文章的摘要，以便在下一步使用。这也是我们可以基于访问控制或其他用户控制参数（如作者、文件类型、发布日期等）进行过滤的地方。我在这个应用中没有包括这些内容，但我确实添加了访问控制和发布日期的属性，以防我们以后想在这个用户界面中添加这些功能。
- en: 'Here is what the code looks like in app.py:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是app.py中的代码样式：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This uses the function query_rdf in the rdf_queries.py file. That function
    looks like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用了rdf_queries.py文件中的query_rdf函数。该函数如下所示：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, this function also converts the MeSH terms to URIs so we can
    filter using the graph. Be careful in the way you convert terms to URIs and ensure
    it aligns with the other functions.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个功能还会将MeSH术语转换为URI，这样我们就可以通过图形进行过滤。在将术语转换为URI时要小心，并确保它与其他功能一致。
- en: 'Here is what it looks like in the app:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是应用程序中的界面样式：
- en: '![](../Images/11971e4329e6ec965e8cf188e1aec1a1.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11971e4329e6ec965e8cf188e1aec1a1.png)'
- en: Image by Author
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: As you can see, the two MeSH terms we selected from the previous step are here.
    If I click “Filter Articles,” it will filter the original 10 articles using our
    filter criteria in step 2\. The articles will be returned with their full abstracts,
    along with their tagged MeSH terms (see image below).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们从前一步选择的两个MeSH术语已经列出。如果我点击“过滤文章”，它将使用我们在第2步中的过滤条件过滤原始的10篇文章。文章将返回其完整的摘要，以及标记的MeSH术语（见下图）。
- en: '![](../Images/5f45112e4ef1d0b014865f755e64ac2c.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f45112e4ef1d0b014865f755e64ac2c.png)'
- en: Image by Author
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: There are 5 articles returned. Two are tagged with “mouth neoplasms,” one with
    “gingival neoplasms,” and two with “palatal neoplasms”.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 返回了5篇文章。其中两篇标记为“口腔肿瘤”，一篇标记为“牙龈肿瘤”，两篇标记为“腭肿瘤”。
- en: 'Now that we have a refined list of articles we want to use to generate a response,
    we can move to the final step. We want to send these articles to an LLM to generate
    a response but we can also add in additional context to the prompt. I have a default
    prompt that says, “Summarize the key information here in bullet points. Make it
    understandable to someone without a medical degree.” For this demo, I am going
    to adjust the prompt to reflect our original search term:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个精炼的文章列表，准备用来生成回应，我们可以进入最后一步。我们希望将这些文章发送给LLM生成回应，但我们也可以在提示中加入额外的上下文。我有一个默认的提示，内容是：“用要点总结这里的关键信息。使其对没有医学学位的人也能理解。”对于这个演示，我将调整提示以反映我们的原始搜索词：
- en: '![](../Images/ebb1666b6c3ca891803cb3d817272f05.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebb1666b6c3ca891803cb3d817272f05.png)'
- en: 'The results are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/e55ff463f58f5f79fd3a82d1d842be3a.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e55ff463f58f5f79fd3a82d1d842be3a.png)'
- en: The results look better to me, mostly because I know that the articles we are
    summarizing are, presumably, about treatments for mouth cancer. The dataset doesn’t
    contain the actual journal articles, just the abstracts. So these results are
    just summaries of summaries. There may be some value to this, but if we were building
    a real app and not just a demo, this is the step where we could incorporate the
    full text of the articles. Alternatively, this is where the user/researcher would
    go read these articles themselves, rather than relying exclusively on the LLM
    for the summaries.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来对我来说更好，主要是因为我知道我们总结的文章大概是关于口腔癌治疗的。这些数据集不包含实际的期刊文章，只有摘要。因此，这些结果只是摘要的摘要。这可能有一定价值，但如果我们在构建一个真正的应用程序，而不仅仅是一个演示的话，这是我们可以将文章的全文加入的步骤。或者，这也是用户/研究人员自己去阅读这些文章的地方，而不是完全依赖于LLM来进行总结。
- en: Conclusion
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This tutorial demonstrates how combining vector databases and knowledge graphs
    can significantly enhance RAG applications. By leveraging vector similarity for
    initial searches and structured knowledge graph metadata for filtering and organization,
    we can build a system that delivers accurate, explainable, and domain-specific
    results. The integration of MeSH, a well-established controlled vocabulary, highlights
    the power of domain expertise in curating metadata, which ensures that the retrieval
    step aligns with the unique needs of the application while maintaining interoperability
    with other systems. This approach is not limited to medicine — its principles
    can be applied across domains wherever structured data and textual information
    coexist.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程演示了如何将向量数据库和知识图谱相结合，以显著提升RAG应用程序的效果。通过利用向量相似性进行初步搜索，结合结构化的知识图谱元数据进行筛选和组织，我们可以构建一个提供准确、可解释和领域特定结果的系统。MeSH（医学主题词表）的集成展示了领域专业知识在策划元数据中的重要性，它确保了检索步骤与应用程序的独特需求保持一致，同时与其他系统保持互操作性。这种方法不限于医学领域——其原理可以应用于任何结构化数据与文本信息共存的领域。
- en: This tutorial underscores the importance of leveraging each technology for what
    it does best. Vector databases excel at similarity-based retrieval, while knowledge
    graphs shine in providing context, structure, and semantics. Additionally, scaling
    RAG applications demands a metadata layer to break down data silos and enforce
    governance policies. Thoughtful design, rooted in domain-specific metadata and
    robust governance, is the path to building RAG systems that are not only accurate
    but also scalable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程强调了充分利用每种技术各自擅长领域的重要性。向量数据库擅长基于相似性的检索，而知识图谱则在提供上下文、结构和语义方面表现出色。此外，扩展RAG应用程序需要一个元数据层，以打破数据孤岛并实施治理策略。深思熟虑的设计，根植于特定领域的元数据和强有力的治理，是构建既准确又可扩展的RAG系统的关键路径。
