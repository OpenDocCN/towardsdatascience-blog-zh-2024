- en: 'Introducing Semantic Tag Filtering: Enhancing Retrieval with Tag Similarity'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍语义标签过滤：通过标签相似性增强检索
- en: 原文：[https://towardsdatascience.com/introducing-semantic-tag-filtering-enhancing-retrieval-with-tag-similarity-4f1b2d377a10?source=collection_archive---------2-----------------------#2024-09-09](https://towardsdatascience.com/introducing-semantic-tag-filtering-enhancing-retrieval-with-tag-similarity-4f1b2d377a10?source=collection_archive---------2-----------------------#2024-09-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introducing-semantic-tag-filtering-enhancing-retrieval-with-tag-similarity-4f1b2d377a10?source=collection_archive---------2-----------------------#2024-09-09](https://towardsdatascience.com/introducing-semantic-tag-filtering-enhancing-retrieval-with-tag-similarity-4f1b2d377a10?source=collection_archive---------2-----------------------#2024-09-09)
- en: Semantic Tag Filtering
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义标签过滤
- en: How to use Semantic Similarity to improve tag filtering
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何利用语义相似度改进标签过滤
- en: '[](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)[![Michelangiolo
    Mazzeschi](../Images/9211748ac638d2ed07679ac73ea17296.png)](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)
    [Michelangiolo Mazzeschi](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)[![Michelangiolo
    Mazzeschi](../Images/9211748ac638d2ed07679ac73ea17296.png)](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)
    [Michelangiolo Mazzeschi](https://medium.com/@ardito.bryan?source=post_page---byline--4f1b2d377a10--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)
    ·9 min read·Sep 9, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4f1b2d377a10--------------------------------)
    ·阅读时长9分钟·2024年9月9日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '***To understand this article, the knowledge of both **Jaccard similarity**
    and **vector search** is required. The implementation of this algorithm has been
    released on [GitHub](https://github.com/atlantis-nova/simtag) and is fully open-source.'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***要理解这篇文章，需要掌握**Jaccard相似度**和**向量搜索**的知识。此算法的实现已发布在[GitHub](https://github.com/atlantis-nova/simtag)上，并且完全开源。'
- en: Over the years, we have discovered how to retrieve information from different
    modalities, such as **numbers**, **raw text**, **images**, and also **tags**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，我们已经掌握了如何从不同模态中检索信息，如**数字**、**原始文本**、**图像**，以及**标签**。
- en: With the growing popularity of customized UIs, **tag search systems** have become
    a convenient way of easily filtering information with a good degree of accuracy.
    Some cases **where tag search is commonly employed** are the retrieval of social
    media posts, articles, games, movies, and even resumes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着定制化用户界面（UI）越来越受欢迎，**标签搜索系统**成为了一种方便的方式，可以高效且准确地过滤信息。一些常见的**标签搜索应用场景**包括社交媒体帖子、文章、游戏、电影，甚至是简历的检索。
- en: However, traditional tag search lacks flexibility. If we are to filter the samples
    that contain exactly the given tags, there might be cases when, especially for
    databases containing only a few thousand samples, **there might not be any (or
    only a few) matching samples for our query**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传统的标签搜索缺乏灵活性。如果我们要筛选包含精确标签的样本，可能会遇到一些情况，尤其是对于只包含几千个样本的数据库，**可能没有（或仅有少数）匹配的样本**。
- en: '![](../Images/8deb50b654d346627375b7d90a6963a5.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8deb50b654d346627375b7d90a6963a5.png)'
- en: difference of the two searches in front of a scarcity of results, Image by author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 两种搜索方式在结果稀缺情况下的区别，图片来源：作者
- en: '****Through the following article I am trying to introduce several new algorithms
    that, to the extent of my knowledge, I have been unable to find.* ***I am open
    to criticism*** *and* ***welcome any feedback.***'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '****通过以下文章，我试图介绍几种新的算法，据我所知，我一直没有找到相关的资料。***我愿意接受批评*** *并且* ***欢迎任何反馈。***'
- en: How does traditional tag search work?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统的标签搜索是如何工作的？
- en: Traditional systems employ an algorithm called **Jaccard similarity** (commonly
    executed through the **minhash algo**), which is able to compute the similarity
    between two sets of elements (in our case, those elements are tags). As previously
    clarified, the search is not flexible at all (sets either **contain** or **do
    not contain** the queried tags).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 传统系统使用一种叫做**Jaccard相似度**的算法（通常通过**minhash算法**执行），它能够计算两个元素集合之间的相似度（在我们的例子中，这些元素是标签）。如前所述，这种搜索方法根本不灵活（集合要么**包含**，要么**不包含**查询的标签）。
- en: '![](../Images/db30a66064d36f7c16764a5cf985b2d7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db30a66064d36f7c16764a5cf985b2d7.png)'
- en: example of a **simple AND bitwise operation** (this is not Jaccard similarity,
    but can give you an approximate idea of the filtering method), Image by author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单与位运算**示例（这不是Jaccard相似度，但可以让你大致了解过滤方法），图像由作者提供'
- en: Can we do better?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能做得更好吗？
- en: What if, instead, rather than just filtering a sample from matching tags, we
    could take into account all the other labels in the sample that are not identical,
    but are **similar** to our chosen tags? We could be making the algorithm more
    flexible, expanding the results to non-perfect matches, but still good matches.
    We would be applying **semantic similarity** directly totags, rather than text.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果我们不仅仅是从匹配标签中过滤样本，而是考虑样本中所有其他不完全相同但与我们选择的标签**相似**的标签呢？我们可以使算法更加灵活，将结果扩展到非完美匹配的项，但仍然是较好的匹配。我们将直接将**语义相似性**应用于标签，而不是文本。
- en: Introducing Semantic Tag Search
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入语义标签搜索
- en: 'As briefly explained, this new approach attempts to combine the **capabilities
    of semantic search** with tag filtering systems. For this algorithm to be built,
    we need only one thing:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这种新方法试图将**语义搜索的能力**与标签过滤系统相结合。为了构建这个算法，我们只需要一件事：
- en: A database of **tagged samples**
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**带标签的样本数据库**
- en: The reference data I will be using is the open-source collection of the **Steam
    game library** ([downloadable from Kaggle](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset)
    — [MIT License](https://www.mit.edu/~amini/LICENSE.md)) — approx. 40,000 samples,
    which is a good amount of samples to test our algorithm. As we can see from the
    displayed dataframe, each game has several assigned tags, with over 400 unique
    tags in our database.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用的参考数据是开源的**Steam游戏库**（[可从Kaggle下载](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset)
    — [MIT许可证](https://www.mit.edu/~amini/LICENSE.md)） — 大约40,000个样本，这是测试我们算法的一个不错的样本量。从显示的数据框中可以看到，每个游戏都有多个分配的标签，在我们的数据库中有超过400个独特的标签。
- en: '![](../Images/98840614196d9a8643fe33a8f184b312.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98840614196d9a8643fe33a8f184b312.png)'
- en: Screenshot of the Steam dataframe available in the example notebook, Image by
    author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 示例笔记本中的Steam数据框截图，图像由作者提供
- en: 'Now that we have our starting data, we can proceed: the algorithm will be articulated
    in the following steps:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了起始数据，我们可以继续：算法将在以下步骤中进行阐述：
- en: Extracting tags relationships
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取标签关系
- en: Encoding queries and samples
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码查询和样本
- en: Perform the semantic tag search using vector retrieval
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用向量检索进行语义标签搜索
- en: Validation
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证
- en: 'In this article, **I will only explore the math** behind this new approach
    (for an in-depth [explanation of the code with a working demo](https://github.com/atlantis-nova/simtag/blob/main/notebooks/steam_example.ipynb),
    please refer to the following notebook: instructions on how to use simtag are
    available in the [README.md file on root](https://github.com/atlantis-nova/simtag)).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，**我将仅探讨**这种新方法背后的数学（有关带有工作演示的代码的详细[解释](https://github.com/atlantis-nova/simtag/blob/main/notebooks/steam_example.ipynb)，请参阅以下笔记本：如何使用simtag的说明请参见[根目录的README.md文件](https://github.com/atlantis-nova/simtag)）。
- en: 1\. Extracting tag relationships
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 提取标签关系
- en: 'The first question that comes to mind is how can we find the **relationships
    between our tags**. Note that there are several algorithms used to obtain the
    same result:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个想到的问题是我们如何找到**标签之间的关系**。请注意，有几种算法可以用于获得相同的结果：
- en: Using s**tatistical methods** The simplest employable method we can use to extract
    tag relationships is called **co-occurrence matrix**, which is the format that
    (for both its effectiveness and simplicity) I will employ in this article.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**统计方法**我们可以使用的最简单的方法来提取标签关系叫做**共现矩阵**，这是我在本文中将采用的格式（因其高效性和简单性）。
- en: Using **Deep Learning** The most advanced ones are all based on Embeddings neural
    networks (such as [Word2Vec](https://projector.tensorflow.org/) in the past, now
    it is common to use transformers, such as LLMs) that can extract the semantic
    relationships between samples. Creating a neural network to extract tag relationships
    (in the form of an autoencoder) is a possibility, and it is usually advisable
    when facing certain circumstances.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**深度学习**：最先进的深度学习方法都基于嵌入式神经网络（例如，过去使用[Word2Vec](https://projector.tensorflow.org/)，现在常用的则是变换器模型，如LLMs），这些方法能够提取样本之间的语义关系。创建一个神经网络来提取标签关系（以自编码器的形式）是一个可能的选项，并且在面对特定情境时，通常建议这样做。
- en: Using **a pre-trained model** Because tags are defined using human language,
    it is possible to employ existing pre-trained models to compute already existing
    similarities. This will likely be much faster and less troubling. However, each
    dataset has its uniqueness. Using a pre-trained model **will ignore the customer
    behavior**.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**预训练模型**：由于标签是使用人类语言定义的，因此可以使用现有的预训练模型来计算已经存在的相似度。这通常会更快，也不会那么麻烦。然而，每个数据集都有其独特性。使用预训练模型**将忽略客户行为**。
- en: 'Ex. We will later see how 2D has a strong relationship with Fantasy: such a
    pair will never be discovered using pre-trained models.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，我们稍后会看到 2D 与 Fantasy 之间有强关联：这种配对使用预训练模型永远无法发现。
- en: 'The choice of the algorithm may depend on many factors, especially when we
    have to work with a huge data pool or we have scalability concerns (ex. **# tags
    will equal our vector length**: if we have too many tags, we need to use Machine
    Learning to stem this problem.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的选择可能取决于许多因素，特别是当我们需要处理庞大的数据池或存在可扩展性问题时（例如，**# 标签将等于我们的向量长度**：如果标签太多，我们需要使用机器学习来解决这个问题）。
- en: a. Build co-occurence matrix using Michelangiolo similarity
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: a. 使用米开朗基罗相似度构建共现矩阵
- en: 'As mentioned, I will be using the **co-occurrence matrix** as a means to extract
    these relationships. My goal is to find the relationship between **every pair
    of tags**, and I will be doing so by applying the following count across the entire
    collection of samples using IoU (Intersection over Union) over the set of all
    samples (S):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我将使用**共现矩阵**来提取这些关系。我的目标是找到**每一对标签**之间的关系，我将通过对整个样本集合（S）应用以下计数来做到这一点，使用
    IoU（交集除以并集）：
- en: '![](../Images/edef7f7dd297a3d5f926a284a19e904b.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/edef7f7dd297a3d5f926a284a19e904b.png)'
- en: formula to compute the **similarity between a pair of tags,** Image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 计算**标签对之间相似度**的公式，作者提供的图像
- en: This algorithm is very similar to Jaccard similarity. While it operates on samples,
    the one I introduce operates on elements, but since (**as of my knowledge**) this
    specific application has not been codified, yet, we can name it **Michelangiolo
    similarity. (**To be fair, the use of this algorithm has been previously mentioned
    in a [StackOverflow question](https://stackoverflow.com/questions/76910725/pyspark-getting-jaccard-similarity-from-co-ocurrence-matrix),
    yet, never codified).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法与 Jaccard 相似度非常相似。虽然它作用于样本，但我介绍的这个算法作用于元素，然而（**据我所知**）这个特定的应用尚未被正式化，所以我们可以将其称为**米开朗基罗相似度**。（**公平地说，这个算法的使用曾在[StackOverflow
    问题](https://stackoverflow.com/questions/76910725/pyspark-getting-jaccard-similarity-from-co-ocurrence-matrix)中提到过，但从未被正式化**）。
- en: '![](../Images/52f16770cab51be3ec71fcaf42785d46.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52f16770cab51be3ec71fcaf42785d46.png)'
- en: difference between **Jaccard similarity** and **Michelangiolo similarity,**
    Image by author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jaccard 相似度**和**米开朗基罗相似度**的区别，作者提供的图像'
- en: 'For 40,000 samples, it takes about an hour to extract the **similarity matrix**,
    this will be the result:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 40,000 个样本，提取**相似度矩阵**大约需要一个小时，结果将是：
- en: '![](../Images/c04b998382818044cd5070897e0922e0.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c04b998382818044cd5070897e0922e0.png)'
- en: '**co-occurrence matrix** of all unique tags in our sample list **S,** Image
    by author'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们样本列表中所有独特标签的**共现矩阵** **S，**作者提供的图像
- en: 'Let us make a manual check of the top 10 samples for some very common tags,
    to see if the result makes sense:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们手动检查一些非常常见标签的前 10 个样本，看看结果是否合理：
- en: '![](../Images/d5702dfcde2134de320553a4ddd6af25.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5702dfcde2134de320553a4ddd6af25.png)'
- en: sample relationships extracted from the **co-occurrence matrix,** Image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从**共现矩阵**中提取的样本关系，作者提供的图像
- en: The result looks very promising! We started from plain categorical data (only
    convertible to 0 and 1), but we have extracted the semantic relationship between
    tags (without even using a neural network).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来非常有前景！我们从纯粹的分类数据（仅能转换为0和1）开始，但我们已经提取了标签之间的语义关系（甚至没有使用神经网络）。
- en: b. Use a pre-trained neural network
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: b. 使用预训练神经网络
- en: Equally, we can extract existing relationships between our samples using [a
    pre-trained encoder](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2).
    This solution, however, ignores the relationships that can only be extracted from
    our data, only focusing on existing semantic relationships of the human language.
    This may not be a well-suited solution to work on top of retail-based data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用[预训练编码器](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)提取我们样本之间的现有关系。然而，这种解决方案忽略了只能从我们的数据中提取的关系，仅关注人类语言的现有语义关系。这可能不是在零售数据上工作的最佳解决方案。
- en: 'On the other hand, by using a neural network we would not need to build a relationship
    matrix: hence, this is a proper solution for scalability. For example, if we had
    to analyze a large batch of Twitter data, we reach 53.300 tags. Computing a co-occurrence
    matrix from this number of tags will result in a sparse matrix of size **2,500,000,000**
    (quite a non-practical feat). Instead, by using a standard encoder that outputs
    a vector length of 384, the resulting matrix will have a total size of **19,200,200**.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，通过使用神经网络，我们不需要构建关系矩阵：因此，这是一个适合可扩展性的解决方案。例如，如果我们必须分析大量的Twitter数据，我们将达到53,300个标签。从这个标签数计算共现矩阵将得到一个大小为**2,500,000,000**的稀疏矩阵（这相当不切实际）。相反，通过使用一个标准的编码器，输出长度为384的向量，结果矩阵的总大小将是**19,200,200**。
- en: '![](../Images/4e906835f1508685df5e19c9bcddf4a0.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e906835f1508685df5e19c9bcddf4a0.png)'
- en: snapshot of an encoded set of tags usin a pre-trained encoder
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练编码器编码标签集的快照
- en: 2\. Encoding queries and samples
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 编码查询和样本
- en: 'Our goal is to build a search engine capable of supporting the semantic tag
    search: with the format we have been building, the only technology capable of
    supporting such an enterprise is **vector search**. Hence, we need to find a proper
    encoding algorithm to convert both our samples and queries into vectors.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是构建一个能够支持语义标签搜索的搜索引擎：在我们一直在构建的格式下，唯一能够支持此类企业的技术是**向量搜索**。因此，我们需要找到一个合适的编码算法，将我们的样本和查询转换为向量。
- en: In most encoding algorithms, **we encode both queries and samples using the
    same algorithm**. However, each sample contains more than one tag, each represented
    by a different set of relationships that **we need to capture in a single vector**.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数编码算法中，**我们使用相同的算法对查询和样本进行编码**。然而，每个样本包含多个标签，每个标签由一组不同的关系表示，**我们需要在单个向量中捕捉这些关系**。
- en: '![](../Images/133e3c177bc6e5f2c72451c58c86686f.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/133e3c177bc6e5f2c72451c58c86686f.png)'
- en: '**Covariate Encoding,** Image by author'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**协变量编码，** 图片由作者提供'
- en: In addition, we need to address the aforementioned problem of scalability, and
    we will do so by using a **PCA module** (when we use a co-occurrence matrix, instead,
    we can skip the PCA because there is no need to compress our vectors).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们需要解决前面提到的可扩展性问题，我们将通过使用**PCA模块**来解决（如果我们使用共现矩阵，则可以跳过PCA，因为不需要压缩我们的向量）。
- en: When the number of tags becomes too large, we need to abandon the possibility
    of computing a co-occurrence matrix, because it scales at a squared rate. Therefore,
    we can extract the vector of each existing tag using a pre-trained neural network
    (the first step in the PCA module). For example, **all-MiniLM-L6-v2** converts
    each tag into a vector of length 384.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当标签数量变得过大时，我们需要放弃计算共现矩阵的可能性，因为其计算量是平方级别的。因此，我们可以使用预训练的神经网络提取每个现有标签的向量（PCA模块的第一步）。例如，**all-MiniLM-L6-v2**将每个标签转换为长度为384的向量。
- en: 'We can then transpose the obtained matrix, and compress it: we will initially
    encode our queries/samples using 1 and 0 for the available tag indexes, resulting
    in an initial vector of the same length as our initial matrix (53,300). At this
    point, we can use our pre-computed PCA instance **to compress the same sparse
    vector in 384 dims**.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以转置获得的矩阵，并对其进行压缩：我们最初使用1和0编码我们的查询/样本，代表可用的标签索引，结果是一个与我们初始矩阵（53,300）长度相同的初始向量。此时，我们可以使用我们预计算的PCA实例**来压缩相同的稀疏向量至384维**。
- en: Encoding samples
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码样本
- en: In the case of our samples, the process ends just right after the PCA compression
    (when activated).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的样本中，过程在PCA压缩后（激活时）刚好结束。
- en: 'Encoding queries: Covariate Encoding'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码查询：协变量编码
- en: 'Our query, however, needs to be encoded differently: we need to take into account
    **the relationships associated with each existing tag**. This process is executed
    by first summing our compressed vector to the compressed matrix (the total of
    all existing relationships). Now that we have obtained a matrix (384x384), **we
    will need to average it**, obtaining our query vector.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的查询需要不同的编码方式：我们需要考虑**每个现有标签相关的关系**。这个过程首先通过将我们的压缩向量加到压缩矩阵上（所有现有关系的总和）来执行。现在我们得到了一个矩阵（384x384），**我们需要对其进行平均**，从而得到我们的查询向量。
- en: Because we will make use of Euclidean search, it will first prioritize the search
    for features with the highest score (ideally, the one we activated using the number
    1), but it will also consider the additional minor scores.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将使用欧几里得搜索，它会首先优先搜索得分最高的特征（理想情况下是我们用数字1激活的那个），但它也会考虑其他较小的得分。
- en: Weighted search
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加权搜索
- en: Because we are averaging vectors together, we can even apply a weight to this
    calculation, and the vectors will be impacted differently from the query tags.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们是在对向量进行平均计算，我们甚至可以为这个计算应用一个权重，向量将会根据查询标签的不同而受到不同的影响。
- en: 3\. Perform the semantic tag search using vector retrieval
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 使用向量检索执行语义标签搜索
- en: 'The question you might be asking is: why did we undergo **this complex encoding
    process**, rather than just inputting the pair of tags into a function and obtaining
    a score — **f(query, sample)**?'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问：为什么我们要经历**这个复杂的编码过程**，而不是直接将标签对输入到一个函数中并获得一个得分——**f(query, sample)**？
- en: 'If you are familiar with vector-based search engines, you will already know
    the answer. By performing calculations by pairs, in the case of just 40,000 samples
    the computing power required is huge (can take up to **10 seconds for a single
    query**): it is not a scalable practice. However, if we choose to perform a vector
    retrieval of 40,000 samples, the search will finish in **0.1 seconds**: it is
    a highly scalable practice, which in our case is perfect.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉基于向量的搜索引擎，你已经知道答案了。通过对每一对进行计算，在仅仅40,000个样本的情况下，所需的计算力是巨大的（单次查询可能需要**10秒**）：这不是一种可扩展的做法。然而，如果我们选择对40,000个样本进行向量检索，搜索将在**0.1秒**内完成：这是一个高度可扩展的做法，在我们的案例中非常完美。
- en: 4\. Validate
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 验证
- en: For an algorithm to be effective, needs to be validated. For now, we lack a
    proper mathematical validation (at first sight, averaging similarity scores from
    M already shows very promising results, but further research is needed for an
    objective metric backed up by proof).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让一个算法有效，必须进行验证。目前，我们缺乏适当的数学验证（乍一看，从M中平均相似度得分已经显示出非常有前景的结果，但仍需要进一步研究，以便有一个客观的度量并且有证据支持）。
- en: However, existing results are quite intuitive when visualized using a comparative
    example. The following is the **top search result (what you are seeing are the
    tags assigned to this game)** of both search methods.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当使用对比示例进行可视化时，现有的结果是相当直观的。以下是两种搜索方法的**顶部搜索结果（您看到的是分配给此游戏的标签）**。
- en: '![](../Images/c69b5bc43d2afec62188a510b720321f.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c69b5bc43d2afec62188a510b720321f.png)'
- en: comparison between **traditional tag search** and **semantic tag search,** Image
    by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**传统标签搜索**与**语义标签搜索**的对比，图片由作者提供'
- en: '**Traditional tag search** We can see how traditional search might (without
    additional rules, samples are filtered based on the availability of all tags,
    and not sorted) return a sample with a higher number of tags, but many of them
    may not be relevant.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传统标签搜索**我们可以看到，传统搜索可能（没有额外规则时，样本是基于所有标签的可用性过滤的，而不是排序的）返回一个拥有更多标签的样本，但其中许多标签可能并不相关。'
- en: '**Semantic tag search**'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义标签搜索**'
- en: Semantic tag search sorts all samples based on the relevance of all tags, in
    simple terms, it **disqualifies samples containing irrelevant tags**.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语义标签搜索根据所有标签的相关性对所有样本进行排序，简而言之，它**排除包含无关标签的样本**。
- en: The real advantage of this new system is that when traditional search does not
    return enough samples, **we can select as many as we want** using semantic tag
    search.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新系统的真正优势在于，当传统搜索未能返回足够的样本时，**我们可以使用语义标签搜索选择任意数量的样本**。
- en: '![](../Images/8deb50b654d346627375b7d90a6963a5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8deb50b654d346627375b7d90a6963a5.png)'
- en: difference of the two searches in front of a scarcity of results, Image by author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果稀缺时，两种搜索的区别，图片由作者提供
- en: In the example above, using traditional tag filtering **does not return any
    game** from the Steam library. However, by using semantic tag filtering we still
    get results that are not perfect, but **the best ones matching our query**. The
    ones you are seeing are the tags of the top 5 games matching our search.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，使用传统的标签过滤**无法从Steam库中返回任何游戏**。然而，通过使用语义标签过滤，我们仍然能获得结果，虽然这些结果并不完美，但**是最符合我们查询的那些**。你所看到的这些是与我们搜索最匹配的前五款游戏的标签。
- en: Conclusion
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Before now, it was not possible to filter tags also taking into account their
    semantic relationships **without resorting to complex methods**, such as clustering,
    deep learning, or multiple knn searches.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，无法在不依赖复杂方法的情况下过滤标签，同时考虑到它们的语义关系，**例如聚类、深度学习或多个knn搜索**。
- en: The degree of flexibility offered by this algorithm **should allow the detachment
    from traditional manual labeling methods**, which force the user to choose between
    a pre-defined set of tags, and open the possibility of using LLMs of VLMs **to
    freely assign tags to a text or an image without being confined to a pre-existing
    structure**, opening up new options for scalable and improved search methods.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法所提供的灵活性**应该使其脱离传统的人工标签方法**，这些方法迫使用户在预定义的标签集之间做出选择，同时也开辟了使用LLM或VLM的可能性，**可以自由地为文本或图像分配标签，而不受限于预先存在的结构**，从而为可扩展且改进的搜索方法提供了新的选项。
- en: It is with my best wishes that I open this algorithm to the world, and I hope
    it will be utilized to its full potential.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我怀着最好的祝愿将这个算法开放给全世界，并希望它能够被充分利用。
