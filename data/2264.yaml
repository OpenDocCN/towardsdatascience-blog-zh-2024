- en: 'OpenAI o1: Is This the Enigmatic Force That Will Reshape Every Knowledge Sector
    We Know?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI o1：这是将重塑我们所知道的每个知识领域的神秘力量吗？
- en: 原文：[https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=collection_archive---------6-----------------------#2024-09-16](https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=collection_archive---------6-----------------------#2024-09-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=collection_archive---------6-----------------------#2024-09-16](https://towardsdatascience.com/openai-o1-the-enigmatic-force-that-will-reshape-every-knowledge-sector-that-we-know-of-or-99396d641fff?source=collection_archive---------6-----------------------#2024-09-16)
- en: My first encounters with the o1 model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我第一次接触 o1 模型
- en: '[](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)[![Abhinav
    Prasad Yasaswi](../Images/22731615708560c0826c9a17365e3bb9.png)](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)
    [Abhinav Prasad Yasaswi](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)[![Abhinav
    Prasad Yasaswi](../Images/22731615708560c0826c9a17365e3bb9.png)](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)
    [Abhinav Prasad Yasaswi](https://medium.com/@abhinavp_41237?source=post_page---byline--99396d641fff--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)
    ·6 min read·Sep 16, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99396d641fff--------------------------------)
    ·6分钟阅读·2024年9月16日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d5942dac6b543e469c097f7a8e02b6d2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5942dac6b543e469c097f7a8e02b6d2.png)'
- en: An image generated by DALL-E with a prompt precisely the same as the blog title.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 DALL-E 生成的一幅图像，提示与博客标题完全相同。
- en: My first encounters with the o1 model
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我第一次接触 o1 模型
- en: On the 12th of September at 10:00 a.m., I was in the class “**Frontier Topics
    in Generative AI**,” a graduate-level course at Arizona State University. A day
    before this, on the 11th of September, I submitted a team assignment that involved
    trying to identify flaws and erroneous outputs generated by GPT-4 (essentially
    trying to prompt GPT-4 to see if it makes mistakes on trivial questions or high-school-level
    reasoning questions) as part of another graduate-level class “**Topics in Natural
    Language Processing.”** We identified several trivial mistakes that GPT-4 made,
    one of them being *unable to count the number of r’s in the word strawberry*.
    Before submitting this assignment, I researched several peer-reviewed papers on
    the internet that identified where and why GPT -4 made mistakes and how you could
    rectify them. Most of the documents I came across identified two main domains
    where GPT-4 erred, and they dealt with **planning and reasoning**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年9月12日上午10点，我正在亚利桑那州立大学的“**生成式人工智能前沿课题**”课堂上上课。这是一个研究生水平的课程。就在前一天，即9月11日，我提交了一份团队作业，内容是尝试识别
    GPT-4 生成的缺陷和错误输出（本质上是通过提示 GPT-4，看看它是否会在琐碎问题或高中水平推理问题上犯错），这是另一个研究生课程“**自然语言处理课题**”的一部分。我们识别出了
    GPT-4 的几个小错误，其中之一是 *无法数出单词 strawberry 中字母 r 的数量*。在提交这份作业之前，我在网上查阅了几篇同行评审的论文，这些论文指出了
    GPT-4 出错的地方和原因，以及如何改正这些错误。我看到的大多数文献指出了 GPT-4 出错的两个主要领域，分别是 **规划和推理**。
- en: This paper¹ (although almost a year old) goes in depth through several cases
    where GPT-4 fails to answer trivial questions that involve simple counting, simple
    arithmetic, elementary logic, and even common sense. The paper¹ reasons that these
    questions require some level of reasoning and that because GPT-4 is utterly incapable
    of reasoning, it almost always gets these questions wrong. The author also states
    that reasoning is a (very) computationally hard problem. Although GPT-4 is very
    compute-intensive, its **compute-intensive nature is not geared towards involving
    reasoning** in solving the questions that it’s prompted with. Several other papers
    echo this notion of GPT-4 being unable to reason or plan²³.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇论文¹（尽管已接近一年）深入探讨了多个案例，其中 GPT-4 无法回答一些涉及简单计数、简单算术、基础逻辑，甚至常识的 trivial 问题。论文¹
    认为这些问题需要一定程度的推理，而 GPT-4 完全无法进行推理，因此几乎总是会答错这些问题。作者还指出，推理是一个（非常）计算上困难的问题。尽管 GPT-4
    计算资源密集，但它的**计算密集型特性并未针对涉及推理的问答设计**。其他几篇论文也呼应了 GPT-4 无法推理或规划²³的观点。
- en: Well, let’s get back to the 12th of September. My class ends at around 10:15
    a.m., and I come back straight home from class and open up YouTube on my phone
    as I dig into my morning brunch. The first recommendation on my YouTube homepage
    was a video from OpenAI announcing the release of GPT-o1 named “[Building OpenAI
    o1](https://youtu.be/3k89FMJhZ00?feature=shared)”. They announced that this model
    is a straight-up a **reasoning model** and that it would take more time to reason
    and answer your questions providing more accurate answers. They state that they
    have put more compute time into RL (Reinforcement Learning) than previous models
    to generate coherent ***chains-of-thoughts⁴***. Essentially, they have trained
    the chain of thought generation process using Reinforcement learning (to generate
    and hone its own generated chain of thought process). In the o1 models, the engineers
    were able to ask the model questions as to why it was wrong (whenever it was wrong)
    in its chain-of-thought process and it could identify the mistakes and correct
    itself from them. The model could question itself and have to reflect (see “Reflection
    in LLMs”) on its outputs and correct itself.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们回到9月12日。我的课大约在上午10:15结束，然后我直接从课堂回到家，打开手机上的 YouTube，一边享用我的早午餐。我的 YouTube
    首页上的第一个推荐视频是 OpenAI 发布的名为 “[Building OpenAI o1](https://youtu.be/3k89FMJhZ00?feature=shared)”
    的视频。他们宣布这个模型是一个专门的**推理模型**，并表示它将在推理和回答问题时花费更多时间，从而提供更准确的答案。他们表示，在 RL（强化学习）方面投入的计算时间比之前的模型更多，以生成连贯的***思维链⁴***。实质上，他们使用强化学习训练了思维链生成过程（以生成和完善自身生成的思维链过程）。在
    o1 模型中，工程师们可以向模型提出问题，询问它在思维链过程中为什么会出错（每当它出错时），模型可以识别出错误并自我纠正。模型可以自我质疑并反思（见“LLM中的反思”）其输出并加以修正。
- en: 'In another video “[Reasoning with OpenAI o1](https://youtu.be/3BkQI3nIiB8?feature=shared)”,
    [Jerry Tworek](https://www.linkedin.com/in/jerry-tworek-b5b9aa56/) demonstrates
    how previous OpenAI and most other LLMs in the market tend to fail on the following
    prompt:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个视频 “[Reasoning with OpenAI o1](https://youtu.be/3BkQI3nIiB8?feature=shared)”
    中，[Jerry Tworek](https://www.linkedin.com/in/jerry-tworek-b5b9aa56/) 展示了之前的 OpenAI
    模型和市场上大多数其他大型语言模型（LLM）在以下提示上通常会失败：
- en: “Assume the laws of physics on earth. A small strawberry is put into a normal
    cup and the cup is placed upside down on a table. Someone then takes the cup and
    puts it inside the microwave. Where is the strawberry now? Explain your reasoning
    step by step.”
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “假设地球上的物理定律成立。将一个小草莓放入一个普通的杯子里，并将杯子倒扣放在桌子上。然后，有人把这个杯子放入微波炉。现在草莓在哪里？请逐步解释你的推理过程。”
- en: 'Legacy GPT-4 answers as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 GPT-4 的传统答案：
- en: '![](../Images/bb0dcbe3c0b129811486cf62d8eead58.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb0dcbe3c0b129811486cf62d8eead58.png)'
- en: 'Figure 1: GPT-4 getting the strawberry in a cup question wrong'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GPT-4 在草莓杯子问题上的错误回答
- en: 'The relatively newer GPT-4o also gets it wrong:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 相对较新的 GPT-4o 也答错了：
- en: '![](../Images/bc13c3a9bd503719a5b4d33cbdff2240.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc13c3a9bd503719a5b4d33cbdff2240.png)'
- en: 'Figure 2: GPT-4 o getting the strawberry in a cup question wrong'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：GPT-4 o 在草莓杯子问题上的错误回答
- en: 'GPT o1 gets the answer right:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GPT o1 给出了正确答案：
- en: '![](../Images/e05827f6ff9242c81afa26fb4d112eae.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e05827f6ff9242c81afa26fb4d112eae.png)'
- en: 'Figure 3: GPT o1 getting the answer to the strawberry in a cup question right'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：GPT o1 在草莓杯子问题上的正确回答
- en: If you click on the dropdown at the beginning of the model’s response (see Figure
    4), you know that it elicits its thought process (chain-of-thought), and the researchers
    at OpenAI claim that the o1 model has been trained with reinforcement learning
    to get this chain of thought better. Also, it’s interesting to note that [Jason
    Wei](https://www.linkedin.com/in/jason-wei-5a7323b0/) (you can see him sitting
    third from the right on the bottom row in the video “[Building OpenAI o1](https://youtu.be/3k89FMJhZ00?feature=shared)”),
    the author of the chain-of-thought paper⁴ that he published back at Google, is
    now an OpenAI employee that is working on the o1 model to integrate the chain-of-thought
    (that he discovered at Google) process into this model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你点击模型回答开头的下拉菜单（见图4），你会看到它展示了自己的思考过程（链式思维），OpenAI的研究人员声称o1模型已经通过强化学习训练，使这个思考链变得更加完善。另外，有趣的是，[Jason
    Wei](https://www.linkedin.com/in/jason-wei-5a7323b0/)（你可以在视频《[构建OpenAI o1](https://youtu.be/3k89FMJhZ00?feature=shared)》中看到他坐在底行第三个位置），他曾在Google发布了链式思维的论文，现在是OpenAI的员工，正在致力于将他在Google发现的链式思维过程整合到o1模型中。
- en: '![](../Images/782b733ada9d6169722aa4ce2703e984.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/782b733ada9d6169722aa4ce2703e984.png)'
- en: 'Figure 4: Chain-of-thought elicitation by GPT o1'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：GPT o1的链式思维引导
- en: Now, let’s get back to the counting question that my team found out about as
    part of my assignment.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到我的团队在我的任务中发现的计数问题。
- en: How many r’s are in the word strawberry?
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 草莓这个词中有多少个字母r？
- en: 'Let’s run this question on GPT-4o:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在GPT-4o上运行这个问题：
- en: '![](../Images/a5804ab99e4ef3d95165148948f10df5.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5804ab99e4ef3d95165148948f10df5.png)'
- en: 'Figure 5: GPT4o getting the number of r’s in strawberry question wrong.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：GPT4o在回答草莓问题时，错误地计算了字母r的个数。
- en: A very simple counting problem that it get’s wrong.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常简单的计数问题，它做错了。
- en: 'Let’s run this on the new GPT o1:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在新的GPT o1上运行这个问题：
- en: '![](../Images/bab8fe662094f3e72eb9d9a886e6daa7.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bab8fe662094f3e72eb9d9a886e6daa7.png)'
- en: 'Figure 6: GPT o1 getting the number of r’s in strawberry question right.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：GPT o1正确地回答了草莓问题中字母r的个数。
- en: GPT o1 gets the answer right by thinking for a couple of seconds. The researchers
    at OpenAI say that it goes through its response repeatedly and thinks its way
    to the right answer. There does seem to be really significant improvements in
    terms of the model’s ability to solve a lot of academic exam questions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: GPT o1通过思考几秒钟后得出了正确答案。OpenAI的研究人员表示，它会反复检查自己的回答，并通过思考找到正确的答案。看来模型在解决许多学术考试问题方面确实有了显著的进步。
- en: Anyways after I opened up X.com (Formerly Twitter), I came across several people
    showcasing their attempts at trying to make the o1 model fail. This is a fascinating
    one I came across (this [tweet](https://x.com/creeoer/status/1834588136749388035)
    by @creeor) where the model fails to answer a trivial question in which the answer
    lies in the question itself. So I tried the exact same prompt on my account and
    it gave me the wrong answer (see Figure 7).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不管怎样，在我打开X.com（前身为Twitter）后，我看到几个人展示了他们试图让o1模型失败的尝试。这是我看到的一个有趣的例子（来自@creeor的[this
    tweet](https://x.com/creeoer/status/1834588136749388035)），在这个例子中，模型未能回答一个非常简单的问题，而答案就在问题本身。于是我在我的账户上尝试了完全相同的提示，但它给出了错误的答案（见图7）。
- en: '![](../Images/a308a9ce3906f01eddd5001ca4a82df6.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a308a9ce3906f01eddd5001ca4a82df6.png)'
- en: 'Figure 7: OpenAI o1 is still getting simple riddles wrong when you tweak the
    riddle. Shows that the models still rely on a lot of the memorization that happened
    during it’s training and isn’t fully using it’s reasoning capabilities.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：即使在调整谜语后，OpenAI o1仍然无法解答简单的谜题。显示出模型仍然依赖于它在训练过程中记住的很多内容，并没有充分发挥其推理能力。
- en: When I ask it what this classic riddle is that it is talking about it tells
    me about a riddle that it memorized from the internet. It’s interesting to see
    how these models can sometimes fall back on memorized content rather than truly
    reasoning through a problem. Despite the significant advancements and [benchmark](https://cdn.openai.com/o1-system-card.pdf)
    improvements, there are still areas where AI models struggle, especially with
    tasks that require deeper reasoning or understanding context in a nuanced way.
    While benchmarks can show progress, real-world applications often reveal the limitations.
    It’s through continuous testing, feedback, and real-world use cases that these
    models can be further refined.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我问它它在谈论的这个经典谜语是什么时，它告诉我一个它从互联网记住的谜语。很有趣的是，看到这些模型有时会依赖于记忆的内容，而不是通过真正的推理来解决问题。尽管在[基准测试](https://cdn.openai.com/o1-system-card.pdf)上有了显著进展和改进，但AI模型在某些领域仍然存在困难，特别是在那些需要深入推理或以细致的方式理解上下文的任务中。尽管基准测试可以显示进展，实际应用往往暴露了其局限性。正是通过持续的测试、反馈和实际应用案例，这些模型才能不断得到完善。
- en: '![](../Images/9b25f1703d94524a7f99069f24231a57.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b25f1703d94524a7f99069f24231a57.png)'
- en: 'Figure 8: o1 blindly answers from a riddle it memorized. It doesn’t read the
    question that was given to it and try to answer it as presented.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：o1盲目地从它记住的谜语中回答问题。它没有阅读给定的问题，并尝试按所呈现的方式作答。
- en: There was a [compilation](https://medium.com/@aliborji/a-categorical-archive-of-chatgpt-failures-2c888805d3c3)
    of ChatGPT failures done about a year and a half back. Compilations of model errors
    are invaluable for understanding and improving AI systems. I’m sure people will
    come up with another compilation of errors for the o1 model soon.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 大约一年半前曾有一份关于[ChatGPT错误汇编](https://medium.com/@aliborji/a-categorical-archive-of-chatgpt-failures-2c888805d3c3)。模型错误的汇编对于理解和改进AI系统非常宝贵。我相信人们很快会推出一份关于o1模型的错误汇编。
- en: Although I agree entirely that the chain-of-thought process benefits both AI
    and human learning, real learning indeed comes from experience and making mistakes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我完全同意链式思维过程有利于AI和人类的学习，但真正的学习确实来自于经验和犯错误。
- en: I will continue to keep posting my findings on the o1 model on my Medium page.
    Follow my account to keep posted. And thank you for taking the time to read my
    Medium post.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我将继续在我的Medium页面上发布关于o1模型的发现。关注我的账户以保持更新。感谢你抽时间阅读我的Medium文章。
- en: 'References:'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[1] Arkoudas, Konstantine. “GPT-4 can’t reason.” *arXiv preprint arXiv:2308.03762*
    (2023).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Arkoudas, Konstantine。“GPT-4无法推理。” *arXiv预印本 arXiv:2308.03762*（2023年）。'
- en: '[2] Aghzal, Mohamed, Erion Plaku, and Ziyu Yao. “Look Further Ahead: Testing
    the Limits of GPT-4 in Path Planning.” *arXiv preprint arXiv:2406.12000* (2024).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Aghzal, Mohamed, Erion Plaku 和 Ziyu Yao。“往前看：测试GPT-4在路径规划中的极限。” *arXiv预印本
    arXiv:2406.12000*（2024年）。'
- en: '[3] Kambhampati, Subbarao, et al. “LLMs Can’t Plan, But Can Help Planning in
    LLM-Modulo Frameworks.” *arXiv preprint arXiv:2402.01817* (2024).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Kambhampati, Subbarao 等人。“LLMs不能规划，但可以在LLM-Modulo框架中帮助规划。” *arXiv预印本 arXiv:2402.01817*（2024年）。'
- en: '[4] Wei, Jason, et al. “Chain-of-thought prompting elicits reasoning in large
    language models.” *Advances in neural information processing systems* 35 (2022):
    24824–24837.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Wei, Jason 等人。“链式思维提示在大型语言模型中引发推理。” *神经信息处理系统进展* 35（2022年）：24824–24837。'
