- en: 'Breaking It Down : Chunking for Better RAG'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析：为更好的RAG进行分块
- en: 原文：[https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23](https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23](https://towardsdatascience.com/breaking-it-down-chunking-techniques-for-better-rag-3fd288bf25a0?source=collection_archive---------3-----------------------#2024-09-23)
- en: Mastering chunking for efficient retrieval in RAG systems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 掌握分块技术以提高RAG系统中的信息检索效率
- en: '[](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[![Abhinav
    Kimothi](../Images/ed5548c99e1910e7dc35bfcac26cb314.png)](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    [Abhinav Kimothi](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[![Abhinav
    Kimothi](../Images/ed5548c99e1910e7dc35bfcac26cb314.png)](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    [Abhinav Kimothi](https://medium.com/@abhinavkimothi?source=post_page---byline--3fd288bf25a0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    ·16 min read·Sep 23, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fd288bf25a0--------------------------------)
    ·阅读时长：16分钟·2024年9月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/abcbc7730840cce9e65a7c001518abe9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abcbc7730840cce9e65a7c001518abe9.png)'
- en: 'Chunking is a crucial component of RAG systems (Source: AI Image generated
    by the author using FLUX)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 分块是RAG系统中的关键组成部分（来源：作者使用FLUX生成的AI图像）
- en: 'Preamble : RAG and the need for a Knowledge Base'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言：RAG和知识库的需求
- en: In a short time, **Large Language Models (LLMs)** have found a wide applicability
    in modern language processing tasks and even paved the way for autonomous AI agents.
    There are high chances that you’ve heard about, if not personally used, ChatGPT.
    ChatGPT is powered by a generative AI technique called Large Language Models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在短短的时间里，**大语言模型（LLMs）**已经在现代语言处理任务中找到了广泛的应用，甚至为自主AI代理铺平了道路。你很可能听说过（如果没有亲自使用过）ChatGPT。ChatGPT由一种叫做大语言模型的生成式AI技术驱动。
- en: '**Retrieval Augmented Generation**, or **RAG**, has emerged to be one of the
    most popular techniques in the applied generative AI world. Despite Large Language
    Models demonstrating unprecedented ability to generate text, their responses are
    not always correct. Upon more careful observation, you may notice that LLM responses
    are plagued with sub-optimal information and inherent memory limitations. [RAG
    addresses these limitations of LLMs by providing them with information external
    to these models.](https://arxiv.org/abs/2005.11401) Thereby, resulting in LLM
    responses that are more reliable and trustworthy. The basic concept of RAG is
    *illustrated in the example below*. Here we provide external information to ChatGPT
    (manually) to make it respond accurately.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索增强生成（RAG）**已成为应用生成AI领域中最流行的技术之一。尽管大语言模型展示了前所未有的文本生成能力，但它们的回答并不总是准确的。经过更仔细的观察，你可能会发现，LLM的回答常常存在次优信息和固有的记忆限制。[RAG通过为这些模型提供外部信息来解决LLM的这些局限性。](https://arxiv.org/abs/2005.11401)
    这样，LLM的回答变得更加可靠和值得信赖。RAG的基本概念 *如下示例所示*。在这里，我们向ChatGPT提供外部信息（手动）以使其准确回答。'
