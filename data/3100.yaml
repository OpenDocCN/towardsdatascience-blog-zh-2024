- en: 'Mastering Model Uncertainty: Thresholding Techniques in Deep Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握模型不确定性：深度学习中的阈值技术
- en: 原文：[https://towardsdatascience.com/mastering-model-uncertainty-thresholding-techniques-in-deep-learning-1f1ab3912fd1?source=collection_archive---------4-----------------------#2024-12-30](https://towardsdatascience.com/mastering-model-uncertainty-thresholding-techniques-in-deep-learning-1f1ab3912fd1?source=collection_archive---------4-----------------------#2024-12-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mastering-model-uncertainty-thresholding-techniques-in-deep-learning-1f1ab3912fd1?source=collection_archive---------4-----------------------#2024-12-30](https://towardsdatascience.com/mastering-model-uncertainty-thresholding-techniques-in-deep-learning-1f1ab3912fd1?source=collection_archive---------4-----------------------#2024-12-30)
- en: '![](../Images/362f6c4b9a404f01233bdc391dd4bce7.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/362f6c4b9a404f01233bdc391dd4bce7.png)'
- en: Image generated by Dall-e
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由Dall-e生成
- en: A few words on thresholding, the softmax activation function, introducing an
    extra label, and considerations regarding output activation functions.
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一些关于阈值处理、softmax激活函数、引入额外标签以及关于输出激活函数的考虑事项。
- en: '[](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)[![Hampus
    Gustavsson](../Images/a22f27fc40e4a612058379928d30f609.png)](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)
    [Hampus Gustavsson](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)[![Hampus
    Gustavsson](../Images/a22f27fc40e4a612058379928d30f609.png)](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)
    [Hampus Gustavsson](https://medium.com/@hampusg?source=post_page---byline--1f1ab3912fd1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)
    ·6 min read·5 days ago
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1f1ab3912fd1--------------------------------)
    ·6分钟阅读·5天前
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In many real-world applications, machine learning models are not designed to
    make decisions in an all-or-nothing manner. Instead, there are situations where
    it is more beneficial for the model to flag certain predictions for human review
    — a process known as human-in-the-loop. This approach is particularly valuable
    in high-stakes scenarios such as fraud detection, where the cost of false negatives
    is significant. By allowing humans to intervene when a model is uncertain or encounters
    complex cases, businesses can ensure more nuanced and accurate decision-making.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多现实世界的应用中，机器学习模型并不是为了以“全有或全无”的方式做出决策。相反，存在一些情形，模型标记某些预测以供人工审查会更为有益——这一过程称为“人类参与”方法。这种方法在高风险场景中尤其有价值，例如欺诈检测，在这些场景中，假阴性（漏检）带来的成本非常高。通过在模型不确定或遇到复杂案例时允许人工干预，企业可以确保更加细致和准确的决策。
- en: In this article, we will explore how thresholding, a technique used to manage
    model uncertainty, can be implemented within a deep learning setting. Thresholding
    helps determine when a model is confident enough to make a decision autonomously
    and when it should defer to human judgment. This will be done using a real-world
    example to illustrate the potential.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨如何在深度学习环境中实现一种用于管理模型不确定性的技术——阈值处理。阈值处理帮助确定模型何时足够自信以自主做出决策，何时应该将决策交给人工判断。我们将使用一个现实世界的例子来说明其潜力。
- en: By the end of this article, the hope is to provide both technical teams and
    business stakeholders with some tips and inspiration for making decisions about
    modelling, thresholding strategies, and the balance between automation and human
    oversight.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的结尾，目标是为技术团队和业务利益相关者提供一些关于建模、阈值策略以及自动化与人工监督之间平衡的决策建议和启发。
- en: 'Business Case: Detecting Fraudulent Transactions with Confidence'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业案例：通过信心检测欺诈交易
- en: To illustrate the value of thresholding in a real-world situation, let’s consider
    the case of a financial institution tasked with detecting fraudulent transactions.
    We’ll use the [Kaggle fraud detection dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)
    (DbCL license), which contains anonymized transaction data with labels for fraudulent
    activity. The institutions process lots of transactions, making it difficult to
    manually review each one. We want to develop a system that accurately flags suspicious
    transactions while minimizing unnecessary human intervention.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明阈值化在现实情况中的价值，我们来考虑一个金融机构检测欺诈交易的案例。我们将使用 [Kaggle 欺诈检测数据集](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)（DbCL
    许可），该数据集包含匿名化的交易数据和欺诈活动标签。金融机构处理大量交易，手动审核每一笔交易非常困难。我们希望开发一个系统，既能准确标记可疑交易，又能最大限度减少不必要的人工干预。
- en: The challenge lies in balancing precision and efficiency. Thresholding is a
    strategy used to introduce this trade-off. With this strategy we add an additional
    label to the sample space—*unknown*. This label serves as a signal from the model
    when it is uncertain about a particular prediction, effectively deferring the
    decision to human review. In situations where the model lacks enough certainty
    to make a reliable prediction, marking a transaction as unknown ensures that only
    the most confident predictions are acted upon.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战在于平衡精度和效率。阈值化是一种用于引入这种权衡的策略。通过这种策略，我们为样本空间添加了一个额外的标签——*未知*。当模型对某个特定预测不确定时，这个标签作为模型的信号，实际上是将决策推迟到人工审核。当模型缺乏足够的确定性来做出可靠预测时，将交易标记为未知可以确保只有最有信心的预测会被执行。
- en: Also, thresholding might come with another positive side effect. It helps overcome
    potential tech skepticism. When a model indicates uncertainty and defers to human
    judgment when needed, it can foster greater trust in the system. In previous projects,
    this has been of help when rolling projects out in various organisations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，阈值化可能还会带来另一个积极的副作用。它有助于克服潜在的技术怀疑。当模型表示不确定并在需要时将决策推迟给人工判断时，可以增强对系统的信任。在之前的项目中，这在将项目推向各个组织时非常有帮助。
- en: '**Technical and analytical aspects.**'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**技术和分析方面。**'
- en: We will explore the concept of thresholding in a deep learning context. However,
    it’s important to note that thresholding is a model agnostic technique with application
    across various types of situations, not just deep learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨阈值化在深度学习中的应用。然而，值得注意的是，阈值化是一种与模型无关的技术，适用于各种类型的情况，而不仅仅是深度学习。
- en: When implementing a thresholding step in a neural network, it is not obvious
    in what layer to put it. In a classification setting, an output transformation
    can be implemented. The sigmoid function is an option, but also a softmax function.
    Softmax offers a very practical transformation, making the logits adhere to certain
    nice statistical properties. These properties are that we are guaranteed logits
    will sum to one, and they will all be between zero and one.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中实现阈值化步骤时，放在哪个层并不明显。在分类设置中，可以实现输出转换。sigmoid 函数是一种选择，但也可以使用 softmax 函数。Softmax
    提供了一种非常实用的转换，使得 logits 符合某些良好的统计性质。这些性质确保了 logits 的和为 1，并且它们都在 0 和 1 之间。
- en: '![](../Images/1a79c75ed309e956b5de3d6d00cd0871.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a79c75ed309e956b5de3d6d00cd0871.png)'
- en: Softmax function. Image by author.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax 函数。图片由作者提供。
- en: However, in this process, some information is lost. Softmax captures only the
    relative certainty between labels. It does not provide an absolute measure of
    certainty for any individual label, which in turn can lead to overconfidence in
    cases where the true distribution of uncertainty is more nuanced. This limitation
    becomes critical in applications requiring precise decision thresholds.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这个过程中，某些信息会丢失。Softmax 仅捕捉标签之间的相对确定性。它并没有提供任何单一标签的绝对确定性度量，这可能会导致在真实的不确定性分布更为复杂的情况下出现过度自信。这一限制在需要精确决策阈值的应用中变得尤为关键。
- en: This article will not delve into the details of the model architecture, as these
    are covered in an upcoming article for those interested. The only thing being
    used from the model are the outcomes before and after the softmax transformation
    has been implemented, as the final layer. A sample of the output is depicted here.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本文不会深入探讨模型架构的细节，因为这些内容将在未来的文章中讨论，供感兴趣的读者参考。本文使用的只是模型在进行 softmax 转换前后的输出结果，作为最终层。这里展示了输出的一个示例。
- en: '![](../Images/823ba6e84288bea4f7529fc4e4ea1589.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/823ba6e84288bea4f7529fc4e4ea1589.png)'
- en: Sample of twenty predictions, after softmax has been applied.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 二十个预测样本，软最大（softmax）应用之后。
- en: As seen, the outputs are rather homogenic. And without knowing the mechanics
    of the softmax, it looks as if the model is pretty certain about the classifications.
    But as we will see further down in the article, the strong relationship we are
    capturing here is not the true certainty of the labels. Rather, this is to be
    interpreted as one label’s predictions in comparison with the other. In our case,
    this means the model may capture some labels as being significantly more likely
    than others, but it does not reflect the overall certainty of the model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，输出相当均匀。没有了解softmax的机制时，看起来模型对于分类相当确定。但正如我们将在文章后面看到的那样，我们在这里捕捉到的强关系并非标签的真正确定性。实际上，这应当被解释为一个标签相对于其他标签的预测。在我们的例子中，这意味着模型可能会捕捉到某些标签的概率明显高于其他标签，但这并不反映模型的整体确定性。
- en: With this understanding of the interpretation of the outputs, let’s explore
    how the model performs in practice. Looking at the confusion matrix.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了输出的解释后，让我们探讨一下模型在实际中的表现。查看混淆矩阵。
- en: '![](../Images/6c8238de46a1322572c563248f2d7e54.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c8238de46a1322572c563248f2d7e54.png)'
- en: Confusion matrix for the entire, un-thresholded test dataset.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 整个未经过阈值处理的测试数据集的混淆矩阵。
- en: The model does not perform terribly, although it is far from perfect. With these
    base results at hand, we will look into implementing a threshold.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的表现并不差，尽管远非完美。有了这些基础结果，我们将探讨如何实现阈值处理。
- en: We will be starting out going one layer into the network — examining the values
    right before the final activation function. This renders the following logits.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从进入网络的一层开始——检查最终激活函数之前的值。这些值呈现出以下logits。
- en: '![](../Images/aaf508678b1d63c8b07461d6962425af.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aaf508678b1d63c8b07461d6962425af.png)'
- en: Sample of twenty predictions, before softmax transformation have been applied.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 二十个预测样本，软最大（softmax）变换应用之前。
- en: Here we see a larger variety of values. This layer provides a more detailed
    view of the model’s uncertainty in its predictions and it is here where the threshold
    layer is inserted.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到更丰富的数值种类。这一层提供了模型在预测中的不确定性的更详细视图，这也是阈值层被插入的位置。
- en: By introducing an upper and lower confidence threshold, the model only labels
    approximately 34% of the dataset, focusing on the most certain predictions. But
    in turn, the results are more certain, depicted in the following confusion matrix.
    It’s important to note that thresholding does not have to be uniform. For example,
    some labels may be more difficult to predict than others, and label imbalance
    can also affect the thresholding strategy.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入上下置信度阈值，模型仅对大约34%的数据集进行标记，集中关注最确定的预测。然而，反过来，结果更加确定，如下所示的混淆矩阵所示。值得注意的是，阈值处理不一定是统一的。例如，某些标签可能比其他标签更难预测，标签不平衡也可能影响阈值策略。
- en: '![](../Images/b778128979b220c8af4da135407381a1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b778128979b220c8af4da135407381a1.png)'
- en: Confusion matrix after thresholding have been applied.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值处理应用后的混淆矩阵。
- en: '**Metrics**.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**指标**。'
- en: In this scenario, we have only touched upon the two edge cases in thresholding;
    the ones letting all predictions through (base case) and the ones that removed
    all faulty predictions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们仅触及了阈值处理中的两个极端情况；一个是让所有预测通过（基本情况），另一个是移除所有错误预测。
- en: Based on practical experience, deciding whether to label fewer data points with
    high certainty (which might reduce the total number of flagged transactions) or
    label more data points with lower certainty is quite a complex trade-off. This
    decision can impact operational efficiency and could be informed by business priorities,
    such as risk tolerance or operational constraints. Discussing this together with
    subject matter experts is a perfectly viable way of figuring out the thresholds.
    Another, is if you are able to optimise this in conjunction with a known or approximated
    metric. This can be done by aligning thresholds with specific business metrics,
    such as cost per false negative or operational capacity.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据实际经验，决定是用较高的确定性标记较少的数据点（这可能减少被标记的事务总数），还是用较低的确定性标记更多的数据点，是一个相当复杂的权衡决策。这个决策会影响操作效率，并可能受到业务优先级的影响，例如风险容忍度或操作约束。与领域专家一起讨论这个问题，是找出阈值的一个完全可行的方式。另一种方法是，如果您能够结合已知或近似的度量指标进行优化。可以通过将阈值与特定的业务指标对齐来实现，比如每个假阴性成本或操作能力。
- en: '**Summarization.**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结。**'
- en: In conclusion, the goal is not to discard the softmax transformation, as it
    provides valuable statistical properties. Rather, we suggest introducing an intermediate
    threshold layer to filter out uncertain predictions and leave room for an unknown
    label when necessary.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，目标并不是丢弃 softmax 转换，因为它提供了有价值的统计特性。我们建议引入一个中间阈值层，用于筛选不确定的预测，并在必要时为未知标签留出空间。
- en: The exact way to implement this I believe comes down to the project at hand.
    The fraud example also highlights the importance of understanding the business
    need aimed to solve. Here, we showed an example where we had thresholded away
    all faulty predictions, but this is not at all necessary in all use cases. In
    many cases, the optimal solution lies in finding a balance between accuracy and
    coverage.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为，实施的具体方式取决于手头的项目。欺诈的例子也突显了理解解决的业务需求的重要性。在这里，我们展示了一个例子，我们已经通过阈值排除了所有错误的预测，但这并非所有用例中的必需做法。在许多情况下，最佳解决方案是在准确性和覆盖率之间找到平衡。
- en: '**Thank you for taking the time to explore this topic.**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢您花时间探索这个话题。**'
- en: I hope you found this article useful and/or inspiring. If you have any comments
    or questions, please reach out. You can also connect with me on [LinkedIn](https://www.linkedin.com/in/hampus-gustavsson-23721a116/).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望您觉得这篇文章有用和/或富有启发。如果您有任何评论或问题，请随时与我联系。您也可以通过[LinkedIn](https://www.linkedin.com/in/hampus-gustavsson-23721a116/)与我建立联系。
