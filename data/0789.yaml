- en: Learning to Rank — Contextual Item Recommendations for User Pairs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习排序 — 针对用户对的情境项目推荐
- en: 原文：[https://towardsdatascience.com/learning-to-rank-contextual-item-recommendations-for-user-pairs-dc4f56e24d94?source=collection_archive---------6-----------------------#2024-03-26](https://towardsdatascience.com/learning-to-rank-contextual-item-recommendations-for-user-pairs-dc4f56e24d94?source=collection_archive---------6-----------------------#2024-03-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/learning-to-rank-contextual-item-recommendations-for-user-pairs-dc4f56e24d94?source=collection_archive---------6-----------------------#2024-03-26](https://towardsdatascience.com/learning-to-rank-contextual-item-recommendations-for-user-pairs-dc4f56e24d94?source=collection_archive---------6-----------------------#2024-03-26)
- en: Train a Machine Learning recommendation engine that learns the shared preferences
    of groups of people
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练一个机器学习推荐引擎，学习一群人共同的偏好
- en: '[](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)[![Jay
    Franck](../Images/8a8bd2265c46453036916ebda2adf119.png)](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)
    [Jay Franck](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)[![Jay
    Franck](../Images/8a8bd2265c46453036916ebda2adf119.png)](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)
    [Jay Franck](https://medium.com/@franckjay?source=post_page---byline--dc4f56e24d94--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)
    ·6 min read·Mar 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dc4f56e24d94--------------------------------)
    ·阅读时长6分钟·2024年3月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/10746b4c52d60313deafae632ae91b48.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10746b4c52d60313deafae632ae91b48.png)'
- en: Photo by [Lucrezia Carnelos](https://unsplash.com/@ciabattespugnose?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Lucrezia Carnelos](https://unsplash.com/@ciabattespugnose?utm_source=medium&utm_medium=referral)于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This walkthrough is for…
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本文教程适合…
- en: Anyone interested in DIY recommendations
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任何对DIY推荐感兴趣的人
- en: Engineers interested in basic PyTorch ranking models
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对基本的PyTorch排序模型感兴趣的工程师
- en: Coffee nerds
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 咖啡迷
- en: This walkthrough is not for…
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本文教程不适合…
- en: Someone who wants to copy-paste code into their production system
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 想要将代码复制粘贴到生产系统中的人
- en: Folks that wanted a TensorFlow model
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 想要一个TensorFlow模型的人
- en: Motivation
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: Imagine you are sitting on your couch, friends or family present. You have your
    preferred game console/streaming service/music app open, and each item is a glittering
    jewel of possibility, tailored for you. But those personalized results may be
    for the solo version of yourself, and do not reflect the version of yourself when
    surrounded by this particular mix of others.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正坐在沙发上，朋友或家人陪伴在侧。你打开了自己喜爱的游戏主机/流媒体服务/音乐应用，每一项都像是闪闪发光的可能性之宝，为你量身定制。但这些个性化的结果可能只是你独自一人的版本，并不能反映你在这群人中时的样子。
- en: This project truly started with coffee. I am enamored with roasting my own green
    coffee sourced from Sweet Maria’s (no affiliation), as it has such a variety of
    delicious possibilities. [Colombian](https://www.sweetmarias.com/colombia-honey-aponte-hugo-agreda-7759.html)?
    [Java-beans](https://www.sweetmarias.com/java-dry-process-kuningan-robusta-7286.html)?
    [Kenyan Peaberry](https://www.sweetmarias.com/kenya-kiambu-ngaita-peaberry-7241.html)?
    Each description is more tantalizing than the last. It is so hard to choose even
    for myself as an individual. What happens if you are buying green coffee for your
    family or guests?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目真的是从咖啡开始的。我迷恋自己烘焙来自Sweet Maria's（无任何关联）的绿咖啡豆，因为它有各种美味的可能性。[哥伦比亚](https://www.sweetmarias.com/colombia-honey-aponte-hugo-agreda-7759.html)?
    [爪哇豆](https://www.sweetmarias.com/java-dry-process-kuningan-robusta-7286.html)?
    [肯尼亚圆粒](https://www.sweetmarias.com/kenya-kiambu-ngaita-peaberry-7241.html)? 每一种描述都比上一种更加诱人。即使是我自己作为个人，也很难做出选择。如果你是为家人或客人购买绿咖啡豆，情况会怎样呢？
- en: I wanted to create a Learning to Rank (LTR) model that could potentially solve
    this coffee conundrum. For this project, I began by building a simple [TensorFlow
    Ranking](https://www.tensorflow.org/ranking) project to predict user-pair rankings
    of different coffees. I had some experience with TFR, and so it seemed like a
    natural fit.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我想创建一个“学习排名”（LTR）模型，可能解决这个咖啡难题。对于这个项目，我首先构建了一个简单的 [TensorFlow Ranking](https://www.tensorflow.org/ranking)
    项目，来预测不同咖啡的用户对偶排名。我对 TFR 有一些经验，因此它似乎是一个自然的选择。
- en: However, I realized I had never made a ranking model from scratch before! I
    set about constructing a very hacky PyTorch ranking model to see if I could throw
    one together and learn something in the process. This is obviously not intended
    for a production system, and I made a lot of shortcuts along the way, but it has
    been an amazing pedagogical experience.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我意识到我之前从未从零开始构建过一个排名模型！于是我着手构建了一个非常简陋的 PyTorch 排名模型，看看我能否快速搭建一个并在过程中学习一些东西。显然，这并不适用于生产系统，我在过程中做了很多捷径，但这的确是一次极好的教学体验。
- en: Data
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: '![](../Images/c39e6fe51959571e8377a161bee7b3cb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c39e6fe51959571e8377a161bee7b3cb.png)'
- en: Photo by [Pritesh Sudra](https://unsplash.com/@pritesh557?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Pritesh Sudra](https://unsplash.com/@pritesh557?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Our supreme goal is the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的终极目标如下：
- en: develop a ranking model that learns the pairwise preferences of users
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个学习用户对偶偏好的排名模型
- en: apply this to predict the listwise ranking of `k` items
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将此应用于预测 `k` 个项目的按列表排名
- en: What signal might lie in user and item feature combinations to produce a set
    of recommendations for that user pair?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 用户和项目特征组合中可能包含的信号是什么，以为该用户对提供一组推荐？
- en: 'To collect this data, I had to perform painful research of taste-testing amazing
    coffees with my wife. Each of us then rated them on a 10-point scale. The target
    value is simply the sum of our two scores (20 point maximum). The object of the
    model is to Learn to Rank coffees that we will both enjoy, and not just one member
    of any pair. The contextual data that we will be using is the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集这些数据，我不得不和我的妻子一起进行痛苦的咖啡品鉴研究。然后我们各自为这些咖啡打分，满分为 10 分。目标值只是我们两人分数的总和（最大为 20
    分）。模型的目标是学习排名我们都喜欢的咖啡，而不仅仅是某一对中的一个成员。我们将使用的上下文数据如下：
- en: ages of both users in the pair
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对用户的年龄
- en: user ids that will be turned into embeddings
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户 ID，将转换为嵌入向量
- en: 'SweetMarias.com provides a lot of item data:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SweetMarias.com 提供了大量的项目数据：
- en: the origin of the coffee
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 咖啡的来源
- en: Processing and cultivation notes
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加工和培养笔记
- en: tasting descriptions
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 品尝描述
- en: professional grading scores (100 point scale)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专业评分（100 分制）
- en: So for each training example, we will have the user data as the contextual information
    and each item’s feature set will be concatenated.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于每个训练示例，我们将把用户数据作为上下文信息，每个项目的特征集将被连接在一起。
- en: 'TensorFlow Ranking models are typically trained on data in [ELWC](https://www.tensorflow.org/ranking/tutorials/ranking_dnn_distributed#elwc_data_formats_for_ranking)
    format: ExampleListWithContext. You can think of it like a dictionary with 2 keys:
    CONTEXT and EXAMPLES (list). Inside each EXAMPLE is a dictionary of features per
    item you wish to rank.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Ranking 模型通常在 [ELWC](https://www.tensorflow.org/ranking/tutorials/ranking_dnn_distributed#elwc_data_formats_for_ranking)
    格式的数据上进行训练：ExampleListWithContext。你可以把它想象成一个字典，包含两个键：CONTEXT 和 EXAMPLES（列表）。每个
    EXAMPLE 内部是一个字典，包含每个你想排名的项目的特征。
- en: For example, let us assume that I was searching for a new coffee to try out,
    and some candidate pool was presented to me of k=10 coffee varietals. An ELWC
    would consist of the context/user information, as well as a list of 10 items,
    each with its own feature set.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我正在寻找一款新的咖啡来尝试，系统展示了一个包含 k=10 种咖啡品种的候选池。一个 ELWC 将包括上下文/用户信息，以及一个包含 10 个项目的列表，每个项目都有自己的特征集。
- en: As I was no longer using TensorFlow Ranking, I made my own hacky ranking/list
    building aspect of this project. I grabbed random samples of k items from which
    we have scores and added them to a list. I split the first coffees I tried into
    a training set, and later examples became a small validation set to evaluate the
    model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我不再使用 TensorFlow Ranking，我自己做了一个简陋的排名/列表构建部分。我随机挑选了 k 个项目样本，并为它们评分，然后将它们添加到一个列表中。我把最初尝试的咖啡分成了训练集，之后的示例则成为了一个小的验证集，用来评估模型。
- en: Feature Intuition
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征直觉
- en: In this toy example, we have a fairly rich dataset. Context-wise, we ostensibly
    know the users’ age and can learn their respective preference embeddings. Through
    subsequent layers inside the LTR, these contextual features can be compared and
    contrasted. Does one user in the pair like dark, fruity flavors, while the other
    enjoys invigorating citrus and fruity notes in their cup?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个玩具示例中，我们拥有一个相当丰富的数据集。从上下文角度来看，我们明显知道用户的年龄，并能学习到他们各自的偏好嵌入。通过LTR模型内部的后续层，这些上下文特征可以进行比较和对比。例如，是否一对用户中，一个喜欢浓郁的水果味，而另一个则喜欢杯中清新的柑橘和水果味呢？
- en: '![](../Images/bd27ef43ea5e42371aedad3d073eac48.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd27ef43ea5e42371aedad3d073eac48.png)'
- en: Photo by [Nathan Dumlao](https://unsplash.com/@nate_dumlao?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Nathan Dumlao](https://unsplash.com/@nate_dumlao?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: For the item features, we have a generous helping of rich, descriptive text
    of each coffee’s tasting notes, origin, etc. More on this later, but the general
    idea is that we can capture the meaning of these descriptions and match the descriptions
    with the context (user-pair) data. Finally, we have some numerical features like
    the product expert tasting score per item that (should) have some semblance to
    reality.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于商品特征，我们拥有丰富的描述性文本，包括每种咖啡的品尝笔记、产地等。稍后会详细介绍，但总体来说，我们可以捕捉这些描述的含义，并将这些描述与上下文（用户对）数据进行匹配。最后，我们还有一些数值特征，比如每种商品的专家品尝评分，这些（应该）与现实有一定的相似性。
- en: Preprocessing
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: A stunning shift is underway in text embeddings from when I was starting out
    in the ML industry. Long gone are the GLOVE and Word2Vec models that I used to
    use to try to capture some semantic meaning from a word or phrase. If you head
    on over to [https://huggingface.co/blog/mteb](https://huggingface.co/blog/mteb),
    you can easily compare what the latest and greatest embedding models are for a
    variety of purposes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我刚开始从事机器学习行业以来，文本嵌入技术发生了惊人的变化。那些我曾用来尝试捕捉词语或短语语义的 GLOVE 和 Word2Vec 模型早已不再使用。如果你访问[https://huggingface.co/blog/mteb](https://huggingface.co/blog/mteb)，你可以轻松比较最新最强的嵌入模型，用于各种目的。
- en: For the sake of simplicity and familiarity, we will be using [https://huggingface.co/BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5)
    embeddings to help us project our text features into something understandable
    by a LTR model. Specifically we will use this for the product descriptions and
    product names that Sweet Marias provides.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化和熟悉，我们将使用[https://huggingface.co/BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5)的嵌入模型，帮助我们将文本特征投射到LTR模型能够理解的格式。具体来说，我们将使用这个模型来处理Sweet
    Marias提供的产品描述和产品名称。
- en: We will also need to convert all of our user- and item-id values into an embedding
    space. PyTorch handles this beautifully with the [Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)
    Layers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要将所有用户和商品的 ID 值转换为嵌入空间。PyTorch 通过[Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)层很好地处理了这一点。
- en: Finally we do some scaling on our float features with a simple [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html).
    This can all happen inside our Torch Dataset class which then gets dumped into
    a DataLoader for training. The trick here is to separate out the different identifiers
    that will get past into the `forward()` call for PyTorch. This [article](/deep-learning-using-pytorch-for-tabular-data-c68017d8b480)
    by Offir Inbar really saved me some time by doing just that!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们对浮动特征进行简单的[RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)缩放。所有这些都可以在我们的Torch数据集类内部完成，然后将其输入到用于训练的DataLoader中。关键在于分离出不同的标识符，这些标识符将在PyTorch的`forward()`调用中传递。[Offir
    Inbar](https://www.linkedin.com/in/offir-inbar/)的这篇[文章](/deep-learning-using-pytorch-for-tabular-data-c68017d8b480)真的是帮我节省了不少时间！
- en: Model Building and Training
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建与训练
- en: 'The only interesting thing about the Torch training was ensuring that the 2
    user embeddings (one for each rater) and the `k` coffees in the list for training
    had the correct embeddings and dimensions to pass through our neural network.
    With a few tweaks, I was able to get something out:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Torch 训练，唯一有趣的事情是确保两个用户嵌入（每个评分者一个）和训练列表中的`k`种咖啡具有正确的嵌入和维度，以便通过我们的神经网络。经过一些调整，我终于得到了一些结果：
- en: This forward pushes each training example into a single concatenated list with
    all of the features.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个前向传播将每个训练示例推入一个包含所有特征的单一连接列表中。
- en: With so few data points (only 16 coffees were rated), it can be difficult to
    train a robust NN model. I often build a simple `sklearn` model side by side so
    that I can compare the results. Are we really learning anything?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据点如此之少（仅有 16 种咖啡被评分），训练一个强大的神经网络模型可能会很困难。我通常会并排构建一个简单的 `sklearn` 模型，以便比较结果。我们真的学到了什么吗？
- en: Using the same data preparation techniques, I built a LogisticRegression multi-class
    classifier model, and then dumped out the `.predict_proba()` scores to be used
    as our rankings. What could our metrics say about the performance of these two
    models?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的数据准备技术，我构建了一个 LogisticRegression 多类分类器模型，然后将 `.predict_proba()` 的得分输出，用作我们的排序。我们的指标能告诉我们这两个模型的表现如何吗？
- en: Results
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'For the metrics, I chose to track two:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于指标，我选择追踪两个：
- en: Top (`k=1`) accuracy
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Top（`k=1`）准确率
- en: '[NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG)'
- en: The goal, of course, is to get the ranking correct for these coffees. NDCG will
    fit the bill nicely here. However, I suspected that the LogReg model might struggle
    with the ranking aspect, so I thought I might throw a simple accuracy in there
    as well. Sometimes you only want one really good cup of coffee and don’t need
    a ranking!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 目标，当然，是正确排序这些咖啡。NDCG 在这里非常适用。不过，我怀疑 LogReg 模型在排序方面可能会遇到困难，所以我考虑可能也加入一个简单的准确率指标。有时你只想要一杯真正好的咖啡，而不需要排序！
- en: Without any significant investment in parameter tuning on my part, I achieved
    very similar results between the two models. SKLearn had slightly worse NDCG on
    the (tiny) validation set (0.9581 vs 0.950), but similar accuracy. I believe with
    some hyper-parameter tuning on both the PyTorch model and the LogReg model, the
    results could be very similar with so little data. But at least they broadly agree!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我没有进行任何显著的参数调整的情况下，两个模型的结果非常相似。SKLearn 在（极小的）验证集上的 NDCG 稍微差一些（0.9581 对比 0.950），但准确率相似。我相信通过对
    PyTorch 模型和 LogReg 模型进行一些超参数调优，结果在如此少的数据情况下会非常相似。不过至少它们的大致结论一致！
- en: Future Work
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来工作
- en: I have a new batch of 16 pounds of coffee to start ranking to add to the model,
    and I deliberately added some lesser-known varietals to the mix. I hope to clean
    up the repo a bit and make it less of a hack-job. Also I need to add a prediction
    function for unseen coffees so that I can figure out what to buy next order!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一批新的 16 磅咖啡开始进行排名，并且故意将一些不太为人知的品种加入其中。我希望能稍微整理一下仓库，让它看起来不那么像一个临时的黑客作品。另外，我还需要为未见过的咖啡添加一个预测函数，以便我能搞清楚下次该买什么！
- en: One thing to note is that if you are building a recommender for production,
    it is often a good idea to use a real library built for ranking. TensorFlow Ranking,
    XGBoost, LambdaRank, etc. are accepted in the industry and have lots of the pain
    points ironed out.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，如果你正在为生产环境构建推荐系统，通常使用一个专门为排序构建的真实库是个不错的主意。TensorFlow Ranking、XGBoost、LambdaRank
    等在业界被广泛接受，并且解决了许多痛点。
- en: Please check out the repo [here](https://github.com/franckjay/UserPairRecommendationEngine)
    and let me know if you catch any bugs! I hope you are inspired to train your own
    User-Pair model for ranking.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看[这里](https://github.com/franckjay/UserPairRecommendationEngine)的仓库，并告诉我如果你发现任何
    bug！希望你能受到启发，训练你自己的用户对排序模型。
