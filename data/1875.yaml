- en: Local LLM Fine-Tuning on Mac (M1 16GB)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mac上的本地LLM微调（M1 16GB）
- en: 原文：[https://towardsdatascience.com/local-llm-fine-tuning-on-mac-m1-16gb-f59f4f598be7?source=collection_archive---------2-----------------------#2024-08-01](https://towardsdatascience.com/local-llm-fine-tuning-on-mac-m1-16gb-f59f4f598be7?source=collection_archive---------2-----------------------#2024-08-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/local-llm-fine-tuning-on-mac-m1-16gb-f59f4f598be7?source=collection_archive---------2-----------------------#2024-08-01](https://towardsdatascience.com/local-llm-fine-tuning-on-mac-m1-16gb-f59f4f598be7?source=collection_archive---------2-----------------------#2024-08-01)
- en: Beginner-friendly Python code walkthrough (ft. MLX)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初学者友好的Python代码演示（特邀：MLX）
- en: '[](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page---byline--f59f4f598be7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)
    ·8 min read·Aug 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f59f4f598be7--------------------------------)
    ·8分钟阅读·2024年8月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article is part of a [larger series](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c)
    on using large language models (LLMs) in practice. In a [previous post](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32),
    I showed how to fine-tune an LLM using a single (free) GPU on Google Colab. While
    that example (and many others) readily runs on Nvidia hardware, they are not easily
    adapted to M-series Macs. In this article, I walk through an easy way to fine-tune
    an LLM locally on a Mac.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是关于使用大型语言模型（LLM）实践的[系列文章](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c)的一部分。在[上一篇文章](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)中，我展示了如何在Google
    Colab上使用一块（免费的）GPU微调LLM。虽然那个例子（以及许多其他例子）可以在Nvidia硬件上轻松运行，但它们无法轻松适配M系列Mac。在本文中，我将介绍如何在Mac上本地微调LLM的一种简单方法。
- en: '![](../Images/ff42af007f050edf17f7fa56426c6535.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff42af007f050edf17f7fa56426c6535.png)'
- en: Photo by [Myron Mott](https://unsplash.com/@s2killa?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Myron Mott](https://unsplash.com/@s2killa?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: With the rise of open-source large language models (LLMs) and efficient fine-tuning
    methods, building custom ML solutions has never been easier. Now, anyone with
    **a single GPU can fine-tune an LLM on their local machine**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着开源大型语言模型（LLM）和高效微调方法的兴起，构建定制的机器学习解决方案变得前所未有的容易。现在，任何拥有**一块GPU的人都可以在本地机器上微调LLM**。
- en: However, Mac users have been largely left out of this trend due to Apple’s M-series
    chips. These chips employ a unified memory framework, which precludes the need
    for a GPU. Thus, many (GPU-centric) open-source tools for running and training
    LLMs are not compatible with (or don’t fully utilize) modern Mac computing power.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于苹果的M系列芯片，Mac用户在这一趋势中基本被排除在外。这些芯片采用了统一内存架构，这使得不再需要GPU。因此，许多（以GPU为中心的）开源工具无法兼容（或无法充分利用）现代Mac的计算能力，用于运行和训练LLM。
- en: I had **almost** given up on my dreams of training LLMs locally until I discovered
    the MLX Python library.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我差点**放弃**了在本地训练LLM的梦想，直到我发现了MLX Python库。
