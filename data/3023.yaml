- en: 'The Good, the Bad, and the Ugly: Memory for a Neural Network'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 好的、坏的和丑的：神经网络的记忆
- en: 原文：[https://towardsdatascience.com/the-good-the-bad-an-ugly-memory-for-a-neural-network-bac1f79e8dfd?source=collection_archive---------6-----------------------#2024-12-17](https://towardsdatascience.com/the-good-the-bad-an-ugly-memory-for-a-neural-network-bac1f79e8dfd?source=collection_archive---------6-----------------------#2024-12-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-good-the-bad-an-ugly-memory-for-a-neural-network-bac1f79e8dfd?source=collection_archive---------6-----------------------#2024-12-17](https://towardsdatascience.com/the-good-the-bad-an-ugly-memory-for-a-neural-network-bac1f79e8dfd?source=collection_archive---------6-----------------------#2024-12-17)
- en: '|ARTIFICIAL INTELLIGENCE|MEMORY|NEURAL NETWORK|LEARNING|'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '|人工智能|记忆|神经网络|学习|'
- en: Memory can play tricks; to learn best it is not always good to memorize
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记忆可能会耍花招；要学得最好，记忆并不总是有效的
- en: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)
    ·12 min read·Dec 17, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--bac1f79e8dfd--------------------------------)
    ·12分钟阅读·2024年12月17日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b0b6fc0d8316c04da45469a33f2812a6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0b6fc0d8316c04da45469a33f2812a6.png)'
- en: image generated by the author using DALL-E
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者使用DALL-E生成的图像
- en: No man has a good enough memory to be a successful liar. — Abraham Lincoln
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 没有人有足够好的记忆力，能够成为一个成功的骗子。——亚伯拉罕·林肯
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Memory is more indelible than ink. — Anita Loos
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记忆比墨水更难忘。——安妮塔·卢斯
- en: '**Memorize bad, generalization good.** This is considered as a dogma of artificial
    intelligence. But why? What is wrong with memorization?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**记忆不好，泛化好。** 这是人工智能的一个教条。但为什么呢？记忆有什么问题？'
- en: Intuitively a student who memorizes the whole book might still fail a test if
    the exercises are different from those in the book. If memorizing does not mean
    learning, sometimes a little memory can also be beneficial. For example, there
    is no point in learning complex rules to learn a list of names of historical figures.
    You have to know how to find the right balance. Something similar is happening
    with neural networks. This article discusses the complex love/hate relationship
    between neural networks and memory.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，一个背下整本书的学生，如果考试中的练习题与书中的内容不同，可能仍然会失败。如果背诵并不等于学习，有时适当的记忆也有益。例如，学习复杂的规则来记住一串历史人物的名字是没有意义的。你必须知道如何找到合适的平衡。神经网络中也发生着类似的事情。本文讨论了神经网络与记忆之间复杂的爱/恨关系。
- en: '***Artificial intelligence is transforming our world, shaping how we live and
    work. Understanding how it works and its implications has never been more crucial.***
    *If*…'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '***人工智能正在改变我们的世界，塑造我们的生活和工作方式。理解它如何运作以及它的影响，比以往任何时候都更加重要。*** *如果*…'
