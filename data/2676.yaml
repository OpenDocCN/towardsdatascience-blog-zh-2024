- en: 'Paper Walkthrough: Attention Is All You Need'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 论文解析：Attention Is All You Need
- en: 原文：[https://towardsdatascience.com/paper-walkthrough-attention-is-all-you-need-80399cdc59e1?source=collection_archive---------1-----------------------#2024-11-03](https://towardsdatascience.com/paper-walkthrough-attention-is-all-you-need-80399cdc59e1?source=collection_archive---------1-----------------------#2024-11-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/paper-walkthrough-attention-is-all-you-need-80399cdc59e1?source=collection_archive---------1-----------------------#2024-11-03](https://towardsdatascience.com/paper-walkthrough-attention-is-all-you-need-80399cdc59e1?source=collection_archive---------1-----------------------#2024-11-03)
- en: The complete guide to implementing a Transformer from scratch
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整的从零开始实现Transformer的指南
- en: '[](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)[![Muhammad
    Ardi](../Images/b59b3752bc33df0166eea834bbdb122f.png)](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)
    [Muhammad Ardi](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)[![Muhammad
    Ardi](../Images/b59b3752bc33df0166eea834bbdb122f.png)](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)
    [Muhammad Ardi](https://medium.com/@muhammad_ardi?source=post_page---byline--80399cdc59e1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)
    ·42 min read·Nov 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--80399cdc59e1--------------------------------)
    ·阅读时间42分钟·2024年11月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d18eed9a18d83ad060417f4fe0323909.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d18eed9a18d83ad060417f4fe0323909.png)'
- en: Photo by [Samule Sun](https://unsplash.com/@samule?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Samule Sun](https://unsplash.com/@samule?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: As the title suggests, in this article I am going to implement the Transformer
    architecture from scratch with PyTorch — yes, literally from scratch. Before we
    get into it, let me provide a brief overview of the architecture. Transformer
    was first introduced in a paper titled “*Attention Is All You Need*” written by
    Vaswani et al. back in 2017 [1]. This neural network model is designed to perform
    *seq2seq* (Sequence-to-Sequence) tasks, where it accepts a sequence as the input
    and is expected to return another sequence for the output such as machine translation
    and question answering.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如标题所示，本文将从零开始用PyTorch实现Transformer架构——没错，真的是从零开始。在开始之前，让我简要介绍一下该架构。Transformer首次出现在2017年Vaswani等人撰写的论文《*Attention
    Is All You Need*》中[1]。该神经网络模型旨在执行*seq2seq*（序列到序列）任务，它接收一个序列作为输入，并期望返回另一个序列作为输出，应用场景包括机器翻译和问答系统。
- en: Before Transformer was introduced, we usually used RNN-based models like LSTM
    or GRU to accomplish *seq2seq* tasks. These models are indeed capable of capturing
    context, yet they do so in a sequential manner. This approach makes it challenging
    to capture long-range dependencies, especially when the important context is very
    far behind the current timestep. In contrast, Transformer can freely attend any
    parts of the sequence that it considers important without being constrained by
    sequential processing.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在Transformer出现之前，我们通常使用基于RNN的模型，如LSTM或GRU，来完成*seq2seq*任务。这些模型确实能够捕获上下文，但它们是按顺序处理的。这种方法使得捕捉长程依赖变得具有挑战性，尤其是当重要的上下文信息远在当前时间步之前时。相比之下，Transformer能够自由地关注序列中任何它认为重要的部分，而不受顺序处理的限制。
- en: Transformer Components
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transformer组件
