- en: 'Text Vectorization Demystified: Transforming Language into Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本向量化解密：将语言转化为数据
- en: 原文：[https://towardsdatascience.com/text-vectorization-demystified-transforming-language-into-data-abce8f701073?source=collection_archive---------3-----------------------#2024-08-03](https://towardsdatascience.com/text-vectorization-demystified-transforming-language-into-data-abce8f701073?source=collection_archive---------3-----------------------#2024-08-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-vectorization-demystified-transforming-language-into-data-abce8f701073?source=collection_archive---------3-----------------------#2024-08-03](https://towardsdatascience.com/text-vectorization-demystified-transforming-language-into-data-abce8f701073?source=collection_archive---------3-----------------------#2024-08-03)
- en: An intuitive guide to text vectorization
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一份关于文本向量化的直观指南
- en: '[](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)[![Lakshmi
    Narayanan](../Images/4a1ccd6d141b82e883cb5b25a98c1fa1.png)](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)
    [Lakshmi Narayanan](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)[![Lakshmi
    Narayanan](../Images/4a1ccd6d141b82e883cb5b25a98c1fa1.png)](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)
    [Lakshmi Narayanan](https://medium.com/@lakshmi.sunil5486?source=post_page---byline--abce8f701073--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)
    ·12 min read·Aug 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--abce8f701073--------------------------------)
    ·12分钟阅读·2024年8月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In my last [post](https://medium.com/@lakshmi.sunil5486/diving-into-foundation-models-and-large-language-models-a-beginners-guide-0560f0996219),
    we took a closer look at foundation models and large language models (LLMs). We
    tried to understand what they are, how they are used and what makes them special.
    We explored where they work well and where they might fall short. We discussed
    their applications in different areas like understanding text and generating content.
    These LLMs have been transformative in the field of Natural Language Processing
    (NLP).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在我上一篇[文章](https://medium.com/@lakshmi.sunil5486/diving-into-foundation-models-and-large-language-models-a-beginners-guide-0560f0996219)中，我们深入探讨了基础模型和大型语言模型（LLMs）。我们尝试了解它们是什么，它们是如何使用的，以及它们的特别之处。我们探索了它们在哪些方面表现优异，哪些方面可能存在不足。我们讨论了它们在理解文本和生成内容等不同领域的应用。这些LLMs在自然语言处理（NLP）领域带来了变革。
- en: When we think of an NLP Pipeline, feature engineering (also known as *feature
    extraction* or *text representation* or *text vectorization*) is a very integral
    and important step. This step involves techniques to represent text as numbers
    (feature vectors). We need to perform this step when working on NLP problem as
    computers cannot understand text, they only understand numbers and it is this
    numerical representation of text that needs to be fed into the machine learning
    algorithms for solving various text based use cases such as language translation,
    sentiment analysis, summarization etc.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论NLP管道时，特征工程（也称为*特征提取*、*文本表示*或*文本向量化*）是一个非常重要且不可或缺的步骤。这个步骤涉及使用技术将文本表示为数字（特征向量）。在处理NLP问题时我们需要进行这一步骤，因为计算机无法理解文本，它们只能理解数字，正是这种文本的数值表示需要输入到机器学习算法中，用于解决各种基于文本的应用案例，如语言翻译、情感分析、摘要生成等。
- en: For those of us who are aware of the machine learning pipeline in general, we
    understand that feature engineering is a very crucial step in generating good
    results from the model. The same concept applies in NLP as well. When we generate
    numerical representation of textual data, one important objective that we are
    trying to achieve is that the numerical representation generated ***should***…
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们这些了解机器学习管道的人来说，我们明白特征工程是从模型中获得良好结果的关键步骤。这一概念在NLP中同样适用。当我们生成文本数据的数值表示时，我们努力实现的一个重要目标是，这个数值表示生成的***应该***…
