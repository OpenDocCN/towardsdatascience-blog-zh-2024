- en: 'Gaussian Naive Bayes, Explained: A Visual Guide with Code Examples for Beginners'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高斯朴素贝叶斯解释：为初学者提供的带有代码示例的可视化指南
- en: 原文：[https://towardsdatascience.com/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c?source=collection_archive---------2-----------------------#2024-10-12](https://towardsdatascience.com/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c?source=collection_archive---------2-----------------------#2024-10-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c?source=collection_archive---------2-----------------------#2024-10-12](https://towardsdatascience.com/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c?source=collection_archive---------2-----------------------#2024-10-12)
- en: CLASSIFICATION ALGORITHM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '**Bell-shaped assumptions for better predictions**'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**钟形曲线假设带来更好的预测**'
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--04949cef383c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)
    ·9 min read·Oct 12, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04949cef383c--------------------------------)
    ·阅读时间：9分钟·2024年10月12日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3461eb23bbba050007a17f806c580568.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3461eb23bbba050007a17f806c580568.png)'
- en: '`⛳️ More [CLASSIFICATION ALGORITHM](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c),
    explained: · [Dummy Classifier](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    · [K Nearest Neighbor Classifier](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    · [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    ▶ [Gaussian Naive Bayes](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    · [Decision Tree Classifier](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    · [Logistic Regression](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    · [Support Vector Classifier](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    · [Multilayer Perceptron](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`⛳️ 更多[分类算法](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c)讲解：·
    [虚拟分类器](/dummy-classifier-explained-a-visual-guide-with-code-examples-for-beginners-009ff95fc86e)
    · [K 最近邻分类器](/k-nearest-neighbor-classifier-explained-a-visual-guide-with-code-examples-for-beginners-a3d85cad00e1)
    · [伯努利朴素贝叶斯](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)
    ▶ [高斯朴素贝叶斯](/gaussian-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-04949cef383c)
    · [决策树分类器](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    · [逻辑回归](/logistic-regression-explained-a-visual-guide-with-code-examples-for-beginners-81baf5871505)
    · [支持向量机分类器](/support-vector-classifier-explained-a-visual-guide-with-mini-2d-dataset-62e831e7b9e9)
    · [多层感知机](/multilayer-perceptron-explained-a-visual-guide-with-mini-2d-dataset-0ae8100c5d1c)`'
- en: Building on our previous article about [Bernoulli Naive Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6),
    which handles binary data, we now explore Gaussian Naive Bayes for continuous
    data. Unlike the binary approach, this algorithm assumes each feature follows
    a normal (Gaussian) distribution.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前关于[伯努利朴素贝叶斯](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)的文章基础上，这一方法处理的是二元数据，我们现在探讨的是用于连续数据的高斯朴素贝叶斯。与二元方法不同，该算法假设每个特征遵循正态（高斯）分布。
- en: Here, we’ll see how Gaussian Naive Bayes handles continuous, bell-shaped data
    — ringing in accurate predictions — all **without getting into the intricate math**
    of Bayes’ Theorem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将看到高斯朴素贝叶斯如何处理连续的钟形数据——为准确预测打下基础——**而无需深入探讨贝叶斯定理的复杂数学**。
- en: '![](../Images/c31e0cb8eff429b558a8a46174d03a76.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c31e0cb8eff429b558a8a46174d03a76.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有视觉内容：作者使用Canva Pro创作。优化了移动端显示，可能在桌面端显示过大。
- en: Definition
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: Like other Naive Bayes variants, Gaussian Naive Bayes makes the “naive” assumption
    of feature independence. It assumes that the features are conditionally independent
    given the class label.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他朴素贝叶斯变种一样，高斯朴素贝叶斯做出了“朴素”的特征独立性假设。它假设在给定类标签的条件下，特征是相互独立的。
- en: However, while Bernoulli Naive Bayes is suited for datasets with binary features,
    Gaussian Naive Bayes assumes that the features follow **a continuous normal (Gaussian)**
    distribution. Although this assumption may not always hold true in reality, it
    simplifies the calculations and often leads to surprisingly accurate results.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，虽然伯努利朴素贝叶斯适用于具有二元特征的数据集，但高斯朴素贝叶斯假设特征服从**连续的正态（高斯）**分布。尽管这一假设在现实中并不总是成立，但它简化了计算，并且常常能够得到出人意料的准确结果。
- en: '![](../Images/0d0e6eec6460b4247cf38d8dc3c8600e.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d0e6eec6460b4247cf38d8dc3c8600e.png)'
- en: Bernoulli NB assumes binary data, Multinomial NB works with discrete counts,
    and Gaussian NB handles continuous data assuming a normal distribution.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利朴素贝叶斯假设数据是二元的， multinomial 朴素贝叶斯适用于离散计数数据，而高斯朴素贝叶斯处理连续数据，假设数据服从正态分布。
- en: Dataset Used
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的数据集
- en: Throughout this article, we’ll use this artificial golf dataset (made by author)
    as an example. This dataset predicts whether a person will play golf based on
    weather conditions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将使用这个人工高尔夫数据集（由作者制作）作为示例。该数据集预测一个人是否会根据天气条件去打高尔夫。
- en: '![](../Images/fc1873cedde634b5e602a6129e33ac2e.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc1873cedde634b5e602a6129e33ac2e.png)'
- en: 'Columns: ‘RainfallAmount’ (in mm), ‘Temperature’ (in Celcius), ‘Humidity’ (in
    %), ‘WindSpeed’ (in km/h) and ‘Play’ (Yes/No, target feature)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 列：‘降水量’（单位：毫米）、‘温度’（单位：摄氏度）、‘湿度’（单位：百分比）、‘风速’（单位：千米/小时）和‘是否下棋’（是/否，目标特征）
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Main Mechanism
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要机制
- en: Gaussian Naive Bayes works with continuous data, assuming each feature follows
    a Gaussian (normal) distribution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯朴素贝叶斯适用于连续数据，假设每个特征都服从高斯（正态）分布。
- en: Calculate the probability of each class in the training data.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练数据中每个类别的概率。
- en: For each feature and class, estimate the mean and variance of the feature values
    within that class.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个特征和类别，估计该类别中该特征值的均值和方差。
- en: 'For a new instance:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于新实例：
- en: a. For each class, calculate the probability density function (PDF) of each
    feature value under the Gaussian distribution of that feature within the class.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 对于每个类别，计算该类别下每个特征值在该特征高斯分布下的概率密度函数（PDF）。
- en: b. Multiply the class probability by the product of the PDF values for all features.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 将类别概率与所有特征的PDF值的乘积相乘。
- en: Predict the class with the highest resulting probability.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测具有最高概率的类别。
- en: '![](../Images/a090060bd91a5d5c69880a4926db7175.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a090060bd91a5d5c69880a4926db7175.png)'
- en: Gaussian Naive Bayes uses the normal distribution to model the likelihood of
    different feature values for each class. It then combines these likelihoods to
    make a prediction.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯朴素贝叶斯使用正态分布来建模每个类别中不同特征值的可能性。然后，它将这些可能性结合起来进行预测。
- en: Transforming non-Gaussian distributed data
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换非高斯分布数据
- en: Remember that this algorithm naively assume that all the input features are
    having Gaussian/normal distribution?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这个算法天真地假设所有输入特征都服从高斯/正态分布吗？
- en: Since we are not really sure about the distribution of our data, especially
    for features that clearly don’t follow a Gaussian distribution, applying a [power
    transformation](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)
    (like Box-Cox) before using Gaussian Naive Bayes can be beneficial. This approach
    can help make the data more Gaussian-like, which aligns better with the assumptions
    of the algorithm.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不确定数据的分布，尤其是对于那些明显不遵循高斯分布的特征，在使用高斯朴素贝叶斯之前应用[幂变换](/scaling-numerical-data-explained-a-visual-guide-with-code-examples-for-beginners-11676cdb45cb)（如Box-Cox变换）可能会有帮助。这种方法可以帮助数据更接近高斯分布，从而更符合算法的假设。
- en: '![](../Images/90d0627b51b81e1b87930635d3497adc.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90d0627b51b81e1b87930635d3497adc.png)'
- en: All columns are scaled using Power Transformation (Box-Cox Transformation) and
    then standardized.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列都使用幂变换（Box-Cox变换）进行缩放，然后标准化。
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we are ready for the training.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备开始训练。
- en: Training Steps
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练步骤
- en: '1. **Class Probability Calculation**: For each class, calculate its probability:
    (Number of instances in this class) / (Total number of instances)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 1. **类别概率计算**：对于每个类别，计算其概率：（该类别中的实例数量）/（实例总数）
- en: '![](../Images/c06266178b47854c1548da3d97e124f7.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c06266178b47854c1548da3d97e124f7.png)'
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '2\. **Feature Probability Calculation** : For each feature and each class,
    calculate the mean (μ) and standard deviation (σ) of the feature values within
    that class using the training data. Then, calculate the probability using Gaussian
    Probability Density Function (PDF) formula.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **特征概率计算**：对于每个特征和每个类别，使用训练数据计算该类别中特征值的均值（μ）和标准差（σ）。然后，使用高斯概率密度函数（PDF）公式计算概率。
- en: '![](../Images/b1e80a1082f80606387c89d90f62303c.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1e80a1082f80606387c89d90f62303c.png)'
- en: For each weather condition, determine the mean and standard deviation for both
    “YES” and “NO” instances. Then calculate their PDF using the PDF formula for normal/Gaussian
    distribution.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个天气条件，确定“YES”和“NO”实例的均值和标准差。然后使用正态/高斯分布的PDF公式计算它们的PDF。
- en: '![](../Images/a40cfb56adeb49c44ff0899ca2e3dbc1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a40cfb56adeb49c44ff0899ca2e3dbc1.png)'
- en: The same process is applied to all of the other features.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的过程应用于其他所有特征。
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/9b65e3ad3d83feb7d761c151b3593320.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b65e3ad3d83feb7d761c151b3593320.png)'
- en: '3\. **Smoothing**: Gaussian Naive Bayes uses a unique smoothing approach. Unlike
    Laplace smoothing [in other variants](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6),
    it adds a tiny value (0.000000001 times the largest variance) to all variances.
    This prevents numerical instability from division by zero or very small numbers.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. **平滑**：高斯朴素贝叶斯使用一种独特的平滑方法。与[其他变种中的拉普拉斯平滑](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)不同，它将一个微小的值（0.000000001倍的最大方差）添加到所有方差中。这可以防止由于除以零或非常小的数字导致的数值不稳定。
- en: Prediction/Classification Step
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测/分类步骤
- en: 'Given a new instance with continuous features:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个具有连续特征的新实例：
- en: '1\. **Probability Collection**:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. **概率收集**：
- en: 'For each possible class:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个可能的类别：
- en: · Start with the probability of this class occurring (class probability).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: · 从该类别发生的概率（类别概率）开始。
- en: · For each feature in the new instance, calculate the probability density function
    of that feature within the class.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: · 对于新实例中的每个特征，计算该特征在该类别中的概率密度函数。
- en: '![](../Images/bf29443203d3ddc521fc69caf88fa8bf.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf29443203d3ddc521fc69caf88fa8bf.png)'
- en: For ID 14, we calculate the PDF each of the feature for both “YES” and “NO”
    instances.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ID 14，我们计算每个特征在“YES”和“NO”实例中的PDF。
- en: '2\. **Score Calculation & Prediction**:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **分数计算与预测**：
- en: 'For each class:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个类别：
- en: · Multiply all the collected PDF values together.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: · 将所有收集到的PDF值相乘。
- en: · The result is the score for this class.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: · 结果是该类别的分数。
- en: · The class with the highest score is the prediction.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: · 得分最高的类别就是预测结果。
- en: '![](../Images/8c0e57938597cec51337f265f8a137f9.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c0e57938597cec51337f265f8a137f9.png)'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/9c97ff87d73e99807c7113e900035931.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c97ff87d73e99807c7113e900035931.png)'
- en: Evaluation Step
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估步骤
- en: '![](../Images/5a17bec3594c45626bd3222026fed233.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a17bec3594c45626bd3222026fed233.png)'
- en: For this particular dataset, this accuracy is considered quite good.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的数据集，这个准确度被认为是相当好的。
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Key Parameters
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键参数
- en: 'GaussianNB is known for its simplicity and effectiveness. The main thing to
    remember about its parameters is:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: GaussianNB因其简洁性和有效性而闻名。关于其参数，主要需要记住的是：
- en: '**priors**: This is the most notable parameter, [similar to Bernoulli Naive
    Bayes](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6).
    In most cases, you don’t need to set it manually. By default, it’s calculated
    from your training data, which often works well.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**priors**：这是最显著的参数，[类似于伯努利朴素贝叶斯](/bernoulli-naive-bayes-explained-a-visual-guide-with-code-examples-for-beginners-aec39771ddd6)。在大多数情况下，你不需要手动设置它。默认情况下，它是从你的训练数据中计算出来的，通常效果很好。'
- en: '**var_smoothing**: This is a stability parameter that you rarely need to adjust.
    (the default is 0.000000001)'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**var_smoothing**：这是一个稳定性参数，通常不需要调整。（默认值为0.000000001）'
- en: The key takeaway is that this algoritm is designed to work well out-of-the-box.
    In most situations, you can use it without worrying about parameter tuning.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 关键结论是，这个算法设计得非常易用，通常在大多数情况下你可以直接使用，而不必担心参数调整。
- en: Pros & Cons
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优缺点
- en: 'Pros:'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点：
- en: '**Simplicity**: Maintains the easy-to-implement and understand trait.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简洁性**：保持了易于实现和理解的特点。'
- en: '**Efficiency**: Remains swift in training and prediction, making it suitable
    for large-scale applications with continuous features.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**效率**：在训练和预测时保持快速，使其适用于具有连续特征的大规模应用。'
- en: '**Flexibility with Data**: Handles both small and large datasets well, adapting
    to the scale of the problem at hand.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据的灵活性**：能够很好地处理小型和大型数据集，根据手头问题的规模进行调整。'
- en: '**Continuous Feature Handling**: Thrives with continuous and real-valued features,
    making it ideal for tasks like predicting real-valued outputs or working with
    data where features vary on a continuum.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**连续特征处理**：擅长处理连续和实值特征，非常适合预测实值输出或处理特征在连续性上变化的数据。'
- en: 'Cons:'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺点：
- en: '**Independence Assumption**: Still assumes that features are conditionally
    independent given the class, which might not hold in all real-world scenarios.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**独立性假设**：仍然假设特征在给定类别的条件下是独立的，但在所有实际场景中，这一假设可能并不成立。'
- en: '**Gaussian Distribution Assumption**: Works best when feature values truly
    follow a normal distribution. Non-normal distributions may lead to suboptimal
    performance (but can be fixed with Power Transformation we’ve discussed)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**高斯分布假设**：当特征值真正符合正态分布时效果最好。非正态分布可能导致性能不理想（但可以通过我们讨论的幂变换来修正）'
- en: '**Sensitivity to Outliers**: Can be significantly affected by outliers in the
    training data, as they skew the mean and variance calculations.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对异常值的敏感性**：训练数据中的异常值可能会显著影响其表现，因为异常值会扭曲均值和方差的计算。'
- en: Final Remarks
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的备注
- en: Gaussian Naive Bayes stands as an efficient classifier for a wide range of applications
    involving continuous data. Its ability to handle real-valued features extends
    its use beyond binary classification tasks, making it a go-to choice for numerous
    applications.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯朴素贝叶斯是一个高效的分类器，适用于处理涉及连续数据的广泛应用。它处理实值特征的能力使其在二分类任务之外有更广泛的应用，因此成为许多应用中的首选。
- en: While it makes some assumptions about data (feature independence and normal
    distribution), when these conditions are met, it gives robust performance, making
    it a favorite among both beginners and seasoned data scientists for its balance
    of simplicity and power.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它对数据（特征独立性和正态分布）做出了一些假设，但当这些条件满足时，它能提供稳健的表现，因此在初学者和经验丰富的数据科学家中都很受欢迎，因为它在简洁性和强大功能之间取得了良好的平衡。
- en: 🌟 Gaussian Naive Bayes Simplified
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🌟 高斯朴素贝叶斯简化版
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Further Reading
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For a detailed explanation of the [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)
    and its implementation in scikit-learn, readers can refer to the official documentation,
    which provides comprehensive information on its usage and parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于[GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)及其在
    scikit-learn 中的实现的详细解释，读者可以参考官方文档，该文档提供了关于其使用和参数的全面信息。
- en: Technical Environment
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术环境
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的是 Python 3.7 和 scikit-learn 1.5。虽然讨论的概念通常适用，但不同版本的具体代码实现可能会有所不同。
- en: About the Illustrations
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于插图
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有注明，所有图片均由作者创作，包含来自 Canva Pro 的授权设计元素。
- en: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘾𝙡𝙖𝙨𝙨𝙞𝙛𝙞𝙘𝙖𝙩𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙎𝙚𝙚 𝙢𝙤𝙧𝙚 𝘾𝙡𝙖𝙨𝙨𝙞𝙛𝙞𝙘𝙖𝙩𝙞𝙤𝙣 𝘼𝙡𝙜𝙤𝙧𝙞𝙩𝙝𝙢𝙨 𝙝𝙚𝙧𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
- en: Classification Algorithms
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----04949cef383c--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----04949cef383c--------------------------------)8
    个故事![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
- en: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '𝙔𝙤𝙪 𝙢𝙞𝙜𝙝𝙩 𝙖𝙡𝙨𝙤 𝙡𝙞𝙠𝙚:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
- en: Regression Algorithms
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归算法
- en: '[View list](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----04949cef383c--------------------------------)5
    stories![A cartoon doll with pigtails and a pink hat. This “dummy” doll, with
    its basic design and heart-adorned shirt, visually represents the concept of a
    dummy regressor in machine. Just as this toy-like figure is a simplified, static
    representation of a person, a dummy regressor is a basic models serve as baselines
    for more sophisticated analyses.](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/regression-algorithms-b0b6959f1b39?source=post_page-----04949cef383c--------------------------------)5
    个故事![一只带着辫子和粉色帽子的卡通娃娃。这个“假人”娃娃，凭借其简单的设计和心形装饰的衬衫，形象地代表了机器中的“假回归模型”概念。正如这个玩具般的人物是简化的静态人类形象，假回归模型是作为更复杂分析的基线的基本模型。](../Images/aa7eeaa18e4bb093f5ce4ab9b93a8a27.png)![](../Images/44e6d84e61c895757ff31e27943ee597.png)![](../Images/7f3e5f3e2aca2feec035ca92e1bc440a.png)![Samy
    Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----04949cef383c--------------------------------)'
- en: Ensemble Learning
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成学习
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----04949cef383c--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----04949cef383c--------------------------------)4
    个故事![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
