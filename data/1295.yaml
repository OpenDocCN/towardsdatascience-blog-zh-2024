- en: Are AI Deep Network Models Converging?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能深度网络模型是否正在趋同？
- en: 原文：[https://towardsdatascience.com/platonic-representation-hypothesis-c812813d7248?source=collection_archive---------9-----------------------#2024-05-23](https://towardsdatascience.com/platonic-representation-hypothesis-c812813d7248?source=collection_archive---------9-----------------------#2024-05-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/platonic-representation-hypothesis-c812813d7248?source=collection_archive---------9-----------------------#2024-05-23](https://towardsdatascience.com/platonic-representation-hypothesis-c812813d7248?source=collection_archive---------9-----------------------#2024-05-23)
- en: Are artificial intelligence models evolving towards a unified representation
    of reality? The Platonic Representation Hypothesis says ML models are converging.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能模型是否正在朝着统一的现实表征演化？柏拉图式表征假设认为，机器学习模型正在趋同。
- en: '[](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)[![Hesam
    Sheikh](../Images/b8d5f4f285eef77634e4c1d4321580ed.png)](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)
    [Hesam Sheikh](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)[![Hesam
    Sheikh](../Images/b8d5f4f285eef77634e4c1d4321580ed.png)](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)
    [Hesam Sheikh](https://medium.com/@itshesamsheikh?source=post_page---byline--c812813d7248--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)
    ·8 min read·May 23, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c812813d7248--------------------------------)
    ·8分钟阅读·2024年5月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'A recent MIT paper has come to my attention for its impressive claim: AI models
    are converging, even across different modalities — vision and language. “*We argue
    that representations in AI models, particularly deep networks, are converging*”
    is how [**The Platonic Representation Hypothesis**](https://arxiv.org/abs/2405.07987)
    paper begins.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇近期的 MIT 论文引起了我的注意，因为其提出了一个令人印象深刻的观点：人工智能模型正在趋同，即使是在不同的模态——视觉和语言之间。“*我们认为，人工智能模型中的表征，特别是深度网络的表征，正在趋同*”，这就是[**柏拉图式表征假设**](https://arxiv.org/abs/2405.07987)论文的开头。
- en: But how can different models, trained on different datasets and for different
    use cases converge? What has led to this convergence?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，不同的模型，经过不同数据集的训练并用于不同的应用场景，如何能够趋同？是什么导致了这种趋同？
- en: '*✨This is a paid article. If you’re not a Medium member, you can read this
    for free in my newsletter:* [***Qiubyte***](https://hesamsheikh.substack.com/)***.***'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*✨这是付费文章。如果你不是 Medium 会员，你可以在我的新闻通讯中免费阅读此文：* [***Qiubyte***](https://hesamsheikh.substack.com/)***.***'
- en: '![](../Images/7d3f9d3d6b75ce9eeffa8cf92e8fdd3e.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d3f9d3d6b75ce9eeffa8cf92e8fdd3e.png)'
- en: Plato’s allegory of the cave by [Jan Saenredam](https://en.wikipedia.org/wiki/Allegory_of_the_cave#/media/File:Platon_Cave_Sanraedam_1604.jpg)
    (public domain).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 柏拉图的洞穴寓言，由[Jan Saenredam](https://en.wikipedia.org/wiki/Allegory_of_the_cave#/media/File:Platon_Cave_Sanraedam_1604.jpg)（公有领域）创作。
- en: 1\. The Platonic Representation Hypothesis
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 柏拉图式表征假设
- en: We argue that there is a growing similarity in how datapoints are represented
    in different neural network models. This similarity spans across different model
    architectures, training objectives, and even data modalities.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们认为，不同神经网络模型中数据点的表示方式正日益相似。这种相似性跨越了不同的模型架构、训练目标，甚至数据形式。
- en: '![](../Images/5da8256363d2d7ad31122d9252187a10.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5da8256363d2d7ad31122d9252187a10.png)'
- en: 'The Platonic Representation Hypothesis. The visual representation, **X,** and
    the textual one **Y**, are both projections of a common reality, **Z**. (source:
    [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 柏拉图式表征假设。视觉表征**X**和文本表征**Y**都是共同现实**Z**的投影。（来源：[论文](https://arxiv.org/abs/2405.07987)）
- en: introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: The paper’s central argument is that models of various origins and modalities
    are converging to a *representation of reality* — the joint distribution over
    the events of the world that generate the data we observe and use to train the
    models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的核心论点是，来源和形式各异的模型正在趋向于一种*现实的表征*——即描述我们观察到并用于训练模型的世界事件的联合分布。
- en: The authors argue that this convergence towards a **platonic representation**
    is driven by the underlying structure and nature of the data that models are trained
    on, and by the growing complexity and capability of the models themselves. As
    models encounter various datasets and wider applications, they require a representation
    that captures the fundamental properties commonly found in all data types.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作者认为，这种趋向**柏拉图式表示**的收敛性是由模型所训练的底层数据结构和数据本身的性质驱动的，以及模型本身日益增长的复杂性和能力。随着模型接触到更多样的数据集和更广泛的应用，它们需要一种能够捕捉所有数据类型中常见的基本属性的表示。
- en: '![](../Images/c0a103eba7bdc3841ba60e0dd6101975.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0a103eba7bdc3841ba60e0dd6101975.png)'
- en: 'An Illustration of The Allegory of the Cave, from Plato’s Republic (art by
    [4edges](https://commons.wikimedia.org/wiki/User:4edges), source: [Wikipedia](https://en.wikipedia.org/wiki/Allegory_of_the_cave#/media/File:An_Illustration_of_The_Allegory_of_the_Cave,_from_Plato%E2%80%99s_Republic.jpg))'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 《洞穴寓言》的插图，摘自柏拉图的《理想国》（艺术作品来自[4edges](https://commons.wikimedia.org/wiki/User:4edges)，来源：[Wikipedia](https://en.wikipedia.org/wiki/Allegory_of_the_cave#/media/File:An_Illustration_of_The_Allegory_of_the_Cave,_from_Plato%E2%80%99s_Republic.jpg))
- en: 2\. Are AI Models Converging?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2.  AI模型会收敛吗？
- en: AI models of various scales, even built on diverse architecture and trained
    for different tasks, are showing signs of convergence in how they represent data.
    As these models grow in size and complexity and the feeding data becomes larger
    and varied, their methods of processing data begin to *align.*
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 各种规模的AI模型，即使是基于不同架构构建并为不同任务训练的模型，也开始表现出在数据表示上的收敛迹象。随着这些模型的规模和复杂度不断增长，输入数据变得更加庞大和多样，它们处理数据的方式开始*趋于一致。*
- en: Do models trained on different data modalities — vision or text, also converge?
    The answer could be *yes!*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同数据模态——视觉或文本上训练的模型也会收敛吗？答案可能是*是的！*
- en: 2.1 Vision Models that Talk
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 能说话的视觉模型
- en: This alignment spans over visual and textual data — the paper later confirms
    that the limitations of this theory are that it’s focused on these two modularities
    and not other modalities such as audio, or robotics perception of the world. One
    of the cases [1] to support this is [***LLaVA***](https://llava-vl.github.io/),
    which shows projecting visual features into language features using a 2-layer
    MLP, resulting in state-of-the-art results.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对齐跨越了视觉和文本数据——论文随后确认，这一理论的局限性在于它只关注这两种模态，而没有涉及音频或机器人对世界的感知等其他模态。支持这一点的一个案例[1]是[***LLaVA***](https://llava-vl.github.io/)，该案例展示了通过2层MLP将视觉特征投影到语言特征中，从而实现了最先进的结果。
- en: '![](../Images/55ffd69249f08c5f8411e44c510cb79c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55ffd69249f08c5f8411e44c510cb79c.png)'
- en: 'Outline of how LLaVA maps visual features to a Language Model. (source: [LLaVA](https://llava-vl.github.io/3),
    CC-BY)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: LLaVA如何将视觉特征映射到语言模型的概述。（来源：[LLaVA](https://llava-vl.github.io/3)，CC-BY）
- en: 2.2 Language Models that See
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 能看见的语言模型
- en: Another interesting example is ***A Vision Check-up for Language Models*** [2]
    which explores the extent to which large language models understand and process
    visual data. The study uses code as a bridge between images and text, as a novel
    approach to feed visual data to LLMs. The paper reveals that LLMs can generate
    images by code that while may not look realistic, still contain enough visual
    information to train vision models.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的例子是***大型语言模型的视力检查***[2]，它探讨了大型语言模型在理解和处理视觉数据方面的程度。该研究使用代码作为图像和文本之间的桥梁，作为将视觉数据输入LLM的创新方法。论文揭示了LLM可以通过代码生成图像，这些图像虽然可能看起来不真实，但仍包含足够的视觉信息来训练视觉模型。
- en: '![](../Images/b5cf01098f7054317c6704cf8e05dd91.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5cf01098f7054317c6704cf8e05dd91.png)'
- en: Can a language model see? ([source](https://arxiv.org/abs/2401.01862))
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型能看见吗？([source](https://arxiv.org/abs/2401.01862))
- en: 2.3 Bigger Models, Bigger Alignment
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 更大的模型，更强的对齐
- en: The alignment of different models is correlated with their scale. As an example,
    models trained on *CIFAR-10 classification* that are bigger, show greater alignment
    with each other, compared to smaller models. This means that with the current
    trend of building models in the order of 10s and now 100s of billions, these giants
    will be even more aligned.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型的对齐与其规模相关。例如，训练用于*CIFAR-10分类*的较大模型，表现出比小模型更强的对齐性。这意味着随着当前构建模型的趋势向10亿和100亿级别发展，这些巨型模型将会更加一致。
- en: “all strong models are alike, each weak model is weak in its own way.”
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “所有强大的模型都是相似的，每个弱模型都是以自己独特的方式弱。”
- en: 3\. Why are AI Models Converging?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 为什么AI模型会收敛？
- en: '![](../Images/da754cb83931f36ce44538279e2c757f.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da754cb83931f36ce44538279e2c757f.png)'
- en: 'The learning process of an AI model, f ∗ is the trained model, 𝐹 F is the function
    class, 𝐿 L is the loss function depending on the model 𝑓 f and an input 𝑥 x from
    the dataset, 𝑅 R represents the regularization function, and 𝐸 E denotes the expectation
    over the dataset. Each color represents one of the causes of this convergence.
    (source: [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: AI 模型的学习过程，f ∗ 是训练后的模型，𝐹 F 是函数类，𝐿 L 是依赖于模型 𝑓 f 和来自数据集的输入 𝑥 x 的损失函数，𝑅 R 表示正则化函数，𝐸
    E 表示数据集的期望值。每种颜色代表收敛的一个原因。 (来源：[论文](https://arxiv.org/abs/2405.07987))
- en: 'In training an AI model, there are elements that contribute most to why AI
    models converge:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练一个 AI 模型时，有一些因素对 AI 模型为何会收敛贡献最大：
- en: 3.1 Tasks are Becoming General
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 任务变得更加通用
- en: As models are trained to solve tasks that are more and more general simultaneously,
    the size of their solution space becomes smaller and more constrained. More generality
    means trying to learn data points that are closer to *reality*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型被训练以同时解决越来越多的任务，其解决方案空间变得越来越小且更加受限。更高的通用性意味着尝试学习更接近*现实*的数据点。
- en: '![](../Images/94dad5d024071616ad980eacb4c22f08.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94dad5d024071616ad980eacb4c22f08.png)'
- en: 'The more tasks a model can solve, it is forced to learn a disjoint representation
    that is useful in solving all of those tasks. (source: [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型能够解决的任务越多，它就被迫学习一个在解决所有这些任务时都有效的非重叠表示。 (来源：[论文](https://arxiv.org/abs/2405.07987))
- en: '*The Platonic Representation Hypothesis* paper formulates this as ***The Multitask
    Scaling Hypothesis:***'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*柏拉图表示假说* 论文将其表述为 ***多任务扩展假说：***'
- en: “There are fewer representations that are competent for N tasks than there are
    for M < N tasks. As we train more general models that solve more tasks at once,
    we should expect fewer possible solutions.”
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “能够胜任 N 个任务的表示比能够胜任 M < N 个任务的表示要少。随着我们训练更多通用的模型以同时解决更多任务，我们应该预期可能的解决方案会更少。”
- en: In other words, the solution to a complex problem is much more narrow than the
    solution to an easy problem. As we are training models that are more and more
    general on gigantic internet-wide datasets across different modalities, you can
    only imagine how constrained the solution space will be.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，解决复杂问题的方案比解决简单问题的方案要窄得多。当我们训练越来越通用的模型，且这些模型在庞大的、跨不同模态的互联网数据集上进行训练时，你可以想象解决方案空间会是多么的受限。
- en: 3.2 Models are Getting Bigger
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 模型变得越来越大
- en: As the capacity of models increases, through more sophisticated architectures,
    larger datasets, or more complex training algorithms, these models develop representations
    that are more similar to each other.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型的能力增强，通过更复杂的架构、更大的数据集或更复杂的训练算法，这些模型开发出的表示方式变得更加相似。
- en: '![](../Images/1b9e4e58eaeecfa96213276140d77730.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b9e4e58eaeecfa96213276140d77730.png)'
- en: 'Bigger hypothesis spaces are more likely to converge on a solution, rather
    than smaller spaces. (source: [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的假设空间比小的假设空间更容易收敛到一个解。 (来源：[论文](https://arxiv.org/abs/2405.07987))
- en: While *The Platonic Representation Hypothesis* paper doesn’t offer proofs or
    examples for this hypothesis that they call **The Capacity Hypothesis —** that
    “Bigger models are more likely to converge to a shared representation than smaller
    models”, it seems trivial that bigger models at least have *more capacity* to
    come up with mutual solution spaces than small models.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 *柏拉图表示假说* 论文并未为他们所称之为 **能力假说** 提供证明或示例——即“更大的模型比小的模型更容易收敛到共享表示”，但似乎显而易见的是，至少更大的模型有*更多的能力*去得出共同的解空间，远超过小模型。
- en: As AI models scale, thanks to their depth and complexity, they have a greater
    capacity for abstraction. This allows them to capture underlying concepts and
    patterns of the data and wave off noise or outliers, thus arriving at a representation
    that is more generalized and possibly closer to the real world.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 AI 模型的规模扩大，得益于它们的深度和复杂性，它们具备了更强的抽象能力。这使得它们能够捕捉数据的基本概念和模式，同时抛弃噪声或异常值，从而得出一个更加通用且可能更接近现实世界的表示。
- en: 3.3 The Simplicity Bias
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 简单性偏向
- en: 'Imagine training two **large-scale** neural networks on two separate tasks:
    one model must be able to recognize faces from images, and another is trained
    to interpret the emotions of faces. Initially, these two tasks might seem unrelated
    — but would you be surprised to see both models converge on similar ways of representing
    facial features? After all, it all comes down to an accurate identification and
    interpretation of key facial landmarks (eyes, nose, mouth, etc).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，在两个不同任务上训练两个**大规模**神经网络：一个模型必须能够识别图像中的面孔，另一个模型被训练来解读面孔的情绪。最初，这两个任务似乎没有什么关系——但是你会惊讶地发现两个模型最终会在面部特征表示上趋于相似吗？毕竟，一切归结于准确识别和解读面部关键点（眼睛、鼻子、嘴巴等）。
- en: '![](../Images/406bfc4d6cdfd719d909d9d7d8969fd8.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/406bfc4d6cdfd719d909d9d7d8969fd8.png)'
- en: 'Deep Neural Networks tend towards simpler functions. (source: [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络倾向于更简单的函数。（来源：[论文](https://arxiv.org/abs/2405.07987)）
- en: 'Several literature points out a tendency of deep neural networks to find simpler
    and more general solutions [3,4,5]. In other words, deep networks favor simple
    solutions. Often called **The Simplicity Bias** the paper formulates it as such:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有多篇文献指出深度神经网络有一种倾向，倾向于找到更简单、更通用的解决方案[3,4,5]。换句话说，深度网络偏爱简单的解决方案。通常被称为**简约偏差**，论文将其表述为：
- en: Deep networks are biased toward finding simple fits to the data, and the bigger
    the model, the stronger the bias. Therefore, as models get bigger, we should expect
    convergence to a smaller solution space.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 深度网络偏向于找到对数据的简单拟合，并且模型越大，偏差越强。因此，随着模型的增大，我们应预期其收敛到更小的解决空间。
- en: Why do neural networks show this behavior? Networks show simplicity bias mostly
    because of the fundamental properties of the learning algorithms used to train
    them. Algorithms tend to favor simpler, more generalizable models as a way to
    prevent overfitting and enhance generalization. During training, simpler models
    are more likely to emerge because by capturing the dominant patterns in the data,
    they minimize the loss function more efficiently.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么神经网络会表现出这种行为？网络表现出简约偏差主要是因为用于训练它们的学习算法的基本属性。算法倾向于偏好更简单、可泛化的模型，这是为了防止过拟合并增强泛化能力。在训练过程中，简单的模型更有可能出现，因为通过捕捉数据中的主导模式，它们可以更有效地最小化损失函数。
- en: Simplicity bias acts as a natural regulator during training. It pushes models
    toward an optimal way of representing and processing data, which is both general
    across tasks and simple enough to be efficiently learned and applied, and this
    increases the chance of models learning mutual hypothesis spaces.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 简约偏差在训练过程中充当了一种自然的调节器。它推动模型朝向一种最佳的数据表示和处理方式，这种方式不仅能跨任务通用，而且足够简单，便于高效学习和应用，从而增加了模型学习到共同假设空间的机会。
- en: 4\. Implications of This Convergence
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 这种收敛性的影响
- en: So what if models are converging? First of all, this shows that data across
    different modalities can be more useful than thought before. Fine-tuning vision
    models from pre-trained LLMs or vice-versa could yield surprisingly good results.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果模型正在收敛，又会怎么样呢？首先，这表明不同模态的数据比以前认为的更有用。从预训练的LLM微调视觉模型，或反之，可能会得到出乎意料的好结果。
- en: Another implication pointed out by the paper is that **“Scaling may reduce hallucination
    and bias”**. The argument is that as models scale, they can learn from a larger
    and more diverse dataset, which helps them develop a more accurate and robust
    understanding of the world. This enhanced understanding allows them to make predictions
    and generate outputs that are not only more reliable but also less biased.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中指出的另一个影响是**“规模化可能减少幻觉和偏见”**。这一论点是，随着模型的规模扩大，它们可以从更大、更具多样性的数据库中学习，从而帮助它们形成更准确、更健壮的世界理解。这种增强的理解使得模型能够做出更加可靠且更少偏见的预测和输出。
- en: '![](../Images/2165138d4d2f30d11a5c239ac0ba9116.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2165138d4d2f30d11a5c239ac0ba9116.png)'
- en: 'VISION models converge as COMPETENCE increases. (source: [Paper](https://arxiv.org/abs/2405.07987))'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: VISION模型随着**能力**的增加而收敛。（来源：[论文](https://arxiv.org/abs/2405.07987)）
- en: 5\. A Pinch of Salt
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 一点怀疑
- en: When it comes to the arguments posed by the paper, you have to consider some
    limitations, almost all of which are also addressed by the paper as well.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑论文中提出的论点时，必须考虑一些局限性，几乎所有这些局限性都在论文中有所讨论。
- en: Firstly, the paper assumes a **bijective projection of reality** in which one
    real-world concept Z, has projections X and Y that can be learned. However, some
    concepts are uniquely inherent in one modularity. Sometimes, language can express
    a concept or feeling that many images can’t, and in the same way, language can
    fail to take the place of an image in describing a visual concept.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，论文假设现实世界的**双射投影**，其中一个现实世界概念Z有可以学习的投影X和Y。然而，某些概念是独特地固有于某一模态的。有时，语言能够表达一种概念或情感，而许多图像无法做到，反之，语言也可能无法替代图像来描述视觉概念。
- en: 'Secondly, as mentioned before, the paper focuses on two modalities: vision
    and language. Thirdly, the argument that “AI models are Converging” only holds
    for multi-task AI models and not specific ones, such as ADAS or Sentiment Analysis
    models.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，正如前面提到的，论文关注两种模态：视觉和语言。第三，关于“AI模型正在趋同”的论点仅适用于多任务AI模型，而不适用于特定模型，如ADAS或情感分析模型。
- en: Lastly, while the paper shows that the alignment of different models **increases**,
    it doesn’t indicate the models’ representations become similar. The score of alignment
    between larger models is indeed higher than smaller ones, but still, a score of
    0.16/1.00 leaves some open questions to the research.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，尽管论文表明不同模型的**对齐度**有所**增加**，但并未表明这些模型的表示变得相似。大模型之间的对齐分数确实高于小模型，但即使如此，0.16/1.00的分数仍然留给研究一些悬而未解的问题。
- en: '**🌟 Join +1000 people learning about** Python🐍, ML/MLOps/AI🤖, Data Science📈,
    and LLM 🗯'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**🌟 加入1000+人一起学习** Python🐍，机器学习/机器学习操作/人工智能🤖，数据科学📈，以及大语言模型 🗯'
- en: '[**follow me**](https://medium.com/@itshesamsheikh/subscribe)and check out
    my [**X/Twitter**](https://twitter.com/itsHesamSheikh), where I keep you updated
    Daily**.**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[**关注我**](https://medium.com/@itshesamsheikh/subscribe)，并查看我的[**X/Twitter**](https://twitter.com/itsHesamSheikh)，我每天都会为你提供更新**。**'
- en: '[](https://hesamsheikh.substack.com/?source=post_page-----c812813d7248--------------------------------)
    [## QiuByte | Hesam Sheikh | Substack'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://hesamsheikh.substack.com/?source=post_page-----c812813d7248--------------------------------)
    [## QiuByte | Hesam Sheikh | Substack'
- en: AI, Programming, and Machine Learning, only in the EASY way. Click to read QiuByte,
    by Hesam Sheikh, a Substack…
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能、编程和机器学习，仅在简易的方式下。点击阅读《QiuByte》，由Hesam Sheikh主办，Substack…
- en: hesamsheikh.substack.com](https://hesamsheikh.substack.com/?source=post_page-----c812813d7248--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[hesamsheikh.substack.com](https://hesamsheikh.substack.com/?source=post_page-----c812813d7248--------------------------------)'
- en: Thanks for reading,
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，
- en: — Hesam
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: — Hesam
- en: '[1] Liu, H., Li, C., Wu, Q., and Lee, Y. J. Visual instruction tuning. In NeurIPS,
    2023.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 刘浩，李晨，吴奇，李洋杰。《视觉指令调优》。发表于NeurIPS，2023。'
- en: '[2] Sharma, P., Rott Shaham, T., Baradad, M., Fu, S., Rodriguez-Munoz, A.,
    Duggal, S., Isola, P., and Torralba, A. A vision check-up for language models.
    In arXiv preprint, 2024.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Sharma, P., Rott Shaham, T., Baradad, M., Fu, S., Rodriguez-Munoz, A.,
    Duggal, S., Isola, P., and Torralba, A. 《语言模型的视觉检查》。发表于arXiv预印本，2024。'
- en: '[3]H. Shah, K. Tamuly, The Pitfalls of Simplicity Bias in Neural Networks,
    2020, [https://arxiv.org/abs/2006.07710](https://arxiv.org/abs/2006.07710)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] H. Shah，K. Tamuly，《神经网络中简单性偏差的陷阱》，2020年，[https://arxiv.org/abs/2006.07710](https://arxiv.org/abs/2006.07710)'
- en: '[4] [A brief note on Simplicity Bias](https://www.lesswrong.com/posts/Gyggp2DJRMRLSnhid/a-brief-note-on-simplicity-bias-1)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [关于简单性偏差的简短说明](https://www.lesswrong.com/posts/Gyggp2DJRMRLSnhid/a-brief-note-on-simplicity-bias-1)'
- en: '[5] [Deep Neural Networks are biased, at initialisation, towards simple functions](/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [深度神经网络在初始化时偏向简单函数](/deep-neural-networks-are-biased-at-initialisation-towards-simple-functions-a63487edcb99)'
