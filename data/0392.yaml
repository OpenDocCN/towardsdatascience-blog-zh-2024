- en: Speech to Text to Speech with AI Using Python â€” a How-To Guide
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python å’Œ AI çš„è¯­éŸ³è½¬æ–‡æœ¬å†è½¬è¯­éŸ³ â€” ä¸€ä»½å¦‚ä½•å®ç°çš„æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11](https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11](https://towardsdatascience.com/speech-to-text-to-speech-with-ai-using-python-a-how-to-guide-ee9b0b0ef082?source=collection_archive---------1-----------------------#2024-02-11)
- en: How to Create a Speech-to-Text-to-Speech Program
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•åˆ›å»ºä¸€ä¸ªè¯­éŸ³è½¬æ–‡æœ¬å†è½¬è¯­éŸ³ç¨‹åº
- en: '[](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Naomi
    Kriger](../Images/14839f859e1375965c046912f00df5b9.png)](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    [Naomi Kriger](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Naomi
    Kriger](../Images/14839f859e1375965c046912f00df5b9.png)](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    [Naomi Kriger](https://naomikriger.medium.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    Â·8 min readÂ·Feb 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ee9b0b0ef082--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 8 åˆ†é’ŸÂ·2024å¹´2æœˆ11æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9373a2a21c40ba755fe7e692fc61b292.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9373a2a21c40ba755fe7e692fc61b292.png)'
- en: '[Image](https://unsplash.com/photos/aaujbh59zqI) by [Mariia Shalabaieva](https://unsplash.com/@maria_shalabaieva)
    from [unsplash](http://unsplash.com)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾ç‰‡](https://unsplash.com/photos/aaujbh59zqI) ç”± [Mariia Shalabaieva](https://unsplash.com/@maria_shalabaieva)
    æä¾›ï¼Œæ¥æºäº [unsplash](http://unsplash.com)'
- en: 'Itâ€™s been exactly a decade since I started attending GeekCon (yes, a geeksâ€™
    conference ğŸ™‚) â€” a weekend-long hackathon-makeathon in which all projects must
    be useless and just-for-fun, and this year there was an exciting twist: all projects
    were required to incorporate some form of AI.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä»æˆ‘å¼€å§‹å‚åŠ  GeekConï¼ˆæ˜¯çš„ï¼Œä¸€ä¸ªæå®¢ä¼šè®® ğŸ™‚ï¼‰å·²ç»æ•´æ•´åå¹´äº†â€”â€”è¿™æ˜¯ä¸€ä¸ªä¸ºæœŸä¸€å‘¨æœ«çš„é»‘å®¢é©¬æ‹‰æ¾å¼æ´»åŠ¨ï¼Œæ‰€æœ‰é¡¹ç›®å¿…é¡»æ˜¯æ— ç”¨çš„ã€çº¯ç²¹ä¸ºäº†å¥½ç©ï¼Œä»Šå¹´æœ‰ä¸€ä¸ªæ¿€åŠ¨äººå¿ƒçš„å˜åŒ–ï¼šæ‰€æœ‰é¡¹ç›®éƒ½å¿…é¡»åŒ…å«æŸç§å½¢å¼çš„
    AIã€‚
- en: 'My groupâ€™s project was a speech-to-text-to-speech game, and hereâ€™s how it works:
    the user selects a character to talk to, and then verbally expresses anything
    theyâ€™d like to the character. This spoken input is transcribed and sent to ChatGPT,
    which responds as if it were the character. The response is then read aloud using
    text-to-speech technology.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°ç»„çš„é¡¹ç›®æ˜¯ä¸€ä¸ªè¯­éŸ³è½¬æ–‡æœ¬å†è½¬è¯­éŸ³çš„æ¸¸æˆï¼Œå·¥ä½œåŸç†å¦‚ä¸‹ï¼šç”¨æˆ·é€‰æ‹©ä¸€ä¸ªè§’è‰²è¿›è¡Œå¯¹è¯ï¼Œç„¶åé€šè¿‡è¯­éŸ³è¡¨è¾¾ä»–ä»¬æƒ³å¯¹è§’è‰²è¯´çš„ä»»ä½•è¯ã€‚è¿™æ®µè¯­éŸ³è¾“å…¥è¢«è½¬å½•åå‘é€ç»™
    ChatGPTï¼ŒChatGPT ä¼šåƒè§’è‰²ä¸€æ ·è¿›è¡Œå›åº”ã€‚ç„¶åï¼Œä½¿ç”¨è¯­éŸ³åˆæˆæŠ€æœ¯å°†å›åº”è¯»å‡ºæ¥ã€‚
- en: Now that the game is up and running, bringing laughs and fun, Iâ€™ve crafted this
    how-to guide to help you create a similar game on your own. Throughout the article,
    weâ€™ll also explore the various considerations and decisions we made during the
    hackathon.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¸¸æˆå·²ç»ä¸Šçº¿ï¼Œå¸¦æ¥äº†è®¸å¤šæ¬¢ç¬‘ä¸ä¹è¶£ï¼Œæˆ‘ç¼–å†™äº†è¿™ä»½æŒ‡å—ï¼Œå¸®åŠ©ä½ è‡ªå·±åˆ›å»ºä¸€ä¸ªç±»ä¼¼çš„æ¸¸æˆã€‚åœ¨æ•´ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬è¿˜å°†æ¢ç´¢æˆ‘ä»¬åœ¨é»‘å®¢é©¬æ‹‰æ¾ä¸­æ‰€åšçš„å„ç§è€ƒè™‘å’Œå†³ç­–ã€‚
- en: Want to see the full code? [Here is the link](https://github.com/NaomiKriger/speech_to_speech_magician)!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³æŸ¥çœ‹å®Œæ•´ä»£ç å—ï¼Ÿ[ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹](https://github.com/NaomiKriger/speech_to_speech_magician)!
- en: The Programâ€™s Flow
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¨‹åºçš„æµç¨‹
- en: Once the server is running, the user will hear the app â€œtalkingâ€, prompting
    them to choose the figure they want to talk to and start conversing with their
    selected character. Each time they want to talk out loud â€” they should press and
    hold a key on the keyboard while talking. When they finish talking (and release
    the key), their recording will be transcribed by `[Whisper](https://platform.openai.com/docs/guides/speech-to-text/quickstart)`
    (a speech-to-text model by `[OpenAI](https://platform.openai.com/docs/introduction/overview)`),
    and the transcription will be sent to `[ChatGPT](https://platform.openai.com/docs/guides/gpt/chat-completions-api)`
    for a response. The response will be read out loud using a text-to-speech library,
    and the user will hear it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æœåŠ¡å™¨è¿è¡Œï¼Œç”¨æˆ·å°†å¬åˆ°åº”ç”¨ç¨‹åºâ€œè®²è¯â€ï¼Œæç¤ºä»–ä»¬é€‰æ‹©æƒ³è¦äº¤è°ˆçš„äººç‰©å¹¶å¼€å§‹ä¸æ‰€é€‰è§’è‰²å¯¹è¯ã€‚æ¯æ¬¡æƒ³è¦å¤§å£°è¯´è¯æ—¶ â€”â€” ä»–ä»¬åº”æŒ‰ä½é”®ç›˜ä¸Šçš„æŸä¸ªé”®å¹¶è¿›è¡Œè®²è¯ã€‚å½“ä»–ä»¬è®²è¯ç»“æŸï¼ˆå¹¶æ¾å¼€æŒ‰é”®ï¼‰æ—¶ï¼Œå½•éŸ³å°†é€šè¿‡
    `[Whisper](https://platform.openai.com/docs/guides/speech-to-text/quickstart)`ï¼ˆ`OpenAI`
    çš„è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹ï¼‰è¿›è¡Œè½¬å½•ï¼Œè½¬å½•ç»“æœå°†å‘é€ç»™ `[ChatGPT](https://platform.openai.com/docs/guides/gpt/chat-completions-api)`
    ä»¥è·å–å›å¤ã€‚å›å¤å°†é€šè¿‡æ–‡æœ¬è½¬è¯­éŸ³åº“å¤§å£°æœ—è¯»ï¼Œç”¨æˆ·å°†å¬åˆ°å›å¤å†…å®¹ã€‚
- en: Implementation
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®ç°
- en: Disclaimer
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…è´£å£°æ˜
- en: 'Note: The project was developed on a Windows operating system and incorporates
    the `pyttsx3` library, which lacks compatibility with M1/M2 chips. As `pyttsx3`
    is not supported on Mac, users are advised to explore alternative text-to-speech
    libraries that are compatible with macOS environments.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼šè¯¥é¡¹ç›®æ˜¯åœ¨ Windows æ“ä½œç³»ç»Ÿä¸Šå¼€å‘çš„ï¼Œå¹¶ä¸”åŒ…å«äº† `pyttsx3` åº“ï¼Œè¯¥åº“ä¸ M1/M2 èŠ¯ç‰‡ä¸å…¼å®¹ã€‚ç”±äº `pyttsx3` åœ¨ Mac
    ä¸Šä¸å—æ”¯æŒï¼Œå› æ­¤å»ºè®®ç”¨æˆ·æ¢ç´¢ä¸ macOS ç¯å¢ƒå…¼å®¹çš„å…¶ä»–æ–‡æœ¬è½¬è¯­éŸ³åº“ã€‚
- en: Openai Integration
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI é›†æˆ
- en: 'I utilized two `OpenAI` models: `Whisper`, for speech-to-text transcription,
    and the `ChatGPT` API for generating responses based on the userâ€™s input to their
    selected figure. While doing so costs money, the pricing model is very cheap,
    and personally, my bill is still under $1 for all my usage. To get started, I
    made an initial deposit of $5, and to date, I have not exhausted this deposit,
    and this initial deposit wonâ€™t expire until a year from now.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†ä¸¤ä¸ª `OpenAI` æ¨¡å‹ï¼š`Whisper` ç”¨äºè¯­éŸ³è½¬æ–‡æœ¬è½¬å½•ï¼Œ`ChatGPT` API ç”¨äºæ ¹æ®ç”¨æˆ·å¯¹æ‰€é€‰äººç‰©çš„è¾“å…¥ç”Ÿæˆå›å¤ã€‚å°½ç®¡è¿™æ ·åšä¼šäº§ç”Ÿè´¹ç”¨ï¼Œä½†å®šä»·æ¨¡å‹éå¸¸ä¾¿å®œï¼Œå°±æˆ‘ä¸ªäººè€Œè¨€ï¼Œæˆ‘çš„è´¦å•è‡³ä»Šè¿˜ä¸åˆ°
    $1ã€‚ä¸ºäº†å¼€å§‹ä½¿ç”¨ï¼Œæˆ‘è¿›è¡Œäº† $5 çš„åˆå§‹å­˜æ¬¾ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘è¿˜æ²¡æœ‰ç”¨å®Œè¿™ç¬”å­˜æ¬¾ï¼Œè€Œä¸”è¿™ç¬”åˆå§‹å­˜æ¬¾å°†æŒç»­åˆ°ä¸€å¹´åæ‰ä¼šè¿‡æœŸã€‚
- en: Iâ€™m not receiving any payment or benefits from `OpenAI` for writing this.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å†™è¿™ç¯‡æ–‡ç« å¹¶æœªä» `OpenAI` è·å¾—ä»»ä½•æŠ¥é…¬æˆ–åˆ©ç›Šã€‚
- en: Once you get your `OpenAI` API key â€” set it as an environment variable to use
    upon making the API calls. Make sure not to push your key to the codebase or any
    public location, and not to share it unsafely.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ è·å¾—äº† `OpenAI` API å¯†é’¥ â€”â€” è¯·å°†å…¶è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œåœ¨è¿›è¡Œ API è°ƒç”¨æ—¶ä½¿ç”¨ã€‚ç¡®ä¿ä¸è¦å°†å¯†é’¥æ¨é€åˆ°ä»£ç åº“æˆ–ä»»ä½•å…¬å…±ä½ç½®ï¼Œä¹Ÿä¸è¦ä¸å®‰å…¨åœ°å…±äº«å®ƒã€‚
- en: Speech to Text â€” Create Transcription
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯­éŸ³è½¬æ–‡æœ¬ â€”â€” åˆ›å»ºè½¬å½•
- en: The implementation of the speech-to-text feature was achieved using `Whisper`,
    an `OpenAI` model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½çš„å®ç°æ˜¯é€šè¿‡ `Whisper` å®Œæˆçš„ï¼Œè¿™æ˜¯ä¸€ç§ `OpenAI` æ¨¡å‹ã€‚
- en: 'Below is the code snippet for the function responsible for transcription:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯è´Ÿè´£è½¬å½•çš„å‡½æ•°ä»£ç ç‰‡æ®µï¼š
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This function is marked as asynchronous (async) since the API call may take
    some time to return a response, and we await it to ensure that the program doesnâ€™t
    progress until the response is received.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å‡½æ•°è¢«æ ‡è®°ä¸ºå¼‚æ­¥ï¼ˆasyncï¼‰ï¼Œå› ä¸º API è°ƒç”¨å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´æ‰èƒ½è¿”å›å“åº”ï¼Œæˆ‘ä»¬ä½¿ç”¨ `await` ç­‰å¾…å®ƒï¼Œä»¥ç¡®ä¿ç¨‹åºåœ¨æ”¶åˆ°å“åº”ä¹‹å‰ä¸ä¼šç»§ç»­æ‰§è¡Œã€‚
- en: As you can see, the `get_transcript` function also invokes the `print_text_while_waiting_for_transcription`
    function. Why? Since obtaining the transcription is a time-consuming task, we
    wanted to keep the user informed that the program is actively processing their
    request and not stuck or unresponsive. As a result, this text is gradually printed
    as the user awaits the next step.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œ`get_transcript` å‡½æ•°è¿˜è°ƒç”¨äº† `print_text_while_waiting_for_transcription`
    å‡½æ•°ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºè·å–è½¬å½•æ˜¯ä¸€ä¸ªè€—æ—¶çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å¸Œæœ›è®©ç”¨æˆ·çŸ¥é“ç¨‹åºæ­£åœ¨ç§¯æå¤„ç†ä»–ä»¬çš„è¯·æ±‚ï¼Œè€Œä¸æ˜¯å¡ä½æˆ–æ— å“åº”ã€‚å› æ­¤ï¼Œåœ¨ç”¨æˆ·ç­‰å¾…ä¸‹ä¸€æ­¥æ“ä½œæ—¶ï¼Œè¿™æ®µæ–‡å­—ä¼šé€æ¸æ‰“å°å‡ºæ¥ã€‚
- en: String Matching Using FuzzyWuzzy for Text Comparison
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ FuzzyWuzzy è¿›è¡Œæ–‡æœ¬æ¯”è¾ƒçš„å­—ç¬¦ä¸²åŒ¹é…
- en: After transcribing the speech into text, we either utilized it as is, or attempted
    to compare it with an existing string.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¯­éŸ³è½¬å½•ä¸ºæ–‡æœ¬åï¼Œæˆ‘ä»¬è¦ä¹ˆç›´æ¥ä½¿ç”¨å®ƒï¼Œè¦ä¹ˆå°è¯•å°†å…¶ä¸ç°æœ‰å­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒã€‚
- en: 'The comparison use cases were: selecting a figure from a predefined list of
    options, deciding whether to continue playing or not, and when opting to continue
    - deciding whether to choose a new figure or stick with the current one.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”è¾ƒçš„ä½¿ç”¨æ¡ˆä¾‹åŒ…æ‹¬ï¼šä»é¢„å®šä¹‰çš„é€‰é¡¹åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªè§’è‰²ï¼Œå†³å®šæ˜¯å¦ç»§ç»­æ¸¸æˆï¼Œä»¥åŠåœ¨é€‰æ‹©ç»§ç»­æ—¶â€”â€”å†³å®šæ˜¯é€‰æ‹©æ–°è§’è‰²è¿˜æ˜¯ç»§ç»­å½“å‰è§’è‰²ã€‚
- en: In such cases, we wanted to compare the userâ€™s spoken input transcription with
    the options in our lists, and therefore we decided to use the `FuzzyWuzzy` library
    for string matching.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›å°†ç”¨æˆ·çš„è¯­éŸ³è¾“å…¥è½¬å½•ä¸æˆ‘ä»¬åˆ—è¡¨ä¸­çš„é€‰é¡¹è¿›è¡Œæ¯”è¾ƒï¼Œå› æ­¤æˆ‘ä»¬å†³å®šä½¿ç”¨`FuzzyWuzzy`åº“è¿›è¡Œå­—ç¬¦ä¸²åŒ¹é…ã€‚
- en: This enabled choosing the closest option from the list, as long as the matching
    score exceeded a predefined threshold.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥ä»åˆ—è¡¨ä¸­é€‰æ‹©æœ€æ¥è¿‘çš„é€‰é¡¹ï¼Œåªè¦åŒ¹é…åˆ†æ•°è¶…è¿‡é¢„å®šçš„é˜ˆå€¼ã€‚
- en: 'Hereâ€™s a snippet of our function:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬åŠŸèƒ½çš„ä¸€æ®µä»£ç ï¼š
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you want to learn more about the `FuzzyWuzzy` library and its functions â€”
    you can check out an article I wrote about it [here](/string-comparison-is-easy-with-fuzzywuzzy-library-611cc1888d97).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº`FuzzyWuzzy`åº“åŠå…¶åŠŸèƒ½çš„ä¿¡æ¯ï¼Œå¯ä»¥é˜…è¯»æˆ‘å†™çš„è¿™ç¯‡æ–‡ç« [è¿™é‡Œ](/string-comparison-is-easy-with-fuzzywuzzy-library-611cc1888d97)ã€‚
- en: Get ChatGPT Response
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è·å–ChatGPTå“åº”
- en: Once we have the transcription, we can send it over to `ChatGPT` to get a response.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬å¾—åˆ°äº†è½¬å½•å†…å®¹ï¼Œå°±å¯ä»¥å°†å…¶å‘é€ç»™`ChatGPT`ä»¥è·å–å›å¤ã€‚
- en: For each `ChatGPT` request, we added a prompt asking for a short and funny response.
    We also told `ChatGPT` which figure to pretend to be.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ª`ChatGPT`è¯·æ±‚ï¼Œæˆ‘ä»¬éƒ½ä¼šæ·»åŠ ä¸€ä¸ªæç¤ºï¼Œè¦æ±‚å®ƒç»™å‡ºç®€çŸ­è€Œæœ‰è¶£çš„å›åº”ã€‚æˆ‘ä»¬è¿˜å‘Šè¯‰`ChatGPT`åº”è¯¥å‡è£…æˆå“ªä¸ªè§’è‰²ã€‚
- en: 'So our function looked as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬çš„åŠŸèƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'and the system instructions looked as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç³»ç»ŸæŒ‡ä»¤å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Text to Speech
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ–‡æœ¬è½¬è¯­éŸ³
- en: For the text-to-speech part, we opted for a Python library called `pyttsx3`.
    This choice was not only straightforward to implement but also offered several
    additional advantages. Itâ€™s free of charge, provides two voice options â€” male
    and female â€” and allows you to select the speaking rate in words per minute (speech
    speed).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ–‡æœ¬è½¬è¯­éŸ³éƒ¨åˆ†ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªåä¸º`pyttsx3`çš„Pythonåº“ã€‚è¿™ä¸ªé€‰æ‹©ä¸ä»…å®ç°èµ·æ¥ç›´æ¥ï¼Œè€Œä¸”è¿˜æä¾›äº†è‹¥å¹²é¢å¤–çš„ä¼˜åŠ¿ã€‚å®ƒæ˜¯å…è´¹çš„ï¼Œæä¾›ä¸¤ç§è¯­éŸ³é€‰é¡¹â€”â€”ç”·æ€§å’Œå¥³æ€§â€”â€”å¹¶å…è®¸ä½ é€‰æ‹©è¯­é€Ÿï¼ˆæ¯åˆ†é’Ÿå•è¯æ•°ï¼‰ã€‚
- en: When a user starts the game, they pick a character from a predefined list of
    options. If we couldnâ€™t find a match for what they said within our list, weâ€™d
    randomly select a character from our â€œfallback figuresâ€ list. In both lists, each
    character was associated with a gender, so our text-to-speech function also received
    the voice ID corresponding to the selected gender.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç”¨æˆ·å¼€å§‹æ¸¸æˆæ—¶ï¼Œä»–ä»¬ä»é¢„å®šä¹‰çš„é€‰é¡¹åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªè§’è‰²ã€‚å¦‚æœæˆ‘ä»¬åœ¨åˆ—è¡¨ä¸­æ‰¾ä¸åˆ°åŒ¹é…çš„å†…å®¹ï¼Œå°±ä¼šä»â€œå¤‡é€‰è§’è‰²â€åˆ—è¡¨ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªè§’è‰²ã€‚åœ¨è¿™ä¸¤ä¸ªåˆ—è¡¨ä¸­ï¼Œæ¯ä¸ªè§’è‰²éƒ½ä¸ä¸€ä¸ªæ€§åˆ«å…³è”ï¼Œå› æ­¤æˆ‘ä»¬çš„æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½ä¹Ÿä¼šæ”¶åˆ°å¯¹åº”æ‰€é€‰æ€§åˆ«çš„è¯­éŸ³IDã€‚
- en: 'This is what our text-to-speech function looked like:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬æ–‡æœ¬è½¬è¯­éŸ³åŠŸèƒ½çš„æ ·å­ï¼š
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Main Flow
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸»è¦æµç¨‹
- en: Now that weâ€™ve more or less got all the pieces of our app in place, itâ€™s time
    to dive into the gameplay! The main flow is outlined below. You might notice some
    functions we havenâ€™t delved into (e.g. `choose_figure`, `play_round`), but you
    can explore the full code by [checking out the repo](https://github.com/NaomiKriger/speech_to_speech_magician).
    Eventually, most of these higher-level functions tie into the internal functions
    weâ€™ve covered above.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å¤§è‡´å®Œæˆäº†åº”ç”¨ç¨‹åºçš„æ‰€æœ‰éƒ¨åˆ†ï¼Œæ˜¯æ—¶å€™æ·±å…¥äº†è§£æ¸¸æˆç©æ³•äº†ï¼ä¸»è¦æµç¨‹å¦‚ä¸‹æ‰€ç¤ºã€‚ä½ å¯èƒ½ä¼šæ³¨æ„åˆ°ä¸€äº›æˆ‘ä»¬å°šæœªæ·±å…¥æ¢è®¨çš„åŠŸèƒ½ï¼ˆä¾‹å¦‚`choose_figure`ã€`play_round`ï¼‰ï¼Œä½†ä½ å¯ä»¥é€šè¿‡[æŸ¥çœ‹ä»“åº“](https://github.com/NaomiKriger/speech_to_speech_magician)æ¥æ¢ç´¢å®Œæ•´ä»£ç ã€‚æœ€ç»ˆï¼Œå¤§éƒ¨åˆ†è¿™äº›æ›´é«˜å±‚æ¬¡çš„åŠŸèƒ½éƒ½ä¸æˆ‘ä»¬ä¸Šé¢æåˆ°çš„å†…éƒ¨åŠŸèƒ½ç›¸è”ç³»ã€‚
- en: 'Hereâ€™s a snippet of the main game flow:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸»æ¸¸æˆæµç¨‹çš„ä¸€æ®µä»£ç ï¼š
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The Roads Not Taken
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœªèµ°çš„é“è·¯
- en: 'We had several ideas in mind that we didnâ€™t get to implement during the hackathon.
    This was either because we did not find an API we were satisfied with during that
    weekend, or due to the time constraints preventing us from developing certain
    features. These are the paths we didnâ€™t take for this project:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰å‡ ä¸ªæƒ³æ³•ï¼Œåœ¨é»‘å®¢æ¾æœŸé—´æ²¡æœ‰å®ç°ã€‚è¿™æ˜¯å› ä¸ºåœ¨é‚£ä¸ªå‘¨æœ«æˆ‘ä»¬æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªä»¤æˆ‘ä»¬æ»¡æ„çš„APIï¼Œæˆ–è€…ç”±äºæ—¶é—´é™åˆ¶æ— æ³•å¼€å‘æŸäº›åŠŸèƒ½ã€‚è¿™äº›å°±æ˜¯æˆ‘ä»¬æœªé€‰æ‹©çš„è·¯å¾„ï¼š
- en: Matching the Response Voice with the Chosen Figureâ€™s â€œActualâ€ Voice
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŒ¹é…å“åº”è¯­éŸ³ä¸æ‰€é€‰è§’è‰²çš„â€œå®é™…â€è¯­éŸ³
- en: Imagine if the user chose to talk to Shrek, Trump, or Oprah Winfrey. We wanted
    our text-to-speech library or API to articulate responses using voices that matched
    the chosen figure. However, we couldnâ€™t find a library or API during the hackathon
    that offered this feature at a reasonable cost. Weâ€™re still open to suggestions
    if you have any =)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœç”¨æˆ·é€‰æ‹©ä¸å²ç‘å…‹ã€ç‰¹æœ—æ™®æˆ–å¥¥æ™®æ‹‰Â·æ¸©å¼—ç‘å¯¹è¯ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ–‡æœ¬åˆ°è¯­éŸ³åº“æˆ–APIèƒ½å¤Ÿç”¨ä¸æ‰€é€‰äººç‰©åŒ¹é…çš„å£°éŸ³æ¥è¡¨è¾¾å›åº”ã€‚ç„¶è€Œï¼Œåœ¨é»‘å®¢æ¾æœŸé—´ï¼Œæˆ‘ä»¬æ²¡æœ‰æ‰¾åˆ°ä¸€ä¸ªä»·æ ¼åˆç†çš„åº“æˆ–APIæä¾›è¿™ä¸ªåŠŸèƒ½ã€‚å¦‚æœä½ æœ‰å»ºè®®ï¼Œæˆ‘ä»¬ä¾ç„¶æ¬¢è¿å“¦
    =)
- en: Let the Users Talk to â€œThemselvesâ€
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®©ç”¨æˆ·ä¸â€œè‡ªå·±â€å¯¹è¯
- en: Another intriguing idea was to prompt users to provide a vocal sample of themselves
    speaking. We would then train a model using this sample and have all the responses
    generated by ChatGPT read aloud in the userâ€™s own voice. In this scenario, the
    user could choose the tone of the responses (affirmative and supportive, sarcastic,
    angry, etc.), but the voice would closely resemble that of the user. However,
    we couldnâ€™t find an API that supported this within the constraints of the hackathon.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæœ‰è¶£çš„æƒ³æ³•æ˜¯æç¤ºç”¨æˆ·æä¾›ä»–ä»¬è‡ªå·±çš„è¯­éŸ³æ ·æœ¬ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªæ ·æœ¬è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åè®©ChatGPTç”Ÿæˆçš„æ‰€æœ‰å›åº”ç”¨ç”¨æˆ·è‡ªå·±çš„å£°éŸ³æœ—è¯»ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©å›åº”çš„è¯­æ°”ï¼ˆè‚¯å®šå’Œæ”¯æŒã€è®½åˆºã€æ„¤æ€’ç­‰ï¼‰ï¼Œä½†å£°éŸ³ä¼šå°½å¯èƒ½åƒç”¨æˆ·è‡ªå·±çš„å£°éŸ³ã€‚ç„¶è€Œï¼Œåœ¨é»‘å®¢æ¾çš„é™åˆ¶ä¸‹ï¼Œæˆ‘ä»¬æ²¡èƒ½æ‰¾åˆ°æ”¯æŒè¿™ç§åŠŸèƒ½çš„APIã€‚
- en: Adding a Frontend to Our Application
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºæˆ‘ä»¬çš„åº”ç”¨æ·»åŠ å‰ç«¯
- en: Our initial plan was to include a frontend component in our application. However,
    due to a last-minute change in the number of participants in our group, we decided
    to prioritize the backend development. As a result, the application currently
    runs on the command line interface (CLI) and doesnâ€™t have frontend side.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€åˆçš„è®¡åˆ’æ˜¯åœ¨åº”ç”¨ç¨‹åºä¸­åŒ…å«ä¸€ä¸ªå‰ç«¯ç»„ä»¶ã€‚ç„¶è€Œï¼Œç”±äºç»„å†…å‚ä¸è€…äººæ•°çš„ä¸´æ—¶å˜åŠ¨ï¼Œæˆ‘ä»¬å†³å®šä¼˜å…ˆå¼€å‘åç«¯ã€‚å› æ­¤ï¼Œå½“å‰åº”ç”¨ç¨‹åºä»…åœ¨å‘½ä»¤è¡Œç•Œé¢ï¼ˆCLIï¼‰ä¸Šè¿è¡Œï¼Œæ²¡æœ‰å‰ç«¯éƒ¨åˆ†ã€‚
- en: Additional Improvements We Have In Mind
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è€ƒè™‘çš„å…¶ä»–æ”¹è¿›
- en: Latency is what bothers me most at the moment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰æœ€å›°æ‰°æˆ‘çš„æ˜¯å»¶è¿Ÿã€‚
- en: 'There are several components in the flow with a relatively high latency that
    in my opinion slightly harm the user experience. For example: the time it takes
    from finishing providing the audio input and receiving a transcription, and the
    time it takes since the user presses a button until the system actually starts
    recording the audio. So if the user starts talking right after pressing the key
    â€” there will be at least one second of audio that wonâ€™t be recorded due to this
    lag.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æµç¨‹ä¸­æœ‰å‡ ä¸ªç›¸å¯¹è¾ƒé«˜å»¶è¿Ÿçš„ç»„ä»¶ï¼Œåœ¨æˆ‘çœ‹æ¥ç¨å¾®å½±å“äº†ç”¨æˆ·ä½“éªŒã€‚ä¾‹å¦‚ï¼šä»æä¾›éŸ³é¢‘è¾“å…¥åˆ°æ”¶åˆ°è½¬å½•æ–‡æœ¬ä¹‹é—´çš„æ—¶é—´ï¼Œä»¥åŠä»ç”¨æˆ·æŒ‰ä¸‹æŒ‰é’®åˆ°ç³»ç»Ÿå®é™…å¼€å§‹å½•éŸ³ä¹‹é—´çš„æ—¶é—´ã€‚æ‰€ä»¥ï¼Œå¦‚æœç”¨æˆ·åœ¨æŒ‰ä¸‹æŒ‰é’®åç«‹å³å¼€å§‹è®²è¯â€”â€”ç”±äºè¿™ç§å»¶è¿Ÿï¼Œè‡³å°‘ä¼šæœ‰ä¸€ç§’é’Ÿçš„éŸ³é¢‘æ²¡æœ‰è¢«å½•åˆ¶ã€‚
- en: Link to the Repo & Credits
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»“åº“é“¾æ¥ä¸è‡´è°¢
- en: Want to see the whole project? [Itâ€™s right here](https://github.com/NaomiKriger/speech_to_speech_magician)!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³çœ‹çœ‹æ•´ä¸ªé¡¹ç›®å—ï¼Ÿ[å°±åœ¨è¿™é‡Œ](https://github.com/NaomiKriger/speech_to_speech_magician)!
- en: Also, warm credit goes to [Lior Yardeni](https://www.linkedin.com/in/lioryardeni),
    my hackathon partner with whom I created this game.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ¸©æš–çš„è‡´è°¢é€ç»™æˆ‘çš„é»‘å®¢æ¾ä¼™ä¼´[åˆ©å¥¥å°”Â·é›…å°”å¾·å°¼](https://www.linkedin.com/in/lioryardeni)ï¼Œæ˜¯ä»–å’Œæˆ‘ä¸€èµ·åˆ›é€ äº†è¿™ä¸ªæ¸¸æˆã€‚
- en: Summing Up
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: In this article, we learned how to create a speech-to-text-to-speech game using
    Python, and intertwined it with AI. Weâ€™ve used the `Whisper` model by `OpenAI`
    for speech recognition, played around with the `FuzzyWuzzy` library for text matching,
    tapped into `ChatGPT`â€™s conversational magic via their developer API, and brought
    it all to life with `pyttsx3` for text-to-speech. While `OpenAI`â€™s services (`Whisper`
    and `ChatGPT` for developers) do come with a modest cost, itâ€™s budget-friendly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨Pythonåˆ›å»ºä¸€ä¸ªè¯­éŸ³åˆ°æ–‡æœ¬å†åˆ°è¯­éŸ³çš„æ¸¸æˆï¼Œå¹¶å°†å…¶ä¸AIç»“åˆã€‚æˆ‘ä»¬ä½¿ç”¨äº†`OpenAI`çš„`Whisper`æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œç©å¼„äº†`FuzzyWuzzy`åº“è¿›è¡Œæ–‡æœ¬åŒ¹é…ï¼Œåˆ©ç”¨`ChatGPT`çš„å¯¹è¯é­”åŠ›é€šè¿‡å¼€å‘è€…APIå®ç°ï¼Œå¹¶é€šè¿‡`pyttsx3`å°†å…¶è½¬æ¢ä¸ºè¯­éŸ³ã€‚è™½ç„¶`OpenAI`çš„æœåŠ¡ï¼ˆ`Whisper`å’Œ`ChatGPT`å¼€å‘è€…ç‰ˆï¼‰ç¡®å®æœ‰ä¸€å®šçš„è´¹ç”¨ï¼Œä½†å®ƒè¿˜æ˜¯å¾ˆå®æƒ çš„ã€‚
- en: We hope youâ€™ve found this guide enlightening and that itâ€™s motivating you to
    embark on your projects.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡æŒ‡å—å¯¹ä½ æœ‰æ‰€å¯å‘ï¼Œå¹¶æ¿€åŠ±ä½ å¼€å§‹ä½ çš„é¡¹ç›®ã€‚
- en: Cheers to coding and fun! ğŸš€
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºç¼–ç¨‹å’Œä¹è¶£å¹²æ¯ï¼ğŸš€
