- en: A Beginner’s Guide to Building Knowledge Graphs from Videos
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从视频构建知识图谱的入门指南
- en: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-knowledge-graphs-from-videos-6cafcba5f3e5?source=collection_archive---------5-----------------------#2024-01-17](https://towardsdatascience.com/a-beginners-guide-to-building-knowledge-graphs-from-videos-6cafcba5f3e5?source=collection_archive---------5-----------------------#2024-01-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-knowledge-graphs-from-videos-6cafcba5f3e5?source=collection_archive---------5-----------------------#2024-01-17](https://towardsdatascience.com/a-beginners-guide-to-building-knowledge-graphs-from-videos-6cafcba5f3e5?source=collection_archive---------5-----------------------#2024-01-17)
- en: Build a pipeline to analyze and store the data within videos.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个管道来分析并存储视频中的数据。
- en: '[](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[![Mohammed
    Mohammed](../Images/33e1776db18c6f71c5b4138fd4536043.png)](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)
    [Mohammed Mohammed](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[![Mohammed
    Mohammed](../Images/33e1776db18c6f71c5b4138fd4536043.png)](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)
    [Mohammed Mohammed](https://mohammed249.medium.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)
    ·10 min read·Jan 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6cafcba5f3e5--------------------------------)
    ·阅读时间：10分钟·2024年1月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Before diving into the technical aspect of the article let’s set the context
    and answer the question that you might have, What is a knowledge graph ?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论本文的技术内容之前，让我们先设定一下背景，回答一个你可能有的问题：什么是知识图谱？
- en: And to answer this, imagine instead of storing the knowledge in cabinets we
    store them in a fabric net. Each fact, concept, piece of information about people,
    places, events, or even abstract ideas are knots, and the line connecting them
    together is the relationship they have with each other. This intricate web, my
    friends, is the essence of a knowledge graph.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，想象一下，不是将知识存储在文件柜中，而是将它们存储在一张织网中。每一个事实、概念、关于人、地点、事件甚至抽象概念的信息都是一个节点，而将它们连接在一起的线条则是它们之间的关系。这张错综复杂的网络，朋友们，就是知识图谱的精髓。
- en: '![](../Images/1ecf3cc7e1b15408e2b01383c3a18df7.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ecf3cc7e1b15408e2b01383c3a18df7.png)'
- en: Photo by [Shubham Dhage](https://unsplash.com/@theshubhamdhage?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Shubham Dhage](https://unsplash.com/@theshubhamdhage?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Think of it like a bustling city map, not just showing streets but revealing
    the connections between landmarks, parks, and shops. Similarly, a knowledge graph
    doesn’t just store cold facts; it captures the rich tapestry of how things are
    linked. For example, you might learn that Marie Curie discovered radium, then
    follow a thread to see that radium is used in medical treatments, which in turn
    connect to hospitals and cancer research. See how one fact effortlessly leads
    to another, painting a bigger picture?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '可以把它想象成一张繁忙的城市地图，不仅显示街道，还揭示了地标、公园和商店之间的联系。同样，知识图谱不仅仅是存储冷冰冰的事实，它捕捉了事物如何相互联系的丰富画面。例如，你可能知道玛丽·居里发现了镭，然后通过一条线索发现镭被用于医学治疗，进而与医院和癌症研究相关联。你看到了吗？一个事实如何自然而然地引导到另一个事实，勾画出一个更大的图景。 '
- en: So why is this map-like way of storing knowledge so popular? Well, imagine searching
    for information online. Traditional methods often leave you with isolated bits
    and pieces, like finding only buildings on a map without knowing the streets that
    connect them. A knowledge graph, however, takes you on a journey, guiding you
    from one fact to another, like having a friendly guide whisper fascinating stories
    behind every corner of the information world. Interesting right? I know.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么这种像地图一样存储知识的方式如此流行呢？嗯，想象一下在线搜索信息。传统的方法常常让你得到的是零散的片段，就像你只看到地图上的建筑物，却不知道连接它们的街道。而知识图谱则像是带你进行一场旅行，从一个事实引导到另一个事实，就像有一个友好的向导在信息世界的每个角落悄悄地讲述迷人的故事。很有趣，对吧？我知道。
- en: Since I discovered this magic, it captured my attention and I explored and played
    around with many potential applications. In this article, I will show you how
    to build a pipeline that extracts audio from video, then transcribes that audio,
    and from the transcription, build a knowledge graph allowing for a more nuanced
    and interconnected representation of information within the video.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我发现了这个魔法，它就吸引了我的注意力，我探索并玩弄了许多潜在的应用。在这篇文章中，我将向你展示如何构建一个管道，从视频中提取音频，然后将音频转录，再从转录的文本中构建一个知识图谱，从而实现对视频中信息的更加细致和互联的表示。
- en: 'I will be using Google Drive to upload the video sample. I will also use Google
    Colab to write the code, and finally, you need access to the GPT Plus API for
    this project. I will break this down into steps to make it clear and easy for
    beginners:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用 Google Drive 来上传视频样本。我还将使用 Google Colab 编写代码，最后，你需要有 GPT Plus API 的访问权限来进行这个项目。我将把步骤分解清楚，确保对初学者来说易于理解：
- en: Setting up everything.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置一切。
- en: Extracting audio from video.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从视频中提取音频。
- en: Transcribing audio to text.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将音频转录为文本。
- en: Building the knowledge graph.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建知识图谱。
- en: By the end of this article, you will construct a graph with the following schema.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到了本文的最后，你将构建一个如下所示的图谱。
- en: '![](../Images/06861e8c6ec369ade11ea179528932f2.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06861e8c6ec369ade11ea179528932f2.png)'
- en: Image by the author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Let’s dive right into it!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接开始吧！
- en: '**1- Setting up everything**'
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1- 设置一切**'
- en: As mentioned, we will be using Google Drive and Colab. In the first cell, let’s
    connect Google Drive to Colab and create our directory folders (video_files, audio_files,
    text_files). The following code can get this done. (*If you want to follow along
    with the code, I have uploaded all the code for this project on GitHub; you can
    access it from* [***here***](https://github.com/mohammed-249/Data_Science_Projects/tree/main/NLP%20%7C%20Building%20Knowledge%20Graph%20from%20videos)*.*)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用 Google Drive 和 Colab。在第一个单元格中，让我们将 Google Drive 连接到 Colab，并创建我们的目录文件夹（video_files、audio_files、text_files）。下面的代码可以完成这项工作。(*如果你想跟着代码一起操作，我已经将这个项目的所有代码上传到
    GitHub，你可以从* [***这里***](https://github.com/mohammed-249/Data_Science_Projects/tree/main/NLP%20%7C%20Building%20Knowledge%20Graph%20from%20videos)*访问它。*)
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Or you can create the folders manually and upload your video sample to the
    “video_files” folder, whichever is easier for you.*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*或者，你也可以手动创建文件夹，并将视频样本上传到“video_files”文件夹，随你更方便的方式来做。*'
- en: Now we have our three folders with a video sample in the “video_files” folder
    to test the code.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了三个文件夹，其中“video_files”文件夹中有一个视频样本，用于测试代码。
- en: 2- Extracting audio from video
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2- 从视频中提取音频
- en: The next thing we want to do is to import our video and extract the audio from
    it. We can use the *Pydub* library, which is a high-level audio processing library
    that can help us to do that. Let’s see the code and then explain it underneath.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要做的是导入视频并从中提取音频。我们可以使用 *Pydub* 库，它是一个高级音频处理库，可以帮助我们完成这项工作。让我们看看代码，然后再在下面解释。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After installing our package *pydub*, we imported the *AudioSegment* class from
    the *Pydub* library. Then, we created a loop that iterates through all the video
    files in the “video_files” folder we created earlier and passes each file through
    *AudioSegment.from_file* to load the audio from the video file. The loaded audio
    is then exported as a WAV file using *audio.export* and saved in the specified
    “audio_files” folder with the same name as the video file but with the extension
    .wav.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完我们的包 *pydub* 后，我们从 *Pydub* 库中导入了 *AudioSegment* 类。接着，我们创建了一个循环，遍历我们之前创建的“video_files”文件夹中的所有视频文件，并通过
    *AudioSegment.from_file* 将每个文件加载为音频。然后，使用 *audio.export* 将加载的音频导出为 WAV 文件，并保存到指定的“audio_files”文件夹中，文件名与视频文件相同，但扩展名为
    .wav。
- en: At this point, you can go to the “audio_files” folder in Google Drive where
    you will see the extracted audio.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可以去 Google Drive 中的“audio_files”文件夹，那里可以看到提取的音频。
- en: 3- Transcribing audio to text
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3- 音频转录为文本
- en: In the third step, we will transcribe the audio file we have to a text file
    and save it as a .txt file in the “text_files” folder. Here I used the Whisper
    ASR (Automatic Speech Recognition) system from OpenAI to do this. I used it because
    it’s easy and fairly accurate, beside it has different models for different accuracy.
    But the more accurate the model is the larger the model the slower to load, hence
    I will be using the medium one just for demonstration. To make the code cleaner,
    let’s create a function that transcribes the audio and then use a loop to use
    the function on all the audio files in our directory
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三步，我们将把音频文件转录为文本文件，并将其作为 .txt 文件保存在“text_files”文件夹中。在这里，我使用了 OpenAI 的 Whisper
    ASR（自动语音识别）系统来完成这项工作。我之所以选择它，是因为它简单且相当准确，并且它有不同的模型可以提供不同的准确度。不过，模型越准确，模型的体积就越大，加载速度也会越慢，因此我将使用中等精度的模型来进行演示。为了使代码更简洁，我们将创建一个函数来转录音频，然后使用循环对目录中的所有音频文件应用这个函数。
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Libraries Used:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用的库：**'
- en: '*os*: Provides a way of interacting with the operating system, used for handling
    file paths and names.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*os*: 提供与操作系统交互的方式，用于处理文件路径和文件名。'
- en: '*re*: Regular expression module for pattern matching and substitution.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*re*: 用于模式匹配和替换的正则表达式模块。'
- en: '*subprocess*: Allows the creation of additional processes, used here to execute
    the Whisper ASR system from the command line.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*subprocess*: 允许创建额外的进程，这里用来从命令行执行 Whisper ASR 系统。'
- en: We created a Whisper command and saved it as a variable to facilitate the process.
    After that, we used *subprocess.check_output* to run the Whisper command and save
    the resulting transcription in the transcription variable. But the transcription
    at this point is not clean (*you can check it by printing the transcription variable
    out of the function; it has timestamps and a couple of lines that are not relevant
    to the transcription*), so we added a cleaning code that removes the timestamp
    using *re.sub* and joins the sentences together. After that, we created a text
    file within the “text_files” folder with the same name as the audio and saved
    the cleaned transcription in it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个 Whisper 命令，并将其保存为变量以便于处理。之后，我们使用 *subprocess.check_output* 来运行 Whisper
    命令，并将生成的转录结果保存在 transcription 变量中。但此时的转录结果并不干净（*你可以通过在函数外打印 transcription 变量来检查，它包含时间戳和一些与转录无关的内容*），因此我们添加了一个清理代码，使用
    *re.sub* 去除时间戳并将句子合并在一起。之后，我们在“text_files”文件夹中创建了一个与音频文件同名的文本文件，并将清理后的转录结果保存到其中。
- en: Now if you go to the “text_files” folder, you can see the text file that contains
    the transcription. Woah, step 3 done successfully! Congratulations!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你去“text_files”文件夹，你可以看到包含转录结果的文本文件。哇，第三步成功完成！恭喜！
- en: 4- Building the knowledge graph
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4- 构建知识图谱
- en: This is the crucial part — and maybe the longest. I will follow a modular approach
    with 5 functions to handle this task, but before that, let’s begin with the libraries
    and modules necessary for making HTTP requests *requests*, handling JSON *json*,
    working with data frames *pandas*, and creating and visualizing graphs *networkx*
    and *matplotlib*. And setting the global constants which are variables used throughout
    the code. *API_ENDPOINT* is the endpoint for OpenAI’s API, *API_KEY* is where
    the OpenAI API key will be stored, and *prompt_text* will store the text used
    as input for the OpenAI prompt. All of this is done in this code
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关键部分——可能也是最长的部分。我将采用模块化方法，使用 5 个函数来处理这项任务，但在此之前，让我们先从必要的库和模块开始，包括用于发出 HTTP
    请求的 *requests*，用于处理 JSON 数据的 *json*，用于处理数据框的 *pandas*，以及用于创建和可视化图形的 *networkx*
    和 *matplotlib*。同时，还需要设置全局常量，这些常量是在代码中各个地方使用的变量。*API_ENDPOINT* 是 OpenAI API 的端点，*API_KEY*
    是存储 OpenAI API 密钥的位置，*prompt_text* 将存储用作 OpenAI 提示输入的文本。所有这些都在这段代码中完成。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Then let’s continue with breaking down the structure of our functions:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**接下来，让我们继续分析我们函数的结构：**'
- en: '**The first function**, *create_graph()*, the task of this function is to create
    a graph visualization using the *networkx* library. It takes a DataFrame *df*
    and a dictionary of edge labels *rel_labels* — which will be created on the following
    function — as input. Then, it uses the DataFrame to create a directed graph and
    visualizes it using *matplotlib* with some customization and outputs the beautiful
    graph we need'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**第一个函数**，*create_graph()*，该函数的任务是使用 *networkx* 库创建一个图形可视化。它接收一个 DataFrame
    *df* 和一个边标签字典 *rel_labels*（将在下一个函数中创建）作为输入。然后，它使用 DataFrame 创建一个有向图，并利用 *matplotlib*
    进行可视化，经过一些自定义后输出我们需要的漂亮图形。'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The DataFrame *df* and the edge labels *rel_labels* are the output of the next
    function, which is: *preparing_data_for_graph()*. This function takes the OpenAI
    *api_response* — which will be created from the following function — as input
    and extracts the entity-relation triples (*source, target, edge*) from it. Here
    we used the *json* module to parse the response and obtain the relevant data,
    then filter out elements that have missing data. After that, build a knowledge
    base dataframe *kg_df* from the triples, and finally, create a dictionary (*relation_labels*)
    mapping pairs of nodes to their corresponding edge labels, and of course, return
    the DataFrame and the dictionary.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame *df* 和边标签 *rel_labels* 是下一个函数 *preparing_data_for_graph()* 的输出。这个函数将作为输入的
    OpenAI *api_response*（将在下一个函数中创建）进行处理，并从中提取实体关系三元组 (*source, target, edge*)。这里我们使用
    *json* 模块解析响应并获取相关数据，然后过滤掉缺失数据的元素。之后，根据这些三元组构建一个知识库 DataFrame *kg_df*，最后创建一个字典
    (*relation_labels*)，将节点对与对应的边标签进行映射，最终返回 DataFrame 和字典。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The third function is *call_gpt_api()*, which is responsible for making a POST
    request to the OpenAI API and output the *api_response*. Here we construct the
    data payload with model information, prompt, and other parameters like the model
    (in this case: *gpt-3.5-turbo-instruct*), max_tokens, stop, and temperature. Then
    send the request using *requests.post* and return the response. I have also included
    simple error handling to print an error message in case an exception occurs. The
    try block contains the code that might raise an exception from the request during
    execution, so if an exception occurs during this process (for example, due to
    network issues, API errors, etc.), the code within the except block will be executed.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个函数是 *call_gpt_api()*，它负责向 OpenAI API 发送 POST 请求并输出 *api_response*。这里我们构造了一个包含模型信息、提示词和其他参数（如模型（此处为：*gpt-3.5-turbo-instruct*）、max_tokens、stop
    和 temperature）的数据负载。然后通过 *requests.post* 发送请求并返回响应。我还加入了简单的错误处理，如果发生异常，将打印错误信息。try
    块包含可能会在执行过程中抛出异常的请求代码，因此如果在此过程中发生异常（例如网络问题、API 错误等），except 块中的代码将会被执行。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then the function before the last is the *main()* function, which orchestrates
    the main flow of the script. First, it reads the text file contents from the “text_files”
    folder we had earlier and saves it in the variable *kb_text*. Bring the global
    variable *prompt_text*, which stores our prompt, then replace a placeholder in
    the prompt template (*$prompt*) with the text file content *kb_text*. Then call
    the *call_gpt_api()* function, give it the *api_key* and *prompt_text* to get
    the OpenAI API response. The response is then passed to *preparing_data_for_graph()*
    to prepare the data and get the DataFrame and the edge labels dictionary, finally
    pass these two values to the *create_graph()* function to build the knowledge
    graph.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后倒数第二个函数是 *main()* 函数，它协调脚本的主流程。首先，它读取之前在“text_files”文件夹中的文本文件内容，并将其保存到变量 *kb_text*
    中。接着获取存储我们提示词的全局变量 *prompt_text*，然后用文本文件内容 *kb_text* 替换提示模板中的占位符 (*$prompt*)。接下来调用
    *call_gpt_api()* 函数，传入 *api_key* 和 *prompt_text*，以获取 OpenAI API 的响应。然后将响应传递给 *preparing_data_for_graph()*
    函数，以准备数据并获取 DataFrame 和边标签字典，最后将这两个值传递给 *create_graph()* 函数来构建知识图谱。
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, we have the *start()* function, which iterates through all the text
    files in our “text_files” folder — if we have more than one, gets the name and
    the path of the file, and passes it along with the *api_key* to the main function
    to do its job.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后是 *start()* 函数，它会遍历我们“text_files”文件夹中的所有文本文件——如果有多个文件，它会获取文件的名称和路径，并将其与 *api_key*
    一起传递给主函数以完成任务。
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you have correctly followed the steps, after running the *start()* function,
    you should see a similar visualization.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正确地按照步骤操作，运行 *start()* 函数后，你应该能看到类似的可视化效果。
- en: '![](../Images/06861e8c6ec369ade11ea179528932f2.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06861e8c6ec369ade11ea179528932f2.png)'
- en: Image by the author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: You can of course save this knowledge graph in the Neo4j database and take it
    further.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你当然可以将这个知识图谱保存到Neo4j数据库中，并进一步拓展。
- en: 'NOTE: This workflow ONLY applies to videos you own or whose terms allow this
    kind of download/processing.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：此工作流仅适用于你拥有的视频，或其条款允许这种下载/处理的情况。
- en: 'Summary:'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要：
- en: Knowledge graphs use semantic relationships to represent data, enabling a more
    nuanced and context-aware understanding. This semantic richness allows for more
    sophisticated querying and analysis, as the relationships between entities are
    explicitly defined.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱利用语义关系来表示数据，从而实现更细致和具有上下文意识的理解。这种语义丰富性使得查询和分析更加复杂，因为实体之间的关系被明确地定义了。
- en: In this article, I outline detailed steps on how to build a pipeline that involves
    extracting audio from videos, transcribing with OpenAI’s Whisper ASR, and crafting
    a knowledge graph. As someone interested in this field, I hope that this article
    makes it easier to understand for beginners, demonstrating the potential and versatility
    of knowledge graph applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我概述了如何构建一个流程，包括从视频中提取音频，使用OpenAI的Whisper ASR进行转录，以及构建知识图谱的详细步骤。作为对这一领域感兴趣的人，我希望本文能使初学者更容易理解，展示知识图谱应用的潜力和多样性。
- en: And as always the whole code is available in [GitHub](https://github.com/mohammed-249/Data_Science_Projects/tree/main/NLP%20%7C%20Building%20Knowledge%20Graph%20from%20videos).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的完整版本可以在[GitHub](https://github.com/mohammed-249/Data_Science_Projects/tree/main/NLP%20%7C%20Building%20Knowledge%20Graph%20from%20videos)找到。
