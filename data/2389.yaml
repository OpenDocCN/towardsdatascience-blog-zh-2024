- en: Geographic Position Encoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 地理位置编码器
- en: 原文：[https://towardsdatascience.com/geographic-position-encoders-59dafebf6f2d?source=collection_archive---------10-----------------------#2024-10-01](https://towardsdatascience.com/geographic-position-encoders-59dafebf6f2d?source=collection_archive---------10-----------------------#2024-10-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/geographic-position-encoders-59dafebf6f2d?source=collection_archive---------10-----------------------#2024-10-01](https://towardsdatascience.com/geographic-position-encoders-59dafebf6f2d?source=collection_archive---------10-----------------------#2024-10-01)
- en: Understanding modern techniques for encoding geographic coordinates in a neural
    network
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解现代技术如何在神经网络中编码地理坐标
- en: '[](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)[![Ruth
    Crasto](../Images/5deaf13d4a79273e3f2986793aecc123.png)](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)
    [Ruth Crasto](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)[![Ruth
    Crasto](../Images/5deaf13d4a79273e3f2986793aecc123.png)](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)
    [Ruth Crasto](https://medium.com/@crastoru?source=post_page---byline--59dafebf6f2d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)
    ·10 min read·Oct 1, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--59dafebf6f2d--------------------------------)
    ·10分钟阅读·2024年10月1日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5d581953d4a0e7b66067889fdc282b58.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d581953d4a0e7b66067889fdc282b58.png)'
- en: Photo by [CHUTTERSNAP](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [CHUTTERSNAP](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral)
    提供，来源：[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'An inductive bias in machine learning is a constraint on a model given some
    prior knowledge of the target task. As humans, we can recognize a bird whether
    it’s flying in the sky or perched in a tree. Moreover, we don’t need to examine
    every cloud or take in the entirety of the tree to know that we are looking at
    a bird and not something else. These biases in the vision process are encoded
    in convolution layers via two properties:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的归纳偏差是基于某些先验知识对模型施加的约束。作为人类，我们可以识别出飞翔在天空中的鸟或栖息在树上的鸟。此外，我们不需要检查每一朵云或完全观察整棵树，就能知道我们正在看的是鸟而不是其他东西。这些在视觉过程中的偏差通过两个属性在卷积层中编码：
- en: '**Weight sharing**: the same kernel weights are re-used along an input channel’s
    full width and height.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**权重共享**：相同的卷积核权重在输入通道的整个宽度和高度上被重复使用。'
- en: '**Locality**: the kernel has a much smaller width and height than the input.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部性**：卷积核的宽度和高度远小于输入。'
- en: We can also encode inductive biases in our choice of input features to the model,
    which can be interpreted as a constraint on the model itself. Designing input
    features for a neural network involves a trade-off between expressiveness and
    inductive bias. On one hand, we want to allow the model the flexibility to learn
    patterns beyond what we humans can detect and encode. On the other hand, a model
    without any inductive biases will struggle to learn anything meaningful at all.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过选择模型的输入特征来编码归纳偏差，这可以看作是对模型本身的约束。为神经网络设计输入特征涉及表达能力和归纳偏差之间的权衡。一方面，我们希望允许模型具备灵活性，学习超出人类能够检测和编码的模式。另一方面，若没有任何归纳偏差的模型将难以学到任何有意义的内容。
- en: In this article, we will explore the inductive biases that go into designing
    effective position encoders for geographic coordinates. Position on Earth can
    be a useful input to a wide range of prediction tasks, including image classification.
    As we will see, using latitude and longitude directly as input features is under-constraining
    and ultimately will make it harder for the model to learn anything meaningful.
    Instead, it is more common to encode prior knowledge about latitude and longitude
    in a nonparametric re-mapping that we call a positional encoder.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨设计有效位置编码器的归纳偏差，特别是在地理坐标上的应用。地球上的位置可以作为广泛预测任务的有用输入，包括图像分类。正如我们将看到的，直接使用纬度和经度作为输入特征是约束不足的，最终会使模型更难学习有意义的内容。相反，更常见的做法是将纬度和经度的先验知识编码为一种非参数化的重新映射，我们称之为位置编码器。
- en: 'Introduction: Position Encoders in Transformers'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍：变换器中的位置编码器
- en: 'To motivate the importance of choosing effective position encoder more broadly,
    let’s first examine the well-known position encoder in the transformer model.
    We start with the notion that the representation of a token input to an attention
    block should include some information about its position in the sequence it belongs
    to. The question is then: how should we encode the position index (0, 1, 2…) into
    a vector?'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更广泛地说明选择有效位置编码器的重要性，我们首先来看看变换器模型中著名的位置编码器。我们从一个观点开始：传递给注意力模块的标记输入的表示应该包含一些关于它在所属序列中位置的信息。问题是：我们应当如何将位置索引（0,
    1, 2…）编码为一个向量？
- en: 'Assume we have a position-independent token embedding. One possible approach
    is to add or concatenate the index value directly to this embedding vector. Here
    is why this doesn’t work well:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个与位置无关的标记嵌入。一种可能的方法是将索引值直接加到这个嵌入向量中或与之连接。以下是为什么这种方法效果不佳的原因：
- en: The similarity (dot product) between two embeddings — after their position has
    been encoded — should be independent of the total number of tokens in the sequence.
    The two last tokens of a sequence should record the same similarity whether the
    sequence is 5 or 50 words long.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个嵌入之间的相似性（点积）——在它们的位置被编码之后——应当独立于序列中标记的总数。序列的最后两个标记无论序列长度是5个单词还是50个单词，它们应该记录相同的相似性。
- en: The similarity between two tokens should not depend on the absolute value of
    their positions, but only the relative distance between them. Even if the encoded
    indices were normalized to the range [0, 1], two adjacent tokens at positions
    1 and 2 would record a lower similarity than the same two tokens later in the
    sequence.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个标记之间的相似性不应该依赖于它们位置的绝对值，而只应依赖于它们之间的相对距离。即使编码的索引被归一化到[0, 1]的范围内，位置为1和2的相邻两个标记也会记录比序列中稍后位置的相同两个标记更低的相似性。
- en: 'The original “Attention is All You Need” paper [[1]](https://arxiv.org/pdf/1706.03762)
    proposes instead to encode the position index *pos* into a discrete “snapshot”
    of *k* different sinusoids, where *k* is the dimension of the token embeddings.
    These snapshots are computed as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的《Attention is All You Need》论文[[1]](https://arxiv.org/pdf/1706.03762)提出的做法是将位置索引*pos*编码为*k*个不同正弦波的离散“快照”，其中*k*是标记嵌入的维度。这些快照计算如下：
- en: '![](../Images/a9556872f6edc6eda258a8d68f95decf.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9556872f6edc6eda258a8d68f95decf.png)'
- en: where *i =* 1, 2, …, *k* / 2\. The resulting *k*-dimensional position embedding
    is then added elementwise to the corresponding token embedding.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *i =* 1, 2, …, *k* / 2\. 然后，得到的*k*维位置嵌入将按元素与对应的标记嵌入相加。
- en: The intuition behind this encoding is that the more snapshots are out of phase
    for any two embeddings, the further apart are their corresponding positions. The
    absolute value of two different positions will not influence how out of phase
    their snapshots are. Moreover, since the range of any sinusoid is the interval
    [-1, 1], the magnitude of the positional embeddings will not grow with sequence
    length.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码的直觉是，任何两个嵌入的快照相位差越大，它们对应位置的距离就越远。两个不同位置的绝对值不会影响它们快照的相位差。此外，由于任何正弦波的范围是[-1,
    1]，位置嵌入的幅度不会随着序列长度的增加而增长。
- en: I won’t go into more detail on this particular position encoder since there
    are several excellent blog posts that do so (see [[2]](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)).
    Hopefully, you can now see why it is important, in general, to think carefully
    about how position should be encoded.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会进一步详细讨论这个特定的定位编码器，因为已经有几篇优秀的博客文章做了深入讲解（见 [[2]](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)）。希望你现在可以理解，一般来说，仔细考虑如何编码位置为什么是如此重要。
- en: Geographic Position Encoders
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 地理位置编码器
- en: Let’s now turn to encoders for geographic position. We want to train a neural
    network to predict some variable of interest given a position on the surface of
    the Earth. How should we encode a position (λ, ϕ) in spherical coordinates — i.e.
    a longitude/latitude pair — into a vector that can be used as an input to our
    network?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向地理位置编码器。我们希望训练一个神经网络，根据地球表面上的位置预测某些感兴趣的变量。我们该如何将球面坐标系中的位置（λ, ϕ）——即经度/纬度对——编码为一个向量，以便将其作为我们网络的输入？
- en: '![](../Images/1b247402a9bb764ff5a8cfafb2529c4f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b247402a9bb764ff5a8cfafb2529c4f.png)'
- en: By Peter Mercator, [Public Domain](https://commons.wikimedia.org/w/index.php?curid=12226167).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Peter Mercator 编著， [公有领域](https://commons.wikimedia.org/w/index.php?curid=12226167)。
- en: Simple approach
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单方法
- en: 'One possible approach would be to use latitude and longitude values directly
    as inputs. In this case our input feature space would be the rectangle [-*π, π*]
    × [0*, π*], which I will refer to as lat/lon space. As with position encoders
    for transformers, this simple approach unfortunately has its limitations:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的方法是直接使用纬度和经度值作为输入。在这种情况下，我们的输入特征空间将是矩形 [-*π, π*] × [0*, π*]，我将其称为纬度/经度空间。与变换器的定位编码器类似，这种简单的方法不幸的是也有其局限性：
- en: Notice that as you move towards the poles, the distance on the surface of the
    Earth covered by 1 unit of longitude (λ) decreases. Lat/lon space does not preserve
    distances on the surface of the Earth.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，当你向两极移动时，地球表面上由 1 单位经度 (λ) 覆盖的距离会减小。纬度/经度空间并不能保持地球表面上的距离。
- en: 'Notice that the position on Earth corresponding to coordinates (λ, ϕ) should
    be identical to the position corresponding to (λ + 2*π,* ϕ). But in lat/lon space,
    these two coordinates are very far apart. Lat/lon space does not preserve periodicity:
    the way spherical coordinates wrap around the surface of the Earth.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，地球上与坐标（λ, ϕ）对应的位置应与坐标（λ + 2*π，ϕ）对应的位置相同。但在纬度/经度空间，这两个坐标之间相距甚远。纬度/经度空间并不能保持周期性：即球面坐标如何在地球表面上环绕。
- en: To learn anything meaningful directly from inputs in lat/long space, a neural
    network must learn how to encode these properties about the curvature of the Earth’s
    surface on its own — a challenging task. How can we instead design a position
    encoder that already encodes these inductive biases? Let’s explore some early
    approaches to this problem and how they have evolved over time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了直接从纬度/经度空间的输入中学习有意义的内容，神经网络必须学会如何自行编码关于地球表面曲率的这些属性——这是一个具有挑战性的任务。那么，我们该如何设计一个已经编码了这些归纳偏置的定位编码器呢？让我们探索一下早期的解决方案，以及它们是如何随着时间的推移演变的。
- en: Early Position Encoders
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早期的定位编码器
- en: Discretization-based (2015)
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于离散化的方法（2015年）
- en: The first paper to propose featurizing geographic coordinates for use as input
    to a convolutional neural network is called “Improving Image Classification with
    Location Context” [[3]](https://arxiv.org/pdf/1505.03873). Published in 2015,
    this work proposes and evaluates many different featurization approaches with
    the goal of training better classification models for geo-tagged images.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 第一篇提出将地理坐标特征化并作为卷积神经网络输入的论文名为《通过位置上下文改善图像分类》[[3]](https://arxiv.org/pdf/1505.03873)。该论文于
    2015 年发表，提出并评估了多种不同的特征化方法，旨在训练更好的地理标记图像分类模型。
- en: 'The idea behind each of their approaches is to directly encode a position on
    Earth into a set of numerical features that can be computed from auxiliary data
    sources. Some examples include:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 它们每种方法背后的理念是将地球上的位置直接编码为一组可以从辅助数据源计算得出的数值特征。一些例子包括：
- en: Dividing the U.S. into evenly spaced grids in lat/lon space and using a one-hot
    encoding to encode a given location into a vector based on which grid it falls
    into.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将美国划分为均匀间隔的网格，在纬度/经度空间中使用独热编码将给定位置编码为一个向量，依据其所在的网格来确定。
- en: Looking up the U.S ZIP code that corresponds to a given location, then retrieving
    demographic data about this ZIP code from ACS (American Community Survey) related
    to age, sex, race, living conditions, and more. This is made into a numerical
    vector using one-hot encodings.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找与给定位置对应的美国邮政编码，然后从美国社区调查（ACS）中检索关于该邮政编码的人口统计数据，涉及年龄、性别、种族、居住条件等。使用独热编码将这些数据转化为数值向量。
- en: For a chosen set of Instagram hashtags, counting how many hashtags are recorded
    at different distances from a given location and concatenating these counts into
    a vector.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一组选择的Instagram标签，统计不同距离给定位置的标签数量，并将这些计数值连接成一个向量。
- en: Retrieving color-coded maps from Google Maps for various features such as precipitation,
    land cover, congressional district, and concatenating the numerical color values
    from each into a vector.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Google Maps中检索颜色编码地图，用于表示降水、土地覆盖、国会选区等各种特征，并将每个特征的数值颜色值连接成一个向量。
- en: Note that these positional encodings are not continuous and do not preserve
    distances on the surface of the Earth. In the first example, two nearby locations
    that fall into different grids will be equally distant in feature space as two
    locations from opposite sides of the country. Moreover, these features mostly
    rely on the availability of auxiliary data sources and must be carefully hand-crafted,
    requiring a specific choice of hashtags, map features, survey data, etc. These
    approaches do not generalize well to arbitrary locations on Earth.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些位置编码不是连续的，并且不保留地球表面上的距离。在第一个例子中，两个邻近的地点如果落入不同的网格，它们在特征空间中的距离与两个位于国家两端的地点相等。此外，这些特征大多依赖于辅助数据源的可用性，必须精心设计，并需要特定的标签、地图特征、调查数据等选择。这些方法无法很好地推广到地球上任意位置。
- en: WRAP (2019)
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WRAP (2019)
- en: In 2019, a paper titled “Presence-Only Geographical Priors for Fine-Grained
    Image Classification” [[4]](https://arxiv.org/pdf/1906.05272) took an important
    step towards the geographic position encoders commonly used today. Similar to
    the work from the previous section, this paper studies how to use geographic coordinates
    for improving image classification models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在2019年，一篇名为“仅使用位置的地理先验进行细粒度图像分类”的论文[[4]](https://arxiv.org/pdf/1906.05272)迈出了通向今天广泛使用的地理位置编码器的重要一步。与上一节的工作类似，这篇论文研究了如何利用地理坐标来改进图像分类模型。
- en: 'The key idea behind their position encoder is to leverage the periodicity of
    sine and cosine functions to encode the way geographic coordinates wrap around
    the surface of the Earth. Given latitude and longitude (λ, ϕ), both normalized
    to the range [-1, 1], the WRAP position encoder is defined as:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的位置编码器背后的关键思想是利用正弦和余弦函数的周期性来编码地理坐标如何在地球表面上环绕。给定纬度和经度（λ，ϕ），都被归一化到[-1, 1]范围内，WRAP位置编码器定义如下：
- en: '![](../Images/920ea42f1458310b33c5bf742712d519.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/920ea42f1458310b33c5bf742712d519.png)'
- en: Unlike the approaches in the previous section, WRAP is continuous and easily
    computed for any position on Earth. The paper then shows empirically that training
    a fully-connected network on top of these features and combining them with latent
    image features can lead to improved performance on fine-grained image classification
    benchmarks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一节中的方法不同，WRAP是连续的，并且可以轻松计算地球上任何位置的值。然后，论文通过实验证明，在这些特征上训练一个全连接网络，并将它们与潜在图像特征结合，可以在细粒度图像分类基准测试中提高性能。
- en: The Double Fourier Sphere Method
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 双重傅里叶球面方法
- en: The WRAP encoder appears simple, but it successfully encodes a key inductive
    bias about geographic position while remaining expressive and flexible. In order
    to see why this choice of position encoder is so powerful, we need to understand
    the Double Fourier Sphere (DFS) method [[5]](https://en.wikipedia.org/wiki/Double_Fourier_sphere_method).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: WRAP编码器看起来简单，但它成功地编码了关于地理位置的一个关键归纳偏差，同时保持了表达性和灵活性。为了理解为什么这种位置编码器选择如此强大，我们需要理解双重傅里叶球面（DFS）方法[[5]](https://en.wikipedia.org/wiki/Double_Fourier_sphere_method)。
- en: 'DFS is a method of transforming any real-valued function *f* (*x*, *y*, *z*)
    defined on the surface of a unit sphere into a 2*π*-periodic function defined
    on a rectangle [-*π*, *π*] × [-*π*, *π*]. At a high level, DFS consists of two
    steps:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: DFS是一种方法，它将定义在单位球面上的任何实值函数*f*（*x*，*y*，*z*）转换为在矩形[-*π*，*π*] × [-*π*，*π*]上定义的2*π*周期函数。从高层次来看，DFS包括两个步骤：
- en: Re-parametrize the function *f* (*x*, *y*, *z*) using spherical coordinates,
    where (λ, ϕ) ∈ [-*π*, *π*] × [0*, π*]
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用球面坐标重新参数化函数*f*（*x*，*y*，*z*），其中（λ，ϕ）∈ [-*π*，*π*] × [0*，π*]
- en: '![](../Images/61081c492c27cdcfaa8390d55d660dfc.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61081c492c27cdcfaa8390d55d660dfc.png)'
- en: 2\. Define a new piece-wise function over the rectangle [-*π*, *π*] × [-*π*,
    *π*] based on the re-parametrized *f* (essentially “doubling it over”).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 基于重新参数化的* f*（本质上是“在其上翻倍”）在矩形[-*π*，*π*] × [-*π*，*π*]上定义一个新的分段函数。
- en: Notice that the DFS re-parametrization of the Earth’s surface (step 1.) preserves
    the properties we discussed earlier. For one, as ϕ tends to 0 or ± *π* (the Earth’s
    poles), the distance between two points (λ, ϕ) and (λ’, ϕ) after re-parametrization
    decreases. Moreover, the re-parametrization is periodic and smooth.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，地球表面的DFS重新参数化（步骤1）保持了我们之前讨论的性质。首先，当ϕ趋近于0或±*π*（地球的极点）时，经过重新参数化后，两点（λ，ϕ）和（λ'，ϕ）之间的距离会减小。此外，重新参数化是周期性的并且平滑的。
- en: Fourier Theorem
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 傅里叶定理
- en: 'It is a fact that any continuous, periodic, real-valued function can be represented
    as a weighted sum of sines and cosines. This is called the Fourier Theorem, and
    this weighted sum representation is called a Fourier series. It turns out that
    any DFS-transformed function can be represented with a finite set of sines and
    cosines. They are known as **DFS basis functions**, listed below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 任何连续的、周期性的实值函数都可以表示为正弦和余弦的加权和，这是一个事实。这个理论叫做傅里叶定理，这种加权和表示形式叫做傅里叶级数。事实证明，任何经过DFS变换的函数都可以用有限的正弦和余弦表示。它们被称为**DFS基函数**，如下所示：
- en: '![](../Images/17444feab234a748fcd0872fe182820b.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17444feab234a748fcd0872fe182820b.png)'
- en: Here, ∪ denotes union of sets, and *S* is a collection of scales (i.e. frequencies)
    for the sinusoids.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，∪表示集合的并集，*S*是正弦波的尺度（即频率）集合。
- en: DFS-Based Position Encoders
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于DFS的位置编码器
- en: Notice that the set of DFS basis functions includes the four terms in the WRAP
    position encoder. “Sphere2Vec” [[6]](https://arxiv.org/pdf/2201.10489) is the
    earliest publication to observe this, proposing a unified view of position encoders
    based on DFS. In fact, with this generalization in mind, we can construct a geographic
    position encoder by choosing any subset of the DFS basis functions — WRAP is just
    one such choice. Take a look at [[7]](https://arxiv.org/pdf/2310.06743v2) for
    a comprehensive overview of various DFS-based position encoders.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，DFS基函数集包含了WRAP位置编码器中的四项。“Sphere2Vec”[[6]](https://arxiv.org/pdf/2201.10489)是最早观察到这一点的论文，提出了基于DFS的统一位置编码器视角。实际上，考虑到这种泛化，我们可以通过选择DFS基函数的任何子集来构建一个地理位置编码器——WRAP仅仅是其中的一种选择。想了解更多，可以参考[[7]](https://arxiv.org/pdf/2310.06743v2)中对各种基于DFS的位置编码器的全面概述。
- en: Why are DFS-based encoders so powerful?
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么基于DFS的编码器如此强大？
- en: 'Consider what happens when a linear layer is trained on top of a DFS-based
    position encoder: each output element of the network is a weighted sum of the
    chosen DFS basis functions. Hence, the network can be interpreted as a **learned
    Fourier series**.Since virtually any function defined on the surface of a sphere
    can be transformed using the DFS method, it follows that a linear layer trained
    on top of DFS basis functions is powerful enough to encode arbitrary functions
    on the sphere! This is akin to the universal approximation theorem for multilayer
    perceptrons.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑在基于DFS的位置编码器上训练一个线性层时会发生什么：网络的每个输出元素都是所选DFS基函数的加权和。因此，网络可以被解释为**学习到的傅里叶级数**。由于几乎任何定义在球面上的函数都可以使用DFS方法进行变换，因此可以推断，在线性层上训练的DFS基函数足够强大，能够在球面上编码任意函数！这类似于多层感知器的通用逼近定理。
- en: 'In practice, only a small subset of the DFS basis functions is used for the
    position encoder and a fully-connected network is trained on top of these. The
    composition of a non-parametric position encoder with a neural network is commonly
    referred to as a **location encoder**:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，仅使用DFS基函数的一个小子集用于位置编码器，并在其上训练一个全连接网络。非参数化位置编码器与神经网络的组合通常被称为**位置编码器**：
- en: '![](../Images/315f844ae0997de2f4526c4cbc711b3d.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/315f844ae0997de2f4526c4cbc711b3d.png)'
- en: A depiction of a geographic location encoder. Image by author.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 地理位置编码器的示意图。图片来自作者。
- en: Geographic Location Encoders Today
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前的地理位置编码器
- en: As we have seen, a DFS-based position encoder can effectively encode inductive
    biases we have about the curvature of the Earth’s surface. One limitation of DFS-based
    encoders is that they assume a rectangular domain [-*π*, *π*] × [-*π*, *π*]. While
    this is mostly fine since the DFS re-parametrization already accounts for how
    distances get warped closer to the poles, this assumption breaks down at the poles
    themselves (ϕ = 0, ± *π*), which are lines in the rectangular domain that collapse
    to singular points on the Earth’s surface.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，基于DFS的位置编码器可以有效地编码我们对于地球表面曲率的归纳偏见。基于DFS的编码器的一个局限性是它们假设矩形域[-*π*，*π*] ×
    [-*π*，*π*]。虽然这个假设通常是可以接受的，因为DFS重新参数化已经考虑到距离在接近极地时如何发生扭曲，但这个假设在极地本身（ϕ = 0，± *π*）的地方会失效，因为这些点在矩形域中是线段，而在地球表面则会塌缩成单一的点。
- en: A different set of basis functions called spherical harmonics have recently
    emerged as an alternative. Spherical harmonics are basis functions that are natively
    defined on the surface of the sphere as opposed to a rectangle. They have been
    shown to exhibit fewer artifacts around the Earth’s poles compared to DFS-based
    encoders [[7]](https://arxiv.org/pdf/2310.06743v2). Notably, spherical harmonics
    are the basis functions used in the SatCLIP location encoder [[8]](https://arxiv.org/pdf/2311.17179),
    a recent foundation model for geographic coordinates trained in the style of CLIP.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一种名为球面调和函数的不同基函数最近成为了一种替代方案。球面调和函数是本地定义在球面上的基函数，而非矩形区域。与基于DFS的编码器相比，它们已被证明在地球极地区域展现出较少的伪影[[7]](https://arxiv.org/pdf/2310.06743v2)。值得注意的是，球面调和函数是SatCLIP位置编码器[[8]](https://arxiv.org/pdf/2311.17179)中使用的基函数，SatCLIP是一个近期的地理坐标基础模型，以CLIP的风格进行训练。
- en: Though geographic position encoders began with discrete, hand-crafted features
    in the 2010s, these do not easily generalize to arbitrary locations and require
    domain-specific metadata such as land cover and demographic data. Today, geographic
    coordinates are much more commonly used as neural network inputs because simple
    yet meaningful and expressive ways of encoding them have emerged. With the rise
    of web-scale datasets which are often geo-tagged, the potential for using geographic
    coordinates as inputs for prediction tasks is now immense.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管地理位置编码器在2010年代初期始于离散的、手工设计的特征，但这些特征并不容易推广到任意位置，并且需要特定领域的元数据，如土地覆盖和人口统计数据。今天，地理坐标作为神经网络输入变得更为普遍，因为已有简单但有意义且富有表现力的编码方式出现。随着网络规模数据集的崛起，这些数据集通常带有地理标签，使用地理坐标作为预测任务的输入的潜力如今巨大。
- en: References
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser & I. Polosukhin, [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
    (2017), 31st Conference on Neural Information Processing Systems'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser & I. Polosukhin, [Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
    (2017), 第31届神经信息处理系统大会'
- en: '[2] A Kazemnejad, [Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
    (2019), Amirhossein Kazemnejad’s Blog'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] A Kazemnejad, [Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
    (2019), Amirhossein Kazemnejad’s Blog'
- en: '[3] K. Tang, M. Paluri, L. Fei-Fei, R. Fergus, L. Bourdev, [Improving Image
    Classification with Location Context](https://arxiv.org/pdf/1505.03873) (2015)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] K. Tang, M. Paluri, L. Fei-Fei, R. Fergus, L. Bourdev, [Improving Image
    Classification with Location Context](https://arxiv.org/pdf/1505.03873) (2015)'
- en: '[4] O. Mac Aodha, E. Cole, P. Perona, [Presence-Only Geographical Priors for
    Fine-Grained Image Classification](https://arxiv.org/pdf/1906.05272) (2019)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] O. Mac Aodha, E. Cole, P. Perona, [Presence-Only Geographical Priors for
    Fine-Grained Image Classification](https://arxiv.org/pdf/1906.05272) (2019)'
- en: '[5] [Double Fourier Sphere Method](https://en.wikipedia.org/wiki/Double_Fourier_sphere_method),
    Wikipedia'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [双重傅里叶球面方法](https://en.wikipedia.org/wiki/Double_Fourier_sphere_method)，维基百科'
- en: '[6] G. Mai, Y. Xuan, W. Zuo, K. Janowicz, N. Lao [Sphere2Vec: Multi-Scale Representation
    Learning over a Spherical Surface for Geospatial Predictions](https://arxiv.org/pdf/2201.10489)
    (2022)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] G. Mai, Y. Xuan, W. Zuo, K. Janowicz, N. Lao [Sphere2Vec: Multi-Scale Representation
    Learning over a Spherical Surface for Geospatial Predictions](https://arxiv.org/pdf/2201.10489)
    (2022)'
- en: '[7] M. Rußwurm, K. Klemmer, E. Rolf, R. Zbinden, D. Tuia, [Geographic Location
    Encoding with Spherical Harmonics and Sinusoidal Representation Network](https://arxiv.org/pdf/2310.06743v2)
    (2024), ICLR 2024'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] M. Rußwurm, K. Klemmer, E. Rolf, R. Zbinden, D. Tuia, [Geographic Location
    Encoding with Spherical Harmonics and Sinusoidal Representation Network](https://arxiv.org/pdf/2310.06743v2)
    (2024), ICLR 2024'
- en: '[8] K. Klemmer, E. Rolf, C. Robinson, L. Mackey, M. Rußwurm, [SatCLIP: Global,
    General-Purpose Location Embeddings with Satellite Imagery](https://arxiv.org/pdf/2311.17179)
    (2024)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[SatCLIP: 全球通用的卫星图像位置嵌入](https://arxiv.org/pdf/2311.17179)（2024）由K. Klemmer,
    E. Rolf, C. Robinson, L. Mackey, M. Rußwurm编写。'
