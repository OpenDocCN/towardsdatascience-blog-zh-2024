- en: 'Real-Time Hand Tracking and Gesture Recognition with MediaPipe: Rerun Showcase'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MediaPipe 进行实时手部追踪和手势识别：Rerun 展示
- en: 原文：[https://towardsdatascience.com/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=collection_archive---------4-----------------------#2024-03-05](https://towardsdatascience.com/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=collection_archive---------4-----------------------#2024-03-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=collection_archive---------4-----------------------#2024-03-05](https://towardsdatascience.com/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=collection_archive---------4-----------------------#2024-03-05)
- en: How to visualise MediaPipe’s Hand Tracking and Gesture Recognition with Rerun
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 Rerun 可视化 MediaPipe 的手部追踪与手势识别
- en: '[](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[![Andreas
    Naoum](../Images/e14d545f270170877e0af31572275e17.png)](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)
    [Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[![Andreas
    Naoum](../Images/e14d545f270170877e0af31572275e17.png)](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)
    [Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page---byline--9ec57cb0c831--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)
    ·8 min read·Mar 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ec57cb0c831--------------------------------)
    ·8 分钟阅读·2024年3月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8ec748453f3b800b051414e9d6c7ca7b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ec748453f3b800b051414e9d6c7ca7b.png)'
- en: Hand Tracking and Gesture Recognition | Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 手部追踪与手势识别 | 作者提供的图片
- en: In this post, I’m presenting an example of **Hand Tracking and Gesture Recognition
    using** [**MediaPipe**](https://mediapipe-studio.webapps.google.com/home) **Python**
    **and** [**Rerun SDK**](https://www.rerun.io).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示一个使用 [**MediaPipe**](https://mediapipe-studio.webapps.google.com/home)
    **Python** **和** [**Rerun SDK**](https://www.rerun.io) 进行的**手部追踪和手势识别**示例。
- en: If you’re interested in delving deeper and expanding your understanding, I will
    guide you on **how to install** [**MediaPipe**](https://mediapipe-studio.webapps.google.com/home)
    **Python** **and** [**Rerun SDK**](https://www.rerun.io)to track a hand, recognise
    different gestures and visualise the data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣深入了解并扩展你的理解，我将指导你**如何安装** [**MediaPipe**](https://mediapipe-studio.webapps.google.com/home)
    **Python** **和** [**Rerun SDK**](https://www.rerun.io)，以便进行手部追踪、识别不同手势并可视化数据。
- en: 'Therefore, you’ll learn:'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因此，你将学习：
- en: How to install MediaPipe Python and Rerun
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何安装 MediaPipe Python 和 Rerun
- en: How to use [MediaPipe Gesture Recognition](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer#models)
    for Hand Tracking and Gesture Recognition
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 [MediaPipe 手势识别](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer#models)
    进行手部追踪与手势识别
- en: How to visualise the results of the hand-tracking and gesture recognition in
    the [Rerun Viewer](https://www.rerun.io/docs/getting-started/viewer-walkthrough)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 [Rerun Viewer](https://www.rerun.io/docs/getting-started/viewer-walkthrough)
    中可视化手部追踪和手势识别的结果
- en: 'If you’re just eager to give the example a try, simply use the provided code:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你迫不及待想尝试这个示例，可以直接使用提供的代码：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Hand Tracking and Gesture Recognition Technology
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手部追踪和手势识别技术
- en: Before we proceed, let’s give credit to the technology that makes this possible.
    The hand tracking and gesture recognition technology aims to give the ability
    of the devices to interpret hand movements and gestures as commands or inputs.
    At the core of this technology, a pre-trained machine-learning model analyses
    the visual input and identifies hand landmarks and hand gestures. The real applications
    of such technology vary, as hand movements and gestures can be used to control
    smart devices. Human-Computer Interaction, Robotics, Gaming, and Augmented Reality
    are a few of the fields where the potential applications of this technology appear
    most promising.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，先对使这一切成为可能的技术给予应有的认可。手部追踪和手势识别技术旨在赋予设备解读手部动作和手势作为指令或输入的能力。在这项技术的核心，一种预训练的机器学习模型分析视觉输入并识别手部地标和手势。这项技术的实际应用范围广泛，手部动作和手势可用于控制智能设备。人机交互、机器人学、游戏和增强现实是这项技术潜在应用最有前景的一些领域。
- en: However, we should always be conscious of how we use such a technology. It’s
    really challenging to use it in sensitive and critical systems because the model
    can misinterpret gestures and the potential for false positives or negatives is
    not minimal. Ethical and legal challenges arise from utilising this, as users
    may not want their gestures to be recorded especially in public spaces. If you
    intend to implement this technology in real-world scenarios, it’s important to
    take into account any ethical and legal considerations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在使用此类技术时应时刻保持警觉。因为模型可能会误解手势，且假阳性或假阴性的可能性不容忽视，所以在敏感和关键系统中使用它是非常具有挑战性的。利用这项技术还可能带来伦理和法律方面的问题，因为用户可能不希望在公共场所被记录他们的手势。如果你打算在现实世界的场景中实施这项技术，考虑任何伦理和法律问题是非常重要的。
- en: Prerequisites & Setup
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前提条件与设置
- en: First, you need to install the necessary libraries, including OpenCV, MediaPipe
    and Rerun. [**MediaPipe Python**](https://mediapipe-studio.webapps.google.com/home)
    is a handy tool for developers looking to integrate on-device ML solutions for
    computer vision and machine learning, and [**Rerun**](https://www.rerun.io) is
    an SDK for visualizing multimodal data that changes over time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要安装必要的库，包括 OpenCV、MediaPipe 和 Rerun。[**MediaPipe Python**](https://mediapipe-studio.webapps.google.com/home)
    是一个方便的工具，供开发者在计算机视觉和机器学习领域集成设备端 ML 解决方案，[**Rerun**](https://www.rerun.io) 是一个用于可视化随时间变化的多模态数据的
    SDK。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, you have to download the predefined model from here: [HandGestureClassifier](https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/latest/gesture_recognizer.task)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要从此处下载预定义模型：[HandGestureClassifier](https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/latest/gesture_recognizer.task)
- en: Hand Tracking and Gesture Recognition using MediaPipe
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MediaPipe 进行手部追踪和手势识别
- en: '![](../Images/47ff9b3771ef5e9e98811c796da311bf.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47ff9b3771ef5e9e98811c796da311bf.png)'
- en: Image via [Gesture Recognition Task Guide](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
    by [Google](https://about.google/brand-resource-center/)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [手势识别任务指南](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
    由 [Google](https://about.google/brand-resource-center/) 提供
- en: “The MediaPipe Gesture Recognizer task lets you recognize hand gestures in real
    time, and provides the recognized hand gesture results along with the landmarks
    of the detected hands. You can use this task to recognize specific hand gestures
    from a user, and invoke application features that correspond to those gestures.”
    from [Gesture Recognition Task Guide](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “MediaPipe 手势识别任务允许你实时识别手势，并提供识别到的手势结果以及检测到的手的地标。你可以使用此任务识别用户的特定手势，并调用与这些手势对应的应用功能。”
    引自 [手势识别任务指南](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
- en: Now, let’s try to use the MediaPipe pre-trained model for gesture recognition
    for a sample image. Overall, the below code sets the foundation for initialising
    and configuring a MediaPipe Gesture Recognition solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用 MediaPipe 预训练模型进行手势识别，处理一张示例图像。总体而言，以下代码为初始化和配置 MediaPipe 手势识别解决方案奠定了基础。
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `detect` function within the `GestureDetectorLogger` class accepts an image
    as its argument and prints the model results, highlighting the top recognized
    gesture and the detected hand landmarks. For additional details regarding the
    model, refer to its [model card](https://storage.googleapis.com/mediapipe-assets/gesture_recognizer/model_card_hand_gesture_classification_with_faireness_2022.pdf).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`GestureDetectorLogger`类中的`detect`函数接受一张图片作为参数，并打印模型结果，突出显示识别出的手势及检测到的手部地标。有关模型的更多细节，请参考其[模型卡片](https://storage.googleapis.com/mediapipe-assets/gesture_recognizer/model_card_hand_gesture_classification_with_faireness_2022.pdf)。'
- en: '![](../Images/af87cc0b5c9dacee7900b4dab9433aee.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af87cc0b5c9dacee7900b4dab9433aee.png)'
- en: Image via [Gesture Recognition Task Guide](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
    by [Google](https://about.google/brand-resource-center/)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[手势识别任务指南](https://developers.google.com/mediapipe/solutions/vision/gesture_recognizer)
    由[Google](https://about.google/brand-resource-center/)提供
- en: 'You can try it by yourself using the code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码亲自尝试：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Verify, Debug and Demo using Rerun
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Rerun进行验证、调试和演示
- en: This step allows you to ensure the reliability and effectiveness of your solution.
    With the model now prepared, visualise the results to verify the accuracy, debug
    any potential issues, and demonstrate its capabilities. Visualising the results
    could be simple and fast using Rerun SDK.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤帮助你确保解决方案的可靠性和有效性。现在模型已经准备好，接下来可视化结果以验证准确性，调试潜在问题，并展示其功能。使用Rerun SDK，可以简单快速地实现结果的可视化。
- en: How do we use Rerun?
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何使用Rerun？
- en: '![](../Images/dd9474d4f31555cc7fc2c9f655597e18.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd9474d4f31555cc7fc2c9f655597e18.png)'
- en: Image via [Rerun Docs](https://www.rerun.io/docs) by [Rerun](https://www.rerun.io)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Rerun文档](https://www.rerun.io/docs) 由[Rerun](https://www.rerun.io)提供
- en: Stream multimodal data from your code by logging it with the Rerun SDK
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用Rerun SDK记录数据，将多模态数据从代码流式传输
- en: Visualise and interact with **live or recorded streams**, whether local or remote
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化并与**实时或录制的流**进行交互，无论是本地的还是远程的
- en: Interactively build layouts and customize visualisations
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 互动式构建布局并自定义可视化
- en: Extend Rerun when you need to
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在需要时扩展Rerun
- en: Before getting into the code, you should visit the page [installing the Rerun
    Viewer](https://www.rerun.io/docs/getting-started/installing-viewer) to install
    the Viewer. Then, I highly suggested getting familiar with Rerun SDK by reading
    these guides [Python Quick Start](https://www.rerun.io/docs/getting-started/python)
    and [Logging Data in Python](https://www.rerun.io/docs/getting-started/logging-python).
    These initial steps will ensure a smooth setup and help you get started with the
    upcoming code implementation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入代码之前，你应该访问页面[安装Rerun查看器](https://www.rerun.io/docs/getting-started/installing-viewer)来安装查看器。然后，我强烈建议通过阅读以下指南来熟悉Rerun
    SDK：[Python快速入门](https://www.rerun.io/docs/getting-started/python)和[在Python中记录数据](https://www.rerun.io/docs/getting-started/logging-python)。这些初始步骤将确保顺利设置，并帮助你开始接下来的代码实现。
- en: Run from Video or Real-Time
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从视频或实时运行
- en: For video streaming, OpenCV is employed. You can select either a file path for
    a specific video or access your own camera by providing an argument of 0 or 1
    (use 0 for the default camera; on Mac, you may use 1).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于视频流，使用了OpenCV。你可以选择特定视频的文件路径，或者通过提供参数0或1来访问你自己的摄像头（使用0为默认摄像头；在Mac上，你可以使用1）。
- en: It’s noteworthy to emphasise the introduction of [timelines](https://www.rerun.io/docs/concepts/timelines).
    Rerun timelines’ functions enable the association of data with one or more timelines.
    Consequently, each frame of the video is associated with its corresponding timestamp.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，要强调[时间轴](https://www.rerun.io/docs/concepts/timelines)的介绍。Rerun时间轴的功能使得可以将数据与一个或多个时间轴关联。因此，视频的每一帧都与其对应的时间戳相关联。
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Logging Data for Visualisation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为可视化记录数据
- en: '![](../Images/669757c874516e02624cf43b52a69a60.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/669757c874516e02624cf43b52a69a60.png)'
- en: Logging 2D data using Rerun SDK | Image by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Rerun SDK记录2D数据 | 图片来源：作者
- en: To visualise the data in the Rerun Viewer, it’s essential to log the data using
    the Rerun SDK. The guides mentioned earlier provide insights into this process.
    In this context, we extract hand landmark points as normalized values, and then
    utilise the image’s width and height for conversion into image coordinates. These
    coordinates are then logged as [2D points](https://www.rerun.io/docs/reference/types/archetypes/points2d)
    to the Rerun SDK. Additionally, we identify connections between the landmarks
    and log them as [2D linestrips](https://www.rerun.io/docs/reference/types/archetypes/line_strips2d).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Rerun 查看器中可视化数据，必须使用 Rerun SDK 记录数据。前面提到的指南提供了关于这一过程的深入见解。在这个上下文中，我们提取手部地标点作为归一化值，然后利用图像的宽度和高度将其转换为图像坐标。这些坐标随后作为[2D
    点](https://www.rerun.io/docs/reference/types/archetypes/points2d)记录到 Rerun SDK
    中。此外，我们识别地标之间的连接，并将其作为[2D 线段](https://www.rerun.io/docs/reference/types/archetypes/line_strips2d)记录。
- en: For gesture recognition, the results are printed to the console. However, within
    the source code, you can explore a method to present these results to the viewer
    using [TextDocument](https://www.rerun.io/docs/reference/types/archetypes/text_document)
    and emojis.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于手势识别，结果会打印到控制台。然而，在源代码中，你可以探索一种方法，通过[TextDocument](https://www.rerun.io/docs/reference/types/archetypes/text_document)和表情符号将这些结果呈现给查看器。
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 3D Points
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D 点
- en: Finally, we examine how we can present the hand landmarks as 3D points. We first
    define the connections between the points using keypoints from [Annotation Context](https://www.rerun.io/docs/concepts/annotation-context)
    in the init function, and then we log them as [3D points](https://www.rerun.io/docs/reference/types/archetypes/points3d).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们研究如何将手部地标呈现为 3D 点。我们首先在初始化函数中使用来自[注释上下文](https://www.rerun.io/docs/concepts/annotation-context)的关键点定义点之间的连接，然后将它们作为[3D
    点](https://www.rerun.io/docs/reference/types/archetypes/points3d)进行记录。
- en: '![](../Images/140447578f2915dba04718f2d11f1588.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/140447578f2915dba04718f2d11f1588.png)'
- en: Logging 3D data using Rerun SDK | Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Rerun SDK 记录 3D 数据 | 图片来自作者
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You’re ready! Let the magic begin:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你准备好了！让魔法开始吧：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The full source code for this example is available on [GitHub](https://github.com/rerun-io/rerun/tree/main/examples/python/gesture_detection).
    Feel free to explore, modify, and understand the inner workings of the implementation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的完整源代码可以在[GitHub](https://github.com/rerun-io/rerun/tree/main/examples/python/gesture_detection)上找到。欢迎随意探索、修改并理解实现的内部工作原理。
- en: Beyond Hand-Tracking and Gesture Recognition
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越手部跟踪与手势识别
- en: '![](../Images/e3e98cf7eca2c494781c91cf7e150a09.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3e98cf7eca2c494781c91cf7e150a09.png)'
- en: Rerun Examples | Image by [Rerun](https://www.rerun.io)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Rerun 示例 | 图片来自 [Rerun](https://www.rerun.io)
- en: Finally, if you have a keen interest in visualising streams of multimodal data
    across a diverse range of applications, I encourage you to explore the [Rerun
    Examples](https://www.rerun.io/examples/real-data). These examples highlight potential
    real-world cases and provide valuable insights into the practical applications
    of such visualisation techniques.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你对可视化跨多种应用场景的多模态数据流有浓厚兴趣，我鼓励你探索[Rerun 示例](https://www.rerun.io/examples/real-data)。这些示例展示了潜在的现实世界案例，并提供了有关这些可视化技术实际应用的宝贵见解。
- en: '*If you found this article useful and insightful, there’s more coming! I regularly
    share in-depth content on robotics and computer vision visualisation posts that
    you won’t want to miss. For future updates and exciting projects, follow me!*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得这篇文章有用且富有启发性，更多内容即将发布！我定期分享关于机器人技术和计算机视觉可视化的深度内容，绝对不容错过。为了获取未来的更新和令人兴奋的项目，记得关注我！*'
- en: '*Also, you can find me on* [***LinkedIn***](http://www.linkedin.com/in/andreas-naoum)***.***'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*此外，你还可以在* [***LinkedIn***](http://www.linkedin.com/in/andreas-naoum)***上找到我。***'
- en: '*Similar articles:*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*类似文章：*'
- en: '[](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----9ec57cb0c831--------------------------------)
    [## Real-Time Face and Face Landmark Detection with MediaPipe: Rerun Showcase'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----9ec57cb0c831--------------------------------)
    [## 使用 MediaPipe 进行实时人脸和人脸地标检测：Rerun 展示'
- en: How to easily visualise MediaPipe’s face and face landmark detection in 2D and
    3D with Rerun
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何轻松地在 2D 和 3D 中可视化 MediaPipe 的人脸和人脸地标检测，使用 Rerun
- en: 'ai.gopubby.com](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----9ec57cb0c831--------------------------------)
    [](/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=post_page-----9ec57cb0c831--------------------------------)
    [## Human Pose Tracking with MediaPipe in 2D and 3D: Rerun Showcase'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ai.gopubby.com](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----9ec57cb0c831--------------------------------)
    [](/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=post_page-----9ec57cb0c831--------------------------------)
    [## 使用MediaPipe进行2D和3D人体姿态跟踪：Rerun展示
- en: How to easily visualise MediaPipe’s human pose tracking with Rerun
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何轻松地通过Rerun可视化MediaPipe的人体姿态跟踪
- en: towardsdatascience.com](/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=post_page-----9ec57cb0c831--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=post_page-----9ec57cb0c831--------------------------------)
- en: Portions of this page are reproduced from work created and [shared by Google](https://developers.google.com/readme/policies)
    and used according to terms described in the [Creative Commons 4.0 Attribution
    License](https://creativecommons.org/licenses/by/4.0/).
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本页面的部分内容转载自[Google](https://developers.google.com/readme/policies)创建并分享的作品，并根据[创意共享4.0署名许可协议](https://creativecommons.org/licenses/by/4.0/)中的条款使用。
