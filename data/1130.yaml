- en: 'Prompt Like a Data Scientist: Auto Prompt Optimization and Testing with DSPy'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 像数据科学家一样构建提示：使用DSPy进行自动提示优化和测试
- en: 原文：[https://towardsdatascience.com/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=collection_archive---------0-----------------------#2024-05-05](https://towardsdatascience.com/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=collection_archive---------0-----------------------#2024-05-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=collection_archive---------0-----------------------#2024-05-05](https://towardsdatascience.com/prompt-like-a-data-scientist-auto-prompt-optimization-and-testing-with-dspy-ff699f030cb7?source=collection_archive---------0-----------------------#2024-05-05)
- en: Applying machine learning methodology to prompt building
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用机器学习方法构建提示
- en: '[](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)[![Julian
    Yip](../Images/2afc0ac6c4dcccaa57ffe70b2f5a14d0.png)](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)
    [Julian Yip](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)[![Julian
    Yip](../Images/2afc0ac6c4dcccaa57ffe70b2f5a14d0.png)](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)
    [Julian Yip](https://medium.com/@jyipkl?source=post_page---byline--ff699f030cb7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)
    ·40 min read·May 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff699f030cb7--------------------------------)
    ·40分钟阅读·2024年5月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/266f734fa2fbe701359eb41fa9d06e9d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/266f734fa2fbe701359eb41fa9d06e9d.png)'
- en: Drawn by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘制
- en: 'LLMs are grounded in data science, but our approach to prompt engineering might
    strike us as unscientific:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的基础是数据科学，但我们对提示工程的处理方式可能显得不够科学：
- en: '**Manual prompt engineering which does not generalize well**: LLMs are highly
    sensitive to how they are prompted for each task, so we need to handcraft long
    strings of instructions and demonstrations. This requires not only time-consuming
    prompt writing process, but the given string prompt might not generalize to different
    pipelines or across different LMs, data domains, or even inputs. To deal with
    a new problem we often need to handcraft a new prompt.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不易泛化的手动提示工程**：大型语言模型（LLMs）对每个任务的提示非常敏感，因此我们需要手工编写长字符串的指令和示范。这不仅需要耗时的提示写作过程，而且给定的字符串提示可能无法在不同的管道、不同的语言模型（LMs）、数据领域甚至输入之间泛化。为了应对新问题，我们通常需要手工编写新的提示。'
- en: '**Lack framework to conduct testing**: Instead of the usual train-test regime
    in typical data science applications to pick the model which maximizes a certain
    metric like AUC, with LLMs we arrive at the best prompt via trial and error, often
    without an objective metric to say how well our model is performing. Thus no matter
    how we try to improve the prompt, we can’t confidently say how reliable our application
    is.'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缺乏进行测试的框架**：与典型数据科学应用中的常规训练-测试模式不同，通常是通过选择最大化某个指标（如AUC）的模型，而在LLMs中，我们是通过反复试验找到最佳提示，通常没有客观指标来评估我们的模型表现如何。因此，无论我们如何尝试改进提示，都无法自信地说我们的应用有多可靠。'
- en: 'To address these issues, Stanford NLP has published a [paper](https://arxiv.org/abs/2310.03714)
    introducing a new approach with prompt writing: instead of manipulating free-form
    strings, we generate prompts via modularized programming. The associated library,
    called DSPy, can be found [here](https://github.com/stanfordnlp/dspy).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，斯坦福NLP发布了一篇[论文](https://arxiv.org/abs/2310.03714)，介绍了一种新的提示编写方法：我们不再操作自由格式的字符串，而是通过模块化编程生成提示。相关库DSPy可以在[这里](https://github.com/stanfordnlp/dspy)找到。
- en: This article aims to show how this “prompt programming” is done, to go deeper
    in explaining what’s happening behind the optimization process. The code can also
    be found [here](https://github.com/yip-kl/llm_dspy_tutorial).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在展示如何进行这种“提示编程”，并深入解释优化过程背后发生的事情。代码也可以在[这里](https://github.com/yip-kl/llm_dspy_tutorial)找到。
- en: '*(Speaking of which, you might also find coaxing LLMs to output properly formatted
    JSON very unscientific too, I have also written an article about how to address
    this with Function Calling. Check it out !)*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*(说到这，你可能会发现让LLM输出格式正确的JSON也非常不科学，我也写了一篇关于如何通过函数调用解决这个问题的文章。快去看看吧！)*'
- en: '[](/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=post_page-----ff699f030cb7--------------------------------)
    [## Build Autonomous AI Agents with Function Calling'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=post_page-----ff699f030cb7--------------------------------)
    [## 使用函数调用构建自主AI代理'
- en: Transform your chatbot into an agent that can interact with external APIs
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将你的聊天机器人转变为一个能够与外部API交互的代理
- en: towardsdatascience.com](/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=post_page-----ff699f030cb7--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/build-autonomous-ai-agents-with-function-calling-0bb483753975?source=post_page-----ff699f030cb7--------------------------------)
- en: 'We will spend some time to go over the environment preparation. Afterwards,
    this article is divided into 3 sections:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将花些时间来讲解环境准备。之后，本文分为三个部分：
- en: '***Basic concept of DSPy: Signature and Module***'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***DSPy的基本概念：签名和模块***'
- en: Basic building blocks in DSPy for describing your task, and the prompt technique
    used
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于描述任务的DSPy基本构建模块，以及使用的提示技术
- en: '***Optimizer: Train our prompt as with machine learning***'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***优化器：像机器学习一样训练我们的提示***'
- en: How DSPy optimizes your prompt with bootstrapping
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DSPy如何通过自举优化你的提示
- en: '***Full fledged example: Prompt comparison with LLM***'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***完整示例：与LLM的提示比较***'
- en: Applying the rigour of traditional machine learning for prompt testing and selection
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将传统机器学习的严谨性应用于提示测试和选择
- en: We are now ready to start!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好开始了！
- en: Preparation
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Head over to [Github](https://github.com/yip-kl/llm_dspy_tutorial) to clone
    my code. The contents in my article can be found in the `dspy_tutorial` Notebook.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往[Github](https://github.com/yip-kl/llm_dspy_tutorial)克隆我的代码。我的文章中的内容可以在`dspy_tutorial`
    Notebook中找到。
- en: Please also create and activate a virtual environment, then `pip install -r
    requirements.txt` to install the required packages. If you are on Windows, please
    also install Windows C++ build tools which are required for the `phoneix` library
    with which we will observe how DSPy works
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请同时创建并激活一个虚拟环境，然后运行`pip install -r requirements.txt`来安装所需的包。如果你在Windows系统上，还请安装Windows
    C++构建工具，这对于我们将要使用的`phoneix`库是必需的，它能帮助我们观察DSPy的工作方式。
- en: My code uses OpenRouter, which allow us to access OpenAI API in blocked regions.
    Please set up your `OPENROUTER_API_KEY` as environment variable, and execute the
    code under the “Preparation” block. Alternatively, you can use `dspy.OpenAI` class
    directly and define Open AI API key if it works for you
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我的代码使用了OpenRouter，这使我们能够在封锁地区访问OpenAI API。请将你的`OPENROUTER_API_KEY`设置为环境变量，并在“准备”块下执行代码。或者，你也可以直接使用`dspy.OpenAI`类并定义OpenAI
    API密钥，如果它适合你。
- en: 'Basic concept of DSPy: Signature and Module'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DSPy的基本概念：签名和模块
- en: They are the building blocks of prompt programming in DSPy. Let’s dive in to
    see what they are about!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它们是DSPy提示编程的构建块。让我们深入了解它们的内容吧！
- en: '**Signatures: Specification of input/output**'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**签名：输入/输出的规范**'
- en: A signature is the most fundamental building block in DSPy’s prompt programming,
    which is a declarative specification of input/output behavior of a DSPy module.
    Signatures allow you to tell the LM **what** it needs to do, rather than specify
    how we should ask the LM to do it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 签名是DSPy提示编程中最基本的构建模块，它是对DSPy模块输入/输出行为的声明性规范。签名允许你告诉语言模型**需要**做什么，而不是指定如何请求语言模型去做。
- en: 'Say we want to obtain the sentiment of a sentence, traditionally we might write
    such prompt:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要获取一句话的情感，传统上我们可能会写出这样的提示：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: But in DSPy, we can achieve the same by defining a `signature` as below. At
    its most basic form, a signature is as simple as a single string separating the
    inputs and output with a `->`
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在DSPy中，我们可以通过如下定义一个`签名`来实现相同的效果。最基本的形式，签名只是一个简单的字符串，用`->`分隔输入和输出。
- en: '*Note: Code in this section contains those referred from DSPy’s documentation
    of* [*Signatures*](https://dspy-docs.vercel.app/docs/building-blocks/signatures)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：本节代码包含了来自DSPy文档中* [*签名*](https://dspy-docs.vercel.app/docs/building-blocks/signatures)
    的相关内容。'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The prediction is not a good one, but for instructional purpose let’s inspect
    what was the issued prompt.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果不好，但为了教学目的，让我们检查一下所发出的提示是什么。
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can see the above prompt is assembled from the `sentence -> sentiment` signature.
    But how did DSPy came up with the `Given the fields…` in the prompt?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，上面的提示是从`sentence -> sentiment`签名拼接而来的。但DSPy是如何得出提示中的`Given the fields…`部分的呢？
- en: Inspecting the `dspy.Predict()` class, we see when we pass to it our signature,
    the signature will be parsed as the `signature` attribute of the class, and subsequently
    assembled as a prompt. The `instructions` is a default one hardcoded in the DSPy
    library.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`dspy.Predict()`类时，我们看到当我们将签名传递给它时，签名会被解析为该类的`signature`属性，随后被组装成提示。`instructions`是DSPy库中硬编码的默认值。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: What if we want to provide a more detailed description of our objective to the
    LLM, beyond the basic `sentence -> sentiment` signature? To do so we need to provide
    a more verbose signature in form of **Class-based DSPy Signatures**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要向LLM提供更详细的目标描述，而不仅仅是基本的`sentence -> sentiment`签名，怎么办？为此，我们需要提供更详细的签名，形式为**基于类的DSPy签名**。
- en: Notice we provide no explicit instruction as to how the LLM should obtain the
    sentiment. We are just describing the task at hand, and also the expected output.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们没有明确指示LLM应如何获取情感。我们只是描述了当前的任务，以及预期的输出。
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It is now outputting a much better prediction! Again we see the descriptions
    we made when defining the class-based DSPy signatures are assembled into a prompt.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 它现在输出了一个更好的预测！我们再次看到，在定义基于类的DSPy签名时，我们所做的描述被组装成了提示。
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This might do for simple tasks, but advanced applications might require sophisticated
    prompting techniques like Chain of Thought or ReAct. In DSPy these are implemented
    as **Modules**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于简单任务可能足够了，但高级应用可能需要复杂的提示技巧，如Chain of Thought或ReAct。在DSPy中，这些都作为**模块**实现。
- en: '**Modules: Abstracting prompting techniques**'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**模块：抽象提示技巧**'
- en: We may be used to apply “prompting techniques” by hardcoding phrases like `let’s
    think step by step` in our prompt . In DSPy these prompting techniques are abstracted
    as **Modules**. Let’s see below for an example of applying our class-based signature
    to the `dspy.ChainOfThought` module
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能已经习惯通过硬编码诸如`let’s think step by step`这样的短语来应用“提示技巧”在我们的提示中。在DSPy中，这些提示技巧被抽象为**模块**。下面我们来看一个将基于类的签名应用于`dspy.ChainOfThought`模块的示例。
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Notice how the “Reasoning: Let’s think step by step…” phrase is added to our
    prompt, and the quality of our prediction is even better now.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，“推理：让我们逐步思考...”这一短语是如何添加到我们的提示中的，现在我们的预测质量更高了。
- en: According to DSPy’s [documentation](https://dspy-docs.vercel.app/docs/building-blocks/modules),
    as of time of writing DSPy provides the following prompting techniques in form
    of Modules. Notice the `dspy.Predict` we used in the initial example is also a
    Module, representing no prompting technique!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 根据DSPy的[文档](https://dspy-docs.vercel.app/docs/building-blocks/modules)，截至本文写作时，DSPy提供了以下形式为模块的提示技巧。请注意，我们在初始示例中使用的`dspy.Predict`也是一个模块，代表没有提示技巧！
- en: '`dspy.Predict`: Basic predictor. Does not modify the signature. Handles the
    key forms of learning (i.e., storing the instructions and demonstrations and updates
    to the LM).'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dspy.Predict`：基本的预测器。不会修改签名。处理学习的关键形式（即存储指令和示范以及对LM的更新）。'
- en: '`dspy.ChainOfThought`: Teaches the LM to think step-by-step before committing
    to the signature’s response.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dspy.ChainOfThought`：教会LM在给出签名的回应之前，逐步思考。'
- en: '`dspy.ProgramOfThought`: Teaches the LM to output code, whose execution results
    will dictate the response.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dspy.ProgramOfThought`：教会LM输出代码，其执行结果将决定响应。'
- en: '`dspy.ReAct`: An agent that can use tools to implement the given signature.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dspy.ReAct`：一个可以使用工具来执行给定签名的智能体。'
- en: '`dspy.MultiChainComparison`: Can compare multiple outputs from ChainOfThought
    to produce a final prediction.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dspy.MultiChainComparison`：可以比较ChainOfThought的多个输出，以产生最终预测。'
- en: 'It also have some function-style modules:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它也有一些类似函数的模块：
- en: '6\. `dspy.majority`: Can do basic voting to return the most popular response
    from a set of predictions.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 6. `dspy.majority`：可以进行基本的投票，从一组预测中返回最受欢迎的响应。
- en: You can check out further examples in [each module’s respective guide](https://dspy-docs.vercel.app/api/category/modules).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[每个模块的相关指南](https://dspy-docs.vercel.app/api/category/modules)中查看更多示例。
- en: Chaining the modules
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链接模块
- en: On the other hand, what about RAG? We can chain the modules together to deal
    with bigger problems!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，RAG怎么办？我们可以将模块串联在一起，处理更大的问题！
- en: First we define a retriever, for our example we use a ColBERT retriever getting
    information from Wikipedia Abstracts 2017
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个检索器，在我们的示例中，我们使用ColBERT检索器从维基百科摘要2017年中获取信息。
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we define the `RAG` class inherited from `dspy.Module`. It needs two methods:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义继承自`dspy.Module`的`RAG`类。它需要两个方法：
- en: 'The `__init__` method will simply declare the sub-modules it needs: `dspy.Retrieve`
    and `dspy.ChainOfThought`. The latter is defined to implement our `context, question
    -> answer` signature.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__init__`方法将简单声明它需要的子模块：`dspy.Retrieve`和`dspy.ChainOfThought`。后者被定义为实现我们的`context,
    question -> answer`签名。'
- en: The `forward` method will describe the control flow of answering the question
    using the modules we have.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward`方法将描述使用我们已有的模块来回答问题的控制流程。'
- en: '*Note: Code in this section is borrowed from* [*DSPy’s introduction notebook*](https://github.com/stanfordnlp/dspy/blob/main/intro.ipynb)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：本部分的代码借用自* [*DSPy简介笔记本*](https://github.com/stanfordnlp/dspy/blob/main/intro.ipynb)'
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Then we make use of the class to perform a RAG
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们利用这个类来执行RAG。
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Inspecting the prompt, we see that 3 passages retrieved from Wikipedia Abstracts
    2017 is interpersed as context for Chain of Thought generation
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 检查提示时，我们发现从维基百科摘要2017年中检索的三段文本被交替作为链式思维生成的上下文。
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The above examples might not seem much. At its most basic application the DSPy
    seemed only doing nothing that can’t be done with f-string, but it actually present
    a paradigm shift for prompt writing, as this brings **modularity** to prompt composition!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的例子看起来可能不算什么。在最基本的应用中，DSPy似乎只是做了一些用f-string也能做到的事情，但实际上，它为提示写作带来了范式的转变，因为它为提示组成引入了**模块化**！
- en: First we describe our objective with `Signature`, then we apply different prompting
    techniques with `Modules`. To test different prompt techniques for a given problem,
    we can simply switch the modules used and compare their results, rather than hardcoding
    the “let’s think step by step…” (for Chain of Thought) or “you will interleave
    Thought, Action, and Observation steps” (for ReAct) phrases. The benefit of modularity
    will be demonstrated later in this article with a full-fledged example.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们用`Signature`描述我们的目标，然后使用`Modules`应用不同的提示技巧。为了测试不同的提示技巧，我们可以简单地切换使用的模块并比较它们的结果，而不是硬编码“让我们一步步思考……”（对于链式思维）或“你将交替进行思考、行动和观察步骤”（对于ReAct）这样的短语。模块化的好处将在本文后面通过一个完整的示例进行演示。
- en: The power of DSPy is not only limited to modularity, it can also optimize our
    prompt based on training samples, and test it systematically. We will be exploring
    this in the next section!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DSPy的强大之处不仅限于模块化，它还可以根据训练样本优化我们的提示，并系统地进行测试。我们将在下一部分深入探讨！
- en: '**Optimizer: Train our prompt as with machine learning**'
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**优化器：像机器学习一样训练我们的提示**'
- en: In this section we try to optimize our prompt for a RAG application with DSPy.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们尝试使用DSPy优化我们的提示，以便应用于RAG（检索增强生成）应用。
- en: 'Taking Chain of Thought as an example, beyond just adding the “let’s think
    step by step” phrase, we can boost its performance with a few tweaks:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以链式思维为例，除了仅仅添加“让我们一步步思考”这句话外，我们还可以通过一些调整来提升其表现：
- en: Adding suitable examples (aka **few-shot learning**).
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加适当的示例（即**少量学习**）。
- en: Furthermore, we can **bootstrap demonstrations of reasoning** to teach the LMs
    to apply proper reasoning to deal with the task at hand.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们还可以**启动推理演示**，教导大规模语言模型如何应用恰当的推理来处理当前任务。
- en: Doing this manually would be highly time-consuming and can’t generalize to different
    problems, but with DSPy this can be done automatically. Let’s dive in!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 手动执行这个过程将非常耗时，且无法推广到不同的问题，但借助DSPy，这一切都可以自动完成。让我们深入了解一下！
- en: Preparation
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: '**#1: Loading test data**: Like machine learning, to train our prompt we need
    to prepare our training and test datasets. Initially this cell will take around
    20 minutes to run.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**#1：加载测试数据**：像机器学习一样，为了训练我们的提示，我们需要准备训练数据和测试数据集。最初，这个单元大约需要20分钟才能运行完毕。'
- en: '[PRE17]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Inspecting our dataset, which is basically a set of question-and-answer pairs
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 检查我们的数据集，它基本上是一组问答对。
- en: '[PRE18]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**#2 Set up Phoenix for observability**: To facilitate understanding of the
    optimization process, we launch **Phoenix** to observe our DSPy application, which
    is a great tool for LLM observability in general! I will skip pasting the code
    here, but you can execute it in the notebook.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**#2 设置Phoenix以进行可观察性**：为了便于理解优化过程，我们启动**Phoenix**来观察我们的DSPy应用，这是一个非常适合大规模语言模型（LLM）可观察性的工具！我将跳过在这里粘贴代码，但你可以在笔记本中执行它。'
- en: 'Note: If you are on Windows, please also install Windows C++ Build Tools [here](https://visualstudio.microsoft.com/visual-cpp-build-tools/),
    which is necessary for Phoenix'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你使用的是 Windows，请同时安装 Windows C++ Build Tools，[点击这里](https://visualstudio.microsoft.com/visual-cpp-build-tools/)，这是
    Phoenix 所必需的。
- en: Prompt Optimization
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示优化
- en: 'Then we are ready to see what this opimitzation is about! To “train” our prompt,
    we need 3 things:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们准备好看看这个优化到底是什么！为了“训练”我们的提示，我们需要3样东西：
- en: A training set. We’ll just use our 20 question–answer examples from `trainset`.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个训练集。我们将只使用来自`trainset`的20个问答示例。
- en: A metric for validation. Here we use the native `dspy.evaluate.answer_exact_match`
    which checks if the predicted answer exactly matches the right answer (questionable
    but suffice for demonstration). For real-life applications you can define your
    own evaluation criteria
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个验证指标。这里我们使用原生的`dspy.evaluate.answer_exact_match`，它检查预测的答案是否完全匹配正确答案（虽然值得怀疑，但足以用于演示）。对于实际应用，你可以定义自己的评估标准。
- en: A specific **Optimizer** (formerly teleprompter). The DSPy library includes
    a number of optimization strategies and you can check them out [here](https://dspy-docs.vercel.app/docs/building-blocks/optimizers).
    For our example we use `BootstrapFewShot`. Instead of describing it here with
    lengthy description, I will demonstrate it with code subsequently
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个特定的**优化器**（前身为提词器）。DSPy 库包含了多种优化策略，你可以在[这里](https://dspy-docs.vercel.app/docs/building-blocks/optimizers)查看它们。对于我们的例子，我们使用`BootstrapFewShot`。我将通过代码演示，而不是在这里用冗长的描述来解释它。
- en: Now we train our prompt.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们开始训练我们的提示。
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Before using the `compiled_rag` to answer a question, let’s see what went behind
    the scene during the training process (aka compile). We launch the Phoenix console
    by visiting `http://localhost:6006/` in browser
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`compiled_rag`回答问题之前，让我们看看在训练过程中（即编译过程中）发生了什么。我们通过在浏览器中访问`http://localhost:6006/`来启动
    Phoenix 控制台。
- en: '![](../Images/d94f1dbe53ce5b4aef6a0ea2796a406a.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d94f1dbe53ce5b4aef6a0ea2796a406a.png)'
- en: 14 calls during “compile”
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在“编译”过程中进行了14次调用。
- en: In my run I have made 14 calls using the `RAG` class, in each of those calls
    we post a question to LM to obtain a prediction.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的运行中，我使用`RAG`类进行了14次调用，每次调用时我们都会向语言模型发送一个问题以获取预测结果。
- en: Refer to the result summary table in my notebook, 4 correct answers are made
    from these 14 samples, thus reaching our `max_bootstrapped_demos` parameter and
    stopping the calls.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅我的笔记本中的结果摘要表，从这14个样本中得出了4个正确答案，因此达到了我们的`max_bootstrapped_demos`参数，并停止了调用。
- en: 'But what are the prompts DSPy issued to obtain the bootstrapped demos? Here’s
    the prompt for question #14\. We can see as DSPy tries to generate one bootstrapped
    demo, it would randomly add samples from our `trainset` for few-short learning.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '那么，DSPy 发出的提示是什么，用以获得引导的演示？这是问题 #14 的提示。我们可以看到，当 DSPy 尝试生成一个引导演示时，它会随机从我们的`trainset`中添加样本进行少量学习。'
- en: '[PRE21]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Time to put the `compiled_rag` to test! Here we raise a question which was answered
    wrongly in our summary table, and see if we can get the right answer this time.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候测试一下`compiled_rag`了！我们提出一个在总结表中被错误回答的问题，看看这次是否能得到正确的答案。
- en: '[PRE22]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We now get the right answer!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在得到了正确的答案！
- en: Again let’s inspect the prompt issued. Notice how the compiled prompt is different
    from the ones that were used during bootstrapping. Apart from the few-shot examples,
    **bootstrapped Context-Question-Reasoning-Answer demonstrations from correct predictions
    are added to the prompt**, improving the LM’s capability.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看发出的提示。注意编译后的提示与引导过程中使用的提示有何不同。除了少量示例之外，**引导的上下文-问题-推理-答案演示（来自正确的预测）被添加到提示中**，从而提高了语言模型的能力。
- en: '[PRE24]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'So the below is basically went behind the scene with BootstrapFewShot during
    compilation:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 所以下面的内容基本上是在编译过程中，`BootstrapFewShot`在后台完成的工作：
- en: '![](../Images/843ab35d315078ee9a3d523c13b6f5a5.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/843ab35d315078ee9a3d523c13b6f5a5.png)'
- en: Bootstrapping demonstrations to enhance the prompt
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 引导演示以增强提示
- en: 'The above example still falls short of what we typically do with machine learning:
    Even boostrapping maybe useful, we are not yet proving it to improve the quality
    of the responses.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的例子仍然无法满足我们通常在机器学习中所做的事情：即使引导可能有用，我们还没有证明它能提高响应的质量。
- en: Ideally, like in traditional machine learning we should define a couple of candidate
    models, see how they perform against the test set, and select the one achieving
    the highest performance score. This is what we will do next!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，像传统机器学习一样，我们应该定义几个候选模型，查看它们在测试集上的表现，并选择表现最好的那个。这就是我们接下来要做的！
- en: '**Full fledged example: Prompt comparison with LLM**'
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**完整示例：与LLM的提示比较**'
- en: The aim of this example
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个示例的目的是
- en: In this section, we want to evaluate what is the “best prompt” **(expressed
    in terms of module and optimizer combination)** to perform a RAG against the [HotpotQA
    dataset](https://hotpotqa.github.io/) (distributed under a [CC BY-SA 4.0 License](http://creativecommons.org/licenses/by-sa/4.0/)),
    given the LM we use (GPT 3.5 Turbo).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们希望评估**（通过模块与优化器组合的方式）**哪个是进行RAG的“最佳提示”，并使用我们所用的语言模型（GPT 3.5 Turbo），对[HotpotQA数据集](https://hotpotqa.github.io/)（按[CC
    BY-SA 4.0许可证](http://creativecommons.org/licenses/by-sa/4.0/)分发）进行评估。
- en: 'The Modules under evaluation are:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正在评估的模块如下：
- en: '**Vanilla**: Single-hop RAG to answer a question based on the retrieved context,
    without key phrases like “let’s think step by step”'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原生**：基于检索的上下文回答问题的单跳RAG，没有像“让我们一步一步思考”这样的关键短语'
- en: '**COT**: Single-hop RAG with Chain of Thought'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**COT**：带有思维链的单跳RAG'
- en: '**ReAct**: Single-hop RAG with ReAct prompting'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReAct**：带有ReAct提示的单跳RAG'
- en: '**BasicMultiHop**: 2-hop RAG with Chain of Thought'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BasicMultiHop**：带有思维链的2跳RAG'
- en: 'And the Optimizer candidates are:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 优化器候选项如下：
- en: '**None**: No additional instructions apart from the signature'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无**：除了签名外没有额外的指令'
- en: '**Labeled few-shot**: Simply constructs few-shot examples from provided labeled
    Q/A pairs'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标注少样本**：仅通过提供的标注问答对构造少样本示例'
- en: '**Bootstrap few-shot**: As we demonstrated, self-generate complete demonstrations
    for every stage of our module. Will simply use the generated demonstrations (if
    they pass the metric) without any further optimization. For `Vanilla` it is just
    equal to “Labeled few-shot”'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bootstrap少样本**：如我们所示，为我们模块的每个阶段自生成完整的示范。如果示范通过了评估指标，我们将直接使用这些生成的示范（无需进一步优化）。对于`原生`来说，它就等同于“标注少样本”'
- en: As for evaluation metric, we again use exact match as criteria (`dspy.evaluate.metrics.answer_exact_match`)
    against the test set.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 至于评估指标，我们再次使用精确匹配作为标准（`dspy.evaluate.metrics.answer_exact_match`）对测试集进行评估。
- en: Comparison
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较
- en: Let’s begin! First, we define our modules
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧！首先，我们定义我们的模块
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Then define permutations for our model candidates
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后定义我们模型候选项的排列
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Then I defined a helper class to facilitate the evaluation. The code is a tad
    bit long so I am not pasting it here, but it could be found in my notebook. What
    it does is to apply each the optimizers against the modules, compile the prompt,
    then perform evaluation against the test set.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我定义了一个帮助类来简化评估过程。代码稍长，所以我没有在这里粘贴，但它可以在我的笔记本中找到。它的作用是对每个优化器与模块组合进行应用，编译提示，然后在测试集上进行评估。
- en: We are now ready to start the evaluation, it would take around 20 minutes to
    complete
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备开始评估，预计大约需要20分钟完成
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here’s the evaluation result. We can see the `COT` module with `BootstrapFewShot`
    optimizer has the best performance. The scores represent the percentage of correct
    answers (judged by exact match) made for the test set.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是评估结果。我们可以看到，`COT`模块与`BootstrapFewShot`优化器的表现最佳。分数表示测试集中正确答案的百分比（通过精确匹配判断）。
- en: '![](../Images/5d270eb34c7f0f594923555c9e6499f9.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d270eb34c7f0f594923555c9e6499f9.png)'
- en: 'But before we conclude the exercise, it might be useful to inspect the result
    more deeply: **Multihop with BootstrapFewShot**, which supposedly equips with
    more relevant context than **COT with BootstrapFewShot**, has a worse performance.
    It is strange!'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们得出结论之前，可能需要更深入地检查结果：**Multihop与BootstrapFewShot**，据说比**COT与BootstrapFewShot**提供更多相关上下文，但其表现更差，真是奇怪！
- en: Debug and fine-tune our prompt
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调试并微调我们的提示
- en: 'Now head to the Phoenix Console to see what’s going on. We pick a random question
    `William Hughes Miller was born in a city with how many inhabitants ?`, and inspect
    how did COT, ReAct, BasicMultiHop with BoostrapFewShot optimizer came up with
    their answer. You can type this in the search bar for filter: `"""William Hughes
    Miller was born in a city with how many inhabitants ?""" in input.value`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在前往Phoenix控制台，看看发生了什么。我们选择一个随机问题`William Hughes Miller出生在一个有多少居民的城市？`，并检查COT、ReAct、BasicMultiHop与BootstrapFewShot优化器是如何得出答案的。你可以在搜索栏中输入以下内容进行筛选：`"""William
    Hughes Miller出生在一个有多少居民的城市？""" in input.value`
- en: '![](../Images/588fb6cbfd28970cd79b6918e2a6f614.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/588fb6cbfd28970cd79b6918e2a6f614.png)'
- en: The calls follow sequential order, so for each of the module we can pick the
    BootstrapFewShot variant by picking the 3rd call
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 调用按顺序进行，因此对于每个模块，我们可以通过选择第三个调用来选择BootstrapFewShot变体
- en: 'These are the answers provided by the 3 models during my run:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我运行过程中3个模型提供的答案：
- en: '**Multihop with BootstrapFewShot**: `The answer will vary based on the specific
    city of William Hughes Miller’s birthplace.`'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Multihop with BootstrapFewShot**: `答案将根据 William Hughes Miller 出生城市的具体情况而有所不同。`'
- en: '**ReAct with BootstrapFewShot**: `Kosciusko, Mississippi`'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReAct with BootstrapFewShot**: `Kosciusko, Mississippi`'
- en: '**COT with BootstrapFewShot**: `The city of Kosciusko, Mississippi, has a population
    of approximately 7,402 inhabitants.`'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**COT with BootstrapFewShot**: `Kosciusko, Mississippi 市的人口大约为 7,402 人。`'
- en: The correct answer is `7,402 at the 2010 census`. Both **ReAct with BootstrapFewShot**
    and **COT with BootstrapFewShot** provided relevant answers, but **Multihop with
    BootstrapFewShot** simply failed to provide one.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案是 `2010年普查时为7,402人`。**ReAct with BootstrapFewShot** 和 **COT with BootstrapFewShot**
    都提供了相关答案，但 **Multihop with BootstrapFewShot** 简直没有提供任何答案。
- en: Checking the execution trace in Phoenix for Multihop with BootstrapFewShot,
    looks like the LM fails to understand what is expected for the `search_query`
    specified in the **signature**.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Phoenix 中检查 Multihop with BootstrapFewShot 的执行轨迹，似乎语言模型无法理解在**签名**中指定的 `search_query`
    所期望的内容。
- en: '![](../Images/0e1e7217ff54735470d988cac17fea8f.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e1e7217ff54735470d988cac17fea8f.png)'
- en: The LM can’t come up with the search_query during the 1st hop
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次跳跃期间，语言模型无法生成 search_query。
- en: So we revise the signature, and re-run the evaluation with the code below
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们修订了签名，并使用下面的代码重新运行评估。
- en: '[PRE28]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](../Images/09f52de40780a66ef1cad4de15b306b6.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09f52de40780a66ef1cad4de15b306b6.png)'
- en: Performance improved after updating the signatures
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 更新签名后，性能有所提升。
- en: We now see the score improved across all models, and **Multihop with LabeledFewShot**
    and **Multihop with no examples** now have the best performance! This indicates
    despite DSPy tries to optimize the prompt, **there is still some prompt engineering
    involved by articulating your objective in signature**.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到所有模型的得分都有所提高，并且 **Multihop with LabeledFewShot** 和 **Multihop with no
    examples** 现在表现最好！这表明，尽管 DSPy 尝试优化提示，**仍然需要通过在签名中明确阐述目标来进行一些提示工程。**
- en: '*Note: Even the signature itself can be optimized with DSPy’s* [*COPRO*](https://dspy-docs.vercel.app/docs/deep-dive/teleprompter/signature-optimizer)*!
    But this article will not deep dive into COPRO, as all could be too much to digest.*'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：即使是签名本身也可以通过 DSPy 的* [*COPRO*](https://dspy-docs.vercel.app/docs/deep-dive/teleprompter/signature-optimizer)*进行优化！但本文不会深入探讨
    COPRO，因为那样可能太多信息难以消化。*'
- en: The best model now produce an exact match for our question!
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在最好的模型能准确匹配我们的提问！
- en: '[PRE30]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Since the best prompt is Multihop with LabeledFewShot, the prompt does not contain
    bootstrapped Context-Question-Reasoning-Answer demonstrations. So bootstrapping
    may not surely lead to better performance, **we need to prove which one is the
    best prompt scientifically.**
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最佳的提示是 Multihop with LabeledFewShot，因此提示中不包含自举的上下文-问题-推理-答案示例。因此，自举可能并不一定带来更好的性能，**我们需要科学地证明哪种提示是最好的。**
- en: '[PRE32]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: It does not mean Multihop with BootstrapFewShot has a worse performance **in
    general** however. Only that for our task, if we use GPT 3.5 Turbo to bootstrap
    demonstration (which might be of questionable quality) and output prediction,
    then we might better do without the bootstrapping, and keep only the few-shot
    examples.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着 **Multihop with BootstrapFewShot** 在**总体**表现上较差。只是对于我们的任务来说，如果我们使用
    GPT 3.5 Turbo 进行自举演示（其质量可能值得怀疑）并生成预测，那么我们可能最好不使用自举，而只保留少量示例。
- en: 'This lead to the question: Is it possible to use a more powerful LM, say GPT
    4 Turbo (aka `teacher`) to generate demonstrations, while keeping cheaper models
    like GPT 3.5 Turbo (aka `student`) for prediction?'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个问题：是否有可能使用更强大的语言模型，比如 GPT 4 Turbo（即 `教师`），来生成示范，同时保持像 GPT 3.5 Turbo（即
    `学生`）这样的较便宜的模型用于预测？
- en: '**“Teacher” to power-up bootstrapping capability**'
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**“教师”增强自举能力**'
- en: The answer is **YES** as the following cell demonstrates, we will use GPT 4
    Turbo as teacher.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是**YES**，正如下一个单元格所示，我们将使用 GPT 4 Turbo 作为教师。
- en: '[PRE33]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](../Images/4d747518e8a217acfc20102d3ffef23c.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d747518e8a217acfc20102d3ffef23c.png)'
- en: Result using GPT-4 as teacher
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GPT-4 作为教师的结果
- en: Using GPT-4 Turbo as `teacher` does not significantly boost our models’ performance
    however. Still it is worthwhile to see its effect to our prompt. Below is the
    prompt generated just using GPT 3.5
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 GPT-4 Turbo 作为 `教师` 并没有显著提升我们模型的性能。不过，看看它对提示的影响仍然是值得的。以下是仅使用 GPT 3.5 生成的提示。
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: And here’s the prompt generated using GPT-4 Turbo as `teacher`. Notice how the
    “Reasoning” is much better articulated here!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 GPT-4 Turbo 作为`教师`生成的提示。请注意，“推理”部分在这里阐述得更为清晰！
- en: '[PRE35]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Conclusion
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Currently we often rely on manual prompt engineering at best abstracted as f-string.
    Also, for LM comparison we often raise underspecified questions like “how do different
    LMs compare on a certain problem”, borrowed from the [Stanford NLP paper](https://arxiv.org/abs/2310.03714)’s
    saying.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们常常依赖于手动的提示工程，通常以f-string的形式进行抽象。此外，在语言模型（LM）对比时，我们经常提出一些不够明确的问题，比如“不同的语言模型在某个问题上的表现如何”，这个问题来源于[斯坦福NLP论文](https://arxiv.org/abs/2310.03714)中的说法。
- en: But as the above examples demonstrate, with DSPy’s modular, composable programs
    and optimizers, we are now equipped to answer toward **“how they compare on a
    certain problem with Module X when compiled with Optimizer Y”**, which is a well-defined
    and reproducible run, thus reducing the role of artful prompt construction in
    modern AI.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 但正如上面的示例所展示的，通过DSPy的模块化、可组合程序和优化器，我们现在能够回答**“在与优化器Y编译后的模块X进行对比时，它们在某个问题上的表现如何”**，这是一个定义明确且可重复的运行，从而减少了在现代AI中巧妙提示构建的作用。
- en: That’s it! Hope you enjoy this article.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些！希望你喜欢这篇文章。
- en: '**Unless otherwise noted, all images are by the author*'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**除非另有说明，所有图片均为作者提供**'
