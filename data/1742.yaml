- en: Exploring the Latest Advances in Foundation Time-Series Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索基础时间序列模型的最新进展
- en: 原文：[https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17](https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17](https://towardsdatascience.com/exploring-the-latest-advances-in-foundation-time-series-models-3fc8431ab7bd?source=collection_archive---------1-----------------------#2024-07-17)
- en: Fast and accurate forecasting of new data — without training
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速准确地预测新数据——无需训练
- en: '[](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Nikos
    Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Nikos
    Kafritsas](../Images/de965cfcd8fbd8e1baf849017d365cbb.png)](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    [Nikos Kafritsas](https://medium.com/@nikoskafritsas?source=post_page---byline--3fc8431ab7bd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    ·8 min read·Jul 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: · 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3fc8431ab7bd--------------------------------)
    · 8 分钟阅读 · 2024年7月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5e26a78575698dd1a34f917967ce67c7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e26a78575698dd1a34f917967ce67c7.png)'
- en: '*Join* [*AI Horizon Forecast*](https://aihorizonforecast.substack.com/subscribe)*,
    a blog making complex AI topics as clear as daylight.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*加入* [*AI Horizon Forecast*](https://aihorizonforecast.substack.com/subscribe)*，这是一个将复杂的AI话题讲解得像白昼一样清晰的博客。*'
- en: Recent advances in foundation time-series models are groundbreaking.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基础时间序列模型的最新进展具有突破性意义。
- en: TimeGPT was the first native foundation model. It was released this past August
    and shook the forecasting community.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TimeGPT 是第一个原生基础模型。它在去年8月发布，并震撼了预测社区。
- en: 'Since then, numerous other foundation models have been released, including:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时以来，许多其他基础模型也已发布，包括：
- en: TimesFM
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TimesFM
- en: MOIRAI
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOIRAI
- en: Tiny Time Mixers (TTM)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微型时间混合器（TTM）
- en: MOMENT
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOMENT
- en: We’ve covered these models in previous articles, but they’ve had many updates
    since their initial release.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的文章中讨论过这些模型，但自发布以来，它们已经有了许多更新。
- en: In this article, we’ll explore these updates — which include new benchmarks
    and improved model variants.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探索这些更新——包括新的基准测试和改进后的模型变体。
- en: Let’s get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: TimesFM — Google’s Foundation model [1]
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TimesFM —— 谷歌的基础模型 [1]
- en: '**New updates:** The model weights were recently released on Hugging Face!
    You can find a project tutorial for TimesFM on the [***AI Projects folder***](https://aihorizonforecast.substack.com/p/ai-projects)***!***'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**新更新：** 最近模型的权重在 Hugging Face 上发布了！你可以在[***AI项目文件夹***](https://aihorizonforecast.substack.com/p/ai-projects)找到
    TimesFM 的项目教程***！***'
- en: Google entered the race of foundation models with *TimesFM*, a 200 million parameter
    model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌以 *TimesFM* 进入了基础模型的竞争，这是一个拥有2亿个参数的模型。
