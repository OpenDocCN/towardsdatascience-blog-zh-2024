- en: How to Use Explainable AI Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用可解释的 AI 工具
- en: 原文：[https://towardsdatascience.com/how-to-use-explainable-ai-tools-64749f68088d?source=collection_archive---------7-----------------------#2024-08-15](https://towardsdatascience.com/how-to-use-explainable-ai-tools-64749f68088d?source=collection_archive---------7-----------------------#2024-08-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-use-explainable-ai-tools-64749f68088d?source=collection_archive---------7-----------------------#2024-08-15](https://towardsdatascience.com/how-to-use-explainable-ai-tools-64749f68088d?source=collection_archive---------7-----------------------#2024-08-15)
- en: '[AI Pitfalls Digest](https://medium.com/@pedram-ataee/list/ai-pitfalls-digest-881a26c7eec5)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[AI 陷阱摘要](https://medium.com/@pedram-ataee/list/ai-pitfalls-digest-881a26c7eec5)'
- en: Deep Dive into Feature Importance, Partial Dependence Plot, and Sub-population
    Analysis
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨特征重要性、部分依赖图和子群体分析
- en: '[](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)[![Pedram
    Ataee, PhD](../Images/f4fb1ce6d5543f24e56cdf83630844b2.png)](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)
    [Pedram Ataee, PhD](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)[![Pedram
    Ataee 博士](../Images/f4fb1ce6d5543f24e56cdf83630844b2.png)](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)
    [Pedram Ataee 博士](https://pedram-ataee.medium.com/?source=post_page---byline--64749f68088d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)
    ·7 min read·Aug 15, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--64749f68088d--------------------------------)
    ·阅读时间：7 分钟·2024年8月15日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/22af3c18fc0d81ec941cbdfdfad2e0a6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22af3c18fc0d81ec941cbdfdfad2e0a6.png)'
- en: Photo by [Artem Sapegin](https://unsplash.com/@sapegin?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Artem Sapegin](https://unsplash.com/@sapegin?utm_source=medium&utm_medium=referral)的[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'The AI community has introduced various concepts and tools to interpret AI
    model outcomes, including feature importance, partial dependence plots, and sub-population
    analysis. The Explainable AI (XAI) tools are crucial in building **trust** among
    end-users and regulators, identifying and mitigating **bias,** and improving overall
    model **performance**. They are built to answer the main question of all users:
    “Why did the model make a specific prediction for an instance or a group of instances?”'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: AI 社区已引入了多种概念和工具来解释 AI 模型的结果，包括特征重要性、部分依赖图和子群体分析。可解释 AI（XAI）工具对于在最终用户和监管者之间建立**信任**、识别和减轻**偏见**以及提升整体模型**性能**至关重要。它们的设计目的是回答所有用户的主要问题：“为什么模型会对某个实例或一组实例做出特定的预测？”
- en: While the XAI tools are invaluable in identifying bias and building trust, they
    are highly susceptible to misuse.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 虽然 XAI 工具在识别偏见和建立信任方面具有不可或缺的作用，但它们也容易被误用。
- en: '[](https://shap.readthedocs.io/en/latest/index.html?source=post_page-----64749f68088d--------------------------------)
    [## Welcome to the SHAP documentation - SHAP latest documentation'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shap.readthedocs.io/en/latest/index.html?source=post_page-----64749f68088d--------------------------------)
    [## 欢迎阅读 SHAP 文档 - SHAP 最新文档'
- en: SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain
    the output of any machine learning model…
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SHAP（SHapley 加法解释）是一种博弈论方法，用于解释任何机器学习模型的输出…
- en: shap.readthedocs.io](https://shap.readthedocs.io/en/latest/index.html?source=post_page-----64749f68088d--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: shap.readthedocs.io](https://shap.readthedocs.io/en/latest/index.html?source=post_page-----64749f68088d--------------------------------)
- en: For instance, most feature importance methods assume that features are independent.
    As a result, including highly correlated features in the analysis can lead to
    **unreliable outcomes**. Moreover, different approaches for calculating the global
    importance of features, such as using the “mean…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，大多数特征重要性方法假设特征是独立的。因此，在分析中包含高度相关的特征可能导致**不可靠的结果**。此外，计算特征全局重要性的不同方法，如使用“均值”…
