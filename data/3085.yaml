- en: 'Building Trust in LLM Answers: Highlighting Source Texts in PDFs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建LLM答案的信任：在PDF中突出源文本
- en: 原文：[https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27](https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27](https://towardsdatascience.com/building-trust-in-llm-answers-highlighting-source-texts-in-pdfs-5d1342ecb811?source=collection_archive---------0-----------------------#2024-12-27)
- en: '100% accuracy isn’t everything: helping users navigate the document is the
    real value'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 100%的准确性并不是一切：帮助用户导航文档才是真正的价值所在。
- en: '[](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[![Angela
    & Kezhan Shi](../Images/e6bd57b0ca397b78cf810733c7262e18.png)](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    [Angela & Kezhan Shi](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[![Angela
    & Kezhan Shi](../Images/e6bd57b0ca397b78cf810733c7262e18.png)](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    [Angela & Kezhan Shi](https://medium.com/@angela.shi?source=post_page---byline--5d1342ecb811--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    ·6 min read·Dec 27, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5d1342ecb811--------------------------------)
    ·6分钟阅读·2024年12月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'So, you are building a RAG system or using an LLM to chat with documents. But
    users often ask: how can we trust the answers?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你正在构建一个RAG系统，或者使用LLM与文档进行对话。但用户经常会问：我们如何信任答案呢？
- en: Moreover, we frequently hear about hallucinations, which undermine users’ trust.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们经常听到“幻觉”这一现象，它会破坏用户的信任。
- en: If we build an application but fail to show users where the answers come from,
    the application might become unusable in some cases.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们构建了一个应用程序，但没有向用户展示答案的来源，某些情况下这个应用可能变得无法使用。
- en: In this article, I’ll share an approach to address this concern. By linking
    every answer generated by the LLM to its source text in the document, we can build
    transparency and trust. This method not only provides clear evidence for the answers
    but also allows users to verify the results directly within the PDF.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将分享一种方法来解决这个问题。通过将LLM生成的每个答案与文档中的源文本链接起来，我们可以建立透明度和信任。这种方法不仅提供了明确的答案证据，还允许用户直接在PDF中验证结果。
- en: Sometimes, the generated answer may not be perfectly accurate, but being able
    to locate the correct source text is already helpful for the user.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，生成的答案可能并不完全准确，但能够找到正确的源文本对用户已经非常有帮助。
- en: 'Let’s take an example of [this paper](https://arxiv.org/pdf/2410.05229) from
    arxiv.org. We can imagine this use case:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以[这篇论文](https://arxiv.org/pdf/2410.05229)为例，来自arxiv.org。我们可以想象这个使用场景：
- en: '![](../Images/31cb0653d8ae3ea4091e6e82d5781b0a.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31cb0653d8ae3ea4091e6e82d5781b0a.png)'
- en: Image by author — presentation of the document
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片——文档展示
- en: 'Step 1: Extracting text from PDFs'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步：从PDF中提取文本
- en: The first step in this approach is to extract the text from the PDF in a structured
    format.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的第一步是从PDF中提取结构化格式的文本。
