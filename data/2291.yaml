- en: How Much Data Do You Need to Fine-Tune Gemini?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调 Gemini 需要多少数据？
- en: 原文：[https://towardsdatascience.com/how-much-data-do-you-need-to-fine-tune-gemini-adbfb361a1fc?source=collection_archive---------6-----------------------#2024-09-19](https://towardsdatascience.com/how-much-data-do-you-need-to-fine-tune-gemini-adbfb361a1fc?source=collection_archive---------6-----------------------#2024-09-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-much-data-do-you-need-to-fine-tune-gemini-adbfb361a1fc?source=collection_archive---------6-----------------------#2024-09-19](https://towardsdatascience.com/how-much-data-do-you-need-to-fine-tune-gemini-adbfb361a1fc?source=collection_archive---------6-----------------------#2024-09-19)
- en: Exploring learning curves and sample efficiency of Gemini Flash with code examples.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Gemini Flash 的学习曲线和样本效率，附带代码示例。
- en: '[](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)[![Youness
    Mansar](../Images/b68fe2cbbe219ab0231922c7165f2b6a.png)](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)
    [Youness Mansar](https://medium.com/@CVxTz?source=post_page---byline--adbfb361a1fc--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)
    ·8 min read·Sep 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--adbfb361a1fc--------------------------------)
    ·阅读时间8分钟·2024年9月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1014ddb262374c04c459e1a311744692.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1014ddb262374c04c459e1a311744692.png)'
- en: Photo by [Mohammad Emami](https://unsplash.com/@mo_em?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Mohammad Emami](https://unsplash.com/@mo_em?utm_source=medium&utm_medium=referral)
    通过 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In most common Machine Learning and Natural Language Processing, achieving optimal
    performance often involves a trade-off between the **amount of data** used for
    training and the resulting **model accuracy**. This blog post explores the concept
    of **sample efficiency** in the context of fine-tuning Google’s Gemini Flash model
    using a PII masking dataset as a practical example. We’ll examine how fine-tuning
    with increasing amounts of data impacts the tuned model’s capabilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数常见的机器学习和自然语言处理任务中，达到最佳性能通常需要在**训练数据量**和**模型准确度**之间做出权衡。本博文将探讨**样本效率**这一概念，以使用PII掩码数据集来微调Google的Gemini
    Flash模型为实际例子。我们将分析随着数据量的增加，微调过程如何影响已调优模型的能力。
- en: '**What is Sample Efficiency and Why Does it Matter?**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是样本效率？为什么它如此重要？**'
- en: Sample efficiency refers to a model’s ability to achieve high accuracy with
    a limited amount of training data. It’s a key aspect of ML development, especially
    when dealing with tasks or domains where large, **labeled datasets might be scarce
    or expensive to acquire**. A sample-efficient model can learn effectively from
    fewer examples, reducing the time, cost, and effort associated with data collection
    and training. LLMs were shown to be very sample efficient, even capable of doing
    in-context learning with few examples to significantly boost performance. The
    main motivation of this blog post is to explore this aspect using Gemini Flash
    as an example. We will evaluate this…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 样本效率指的是一个模型在有限的训练数据下实现高准确度的能力。这是机器学习（ML）发展的一个关键方面，特别是在处理那些大量**标注数据可能稀缺或获取成本高昂**的任务或领域时。一个样本高效的模型可以通过更少的例子有效学习，从而减少数据收集和训练所需的时间、成本和努力。研究表明，LLMs（大语言模型）在样本效率方面表现得非常好，甚至能够通过少量的示例进行上下文学习，从而显著提高性能。本博文的主要动机是通过以
    Gemini Flash 为例来探讨这一方面。我们将评估……
