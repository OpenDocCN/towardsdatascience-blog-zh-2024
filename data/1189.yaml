- en: 'Machine Learning on GCP: From Notebooks to Pipelines'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP上的机器学习：从Notebook到数据流水线
- en: 原文：[https://towardsdatascience.com/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f?source=collection_archive---------4-----------------------#2024-05-11](https://towardsdatascience.com/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f?source=collection_archive---------4-----------------------#2024-05-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f?source=collection_archive---------4-----------------------#2024-05-11](https://towardsdatascience.com/machine-learning-on-gcp-from-dev-to-prod-with-vertex-ai-c9e42c4b366f?source=collection_archive---------4-----------------------#2024-05-11)
- en: Notebooks are not enough for ML at scale
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Notebook不足以支撑大规模的机器学习
- en: '[](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)[![Benjamin
    Etienne](../Images/cad8bc2d4b900575e76b7cf9debc9eea.png)](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)
    [Benjamin Etienne](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)[![Benjamin
    Etienne](../Images/cad8bc2d4b900575e76b7cf9debc9eea.png)](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)
    [Benjamin Etienne](https://medium.com/@benjamin_47408?source=post_page---byline--c9e42c4b366f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)
    ·15 min read·May 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c9e42c4b366f--------------------------------)
    ·15分钟阅读·2024年5月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a0f9612d168ba15a6cbadea7628ba7db.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0f9612d168ba15a6cbadea7628ba7db.png)'
- en: Photo by [Sylvain Mauroux](https://unsplash.com/@alpifree?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Sylvain Mauroux](https://unsplash.com/@alpifree?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*All images, unless otherwise noted, are by the author*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者提供*'
- en: Advocating for AI
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推广人工智能
- en: There is a misunderstanding (not to say fantasy) which keeps coming back in
    companies whenever it comes to AI and Machine Learning. People often misjudge
    the complexity and the skills needed to bring Machine Learning projects to production,
    either because they do not understand the job, or (even worse) because they think
    they understand it, whereas they don’t.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 每当谈到 AI 和机器学习时，总有一种误解（甚至可以说是幻想）不断在公司间蔓延。人们常常错误地判断了将机器学习项目投入生产的复杂性和所需的技能，或者是因为他们不了解这项工作，或者更糟的是，他们以为自己了解，却根本不明白。
- en: 'Their first reaction when discovering AI might be something like “AI is actually
    pretty simple, I just need a Jupyter Notebook, copy paste code from here and there
    — or ask Copilot — and boom. No need to hire Data Scientists after all…” And the
    story always end badly, with bitterness, disappointment and a feeling that AI
    is a scam: difficulty to move to production, data drift, bugs, unwanted behavior.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当他们发现 AI 时，第一次的反应可能是：“AI 其实挺简单的，我只需要一个 Jupyter Notebook，从这里那里复制粘贴代码——或者问 Copilot——然后就好了。最终也不需要聘请数据科学家了……”然而故事总是以失败告终，带来的是苦涩、失望，以及
    AI 是骗局的感觉：难以投入生产环境、数据漂移、漏洞、不期望的行为。
- en: 'So let’s write it down once and for all: AI/Machine Learning/any data-related
    job, is a real job, not a hobby. It requires skills, craftsmanship, and tools.
    **If you think you can do ML in production with notebooks, you are wrong.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们一劳永逸地写下来：AI/机器学习/任何数据相关工作，都是一项真正的工作，而不是爱好。它需要技能、工艺和工具。**如果你认为仅凭 Notebook
    就能在生产环境中做机器学习，那你错了。**
- en: This article aims at showing, with a simple example, all the effort, skills
    and tools, it takes to move from a notebook to a real pipeline in production.
    Because ML in production is, mostly, about being able to automate the run of your
    code on a regular basis, with automation and monitoring.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在通过一个简单的例子，展示从 Notebook 到实际生产环境流水线所需的所有努力、技能和工具。因为机器学习的生产环境，主要是要能够定期自动化运行你的代码，并进行自动化和监控。
- en: And for those who are looking for an end-to-end “notebook to vertex pipelines”
    tutorial, you might find this helpful.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些寻找从“笔记本到顶点管道”端到端教程的人来说，你可能会觉得这个有帮助。
- en: A simple use case
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的用例
- en: 'Let’s imagine you are a Data Scientist working at an e-commerce company. Your
    company is selling clothes online, and the marketing team asks for your help:
    they are preparing a special offer for specific products, and they would like
    to efficiently target customers by tailoring email content that will be pushed
    to them to maximize conversion. Your job is therefore simple: each customer should
    be assigned a score which represents the probability he/she purchases a product
    from the special offer.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一位数据科学家，正在一家电子商务公司工作。你的公司在网上销售服装，营销团队请求你的帮助：他们正在为特定产品准备一项特别优惠，并希望通过定制电子邮件内容来高效地将其推送给客户，以最大化转化率。因此，你的工作很简单：每个客户应被分配一个分数，表示他/她购买该特别优惠产品的概率。
- en: 'The special offer will specifically target those brands, meaning that the marketing
    team wants to know which customers will buy their next product from the below
    brands:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 特别优惠将专门针对这些品牌，这意味着营销团队希望知道哪些客户会从以下品牌购买下一个产品：
- en: '*Allegra K, Calvin Klein, Carhartt, Hanes, Volcom, Nautica, Quiksilver, Diesel,
    Dockers, Hurley*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*Allegra K, Calvin Klein, Carhartt, Hanes, Volcom, Nautica, Quiksilver, Diesel,
    Dockers, Hurley*'
- en: We will, for this article, use a publicly available dataset from Google, the
    `*thelook_ecommerce*` [dataset](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce).
    It contains fake data with transactions, customer data, product data, everything
    we would have at our disposal when working at an online fashion retailer.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本文，我们将使用 Google 提供的公开数据集 `*thelook_ecommerce*` [数据集](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce)。它包含了虚构的数据，包括交易数据、客户数据、产品数据，这些数据是我们在在线时尚零售商工作时可以使用的。
- en: To follow this notebook, you will need access to Google Cloud Platform, but
    the logic can be replicated to other Cloud providers or third-parties like Neptune,
    MLFlow, etc.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随此笔记本，你需要访问 Google Cloud Platform，但其逻辑可以移植到其他云服务提供商或第三方平台，如 Neptune、MLFlow
    等。
- en: As a respectable Data Scientist, you start by creating a notebook which will
    help us in exploring the data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名受人尊敬的数据科学家，你开始创建一个笔记本，帮助我们探索数据。
- en: 'We first import libraries which we will use during this article:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入将在本文中使用的库：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Before Production
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产前
- en: Getting and preparing the data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取和准备数据
- en: 'We will then load the data from BigQuery using the Python Client. Be sure to
    use your own project id:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用 Python 客户端从 BigQuery 加载数据。请确保使用你自己的项目 ID：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should see something like that when looking at the dataframe:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 查看数据框时，你应该能看到类似的内容：
- en: '![](../Images/880c9b38a51bc63c48840f0c89577208.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/880c9b38a51bc63c48840f0c89577208.png)'
- en: These represent the transactions / purchases made by the customers, enriched
    with customer and product information.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代表了客户所做的交易/购买，包含了客户和产品信息。
- en: 'Given our objective is to predict which brand customers will buy in their next
    purchase, we will proceed as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们的目标是预测客户在下次购买时将选择哪个品牌，我们将按照以下步骤进行：
- en: Group purchases chronologically for each customer
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照时间顺序为每个客户分组购买记录
- en: If a customer has N purchases, we consider the Nth purchase as the target, and
    the N-1 as our features.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一个客户有 N 次购买，我们将第 N 次购买视为目标，第 N-1 次购买视为特征。
- en: We therefore exclude customers with only 1 purchase
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们排除了只有一次购买的客户
- en: 'Let’s put that into code:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其转化为代码：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Notice how we removed the last item in the sequence features: this is very
    important as otherwise we get what we call a “data leakeage”: the target is part
    of the features, the model is given the answer when learning.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们如何删除了序列特征中的最后一个项：这非常重要，否则我们会遇到所谓的“数据泄漏”问题：目标是特征的一部分，模型在学习时已经获得了答案。
- en: 'We now get this new `df_agg` dataframe:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在得到这个新的 `df_agg` 数据框：
- en: '![](../Images/0b0974517e0f107036fa37d8339f6f23.png)![](../Images/5cb46a927920c0bb0df6c3465aa5ec81.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b0974517e0f107036fa37d8339f6f23.png)![](../Images/5cb46a927920c0bb0df6c3465aa5ec81.png)'
- en: Comparing with the original dataframe, we see that user_id 2 has indeed purchased
    IZOD, Parke & Ronen, and finally Orvis which is not in the target brands.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与原始数据框比较，我们看到用户 ID 为 2 的用户确实购买了 IZOD、Parke & Ronen，最后还购买了 Orvis，而 Orvis 不在目标品牌之内。
- en: Splitting into train, validation and test
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据划分为训练集、验证集和测试集
- en: As a seasoned Data Scientist, you will now split your data into different sets,
    as you obviously know that all three are required to perform some rigorous Machine
    Learning. *(Cross-validation is out of the scope for today folks, let’s keep it
    simple.)*
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名经验丰富的数据科学家，你现在应该将数据分割成不同的子集，因为你显然知道，所有三个子集对于进行严格的机器学习都是必不可少的。*（交叉验证今天不讨论，大家简单了解一下。）*
- en: 'One key thing when splitting the data is to use the not-so-well-known `stratify`
    parameter from the scikit-learn `train_test_split()` method. The reason for that
    is because of class-imbalance: if the target distribution (% of 0 and 1 in our
    case) differs between training and testing, we might get frustrated with poor
    results when deploying the model. *ML 101 kids: keep you data distributions as
    similar as possible between training data and test data.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在分割数据时，一个关键的点是使用 scikit-learn `train_test_split()` 方法中的不太为人知的 `stratify` 参数。这样做的原因是类不平衡：如果目标分布（在我们的例子中是
    0 和 1 的百分比）在训练集和测试集之间有所不同，我们可能在部署模型时遇到差劲的结果，感到沮丧。*机器学习初学者：尽量使训练数据和测试数据之间的数据分布尽可能相似。*
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now this is done, we will gracefully split our dataset between features and
    targets:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这一部分已经完成，我们将优雅地将数据集分割为特征和目标：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Among the feature are different types. We usually separate those between:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 特征中有不同的类型。我们通常将它们分为：
- en: 'numerical features: they are continuous, and reflect a measurable, or ordered,
    quantity.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值特征：它们是连续的，反映了一个可衡量或有序的量。
- en: 'categorical features: they are usually discrete, and are often represented
    as strings (ex: a country, a color, etc…)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别特征：它们通常是离散的，且常常用字符串表示（例如：国家、颜色等）。
- en: 'text features: they are usually sequences of words.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本特征：它们通常是由单词组成的序列。
- en: Of course there can be more like image, video, audio, etc.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还可以有更多类型的数据，比如图像、视频、音频等。
- en: 'The model: introducing CatBoost'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型：介绍CatBoost
- en: 'For our classification problem (you already knew we were in a classification
    framework, didn’t you?), we will use a simple yet very powerful library: CatBoost.
    It is built and maintained by Yandex, and provides a high-level API to easily
    play with boosted trees. It is close to XGBoost, though it does not work exactly
    the same under the hood.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的分类问题（你早就知道我们在做分类问题了，不是吗？），我们将使用一个简单但非常强大的库：CatBoost。它是由 Yandex 构建和维护的，并提供了一个高层次的
    API，方便我们使用提升树。它与 XGBoost 相似，但底层的实现方式并不完全相同。
- en: CatBoost offers a nice wrapper to deal with features from different kinds. In
    our case, some features can be considered as “text” as they are the concatenation
    of words, such as “Calvin Klein;BCBGeneration;Hanes”. Dealing with this type of
    features can sometimes be painful as you need to handle them with text splitters,
    tokenizers, lemmatizers, etc. Hopefully, CatBoost can manage everything for us!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 提供了一个很好的包装器，用来处理不同类型的特征。在我们的例子中，一些特征可以被视为“文本”，因为它们是单词的连接，例如“Calvin
    Klein;BCBGeneration;Hanes”。处理这种类型的特征有时可能会很麻烦，因为你需要用到文本分割器、分词器、词形还原器等工具。幸运的是，CatBoost
    可以为我们处理一切！
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We are now ready to define and train our model. Going through each and every
    parameter is out of today’s scope as the number of parameters is quite impressive,
    but feel free to check the API yourself.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好定义并训练我们的模型。由于参数非常多，今天的范围无法逐一讲解，但欢迎大家自己查看 API。
- en: And for brevity, we will not perform hyperparameter tuning today, but this is
    obviously a large part of the Data Scientist’s job!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们今天不进行超参数调优，但这显然是数据科学家工作的重要组成部分！
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: And voila, our model is trained. Are we done?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我们的模型训练好了。我们完成了吗？
- en: No. We need to check that our model’s performance between training and testing
    is consistent. A huge gap between training and testing means our model is overfitting
    (i.e. “learning the training data by heart and not good at predicting unseen data”).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 不对。我们需要检查模型在训练和测试之间的表现是否一致。训练和测试之间的巨大差距意味着我们的模型出现了过拟合（即“死记硬背训练数据，而在预测未知数据时表现差”）。
- en: For our model evaluation, we will use the ROC-AUC score. Not deep-diving on
    this one either, but from my own experience this is a generally quite robust metric
    and way better than accuracy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的模型评估，我们将使用 ROC-AUC 分数。今天也不会深入探讨这个内容，但根据我个人的经验，这是一个通常非常稳健的评估指标，比准确率要好得多。
- en: 'A quick side note on accuracy: I usually do not recommend using this as your
    evaluation metric. Think of an imbalanced dataset where you have 1% of positives
    and 99% of negatives. What would be the accuracy of a very dumb model predicting
    0 all the time? 99%. So accuracy not helpful here.'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关于准确度的简短备注：我通常不推荐将其作为评估指标。想象一下一个不平衡的数据集，其中有 1% 的正样本和 99% 的负样本。一个总是预测 0 的非常简单的模型，它的准确度是多少？99%。所以在这里，准确度并不有帮助。
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To be honest, 0.62 AUC is not great at all and a little bit disappointing for
    the expert Data Scientist you are. Our model definitely needs a little bit of
    parameter tuning here, and maybe we should also perform feature engineering more
    seriously.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 老实说，0.62 的 AUC 远不算好，对于你这个专家级的数据科学家来说有些让人失望。我们的模型肯定需要一些参数调优，或许我们也应该更加认真地进行特征工程。
- en: 'But it is already better than random predictions (phew):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但这已经比随机预测要好（呼）：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let’s assume we are satisfied for now with our model and our notebook. This
    is where amateur Data Scientists would stop. So how do we make the next step and
    become production ready?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们现在对我们的模型和笔记本感到满意。此时，业余的数据科学家可能就会停下来。那么，我们该如何迈出下一步，成为生产环境下的准备好模型呢？
- en: Moving to Production
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迈向生产
- en: Meet Docker
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 认识 Docker
- en: Docker is a set of platform as a service products that use OS-level virtualization
    to deliver software in packages called containers. This being said, think of Docker
    as code which can run everywhere, and allowing you to avoid the “works on your
    machine but not on mine” situation.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是一套平台即服务（PaaS）产品，使用操作系统级虚拟化技术将软件打包为称为容器的包进行交付。也就是说，可以把 Docker 想象成一种可以在任何地方运行的代码，它能避免“在你的机器上能工作，但在我的机器上不行”的情况。
- en: Why use Docker? Because among cool things such as being able to share your code,
    keep versions of it and ensure its easy deployment everywhere, it can also be
    used to build pipelines. Bear with me and you will understand as we go.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么使用 Docker？因为除了能够分享代码、保留版本并确保代码在任何地方都能轻松部署等酷炫的功能外，它还可以用于构建管道。请耐心听我解释，随着我们的进展你会明白的。
- en: The first step to building a containerized application is to refactor and clean
    up our messy notebook. We are going to define 2 files, `preprocess.py` and `train.py`
    for our very simple example, and put them in a `src` directory. We will also include
    our `requirements.txt` file with everything in it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 构建容器化应用的第一步是重构并清理我们凌乱的笔记本。我们将为这个非常简单的示例定义两个文件，`preprocess.py` 和 `train.py`，并将它们放入
    `src` 目录中。我们还会包括一个包含所有内容的 `requirements.txt` 文件。
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Much cleaner now. You can actually launch your script from the command line
    now!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在干净多了。你实际上可以从命令行启动你的脚本了！
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We are now ready to build our Docker image. For that we need to write a Dockerfile
    at the root of the project:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好构建我们的 Docker 镜像了。为此，我们需要在项目根目录下编写一个 Dockerfile：
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will take our requirements, copy the `src` folder and its contents, and
    install the requirements with pip when the image will build.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将获取我们的需求，复制 `src` 文件夹及其内容，并在镜像构建时使用 pip 安装需求。
- en: 'To build and deploy this image to a container registry, we can use the Google
    Cloud SDK and the `gcloud` commands:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此镜像构建并部署到容器注册表，我们可以使用 Google Cloud SDK 和 `gcloud` 命令：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If everything goes well, you should see something like that:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你应该会看到像这样的结果：
- en: '![](../Images/696d3dbba8791000cd8405119c1144d3.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/696d3dbba8791000cd8405119c1144d3.png)'
- en: Vertex Pipelines, the move to production
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Vertex Pipelines，迈向生产
- en: Docker images are the first step to doing some serious Machine Learning in production.
    The next step is building what we call “pipelines”. Pipelines are a series of
    operations orchestrated by a framework called Kubeflow. Kubeflow can run on Vertex
    AI on Google Cloud.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 镜像是进行生产级机器学习的第一步。下一步是构建我们所称之为“管道”的东西。管道是一系列由名为 Kubeflow 的框架协调的操作。Kubeflow
    可以在 Google Cloud 上的 Vertex AI 运行。
- en: 'The reasons for preferring pipelines over notebooks in production can be debatable,
    but I will give you three based on my experience:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在生产中偏好管道而非笔记本的原因，可能存在争议，但根据我的经验，我给出三个理由：
- en: '**Monitoring and reproducibility**: each pipeline is stored with its artefacts
    (datasets, models, metrics), meaning you can compare runs, re-run them, and audit
    them. Each time you re-run a notebook, you lose the history (or you have to manage
    artefacts yourself as weel as the logs. Good luck.)'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控与可复现性**：每个管道都会与其产物（数据集、模型、指标）一起存储，这意味着你可以比较不同的运行、重新运行它们并进行审计。每次重新运行一个笔记本时，你都会失去历史记录（或者你得自己管理产物和日志。祝你好运。）'
- en: '**Costs**: Running a notebook implies having a machine on which it runs. —
    This machine has a cost, and for large models or huge datasets you will need virtual
    machines with heavy specs.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本**：运行一个笔记本意味着你需要一台能够运行它的机器。— 这台机器是有成本的，对于大型模型或庞大的数据集，你需要具有高规格的虚拟机。'
- en: — You have to remember to switch it off when you don’t use it.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: — 你必须记得在不使用它时将其关闭。
- en: — Or you may simply crash your local machine if you choose not to use a virtual
    machine and have other applications running.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: — 或者，如果你选择不使用虚拟机并且有其他应用程序在运行，你可能会直接崩溃本地机器。
- en: — Vertex AI pipelines is a *serverless* service, meaning you do not have to
    manage the underlying infrastructure, and only pay for what you use, meaning the
    execution time.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: — Vertex AI管道是一个*无服务器*服务，意味着你不需要管理底层基础设施，只需为你使用的部分付费，即执行时间。
- en: '**Scalability**: Good luck when running dozens of experiments on your local
    laptop simultaneously. You will roll back to using a VM, and scale that VM, and
    re-read the bullet point above.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可扩展性**：当你在本地笔记本上同时运行几十个实验时，祝你好运。你将回到使用虚拟机，扩展虚拟机，并重新阅读上面的要点。'
- en: The last reason to prefer pipelines over notebooks is subjective and highly
    debatable as well, but in my opinion notebooks are simply not designed for running
    workloads on a schedule. They are great though for exploration.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 偏好管道而非笔记本的最后一个原因也是主观的，并且高度可辩论，但在我看来，笔记本根本不是为定时调度的工作负载设计的。它们非常适合用于探索。
- en: Use a cron job with a Docker image at least, or pipelines if you want to do
    things the right way, but never, ever, run a notebook in production.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 至少使用Docker镜像来进行定时任务，或者如果你想做得更规范，可以使用管道，但永远不要在生产环境中运行笔记本。
- en: 'Without further ado, let’s write the components of our pipeline:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 不再多说，接下来我们写出管道的组件：
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first component will download the data from Bigquery and store it as a CSV
    file.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个组件将从Bigquery下载数据并将其保存为CSV文件。
- en: 'The BASE_IMAGE we use is the image we build previously! We can use it to import
    modules and functions we defined in our Docker image `src` folder:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的BASE_IMAGE是我们之前构建的镜像！我们可以用它来导入我们在Docker镜像`src`文件夹中定义的模块和函数：
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next step: split data'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步：拆分数据
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next step: model training. We will save the model scores to display them in
    the next step:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步：模型训练。我们将保存模型评分，以便在下一步展示它们：
- en: '[PRE21]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The last step is computing the metrics (which are actually computed in the
    training of the model). It is merely necessary but is nice to show you how easy
    it is to build lightweight components. Notice how in this case we don’t build
    the component from the BASE_IMAGE (which can be quite large sometimes), but only
    build a lightweight image with necessary components:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是计算指标（这些指标实际上是在模型训练过程中计算的）。这只是一个必要步骤，但它能让你看到构建轻量级组件是多么简单。注意，在这种情况下我们并没有从BASE_IMAGE构建组件（它有时可能非常大），而是仅仅构建了一个包含必要组件的轻量级镜像：
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There are usually other steps which we can include, like if we want to deploy
    our model as an API endpoint, but this is more advanced-level and requires crafting
    another Docker image for the serving of the model. To be covered next time.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通常还会有其他步骤可以加入，例如如果我们希望将模型部署为API端点，但这属于更高级的内容，需要为模型的服务创建另一个Docker镜像。下一次会介绍。
- en: 'Let’s now glue the components together:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把组件连接起来：
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If everything works well, you will now see your pipeline in the Vertex UI:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，你现在应该能在Vertex UI中看到你的管道：
- en: '![](../Images/ed0f2a97ea1def0df9a9ccdac40f0be6.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed0f2a97ea1def0df9a9ccdac40f0be6.png)'
- en: 'You can click on it and see the different steps:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以点击它，查看不同的步骤：
- en: '![](../Images/c8ce67a3cf2ebdcff0665e1cbc227d01.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8ce67a3cf2ebdcff0665e1cbc227d01.png)'
- en: Conclusion
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Data Science, despite all the no-code/low-code enthusiasts telling you you don’t
    need to be a developer to do Machine Learning, is a real job. Like every job,
    it requires skills, concepts and tools which go beyond notebooks.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学，尽管所有不写代码/低代码的爱好者告诉你不需要做开发者就能做机器学习，但它依然是一项真正的工作。像所有工作一样，它需要技能、概念和工具，超越了笔记本的范畴。
- en: And for those who aspire to become Data Scientists, here is the reality of the
    job.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些渴望成为数据科学家的朋友们，这就是这份工作的现实。
- en: Happy coding.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 编程愉快。
