- en: Analyzing Unstructured PDF Data with Embedding Models and LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用嵌入模型和大语言模型（LLMs）分析非结构化PDF数据
- en: 原文：[https://towardsdatascience.com/analyzing-unstructured-pdf-data-w-embedding-models-and-llms-f83ae9a57c2b?source=collection_archive---------4-----------------------#2024-06-15](https://towardsdatascience.com/analyzing-unstructured-pdf-data-w-embedding-models-and-llms-f83ae9a57c2b?source=collection_archive---------4-----------------------#2024-06-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/analyzing-unstructured-pdf-data-w-embedding-models-and-llms-f83ae9a57c2b?source=collection_archive---------4-----------------------#2024-06-15](https://towardsdatascience.com/analyzing-unstructured-pdf-data-w-embedding-models-and-llms-f83ae9a57c2b?source=collection_archive---------4-----------------------#2024-06-15)
- en: How to turn PDFs into actionable insights
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何将PDF转化为可操作的见解
- en: '[](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)[![Justin
    Laughlin](../Images/831e75b86ed267033ac09540ce52d6b6.png)](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)
    [Justin Laughlin](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)[![Justin
    Laughlin](../Images/831e75b86ed267033ac09540ce52d6b6.png)](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)
    [Justin Laughlin](https://medium.com/@justin.laughlin12?source=post_page---byline--f83ae9a57c2b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)
    ·8 min read·Jun 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f83ae9a57c2b--------------------------------)
    ·阅读时长8分钟·2024年6月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c01ac4dafe564a7df8a588cc9e784f81.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c01ac4dafe564a7df8a588cc9e784f81.png)'
- en: Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We live in a world with extremely messy data, this much almost any data scientist
    or analyst knows. It’s almost inevitable that any data science project you start,
    the hardest part of the entire project will be acquiring, packaging and cleaning
    data in a way that allows you to deliver insights. The issue for most companies
    and individuals these days though isn’t necessarily the acquiring data (there’s
    lots of that), but rather the packaging and cleaning of unstructured, messy data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个数据极其杂乱的世界里，几乎每个数据科学家或分析师都知道这一点。几乎可以说，无论你开始哪个数据科学项目，整个项目最困难的部分都是获取、打包和清洗数据，以便能够提供有价值的见解。如今大多数公司和个人面临的问题并不一定是数据的获取（那方面数据很多），而是如何打包和清洗那些非结构化的、杂乱无章的数据。
- en: 'Take PDFs of a public company’s SEC filings for example. Inside those documents
    there are hundreds of pages detailing important company information. Additionally,
    new filings are created on a quarterly and annual basis, spanning from when the
    company went public, until their most recent filings. This is so much ***data***
    just not in the traditional sense. The documents contain tables, graphs, summaries,
    explanations and so much more. The issue with analyzing these documents isn’t
    that there isn’t enough information in them (well sometimes that can be true),
    but the larger issue is finding a **quick and easy way** to extract all of the
    most important details to the ***individual user.*** That last piece is possibly
    the most important part: the individual user. What I may find…'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以公共公司的SEC文件中的PDF为例。这些文件包含数百页，详细说明了重要的公司信息。此外，新的文件每季度和每年都会创建，从公司上市以来到最新的文件为止。这些文件包含的***数据***非常庞大，但却不是传统意义上的数据。这些文档包含表格、图表、摘要、解释等大量内容。分析这些文档的问题不是因为它们缺乏信息（当然，有时候确实如此），而是更大的问题在于找到一种**快速简便的方式**来提取对***个体用户***最重要的细节。最后这一点可能是最重要的：个体用户。对于我来说…
