- en: 'Lessons From My ML Journey: Data Splitting and Data Leakage'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的机器学习之旅中的经验教训：数据划分与数据泄漏
- en: 原文：[https://towardsdatascience.com/two-rookie-mistakes-i-made-in-machine-learning-improper-data-splitting-and-data-leakage-3e33a99560ea?source=collection_archive---------1-----------------------#2024-02-25](https://towardsdatascience.com/two-rookie-mistakes-i-made-in-machine-learning-improper-data-splitting-and-data-leakage-3e33a99560ea?source=collection_archive---------1-----------------------#2024-02-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/two-rookie-mistakes-i-made-in-machine-learning-improper-data-splitting-and-data-leakage-3e33a99560ea?source=collection_archive---------1-----------------------#2024-02-25](https://towardsdatascience.com/two-rookie-mistakes-i-made-in-machine-learning-improper-data-splitting-and-data-leakage-3e33a99560ea?source=collection_archive---------1-----------------------#2024-02-25)
- en: Common mistakes to avoid when you transition from statistical modelling to Machine
    Learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从统计建模转向机器学习时需要避免的常见错误
- en: '[](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)[![Khin
    Yadanar Lin](../Images/1018a44583239dfd33901b6d392d257f.png)](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)
    [Khin Yadanar Lin](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)[![Khin
    Yadanar Lin](../Images/1018a44583239dfd33901b6d392d257f.png)](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)
    [Khin Yadanar Lin](https://medium.com/@khinydnlin_310?source=post_page---byline--3e33a99560ea--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)
    ·7 min read·Feb 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3e33a99560ea--------------------------------)
    ·7 分钟阅读·2024年2月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/61b1e12ac5adb638a6f48a7ce5d93b04.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61b1e12ac5adb638a6f48a7ce5d93b04.png)'
- en: Photo by [Susan Q Yin](https://unsplash.com/@syinq?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Susan Q Yin](https://unsplash.com/@syinq?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: My Story
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我的故事
- en: '**Data Science, Machine Learning, and AI** are undeniably buzzwords of today.
    My LinkedIn is flooded with data gurus sharing learning roadmaps for those eager
    to break into this data space.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据科学、机器学习和人工智能**无疑是当今的流行词汇。我的LinkedIn充满了分享学习路线图的数据专家，供那些渴望进入数据领域的人参考。'
- en: Yet, from my personal experience, I’ve found that the journey towards Data Science
    isn’t as linear as merely following a fixed roadmap, especially for individuals
    transitioning from various professional backgrounds. Data Science requires a blend
    of diverse skills like programming, statistics, math, analytics, soft skills,
    and domain knowledge. This means that everyone picks up learning from different
    points depending on their prior experience/skill sets.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从我的个人经验来看，我发现走向数据科学的道路并不像单纯按照固定路线图前进那样线性，尤其是对于那些从不同职业背景转型的人来说。数据科学需要多种技能的结合，如编程、统计学、数学、分析、软技能和领域知识。这意味着每个人根据自己的先前经验和技能集，从不同的起点开始学习。
- en: As someone who worked in research and analytics for years and pursued a master’s
    degree in analytics, I have acquired a fair amount of statistical knowledge and
    its applications. Even then, data science is such a broad and dynamic industry
    that my knowledge is still all over the place. I struggled to find resources that
    could effectively fill my knowledge gap between statistics and ML as well. This
    posed significant challenges to my learning experience.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一位在研究和分析领域工作多年并获得分析学硕士学位的人，我积累了一定的统计学知识及其应用。然而，数据科学是一个如此广泛且充满活力的行业，我的知识仍然是零散的。我也曾努力寻找能够有效填补我在统计学和机器学习之间知识空白的资源。这给我的学习体验带来了重大挑战。
- en: In this article, I aim to share the technical oversights I encounter as I navigate
    from research & analytics to data science. Hopefully, my sharing can save you
    time and help you avoid these pitfalls.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想分享我在从研究与分析转向数据科学过程中遇到的技术性忽视问题。希望我的分享能为你节省时间，并帮助你避免这些陷阱。
- en: Statistical Modelling Vs Machine Learning
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计建模与机器学习
- en: So, you might be wondering why I am starting with a reflection on my journey
    instead of getting to the point. Well, the reason is simple — I have noticed that
    many individuals claim to be building ML models when, in reality, they are only
    crafting statistical models. I confess I was one of them! It’s not like one is
    better than the other, but I believe it is crucial to recognise the nuances between
    statistical modelling and ML before I talk about technicalities.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你可能会想，为什么我从回顾我的旅程开始，而不是直接进入主题。原因很简单——我发现很多人声称自己在构建机器学习模型，但实际上他们只是构建统计模型。我承认我曾是其中之一！并不是说一种比另一种更好，但我认为在讨论技术细节之前，理解统计建模与机器学习之间的差异是非常重要的。
- en: The purpose of **statistical models** is **for making inferences**, while the
    primary goal of **Machine Learning** is **for predictions**. Simply put, the ML
    model leverages statistics and math to generate predictions applicable to real-world
    scenarios. This is where data splitting and data leakage come into the picture,
    particularly in the context of supervised Machine Learning.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**统计模型**的目的是**做出推断**，而**机器学习**的主要目标是**进行预测**。简单来说，机器学习模型利用统计学和数学生成适用于现实世界场景的预测。这也是数据划分和数据泄漏问题出现的地方，特别是在有监督机器学习的背景下。'
- en: My initial belief was that understanding statistical analysis was sufficient
    for prediction tasks. However, I quickly realised that without knowledge of data
    preparation techniques such as proper data splitting and awareness of potential
    pitfalls like data leakage, even the most sophisticated statistical models fall
    short in predictive performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初的信念是，理解统计分析就足够进行预测任务了。然而，我很快意识到，如果没有掌握诸如适当的数据划分和意识到潜在的陷阱（如数据泄漏）等数据准备技巧，即使是最复杂的统计模型在预测性能上也会有所欠缺。
- en: So, let’s get started!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧！
- en: '**Mistake 1: Improper Data Splitting**'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**错误 1: 数据划分不当**'
- en: '**What is meant by data splitting?**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**什么是数据划分？**'
- en: Data splitting, in essence, is dividing your dataset into parts for optimal
    predictive performance of the model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分，本质上是将数据集分割成多个部分，以便模型获得最佳的预测性能。
- en: Consider a simple OLS regression concept that is familiar to many of us. We
    all have heard about it in one of the business/stats/finance, economics, or engineering
    lectures. It is a fundamental ML technique.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个我们许多人都熟悉的简单最小二乘回归（OLS）概念。我们在商学、统计学、金融学、经济学或工程学课程中都听说过它。它是一个基本的机器学习技术。
- en: Let’s say we have a housing price dataset along with the factors that might
    affect housing prices.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个房价数据集，以及可能影响房价的各类因素。
- en: In **traditional statistical analysis,** we employ **the entire dataset** to
    develop a regression model, as our goal is just to understand what factors influence
    housing prices. In other words, regression models can explain what degree of changes
    in prices are associated with the predictors.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在**传统统计分析**中，我们使用**整个数据集**来构建回归模型，因为我们的目标只是理解哪些因素会影响房价。换句话说，回归模型可以解释价格变化的程度与预测变量之间的关系。
- en: However, in ML, the statistical part remains the same, but data splitting becomes
    crucial. Let me explain why — imagine we train the model on the entire set; how
    would we know the predictive performance of the model on unseen data?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在机器学习中，统计部分保持不变，但数据划分变得至关重要。让我解释一下原因——假设我们在整个数据集上训练模型，那么我们如何知道模型在未见数据上的预测表现呢？
- en: 'For this very reason, we typically split the dataset into two sets: training
    and test sets. The idea is to train the model on one set and evaluate its performance
    on the other set. Essentially, the test set should serve as real-world data, meaning
    the model should not have access to the test data in any way throughout the training
    phase.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正因为如此，我们通常将数据集分为两部分：训练集和测试集。其理念是，在一部分数据上训练模型，在另一部分数据上评估模型的性能。本质上，测试集应该充当真实世界的数据，这意味着在训练阶段，模型绝不能接触到测试数据。
- en: Here comes the pitfall that I wasn’t aware of before. Splitting data into two
    sets is not inherently wrong, but there is a risk of creating an unreliable model.
    Imagine you train the model on the training set, validate its accuracy on the
    test set, and then repeat the process to fine-tune the model. This creates a bias
    in model selection and defeats the whole purpose of “unseen data” because test
    data was seen multiple times during model development. It undermines the model’s
    ability to genuinely predict the unseen data, leading to overfitting issues.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这里出现了我之前没有意识到的陷阱。将数据拆分成两个数据集本身并不错误，但存在创建不可靠模型的风险。想象一下，你在训练集上训练模型，在测试集上验证其准确性，然后重复这个过程来微调模型。这会在模型选择中产生偏差，且会违背“未见数据”的初衷，因为测试数据在模型开发过程中已经多次出现。它削弱了模型真实预测未见数据的能力，导致过拟合问题。
- en: '**How to prevent it:**'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**如何防止：**'
- en: 'Ideally, the dataset should be divided into two blocks (three distinct splits):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，数据集应分为两个块（三个不同的拆分）：
- en: '**( Training set + Validation set) → 1st block**'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**（训练集 + 验证集）→ 第一个块**'
- en: '**Test set → 2nd block**'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集 → 第二个块**'
- en: The model can be trained and validated on the 1st block. The 2nd block (the
    test set) should not be involved in any of the model training processes. Think
    of the test set as a danger zone!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以在第一个块上进行训练和验证。第二个块（测试集）不应参与任何模型训练过程。将测试集视为禁区！
- en: How you want to split the data is dependent on the size of the dataset. The
    industry standard is 60% — 80 % for the training set (1st block) and 20% — 40%
    for the test set. The validation set is normally curved out of the 1st block so
    the actual training set would be 70% — 90% out of the 1st block , and the rest
    is for the validation set.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据拆分的方式取决于数据集的大小。行业标准是训练集（第一个块）占60% — 80%，测试集占20% — 40%。验证集通常从第一个块中划分出来，因此实际的训练集将占第一个块的70% — 90%，其余部分为验证集。
- en: 'The best way to grasp this concept is through a visual:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个概念的最好方式是通过一个图示：
- en: '![](../Images/6105336a31da32444fe35c89d8af593c.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6105336a31da32444fe35c89d8af593c.png)'
- en: Leave-One-Out (LOOV) method (Image by the author)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 留一法（LOOV）方法（图像来自作者）
- en: 'There is more than one data-splitting technique other than LOOV (in the picture):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 除了LOOV（图中所示），还有其他多种数据拆分技术：
- en: K-fold Cross-validation, which divides the data into a number of ‘K’ folds and
    iterates the training processes accordingly
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K折交叉验证，将数据分成‘K’个折叠，并相应地迭代训练过程
- en: Rolling Window Cross-validation (for time-series data)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动窗口交叉验证（适用于时间序列数据）
- en: Blocked Cross-validation (for time-series data)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻塞交叉验证（适用于时间序列数据）
- en: Stratified Sampling Splitting for imbalanced classes
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不平衡类别的分层抽样拆分
- en: 'Note: Time series data needs extra caution when splitting data due to its temporal
    order. Randomly splitting the dataset can mess up its time order. (I learnt it
    the hard way)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：时间序列数据在拆分时需要特别小心，因为其时间顺序。随机拆分数据集可能会破坏其时间顺序。（我是通过亲身经历学到的）
- en: The most important thing is regardless of the techniques you use, the “test
    set” should be kept separate and untouched until the model selection.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最重要的一点是，无论使用何种技术，“测试集”都应保持独立且未被触及，直到模型选择阶段。
- en: '**Mistake 2: Data Leakage**'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**错误 2：数据泄漏**'
- en: “In Machine learning, **Data Leakage** refers to a mistake that is made by the
    creator of a machine learning model in which they accidentally share the information
    between the test and training data sets.” — Analytics Vidhya
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在机器学习中，**数据泄漏**是指机器学习模型的创建者犯下的一个错误，他们不小心将测试数据集和训练数据集之间的信息共享。” — Analytics Vidhya
- en: This is connected to my first point about test data being contaminated by training
    data. It’s one example of data leakage. However, having a validation set alone
    can’t avoid data leakage.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我提到的第一个观点有关，即测试数据被训练数据污染。这是数据泄漏的一个例子。然而，仅仅拥有验证集并不能避免数据泄漏。
- en: In order to prevent data leakage, we need to be careful with the data handling
    process — from Exploratory Data Analysis (EDA) to Feature Engineering. Any procedure
    that allows the training data to interact with the test data could potentially
    lead to leakage.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止数据泄漏，我们需要小心处理数据的过程——从探索性数据分析（EDA）到特征工程。任何允许训练数据与测试数据交互的过程，都可能导致泄漏。
- en: 'There are two main types of leakage:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄漏主要有两种类型：
- en: '**Train-test-contamination**'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练-测试污染**'
- en: A common mistake I made involved applying a standardisation/pre-processing procedure
    to the entire set before data splitting. For example, using mean imputation to
    handle missing values/ outliers on the whole dataset. This makes the training
    data incorporate information from the test data. As a result, the model’s accuracy
    is inflated compared to its real-life performance.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾犯的一个常见错误是，在数据拆分之前对整个数据集应用标准化/预处理程序。例如，在整个数据集上使用均值填充来处理缺失值/异常值。这使得训练数据包含了测试数据中的信息。因此，模型的准确率被虚高，相较于它在实际应用中的表现。
- en: '**2\. Target leakage**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 目标泄漏**'
- en: If the features (predictors) have some dependency on the variable that we want
    to predict (target), or if the features data will not be available at the time
    of prediction, this can result in target leakage.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征（预测变量）与我们想要预测的变量（目标变量）之间存在某种依赖关系，或者如果预测时特征数据不可用，这可能会导致目标泄漏。
- en: Let’s look at the data I worked on as an example. Here, I was trying to predict
    sales performance based on advertising campaigns. I tried to include the conversion
    rates. I overlooked the fact that conversion rates are only known post-campaign.
    In other words, I won’t have this information at the time of forecasting. Plus,
    because conversion rates are tied to sales data, this introduces a classic case
    of target leakage. Including conversion rates would lead the model to learn from
    data that would not be normally accessible, resulting in overly optimistic predictions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我所处理的数据为例。在这里，我试图根据广告活动预测销售表现。我尝试加入转化率。我忽略了转化率仅在活动结束后才会得知。换句话说，我在预测时无法获得这些信息。此外，因为转化率与销售数据相关联，这就引入了典型的目标泄漏案例。包括转化率会导致模型学习到通常无法访问的数据，从而产生过于乐观的预测。
- en: '![](../Images/770a023e6724fb3763738400109bd951.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/770a023e6724fb3763738400109bd951.png)'
- en: Sample (made-up) Dataset (Image by the author)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 示例（虚构）数据集（图片由作者提供）
- en: 'How to prevent data leakage:'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何防止数据泄漏：
- en: 'In summary, keep these points in mind to address data leakage issues:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，记住以下几点来解决数据泄漏问题：
- en: Proper Data Preprocessing
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适当的数据预处理
- en: Cross-validation with care
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小心交叉验证
- en: Careful Feature Selection
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小心特征选择
- en: '**Closing Thoughts**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结束语**'
- en: That’s about it! Thanks for sticking with me till the end! I hope this article
    clarifies the common misconceptions around data splitting and sheds light on the
    best practices in building efficient ML models.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！感谢你一直看到最后！希望这篇文章能够澄清关于数据拆分的常见误解，并为构建高效的机器学习模型提供最佳实践。
- en: This is not just for documenting my learning journey but also for mutual learning.
    So, if you spot a gap in my technical know-how or have any insights to share,
    feel free to drop me a message!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅是记录我的学习过程，也是为了共同学习。所以，如果你发现我技术知识中的空白或有任何见解要分享，随时可以给我留言！
- en: 'References:'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[Daniel Lee Datainterview.com LinkedIn Post](https://www.linkedin.com/posts/danleedata_choosing-your-model-on-%3F%3F%3F%3F%3F-%3F%3F-activity-7158131388976693248-FXUT?utm_source=share&utm_medium=member_desktop)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[Daniel Lee Datainterview.com LinkedIn帖子](https://www.linkedin.com/posts/danleedata_choosing-your-model-on-%3F%3F%3F%3F%3F-%3F%3F-activity-7158131388976693248-FXUT?utm_source=share&utm_medium=member_desktop)'
- en: '[Kaggle — Data Leakage Explanation](https://www.kaggle.com/code/alexisbcook/data-leakage)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kaggle — 数据泄漏解释](https://www.kaggle.com/code/alexisbcook/data-leakage)'
- en: '[Analytics Vidhya — Data Leakage And Its Effect On The Performance of An ML
    Model](https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[Analytics Vidhya — 数据泄漏及其对机器学习模型性能的影响](https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/)'
- en: '[Forecasting: Principles and Practice](https://otexts.com/fpp3/tscv.html)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[预测：原理与实践](https://otexts.com/fpp3/tscv.html)'
