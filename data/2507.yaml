- en: 'How to Choose the Best ML Deployment Strategy: Cloud vs. Edge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何选择最佳的机器学习部署策略：云端 vs. 边缘
- en: 原文：[https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14](https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14](https://towardsdatascience.com/how-to-choose-the-best-ml-deployment-strategy-cloud-vs-edge-7b62d9db9b20?source=collection_archive---------3-----------------------#2024-10-14)
- en: The choice between cloud and edge deployment could make or break your project
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择云端还是边缘部署可能决定了你的项目成败
- en: '[](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[![Vincent
    Vandenbussche](../Images/b2febfc63ca0efbda0af5501f6080ab7.png)](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)
    [Vincent Vandenbussche](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[![Vincent
    Vandenbussche](../Images/b2febfc63ca0efbda0af5501f6080ab7.png)](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)
    [Vincent Vandenbussche](https://medium.com/@vincent.vandenbussche?source=post_page---byline--7b62d9db9b20--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)
    ·14 min read·Oct 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7b62d9db9b20--------------------------------)
    ·14分钟阅读·2024年10月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/670dca37200cce7a7304957e014758b6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/670dca37200cce7a7304957e014758b6.png)'
- en: Photo by [Jakob Owens](https://unsplash.com/@jakobowens1?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jakob Owens](https://unsplash.com/@jakobowens1?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: As a machine learning engineer, I frequently see discussions on social media
    emphasizing the importance of deploying ML models. I completely agree — model
    deployment is a critical component of MLOps. As ML adoption grows, there’s a rising
    demand for scalable and efficient deployment methods, yet specifics often remain
    unclear.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名机器学习工程师，我经常看到社交媒体上的讨论强调部署机器学习模型的重要性。我完全同意——模型部署是 MLOps 的关键组成部分。随着机器学习的普及，对可扩展且高效的部署方法的需求日益增加，但具体方法往往仍不明确。
- en: 'So, does that mean model deployment is always the same, no matter the context?
    In fact, quite the opposite: I’ve been deploying ML models for about a decade
    now, and it can be quite different from one project to another. There are many
    ways to deploy a ML model, and having experience with one method doesn’t necessarily
    make you proficient with others.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这是否意味着模型部署在任何情况下都是相同的呢？事实上，正好相反：我已经部署机器学习模型大约十年了，在不同项目之间，部署的方式可能差异很大。部署机器学习模型有很多种方式，拥有一种方法的经验并不意味着你对其他方法也足够熟练。
- en: 'The remaining question is: **what are the methods to deploy a ML model**, and
    **how do we choose the right method**?'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的问题是：**部署机器学习模型的方法有哪些**，以及**我们如何选择合适的方法**？
- en: 'Models can be deployed in various ways, but they typically fall into two main
    categories:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以通过多种方式进行部署，但通常可以分为两大类：
- en: Cloud deployment
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云端部署
- en: Edge deployment
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘部署
- en: 'It may sound easy, but there’s a catch. For both categories, there are actually
    many subcategories. Here is a non-exhaustive diagram of deployments that we will
    explore in this article:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来可能很简单，但实际上有一个陷阱。对于这两大类部署，实际上还有很多子类别。以下是我们将在本文中探讨的一个非详尽的部署图示：
- en: '![](../Images/70f0d9d6cbcae7b724cde834f082013a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70f0d9d6cbcae7b724cde834f082013a.png)'
- en: Diagram of the explored subcategories of deployment in this article. Image by
    author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中探讨的部署子类别图示。图像来自作者。
- en: 'Before talking about how to choose the right method, **let’s explore each category:
    what it is, the pros, the cons, the typical tech stack, and I will also share
    some personal examples** of deployments I did in that context. Let’s dig in!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在谈论如何选择合适的方法之前，**让我们探索一下每个类别：它是什么，优点，缺点，典型的技术栈，我还将分享一些我在这个背景下做的部署的个人示例**。让我们深入了解！
- en: Cloud Deployment
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云部署
- en: 'From what I can see, it seems cloud deployment is by far **the most popular
    choice** when it comes to ML deployment. This is what is usually expected to master
    for model deployment. But cloud deployment usually means one of these, depending
    on the context:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从我所见，云部署似乎是迄今为止 **在 ML 部署中最受欢迎的选择**。这通常是部署模型时需要掌握的内容。但云部署通常意味着以下几种方式之一，具体取决于上下文：
- en: API deployment
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 部署
- en: Serverless deployment
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器部署
- en: Batch processing
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量处理
- en: Even in those sub-categories, one could have another level of categorization
    but we won’t go that far in that post. Let’s have a look at what they mean, their
    pros and cons and a typical associated tech stack.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在这些子类别中，可能还会有另一个层次的分类，但我们在这篇文章中不会探讨那么深入。让我们看看它们的含义、优缺点以及典型的技术栈。
- en: API Deployment
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: API 部署
- en: 'API stands for Application Programming Interface. This is a very popular way
    to deploy a model on the cloud. Some of the most popular ML models are deployed
    as APIs: Google Maps and OpenAI’s ChatGPT can be queried through their APIs for
    examples.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: API 代表应用程序编程接口。这是一种在云中部署模型的非常流行的方式。许多流行的机器学习模型都是作为 API 部署的：例如，Google Maps 和
    OpenAI 的 ChatGPT 都可以通过它们的 API 进行查询。
- en: 'If you’re not familiar with APIs, know that it’s usually called with a simple
    query. For example, type the following command in your terminal to get the 20
    first Pokémon names:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不熟悉 API，了解它通常是通过简单的查询调用的。例如，在终端中输入以下命令来获取前 20 个宝可梦的名字：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Under the hood, what happens when calling an API might be a bit more complex.
    API deployments usually involve a standard tech stack including load balancers,
    autoscalers and interactions with a database:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，当调用一个 API 时，实际发生的可能更为复杂。API 部署通常涉及包括负载均衡器、自动扩展器和与数据库交互的标准技术栈：
- en: '![](../Images/e6dd59aa3082e1c70e16efd4f871e817.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6dd59aa3082e1c70e16efd4f871e817.png)'
- en: A typical example of an API deployment within a cloud infrastructure. Image
    by author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在云基础设施中进行 API 部署的典型示例。图片由作者提供。
- en: '*Note: APIs may have different needs and infrastructure, this example is simplified
    for clarity.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*备注：API 可能有不同的需求和基础设施，本文中的示例已简化以便于理解。*'
- en: 'API deployments are popular for several reasons:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: API 部署因几个原因而流行：
- en: Easy to implement and to integrate into various tech stacks
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于实现并集成到各种技术栈中
- en: 'It’s easy to scale: using horizontal scaling in clouds allow to scale efficiently;
    moreover managed services of cloud providers may reduce the need for manual intervention'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它易于扩展：使用云中的横向扩展可以高效地进行扩展；此外，云提供商的托管服务可能减少手动干预的需求。
- en: It allows centralized management of model versions and logging, thus efficient
    tracking and reproducibility
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它允许集中管理模型版本和日志，从而实现高效的跟踪和可重现性。
- en: 'While APIs are a really popular option, there are some cons too:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 API 是一个非常流行的选择，但它也有一些缺点：
- en: There might be latency challenges with potential network overhead or geographical
    distance; and of course it requires a good internet connection
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会面临延迟问题，特别是由于潜在的网络开销或地理距离；当然，这也需要一个良好的互联网连接。
- en: The cost can climb up pretty quickly with high traffic (assuming automatic scaling)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于高流量，成本可能会迅速攀升（假设自动扩展）。
- en: Maintenance overhead can get expensive, either with managed services cost of
    infra team
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护开销可能会变得很昂贵，无论是托管服务的费用还是基础设施团队的成本。
- en: To sum up, **API deployment is largely used** in many startups and tech companies
    **because of its flexibility** and a rather short time to market. But the **cost
    can climb up quite fast for high traffic**, and the maintenance cost can also
    be significant.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，**API 部署在许多初创公司和技术公司中被广泛使用**，**因为它的灵活性**和较短的市场投入时间。然而，**对于高流量，成本可能会迅速上升**，维护成本也可能相当高。
- en: 'About the tech stack: there are many ways to develop APIs, but the most common
    ones in Machine Learning are probably [FastAPI](https://fastapi.tiangolo.com/)
    and [Flask](https://flask.palletsprojects.com/en/3.0.x/). They can then be deployed
    quite easily on the main cloud providers (AWS, GCP, Azure…), preferably through
    docker images. The orchestration can be done through managed services or with
    Kubernetes, depending on the team’s choice, its size, and skills.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 关于技术栈：开发API有很多方式，但在机器学习中最常见的可能是[FastAPI](https://fastapi.tiangolo.com/)和[Flask](https://flask.palletsprojects.com/en/3.0.x/)。然后，它们可以通过docker镜像非常容易地部署到主要的云提供商（AWS、GCP、Azure等）。可以通过托管服务或Kubernetes进行编排，具体取决于团队的选择、规模和技能。
- en: 'As an example of API cloud deployment, I once deployed a ML solution to automate
    the pricing of an electric vehicle charging station for a customer-facing web
    app. You can have a look at this project here if you want to know more about it:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个API云部署的例子，我曾经为一个面向客户的网页应用部署了一个机器学习解决方案，用来自动化电动汽车充电站的定价。如果你想了解更多，可以在这里查看这个项目：
- en: '[](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)
    [## How Renault Leveraged Machine Learning to Scale Electric Vehicle Sales'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何利用机器学习助力雷诺提升电动汽车销售](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)'
- en: How I built and deployed a machine learning-based solution in a few months that
    allowed Renault to scale the sale of…
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我如何在几个月内构建并部署一个基于机器学习的解决方案，帮助雷诺扩大电动汽车的销售……
- en: pub.towardsai.net](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[pub.towardsai.net](https://pub.towardsai.net/how-renault-leveraged-machine-learning-to-scale-electric-vehicles-sales-4f42bee34a12?source=post_page-----7b62d9db9b20--------------------------------)'
- en: Even if this post does not get into the code, it can give you a good idea of
    what can be done with API deployment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这篇文章没有涉及代码，它也能让你对API部署能做些什么有一个很好的了解。
- en: 'API deployment is very popular for its simplicity to integrate to any project.
    But some projects may need even more flexibility and less maintenance cost: this
    is where serverless deployment may be a solution.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: API部署因其易于集成到任何项目中而非常流行。但有些项目可能需要更多的灵活性和更低的维护成本：这时无服务器部署可能是一种解决方案。
- en: Serverless Deployment
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无服务器部署
- en: Another popular, but probably less frequently used option is serverless deployment.
    Serverless computing means that **you run your model** (or any code actually)
    **without owning nor provisioning any server**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个受欢迎但可能使用较少的选项是无服务器部署。无服务器计算意味着**你运行你的模型**（或者实际上是任何代码）**无需拥有或配置任何服务器**。
- en: 'Serverless deployment offers several significant advantages and is quite easy
    to set up:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器部署提供了几个显著的优势，并且非常容易设置：
- en: No need to manage nor to maintain servers
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需管理或维护服务器。
- en: No need to handle scaling in case of higher traffic
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不需要处理高流量情况下的扩展问题。
- en: 'You only pay for what you use: no traffic means virtually no cost, so no overhead
    cost at all'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你只需为使用的部分付费：没有流量意味着几乎没有成本，因此没有任何开销。
- en: 'But it has some limitations as well:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 但它也有一些局限性：
- en: It is usually not cost effective for large number of queries compared to managed
    APIs
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与托管API相比，它通常不适用于大量查询时的成本效益。
- en: Cold start latency is a potential issue, as a server might need to be spawned,
    leading to delays
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冷启动延迟是一个潜在问题，因为服务器可能需要启动，从而导致延迟。
- en: 'The memory footprint is usually limited by design: you can’t always run large
    models'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存占用通常是按设计限制的：你不能总是运行大型模型。
- en: 'The execution time is limited too: it’s not possible to run jobs for more than
    a few minutes (15 minutes for AWS Lambda for example)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行时间也有限：不可能运行超过几分钟的任务（例如AWS Lambda限制为15分钟）。
- en: In a nutshell, I would say that serverless deployment is a **good option when
    you’re launching something new, don’t expect large traffic and don’t want to spend
    much on infra management**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我认为无服务器部署是一个**在你启动新项目时，流量不大且不想在基础设施管理上花费太多的好选择**。
- en: 'Serverless computing is proposed by all major cloud providers under different
    names: [AWS Lambda](https://aws.amazon.com/lambda/), [Azure Functions](https://azure.microsoft.com/en-us/products/functions/)
    and [Google Cloud Functions](https://cloud.google.com/functions) for the most
    popular ones.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 所有主要的云提供商都以不同的名称提供无服务器计算：最受欢迎的有[AWS Lambda](https://aws.amazon.com/lambda/)、[Azure
    Functions](https://azure.microsoft.com/en-us/products/functions/)和[Google Cloud
    Functions](https://cloud.google.com/functions)。
- en: I personally have never deployed a serverless solution (working mostly with
    deep learning, I usually found myself limited by the serverless constraints mentioned
    above), but there is lots of documentation about how to do it properly, such as
    [this one from AWS](https://aws.amazon.com/blogs/compute/deploying-machine-learning-models-with-serverless-templates/).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 就我个人而言，我从未部署过无服务器解决方案（由于我主要从事深度学习工作，通常会受到上述无服务器限制的制约），但有很多文档可以帮助你正确地进行部署，例如[AWS的这篇文章](https://aws.amazon.com/blogs/compute/deploying-machine-learning-models-with-serverless-templates/)。
- en: While serverless deployment offers a flexible, on-demand solution, some applications
    may require a more scheduled approach, like batch processing.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然无服务器部署提供了一种灵活的按需解决方案，但某些应用可能需要更有计划的方法，比如批处理。
- en: Batch Processing
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批处理
- en: Another way to deploy on the cloud is through scheduled batch processing. While
    serverless and APIs are mostly used for live predictions, in some cases batch
    predictions makes more sense.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种在云上部署的方式是通过定时批处理。虽然无服务器架构和API通常用于实时预测，但在某些情况下，批量预测更有意义。
- en: 'Whether it be database updates, dashboard updates, caching predictions… as
    soon as there is **no need to have a real-time prediction, batch processing is
    usually the best option**:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是数据库更新、仪表盘更新、缓存预测……只要**没有实时预测的需求，批处理通常是最好的选择**：
- en: Processing large batches of data is more resource-efficient and reduce overhead
    compared to live processing
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大批量数据比实时处理更具资源效率，且能够减少开销。
- en: Processing can be scheduled during off-peak hours, allowing to reduce the overall
    charge and thus the cost
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理可以安排在非高峰时段进行，从而减少总体负载，进而降低成本。
- en: 'Of course, it comes with associated drawbacks:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这也有其相关的缺点：
- en: Batch processing creates a spike in resource usage, which can lead to system
    overload if not properly planned
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批处理会导致资源使用激增，如果没有适当的规划，可能会导致系统超载。
- en: Handling errors is critical in batch processing, as you need to process a full
    batch gracefully at once
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误处理在批处理过程中至关重要，因为你需要一次性优雅地处理整个批次。
- en: '**Batch processing should be considered for any task that does not required
    real-time results**: it is usually more cost effective. But of course, for any
    real-time application, it is not a viable option.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于任何不需要实时结果的任务，都应该考虑批处理**：通常它更加具有成本效益。但当然，对于任何实时应用，它并不是一个可行的选择。'
- en: 'It is used widely in many companies, mostly within ETL (Extract, Transform,
    Load) pipelines that may or may not contain ML. Some of the most popular tools
    are:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 它在许多公司中得到了广泛应用，主要是在ETL（提取、转换、加载）管道中，这些管道可能包含机器学习，也可能不包含。以下是一些最流行的工具：
- en: Apache Airflow for workflow orchestration and task scheduling
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Airflow，用于工作流编排和任务调度
- en: Apache Spark for fast, massive data processing
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Spark，用于快速、大规模数据处理
- en: 'As an example of batch processing, I used to work on a YouTube video revenue
    forecasting. Based on the first data points of the video revenue, we would forecast
    the revenue over up to 5 years, using a multi-target regression and curve fitting:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作为批处理的一个例子，我曾经从事YouTube视频收入预测的工作。根据视频收入的初始数据点，我们会预测未来最多5年的收入，使用多目标回归和曲线拟合：
- en: '![](../Images/5e891c0b723fb52a7b5e9269012dfedd.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e891c0b723fb52a7b5e9269012dfedd.png)'
- en: Plot representing the initial data, multi-target regression predictions and
    curve fitting. Image by author.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表示初始数据、多目标回归预测和曲线拟合的图表。图像来源：作者。
- en: 'For this project, we had to re-forecast on a monthly basis all our data to
    ensure there was no drifting between our initial forecasting and the most recent
    ones. For that, we used a managed Airflow, so that every month it would automatically
    trigger a new forecasting based on the most recent data, and store those into
    our databases. If you want to know more about this project, you can have a look
    at this article:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我们需要每月重新进行所有数据的重新预测，以确保我们的初始预测与最新预测之间没有偏差。为此，我们使用了托管的Airflow，每月会自动根据最新的数据触发新的预测，并将这些数据存储到我们的数据库中。如果你想了解更多关于这个项目的信息，可以查看这篇文章：
- en: '[](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)
    [## How to Forecast YouTube Video Revenue'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 如何预测YouTube视频收入](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)'
- en: This method achieved an error rate of less than 6% in revenue forecasting over
    a portfolio of dozens of YouTubers
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 该方法在对数十个YouTuber的收入预测中取得了低于6%的错误率
- en: medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/how-to-forecast-youtube-video-revenue-e35c60bd1105?source=post_page-----7b62d9db9b20--------------------------------)'
- en: After exploring the various strategies and tools available for cloud deployment,
    it’s clear that this approach offers significant flexibility and scalability.
    However, cloud deployment is not always the best fit for every ML application,
    particularly when real-time processing, privacy concerns, or financial resource
    constraints come into play.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了用于云部署的各种策略和工具后，显然这种方法提供了显著的灵活性和可扩展性。然而，云部署并不总是每个机器学习应用的最佳选择，特别是当实时处理、隐私问题或财务资源限制成为因素时。
- en: '![](../Images/578ee44791128a7decddea53afe8da55.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/578ee44791128a7decddea53afe8da55.png)'
- en: A list of pros and cons for cloud deployment. Image by author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 云部署的优缺点列表。图片由作者提供。
- en: This is where edge deployment comes into focus as a viable option. Let’s now
    delve into edge deployment to understand when it might be the best option.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是边缘部署作为一种可行选项的焦点所在。让我们现在深入了解边缘部署，看看什么时候它可能是最佳选择。
- en: Edge Deployment
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘部署
- en: From my own experience, edge deployment is rarely considered as the main way
    of deployment. A few years ago, even I thought it was not really an interesting
    option for deployment. With more perspective and experience now, I think **it
    must be considered as the first option** for deployment anytime you can.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我自己的经验，边缘部署很少被视为主要的部署方式。几年前，连我自己也认为它并不是一个真正有趣的部署选项。但现在通过更多的视角和经验，我认为**它必须在任何可以的情况下作为首选部署方式**。
- en: 'Just like cloud deployment, edge deployment covers a wide range of cases:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 就像云部署一样，边缘部署涵盖了广泛的应用场景：
- en: Native phone applications
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原生手机应用
- en: Web applications
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络应用
- en: Edge server and specific devices
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘服务器和特定设备
- en: While they all share some similar properties, such as limited resources and
    horizontal scaling limitations, each deployment choice may have their own characteristics.
    Let’s have a look.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它们都具有一些相似的特性，例如资源有限和水平扩展的限制，但每种部署选择可能都有其独特的特点。让我们来看看。
- en: Native Application
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原生应用
- en: 'We see more and more smartphone apps with integrated AI nowadays, and it will
    probably keep growing even more in the future. While some Big Tech companies such
    as OpenAI or Google have chosen the API deployment approach for their LLMs, Apple
    is currently working on the iOS app deployment model with solutions such as [OpenELM](https://machinelearning.apple.com/research/openelm),
    a tini LLM. Indeed, this option has several advantages:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在看到越来越多的智能手机应用集成了AI，未来这种趋势可能会进一步增长。虽然一些大科技公司如OpenAI或谷歌为他们的大型语言模型（LLM）选择了API部署方式，但苹果目前正在通过像[OpenELM](https://machinelearning.apple.com/research/openelm)这样的解决方案，专注于iOS应用部署模型，这是一种小型LLM。实际上，这种方式有几个优点：
- en: 'The infra cost if virtually zero: no cloud to maintain, it all runs on the
    device'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施成本几乎为零：无需维护云端，一切都在设备上运行
- en: 'Better privacy: you don’t have to send any data to an API, it can all run locally'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的隐私：你不需要将任何数据发送到API，所有计算都可以在本地完成
- en: Your model is directly integrated to your app, no need to maintain several codebases
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的模型直接集成到你的应用中，无需维护多个代码库
- en: '*Moreover, Apple has built a fantastic ecosystem for model deployment in iOS:
    you can run very efficiently ML models with Core ML on their Apple chips (M1,
    M2, etc…) and take advantage of the neural engine for really fast inferences.
    To my knowledge, Android is slightly lagging behind, but also has a great ecosystem.*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*此外，苹果为iOS上的模型部署打造了一个极好的生态系统：你可以在他们的Apple芯片（如M1、M2等）上高效运行机器学习模型，并利用神经引擎进行非常快速的推理。据我所知，安卓略微落后，但也有一个出色的生态系统。*'
- en: 'While this can be a really beneficial approach in many cases, there are still
    some limitations:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在许多情况下这可能是一个非常有益的方法，但仍然存在一些限制：
- en: Phone resources limit model size and performance, and are shared with other
    apps
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手机资源限制了模型的大小和性能，并且这些资源与其他应用共享
- en: Heavy models may drain the battery pretty fast, which can be deceptive for the
    user experience overall
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重型模型可能会很快消耗电池，这可能会对用户体验产生误导性影响
- en: Device fragmentation, as well as iOS and Android apps make it hard to cover
    the whole market
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备碎片化，以及iOS和Android应用使得覆盖整个市场变得困难
- en: Decentralized model updates can be challenging compared to cloud
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与云部署相比，去中心化的模型更新可能会更加具有挑战性
- en: Despite its drawbacks, native app deployment is often a strong choice for ML
    solutions that run in an app. It **may seem more complex during the development
    phase**, but it will turn out to be **much cheaper** as soon as it’s deployed
    compared to a cloud deployment.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在一些缺点，但原生应用部署通常是针对在应用中运行的机器学习解决方案的一个强有力的选择。**在开发阶段看起来可能更复杂**，但一旦部署，相比云部署，它将**便宜得多**。
- en: 'When it comes to the tech stack, there are actually two main ways to deploy:
    iOS and Android. They both have their own stacks, but they share the same properties:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术栈方面，实际上有两种主要的部署方式：iOS和Android。它们各自有自己的栈，但共享相同的属性：
- en: 'App development: Swift for iOS, Kotlin for Android'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用开发：iOS使用Swift，Android使用Kotlin
- en: 'Model format: Core ML for iOS, TensorFlow Lite for Android'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型格式：iOS使用Core ML，Android使用TensorFlow Lite
- en: 'Hardware accelerator: Apple Neural Engine for iOS, Neural Network API for Android'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件加速器：iOS的Apple Neural Engine，Android的Neural Network API
- en: '*Note: This is a mere simplification of the tech stack. This non-exhaustive
    overview only aims to cover the essentials and let you dig in from there if interested.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：这只是对技术栈的简化描述。这个不完全的概述旨在覆盖要点，并让你如果有兴趣，可以进一步深入了解。*'
- en: As a personal example of such deployment, I once worked on a book reading app
    for Android, in which they wanted to let the user navigate through the book with
    phone movements. For example, shake left to go to the previous page, shake right
    for the next page, and a few more movements for specific commands. For that, I
    trained a model on accelerometer’s features from the phone for movement recognition
    with a rather small model. It was then deployed directly in the app as a TensorFlow
    Lite model.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这种部署的个人例子，我曾经参与过一个Android平台的图书阅读应用，在这个应用中，他们希望让用户通过手机的运动来浏览书籍。例如，左摇动手机翻到上一页，右摇动翻到下一页，其他特定的动作执行特定的命令。为此，我训练了一个模型，使用手机加速度计的特征来识别运动，并且使用了一个相对较小的模型。然后，这个模型直接作为TensorFlow
    Lite模型部署到应用中。
- en: Native application has strong advantages but is limited to one type of device,
    and would not work on laptops for example. A web application could overcome those
    limitations.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 原生应用具有强大的优势，但仅限于一种类型的设备，例如在笔记本电脑上无法运行。Web应用可以克服这些局限。
- en: Web Application
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Web应用
- en: 'Web application deployment means running the model on the client side. Basically,
    it means **running the model inference on the device** used by that browser, whether
    it be a tablet, a smartphone or a laptop (and the list goes on…). This kind of
    deployment can be really convenient:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Web应用部署意味着在客户端运行模型。基本上，它意味着**在浏览器使用的设备上运行模型推理**，无论是平板电脑、智能手机还是笔记本电脑（等等）。这种部署方式非常方便：
- en: Your deployment is working on any device that can run a web browser
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的部署可以在任何能够运行Web浏览器的设备上工作
- en: 'The inference cost is virtually zero: no server, no infra to maintain… Just
    the customer’s device'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理成本几乎为零：无需服务器，无需维护基础设施……只需要客户的设备
- en: 'Only one codebase for all possible devices: no need to maintain an iOS app
    and an Android app simultaneously'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有设备只需一个代码库：无需同时维护iOS应用和Android应用
- en: '*Note: Running the model on the server side would be equivalent to one of the
    cloud deployment options above.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：在服务器端运行模型将等同于上面提到的云部署选项之一。*'
- en: 'While web deployment offers appealing benefits, it also has significant limitations:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Web部署提供了诱人的好处，但它也有显著的局限性：
- en: Proper resource utilization, especially GPU inference, can be challenging with
    TensorFlow.js
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow.js时，合理利用资源，尤其是GPU推理，可能会面临挑战
- en: 'Your web app must work with all devices and browsers: whether is has a GPU
    or not, Safari or Chrome, a Apple M1 chip or not, etc… This can be a heavy burden
    with a high maintenance cost'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的Web应用必须能够在所有设备和浏览器上运行：无论是否有GPU，使用Safari还是Chrome，是否有Apple M1芯片等等……这可能是一个很重的负担，且维护成本较高
- en: 'You may need a backup plan for slower and older devices: what if the device
    can’t handle your model because it’s too slow?'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可能需要为较慢和较老的设备准备一个备份方案：如果设备太慢而无法处理你的模型怎么办？
- en: '*Unlike for a native app, there is no official size limitation for a model.
    However, a small model will be downloaded faster, making it overall experience
    smoother and must be a priority. And a very large model may just not work at all
    anyway.*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*与原生应用不同，模型没有官方的大小限制。然而，较小的模型下载速度更快，整体体验也更加流畅，因此应该优先考虑。而且一个非常大的模型可能根本无法正常工作。*'
- en: 'In summary, while web deployment is powerful, it comes with significant limitations
    and must be used cautiously. One more advantage is that it might be a door to
    another kind of deployment that I did not mention: WeChat Mini Programs.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，虽然网页部署功能强大，但它有显著的局限性，必须谨慎使用。另一个优点是，它可能是我未提及的另一种部署方式的入口：微信小程序。
- en: 'The tech stack is usually the same as for web development: HTML, CSS, JavaScript
    (and any frameworks you want), and of course TensorFlow Lite for model deployment.
    If you’re curious about an example of how to deploy ML in the browser, you can
    have a look at this post where I run a real time face recognition model in the
    browser from scratch:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 技术栈通常与网页开发相同：HTML、CSS、JavaScript（以及你想要的任何框架），当然还有用于模型部署的TensorFlow Lite。如果你对如何在浏览器中部署机器学习感兴趣，可以看看这篇文章，我从零开始在浏览器中运行了一个实时人脸识别模型：
- en: '[](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------)
    [## BlazeFace: How to Run Real-time Object Detection in the Browser'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------)
    [## BlazeFace：如何在浏览器中运行实时物体检测'
- en: A step-by-step guide to training a BlazeFace model, from the Python training
    pipeline to the JavaScript demo through…
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BlazeFace模型训练的逐步指南，从Python训练管道到JavaScript演示，详细介绍了整个过程……
- en: towardsdatascience.com](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/blazeface-how-to-run-real-time-object-detection-in-the-browser-66c2ac9acd75?source=post_page-----7b62d9db9b20--------------------------------)'
- en: This article goes from a model training in PyTorch to up to a working web app
    and might be informative about this specific kind of deployment.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本文从PyTorch中的模型训练讲起，最终实现了一个可工作的网页应用，可能对这种特定类型的部署有所启发。
- en: 'In some cases, native and web apps are not a viable option: we may have no
    such device, no connectivity, or some other constraints. This is where edge servers
    and specific devices come into play.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，原生应用和网页应用都不是可行的选择：我们可能没有合适的设备，无法联网，或者受到其他限制。这时，边缘服务器和特定设备就派上了用场。
- en: Edge Servers and Specific Devices
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘服务器和特定设备
- en: 'Besides native and web apps, edge deployment also includes other cases:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 除了原生应用和网页应用，边缘部署还包括其他情况：
- en: 'Deployment on edge servers: in some cases, there are local servers running
    models, such as in some factory production lines, CCTVs, etc…Mostly because of
    privacy requirements, this solution is sometimes the only available'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘服务器上的部署：在某些情况下，会有本地服务器运行模型，例如某些工厂生产线、CCTV等…由于隐私要求，这种解决方案有时是唯一可用的。
- en: 'Deployment on specific device: either a sensor, a microcontroller, a smartwatch,
    earplugs, autonomous vehicle, etc… may run ML models internally'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定设备上的部署：无论是传感器、微控制器、智能手表、耳塞、自动驾驶汽车等，都可能内部运行机器学习模型。
- en: Deployment on edge servers can be really close to a deployment on cloud with
    API, and the tech stack may be quite close.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘服务器上的部署可以与云端API部署非常接近，技术栈也可能非常相似。
- en: '*Note: It is also possible to run batch processing on an edge server, as well
    as just having a monolithic script that does it all.*'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*备注：也可以在边缘服务器上运行批处理，或者使用一个单一的脚本来完成所有任务。*'
- en: But deployment on specific devices may involve using [FPGA](https://en.wikipedia.org/wiki/Field-programmable_gate_array)s
    or low-level languages. This is another, very different skillset, that may differ
    for each type of device. It is sometimes referred to as TinyML and is a very interesting,
    growing topic.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 但在特定设备上的部署可能涉及使用[FPGA](https://en.wikipedia.org/wiki/Field-programmable_gate_array)或低级语言。这是另一种完全不同的技能集，针对每种设备类型可能有所不同。这个领域有时被称为TinyML，是一个非常有趣且不断发展的话题。
- en: 'On both cases, they share some challenges with other edge deployment methods:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，它们面临与其他边缘部署方法相同的一些挑战：
- en: Resources are limited, and horizontal scaling is usually not an option
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源有限，通常无法进行横向扩展。
- en: The battery may be a limitation, as well as the model size and memory footprint
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电池可能是一个限制因素，模型大小和内存占用也是如此。
- en: Even with these limitations and challenges, in some cases it’s the only viable
    solution, or the most cost effective one.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有这些限制和挑战，在某些情况下，它仍然是唯一可行的解决方案，或者是最具成本效益的方案。
- en: An example of an edge server deployment I did was for a company that wanted
    to automatically check whether the orders were valid in fast food restaurants.
    A camera with a top down view would look at the plateau, compare what is sees
    on it (with computer vision and object detection) with the actual order and raise
    an alert in case of mismatch. For some reason, the company wanted to make that
    on edge servers, that were within the fast food restaurant.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾为一家公司做过一个边缘服务器部署示例，该公司希望自动检查快餐店订单的有效性。一个俯视的摄像头会观察平台，使用计算机视觉和物体检测技术将摄像头看到的内容与实际订单进行对比，在发现不匹配时发出警报。由于某些原因，该公司希望将此系统部署在快餐店内部的边缘服务器上。
- en: 'To recap, here is a big picture of what are the main types of deployment and
    their pros and cons:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是主要的部署类型及其优缺点：
- en: '![](../Images/03465e3c6a42058a4aafcc2c9d2269fc.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03465e3c6a42058a4aafcc2c9d2269fc.png)'
- en: A list of pros and cons for cloud deployment. Image by author.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 云部署的优缺点列表。图片来自作者。
- en: With that in mind, **how to actually choose the right deployment method?** There’s
    no single answer to that question, but let’s try to give some rules in the next
    section to make it easier.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，**如何实际选择合适的部署方式？**这个问题没有单一的答案，但让我们尝试在下一节给出一些规则，以便简化选择过程。
- en: How to Choose the Right Deployment
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何选择合适的部署方式
- en: Before jumping to the conclusion, let’s make a decision tree to help you choose
    the solution that fits your needs.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在得出结论之前，让我们制作一个决策树，帮助你选择最适合的解决方案。
- en: 'Choosing the right deployment requires understanding specific needs and constraints,
    often through discussions with stakeholders. Remember that each case is specific
    and might be a edge case. But in the diagram below I tried to outline the most
    common cases to help you out:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的部署方式需要理解具体的需求和限制，通常需要与利益相关者进行讨论。记住，每个案例都是特定的，可能是一个边缘案例。但在下面的图表中，我试图概括出最常见的情况，帮助你做出决策：
- en: '![](../Images/6f7ccb5214d4bfecc3380b38a08cf0ea.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f7ccb5214d4bfecc3380b38a08cf0ea.png)'
- en: Deployment decision diagram. Note that each use case is specific. Image by author.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 部署决策图。请注意，每个使用场景都是特定的。图片来自作者。
- en: 'This diagram, while being quite simplistic, can be reduced to a few questions
    that would allow you go in the right direction:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表虽然相当简化，但可以归结为几个问题，帮助你走向正确的方向：
- en: Do you need real-time? If no, look for batch processing first; if yes, think
    about edge deployment
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要实时处理吗？如果不需要，首先考虑批处理；如果需要，请考虑边缘部署
- en: Is your solution running on a phone or in the web? Explore these deployments
    method whenever possible
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的解决方案是运行在手机上还是在网页上？在可能的情况下，探索这些部署方式
- en: Is the processing quite complex and heavy? If yes, consider cloud deployment
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理过程是否相当复杂且繁重？如果是，请考虑云部署
- en: 'Again, that’s quite simplistic but helpful in many cases. Also, note that a
    few questions were omitted for clarity but are actually more than important in
    some context: Do you have privacy constraints? Do you have connectivity constraints?
    What is the skillset of your team?'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这虽然很简单，但在许多情况下非常有帮助。同时，请注意，为了清晰起见，省略了一些问题，但在某些情况下，它们实际上非常重要：你有隐私限制吗？你有连接性限制吗？你团队的技能如何？
- en: Other questions may arise depending on the use case; with experience and knowledge
    of your ecosystem, they will come more and more naturally. But hopefully this
    may help you navigate more easily in deployment of ML models.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 根据使用场景，可能还会出现其他问题；随着经验的积累和对你生态系统的了解，这些问题会变得越来越自然。但希望这些内容能帮助你更轻松地进行机器学习模型的部署。
- en: Conclusion and Final Thoughts
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论和最终思考
- en: 'While cloud deployment is often the default for ML models, edge deployment
    can offer significant advantages: cost-effectiveness and better privacy control.
    Despite challenges such as processing power, memory, and energy constraints, I
    believe edge deployment is a compelling option for many cases. Ultimately, the
    best deployment strategy aligns with your business goals, resource constraints
    and specific needs.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管云部署通常是机器学习模型的默认选择，但边缘部署可以提供显著的优势：成本效益和更好的隐私控制。尽管处理能力、内存和能源约束等挑战存在，但我相信边缘部署在许多情况下都是一个值得考虑的选项。最终，最佳的部署策略应该与您的业务目标、资源限制和具体需求相契合。
- en: If you’ve made it this far, I’d love to hear your thoughts on the deployment
    approaches you used for your projects.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你读到这里，我很想听听你在项目中使用过的部署方法的看法。
