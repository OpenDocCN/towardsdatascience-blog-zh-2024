- en: What’s The Story With HNSW?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HNSW的故事是什么？
- en: 原文：[https://towardsdatascience.com/whats-the-story-with-hnsw-d1402c37a44e?source=collection_archive---------0-----------------------#2024-02-25](https://towardsdatascience.com/whats-the-story-with-hnsw-d1402c37a44e?source=collection_archive---------0-----------------------#2024-02-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/whats-the-story-with-hnsw-d1402c37a44e?source=collection_archive---------0-----------------------#2024-02-25](https://towardsdatascience.com/whats-the-story-with-hnsw-d1402c37a44e?source=collection_archive---------0-----------------------#2024-02-25)
- en: Exploring the path to fast nearest neighbour search with Hierarchical Navigable
    Small Worlds
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索使用层次化可导航小世界（HNSW）进行快速最近邻搜索的路径
- en: '[](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)[![Ryan
    McDermott](../Images/90b50c1ae0cbfb0f636543488955d1da.png)](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)
    [Ryan McDermott](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)[![Ryan
    McDermott](../Images/90b50c1ae0cbfb0f636543488955d1da.png)](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)[![数据科学之路](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)
    [Ryan McDermott](https://medium.com/@ryan.mcdermott.000?source=post_page---byline--d1402c37a44e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)
    ·13 min read·Feb 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学之路](https://towardsdatascience.com/?source=post_page---byline--d1402c37a44e--------------------------------)·阅读时间13分钟·2024年2月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d307bf1a8ec4a248af507dda79584af2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d307bf1a8ec4a248af507dda79584af2.png)'
- en: Image created by DALL·E 2 with the prompt “A bright abstract expressionist painting
    of a layered network of dots connected by lines.”
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由DALL·E 2创作的图像，提示词为“由点和线条连接的层次网络的明亮抽象表现主义画作”。
- en: Hierarchical Navigable Small World (HNSW) has become popular as one of the best
    performing approaches for approximate nearest neighbour search. HNSW is a little
    complex though, and descriptions often lack a complete and intuitive explanation.
    This post takes a journey through the history of the HNSW idea to help explain
    what “hierarchical navigable small world” actually means and why it’s effective.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 层次化可导航小世界（HNSW）已经成为近似最近邻搜索中最具性能的算法之一。不过，HNSW略显复杂，且相关描述通常缺乏完整且直观的解释。本文将带您走过HNSW概念的历史，帮助解释“层次化可导航小世界”到底意味着什么，以及它为何如此有效。
- en: Contents
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: Approximate Nearest Neighbour Search
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近似最近邻搜索
- en: Small Worlds
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小世界
- en: Navigable Small Worlds
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可导航小世界
- en: Hierarchical Navigable Small Worlds
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次化可导航小世界
- en: Summary
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结
- en: Appendix
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附录
- en: '- Improved search'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 改进的搜索'
- en: '- HNSW search & insertion'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- HNSW搜索与插入'
- en: '- Improved insertion'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 改进的插入'
- en: References
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文献
- en: Approximate Nearest Neighbour Search
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近似最近邻搜索
- en: A common application of machine learning is *nearest neighbour search*, which
    means finding the most similar items* to a target — for example, to recommend
    items that are similar to a user’s preferences, or to search for items that are
    similar to a user’s search query.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的一个常见应用是*最近邻搜索*，即找到与目标最相似的项*——例如，推荐与用户偏好相似的项，或者搜索与用户查询相似的项。
- en: The simple method is to calculate the similarity of every item to the target
    and return the closest ones. However, if there are a large number of items (maybe
    millions), this will be slow.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 简单方法是计算每个项与目标的相似度，并返回最接近的项。然而，如果项的数量非常庞大（可能有百万个），这一方法将会很慢。
- en: Instead, we can use a structure called an *index* to make things much faster.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 取而代之的是，我们可以使用一种叫做*索引*的结构来大大加速查找过程。
- en: 'There is a trade-off, however. Unlike the simple method, indexes only give
    approximate results: we may not retrieve all of the nearest neighbours (i.e. recall
    may be less than 100%).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这里存在一个权衡。与简单方法不同，索引只给出近似结果：我们可能无法检索到所有的最近邻（即召回率可能低于100%）。
- en: There are several different types of index (e.g. locality sensitive hashing;
    inverted file index), but HNSW has proven particularly effective on various datasets,
    achieving high speeds while keeping high recall.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种不同类型的索引（例如局部敏感哈希；倒排文件索引），但HNSW在各种数据集上表现特别有效，能够在保持高召回率的同时实现高速。
- en: '**Typically, items are represented as* [embeddings](https://www.pinecone.io/learn/vector-embeddings/)*,
    which are vectors produced by a machine learning model; the similarity between
    items corresponds to the* distance *between the embeddings. This post will usually
    talk of vectors and distances, though in general HNSW can handle any kind of items
    with some measure of similarity.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**通常，项目被表示为* [嵌入](https://www.pinecone.io/learn/vector-embeddings/)*，这些嵌入是由机器学习模型生成的向量；项目之间的相似性对应于嵌入之间的*距离*。这篇文章通常会讨论向量和距离，尽管一般来说，HNSW可以处理任何类型的项目，只要它们具有某种相似度度量。*'
- en: Small Worlds
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小世界
- en: '![](../Images/28b5f840ff812ef970754df771ce985f.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28b5f840ff812ef970754df771ce985f.png)'
- en: '*Illustration of the small-world experiment.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*小世界实验的示意图。*'
- en: Small worlds were famously studied in Stanley Milgram’s small-world experiment
    [[1]](https://snap.stanford.edu/class/cs224w-readings/travers69smallworld.pdf).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 小世界现象在斯坦利·米尔格伦（Stanley Milgram）的“小世界实验”中得到了著名的研究[[1]](https://snap.stanford.edu/class/cs224w-readings/travers69smallworld.pdf)。
- en: Participants were given a letter containing the address and other basic details
    of a randomly chosen target individual, along with the experiment’s instructions.
    In the unlikely event that they personally knew the target, they were instructed
    to send them the letter; otherwise, they were told to think of someone they knew
    who was more likely to know the target, and send the letter on to them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者收到一封信，信中包含一个随机选择的目标个体的地址及其他基本信息，以及实验的说明。如果他们不太可能个人认识目标，他们被指示将信转交给更可能认识目标的人。
- en: The surprising conclusion was that the letters were typically only sent around
    six times before reaching the target, demonstrating the famous idea of “six degrees
    of separation” — any two people can usually be connected by a small chain of friends.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的结论是，信件通常只被转发约六次便能到达目标，证明了著名的“六度分隔”理论——任何两个人通常可以通过一小链条的朋友相互连接。
- en: In the mathematical field of graph theory, a [graph](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics))
    is a set of points, some of which are connected. We can think of a social network
    as a graph, with people as points and friendships as connections. The small-world
    experiment found that most pairs of points in this graph are connected by short
    paths that have a small number of steps. (This is described technically as the
    graph having a low *diameter*.)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在图论的数学领域，[图](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics))是一组点，其中一些点是相互连接的。我们可以将社交网络看作是一个图，其中人们是点，友谊是连接。小世界实验发现，这个图中的大多数点对是通过短路径连接的，路径上的步骤很少。（从技术上讲，这是指图的*直径*很小。）
- en: '![](../Images/d9564c64321a802d7ff200d5f4e5c06f.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9564c64321a802d7ff200d5f4e5c06f.png)'
- en: '*Illustration of a small world. Most connections (grey) are local, but there
    are also long-range connections (green), which create short paths between points,
    such as the three step path between points A and B indicated with arrows.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*小世界的示意图。大多数连接（灰色）是局部的，但也有长程连接（绿色），这些长程连接在各个点之间创建了短路径，例如指示箭头的A和B之间的三步路径。*'
- en: 'Having short paths is not that surprising in itself: most graphs have this
    property, including graphs created by just connecting random pairs of points.
    But social networks are not connected randomly, they are highly *local*: friends
    tend to live close to each other, and if you know two people, it’s quite likely
    they know each other too. (This is described technically as the graph having a
    high *clustering coefficient*.) The surprising thing about the small-world experiment
    is that two distant points are only separated by a short path despite connections
    typically being short-range.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有短路径本身并不那么令人惊讶：大多数图都有这一特性，包括通过随机连接点对所创建的图。但社交网络并非随机连接，它们是高度*局部化*的：朋友通常住得很近，而且如果你认识两个人，他们很可能也彼此认识。（从技术上讲，这是指图具有高*聚类系数*。）小世界实验令人惊讶的地方在于，尽管连接通常是短程的，但两个遥远的点之间竟然只通过一条短路径相隔。
- en: In cases like these when a graph has lots of local connections, but also has
    short paths, we say the graph is a **small world**.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在像这样的情况下，当一个图有许多局部连接，但也有短路径时，我们称这个图为**小世界**。
- en: Another good example of a small world is the global airport network. Airports
    in the same region are highly connected to one another, but it’s possible to make
    a long journey in only a few stops by making use of major hub airports. For example,
    a journey from Manchester, UK to Osaka, Japan typically starts with a local flight
    from Manchester to London, then a long distance flight from London to Tokyo, and
    finally another local flight from Tokyo to Osaka. Long-range hubs are a common
    way of achieving the small world property.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个很好的小世界例子是全球机场网络。同一地区的机场之间高度互联，但通过利用主要枢纽机场，通常可以在几个停靠点之间完成长途旅行。例如，从英国曼彻斯特到日本大阪的旅行通常从曼彻斯特到伦敦的短途航班开始，然后是从伦敦到东京的长途航班，最后是从东京到大阪的另一个短途航班。长程枢纽是实现小世界特性的常见方式。
- en: A final interesting example of graphs with the small world property is biological
    neural networks such as the human brain.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个具有小世界特性的图的有趣例子是生物神经网络，比如人脑。
- en: '*Navigable* Small Worlds'
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*可导航的小世界*'
- en: 'In small world graphs, we can quickly reach a target in a few steps. This suggests
    a promising idea for nearest neighbour search: perhaps if we create connections
    between our vectors in such a way that it forms a small world graph, we can quickly
    find the vectors near a target by starting from an arbitrary “entry point” vector
    and then navigating through the graph towards the target.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在小世界图中，我们可以在几步之内快速到达目标。这为最近邻搜索提供了一个有前景的想法：也许如果我们以某种方式在向量之间创建连接，使其形成一个小世界图，我们可以通过从任意“入口点”向量开始，然后通过图进行导航快速找到靠近目标的向量。
- en: 'This possibility was explored by Kleinberg [[2](https://www.stat.berkeley.edu/users/aldous/Networks/swn-1.pdf)].
    He noted that the existence of short paths wasn’t the only interesting thing about
    Miller’s experiment: it was also surprising that people were able to *find* these
    short paths, without using any global knowledge about the graph. Rather, the people
    were following a simple [greedy algorithm](https://en.wikipedia.org/wiki/Greedy_algorithm).
    At each step, they examined each of their immediate connections, and sent it to
    the one they thought was closest to the target. We can use a similar algorithm
    to search a graph that connects vectors.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这一可能性由克莱因伯格探索过[[2](https://www.stat.berkeley.edu/users/aldous/Networks/swn-1.pdf)]。他指出，短路径的存在并不是米勒实验中唯一有趣的地方：更令人惊讶的是，人们能够*找到*这些短路径，而无需使用任何关于图的全局知识。相反，人们是遵循一种简单的[贪心算法](https://en.wikipedia.org/wiki/Greedy_algorithm)。在每一步中，他们检查每一个直接连接，并将信息发送到他们认为最接近目标的连接。我们可以使用类似的算法来搜索连接向量的图。
- en: '![](../Images/1bbc1f0218a57d4865c256ca4ad22f23.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bbc1f0218a57d4865c256ca4ad22f23.png)'
- en: '*Illustration of the greedy search algorithm. We are searching for the vector
    that is nearest the target X. Starting at the entry point E, we check the distance
    to X of each vector connected to E (indicated by the arrows from E), and go to
    the closest one (indicated by the red arrow from E). We repeat this procedure
    at successive vectors until we reach Y. As Y has no connections that are closer
    to X than Y itself, we stop and return Y.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*贪心搜索算法的示意图。我们正在寻找距离目标X最近的向量。从入口点E开始，我们检查与E相连的每个向量到X的距离（由从E出发的箭头表示），并前往最近的一个（由从E出发的红色箭头表示）。我们在后续的向量上重复这个过程，直到到达Y。由于Y没有比Y本身更接近X的连接，我们停止并返回Y。*'
- en: Kleinberg wanted to know whether this greedy algorithm would always find a short
    path. He ran simple simulations of small worlds in which all of the points were
    connected to their immediate neighbours, with additional longer connections created
    between random points. He discovered that the greedy algorithm would only find
    a short path in specific conditions, depending on the lengths of the long-range
    connections.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 克莱因伯格想知道这个贪心算法是否总能找到一条短路径。他进行了简单的小世界模拟，在这些模拟中，所有点都连接到它们的邻居，并且在随机点之间创建了额外的长连接。他发现，贪心算法只会在特定条件下找到短路径，这些条件取决于长程连接的长度。
- en: If the long-range connections were too long (as was the case when they connected
    pairs of points in completely random locations), the greedy algorithm could follow
    a long-range connection to quickly reach the rough area of the target, but after
    that the long-range connections were of no use, and the path had to step through
    the local connections to get closer. On the other hand, if the long-range connections
    were too short, it would simply take too many steps to reach the area of the target.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果长距离连接过长（例如当它们连接完全随机位置的点对时），贪心算法可能会通过长距离连接迅速到达目标的大致区域，但之后这些长距离连接就无用，路径必须通过局部连接来进一步靠近目标。另一方面，如果长距离连接过短，则需要太多步骤才能到达目标区域。
- en: If, however, the lengths of the long-range connections were just right (to be
    precise, if they were uniformly distributed, so that all lengths were equally
    likely), the greedy algorithm would typically reach the neighbourhood of the target
    in an especially small number of steps (to be more specific, a number proportional
    to *log(n)*, where *n* is the number of points in the graph).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果长距离连接的长度刚好合适（准确来说，如果它们是均匀分布的，所有长度的概率相等），则贪心算法通常可以在特别少的步骤中到达目标的邻域（更具体地说，这个步骤数与
    *log(n)* 成比例，其中 *n* 是图中的点数）。
- en: In cases like this where the greedy algorithm can find the target in a small
    number of steps, we say the small world is a **navigable** small world (NSW).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种贪心算法能够在少数步骤内找到目标的情况下，我们称这种小世界为 **可导航** 小世界（NSW）。
- en: 'An NSW sounds like an ideal index for our vectors, but for vectors in a complex,
    high-dimensional space, it’s not clear how to actually build one. Fortunately,
    Malkov et al. [[3](https://publications.hse.ru/mirror/pubs/share/folder/x5p6h7thif/direct/128296059)]
    discovered a method: we insert one randomly chosen vector at a time to the graph,
    and connect it to a small number *m* of nearest neighbours that were already inserted.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: NSW 听起来像是一个理想的向量索引，但对于高维复杂空间中的向量，如何实际构建一个 NSW 还不清楚。幸运的是，Malkov 等人 [[3](https://publications.hse.ru/mirror/pubs/share/folder/x5p6h7thif/direct/128296059)]
    发现了一种方法：我们每次随机选择一个向量插入图中，并将其连接到已插入的少数 *m* 个最近邻。
- en: '![](../Images/c9cab3b1ade02d4f2cef6f39970e4546.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9cab3b1ade02d4f2cef6f39970e4546.png)'
- en: '*Illustration of building an NSW. Vectors are inserted in a random order and
    connected to the nearest m = 2 inserted vectors. Note how the first vectors to
    be inserted form long-range connections while later vectors form local connections.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*构建 NSW 的示意图。向图中随机插入向量，并将其连接到最接近的 m = 2 个已插入向量。注意，最早插入的向量形成长距离连接，而后插入的向量形成局部连接。*'
- en: This method is remarkably simple and requires no global understanding of how
    the vectors are distributed in space. It’s also very efficient, as we can use
    the graph built so far to perform the nearest neighbour search for inserting each
    vector.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法非常简单，无需对向量在空间中的分布进行全局理解。它也非常高效，因为我们可以利用已构建的图来执行每个向量的最近邻搜索。
- en: Experiments confirmed that this method produces an NSW. Because the vectors
    inserted early on are randomly chosen, they tend to be quite far apart. They therefore
    form the long-range connections needed for a small world. It’s not so obvious
    why the small world is navigable, but as we insert more vectors, the connections
    will get gradually shorter, so it’s plausible that the distribution of connection
    lengths will be fairly even, as required.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实验确认这种方法能产生一个 NSW。由于最早插入的向量是随机选择的，它们通常相隔较远。因此，它们形成了小世界所需的长距离连接。虽然为什么小世界是可导航的并不那么显而易见，但随着我们插入更多向量，连接会逐渐变短，因此可以推测连接长度的分布会相当均匀，如所要求的那样。
- en: Hierarchical Navigable Small Worlds
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层次化可导航小世界
- en: Navigable small worlds can work well for approximate nearest neighbours search,
    but further analysis revealed areas for improvement, leading Markov et al. [[4](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)]
    to propose HNSW.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 可导航小世界在近似最近邻搜索中表现良好，但进一步的分析揭示了可以改进的地方，这促使 Markov 等人 [[4](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)]
    提出了 HNSW。
- en: 'A typical path through an NSW from the entry point towards the target went
    through two phases: a “zoom-out” phase, in which connection lengths increase from
    short to long, and a “zoom-in” phase, in which the reverse happens.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的 NSW 路径从入口点到目标分为两个阶段：“缩小”阶段，连接长度从短到长；以及“放大”阶段，连接长度发生相反的变化。
- en: The first simple improvement is to use a long-range hub (such as the first inserted
    vector) as the entry point. This way, we can skip the zoom-out phase and go straight
    to the zoom-in phase.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个简单的改进是使用一个长程中心节点（例如第一个插入的向量）作为入口点。这样，我们可以跳过缩小阶段，直接进入放大阶段。
- en: Secondly, although the search paths were short (with a number of steps proportional
    to *log(n)*), the whole search procedure wasn’t so fast. At each vector along
    the path, the greedy algorithm must examine each of the connected vectors, calculating
    their distance to the target in order to choose the closest one. While most of
    the locally connected vectors had only a few connections, most long-range hubs
    had many connections (again, a number proportional to *log(n)*); this makes sense
    as these vectors were usually inserted early on in the building process and had
    many opportunities to connect to other vectors. As a result, the total number
    of calculations during a search was quite large (proportional to *log(n)²*).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，尽管搜索路径较短（步骤数与*log(n)*成正比），但整个搜索过程并不十分快速。在路径上的每个向量处，贪婪算法必须检查每个连接的向量，计算它们与目标的距离，以选择最近的一个。虽然大多数本地连接的向量只有少数连接，但大多数长程中心节点有很多连接（同样与*log(n)*成正比）；这是有道理的，因为这些向量通常在构建过程中较早插入，并且有更多机会与其他向量连接。因此，在搜索过程中总的计算量相当大（与*log(n)²*成正比）。
- en: 'To improve this, we need to limit the number of connections checked at each
    hub. This leads to the main idea of HNSW: explicitly distinguishing between short-range
    and long-range connections. In the initial stage of a search, we will only consider
    the long-range connections between hubs. Once the greedy search has found a hub
    near the target, we then switch to using the short-range connections.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进这一点，我们需要限制在每个中心节点检查的连接数量。这引出了HNSW的主要思想：明确区分短程连接和长程连接。在搜索的初始阶段，我们只考虑中心节点之间的长程连接。一旦贪婪搜索找到了接近目标的中心节点，我们就切换到使用短程连接。
- en: '![](../Images/45591095e3d1714a360f9685f2d4b2c5.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45591095e3d1714a360f9685f2d4b2c5.png)'
- en: '*Illustration of a search through an HNSW. We are searching for the vector
    nearest the target X. Long-range connections and hubs are green; short-range connections
    are grey. Arrows show the search path. Starting at the entry point E1, we perform
    a greedy search among the long-range connections, reaching E2, which is the nearest
    long-range hub to X. From there we continue the greedy search among the short-range
    connections, ending at Y, the nearest vector to X.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过HNSW进行搜索的示意图。我们正在搜索最接近目标X的向量。长程连接和中心节点是绿色的；短程连接是灰色的。箭头显示了搜索路径。从入口点E1开始，我们在长程连接中执行贪婪搜索，达到E2，这是离X最近的长程中心节点。从那里我们继续在短程连接中进行贪婪搜索，最终到达Y，这是离X最近的向量。*'
- en: As the number of hubs is relatively small, they should have few connections
    to check. We can also explicitly impose a maximum number of long-range and short-range
    connections of each vector when we build the index. This results in a fast search
    time (proportional to *log(n)*).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于中心节点的数量相对较少，因此它们应该检查的连接较少。我们还可以在构建索引时，明确为每个向量强加一个长程连接和短程连接的最大数量。这将导致较快的搜索时间（与*log(n)*成正比）。
- en: The idea of separate short and long connections can be generalised to include
    several intermediate levels of connection lengths. We can visualise this as a
    **hierarchy** of layers of connected vectors, with each layer only using a fraction
    of the vectors in the layer below.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将短程和长程连接分开的思想可以推广到包括多个中间层次的连接长度。我们可以将其可视化为一个**层次结构**，每一层只使用下层中部分向量进行连接。
- en: '![](../Images/fa8d7c3a0bb33530bedb9691c64c77de.png)![](../Images/274baca27e99378be90705c826d71310.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa8d7c3a0bb33530bedb9691c64c77de.png)![](../Images/274baca27e99378be90705c826d71310.png)'
- en: '***Left****: illustration of an HNSW with three levels of connection length
    — short connections are grey, longer connections are green, and the longest connections
    are red.* E *is the entry point.* ***Right****: visualising the HNSW as a stack
    of three layers. Dotted lines indicate the location of the same vector in the
    layer below.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '***左**：一个具有三种连接长度的HNSW示意图——短程连接是灰色的，长程连接是绿色的，最长的连接是红色的。*E*是入口点。***右**：将HNSW可视化为三层堆栈。虚线表示同一向量在下层的位置。*'
- en: The best number of layers (and other parameters like the maximum number of connections
    of each vector) can be found by experiment; there are also heuristics suggested
    in the HNSW paper.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳层数（以及每个向量最大连接数等其他参数）可以通过实验找到；HNSW 论文中也提出了一些启发式方法。
- en: Incidentally, HNSW also generalises another data structure called a [skip list](https://en.wikipedia.org/wiki/Skip_list),
    which enables fast searching of sorted one-dimensional values (rather than multi-dimensional
    vectors).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，HNSW 还推广了一种名为 [跳表](https://en.wikipedia.org/wiki/Skip_list) 的数据结构，它可以快速搜索排序的一维值（而不是多维向量）。
- en: Building an HNSW uses similar ideas to NSW. Vectors are inserted one at a time,
    and long-range connections are created through connecting random vectors — although
    in HNSW, these vectors are randomly chosen throughout the whole building process
    (while in NSW they were the first vectors in the random order of insertion).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 构建 HNSW 使用的思想与 NSW 类似。向量是逐个插入的，通过连接随机向量创建长距离连接——尽管在 HNSW 中，这些向量是在整个构建过程中随机选择的（而在
    NSW 中，它们是按随机顺序插入的第一个向量）。
- en: To be precise, whenever a new vector is inserted, we first use a random function
    to choose the highest layer in which it will appear. All vectors appear in the
    bottom layer; a fraction of those also appear in the first layer up; a fraction
    of those also appear in the second layer up; and so on.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 精确来说，每当插入一个新的向量时，我们首先使用随机函数选择它将出现的最高层级。所有向量都出现在最底层；其中一部分向量也出现在第一层；其中一部分向量又出现在第二层，依此类推。
- en: Similar to NSW, we then connect the inserted vector to its *m* nearest neighbours
    in each layer that it appears; we can search for these neighbours efficiently
    using the index built so far. As the vectors become more sparse in higher layers,
    the connections typically become longer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 与 NSW 类似，我们将插入的向量连接到它在每个层次中出现的 *m* 个最近邻；我们可以利用迄今为止构建的索引高效地搜索这些邻居。随着向量在更高层次上的稀疏性增加，连接通常变得更长。
- en: Summary
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This completes the discussion of the main ideas leading to HNSW. To summarise:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分完成了关于导致 HNSW 的主要思想的讨论。总结如下：
- en: A small world is a graph that connects local points but also has short paths
    between distant points. This can be achieved through hubs with long-range connections.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 小世界是一个连接局部点的图，但也有短的路径连接远距离的点。这可以通过具有长距离连接的枢纽来实现。
- en: Building these long-range connections in the right way results in a small world
    that is navigable, meaning a greedy algorithm can quickly find the short paths.
    This enables fast nearest neighbour search.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以正确的方式构建这些长距离连接，会导致一个小世界图，具有可导航性，这意味着贪心算法可以迅速找到最短路径。这使得快速的最近邻搜索成为可能。
- en: One such method for building the connections is to insert vectors in a random
    order and connect them to their nearest neighbours. However, this leads to long-range
    hubs with many connections, and a slower search time.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 构建连接的一种方法是按随机顺序插入向量，并将其连接到最近邻。然而，这会导致具有大量连接的长距离枢纽，并导致较慢的搜索时间。
- en: To avoid this, a better method is to separately build connections of different
    lengths by choosing random vectors to use as hubs. This gives us the HNSW index,
    which significantly increases the speed of nearest neighbour search.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这一点，更好的方法是通过选择随机向量作为枢纽，单独构建不同长度的连接。这就给我们带来了 HNSW 索引，显著提高了最近邻搜索的速度。
- en: Appendix
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: The post above provides an overview of the HNSW index and the ideas behind it.
    This appendix discusses additional interesting details of the HNSW algorithms
    for readers seeking a complete understanding. See the references for further details
    and pseudocode.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的帖子概述了 HNSW 索引及其背后的思想。本附录讨论了 HNSW 算法的一些额外有趣细节，供那些寻求完整理解的读者参考。更多细节和伪代码请参见参考文献。
- en: Improved search
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改进的搜索
- en: Navigable small world methods only give approximate results for nearest neighbour
    search. Sometimes, the greedy search algorithm stops before finding the nearest
    vector to the target. This happens when the search path encounters a “false local
    optimum”, meaning the vector’s immediate connections are all further from the
    target, although there is a closer vector somewhere else in the graph.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 可导航的小世界方法只能为最近邻搜索提供近似结果。有时，贪心搜索算法会在找到距离目标最近的向量之前停止。这种情况发生在搜索路径遇到“虚假的局部最优”时，即向量的直接连接都离目标更远，尽管在图的其他地方可能有一个更接近的向量。
- en: Things can be improved by performing several independent searches from different
    entry points, the results of which can give us several good *candidates* for the
    nearest neighbour. We then calculate the distance of all of the candidates to
    the target, and return the closest one.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过从不同的入口点执行多个独立的搜索来改进此过程，这些搜索的结果可以为我们提供几个好的 *候选* 向量作为最近邻。然后我们计算所有候选向量与目标的距离，并返回最近的一个。
- en: If we want to find more than one (say *k*) nearest neighbours, we can first
    expand the set of candidates by adding all of their immediate connections, before
    calculating the distances to the target and returning the closest *k*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想找到多个最近邻（例如 *k* 个），我们可以首先通过添加它们的所有直接连接来扩展候选集，然后计算与目标的距离并返回最近的 *k* 个。
- en: This simple method for finding candidates has some shortcomings. Each greedy
    search path is still at risk of ending at a false local optimum; this could be
    improved by exploring beyond the immediate connections of each vector. Also, a
    search path may encounter several vectors towards the end which are close to the
    target, but aren’t chosen as candidates (because they aren’t the final vector
    in the path or one of its immediate connections).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种简单的候选查找方法存在一些不足。每个贪婪搜索路径仍然有可能陷入一个错误的局部最优解；通过探索每个向量的直接连接之外的区域可以改进这一点。此外，搜索路径可能会在结束时遇到几个靠近目标的向量，但这些向量不会被选为候选（因为它们不是路径中的最终向量或它的直接连接之一）。
- en: Rather than following several greedy paths independently, a more effective approach
    is to follow a *set* of vectors, updating the whole set in a greedy fashion.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与其独立地跟踪多个贪婪路径，更有效的方法是跟踪一个 *向量集*，并以贪婪的方式更新整个集合。
- en: To be precise, we will maintain a set containing the closest vectors to the
    target encountered so far, along with their distances to the target. This set
    holds a maximum of *ef* vectors, where *ef* is the desired number of candidates.
    Initially, the set contains the entry points. We then proceed by a greedy process,
    evaluating each vector in the set by checking its connections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 精确来说，我们将维护一个集合，包含到目前为止遇到的离目标最近的向量以及它们到目标的距离。该集合最多包含 *ef* 个向量，其中 *ef* 是期望的候选数量。最初，该集合包含入口点。接下来，我们通过贪婪过程继续，评估集合中的每个向量并检查它的连接。
- en: All vectors in the set are initially marked as “unevaluated”. At each step,
    we evaluate the closest unevaluated vector to the target (and mark it as “evaluated”).
    Evaluating the vector means checking each of its connected vectors by calculating
    that vector’s distance to the target, and inserting it into the set (marked as
    “unevaluated”) if it’s closer than some of the vectors there (pushing the furthest
    vector out of the set if it’s at maximum capacity). (We also keep track of the
    vectors for which we’ve already calculated the distance, to avoid repeating work.)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 集合中的所有向量最初标记为“未评估”。在每一步，我们评估离目标最近的未评估向量（并将其标记为“已评估”）。评估向量意味着检查其每个连接向量，计算该向量与目标的距离，如果比集合中某些向量更近，就将其插入集合（并将最远的向量移出集合，如果集合已达到最大容量）。(我们还会追踪已经计算过距离的向量，以避免重复工作。)
- en: The process ends when all of the vectors in the set have been evaluated and
    no new vectors have been inserted. The final set is returned as the candidates,
    from which we can take the closest vector or *k* closest vectors to the target.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程在集合中的所有向量都被评估过并且没有插入新的向量时结束。最终的集合作为候选集返回，我们可以从中选取离目标最近的向量或 *k* 个最近的向量。
- en: (Note that for *ef = 1*, this algorithm is simply the basic greedy search algorithm.)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: （注意，对于 *ef = 1*，该算法只是基本的贪婪搜索算法。）
- en: HNSW search & insertion
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HNSW 搜索与插入
- en: The above describes a search algorithm for an NSW, or a single layer of an HNSW.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上述描述了一个 NSW 的搜索算法，或 HNSW 的单层搜索算法。
- en: To search the whole HNSW structure, the suggested approach is to use basic greedy
    search for the nearest neighbour in each layer from the top until we reach the
    layer of interest, at which point we use the layer search algorithm with several
    candidates.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要搜索整个 HNSW 结构，建议的方法是从顶部层开始，在每一层使用基本的贪婪搜索找到最近邻，直到到达感兴趣的层，此时我们使用层搜索算法并考虑多个候选。
- en: For performing a k-nearest neighbours search (including *k = 1*) on the completed
    index, this means using basic greedy search until we reach the bottom layer, at
    which point we use the layer search algorithm with *ef = efSearch* candidates.
    *efSearch* is a parameter to be tuned; higher *efSearch* is slower but more accurate.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在完成的索引上进行 k 最近邻搜索（包括 *k = 1*），这意味着使用基本的贪心搜索，直到到达底层，此时我们使用带有 *ef = efSearch*
    候选向量的层搜索算法。*efSearch* 是一个需要调优的参数；较高的 *efSearch* 值虽然速度较慢，但精度更高。
- en: For inserting a vector into HNSW, we use basic greedy search until the first
    layer in which the new vector appears. Here, we search for the *m* nearest neighbours
    using layer search with *ef = efConstruction* candidates. We also use the candidates
    as the entry points for continuing the process in the next layer down.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于将向量插入 HNSW，我们使用基本的贪心搜索，直到找到新向量出现的第一层。在这一层，我们使用带有 *ef = efConstruction* 候选向量的层搜索来寻找
    *m* 个最近邻。我们还将这些候选向量作为进入下一层继续处理的入口点。
- en: Improved insertion
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改进的插入方法
- en: NSW introduced a simple method of building the graph in which each inserted
    vector is connected to its *m* nearest neighbours. While this method for choosing
    connections also works for HNSW, a modified approach was introduced which significantly
    improves the performance of the resulting index.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: NSW 引入了一种简单的构建图的方法，其中每个插入的向量都与其 *m* 个最近邻连接。虽然这种选择连接的方法也适用于 HNSW，但引入了一种改进的方法，显著提升了生成的索引的性能。
- en: As usual, we start by finding *efConstruction* candidate vectors. We then go
    through these candidates in order of increasing distance from the inserted vector
    and connect them. However, if a candidate is closer to one of the newly connected
    candidates than it is to the inserted vector, we skip over it without connecting.
    We stop when *m* candidates have been connected.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我们首先找到 *efConstruction* 候选向量。然后我们按照与插入向量的距离从小到大遍历这些候选向量并连接它们。然而，如果某个候选向量距离一个新连接的候选向量比插入向量还近，我们就跳过它而不进行连接。我们在连接了
    *m* 个候选向量后停止。
- en: The idea is that we can already reach the candidate from the inserted vector
    through a newly connected candidate, so it’s a waste to also add a direct connection;
    it’s better to connect a more distant point. This increases the diversity of connections
    in the graph, and helps connect nearby clusters of vectors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是，我们已经可以通过新连接的候选向量从插入向量到达该候选向量，因此增加一个直接连接是没有必要的；连接一个更远的点会更好。这样可以增加图中连接的多样性，帮助连接相邻的向量簇。
- en: References
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] J. Travers and S. Milgram, [An Experimental Study of the Small World Problem](https://snap.stanford.edu/class/cs224w-readings/travers69smallworld.pdf)
    (1969), Sociometry'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] J. Travers 和 S. Milgram, [小世界问题的实验研究](https://snap.stanford.edu/class/cs224w-readings/travers69smallworld.pdf)（1969），《社会计量学》'
- en: '[2] J. Kleinberg, [The Small-World Phenomenon: An Algorithmic Perspective](https://www.stat.berkeley.edu/users/aldous/Networks/swn-1.pdf)
    (2000), Proceedings of the thirty-second annual ACM symposium on Theory of Computing'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] J. Kleinberg, [小世界现象：一种算法视角](https://www.stat.berkeley.edu/users/aldous/Networks/swn-1.pdf)（2000），《第三十二届年度
    ACM 计算理论会议论文集》'
- en: '[3] Y. Malkov, A. Ponomarenko, A. Logvinov and V. Krylov, [Approximate nearest
    neighbor algorithm based on navigable small world graphs](https://publications.hse.ru/mirror/pubs/share/folder/x5p6h7thif/direct/128296059)
    (2014), Information Systems, vol. 45'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Y. Malkov, A. Ponomarenko, A. Logvinov 和 V. Krylov, [基于可导航小世界图的近似最近邻算法](https://publications.hse.ru/mirror/pubs/share/folder/x5p6h7thif/direct/128296059)（2014），《信息系统》，第
    45 卷'
- en: '*(There are several similar papers; this one is the most recent and complete,
    and includes the more advanced k-nearest neighbours search algorithm.)*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*(有几篇类似的论文；这篇是最新且最完整的，并且包含了更先进的 k 最近邻搜索算法。)*'
- en: '[4] Y. Malkov and D. Yashunin, [Efficient and robust approximate nearest neighbor
    search using Hierarchical Navigable Small World graphs](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)
    (2016), IEEE Transactions on Pattern Analysis and Machine Intelligence'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Y. Malkov 和 D. Yashunin, [使用分层可导航小世界图进行高效且稳健的近似最近邻搜索](https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf)（2016），《IEEE
    模式分析与机器智能学报》'
- en: All images are created by the author and free to use with a citation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图片均由作者创作，可以在注明出处的情况下免费使用。
