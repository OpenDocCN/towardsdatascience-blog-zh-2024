- en: Paradigm Shifts of Eval in the Age of LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大语言模型时代评估的范式转变
- en: 原文：[https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31](https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31](https://towardsdatascience.com/paradigm-shifts-of-eval-in-the-age-of-llm-7afd58e55b29?source=collection_archive---------2-----------------------#2024-12-31)
- en: LLMs requires some subtle, conceptually simple, yet important changes in the
    way we think about evaluation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大语言模型在评估方法上需要一些微妙、概念上简单但却非常重要的变化。
- en: '[](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[![Lili
    Jiang](../Images/ca3c10589bf964a7c29e70f6cdd12244.png)](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)
    [Lili Jiang](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[![Lili
    Jiang](../Images/ca3c10589bf964a7c29e70f6cdd12244.png)](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)
    [Lili Jiang](https://medium.com/@lilipads93?source=post_page---byline--7afd58e55b29--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)
    ·7 min read·5 days ago
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7afd58e55b29--------------------------------)
    ·阅读时长7分钟·5天前
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: I’ve been building evaluation for ML systems throughout my career. As head of
    data science at Quora, we built eval for feed ranking, ads, content moderation,
    etc. My team at Waymo built eval for self-driving cars. Most recently, at our
    fintech startup [Coverbase](http://coverbase.io), we use LLMs to ease the pain
    of third-party risk management. Drawing from these experiences, I’ve come to recognize
    that LLMs requires some subtle, conceptually simple, yet important changes in
    the way we think about evaluation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的职业生涯中，我一直在为机器学习系统构建评估。在Quora担任数据科学主管时，我们为信息流排序、广告、内容审核等构建了评估系统。我的Waymo团队为自动驾驶汽车构建了评估系统。最近，在我们的金融科技创业公司
    [Coverbase](http://coverbase.io) 中，我们使用大语言模型来缓解第三方风险管理的困难。通过这些经验，我逐渐意识到，大语言模型在评估方法上需要一些微妙、概念上简单但却非常重要的变化。
- en: 'The goal of this blog post is not to offer specific eval techniques to your
    LLM application, but rather to suggest these 3 paradigm shifts:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目标不是为您的大语言模型应用提供具体的评估技术，而是提出这三种范式转变：
- en: Evaluation is the cake, no longer the icing.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估是蛋糕，而不再是糖霜。
- en: Benchmark the difference.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基准评估差异。
- en: Embrace human triage as an integral part of eval.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将人工分拣作为评估的重要组成部分。
- en: I should caveat that my discussion is focused on LLM applications, not foundational
    model development. Also, despite the title, much of what I discuss here is applicable
    to other generative systems (inspired by my experience in autonomous vehicles),
    not just LLM applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要说明的是，我的讨论主要集中在大语言模型的应用上，而非基础模型的开发。此外，尽管标题如此，我在这里讨论的内容也适用于其他生成系统（受到我在自动驾驶领域经验的启发），不仅仅是大语言模型应用。
- en: '**1\. Evaluation is the cake, no longer the icing.**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. 评估是蛋糕，而不再是糖霜。**'
- en: 'Evaluation has always been important in ML development, LLM or not. But I’d
    argue that it is extra important in LLM development for two reasons:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 评估在机器学习（ML）发展中一直很重要，不论是否涉及大语言模型（LLM）。但我认为，评估在大语言模型的发展中尤为重要，原因有二：
- en: 'a) The **relative importance** of eval goes up, because there are lower degrees
    of freedom in building LLM applications, making time spent non-eval work go down.
    In LLM development, building on top of foundational models such as OpenAI’s GPT
    or Anthropic’s Claude models, there are fewer knobs available to tweak in the
    application layer. And these knobs are much faster to tweak (caveat: faster to
    tweak, not necessarily faster to get it right). For example, changing the prompt
    is arguably much faster to implement than writing a new hand-crafted feature for
    a Gradient-Boosted Decision Tree. Thus, there is less non-eval work to do, making
    the proportion of time spent on eval go up.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: a) **评估的重要性**上升，因为在构建LLM应用时，调整的自由度较低，导致非评估工作的时间减少。在LLM开发中，基于基础模型（例如OpenAI的GPT或Anthropic的Claude模型）进行开发时，应用层可以调整的参数更少。而这些参数的调整速度也要快得多（警告：调整速度快，并不代表能更快达到正确的结果）。例如，修改提示语（prompt）显然比为一个梯度提升决策树编写一个新的手工特征要快速得多。因此，非评估工作的时间减少，导致评估所占时间比例增加。
- en: '![](../Images/ff691a2259916d0656e6baa7c4384077.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff691a2259916d0656e6baa7c4384077.png)'
- en: Image by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'b) The **absolute importance** of eval goes up, because there are higher degrees
    of freedom in the output of generative AI, making eval a more complex task. In
    contrast with classification or ranking tasks, generative AI tasks (e.g. write
    an essay about X, make an image of Y, generate a trajectory for an autonomous
    vehicle) can have an infinite number of acceptable outputs. Thus, the measurement
    is a process of projecting a high-dimensional space into lower dimensions. For
    example, for an LLM task, one can measure: “Is output text factual?”, “Does the
    output contain harmful content?”, “Is the language concise?”, “Does it start with
    ‘certainly!’ too often?”, etc. If precision and recall in a binary classification
    task are loss-less measurements of those binary outputs (measuring what you see),
    the example metrics I listed earlier for an LLM task are lossy measurements of
    the output text (measuring a low-dimensional representation of what you see).
    And that is much harder to get right.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: b) **评估的绝对重要性**上升，因为生成性人工智能的输出自由度更高，使得评估任务变得更加复杂。与分类或排序任务相比，生成性人工智能任务（例如：写一篇关于X的文章、制作Y的图像、为自动驾驶车辆生成轨迹）可以有无数种可接受的输出。因此，评估是将高维空间投射到低维空间的过程。例如，对于一个LLM任务，可以衡量：“输出文本是否真实？”，“输出是否包含有害内容？”，“语言是否简洁？”，“是否经常以‘当然！’开头？”等。如果二元分类任务中的精确度和召回率是对这些二元输出的无损测量（衡量你所看到的内容），那么我之前列出的LLM任务的示例指标就是对输出文本的有损测量（衡量你所看到内容的低维表示）。这要正确执行要困难得多。
- en: This paradigm shift has practical implications on team sizing and hiring when
    staffing a project on LLM application.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式转变对团队规模和招聘在大语言模型（LLM）应用项目中的实践意义重大。
- en: '**2\. Benchmark the difference.**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2. 基准对比差异。**'
- en: 'This is the dream scenario: we climb on a target metric and keep improving
    on it.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是理想的场景：我们设定一个目标指标并不断在其上进行改进。
- en: '![](../Images/3a3d72ce940c7167b69e889fc2d9f889.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a3d72ce940c7167b69e889fc2d9f889.png)'
- en: Image by author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The reality?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现实情况呢？
- en: You can barely draw more than 2 consecutive points in the graph!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎无法在图表中绘制超过2个连续的点！
- en: 'These might sound familiar to you:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能对你来说很熟悉：
- en: After the 1st launch, we acquired a much bigger dataset, so the new metric number
    is no longer an apple-to-apple comparison with the old number. And we can’t re-run
    the old model on the new dataset — maybe other parts of the system have upgraded
    and we can’t check out the old commit to reproduce the old model; maybe the eval
    metric is an LLM-as-a-judge and the dataset is huge, so each eval run is prohibitively
    expensive, etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次发布后，我们获得了一个更大的数据集，因此新的度量值与旧的度量值不再是苹果对苹果的比较。我们也无法在新数据集上重新运行旧模型——也许系统的其他部分已经升级，我们无法查看旧的提交以重现旧模型；也许评估指标是一个LLM作为评判者，而数据集非常庞大，因此每次评估运行的成本非常高，等等。
- en: After the 2nd launch, we decided to change the output schema. For example, previously,
    we instructed the model to output a yes / no answer; now we instruct the model
    to output yes / no / maybe / I don’t know. So the previously carefully curated
    ground truth set is no longer valid.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次发布后，我们决定更改输出模式。例如，之前我们指示模型输出“是/否”答案；现在我们指示模型输出“是/否/也许/我不知道”。因此，之前精心策划的真实标签集不再有效。
- en: After the 3rd launch, we decided to break the single LLM calls into a composite
    of two calls, and we need to evaluate the sub-component. We need new datasets
    for sub-component eval.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三次发布后，我们决定将单一的LLM调用分解为两个调用的组合，并且需要评估这些子组件。我们需要为子组件评估准备新的数据集。
- en: ….
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ….
- en: The point is the development cycle in the age of LLMs is often too fast for
    longitudinal tracking of the same metric.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是，在LLM时代，开发周期往往太快，以至于无法对同一度量进行纵向跟踪。
- en: So what is the solution?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那么解决方案是什么？
- en: Measure the delta.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 测量增量。
- en: In other words, make peace with having just two consecutive points on that graph.
    The idea is to make sure each model version is better than the previous version
    (to the best of your knowledge at that point in time), even though it is quite
    hard to know where its performance stands in absolute terms.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，接受图表上只有两个连续数据点的事实。关键是确保每个模型版本比前一个版本更好（在当时你所知道的情况下），即使很难知道其表现的绝对水平。
- en: Suppose I have an LLM-based language tutor that first classifies the input as
    English or Spanish, and then offers grammar tips. A simple metric can be the accuracy
    of the “English / Spanish” label. Now, say I made some changes to the prompt and
    want to know whether the new prompt improves accuracy. Instead of hand-labeling
    a large data set and computing accuracy on it, another way is to just focus on
    the data points where the old and new prompts produce different labels. I won’t
    be able to know the absolute accuracy of either model this way, but I will know
    which model has higher accuracy.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我有一个基于LLM的语言辅导器，它首先将输入分类为英语或西班牙语，然后提供语法提示。一个简单的度量可以是“英语/西班牙语”标签的准确率。现在，假设我对提示做了一些修改，想知道新提示是否提高了准确率。与其手动标记一个大型数据集并计算其准确率，另一种方法是只关注旧提示和新提示产生不同标签的数据点。我不能通过这种方式知道任何模型的绝对准确率，但我会知道哪个模型的准确率更高。
- en: '![](../Images/d9d96c3cb0456a62f5a6a56c806bbe1f.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9d96c3cb0456a62f5a6a56c806bbe1f.png)'
- en: Image by author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: I should clarify that I am not saying benchmarking the absolute has no merits.
    I am only saying we should be cognizant of the cost of doing so, and benchmarking
    the delta — albeit not a full substitute — can be a much more cost-effective way
    to get a directional conclusion. One of the more fundamental reasons for this
    paradigm shift is that if you are building your ML model from scratch, you often
    have to curate a large training set anyway, so the eval dataset can often be a
    byproduct of that. This is not the case with zero-shot and few-shots learning
    on pre-trained models (such as LLMs).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要澄清的是，我并不是说基准测试绝对值没有价值。我只是说我们应该意识到这样做的成本，而基准测试增量——尽管不能完全替代——可以是一种更加具有成本效益的方式，来得到一个方向性的结论。这种范式转变的一个更根本的原因是，如果你从零开始构建你的机器学习模型，你通常必须整理一个大的训练集，因此评估数据集通常是这个过程的副产品。而这在零-shot和少-shot学习中（例如，LLM）并非如此。
- en: 'As a second example, perhaps I have an LLM-based metric: we use a separate
    LLM to judge whether the explanation produced in my LLM language tutor is clear
    enough. One might ask, “Since the eval is automated now, is benchmarking the delta
    still cheaper than benchmarking the absolute?” Yes. Because the metric is more
    complicated now, you can keep improving the metric itself (e.g. prompt engineering
    the LLM-based metric). For one, we still need to eval the eval; benchmarking the
    deltas tells you whether the new metric version is better. For another, as the
    LLM-based metric evolves, we don’t have to sweat over backfilling benchmark results
    of all the old versions of the LLM language tutor with the new LLM-based metric
    version, if we only focus on comparing two adjacent versions of the LLM language
    tutor models.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二个例子，假设我有一个基于LLM的度量：我们使用一个独立的LLM来判断我在LLM语言辅导器中生成的解释是否足够清晰。有人可能会问：“既然评估现在是自动化的，基准测试增量仍然比基准测试绝对值便宜吗？”是的。因为度量现在更复杂了，你可以不断改进度量本身（例如，进行基于LLM的度量的提示工程）。首先，我们仍然需要评估评估；基准测试增量可以告诉你新版本的度量是否更好。其次，随着基于LLM的度量的发展，如果我们只专注于比较LLM语言辅导器模型的两个相邻版本，就不必费心去填补所有旧版本的基准结果，用新的基于LLM的度量版本来重新评估。
- en: Benchmarking the deltas can be an effective inner-loop, fast-iteration mechanism,
    while saving the more expensive way of benchmarking the absolute or longitudinal
    tracking for the outer-loop, lower-cadence iterations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试增量可以成为一种有效的内部循环、快速迭代机制，同时节省外部循环、低频率迭代中基准测试绝对值或纵向跟踪的高成本。
- en: '**3\. Embrace human triage as an integral part of eval.**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3\. 将人工筛选作为评估的一个组成部分。**'
- en: As discussed above, the dream of carefully triaging a golden set once-and-for-all
    such that it can be used as an evergreen benchmark can be unattainable. Triaging
    will be an integral, continuous part of the development process, whether it is
    triaging the LLM output directly, or triaging those LLM-as-judges or other kinds
    of more complex metrics. We should continue to make eval as scalable as possible;
    the point here is that despite that, we should not expect the elimination of human
    triage. The sooner we come to terms with this, the sooner we can make the right
    investments in tooling.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，精心筛选一个黄金数据集，一劳永逸地将其作为永恒基准使用的梦想可能无法实现。筛选将成为开发过程中的一个不可或缺的、持续的部分，无论是直接筛选LLM输出，还是筛选LLM作为判断者或其他更复杂的指标。我们应继续使评估尽可能可扩展；关键是，尽管如此，我们不应指望能够消除人工筛选。我们越早接受这一点，就能越早在工具投资上做出正确决策。
- en: As such, whatever eval tools we use, in-house or not, there should be an easy
    interface for human triage. A simple interface can look like the following. Combined
    with the point earlier on benchmarking the difference, it has a side-by-side panel,
    and you can easily flip through the results. It also should allow you to easily
    record your triaged notes such that they can be recycled as golden labels for
    future benchmarking (and hence reduce future triage load).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，无论我们使用何种评估工具，无论是内部工具还是外部工具，都应该有一个便捷的人工筛选界面。一个简单的界面可以像下面这样。结合前面提到的差异基准，界面可以呈现并排面板，用户可以轻松浏览结果。它还应允许你轻松记录筛选的笔记，以便将其作为黄金标签用于未来的基准测试（从而减少未来的筛选负担）。
- en: '![](../Images/5ce8ee267c785af203979bc27966b731.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ce8ee267c785af203979bc27966b731.png)'
- en: Image by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来自作者
- en: A more advanced version ideally would be a blind test, where it is unknown to
    the triager which side is which. We’ve repeatedly confirmed with data that when
    not doing blind testing, developers, even with the best intentions, have subconscious
    bias, favoring the version they developed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 更高级的版本理想情况下应该是盲测，即筛选者不知道哪个版本是哪个。我们通过数据反复验证了，当不进行盲测时，开发人员即便是出于最佳意图，也会有潜在的偏见，偏向自己开发的版本。
- en: These three paradigm shifts, once spotted, are fairly straightforward to adapt
    to. The challenge isn’t in the complexity of the solutions, but in recognizing
    them upfront amidst the excitement and rapid pace of development. I hope sharing
    these reflections helps others who are navigating similar challenges in their
    own work.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发现这三种范式转变，适应起来其实相当直接。挑战不在于解决方案的复杂性，而在于在激动人心的快速开发节奏中，提前识别这些转变。我希望分享这些思考能帮助其他在自己工作中面临类似挑战的人。
