- en: 'Dance Between Dense and Sparse Embeddings: Enabling Hybrid Search in LangChain-Milvus'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稠密和稀疏嵌入之间的舞蹈：启用 LangChain-Milvus 中的混合搜索
- en: 原文：[https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19](https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19](https://towardsdatascience.com/dance-between-dense-and-sparse-embeddings-enabling-hybrid-search-in-langchain-milvus-7c8de54dda24?source=collection_archive---------8-----------------------#2024-11-19)
- en: How to create and search multi-vector-store in langchain-milvus
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在 langchain-milvus 中创建和搜索多向量存储
- en: '[](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)[![Ohad
    Eytan](../Images/46074702c9543b68bf761d51d6a6ac2c.png)](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)
    [Ohad Eytan](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)[![Ohad
    Eytan](../Images/46074702c9543b68bf761d51d6a6ac2c.png)](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)
    [Ohad Eytan](https://ohadeytan.medium.com/?source=post_page---byline--7c8de54dda24--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)
    ·6 min read·Nov 19, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7c8de54dda24--------------------------------)
    ·6 分钟阅读·2024年11月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*This blog post was co-authored by* [***Omri Levy***](https://www.linkedin.com/in/levyomri/)*and*
    ***Ohad Eytan****, as part of the work we have done in* [*IBM Research Israel*](https://research.ibm.com/labs/israel)*.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇博客由* [***Omri Levy***](https://www.linkedin.com/in/levyomri/)*和* ***Ohad
    Eytan*** 共同撰写，作为我们在* [*IBM Research Israel*](https://research.ibm.com/labs/israel)
    *所做工作的一个部分。*'
- en: Intro
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Recently, we — at IBM Research — needed to use hybrid search in the [*Milvus*](https://milvus.io/)vector
    store. Since we were already using the [*LangChain*](https://www.langchain.com/)
    framework, we decided to roll up our sleeves and contribute what was needed to
    enable it in [*langchain-milvus*](https://github.com/langchain-ai/langchain-milvus).
    That included support for **sparse embeddings** ([PR](https://github.com/langchain-ai/langchain/pull/25284))
    and **multi-vector search** ([PR](https://github.com/langchain-ai/langchain-milvus/pull/11))
    through the *langchain* interface.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们——IBM研究院——需要在[*Milvus*](https://milvus.io/)向量存储中使用混合搜索。由于我们已经在使用[*LangChain*](https://www.langchain.com/)框架，因此我们决定动手贡献所需的功能，以便在[*langchain-milvus*](https://github.com/langchain-ai/langchain-milvus)中启用它。我们添加了对**稀疏嵌入**的支持（[PR](https://github.com/langchain-ai/langchain/pull/25284)）和通过*langchain*接口进行**多向量搜索**（[PR](https://github.com/langchain-ai/langchain-milvus/pull/11)）。
- en: In this blog post, we will briefly introduce the difference between dense and
    sparse embeddings, and how you can leverage both using hybrid search. We’ll also
    provide a code walk-through to demonstrate how to use these new features in *langchain-milvus*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将简要介绍稠密嵌入和稀疏嵌入之间的区别，以及如何利用混合搜索来同时使用这两者。我们还将提供一段代码演示，展示如何在*langchain-milvus*中使用这些新功能。
- en: 'To use the code in this blog post, you should install some packages:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这篇博客中的代码，你需要安装一些包：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'and import these:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 并导入以下内容：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can also see and clone the whole code in [this gist](https://gist.github.com/omriel1/3b8ea57cc14b896237c47d5417eaec8f).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在[这个 Gist](https://gist.github.com/omriel1/3b8ea57cc14b896237c47d5417eaec8f)中查看并克隆完整代码。
- en: Let’s go.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Dense Embeddings
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稠密嵌入
- en: The most common way to use vector stores is with dense embeddings. Here we use
    a pre-trained model to embed the data (usually text, but could be other media
    like images etc.) into high dimensional vectors, and store it in the vector database.
    The vectors have a couple of hundred (or even thousands of) dimensions, and each
    entry is a floating-point number. Typically, all of the entries in the vectors
    are occupied with non-zero values, hence the term “dense”. Given a query, we embed
    it using the same model, and the vector store retrieves similar, relevant data
    based on vector similarity. Using *langchain-milvus*, it’s just a couple lines
    of code. Let’s see how it’s done.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用向量存储的最常见方式是稠密嵌入。在这里，我们使用一个预训练模型将数据（通常是文本，但也可以是其他媒体如图片等）嵌入到高维向量中，并将其存储在向量数据库中。这些向量有几百个（甚至几千个）维度，每个条目是一个浮动点数。通常，向量中的所有条目都被非零值占据，因此称为“稠密”。给定查询，我们使用相同的模型将其嵌入，向量存储根据向量相似性检索相关的相似数据。使用*langchain-milvus*，只需要几行代码。让我们看看是如何完成的。
- en: 'First, we define the vector store using [a model from HuggingFace](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用[来自HuggingFace的模型](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)来定义向量存储：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Second, we insert our data into the vector store:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步，我们将数据插入到向量存储中：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Behind the scenes, each document is embedded into a vector using the model we
    supplied, and is stored alongside the original text.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在后台，每个文档都通过我们提供的模型嵌入到一个向量中，并与原始文本一起存储。
- en: 'Finally, we can search for a query and print the result we got:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以搜索查询并打印出得到的结果：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the query is embedded, and the vector store does the (usually approximated)
    similarity search and returns the closest content it found.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，查询被嵌入，向量存储进行（通常是近似的）相似性搜索，并返回它找到的最接近的内容。
- en: Dense embeddings models are trained to capture the **semantic meaning** of the
    data and represent it in the multidimensional space. The advantage is clear —
    it enables semantic search, which means the results are based on the query’s meaning.
    But sometimes that’s not enough. If you look for specific keywords, or even words
    without broader meaning (like names), the semantic search will misguide you and
    this approach will fail.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 稠密嵌入模型经过训练，能够捕捉数据的**语义意义**并将其表示在多维空间中。这个优点非常明显——它使得语义搜索成为可能，这意味着结果是基于查询的含义进行的。但有时这还不够。如果你寻找特定的关键词，甚至是没有更广泛意义的词（如名称），语义搜索可能会误导你，这种方法将会失败。
- en: Sparse embeddings
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏嵌入
- en: 'Ages before LLMs became a thing, and learned models weren’t so popular, search
    engines used traditional methods such as [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
    or its modern enhancement, [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) (known
    for it’s use in [Elastic](https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch)),
    to search relevant data. With these methods, the number of dimensions is the vocabulary
    size (typically tens of thousands, much larger than the dense vector space), and
    each entry represents the relevance of a keyword to a document, while taking into
    consideration the frequency of the term and its rarity across the corpus of documents.
    For each data point, most of the entries are zeros (for words that don’t appear),
    hence the term “sparse”. Although under the hood the implementation is different,
    with *langchain-milvus* interface it becomes very similar. Let’s see it in action:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模语言模型（LLM）流行之前，且学习模型尚未广泛应用时，搜索引擎使用了传统方法，如[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)或其现代增强版[BM25](https://en.wikipedia.org/wiki/Okapi_BM25)（它在[Elastic](https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch)中的应用而闻名），来搜索相关数据。使用这些方法时，维度的数量是词汇表的大小（通常是数万个，远大于稠密向量空间），每个条目代表关键词与文档的相关性，同时考虑到该术语的频率及其在文档语料库中的稀有性。对于每个数据点，大多数条目都是零（对于不出现的词），因此被称为“稀疏”。尽管在底层实现有所不同，但通过*langchain-milvus*接口，它变得非常相似。让我们看看它是如何运作的：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: BM25 is effective for exact keyword matching, which is useful for terms or names
    that lack clear semantic meaning. However, it will not capture the intent of the
    query, and will yield poor results in many cases where semantic understanding
    is needed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: BM25在精确的关键词匹配中非常有效，对于缺乏明确语义意义的术语或名称非常有用。然而，它无法捕捉查询的意图，并且在许多需要语义理解的情况下会产生不好的结果。
- en: 'Note: the term “Sparse embeddings” also refers to advanced methods like SPLADE
    or Elastic Elser. These methods can also be used with Milvus and can be integrated
    into hybrid search!'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：“稀疏嵌入”一词还指代像 SPLADE 或 Elastic Elser 这样的先进方法。这些方法也可以与 Milvus 一起使用，并且可以集成到混合搜索中！
- en: '![](../Images/1ae4c985d8d5a4981502aa1df9fbc7e6.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ae4c985d8d5a4981502aa1df9fbc7e6.png)'
- en: Image by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Hybrid Search
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合搜索
- en: 'If you swap the queries between the two examples above, and use each one with
    the other’s embedding, both will produce the wrong result. This demonstrates the
    fact that each method has its strengths but also its weaknesses. Hybrid search
    combines the two, aiming to leverage the best from both worlds. By indexing data
    with both dense and sparse embeddings, we can perform searches that consider both
    semantic relevance and keyword matching, balancing results based on custom weights.
    Again, the internal implementation is more complicated, but *langchain-milvus*
    makes it pretty simple to use. Let’s look at how this works:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你交换上面两个示例中的查询，并用对方的嵌入进行搜索，两者都会产生错误的结果。这证明了每种方法都有其优点，但也有其缺点。混合搜索将两者结合，旨在发挥两者的最佳优势。通过使用稠密和稀疏嵌入索引数据，我们可以执行既考虑语义相关性又考虑关键词匹配的搜索，并根据自定义权重平衡结果。同样，内部实现更为复杂，但*langchain-milvus*使得使用起来相当简单。让我们看看它是如何工作的：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this setup, both sparse and dense embeddings are applied. Let’s test the
    hybrid search with equal weighting:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设置中，应用了稀疏和稠密嵌入。让我们用相等的权重来测试混合搜索：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This searches for similar results using each embedding function, gives each
    score a weight, and returns the result with the best weighted score. We can see
    that with slightly more weight to the dense embeddings, we get the result we desired.
    This is true for the second query as well.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这会使用每个嵌入函数搜索相似的结果，给每个得分加上权重，并返回得分最高的结果。我们可以看到，稍微增加对稠密嵌入的权重后，我们得到了期望的结果。第二个查询也是如此。
- en: 'If we give more weight to the dense embeddings, we will once again get non-relevant
    results, as with the dense embeddings alone:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们给稠密嵌入更多的权重，我们将再次得到无关的结果，就像只有稠密嵌入时那样：
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Finding the right balance between dense and sparse is not a trivial task, and
    can be seen as part of a wider hyper-parameter optimization problem. There is
    an ongoing research and tools that trying to solve such issues in this area, for
    example [IBM’s AutoAI for RAG](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-programming-rag.html?context=wx&audience=wdp#autorag-implement).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在稠密和稀疏之间找到正确的平衡并非一项简单的任务，可以看作是更广泛的超参数优化问题的一部分。当前在这一领域有正在进行的研究和工具，试图解决这类问题，例如[IBM的AutoAI
    for RAG](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-programming-rag.html?context=wx&audience=wdp#autorag-implement)。
- en: There are many more ways you can adapt and use the hybrid search approach. For
    instance, if each document has an associated title, you could use two dense embedding
    functions (possibly with different models) — one for the title and another for
    the document content — and perform a hybrid search on both indices. Milvus currently
    supports up to 10 different vector fields, providing flexibility for complex applications.
    There are also additional configurations for indexing and reranking methods. You
    can see [Milvus documentation](https://milvus.io/docs/multi-vector-search.md)
    about the available params and options.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过多种方式适应并使用混合搜索方法。例如，如果每个文档都有一个相关的标题，你可以使用两个稠密嵌入函数（可能使用不同的模型）——一个用于标题，另一个用于文档内容——并在两个索引上执行混合搜索。Milvus
    目前支持最多 10 个不同的向量字段，为复杂的应用提供了灵活性。还提供了用于索引和重新排序方法的额外配置。你可以查看[Milvus 文档](https://milvus.io/docs/multi-vector-search.md)，了解可用的参数和选项。
- en: Closing words
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: With Milvus’s multi-vector search capabilities now accessible through LangChain,
    you can integrate hybrid search into your applications easily. This opens up new
    possibilities to apply different search strategies in your application, making
    it easy to tailor search logic to fit specific use cases. For us, it was a good
    opportunity to contribute to an open source project. Many of the libraries and
    tools we use on a daily basis are open source, and it’s nice to give back to the
    community. Hopefully it will be useful for others.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在通过 LangChain 可以轻松访问 Milvus 的多向量搜索功能，你可以轻松地将混合搜索集成到你的应用程序中。这为你在应用中应用不同的搜索策略打开了新的可能性，使得根据具体用例定制搜索逻辑变得更加容易。对我们来说，这是一个为开源项目做贡献的好机会。我们日常使用的许多库和工具都是开源的，能够回馈社区感到非常高兴。希望它能对其他人有所帮助。
- en: Finally, a big shout-out to [Erick Friis](https://github.com/efriis) and [Cheng
    Zi](https://github.com/zc277584121) for all the effort they put on *langchain-milvus*,
    and in these PRs particularly. This work couldn’t have happened without them.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，特别感谢[Erick Friis](https://github.com/efriis)和[Cheng Zi](https://github.com/zc277584121)在*langchain-milvus*项目中的所有努力，特别是在这些PR中。如果没有他们的付出，这项工作是无法完成的。
