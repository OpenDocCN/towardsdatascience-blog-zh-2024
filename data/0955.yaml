- en: Monitor Data Pipelines Using Snowflake’s Data Metric Functions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Snowflake 的数据指标函数监控数据管道
- en: 原文：[https://towardsdatascience.com/monitor-data-pipelines-using-snowflakes-data-metric-functions-0df71c46f04a?source=collection_archive---------8-----------------------#2024-04-15](https://towardsdatascience.com/monitor-data-pipelines-using-snowflakes-data-metric-functions-0df71c46f04a?source=collection_archive---------8-----------------------#2024-04-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/monitor-data-pipelines-using-snowflakes-data-metric-functions-0df71c46f04a?source=collection_archive---------8-----------------------#2024-04-15](https://towardsdatascience.com/monitor-data-pipelines-using-snowflakes-data-metric-functions-0df71c46f04a?source=collection_archive---------8-----------------------#2024-04-15)
- en: Build Trusted Data Platforms with Google SRE Principles
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用谷歌 SRE 原则构建可信的数据平台
- en: '[](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)[![Jess.Z](../Images/ae9505d75966ab9fb60a64366c24e4de.png)](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)
    [Jess.Z](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)[![Jess.Z](../Images/ae9505d75966ab9fb60a64366c24e4de.png)](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)
    [Jess.Z](https://medium.com/@jesszhangcyz?source=post_page---byline--0df71c46f04a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)
    ·6 min read·Apr 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0df71c46f04a--------------------------------)
    ·阅读时间 6 分钟·2024年4月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dd9da14923ac82a0d2d10724afb39253.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd9da14923ac82a0d2d10724afb39253.png)'
- en: Image generated by Dall-E
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Dall-E 生成的图像
- en: Do you have customers coming to you first with a data incident? Are your customers
    building their own data solutions due to un-trusted data? Does your data team
    spend unnecessarily long hours remediating undetected data quality issues instead
    of prioritising strategic work?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否遇到过客户首先因为数据事件而找上门？您的客户是否因为数据不可信而自己构建数据解决方案？您的数据团队是否在修复未检测到的数据质量问题上花费了不必要的长时间，而不是优先处理战略性工作？
- en: Data teams need to be able to paint a complete picture of their data systems
    health in order to gain trust with their stakeholders and have better conversations
    with the business as a whole.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据团队需要能够全面了解其数据系统的健康状况，以便赢得利益相关者的信任，并与整个业务进行更好的沟通。
- en: We can combine data quality dimensions with Google’s Site Reliability Engineering
    principles to measure the health of our Data Systems. To do this, assess a few
    Data Quality Dimensions that makes sense for your data pipelines and come up with
    **service level objectives (SLOs)**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将数据质量维度与谷歌的站点可靠性工程（SRE）原则结合起来，衡量我们数据系统的健康状况。为此，评估一些对您的数据管道有意义的数据质量维度，并制定**服务水平目标（SLOs）**。
- en: What are Service Level Objectives?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是服务水平目标？
- en: The service level terminology we will use in this article are ***service level
    indicators*** and ***service level objectives***. The two are borrowed principles
    from [Google’s SRE book](https://sre.google/sre-book/foreword/).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中我们将使用的服务水平术语是***服务水平指标***和***服务水平目标***。这两个概念是借鉴自 [谷歌 SRE 书籍](https://sre.google/sre-book/foreword/)的原则。
- en: '**service level** **indicator** — a carefully defined quantitative measure
    of some aspect of the level of service that is provided.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**服务水平** **指标** — 精确定义的、定量衡量某个服务层面水平的指标。'
- en: The indicators we’re familiar with in the software world are throughput, latency
    and up time (availability). These are used to measure the reliability of an application
    or website.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在软件领域常见的指标有吞吐量、延迟和正常运行时间（可用性）。这些用于衡量应用程序或网站的可靠性。
- en: '![](../Images/2a926ac827c514fef839a09eae44bb4a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a926ac827c514fef839a09eae44bb4a.png)'
- en: Typical Event
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 典型事件
- en: The indicators are then turned into objectives bounded by a *threshold.* The
    health of the software application is now “measurable” in a sense that we can
    now communicate the state of our application with our customers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这些指标被转化为受*阈值*限制的目标。软件应用的健康状况现在是“可度量的”，我们可以与客户沟通应用的状态。
- en: '**service level objective**: a target value or range of values for a service
    level that is measured by an SLI.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**服务水平目标**：由SLI衡量的服务水平的目标值或范围。'
- en: We have an intuitive understanding of the necessity of these quantitative measures
    and indicators in a typical user applications to reduce friction and establish
    trust with our customers. We need to start adopting a similar mindset when building
    out data pipelines in the data world.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们直观地理解这些定量衡量标准和指标在典型用户应用中的必要性，以减少摩擦并建立与客户的信任。在构建数据管道时，我们需要采用类似的思维方式。
- en: Data Quality Dimensions Translated into Service Level Terminology
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量维度转化为服务水平术语
- en: '![](../Images/55c5bc0af80a676b7e2b04d71b53f3c5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55c5bc0af80a676b7e2b04d71b53f3c5.png)'
- en: Data System with Failure
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据系统故障
- en: Lets say the user interacts with our application and generates X amounts of
    data every hour into our data warehouse, if the number of rows entering the warehouse
    suddenly decreases drastically, we can flag it as an issue. Then trace our timestamps
    from our pipelines to diagnose and treat the problem.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 假设用户与我们的应用程序互动并每小时生成X量的数据进入我们的数据仓库，如果进入仓库的行数突然大幅下降，我们可以将其标记为问题。然后，我们可以追踪管道中的时间戳来诊断并解决问题。
- en: We want to capture enough information about the data coming into our systems
    so that we can detect when anomalies occur. Most data teams tend to start with
    **Data Timeliness.** Is the expected amount of data arriving at the right time?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望捕获进入我们系统的数据的足够信息，以便在发生异常时能够检测到。大多数数据团队倾向于从**数据及时性**开始。预期的数据是否在正确的时间到达？
- en: 'This can be decomposed into the indicators:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以分解为以下指标：
- en: Data Availability — Has the expected amount of data arrived/been made available?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可用性——预期的数据是否已经到达/可用？
- en: Data Freshness — Has new data arrived at the expected time?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据新鲜度——新的数据是否按预期时间到达？
- en: '![](../Images/57963d8ebfec1d046bd5532fc3ac9ba4.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57963d8ebfec1d046bd5532fc3ac9ba4.png)'
- en: Data Quality Dimensions Translated into SLIs & SLOs
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量维度转化为SLIs和SLOs
- en: Once the system is stable it is important to maintain a good relationship with
    your customers in order to set the right objectives that are valuable to your
    stakeholders.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦系统稳定，保持与客户的良好关系就变得重要，以便设定对利益相关者有价值的正确目标。
- en: Concept of a Threshold…
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阈值的概念…
- en: How do we actually figure out how much data to expect and when? What is the
    right amount of data for all our different datasets? This is when we need to focus
    on the **threshold** concept as it does get tricky.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何实际确定期望多少数据以及何时到达？对于我们所有不同的数据集，正确的数据量是多少？这时我们需要关注**阈值**概念，因为它确实比较复杂。
- en: Assume we have an application where users mainly login to the system during
    the working hours. We expect around 2,000 USER_LOGIN events per hour between 9am
    to 5pm, and 100 events outside of those hours. If we use a single threshold value
    for the whole day, it would lead to the wrong conclusion. Receiving 120 events
    at 8pm is perfectly reasonable, but it would be concerning and should be investigated
    further if we only received 120 events at 2pm.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个应用程序，用户主要在工作时间登录系统。我们预计每天9点到下午5点之间大约会有2000次USER_LOGIN事件，而在其他时间则有100次。如果我们为一天使用一个单一的阈值，它会得出错误的结论。在晚上8点接收120个事件是完全合理的，但如果我们在下午2点只接收了120个事件，那就值得关注，并且应该进一步调查。
- en: '![](../Images/735733c28a94f26393e0e1e0ae938481.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/735733c28a94f26393e0e1e0ae938481.png)'
- en: Graph with line of threshold in green
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 显示阈值线的图表，绿色
- en: Because of this, we need to calculate a different expected value for each hour
    of the day for each different dataset — this is the threshold value. A metadata
    table would need to be defined that dynamically fetches the number of rows arrived
    each hour in order to get a resulting threshold that makes sense for each data
    source.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要为一天中的每个小时以及每个不同的数据集计算不同的期望值——这就是阈值。需要定义一个元数据表，动态地获取每小时到达的行数，以便得出对每个数据源有意义的阈值。
- en: There are some thresholds which can be extracted using timestamps as a proxy
    as explained above. This can be done using statistical measures such as averages,
    standard deviations or percentiles to iterate over your metadata table.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有些阈值可以使用时间戳作为代理提取，正如上面所解释的那样。这可以通过统计度量，如平均值、标准差或百分位数，来迭代你的元数据表。
- en: Depending on how creative you want to be, you can even introduce machine learning
    in this part of the process to help you set the threshold. Other thresholds or
    expectations would need to be discussed with your stakeholders as it would stem
    from having specific knowledge of the business to know what to expect.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的创造性程度，你甚至可以在这个过程的某一部分引入机器学习，帮助你设定阈值。其他阈值或预期需要与利益相关者讨论，因为这将依赖于对业务的具体了解，知道该预期什么。
- en: Technical Implementation in Snowflake
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Snowflake 中的技术实现
- en: The very first step to getting started is picking a few business critical dataset
    to build on top of before implementing a data-ops solution at scale. This is the
    easiest way to gather momentum and feel the impact of your data observability
    efforts.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 开始的第一步是选择几个对业务至关重要的数据集，在实现大规模的数据运维解决方案之前在其上构建。这是获取动力并感受数据可观察性工作影响的最简单方式。
- en: Many analytical warehouses already have inbuilt functionalities around this.
    For example, Snowflake has recently pushed out [Data Metric Functions](https://docs.snowflake.com/user-guide/data-quality-intro)
    in preview for Enterprise accounts to help data teams get started quickly.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多分析型数据仓库已经内建了相关功能。例如，Snowflake 最近为企业账户推出了[数据度量函数](https://docs.snowflake.com/user-guide/data-quality-intro)预览版，帮助数据团队快速入门。
- en: Data Metrics Functions is a wrapper around some of the queries we might write
    to get insights into our data systems. We can start with the system DMFs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 数据度量函数是我们可能写的一些查询的包装器，用来洞察我们的数据系统。我们可以从系统 DMF 开始。
- en: '![](../Images/215c9afdc5449c2e9be8cca9b2d89f55.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/215c9afdc5449c2e9be8cca9b2d89f55.png)'
- en: Snowflake System DMF
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Snowflake 系统 DMF
- en: We first need to sort out a few privileges…
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要整理一些权限…
- en: '![](../Images/6b46f55238e93746721c47cdf7ffc705.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b46f55238e93746721c47cdf7ffc705.png)'
- en: DMF Access Control Docs
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: DMF 访问控制文档
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**DATA_METRIC_USER** is a database role which may catch a few people out. It’s
    important to revisit the docs if you’re running into issues. The most likely reason
    is probably due to permissions.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**DATA_METRIC_USER** 是一个数据库角色，这可能会让一些人感到困惑。如果你遇到问题，重新查看文档非常重要。最可能的原因是由于权限问题。'
- en: Then, simply choose a DMF …
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，简单地选择一个 DMF …
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can schedule your DMFs to run using [Data Metric Schedule](https://docs.snowflake.com/en/sql-reference/parameters#label-data-metric-schedule)
    — an object parameter or your usual orchestration tool. The hard-work would still
    need to be done to determine your own thresholds in order to set the right SLOs
    for your pipelines.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用[数据度量调度](https://docs.snowflake.com/en/sql-reference/parameters#label-data-metric-schedule)
    —— 一个对象参数或者你常用的编排工具来安排你的 DMF 运行。仍然需要做大量工作来确定自己的阈值，以便为管道设置正确的 SLO。
- en: In Summary…
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结…
- en: Data teams need to engage with stakeholders to set better expectations about
    the data by using service level indicators and objectives. Introducing these metrics
    will help data teams move from reactively firefighting to a more proactive approach
    in preventing data incidents. This would allow energy to be refocused towards
    delivering business value as well as building a trusted data platform.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 数据团队需要与利益相关者合作，通过使用服务水平指标和目标来设定关于数据的更合理预期。引入这些指标将帮助数据团队从被动的应急响应转变为更主动的方式，防止数据事件的发生。这将使精力重新集中于交付业务价值，并构建一个可信的数据平台。
- en: '*Unless otherwise noted, all images are by the author.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者提供。*'
