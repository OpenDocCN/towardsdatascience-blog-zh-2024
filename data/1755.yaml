- en: A Python Engineer’s Introduction to 3D Gaussian Splatting (Part 3)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一位Python工程师的3D高斯喷溅入门（第3部分）
- en: 原文：[https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-3-398d36ccdd90?source=collection_archive---------5-----------------------#2024-07-18](https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-3-398d36ccdd90?source=collection_archive---------5-----------------------#2024-07-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-3-398d36ccdd90?source=collection_archive---------5-----------------------#2024-07-18](https://towardsdatascience.com/a-python-engineers-introduction-to-3d-gaussian-splatting-part-3-398d36ccdd90?source=collection_archive---------5-----------------------#2024-07-18)
- en: Part 3 of our Gaussian Splatting tutorial, showing how to render splats onto
    a 2D image
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯喷溅教程的第3部分，展示如何将喷溅渲染到2D图像上
- en: '[](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)[![Derek
    Austin](../Images/1bcc5955f32cb798988af5713baae212.png)](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)
    [Derek Austin](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)[![Derek
    Austin](../Images/1bcc5955f32cb798988af5713baae212.png)](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)
    [Derek Austin](https://medium.com/@dcaustin33?source=post_page---byline--398d36ccdd90--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)
    ·8 min read·Jul 18, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--398d36ccdd90--------------------------------)
    ·8分钟阅读·2024年7月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Finally, we reach the most intriguing phase of the Gaussian splatting process:
    rendering! This step is arguably the most crucial, as it determines the realism
    of our model. Yet, it might also be the simplest. In [part 1](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-1-e133b0449fc6)
    and [part 2](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df)
    of our series we demonstrated how to transform raw splats into a format ready
    for rendering, but now we actually have to do the work and render onto a fixed
    set of pixels. The authors have developed a fast rendering engine using CUDA,
    which can be somewhat challenging to follow. Therefore, I believe it is beneficial
    to first walk through the code in Python, using straightforward for loops for
    clarity. For those eager to dive deeper, all the necessary code is available on
    our G[itHub](https://github.com/dcaustin33/intro_to_gaussian_splatting).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进入了高斯喷溅过程中的最有趣的阶段：渲染！这一步可以说是最关键的，因为它决定了我们模型的真实感。然而，它也可能是最简单的。在我们系列的[第一部分](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-1-e133b0449fc6)和[第二部分](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df)中，我们展示了如何将原始的喷溅数据转换为可以渲染的格式，但现在我们实际上要做的是渲染工作，将其绘制到固定的像素集上。作者们使用CUDA开发了一个快速渲染引擎，虽然这个引擎有些难以跟随。因此，我认为首先通过Python代码讲解，使用简单的`for`循环来保持清晰，是非常有益的。对于那些渴望深入了解的人，所有必要的代码都可以在我们的[GitHub](https://github.com/dcaustin33/intro_to_gaussian_splatting)上找到。
- en: 'Let’s discuss how to render each individual pixel. From our previous [article](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df),
    we have all the necessary components: 2D points, associated colors, covariance,
    sorted depth order, inverse covariance in 2D, minimum and maximum x and y values
    for each splat, and associated opacity. With these components, we can render any
    pixel. Given specific pixel coordinates, we iterate through all splats until we
    reach a saturation threshold, following the splat depth order relative to the
    camera plane (projected to the camera plane and then sorted by depth). For each
    splat, we first check if the pixel coordinate is within the bounds defined by
    the minimum and maximum x and y values. This check determines if we should continue
    rendering or ignore the splat for these coordinates. Next, we compute the Gaussian
    splat strength at the pixel coordinate using the splat mean, splat covariance,
    and pixel coordinates.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论如何渲染每一个独立的像素。从我们之前的[文章](https://medium.com/towards-data-science/a-python-engineers-introduction-to-3d-gaussian-splatting-part-2-7e45b270c1df)中，我们已经具备了所有必要的组件：2D
    点、关联的颜色、协方差、排序后的深度顺序、2D 逆协方差、每个溅射的最小和最大 x 和 y 值，以及关联的不透明度。借助这些组件，我们可以渲染任何像素。给定特定的像素坐标，我们会遍历所有的溅射，直到达到饱和度阈值，按照溅射的深度顺序相对于相机平面（先投影到相机平面，然后按深度排序）。对于每个溅射，我们首先检查像素坐标是否在由最小和最大
    x 和 y 值定义的范围内。这个检查决定了我们是继续渲染还是忽略这些坐标的溅射。接下来，我们使用溅射的均值、溅射的协方差和像素坐标来计算该像素位置的高斯溅射强度。
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We multiply this weight by the splat’s opacity to obtain a parameter called
    alpha. Before adding this new value to the pixel, we need to check if we have
    exceeded our saturation threshold. We do not want a splat behind other splats
    to affect the pixel coloring and use computing resources if the pixel is already
    saturated. Thus, we use a threshold that allows us to stop rendering once it is
    exceeded. In practice, we start our saturation threshold at 1 and then multiply
    it by min(0.99, (1 — alpha)) to get a new value. If this value is less than our
    threshold (0.0001), we stop rendering that pixel and consider it complete. If
    not, we add the colors weighted by the saturation * (1 — alpha) value and update
    the saturation as new_saturation = old_saturation * (1 — alpha). Finally, we loop
    over every pixel (or every 16x16 tile in practice) and render. The complete code
    is shown below.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个权重与溅射的不透明度相乘，以获得一个名为 alpha 的参数。在将这个新值添加到像素之前，我们需要检查是否超过了我们的饱和度阈值。如果像素已经饱和，我们不希望其他位于后面的溅射影响像素的着色并浪费计算资源。因此，我们使用一个阈值来确保一旦超过这个阈值，我们就停止渲染。实际上，我们将饱和度阈值从
    1 开始，然后将其与 min(0.99, (1 — alpha)) 相乘得到一个新值。如果该值小于我们的阈值（0.0001），我们就停止渲染这个像素，并认为它已经完成。如果不是，我们将按饱和度
    * (1 — alpha) 的值加权颜色，并更新饱和度为 new_saturation = old_saturation * (1 — alpha)。最后，我们遍历每一个像素（或者实际中是每个
    16x16 的瓦片）进行渲染。完整的代码如下所示。
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we can render a pixel we can render a patch of an image, or what the
    authors refer to as a tile!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以渲染一个像素，那么我们也可以渲染一张图像的一部分，或者说是作者所称的一个瓦片！
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: And finally we can use all of those tiles to render an entire image. Note how
    we check to make sure the splat will actually affect the current tile (x_in_tile
    and y_in_tile code).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用所有这些瓦片来渲染整个图像。注意我们如何检查确保溅射实际上会影响当前瓦片（x_in_tile 和 y_in_tile 代码）。
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: At long last now that we have all the necessary components we can render an
    image. We take all the 3D points from the treehill dataset and initialize them
    as gaussian splats. In order to avoid a costly nearest neighbor search we initialize
    all scale variables as .01 (Note that with such a small variance we will need
    a strong concentration of splats in one spot to be visible. Larger variance makes
    the process quite slow.). Then all we have to do is call render_image with the
    image number we are trying to emulate and as you an see we get a sparse set of
    point clouds that resemble our image! (Check out our bonus section at the bottom
    for an equivalent CUDA kernel using pyTorch’s nifty tool that compiles CUDA code!)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，既然我们已经具备了所有必要的组件，我们就可以渲染图像了。我们从 treehill 数据集中获取所有的 3D 点，并将它们初始化为高斯溅射。为了避免代价高昂的最近邻搜索，我们将所有的尺度变量初始化为
    0.01（注意，使用如此小的方差时，我们需要在一个位置上有较强的溅射集中才能使其可见。较大的方差会使得过程变得相当缓慢）。然后我们所需要做的就是调用 render_image，传入我们尝试模拟的图像编号，正如你所看到的，我们得到了一个稀疏的点云集，看起来像我们的图像！（查看底部的附加部分，了解使用
    pyTorch 的便捷工具编译 CUDA 代码的等效 CUDA 内核！）
- en: '![](../Images/e598799a3b44d0da6514a6f8399487a4.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e598799a3b44d0da6514a6f8399487a4.png)'
- en: Actual image, CPU implementation, CUDA implementation. Image by author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 实际图像，CPU 实现，CUDA 实现。图片来自作者。
- en: While the backwards pass is not part of this tutorial, one note should be made
    that while we start with only these few points, we soon have hundreds of thousands
    of splats for most scenes. This is caused by the breaking up of large splats (as
    defined by larger variance on axes) into smaller splats and removing splats that
    have extremely low opacity. For instance, if we truly initialized the scale to
    the mean of the three closest nearest neighbors we would have a majority of the
    space covered. In order to get fine detail we would need to break these down into
    much smaller splats that are able to capture fine detail. They also need to populate
    areas with very few gaussians. They refer to these two scenarios as over reconstruction
    and under reconstruction and define both scenarios by large gradient values for
    various splats. They then split or clone the splats depending on size (see image
    below) and continue the optimization process.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然反向传递不在本教程的内容中，但有一点需要提到的是，尽管我们一开始只有这些点，但在大多数场景中，我们很快会有数十万个 splats。这是由于将大 splats（由较大的轴方差定义）分解为更小的
    splats，并移除具有极低透明度的 splats。例如，如果我们真的将缩放初始化为三个最邻近点的均值，我们将覆盖大部分空间。为了获得精细的细节，我们需要将这些
    splats 分解成更小的 splats，以便捕捉精细的细节。它们还需要填充那些高斯分布稀少的区域。它们将这两种情况称为过度重建和欠重建，并通过各种 splats
    的大梯度值来定义这两种情况。然后根据 splats 的大小拆分或克隆它们（见下图），并继续优化过程。
- en: Although the backward pass is not covered in this tutorial, it’s important to
    note that we start with only a few points but soon have hundreds of thousands
    of splats in most scenes. This increase is due to the splitting of large splats
    (with larger variances on axes) into smaller ones and the removal of splats with
    very low opacity. For instance, if we initially set the scale to the mean of the
    three nearest neighbors, most of the space would be covered. To achieve fine detail,
    we need to break these large splats into much smaller ones. Additionally, areas
    with very few Gaussians need to be populated. These scenarios are referred to
    as over-reconstruction and under-reconstruction, characterized by large gradient
    values for various splats. Depending on their size, splats are split or cloned
    (see image below), and the optimization process continues.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管反向传递不在本教程的范围内，但需要注意的是，虽然我们一开始只有几个点，但很快在大多数场景中会有数十万个 splats。这一增加是由于将大 splats（在轴上具有较大方差）拆分成更小的
    splats，并移除透明度非常低的 splats。例如，如果我们最初将缩放设置为三个最近邻点的均值，大部分空间会被覆盖。为了实现更细致的细节，我们需要将这些大
    splats 分解成更小的 splats。此外，少数高斯分布的区域也需要填充。这些场景被称为过度重建和欠重建，特征是各种 splats 的大梯度值。根据它们的大小，splats
    会被拆分或克隆（见下图），优化过程继续进行。
- en: '![](../Images/1028ac2dcb239fa565cc73156eef6e93.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1028ac2dcb239fa565cc73156eef6e93.png)'
- en: 'From the Author’s original paper on how gaussians are split or cloned in training.
    Source: [https://arxiv.org/abs/2308.04079](https://arxiv.org/abs/2308.04079)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 来自作者原始论文，讨论在训练过程中如何对高斯分布进行拆分或克隆。来源：[https://arxiv.org/abs/2308.04079](https://arxiv.org/abs/2308.04079)
- en: And that is an easy introduction to Gaussian Splatting! You should now have
    a good intuition on what exactly is going on in the forward pass of a gaussian
    scene render. While a bit daunting and not exactly neural networks, all it takes
    is a bit of linear algebra and we can render 3D geometry in 2D!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是高斯 Splatting 的简单介绍！你现在应该对高斯场景渲染的前向传递过程有了很好的直觉。虽然它有点复杂，并不完全是神经网络，但只需一点线性代数，我们就能在
    2D 中渲染 3D 几何！
- en: Feel free to leave comments about confusing topics or if I got something wrong
    and you can always connect with me on LinkedIn or twitter!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对某些内容有疑问，或者我哪里弄错了，随时可以在评论区留言，你也可以通过 LinkedIn 或 Twitter 与我联系！
- en: Bonus — CUDA Code
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奖金 — CUDA 代码
- en: Use PyTorch’s CUDA compiler to write a custom CUDA kernel!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的 CUDA 编译器编写自定义 CUDA 核心！
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
