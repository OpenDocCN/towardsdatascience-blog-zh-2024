- en: Diving Deep into AutoGen and Multi-Agent Frameworks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨AutoGen与多智能体框架
- en: 原文：[https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=collection_archive---------4-----------------------#2024-06-28](https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=collection_archive---------4-----------------------#2024-06-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=collection_archive---------4-----------------------#2024-06-28](https://towardsdatascience.com/diving-deep-into-autogen-and-agentic-frameworks-3e161fa3c086?source=collection_archive---------4-----------------------#2024-06-28)
- en: 'This blog post will go into the details of the “AutoGen: Enabling Next-Gen
    LLM Applications via Multi-Agent Conversation” paper and the AutoGen project'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '本文将深入探讨《AutoGen: 通过多智能体对话实现下一代大型语言模型应用》论文以及AutoGen项目的细节'
- en: '[](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)[![Matthew
    Gunton](../Images/6f5a9530ad5252aa3f2fae87b3f272b1.png)](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)
    [Matthew Gunton](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)[![Matthew
    Gunton](../Images/6f5a9530ad5252aa3f2fae87b3f272b1.png)](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)
    [Matthew Gunton](https://medium.com/@mgunton7?source=post_page---byline--3e161fa3c086--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)
    ·11 min read·Jun 28, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3e161fa3c086--------------------------------)
    ·11分钟阅读·2024年6月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/4139c2cd244cc4350a926ece5265cdb5.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4139c2cd244cc4350a926ece5265cdb5.png)'
- en: Image by Author — SDXL
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片 — SDXL
- en: Agents have recently been all over technical news sites. While people have big
    aspirations for what these programs can do, there has not been much discussion
    about the frameworks that should power these agents. From a high-level, an agent
    is simply a program, usually powered by a Large Language Model (LLM) that accomplishes
    an action. While anyone can prompt a LLM, the key distinguisher for agentic systems
    is their consistent performance in the face of ambiguous tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 近期，智能体成为技术新闻网站的热议话题。尽管人们对这些程序的潜力抱有很大期望，但关于应该支持这些智能体的框架却鲜有讨论。从高层次来看，智能体不过是一个程序，通常由大型语言模型（LLM）驱动，执行某种操作。虽然任何人都可以向LLM发出提示，但智能体系统的关键区别在于它们在面对模糊任务时的持续表现。
- en: To get this kind of consistent performance is not trivial. While prompting techniques
    like Chain-of-Thought, reflection, and others have been shown to improve LLM performance,
    LLMs tend to improve radically when given proper feedback during a chat session.
    This can look like a scientist pointing out a flaw in the chat bot’s response,
    or a programmer copying in the compiler message when they try to run the LLM’s
    code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种持续的表现并非易事。尽管像思维链、反思等提示技术已被证明能提高LLM的表现，但LLM在聊天过程中接受适当反馈时，往往会显著改善。这可能表现为科学家指出聊天机器人回答中的缺陷，或程序员在尝试运行LLM代码时复制编译器消息。
- en: Thus, as we try to make these agentic systems more consistently performant,
    one might reasonably ask if we can find a way to have multiple LLMs giving each
    other feedback, thus…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们努力使这些智能体系统的表现更加稳定时，人们可能会合理地问，是否可以找到一种方法，让多个LLM相互反馈，从而……
