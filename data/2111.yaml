- en: 'Causal Machine Learning for Customer Retention: a Practical Guide with Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果机器学习在客户保持中的应用：一份使用 Python 的实用指南
- en: 原文：[https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30](https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30](https://towardsdatascience.com/causal-machine-learning-for-customer-retention-a-practical-guide-with-python-6bd959b25741?source=collection_archive---------1-----------------------#2024-08-30)
- en: '![](../Images/4444080567c58b7b2c0d88100cc89dd9.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4444080567c58b7b2c0d88100cc89dd9.png)'
- en: Photo by [Claudio Schwarz](https://unsplash.com/@purzlbaum?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Claudio Schwarz](https://unsplash.com/@purzlbaum?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: An accessible guide to leveraging causal machine learning for optimizing client
    retention strategies
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一本关于利用因果机器学习优化客户保持策略的通俗易懂指南
- en: '[](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[![Arthur
    Cruiziat](../Images/32ae05f184523057a5a2e81184f9bc67.png)](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    [Arthur Cruiziat](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[![Arthur
    Cruiziat](../Images/32ae05f184523057a5a2e81184f9bc67.png)](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    [Arthur Cruiziat](https://medium.com/@arthur.cruiziat?source=post_page---byline--6bd959b25741--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    ·20 min read·Aug 30, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--6bd959b25741--------------------------------)
    ·阅读时长：20分钟·2024年8月30日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Details of this series
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本系列详情
- en: This article is the second in a series on uplift modeling and causal machine
    learning. The idea is to dive deep into these methodologies both from a business
    and a technical perspective.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是关于提升建模和因果机器学习系列中的第二篇。我们的目的是从商业和技术两个角度深入探讨这些方法论。
- en: Before jumping into this one, I highly recommend reading the previous episode
    which explains what uplift modeling is and how it can help your company in general.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解这一部分之前，我强烈建议先阅读前一篇文章，该文解释了什么是提升建模，以及它如何整体帮助您的公司。
- en: Link can be found below.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 链接见下文。
- en: '[](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
    [## From insights to impact: leveraging data science to maximize customer value'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
    [## 从洞察到影响：利用数据科学最大化客户价值'
- en: 'Uplift modeling: how causal machine learning transforms customer relationships
    and revenue'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升建模：因果机器学习如何改变客户关系和收入
- en: towardsdatascience.com](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/from-insights-to-impact-leveraging-data-science-to-maximize-customer-value-9c9af354e192?source=post_page-----6bd959b25741--------------------------------)
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Picture this: you’ve been a client of a bank for a couple years. However, for
    a month or two, you’ve been considering leaving because their application has
    become too complicated. Suddenly, an employee of the bank calls you. He asks about
    your experience and ends up quickly explaining to you how to use the app. In the
    meantime, your daughter, who’s a client of the same bank also thinks about leaving
    them because of their trading fees; she thinks they’re too expensive. While about
    to unsubscribe, out of the blue, she receives a voucher allowing her to trade
    for free for a month! How is that even possible?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：你是某家银行的客户已经有几年了。然而，过去一两个月，你一直在考虑是否离开，因为他们的应用程序变得越来越复杂。突然，银行的一名员工打电话给你。他询问了你的体验，并很快向你解释了如何使用该应用。与此同时，你的女儿也是这家银行的客户，她也因为交易费用太高而考虑离开她们。在快要取消服务时，突然，她收到了一张优惠券，允许她一个月内免费交易！这怎么可能？
- en: 'In my previous article, I introduced the mysterious technique behind this level
    of personalisation: uplift modeling. When traditional approaches usually predict
    an outcome — e.g. the probability of churn of a customer— , uplift modeling predicts
    the potential result of an action taken on a customer. The likelihood of a customer
    staying if called or if offered a voucher, for example!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的文章中，我介绍了这一层次个性化背后的神秘技术：提升建模。当传统方法通常预测一个结果——例如客户流失的概率——时，提升建模预测的是对客户采取某个行动后的潜在结果。例如，预测如果给客户打电话或提供优惠券，客户留下来的可能性！
- en: This approach allows us to target the right customers — as we’ll be removing
    customers who wouldn’t react positively to our approach — but also to increase
    our chance of success by tailoring our approach to each customer. Thanks to uplift
    modeling, not only do we focus our resources toward the right population, we also
    maximise their impact!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法使我们能够针对正确的客户——因为我们将剔除那些对我们的方法反应不佳的客户——同时通过根据每个客户的特点量身定制我们的策略，增加成功的机会。得益于提升建模（uplift
    modeling），我们不仅能够将资源集中在合适的群体上，还能够最大化其影响！
- en: 'Sounds interesting, wouldn’t you agree? Well this is your lucky day as in this
    article we’ll dive deep into the implementation of this approach by solving a
    concrete example: improving our retention. We’ll go through every step, from defining
    our precise use case to evaluating our models results. Our goal today is to provide
    you with the right knowledge and tools to be able to apply this technique within
    your own organisation, adapted to your own data and use case, of course.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很有意思，不是吗？嗯，今天是你的幸运日，因为在这篇文章中，我们将通过解决一个具体的例子——提升客户留存率，深入探讨这种方法的实施。我们将逐步走过每一步，从定义精确的用例到评估模型结果。我们今天的目标是为你提供正确的知识和工具，使你能够在自己的组织中应用这项技术，当然，这需要根据你自己的数据和用例进行调整。
- en: 'Here’s what we’ll cover:'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以下是我们将要涵盖的内容：
- en: We’ll start by **clearly defining our use case.** What is churn? Who do we target?
    What actions will we set up to try and retain our clients with?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从**清晰定义我们的用例**开始。什么是客户流失？我们将目标客户定位在哪里？我们将采取哪些行动来试图留住客户？
- en: Then, **we’ll look into getting the right data for the job.** What data do we
    need to implement uplift modeling and how to get it?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，**我们将讨论获取适合的工作数据**。为了实施提升建模，我们需要哪些数据，如何获得这些数据？
- en: After that, we’ll look into the actual modeling,focusing on u**nderstanding
    the various models behind uplift modeling**.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将深入了解实际的建模，专注于**理解提升建模背后的各种模型**。
- en: 'Then, we’ll apply our newly acquired knowledge to a **first case with a single
    retention action: an email campaign.**'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将运用新学到的知识来解决**第一个案例，涉及单一的留存行动：一场电子邮件活动**。
- en: Finally, we’ll deep dive into a **more complicated implementation with** **many
    treatments, approaching user-level personalisation**
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将深入探讨一个**更复杂的实施案例，涉及多个处理方法，接近用户级别的个性化**。
- en: 'Our use case: improving customer retention'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的用例：提升客户留存率
- en: Before we can apply uplift modeling to improve customer retention, we need to
    clearly define the context. What constitutes “churn” in our business context?
    Do we want to target specific users? If yes, why? Which actions do we plan on
    setting up to retain them? Do we have budget constraints? Let’s try answering
    these questions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够应用提升建模来提升客户留存率之前，我们需要清晰地定义背景。在我们的业务环境中，什么构成了“流失”？我们是否希望定位特定的用户？如果是，为什么？我们计划采取哪些行动来留住他们？我们有预算限制吗？让我们尝试回答这些问题。
- en: Defining Churn
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义客户流失
- en: 'This is our first step. By precisely and quantitatively defining churn, we’ll
    be able to define retention and understand where we stand, how it has evolved
    and, if needed, take action. The churn definition you’ll choose will 100% depend
    on your business model and sector. Here are some factors to consider:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的第一步。通过精确和定量地定义流失，我们将能够定义留存，并了解我们目前的状况、其变化情况以及在需要时采取措施。你选择的流失定义将100%取决于你的商业模式和行业。以下是一些需要考虑的因素：
- en: If you’re in a transaction-based company, you can look at transaction frequency,
    or transaction volumes evolution. You could also look at the time since the last
    transaction occured or a drop in account activity.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你所在的公司是基于交易的公司，你可以查看交易频率，或者交易量的变化。你还可以关注自上次交易以来的时间，或账户活动的下降。
- en: If you’re in a subscription based company, it can be as simple as looking at
    users who have unsubscribed, or subscribed users who have stopped using the product.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你所在的公司是基于订阅的公司，可能只需要查看那些已取消订阅的用户，或者那些已订阅但停止使用产品的用户。
- en: If you’re working in a transaction based tech company, churn could be defined
    as “*customer who has not done a transaction in 90 days”*, whereas if you’re working
    for a mobile app you may prefer to define it as *“customer who has not logged
    in in 30 days*”. Both the time frame and the nature of churn has to be defined
    beforehand as flagging churned user will be our first step.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一家基于交易的科技公司工作，流失可以定义为“*90天内没有进行交易的客户*”，而如果你在一家移动应用公司工作，你可能更倾向于将其定义为*“30天内没有登录的客户*”。流失的时间框架和性质必须提前定义，因为标记流失用户将是我们的第一步。
- en: The complexity of your definition will depend on your company’s specificities
    as well as the number of metrics you want to consider. However, the idea is to
    set up definitions that provide thresholds that are easy to understand and that
    enable us identify churners.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你的定义复杂度将取决于公司特点以及你希望考虑的度量标准数量。然而，目标是设定提供易于理解的阈值的定义，并能够帮助我们识别流失用户。
- en: Churn Prediction Window
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流失预测窗口
- en: 'Now that we know what churn is, we need to define exactly what we want to avoid.
    What I mean is, do we want to prevent customers from churning within the next
    15 days or 30 days? Based on the answer here, you’ll have to organise your data
    in a specific manner, and define different retention actions. I would recommend
    not to be too optimistic here for 2 reasons:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了流失的定义，我们需要明确我们想要避免的是什么。我指的是，我们是想防止客户在接下来的15天内流失，还是30天内流失？根据这里的答案，你将不得不以特定的方式组织数据，并定义不同的留存行动。我建议在这里不要过于乐观，原因有两个：
- en: The longer the time horizon the harder it is for a model to have good performances.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间跨度越长，模型的表现越难保持良好。
- en: The longer we wait after the treatment, the harder it will be to capture its
    effect.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在采取措施后等待的时间越长，捕捉其效果就越困难。
- en: So let’s be reasonable here. If our definition of churn encompasses a 30-day
    timeframe, let’s go with a 30 days horizon and let’s try to limit churn within
    the next 30 days.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们在这里保持合理。如果我们将流失定义为30天的时间框架，那么我们就选择30天的预测期，并尝试限制未来30天内的流失。
- en: The idea is that our timeframe must give us enough time to implement our retention
    strategies and observe their impact on user behavior, while maintaining our models’
    performances.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 关键是，我们的时间框架必须为我们实施留存策略并观察其对用户行为的影响提供足够的时间，同时保持模型的性能。
- en: Selecting Target Users [Optional]
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择目标用户 [可选]
- en: 'Another question we need to answer is: are we targeting a specific population
    with our retention actions? Multiple reasons could motivate such an idea.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要回答的问题是：我们是否针对特定人群进行留存行动？可能有多种原因促使这样一个想法。
- en: We noticed an increase in churn in a specific segment.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们注意到某一特定细分市场中的流失率上升。
- en: We want to target highly valuable customers to maximize our ROI with those actions.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望锁定高价值的客户，以便通过这些行动最大化我们的投资回报率。
- en: We want to target new customers to ensure a durable activation.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望锁定新客户，以确保持久的激活。
- en: We want to target customers that are likely to churn soon.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要锁定那些可能很快流失的客户。
- en: Depending on your own use case, you may want to select only a subset of your
    customers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的具体使用案例，你可能只希望选择一部分客户。
- en: In our case, we’ll choose to target clients with a higher probability of churn,
    so that we target customers that need us most.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将选择锁定那些流失概率较高的客户，以便我们能优先关注那些最需要我们的客户。
- en: Defining retention Actions
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义留存行动
- en: 'Finally, we have to select the actual retention actions we want to use on our
    clients. This is not an easy one, and working alongside your business stakeholders
    here is probably a good idea. In our case, we’ll select 4 different actions:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须选择要对客户采取的实际留存行动。这并不容易，与业务相关方一起工作可能是个好主意。在我们的案例中，我们将选择四种不同的行动：
- en: Personalized email
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 个性化邮件
- en: In-app notifications highlighting new features or opportunities
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用内通知，突出新功能或机会
- en: Directly calling our customer
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接联系我们的客户
- en: Special offers or discounts — *another uplift model could help us identify the
    best voucher amount, should we explore that next?*
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特别优惠或折扣 —— *另一个提升模型可能帮助我们确定最佳优惠金额，我们下一步应该探索这个吗？*
- en: Our uplift model will help us determine which of these actions (if any) is most
    likely to be effective for each individual user.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的提升模型将帮助我们确定哪些行动（如果有的话）最有可能对每个用户有效。
- en: We’re ready! We defined churn, picked a prediction window, and selected the
    actions we want to retain our customers with. Now, the fun part begins, let’s
    gather some data and build a causal machine learning model!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备好了！我们定义了流失，选择了预测窗口，并选择了我们希望用来留存客户的行动。现在，有趣的部分开始了，让我们收集一些数据并构建一个因果机器学习模型！
- en: 'Data gathering: the foundation of our uplift model'
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集：我们的提升模型的基础
- en: Building an effective uplift model requires a good dataset combining both existing
    user information with experimental data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个有效的提升模型需要一个良好的数据集，结合现有用户信息和实验数据。
- en: Leveraging existing user data
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用现有的用户数据
- en: 'First, let’s look at our available data. Tech companies usually have access
    to a lot of those! In our case, we need customer level data such as:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看可用的数据。科技公司通常能访问到这些数据！在我们的案例中，我们需要客户层级的数据，如：
- en: Customer information (like age, geography, gender, acquisition channel etc.)
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户信息（如年龄、地域、性别、获取渠道等）
- en: Product specifics (creation or subscription date, subscription tier etc.)
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 产品具体信息（创建或订阅日期、订阅层级等）
- en: Transactions information ( frequency of transactions, average transaction value,
    total spend, types of products/services purchased, time since last transaction
    etc.)
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交易信息（交易频率、平均交易金额、总消费、购买的产品/服务类型、上次交易以来的时间等）
- en: Engagement (e.g., login frequency, time spent on platform, feature usage statistics,
    etc.)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参与度（例如，登录频率、在平台上花费的时间、功能使用统计等）
- en: 'We can look at this data raw, but what brings even more value is to understand
    how it evolves over time. It enables us to identify behavioral patterns that will
    likely improve our models’ performances. Lucky for us, it’s quite simple to do,
    we just have to look at our data from a different perspective; here are a few
    transformations that can help:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看这些原始数据，但更有价值的是理解它们随时间的变化。这使我们能够识别可能改善模型表现的行为模式。幸运的是，这相当简单，我们只需从不同的角度来看待数据；以下是一些可以帮助我们的转化方法：
- en: Taking moving averages (7, 30 days…) of our main usage metrics — transactions
    for instance.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对我们主要的使用指标（例如交易量）进行移动平均（7天、30天等）。
- en: Looking at the percentage changes over time.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看一段时间内的百分比变化。
- en: Aggregating our data at different time scales such as daily, weekly etc.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同时间尺度上聚合我们的数据，比如每天、每周等。
- en: Or even adding seasonality indicators such as the day of week or week of year.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者甚至可以添加季节性指标，比如星期几或一年中的第几周。
- en: These features bring “dynamic information” that could be valuable when it comes
    to detect future changes! Understanding more precisely which features we should
    select is beyond the scope of this article, however those approaches are best
    practices when it comes to work with temporal data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能带来了“动态信息”，在检测未来变化时可能非常有价值！更精确地了解我们应该选择哪些特征超出了本文的范围，然而这些方法是处理时间数据时的最佳实践。
- en: Remember, our goal is to create a comprehensive user profile that evolves over
    time. This temporal data will serve as the foundation of our uplift model, **enabling
    us to predict not who might churn, but who is most likely to respond positively
    to our retention efforts.**
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住，我们的目标是创建一个随时间演变的全面用户画像。这些时间数据将作为我们提升模型的基础，**使我们能够预测的不是谁可能流失，而是哪些用户最有可能对我们的留存措施做出积极响应。**
- en: Gathering Experimental Data for Uplift Modeling
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集实验数据以进行提升建模
- en: The second part of our data gathering journey is about collecting data related
    to our retention actions. Now, uplift modeling does not require experimental data.
    If you have historical data because of past events — you may already have sent
    emails to customers or offered vouchers — you can leverage those. However, the
    more recent and unbiased your data is, the better your results will be. Debiasing
    observational or non randomized data requires extra steps that we will not discuss
    here.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据收集旅程的第二部分是关于收集与我们留存行动相关的数据。现在，提升建模并不要求必须有实验数据。如果你有过去事件的历史数据——比如你可能已经向客户发送了邮件或提供了优惠券——你可以利用这些数据。然而，数据越新且越不偏，结果会越好。去偏化观察性或非随机数据需要额外的步骤，这里我们不做讨论。
- en: So what exactly do we need? Well, we need to have an idea of the impact of the
    actions you plan to take. We need to set up a randomized experiment where we test
    these actions. A lot of extremely good articles already discuss how to set those
    up, and I will not dive into it here. I just want to add that the better the setup,
    and the bigger the training set, the better it is us!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们到底需要什么呢？嗯，我们需要了解你计划采取的行动的影响。我们需要设置一个随机化实验来测试这些行动。很多非常优秀的文章已经讨论了如何设置这些实验，我在这里就不详细展开了。我只想补充一点，设置越好，训练集越大，对我们越有利！
- en: After the experiment, we’ll obviously analyse the results. And while those are
    not helping us directly in our quest, it will provide us with additional understanding
    of the expected impact of our treatments as well as a good effect baseline we’ll
    try to outperform with our models. Not to bore you too much with definitions and
    acronyms, but the result of a randomized experiment is called “Average treatment
    effect” or ATE. On our side, we’re looking to estimate the **Conditional Average
    Treatment Effect** (CATE), also known as **Individual Treatment Effect** (ITE).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 实验之后，我们显然会分析结果。虽然这些结果不会直接帮助我们达成目标，但它们将为我们提供有关治疗预期影响的额外理解，以及我们将尝试超越的良好效果基准。为了避免让你感到无聊，定义和缩写我们就不再展开了，但随机化实验的结果称为“平均处理效应”或ATE。在我们这边，我们希望估计**条件平均处理效应**（CATE），也称为**个体处理效应**（ITE）。
- en: '*While experimental data is ideal, uplift modeling can still provide insights
    with observational data if an experiment isn’t feasible. If not randomized, several
    techniques exists to debias our dataset, such as propensity score matching. The
    key is to have a rich dataset that captures user characteristics, behaviors, and
    outcomes in relation to our retention efforts.*'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*虽然实验数据是理想的，但如果实验不可行，提升建模仍然可以通过观察性数据提供洞察。如果不是随机化的，存在多种技术来去偏我们的数据集，例如倾向得分匹配。关键是要有一个丰富的数据集，能够捕捉用户特征、行为和与我们的留存努力相关的结果。*'
- en: Generating synthetic data
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成合成数据
- en: For the purpose of this example, we’ll be generating synthetic data using the
    **causalml package from Uber**. Uber has communicated a lot on uplift modeling
    and even created an easy to use and well documented Python package.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用**Uber的causalml包**生成合成数据。Uber已经在提升建模方面做了大量的工作，甚至创建了一个易于使用且文档完善的Python包。
- en: Here’s how we can generate our synthetic data if you’re curious about it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对生成合成数据感兴趣，这里是我们如何生成它的方法。
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Ouf final data should be organized like this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终的数据应组织如下：
- en: '![](../Images/8940c6f65a748c68ab51d0be26a39b51.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8940c6f65a748c68ab51d0be26a39b51.png)'
- en: dataset description
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集描述
- en: In a “real life use case”, this data would be aggregated at time level, for
    instance this would be for each user a daily or weekly aggregation of data gathered
    before we reached out to them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在“实际使用案例”中，这些数据通常会按时间进行汇总，例如，针对每个用户，我们会在接触他们之前，对收集到的数据进行每日或每周的汇总。
- en: X_1 to X_n would be our user level features
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: X_1到X_n将是我们的用户级特征
- en: T would be the actual treatment (1 or 0, treatment or control, treatment 1,
    treatment 2, control depending on your use case)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T将是实际的处理（1或0，处理或控制，处理1，处理2，控制，具体取决于你的使用案例）
- en: 'And Y is the actual outcome: did the user stay or not?'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Y是实际的结果：用户是留了下来还是没有？
- en: Data preparation
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'In our case, in order to analyse both our use cases, we need further preparation.
    Let’s create 2 distinct datasets — training and a testing set — for each use case:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，为了分析两个使用案例，我们需要进一步的准备。让我们为每个使用案例创建两个不同的数据集——一个训练集和一个测试集：
- en: 'First use case: a single treatment case, where we’ll focus on a single retention
    strategy: sending email to our customers.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个使用案例：单一处理案例，我们将专注于单一的留存策略：向客户发送电子邮件。
- en: 'Second use case: a multi treatment case, where we’ll compare the effectiveness
    of different treatments and most importantly find the best one for each customer.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个使用案例：多治疗案例，我们将比较不同治疗方法的有效性，最重要的是为每个客户找到最合适的治疗方法。
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that our data is ready, let’s go through a bit of theory and investigate
    the different approaches available to us!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据准备好了，让我们稍微了解一下理论，并探讨可供选择的不同方法！
- en: Understanding uplift modeling approaches
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解提升建模方法
- en: As we now know, uplift modeling uses machine learning algorithms to estimate
    th**e heterogeneous treatment effect** of an intervention on a population. This
    modelling approach focuses on the **Conditional Average Treatment Effect** (CATE),
    which quantifies the expected difference in outcome with and without the intervention
    for our customers.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们现在所知道的，提升建模使用机器学习算法来估计干预对人群的**异质性治疗效应**。这种建模方法关注的是**条件平均治疗效应**（CATE），它量化了有无干预情况下，我们的客户在结果上的预期差异。
- en: 'Here are the main models we can use to estimate it:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们可以用来估计它的主要模型：
- en: Direct uplift modeling
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接提升建模
- en: This approach is the simplest one. We simply use a specific algorithm, such
    as an uplift decision tree, which loss function is optimized to solve this problem.
    **These models are designed to maximize the difference in outcomes between treated
    and untreated groups within the same model.**
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种方法是最简单的。我们只需使用特定的算法，如提升决策树，其损失函数经过优化以解决这一问题。**这些模型旨在最大化同一模型中处理组和未处理组之间的结果差异。**
- en: We’ll be using an **Uplift Random ForestClassifier** as an example of this.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用**提升随机森林分类器**作为这一例子的模型。
- en: Meta-learners
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元学习者
- en: Meta-learners use known machine learning models to estimate the CATE. They can
    combine multiple models used in different ways, or be trained on the predictions
    of other models.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元学习者使用已知的机器学习模型来估计CATE。它们可以结合以不同方式使用的多个模型，或者在其他模型的预测结果上进行训练。
- en: 'While many exist, we’ll focus on two types : the **S-Learner and the T-Learner**'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然有许多方法，我们将重点介绍两种：**S-Learner和T-Learner**
- en: Let’s quickly understand what those are!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速了解这些是什么！
- en: 1\. S-Learner (Single-Model)
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. S-Learner（单模型）
- en: '![](../Images/408c1ab77023700f4a98eab8514625c4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/408c1ab77023700f4a98eab8514625c4.png)'
- en: S Learner — source causalml documentation
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: S Learner — 来源 causalml 文档
- en: The S-Learner is the simplest meta-learner of all. Why? Because it only consists
    of using a traditional machine learning model that includes the treatment feature
    as input. While simple to implement, it may struggle if the importance of the
    treatment variable is low.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: S-Learner是所有元学习者中最简单的一个。为什么？因为它仅由一个传统的机器学习模型组成，该模型将治疗特征作为输入。虽然实现起来简单，但如果治疗变量的重要性较低，它可能会遇到困难。
- en: 2\. T-Learner (Two-Model)
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. T-Learner（双模型）
- en: '![](../Images/ec3f45f29794d0b392b3229a0d4e9a68.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec3f45f29794d0b392b3229a0d4e9a68.png)'
- en: “The T-Learner tries to solve the problem of discarding the treatment entirely
    by forcing the learner to first split on it. Instead of using a single model,
    we will use one model per treatment variable.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: “T-Learner试图通过强制学习者首先基于治疗进行拆分，解决完全丢弃治疗的问题。我们将使用一个模型来表示每个治疗变量，而不是使用单一模型。
- en: In the binary case, there are only two models that we need to estimate (hence
    the name T)” *Source [3]*
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元情况下，我们只需要估计两个模型（因此得名T）。” *来源[3]*
- en: '*Each of these approaches has its pros and cons. How well they work will depend
    on your data and what you’re trying to achieve.*'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这些方法各有优缺点。它们的效果如何取决于你的数据以及你想要达到的目标。*'
- en: 'In this article we’ll try out all three: an Uplift Random Forest Classifier,
    a S-Learner, and a T-Learner, and compare their performances when it comes to
    improving our company’s retention.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将尝试这三种方法：提升随机森林分类器、S-Learner和T-Learner，并比较它们在提高公司留存率方面的表现。
- en: Single treatment uplift model implementation with causal ML
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单一治疗提升模型的因果机器学习实现
- en: Model Training
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'Now let’s train our models. We’ll start with our direct uplift model, the uplift
    random forest classifier. Then we’ll train our meta models using an XGBoost regressor.
    Two things to note here:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来训练我们的模型。我们将从直接的提升模型——提升随机森林分类器开始。然后，我们将使用XGBoost回归器训练我们的元模型。这里有两点需要注意：
- en: The algorithm choice behind your meta-models will obviously impact the final
    model performances, thus you may want to select it carefully.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你选择的元模型算法显然会影响最终模型的表现，因此你可能需要谨慎选择。
- en: Yes, we’re selecting regressors as meta models rather than classifiers, mainly
    because they provide more flexibility, outputting a precise effect.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的，我们选择回归模型作为元模型而不是分类器，主要是因为它们提供了更多的灵活性，能够输出精准的效果。
- en: 'Here are the different steps you’ll find in the below code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你将在代码中看到的不同步骤：
- en: We initialize our result dataframe
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们初始化我们的结果数据框
- en: Then we train each model on our training set
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们在训练集上训练每个模型
- en: Finally we predict our treatment effects on the test sets before saving the
    results
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们预测我们在测试集上的治疗效果，然后保存结果
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that we’re still using causalml here, and that the API is extremely simple
    to use, very close to a sklearn-like implementation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们仍然在使用 causalml，这个 API 非常简单，使用起来非常像 sklearn 的实现。
- en: Model evaluation
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'How to evaluate and compare our models’ performances? That is a great question!
    As we’re predicting something we do not know — *we don’t know the effect of our
    treatment on our customers as each customer either received the treatment or was
    in the control group*. **We cannot use classic evaluation metrics.** Hopefully,
    there are other ways:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如何评估和比较我们模型的表现？这是个好问题！因为我们预测的是我们并不知道的东西——*我们并不知道我们的治疗对客户的效果，因为每个客户要么接受了治疗，要么在控制组中*。**我们不能使用经典的评估指标**。幸运的是，还有其他方法：
- en: '**The Gain curve**: The gain curve offers an easy way to visualise our model’s
    performance. The idea behind gain is simple:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**增益曲线**：增益曲线提供了一种简便的方式来可视化我们模型的表现。增益的基本思想很简单：'
- en: We compute the estimated effect of each of our customers, order them from the
    biggest effect to the lesser.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们计算了每个客户的估算效果，并按效果从大到小排序。
- en: From here, we move point by point. At each point, we calculate the average treatment
    effect meaning, both the average effect — for control and treatment — and we take
    the difference.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从这里开始，我们逐点进行。在每个点上，我们计算平均治疗效果，意味着同时计算对照组和治疗组的平均效果，然后取它们的差值。
- en: We do that for both our models ordering and a random ordering, simulating random
    selection, and compare both curves!
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们分别对我们的模型排序和随机排序进行相同的操作，模拟随机选择，并比较这两条曲线！
- en: It helps us understand which improvement our model would have brought versus
    a random selection.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 它帮助我们理解如果与随机选择相比，我们的模型带来了什么样的改进。
- en: '**The AAUC score**: the AAUC score is very close to the actual gain curve as
    it measures the Area under the curve of the gain curve of our model, enabling
    us to compare it with the one of the random model. It summarizes the gain curve
    in an easy to compare number.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**AAUC得分**：AAUC得分非常接近实际增益曲线，因为它衡量了模型增益曲线下的面积，使我们能够与随机模型的增益曲线进行比较。它以一个易于比较的数字总结了增益曲线。'
- en: In the following code, we calculate these metrics
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们计算了这些指标
- en: '[PRE3]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here are the results we got. Higher scores are better of course.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的结果。更高的分数当然更好。
- en: 'T-Learner: ~6.4 (best performer)'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: T-Learner：~6.4（最佳表现）
- en: 'S-Learner: ~6.3 (very close second)'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: S-Learner：~6.3（非常接近第二名）
- en: 'Random Forest: ~5.7 (good, but not as good as the others)'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机森林：~5.7（不错，但不如其他模型）
- en: 'Random targeting: ~0.5 (baseline)'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机目标：~0.5（基线）
- en: What do these results mean?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果意味着什么？
- en: Well, all our models are performing way better than random targeting. This is
    reassuring. They’re about 12 times more effective! We’ll understand what it means
    in terms of impact just after.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好吧，所有我们的模型的表现都远远超过了随机目标。这令人放心。它们大约有效12倍！我们稍后将了解这在影响力方面意味着什么。
- en: We also understand from these AAUC score that, while all models are performing
    quite well, the T-Leaner is the best performer
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还可以从这些AAUC得分中看出，尽管所有模型的表现都很好，但T-Learner的表现最好
- en: Now let’s take a look at the gain curve.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下增益曲线。
- en: Gain Curve
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增益曲线
- en: 'How to read a gain curve:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如何阅读增益曲线：
- en: '**X-Axis (Population)**: This represents the size of the population you’re
    targeting, starting from the most responsive individuals (on the left) to the
    least responsive (on the right).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X轴（人群）**：这代表你所针对的目标人群的大小，从最能响应的个体（左侧）到最不响应的个体（右侧）。'
- en: '**Y-Axis (Gain)**: This shows the cumulative gain, which is the improvement
    in your outcome (e.g., increased retention).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Y轴（增益）**：这显示的是累积增益，即你在结果中的改进（例如，提高了留存率）。'
- en: '![](../Images/a3e9e18fe560758b686e9a4cca91aded.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3e9e18fe560758b686e9a4cca91aded.png)'
- en: Gain curve Interpretation
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增益曲线解读
- en: The gain curve shows us the benefit — in our initial unit hence “people retained”
    — of targeting the population using our uplif model or randomly targeting.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 增益曲线向我们展示了目标人群的收益——在我们初始单位中，因此是“保留的人群”——通过使用我们的提升模型或随机目标。
- en: In that case it seems that if we reach out to the whole population with our
    emails, we would retain approximately 100 additional users. This is our baseline
    scenario. Note that every curve ends by this result which is expected considering
    our gain definition.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，似乎如果我们向全体用户发送电子邮件，我们将大约留住100名额外的用户。这是我们的基线场景。请注意，每条曲线最终都会得出这个结果，考虑到我们的增益定义，这是预期的。
- en: So how to interpret this? Well, looking at the curve we can say that using our
    model, **by reaching out to only 50% of the population, we can save 600 additional
    users!** Six times more than by reaching out to everyone. How is that possible?
    By targeting only users that are likely to react positively to our outreach, while
    ignoring those who would leverage this email to actually churn for instance.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那么如何解读这个呢？嗯，通过观察这条曲线，我们可以说，使用我们的模型，**通过只接触50%的人群，我们可以节省600个额外的用户！** 这是通过接触所有人节省的六倍。如何做到的呢？通过仅针对那些可能对我们的接触做出积极反应的用户，而忽略那些可能利用这封邮件实际上选择流失的用户。
- en: '*It is time for a small disclaimer: we’re using synthetic data here, our results
    are extremely unlikely in the real world, but it is good to illustrate.*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*现在是时候做一个小小的免责声明了：我们在这里使用的是合成数据，我们的结果在现实世界中极不可能出现，但这对于说明问题是有益的。*'
- en: In this case, our models enable us to do more with less. This is a good example
    on how we can optimize our resources using uplift modeling and targeting a lower
    share of the population, hence limiting the operation costs, to obtain a good
    share of the results. A kind of Pareto effect if you’d like.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的模型使我们能够用更少的资源做更多的事情。这是一个如何通过使用提升建模并针对较小人群份额来优化资源的好例子，从而限制操作成本，并获得良好的结果份额。如果你愿意的话，这就像一种帕累托效应。
- en: 'But let’s head over to the really cool stuff : how can we personalize our approach
    to every customer.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，让我们转向更酷的部分：我们如何为每个客户个性化我们的接触方式。
- en: 'Multi treatment model: let’s move to Personalization'
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多重处理模型：让我们进入个性化阶段
- en: 'Let’s now restart our analysis, considering all our retention strategies described
    above:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们重新开始分析，考虑我们上面描述的所有用户保持策略：
- en: Email campaign
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 电子邮件营销活动
- en: Call campaign
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 电话营销活动
- en: In-app notification
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用内通知
- en: Vouchers
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代金券
- en: In order to achieve this, we need experimentation results of either a multi-treatment
    experimentation of all those actions, or to aggregate the results of multiple
    experimentation. the better the experimental data, the better predictive output
    we’ll get. However, setting up such experiments can take time and resources.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们需要进行实验，或者进行所有这些操作的多重处理实验，或者聚合多个实验的结果。实验数据越好，预测输出就会越准确。然而，设置这样的实验可能需要时间和资源。
- en: Let’s use our previously generated data, keeping in mind that obtaining this
    data in the first place is probably the biggest challenge of this approach!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前生成的数据，并记住，首先获得这些数据可能是这种方法中最大的挑战！
- en: Model Training
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: Let’s start by training our models. We’ll keep the same model type as before,
    a Random Forest, S-Learner, and T-Learner.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先训练我们的模型。我们将保持与之前相同的模型类型，即随机森林、S-Learner 和 T-Learner。
- en: However, these models will now learn to differentiate between the effects of
    our four distinct treatments.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些模型现在将学习区分我们四种不同处理的效果。
- en: '[PRE4]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Predictions
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: Now that our models are trained, let’s generate our predictions for each treatment.
    For each user, we’ll get the uplift of each treatment. This will enable us to
    choose the most effective treatment by user, if any treatment has a positive uplift.
    Otherwise, we just won’t reach out to this person!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的模型已经训练好了，让我们为每个处理生成预测。对于每个用户，我们将获得每种处理的提升效果。这将使我们能够选择最有效的处理方式，如果某个处理具有正向提升。否则，我们就不会联系这个用户！
- en: '[PRE5]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is the kind of data we’ll obtain from this, for each model:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将从每个模型中获得的数据：
- en: '![](../Images/fd2ce4069ee2507a9add63ae305b450a.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd2ce4069ee2507a9add63ae305b450a.png)'
- en: We’ll be able, for each model, to pick the best treatment for each user!
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个模型，我们将能够为每个用户选择最佳处理方案！
- en: Model evaluation
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'Now let’s look at our approach evaluation. As we have multiple treatments,
    it is slightly different:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看我们的方式评估。由于我们有多种处理方式，这稍微有所不同：
- en: For each user we select the best treatment.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个用户，我们选择最佳的处理方案。
- en: Then we order our user based on their best treatment effect
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们根据每个用户的最佳处理效果对他们进行排序。
- en: 'And look at what really happened : either the user really stayed or left.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看实际发生了什么：用户要么真的留下，要么离开了。
- en: Following this rationale, we easily understand how we can outperform random
    targeting by only targeting a small share of our whole population.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这个思路，我们很容易理解如何通过仅定向我们整体人群的一小部分来优于随机定向。
- en: From here, we’re able to plot our gain curve and compute our AAUC. Easy right?
    The code below does exactly that, still leveraging causalML.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以绘制我们的增益曲线并计算AAUC。简单吧？下面的代码正是这么做的，仍然使用了causalML。
- en: '[PRE6]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Results interpretation
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果解释
- en: 'T-Learner: ~1.45 (best performer)'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: T-Learner：~1.45（最佳表现者）
- en: 'S-Learner: ~1.42 (very close second)'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: S-Learner：~1.42（紧随其后）
- en: 'Random Forest: ~1.20 (good, but not as good as the others)'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机森林：~1.20（不错，但不如其他模型）
- en: 'Random targeting: ~0.52 (baseline)'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机定向：~0.52（基准）
- en: 'What this means:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着：
- en: Once again, all our models outperform random targeting, and once again the T-Learner
    is the best performer
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再一次，我们的所有模型都优于随机定向，再一次，T-Learner是表现最好的。
- en: However we note that the difference is lower than in our first case. Different
    reasons could explain that, one being the actual set-up. We’re considering a bigger
    population here, which we did not consider in our first experiment. It also could
    mean that our models do not perform as well when it comes to multi-treatment and
    we would need to iterate and try to improve their performance.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，我们注意到，差异比我们第一次实验时小。不同的原因可能解释这一点，其中之一是实际的设置。我们现在考虑的是一个更大的群体，这在第一次实验时没有考虑到。也可能意味着我们的模型在多重处理的情况下表现不如预期，因此我们需要反复迭代并努力提高它们的表现。
- en: But let’s look at our gain curve to understand better our performance.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，让我们看看我们的增益曲线，更好地理解我们的表现。
- en: '![](../Images/eefc212c1cd99fe14ac130ba467534db.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eefc212c1cd99fe14ac130ba467534db.png)'
- en: Interpretation of the Multi-Treatment Gain Curve
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重处理增益曲线的解释
- en: As we can see, if we were to target 100% of our population — 30,000 users —
    we would retain an additional 850 users (approximately)
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们所见，如果我们针对100%的目标人群——30,000个用户——进行定向，我们将额外保留大约850个用户。
- en: however, using our models, we are able to retain 1,600 users while only contacting
    33% of the total population
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，通过使用我们的模型，我们能够在仅联系33%的总人群时保留1,600个用户。
- en: Finally, we notice that past 40% of the population all curves start to decrease
    indicating that there is no value contacting those customers.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们注意到，超过40%的目标人群后，所有曲线开始下降，表明联系这些客户没有价值。
- en: We made it. We successfully built a model that enables us to personalize effectively
    our retention actions to maximize our ROI. Based on this model, our company decided
    to put this model to production and saved millions not wasting resources reaching
    out to everyone, but also focusing the right type of effort on the right customer!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功了。我们成功构建了一个模型，使我们能够有效地个性化我们的保留策略，以最大化我们的投资回报率（ROI）。基于这个模型，我们公司决定将其投入生产，节省了数百万资金，避免了浪费资源去联系每个人，同时将正确的努力集中在正确的客户身上！
- en: 'Putting such a model to production is another challenge in itself because we
    need to ensure its performance in the long term, and keep retraining it when possible.
    The framework to do that would be to:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 将这样的模型投入生产本身就是一个挑战，因为我们需要确保它在长期内的表现，并且在可能的情况下持续进行再训练。实现这一目标的框架应该是：
- en: Generate inference with your model on 80% of your target population
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在80%的目标人群上使用你的模型生成推断
- en: 'Keep 10% of your target population intact : Control'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留10%的目标人群不变：对照组
- en: Keep an additional 10% of your population to keep experimenting to train your
    model for the next time period (month/quarter/year depending on your capabilities)
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留目标人群的另外10%，继续进行实验，为下一个时间周期（根据你的能力，可能是月度/季度/年度）训练模型。
- en: We might look into this later on!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能稍后再看看这个！
- en: Conclusion
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: If you made it this far, thank you! I hope this was interesting and that you
    learned how to create an uplift model and how to evaluate its performance.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到这里，谢谢！希望这对你有趣，并且你学会了如何创建一个增益模型以及如何评估它的表现。
- en: If I did a good job, you may now know that uplift models are an incredible tool
    to understand and that it can lead to great, direct and measurable impact. You
    also may have understood that uplift models enable us to target the right population
    with the right treatment, but require a strong and exploitable experimental data
    to be trained on. Getting this data up to date is often the big challenge of such
    projects. It is applicable on historical/observational data, one would need to
    add specific cleaning and treating steps to ensure that the data is unbiased.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我做得不错，你现在可能已经知道提升模型是一个理解因果关系的不可思议的工具，它能够带来巨大的、直接的和可衡量的影响。你可能还已经明白，提升模型使我们能够为合适的人群提供合适的处理方案，但它需要强大且可利用的实验数据来进行训练。将这些数据保持最新通常是此类项目的重大挑战。它适用于历史/观察性数据，但需要添加特定的数据清理和处理步骤，以确保数据不偏倚。
- en: So what’s next? While we’re deep-diving in the world of causal machine learning,
    I want to make sure you are heard. So if you want to look into specific topics
    that you think you could apply in your own company and would like to learn more
    about it, let me know, I’ll do my best. Let’s keep all learning from each other!
    Until next time, happy modeling!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 那接下来呢？在我们深入探讨因果机器学习的世界时，我希望确保你的声音被听到。所以，如果你想深入研究你认为可以在自己公司中应用的特定主题，并且希望了解更多，告诉我，我会尽力而为。让我们继续彼此学习！下次见，祝建模愉快！
- en: Source
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: '*Unless otherwise noted, all images are by the author*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者提供*'
- en: '[1] [https://en.wikipedia.org/wiki/Uplift_modelling](https://en.wikipedia.org/wiki/Uplift_modelling)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://en.wikipedia.org/wiki/Uplift_modelling](https://en.wikipedia.org/wiki/Uplift_modelling)'
- en: '[2] [https://causalml.readthedocs.io/en/latest/index.html](https://causalml.readthedocs.io/en/latest/index.html)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://causalml.readthedocs.io/en/latest/index.html](https://causalml.readthedocs.io/en/latest/index.html)'
- en: '[3] [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://matheusfacure.github.io/python-causality-handbook/landing-page.html](https://matheusfacure.github.io/python-causality-handbook/landing-page.html)'
