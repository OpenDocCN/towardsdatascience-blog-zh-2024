- en: 'High-Performance Python Data Processing: pandas 2 vs. Polars, a vCPU Perspective'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高性能 Python 数据处理：pandas 2 与 Polars，从 vCPU 视角看
- en: 原文：[https://towardsdatascience.com/high-performance-data-processing-pandas-2-vs-polars-a-vcpu-perspective-e922d3064f4e?source=collection_archive---------1-----------------------#2024-08-07](https://towardsdatascience.com/high-performance-data-processing-pandas-2-vs-polars-a-vcpu-perspective-e922d3064f4e?source=collection_archive---------1-----------------------#2024-08-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/high-performance-data-processing-pandas-2-vs-polars-a-vcpu-perspective-e922d3064f4e?source=collection_archive---------1-----------------------#2024-08-07](https://towardsdatascience.com/high-performance-data-processing-pandas-2-vs-polars-a-vcpu-perspective-e922d3064f4e?source=collection_archive---------1-----------------------#2024-08-07)
- en: Polars promises its multithreading capabilities outperform pandas. But is it
    also the case with a single vCore?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Polars 承诺其多线程能力优于 pandas。但在单个 vCore 上是否也是如此？
- en: '[](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)[![Saar
    Berkovich](../Images/8a834597e8c6cce1b948f6aa17bfe8be.png)](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)
    [Saar Berkovich](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)[![Saar
    Berkovich](../Images/8a834597e8c6cce1b948f6aa17bfe8be.png)](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)
    [Saar Berkovich](https://medium.com/@saarb?source=post_page---byline--e922d3064f4e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)
    ·7 min read·Aug 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e922d3064f4e--------------------------------)
    ·阅读时长7分钟·2024年8月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e29e365ebffa968cd44d28f9b23dc0fb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e29e365ebffa968cd44d28f9b23dc0fb.png)'
- en: Image generated by author, using DALL-E
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者生成，使用 DALL-E
- en: Love it or hate it, pandas has been a dominant library in Python data analysis
    for years. It’s being used extensively in data science and analysis (both in industry
    and academia), as well as by software & data engineers in data processing tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 不管喜不喜欢，pandas 多年来一直是 Python 数据分析中占主导地位的库。它在数据科学和分析中得到了广泛应用（无论是在工业界还是学术界），同时也被软件和数据工程师在数据处理任务中大量使用。
- en: pandas’ long reign as the champion of tabular data analysis is currently being
    challenged by a new library, Polars. Polars aims to replace pandas by implementing
    a more modern framework to solve the same use cases pandas solves today. One of
    its main promises is to provide better performance, utilizing a backend written
    in Rust that is optimized for parallel processing. Moreover, it has a deeper implementation
    of vectorized operations ([SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data)),
    which is one of the features that make NumPy and pandas so fast and powerful.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 长期以来作为表格数据分析的冠军，目前正面临着一个新库——Polars 的挑战。Polars 旨在通过实现一个更现代化的框架，替代 pandas
    解决今天 pandas 所解决的相同用例。它的主要承诺之一是提供更好的性能，利用一个用 Rust 编写的后端，这个后端经过优化以进行并行处理。此外，它还深入实现了矢量化操作（[SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data)），这是使
    NumPy 和 pandas 如此快速和强大的功能之一。
- en: How much faster is it?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它到底快多少？
- en: Looking at [this plot](https://pola.rs/_astro/perf-illustration.jHjw6PiD_165TDG.svg)
    (posted on the [Polars homepage](https://pola.rs/) in April 24'), which shows
    the run time in seconds for the TPC-H Benchmark, under different Python data analysis
    ecosystems, at a glance it seems that Polar is 25x faster than pandas. Digging
    a bit deeper, we can find that these benchmarks were collected on a 22 vCPU virtual
    machine. Polars is written to excel at parallel processing, so, of course, it
    benefits greatly by having such a large number of vCPUs available. pandas, on
    the other hand, does not support multithreading at all, and thus likely only utilizes
    1 vCPU on this machine. In other words, Polars completed in 1/25 of the time it
    took pandas, but it also used 22x more compute resources.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[这个图表](https://pola.rs/_astro/perf-illustration.jHjw6PiD_165TDG.svg)（发布于[Polars主页](https://pola.rs/)
    2024年4月24日），该图表展示了在不同的 Python 数据分析生态系统下，TPC-H 基准测试的运行时间（单位：秒）。一眼看上去，Polars 的速度比
    pandas 快 25 倍。深入了解后，我们发现这些基准测试是在一台拥有 22 个 vCPU 的虚拟机上收集的。Polars 被设计为擅长并行处理，因此，当然可以从拥有如此多
    vCPU 的系统中受益。而 pandas 则完全不支持多线程，因此可能仅使用了这台机器的 1 个 vCPU。换句话说，Polars 用 1/25 的时间完成了
    pandas 的工作，但它也使用了 22 倍的计算资源。
- en: The problem with vCores
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: vCore 的问题
- en: While every physical computer nowadays sports a CPU with some form of hardware
    parallelization (multiple cores, multiple ALU, hyper-threading…), the same is
    not always true for virtual servers, where it’s often beneficial to use smaller
    servers to minimize costs. For example, serverless platforms like AWS Lambda Functions,
    GCP Cloud Functions, and Azure Functions scale vCores with memory, and as you
    are charged by GB-second, you would not be inclined to assign more memory to your
    functions than you need.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然如今每台物理计算机都配有某种形式的硬件并行化（多核、多 ALU、超线程等），但虚拟服务器却不总是如此，通常使用较小的服务器可以降低成本。例如，像 AWS
    Lambda Functions、GCP Cloud Functions 和 Azure Functions 等无服务器平台，vCore 会随着内存的变化而扩展，而且由于按
    GB-秒计费，你通常不会为函数分配超过需求的内存。
- en: 'Given that this is the case, I’ve decided to test how Polars performs against
    pandas, in particular, I was interested in two things:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于情况如此，我决定测试 Polars 与 pandas 的表现，特别是我对以下两个问题感兴趣：
- en: '**1\. How Polars compares to pandas, with only 1 vCore available'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 在仅有 1 个 vCore 可用的情况下，Polars 如何与 pandas 比较'
- en: 2\. How Polars scales with vCores**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 2. **Polars 如何随着 vCore 扩展**
- en: 'We will consider 4 operations: grouping and aggregation, [quantile](https://en.wikipedia.org/wiki/Quantile)
    computation, filtering, and sorting, which could be incorporated into a data analysis
    job or pipeline that can be seen in the work of both data analysts and data scientists,
    as well as data and software engineers.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑 4 个操作：分组和聚合、[分位数](https://en.wikipedia.org/wiki/Quantile)计算、过滤和排序，这些操作可能会被融入到数据分析工作或管道中，这些工作可以在数据分析师、数据科学家以及数据和软件工程师的工作中看到。
- en: The setup
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: 'I used an AWS `m6a.xlarge` machine that has 4 vCores and 16GB RAM available
    and utilized [taskset](https://man7.org/linux/man-pages/man1/taskset.1.html) to
    assign 1 vCore and 2 vCores to the process at a time to simulate a machine with
    fewer vCores each time. For lib versions, I took the most up-to-date stable releases
    available at the time:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了一台 AWS `m6a.xlarge` 机器，配备 4 个 vCore 和 16GB 内存，并利用 [taskset](https://man7.org/linux/man-pages/man1/taskset.1.html)
    为每次测试分配 1 个 vCore 或 2 个 vCore，以模拟每次有较少 vCore 的机器。在库版本方面，我选择了当时可用的最新稳定版本：
- en: '`pandas==2.2.2; polars=1.2.1`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas==2.2.2; polars=1.2.1`'
- en: The data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: 'The dataset was randomly generated to be made up of 1M rows and 5 columns,
    and is meant to serve as a history of 100k user operations made in 10k sessions
    within a certain product:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集是随机生成的，包含 100 万行和 5 列，旨在表示某一产品中 10,000 个会话内 100,000 次用户操作的历史记录：
- en: user_id (int)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: user_id（整数）
- en: action_types (enum, can take the values in [“click”, “view”, “purchase”])
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: action_types（枚举类型，可以取值为[“click”, “view”, “purchase”]）
- en: timestamp (datetime)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: timestamp（日期时间类型）
- en: session_id (int)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: session_id（整数）
- en: session_duration (float)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: session_duration（浮动类型）
- en: The premise
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前提
- en: Given the dataset, we want to find the top 10% of most engaged users, judging
    by their average session duration. So, we would first want to calculate the average
    session duration per user (grouping and aggregation), find the 90th quantile (quantile
    computation), select all the users above the quantile (filtering), and make sure
    the list is ordered by the average session duration (sorting).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数据集，我们想要根据用户的平均会话时长找到前10%最活跃的用户。因此，我们首先需要计算每个用户的平均会话时长（分组与聚合），然后找到第90百分位数（百分位数计算），选择所有位于该百分位数以上的用户（筛选），并确保列表按平均会话时长排序（排序）。
- en: Testing
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: Each of the operations were run 200 times (using [timeit](https://docs.python.org/3/library/timeit.html)),
    taking the mean run time each time and the standard error to serve as the measurement
    error. [The code can be found here](https://gist.github.com/Berkodev/68d45dfbffeeb820033f6927e34c0f97).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个操作都运行了200次（使用[timeit](https://docs.python.org/3/library/timeit.html)），每次取平均运行时间，并用标准误差作为测量误差。[代码可以在这里找到](https://gist.github.com/Berkodev/68d45dfbffeeb820033f6927e34c0f97)。
- en: A note on eager vs lazy evaluation
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于急切执行与懒执行的说明
- en: Another difference between pandas and Polars is that the former uses eager execution
    (statements are executed as they are written) by default and the latter uses lazy
    execution (statements are compiled and run only when needed). Polar’s lazy execution
    helps it optimize [queries](https://docs.pola.rs/user-guide/lazy/query-plan/),
    which makes a very nice feature in heavy data analysis tasks. The choice to split
    our task and look at 4 operations is made to eliminate this aspect and focus on
    comparing more basic performance aspects.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: pandas和Polars之间的另一个区别是，前者默认使用急切执行（语句按书写顺序执行），而后者使用懒执行（语句在需要时编译并执行）。Polars的懒执行帮助它优化[查询](https://docs.pola.rs/user-guide/lazy/query-plan/)，这在大数据分析任务中是一个非常好的特性。我们选择将任务拆分，查看四个操作，目的是排除这一方面，专注于比较更基本的性能方面。
- en: Results
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: Group by + Aggregate
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分组 + 聚合
- en: '![](../Images/7359c686432a3b97f6043764e030cff4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7359c686432a3b97f6043764e030cff4.png)'
- en: Mean Execution Time for the group by and aggregate operation, by library and
    vCores. Image and data by author.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 按库和vCore进行的分组和聚合操作的平均执行时间。图像和数据由作者提供。
- en: We can see how pandas does not scale with vCores — as expected. This trend will
    remain throughout our test. I decided to keep it in the plots, but we won’t reference
    it again.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，pandas在vCore的扩展上没有表现出预期的效果。这个趋势在整个测试过程中都会保持。我决定保留图表中的这一部分，但之后我们将不再提及它。
- en: polars’ results are quite impressive here — with a 1vCore setup it managed to
    finish faster than pandas by a third of the time, and as we scale to 2, 4 cores
    it finishes roughly 35% and 50% faster respectively.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: polars的结果相当令人印象深刻——在1vCore配置下，它比pandas快了三分之一的时间，而随着vCore数量增加到2核和4核时，它分别快了约35%和50%。
- en: Quantile Computation
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 百分位数计算
- en: '![](../Images/20b2f53f53b7a2b5cb16441c6d97d3ed.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20b2f53f53b7a2b5cb16441c6d97d3ed.png)'
- en: Mean execution time for the Quantile Computation operation, by library and vCores.
    Image and data by author.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 按库和vCore进行的百分位数计算操作的平均执行时间。图像和数据由作者提供。
- en: This one is interesting. In all vCores setups, polars finished around 5x faster
    than pandas. On the 1vCore setup, it measured 0.2ms on average, but with a significant
    standard error (meaning that the operation would sometimes finish well after 0.2ms,
    and at other times it would finish well before 0.2ms). When scaling to multiple
    cores we get stabler run times — 2vCores at 0.21ms and 4vCores at 0.19 (around
    10% faster).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果很有趣。在所有vCore配置中，polars的执行速度是pandas的5倍。在1vCore配置下，平均执行时间为0.2ms，但标准误差较大（意味着有时操作完成的时间会明显超过0.2ms，而有时则会明显低于0.2ms）。当扩展到多个vCore时，执行时间更加稳定——2vCore配置为0.21ms，4vCore配置为0.19ms（大约快10%）。
- en: Filtering
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 筛选
- en: '![](../Images/a56070692a047244138f5934f1674c14.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a56070692a047244138f5934f1674c14.png)'
- en: Mean execution time for the Filter operation, by library and vCores. Image and
    data by author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 按库和vCore进行的筛选操作的平均执行时间。图像和数据由作者提供。
- en: In all cases, Polars finishes faster than pandas (the worse run time is still
    2 times faster than pandas). However, we can see a very unusual trend here — the
    run time increases with vCores (we’re expecting it to decrease). The run time
    of the operation with 4 vCores is roughly 35% slower than the run time with 1
    vCore. While parallelization gives you more computing power, it often comes with
    some overhead — managing and orchestrating parallel processes is often very difficult.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，Polars 的完成速度都比 pandas 快（最差的运行时间仍然是 pandas 的两倍）。然而，我们在这里看到了一种非常不寻常的趋势
    —— 运行时间随着 vCore 增加而增加（我们原本期望它会减少）。4vCore 的操作运行时间大约比 1vCore 的慢 35%。尽管并行化为你提供了更多的计算能力，但它通常伴随有一定的开销
    —— 管理和协调并行进程通常是非常困难的。
- en: This Polars scaling issue is perplexing — the implementation on my end is very
    simple, and I was not able to find a relevant open issue on the Polars repo (there
    are currently over 1k open issues there, though).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Polars 扩展问题令人困惑 —— 我这边的实现非常简单，而且在 Polars 的仓库中没有找到相关的开放问题（不过现在那儿确实有超过 1000
    个开放问题）。
- en: Do you have any idea as to why this could have happened? Let me know in the
    comments.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道为什么会发生这种情况吗？请在评论中告诉我。
- en: Sorting
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序
- en: '![](../Images/f64ac7d234a1f9f8ccb325be256f7696.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f64ac7d234a1f9f8ccb325be256f7696.png)'
- en: Mean execution time for the Sort operation, by library and vCores. Image and
    data by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 排序操作的平均执行时间，按库和 vCore 分类。图片和数据来源：作者。
- en: After filtering, we are left with around 13.5k rows.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤后，我们剩下了大约 13.5k 行数据。
- en: In this one, we can see that the 1vCore Polars case is significantly slower
    than pandas (by around 45%). As we scale to 2vCores the run time becomes competitive
    with pandas’, and by the time we scale to 4vCores Polars becomes significantly
    faster than pandas. The likely scenario here is that Polars uses a sorting algorithm
    that is optimized for parallelization — such an algorithm may have poor performance
    on a single core.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以看到 1vCore 的 Polars 情况比 pandas 慢得多（慢约 45%）。当我们扩展到 2vCore 时，运行时间与 pandas
    相当，而扩展到 4vCore 时，Polars 的速度明显快于 pandas。这里可能的情况是，Polars 使用了一种针对并行优化的排序算法 —— 这种算法在单核心上可能表现不佳。
- en: Looking more closely at the docs, I found that the sort operation in Polars
    has a `multithreaded` parameter that controls whether a multi-threaded sorting
    algorithm is used or a single-threaded one.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看文档后，我发现 Polars 中的排序操作有一个 `multithreaded` 参数，用于控制是否使用多线程排序算法或单线程排序算法。
- en: Sorting (with multithreading=False)
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序（multithreading=False）
- en: '![](../Images/6e729e639be15093fcff0752aa065de3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e729e639be15093fcff0752aa065de3.png)'
- en: Mean execution time for the Sort operation (with multithreading=False), by library
    and vCores. Image and data by author.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 排序操作的平均执行时间（multithreading=False），按库和 vCore 分类。图片和数据来源：作者。
- en: This time, we can see much more consistent run times, which don’t scale with
    cores but do beat pandas.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们可以看到更加一致的运行时间，虽然它们不会随着核心数的增加而扩展，但确实超过了 pandas。
- en: Conclusions
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Parallel computing & distributed computing is hard. We tend to think that if
    we just scale our program it would complete faster, but it always adds overhead.
    In many cases, programs like Redis and node.js that are known to be blazing fast
    are actually single-threaded, with no parallelization support (node.js is famously
    concurrent, but concurrency =/= parallelization).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行计算和分布式计算是困难的。我们通常认为，只要扩展我们的程序，它就能更快完成，但这总是会增加开销。在很多情况下，像 Redis 和 node.js 这样以极速著称的程序实际上是单线程的，并不支持并行化（node.js
    以并发著称，但并发 ≠ 并行化）。
- en: It appears that, for the most part, Polars is indeed faster than pandas, even
    with just 1 available vCore. Impressive!
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看起来，大多数情况下，即使只有 1 个可用 vCore，Polars 确实比 pandas 更快。令人印象深刻！
- en: Judging by the filter & sorting operation, polars appears to not be well-optimized
    to a single vCore case, as you might encounter on your cloud. This is important
    if you run a lot of small (<2GB in memory) serverless Functions. Scaling for speed
    is often coupled with scaling in price.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从过滤和排序操作来看，Polars 显然没有针对单个 vCore 情况进行优化，就像你在云服务中可能遇到的情况一样。如果你运行大量小型（<2GB 内存）无服务器函数，这是一个重要的考虑因素。为了提高速度进行扩展通常也伴随着价格的上升。
- en: Polars is still a relatively new solution, and as of mid-2024 it feels not as
    mature as pandas. For example, on the `multithreaded` parameter in sort — I’d
    expect there to be an `auto` default option that will choose the algorithm based
    on the hardware.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polars 仍然是一个相对较新的解决方案，截至 2024 年中，它似乎没有 pandas 那么成熟。例如，在排序操作中的 `multithreaded`
    参数 —— 我希望能够有一个 `auto` 默认选项，可以根据硬件选择算法。
- en: Final Notes
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后备注
- en: When considering a switch between foundational libraries like pandas, performance
    is not the only thing that should be on your mind. It’s important to consider
    other parameters such as the cost of switching (learning a new syntax, refactoring
    old code), the compatibility with other libraries, and the maturity of the new
    solution.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在考虑更换像 pandas 这样的基础库时，性能并不是唯一需要考虑的因素。还需要考虑其他参数，例如切换的成本（学习新语法、重构旧代码）、与其他库的兼容性以及新解决方案的成熟度。
- en: The tests here are meant as to be in the middle of the spectrum between quick
    and dirty and thorough benchmarks. There is more to do to reach a decisive conclusion.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这里的测试旨在处于快速粗略和彻底基准测试之间的中间地带。还需要更多工作才能得出决定性结论。
- en: I briefly discussed how pandas and Polars benefit from SIMD (single instruction,
    multiple data), another piece of hardware you [may have heard of](https://www.forbes.com/sites/dereksaul/2024/06/20/nvidia-worlds-most-valuable-company-rallies-another-3-as-4-trillion-valuation-in-sight/),
    the GPU, is famous for implementing the same idea. Nvidia has released a [plugin](https://docs.nvidia.com/spark-rapids/index.html)
    for executing Apache Spark code on a GPU — from my testing, it’s even less mature
    than Polars but worth checking out.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我简要讨论了 pandas 和 Polars 如何受益于 SIMD（单指令多数据），另一个你[可能听说过](https://www.forbes.com/sites/dereksaul/2024/06/20/nvidia-worlds-most-valuable-company-rallies-another-3-as-4-trillion-valuation-in-sight/)的硬件，GPU，因实现相同的思想而闻名。Nvidia
    发布了一个[插件](https://docs.nvidia.com/spark-rapids/index.html)，用于在 GPU 上执行 Apache
    Spark 代码——根据我的测试，它甚至比 Polars 更不成熟，但值得一试。
