- en: The Math Behind Stochastic Gradient Descent
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机梯度下降背后的数学原理
- en: 原文：[https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16](https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16](https://towardsdatascience.com/stochastic-gradient-descent-math-and-python-code-35b5e66d6f79?source=collection_archive---------0-----------------------#2024-01-16)
- en: Deep Dive on Stochastic Gradient Descent. Algorithm, assumptions, benefits,
    formula, and practical implementation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机梯度下降的深度解析：算法、假设、优点、公式和实际应用
- en: '[](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[![Cristian
    Leo](../Images/99074292e7dfda50cf50a790b8deda79.png)](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    [Cristian Leo](https://medium.com/@cristianleo120?source=post_page---byline--35b5e66d6f79--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    ·18 min read·Jan 16, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--35b5e66d6f79--------------------------------)
    ·18分钟阅读·2024年1月16日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/188abc5dbac543899ab3d77a9e4711ee.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/188abc5dbac543899ab3d77a9e4711ee.png)'
- en: Image by [DALL-E-2](https://openai.com/dall-e-2)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [DALL-E-2](https://openai.com/dall-e-2)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The image above is not just an appealing visual that drew you to this article
    (despite its length), but it also represents a potential journey of the SGD algorithm
    in search of a global minimum. In this journey, it navigates rocky paths where
    the height symbolizes the loss. If this doesn’t sound clear now, don’t worry,
    it will be by the end of this article.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图像不仅仅是吸引你阅读本文的一个视觉元素（尽管它的篇幅较长），它还代表了SGD算法在寻找全局最小值过程中的潜在旅程。在这个旅程中，它穿越崎岖的路径，其中高度代表了损失。如果现在这一点还不清楚，别担心，等到本文结束时你就能理解了。
- en: '**Index:**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**索引：**'
- en: '· [1: Understanding the Basics](#6a59)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: · [1：理解基础概念](#6a59)
- en: '∘ [1.1: What is Gradient Descent](#2d34)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [1.1：什么是梯度下降](#2d34)
- en: '∘ [1.2: The ‘Stochastic’ in Stochastic Gradient Descent](#5b93)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [1.2：随机梯度下降中的“随机”](#5b93)
- en: '**·** [**2: The Mechanics of SGD**](#d6f5)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**2：SGD的机制**](#d6f5)'
- en: '∘ [2.1: The Algorithm Explained](#7563)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [2.1：算法解释](#7563)
- en: '∘ [2.2: Understanding Learning Rate](#f1f1)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [2.2：理解学习率](#f1f1)
- en: '**·** [**3: SGD in Practice**](#c500)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**3：SGD在实践中的应用**](#c500)'
- en: '∘ [3.1: Implementing SGD in Machine Learning Models](#c4db)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [3.1：在机器学习模型中实现SGD](#c4db)
- en: '∘ [3.2: SGD in Sci-kit Learn and Tensorflow](#451b)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [3.2：在Sci-kit Learn和Tensorflow中的SGD](#451b)
- en: '**·** [**4: Advantages and Challenges**](#0e3d)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**4：优势与挑战**](#0e3d)'
- en: '∘ [4.1: Why Choose SGD?](#de7c)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.1：为什么选择SGD？](#de7c)
- en: '∘ [4.2: Overcoming Challenges in SGD](#c053)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4.2：克服SGD中的挑战](#c053)
- en: '**·** [**5: Beyond Basic SGD**](#5a3f)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**5：超越基础SGD**](#5a3f)'
- en: '∘ [5.1: Variants of SGD](#19d7)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.1：SGD的变种](#19d7)
- en: '∘ [5.2: Future of SGD](#b6e0)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5.2：SGD的未来](#b6e0)
- en: '**·** [**Conclusion**](#6db6)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**结论**](#6db6)'
