- en: 'Here Comes Mamba: The Selective State Space Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mamba来了：选择性状态空间模型
- en: 原文：[https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451?source=collection_archive---------4-----------------------#2024-09-03](https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451?source=collection_archive---------4-----------------------#2024-09-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451?source=collection_archive---------4-----------------------#2024-09-03](https://towardsdatascience.com/here-comes-mamba-the-selective-state-space-model-435e5d17a451?source=collection_archive---------4-----------------------#2024-09-03)
- en: '[🐍 Towards Mamba State Space Models for Images, Videos and Time Series](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[🐍 向Mamba状态空间模型迈进：适用于图像、视频和时间序列](https://towardsdatascience.com/tagged/mamba-image-video-signal)'
- en: Part 3 — Towards Mamba State Space Models for Images, Videos and Time Series
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3部分 — 向Mamba状态空间模型迈进：适用于图像、视频和时间序列
- en: '[](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)[![Sascha
    Kirch](../Images/a0d45da9dc9c602075b2810786c660c9.png)](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)
    [Sascha Kirch](https://medium.com/@SaschaKirch?source=post_page---byline--435e5d17a451--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)
    ·17 min read·Sep 3, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--435e5d17a451--------------------------------)
    ·阅读时间17分钟·2024年9月3日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/809aa25fa36bff0e6df683db98e295c2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/809aa25fa36bff0e6df683db98e295c2.png)'
- en: Image by [Sascha Kirch](https://medium.com/@SaschaKirch).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Sascha Kirch](https://medium.com/@SaschaKirch).
- en: This is part 3 of my new multi-part series [🐍 Towards Mamba State Space Models
    for Images, Videos and Time Series](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb).
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是我新系列的第3部分：[🐍 向Mamba状态空间模型迈进：适用于图像、视频和时间序列](https://medium.com/@SaschaKirch/list/mamba-state-space-models-for-images-videos-and-timeseries-861ae0ad08fb)。
- en: Mamba, the model to be said to replace the mighty Transformer, has come a long
    way from the initial idea of using state space models (SSMs) in deep learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba，这个被认为将取代强大的Transformer的模型，从最初在深度学习中使用状态空间模型（SSMs）的构想到现在，已经走过了很长的路。
- en: Mamba adds selectivity to state space models which results in Transformer-like
    performance while maintaining the sub-quadratic work complexity of SSMs. Their
    efficient selective scan is 40x faster than a standard implementation and can
    achieve 5x more throughput as a Transformer.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba为状态空间模型添加了选择性，从而在保持SSM子二次工作复杂度的同时，实现了类似Transformer的性能。其高效的选择性扫描比标准实现快40倍，并且在吞吐量上可达到Transformer的5倍。
- en: Join me on this deep dive on Mamba where we will discover how selectivity solves
    the limitations of previous SSMs, how Mamba overcomes new obstacles that come
    with those changes and how we can incorporate Mamba into a modern deep learning
    architecture.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我，一同深入探讨Mamba，我们将发现选择性如何解决以往状态空间模型（SSMs）的局限性，Mamba如何克服这些变化带来的新挑战，以及我们如何将Mamba融入现代深度学习架构中。
