- en: A Deep Dive into In-Context Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨上下文学习
- en: 原文：[https://towardsdatascience.com/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-9ee1d71d1e35?source=collection_archive---------4-----------------------#2024-05-31](https://towardsdatascience.com/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-9ee1d71d1e35?source=collection_archive---------4-----------------------#2024-05-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-9ee1d71d1e35?source=collection_archive---------4-----------------------#2024-05-31](https://towardsdatascience.com/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-9ee1d71d1e35?source=collection_archive---------4-----------------------#2024-05-31)
- en: Stepping out of the “comfort zone” — part 2/3 of a deep-dive into domain adaptation
    approaches for LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跳出“舒适区” — 深入探索LLM领域适应方法的第二部分/共三部分
- en: '[](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)[![Aris
    Tsakpinis](../Images/2cc1101aed68e1f71a0026bfdec28f58.png)](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)
    [Aris Tsakpinis](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)[![Aris
    Tsakpinis](../Images/2cc1101aed68e1f71a0026bfdec28f58.png)](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)
    [Aris Tsakpinis](https://medium.com/@aris.tsakpinis?source=post_page---byline--9ee1d71d1e35--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)
    ·10 min read·May 31, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9ee1d71d1e35--------------------------------)
    ·阅读时间：10分钟·2024年5月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/feba82d03e60bed39dd91e250a8234eb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/feba82d03e60bed39dd91e250a8234eb.png)'
- en: Photo by StableDiffusionXL on Amazon Web Services
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由StableDiffusionXL提供，托管于Amazon Web Services
- en: Exploring domain adapting large language models (LLMs) to your specific domain
    or use case? This **3-part blog post series** explains the motivation for domain
    adaptation and dives deep into various options to do so. Further, a detailed guide
    for mastering the entire domain adaptation journey covering popular tradeoffs
    is being provided.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 探索将大语言模型（LLMs）适应特定领域或用例？这篇**三部分博客系列**解释了领域适应的动机，并深入探讨了实现这一目标的各种选项。此外，还提供了一份详细的指南，帮助掌握整个领域适应过程，并涵盖了常见的权衡取舍。
- en: '[*Part 1: Introduction into domain adaptation — motivation, options, tradeoffs*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-47a865b16740)
    *Part 2: A deep dive into in-context learning* ***— You’re here!***[*Part 3: A
    deep dive into fine-tuning*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-4860c6d16224)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1部分：领域适应简介 — 动机、选项、权衡*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-47a865b16740)
    *第2部分：深入探讨上下文学习* ***— 你现在就在这里！***[*第3部分：深入探讨微调*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-4860c6d16224)'
- en: 'Note: All images, unless otherwise noted, are by the author.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：除非另有说明，所有图片均为作者提供。
- en: Recap
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: In the first part of this blog post series, we discussed the rapid advancements
    in generative AI and the emergence of large language models (LLMs) like Claude,
    GPT-4, Meta LLaMA, and Stable Diffusion. These models have demonstrated remarkable
    capabilities in content creation, sparking both enthusiasm and concerns about
    potential risks. We highlighted that while these AI models are powerful, they
    also have inherent limitations and “comfort zones” — areas where they excel, and
    areas where their performance can degrade when pushed outside their expertise.
    This can lead to model responses that fall below the expected quality, potentially
    resulting in hallucinations, biased outputs, or other undesirable behaviors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客系列的第一部分，我们讨论了生成性人工智能的快速发展，以及像Claude、GPT-4、Meta LLaMA和Stable Diffusion这样的语言模型的出现。这些模型在内容创作中展示了出色的能力，引发了对潜在风险的热情与担忧。我们强调，虽然这些人工智能模型非常强大，但它们也有固有的局限性和“舒适区”——即它们擅长的领域和当它们被推向超出其专业领域时，表现可能下降的领域。这可能导致模型的响应质量低于预期，进而产生幻觉、偏见输出或其他不良行为。
- en: 'To address these challenges and enable the strategic use of generative AI in
    enterprises, we introduced three key design principles: Helpfulness, Honesty,
    and Harmlessness. We also discussed how domain adaptation techniques, such as
    in-context learning and fine-tuning, can be leveraged to overcome the “comfort
    zone” limitations of these models and create enterprise-grade, compliant generative
    AI-powered applications. In this second part, we will dive deeper into the world
    of in-context learning, exploring how these techniques can be used to transform
    tasks and move them back into the models’ comfort zones.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，并使企业能够战略性地使用生成性人工智能，我们提出了三个关键设计原则：有益性、诚实性和无害性。我们还讨论了如何通过领域适配技术，如上下文学习和微调，克服这些模型的“舒适区”局限性，创建符合企业标准的生成性人工智能应用程序。在第二部分中，我们将深入探索上下文学习的世界，研究如何利用这些技术转变任务，并将其带回模型的舒适区。
- en: What is the desired outcome of in-context learning?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文学习的期望结果是什么？
- en: In-context learning aims to make use of external tooling to modify the task
    to be solved in a way that moves it back (or closer) into a model’s comfort zone.
    In the world of LLMs, this can be done through prompt engineering, which involves
    infusing source knowledge through the model prompt to transform the overall complexity
    of a task. It can be executed in a rather static manner (e.g. few-shot prompting),
    but more sophisticated, dynamic prompt engineering techniques like retrieval-augmented
    generation (RAG) or Agents have proven to be powerful.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文学习旨在利用外部工具修改要解决的任务，以一种使任务回到（或更接近）模型舒适区的方式。在大型语言模型（LLM）的世界中，这可以通过提示工程来实现，提示工程涉及通过模型提示注入源知识，从而改变任务的整体复杂度。它可以以一种相对静态的方式执行（例如少量提示），但更复杂的动态提示工程技术，如检索增强生成（RAG）或代理，已被证明具有强大的能力。
- en: '![](../Images/af2cd3d6a0c4550d298df7eee4da2c26.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af2cd3d6a0c4550d298df7eee4da2c26.png)'
- en: 'Figure 1: in-context learning to overcome hallucinations — Source: Claude 3
    Sonnet via Amazon Bedrock'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：利用上下文学习克服幻觉——来源：Claude 3 Sonnet via Amazon Bedrock
- en: In part 1 of this blog post series we noticed alongside the example depicted
    in figure 1 how adding a static context like a speaker bio can help reduce the
    complexity of the task to be solved by the model, leading to better model results.
    In what follows, we will dive deeper into more advanced concepts of in-context
    learning.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客系列的第一部分，我们注意到，通过图1中展示的例子，添加一个静态上下文（如演讲者简介）可以帮助减少任务复杂度，使得模型更容易解决，从而获得更好的模型结果。接下来，我们将深入探讨上下文学习的更高级概念。
- en: From static to dynamic context infusion
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从静态到动态的上下文注入
- en: “The measure of intelligence is the ability to change.” (Albert Einstein)
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “智慧的衡量标准是改变的能力。”（阿尔伯特·爱因斯坦）
- en: While the above example with static context infusion works well for static use
    cases, it lacks the ability to scale across diverse and complex domains. Assuming
    the scope of our closed QA task would not be limited to me as a person only, but
    to all speakers of a huge conference and hence hundreds of speaker bios. In this
    case, manual identification and insertion of the relevant piece of context (i.e.
    the speaker bio) becomes cumbersome, error-prone, and impractical. In theory,
    recent models come with huge context sizes up to 200k tokens or more, fitting
    not only those hundreds of speaker bios, but entire books and knowledge bases.
    However, there is plenty of reasons why this is not a desirable approach, like
    cost in a pay per token approach, compute requirements, latency, etc. .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然上述静态上下文注入的示例对于静态用例效果良好，但它缺乏在不同和复杂领域之间扩展的能力。假设我们封闭问答任务的范围不仅仅局限于我个人，而是扩展到一个大型会议的所有发言人，因此涉及到数百个发言人简历。在这种情况下，手动识别和插入相关的上下文片段（即发言人简历）变得繁琐、容易出错且不实际。从理论上讲，最近的模型支持高达200k个token或更多的巨大上下文大小，不仅能容纳这些数百个发言人简历，还能容纳整个书籍和知识库。然而，这种方法并不理想，原因有很多，比如按token计费的成本、计算需求、延迟等。
- en: Luckily, plenty of optimized content retrieval approaches concerned with identifying
    exactly the piece of context most suitable to ingest in a dynamic approach exist
    — some of a deterministic nature (e.g. SQL-queries on structured data), others
    powered by probabilistic systems (e.g. semantic search). Chaining these two components
    together into an integrated closed Q&A approach with dynamic context retrieval
    and infusion has proven to be extremely powerful. Thereby, a huge (endless?) variety
    of data sources — from relational or graph databases over vector stores to enterprise
    systems or real-time APIs — can be connected. To accomplish this, the identified
    context piece(s) of highest relevance is (are) extracted and dynamically ingested
    into the prompt template used against the generative decoder model when accomplishing
    the desired task. Figure 2 shows this exemplarily for a user-facing Q&A application
    (e.g., a chatbot).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，针对动态方法中最适合吸收的上下文片段的优化内容检索方法有很多——其中一些是确定性的（例如在结构化数据上进行SQL查询），其他则依赖于概率系统（例如语义搜索）。将这两种组件结合在一起，形成一个集成的封闭问答方法，带有动态上下文检索和注入，已经证明极其强大。通过这种方式，可以连接来自各种数据源的大量（甚至是无限的？）数据——从关系数据库或图数据库到向量存储，再到企业系统或实时API等。为实现这一目标，识别出的最相关的上下文片段将被提取，并动态地注入到用于生成解码器模型的提示模板中，以完成所需任务。图2展示了这一过程，举例说明了一个面向用户的问答应用（例如聊天机器人）。
- en: '![](../Images/76fc0f823150897871aee5d6447008aa.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76fc0f823150897871aee5d6447008aa.png)'
- en: 'Figure 2: dynamic context infusion with various data sources'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：与各种数据源的动态上下文注入
- en: Retrieval-augmented generation (RAG)
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）
- en: The by far most popular approach to dynamic prompt engineering is RAG. The approach
    works well when trying to ingest context originating from large full-text knowledge
    bases dynamically. It combines two probabilistic methods by augmenting an open
    Q&A task with dynamic context retrieved by semantic search, turning an open Q&A
    task into a closed one.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最流行的动态提示工程方法是RAG（检索增强生成）。当试图动态地吸收来自大型全文知识库的上下文时，这种方法表现得很好。它通过将语义搜索检索到的动态上下文增强开放问答任务，从而将开放问答任务转变为封闭问答任务，结合了两种概率方法。
- en: '![](../Images/aed9c284bb4b2458d880765186a463b4.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aed9c284bb4b2458d880765186a463b4.png)'
- en: 'Figure 3: retrieval-augmented generation (RAG) on AWS'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：AWS上的检索增强生成（RAG）
- en: First, the documents are being sliced into chunks of digestible size. Then,
    an encoder LLM is used for creating contextualised embeddings of these snippets,
    encoding the semantics of every chunk into the mathematical space in the form
    of a vector. This information is stored in a vector database, which acts as our
    knowledge base. Thereby, the vector is used as the primary key, whereas the text
    itself, together with optional metadata, is stored alongside.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，文档被切分成易于处理的块。然后，使用编码器LLM来创建这些片段的上下文化嵌入，将每个片段的语义以向量的形式编码到数学空间中。该信息存储在向量数据库中，作为我们的知识库。这样，向量作为主键使用，而文本本身及其可选元数据将一同存储。
- en: (0) In case of a user question, the input submitted is cleaned and encoded by
    the very same embeddings model, creating a semantic representation of the user’s
    question in the knowledge base’s vector space.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: (0) 如果是用户提问，提交的输入将通过相同的嵌入模型进行清洗和编码，创建用户问题在知识库向量空间中的语义表示。
- en: (1) This embedding is subsequently used for carrying out a similarity search
    based on vector distance metrics over the entire knowledge base — with the hypothesis
    that the k snippets with the highest similarity to the user’s question in the
    vector space are likely best suited for grounding the question with context.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 该嵌入随后用于在整个知识库中基于向量距离度量进行相似性搜索——假设与用户问题在向量空间中具有最高相似度的 k 个片段可能最适合用来为问题提供上下文支持。
- en: (2) In the next step, these top k snippets are passed to a decoder generative
    LLM as context alongside the user’s initial question, forming a closed Q&A task.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 在下一步，这些最相关的 k 个片段将与用户的初始问题一起作为上下文传递给解码器生成的 LLM，从而形成一个封闭的问答任务。
- en: (3) The LLM answers the question in a grounded way in the style instructed by
    the application’s system prompt (e.g., chatbot style).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (3) LLM 根据应用系统提示（例如，聊天机器人风格）中的指导，以有根据的方式回答问题。
- en: Knowledge Graph-augmented generation (KGAG)
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识图谱增强生成（KGAG）
- en: Knowledge Graph-Augmented Generation (KGAG) is another dynamic prompting approach
    that integrates structured knowledge graphs to transform the task to be solved
    and hence enhance the factual accuracy and informativeness of language model outputs.
    Integrating knowledge graphs can be achieved by several approaches.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱增强生成（KGAG）是另一种动态提示方法，它将结构化的知识图谱与任务进行结合，从而增强语言模型输出的事实准确性和信息丰富性。集成知识图谱可以通过多种方法实现。
- en: '![](../Images/e6cda83730a69f96b25f48c08749580b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6cda83730a69f96b25f48c08749580b.png)'
- en: 'Figure 4: Knowledge Graph augmented generation (KGAG) — Source: Kang et al
    (2023)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：知识图谱增强生成（KGAG）——来源：Kang 等人（2023）
- en: 'As one of those, the KGAG framework proposed by [Kang et al (2023)](https://arxiv.org/pdf/2305.18846)
    consists of three key components:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为其中之一，[Kang 等人 (2023)](https://arxiv.org/pdf/2305.18846) 提出的 KGAG 框架由三个关键组成部分构成：
- en: (1) The context-relevant subgraph retriever retrieves a relevant subgraph Z
    from the overall knowledge graph G given the current dialogue history x. To do
    this, the model defines a retrieval score for each individual triplet z = (eh,
    r, et) in the knowledge graph, computed as the inner product between embeddings
    of the dialogue history x and the candidate triplet z. The triplet embeddings
    are generated using Graph Neural Networks (GNNs) to capture the relational structure
    of the knowledge graph. The retrieval distribution p(Z|x) is then computed as
    the product of the individual triplet retrieval scores p(z|x), allowing the model
    to retrieve only the most relevant subgraph Z for the given dialogue context.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 与上下文相关的子图检索器根据当前对话历史 x 从整体知识图谱 G 中检索相关子图 Z。为此，模型为知识图谱中的每个三元组 z = (eh, r,
    et) 定义一个检索得分，该得分通过对话历史 x 和候选三元组 z 的嵌入进行内积计算。三元组嵌入是通过图神经网络（GNNs）生成的，用于捕捉知识图谱的关系结构。然后，检索分布
    p(Z|x) 被计算为各个三元组检索得分 p(z|x) 的乘积，从而使得模型能够仅检索出与给定对话上下文最相关的子图 Z。
- en: (2) The model needs to encode the retrieved subgraph Z along with the text sequence
    x for the language model. A naive approach would be to simply prepend the tokens
    of entities and relations in Z to the input x, but this violates important properties
    like permutation invariance and relation inversion invariance. To address this,
    the paper proposes an “invariant and efficient” graph encoding method. It first
    sorts the unique entities in Z and encodes them, then applies a learned affine
    transformation to perturb the entity embeddings based on the graph structure.
    This satisfies the desired invariance properties while also being more computationally
    efficient than prepending all triplet tokens.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 模型需要将检索到的子图 Z 与文本序列 x 一起编码，以供语言模型使用。一种简单的方法是将 Z 中实体和关系的标记直接加到输入 x 的前面，但这种做法违反了像置换不变性和关系反转不变性等重要属性。为了解决这个问题，论文提出了一种“不可变且高效”的图编码方法。该方法首先对
    Z 中的唯一实体进行排序并编码，然后基于图结构应用学习的仿射变换来扰动实体嵌入。这种方法在满足所需的不变性属性的同时，还比将所有三元组标记加到前面的做法更具计算效率。
- en: (3) The model uses a contrastive learning objective to ensure the generated
    text is consistent with the retrieved subgraph Z. Specifically, it maximizes the
    similarity between the representations of the retrieved subgraph and the generated
    text, while minimizing the similarity to negative samples. This encourages the
    model to generate responses that faithfully reflect the factual knowledge contained
    in the retrieved subgraph.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 模型使用对比学习目标，确保生成的文本与检索到的子图 Z 一致。具体来说，它通过最大化检索子图和生成文本表示之间的相似度，同时最小化与负样本之间的相似度，来鼓励模型生成真实反映检索子图中事实知识的回应。
- en: By combining these three components — subgraph retrieval, invariant graph encoding,
    and graph-text contrastive learning — the KGAG framework can generate knowledge-grounded
    responses that are both fluent and factually accurate.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合这三种组件——子图检索、不变图编码和图-文本对比学习——KGAG 框架能够生成既流畅又事实准确的基于知识的回应。
- en: KGAG is particularly useful in dialogue systems, question answering, and other
    applications where generating informative and factually accurate responses is
    important. It can be applied in domains where there is access to a relevant knowledge
    graph, such as encyclopaedic knowledge, product information, or domain-specific
    facts. By combining the strengths of language models and structured knowledge,
    KGAG can produce responses that are both natural and trustworthy, making it a
    valuable tool for building intelligent conversational agents and knowledge-intensive
    applications.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: KGAG 特别适用于对话系统、问答系统以及其他需要生成信息丰富且事实准确回应的应用。它可以应用于能够访问相关知识图的领域，如百科知识、产品信息或领域特定事实。通过结合语言模型和结构化知识的优势，KGAG
    能够生成既自然又值得信赖的回应，使其成为构建智能对话代理和知识密集型应用的宝贵工具。
- en: Chain-of-Thought (CoT) — decomposing problems sequentially
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维链（CoT）——顺序分解问题
- en: Chain-of-Thought is a prompt engineering approach introduced by [Wei et al in
    2023](https://arxiv.org/pdf/2201.11903). By providing the model with either instructions
    or few-shot examples of structured reasoning steps towards a problem solution,
    it reduces the complexity of the problem to be solved by the model significantly.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链（CoT）是一种由[Wei 等人于 2023 年](https://arxiv.org/pdf/2201.11903)提出的提示工程方法。通过向模型提供指令或少量结构化推理步骤的示例，帮助解决问题，这大大降低了问题的复杂度，使得模型能够更有效地求解。
- en: '![](../Images/902dbd6bfbc95eaa6192da4157030645.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/902dbd6bfbc95eaa6192da4157030645.png)'
- en: 'Figure 5: chain-of-thought prompting (CoT) — Source: Wei et al (2023)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：思维链提示（CoT）——来源：Wei 等人（2023）
- en: The core idea behind CoT prompting is to mimic the human thought process when
    solving complicated multi-step reasoning tasks. Just as humans decompose a complex
    problem into intermediate steps and solve each step sequentially before arriving
    at the final answer, CoT prompting encourages language models to generate a coherent
    chain of thought — a series of intermediate reasoning steps that lead to the final
    solution. Figure 5 showcases an example where the model produces a chain of thought
    to solve a math word problem it would have otherwise gotten incorrect.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: CoT 提示的核心思想是模仿人类在解决复杂的多步骤推理任务时的思维过程。就像人类将复杂问题分解为中间步骤，并在解决每个步骤后依次得到最终答案一样，CoT
    提示鼓励语言模型生成连贯的思维链——一系列中间推理步骤，最终得出解决方案。图 5 展示了一个例子，其中模型通过生成思维链来解决一个本来会出错的数学应用题。
- en: The paper highlights several attractive properties of CoT prompting. Firstly,
    it allows models to break down multi-step problems into manageable intermediate
    steps, allocating additional computation to problems requiring more reasoning
    steps. Secondly, the chain of thought provides an interpretable window into the
    model’s reasoning process, enabling debugging and understanding where the reasoning
    path might have gone away. Thirdly, CoT reasoning can be applied to various tasks
    such as math word problems, commonsense reasoning, and symbolic manipulation,
    making it potentially applicable to any task solvable via language. Finally, sufficiently
    large off-the-shelf language models can readily generate chains of thought simply
    by including examples of such reasoning sequences in the few-shot prompting exemplars.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 论文强调了 CoT 提示的几个吸引人的特性。首先，它允许模型将多步骤问题分解为可管理的中间步骤，并将更多的计算分配给需要更多推理步骤的问题。其次，思维链为模型的推理过程提供了一个可解释的窗口，有助于调试并理解推理路径可能出现偏差的地方。第三，CoT
    推理可以应用于各种任务，如数学题、常识推理和符号操作，这使其有可能应用于任何通过语言可解的任务。最后，足够大的现成语言模型只需通过在少量示例中加入此类推理序列的例子，即可轻松生成思维链。
- en: Reasoning and Acting (ReAct) — enabling Agent capabilities
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理与行动（ReAct）——实现智能体能力
- en: ReAct prompting is another novel technique introduced by [Yao et al. (2023)](https://arxiv.org/pdf/2210.03629)
    that goes one step further by enabling language models to synergize reasoning
    and acting in a seamless manner for general task-solving. The core idea is to
    augment the action space of the model to include not just domain-specific actions
    but also free-form language “thoughts” that allow the model to reason about the
    task, create plans, track progress, handle exceptions, and incorporate external
    information.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 提示是 [Yao 等人（2023）](https://arxiv.org/pdf/2210.03629) 引入的另一种新颖技术，它通过使语言模型能够无缝地协同推理与行动，进一步推动了通用任务求解的进展。其核心思想是扩大模型的行动空间，不仅包括特定领域的行动，还包括自由形式的语言“思维”，使模型能够推理任务、制定计划、跟踪进展、处理异常并结合外部信息。
- en: In ReAct, the language model is prompted with few-shot examples of human trajectories
    that can trigger actions taken in the environment depending on thoughts/reasoning
    steps. For tasks where reasoning is the primary focus, thoughts and actions alternate,
    allowing the model to reason before acting. For more open-ended decision-making
    tasks, thoughts can occur sparsely and asynchronously as needed to create high-level
    plans, adjust based on observations, or query external knowledge.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ReAct 中，语言模型通过少量示例的人类轨迹进行提示，这些轨迹可以根据思维/推理步骤触发在环境中采取的行动。对于以推理为主要任务的任务，思维和行动交替进行，允许模型在行动之前进行推理。对于更开放的决策任务，思维可以根据需要稀疏且异步地出现，以制定高级计划、根据观察进行调整或查询外部知识。
- en: ReAct synergizes the strengths of large language models for multi-step reasoning
    (like recursive chain-of-thought prompting) with their ability to act and interact
    in environments. By grounding reasoning in an external context and allowing information
    to flow bidirectionally between reasoning and acting, ReAct overcomes key limitations
    of prior work that treated them in isolation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 将大语言模型在多步骤推理（如递归思维链提示）方面的优势与它们在环境中行动和互动的能力相结合。通过将推理扎根于外部上下文并允许信息在推理与行动之间双向流动，ReAct
    克服了以往将推理和行动孤立处理的工作中的关键局限性。
- en: The paper proves that ReAct enables strong few-shot performance across question
    answering, fact verification, text games, and web navigation tasks. Compared to
    chain-of-thought prompting, which relies solely on the model’s internal knowledge,
    ReAct allows the model to incorporate up-to-date information from external sources
    into its reasoning trace through actions. Actions perform dynamic context retrieval,
    integrating data sources like RAG, KGAG, or even web searches or API calls. This
    makes the reasoning process more robust and less prone to hallucinations. Conversely,
    injecting reasoning into an acting-only approach allows for more intelligent long-term
    planning, progress tracking, and flexible adjustment of strategies — going beyond
    simple action prediction.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 论文证明，ReAct 在问答、事实验证、文本游戏和网页导航任务中实现了强大的少样本性能。与仅依赖模型内部知识的思维链提示不同，ReAct 允许模型通过行动将外部来源的最新信息融入其推理过程中。行动执行动态上下文检索，整合如
    RAG、KGAG，甚至网页搜索或 API 调用等数据源。这使得推理过程更加稳健，且不容易产生幻觉。相反，将推理注入仅有行动的方式，可以实现更智能的长期规划、进度跟踪和灵活调整策略——超越了简单的行动预测。
- en: '![](../Images/69a3e38fb09d2436cd91a23143203a55.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69a3e38fb09d2436cd91a23143203a55.png)'
- en: 'Figure 6: reasoning and acting (ReAct) prompting— Source: Google'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：推理与行动（ReAct）提示——来源：Google
- en: Figure 6 ([illustration by Google)](https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/)
    shows examples of different prompt engineering techniques (system prompts including
    few-shot examples and instructions are hidden) trying to solve a Q&A problem originating
    from the HotpotQA dataset ([Yang et al, 2018](https://arxiv.org/pdf/1809.09600)).
    As opposed to the other options ReAct demonstrates strong performance on the task
    through combining reasoning and acting in a recursive manner.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图6（[由Google插图](https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/)）展示了不同的提示工程技术示例（包括少量示例和指令的系统提示被隐藏），这些技术尝试解决源自
    HotpotQA 数据集的问答问题（[Yang等，2018](https://arxiv.org/pdf/1809.09600)）。与其他选项相比，ReAct
    通过将推理与行动以递归方式结合，展示了该任务的强大性能。
- en: 'Next:'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来：
- en: In this blog post we explored in-context learning as a powerful approach to
    domain adaptation. After understanding it’s underlying mechanisms, we discussed
    commonly used static and dynamic prompt engineering techniques and their applications.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博文中，我们探讨了上下文学习作为一种强大的领域适应方法。在理解其基本机制后，我们讨论了常用的静态和动态提示工程技术及其应用。
- en: In the third part of this blog post series, with fine-tuning we will discuss
    different approaches for fine-tuning.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本系列博文的第三部分，我们将通过微调讨论不同的微调方法。
- en: '[*Part 1: Introduction into domain adaptation — motivation, options, tradeoffs*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-47a865b16740)
    *Part 2: A deep dive into in-context learning* ***— You’re here!***[*Part 3: A
    deep dive into fine-tuning*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-4860c6d16224)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1部分：领域适应介绍 — 动机、选项、权衡*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-47a865b16740)
    *第2部分：深入探讨上下文学习* ***— 你现在正在阅读此部分！*** [*第3部分：深入探讨微调*](/stepping-out-of-the-comfort-zone-through-domain-adaptation-a-deep-dive-into-dynamic-prompting-4860c6d16224)'
