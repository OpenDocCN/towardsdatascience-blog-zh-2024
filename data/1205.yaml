- en: Safeguard Your LLM Chatbot With Llama Guard 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Llama Guard 2保护您的LLM聊天机器人
- en: 原文：[https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13](https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13](https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894?source=collection_archive---------9-----------------------#2024-05-13)
- en: How to apply content moderation to your LLM’s inputs and outputs for a more
    responsible AI system
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何将内容审查应用到您的LLM输入和输出，以建立更负责任的AI系统
- en: '[](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Dr.
    Leon Eversberg](../Images/56dc3579a29933f7047a9ce60be4697a.png)](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    [Dr. Leon Eversberg](https://medium.com/@leoneversberg?source=post_page---byline--ff5f5aa0f894--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    ·9 min read·May 13, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ff5f5aa0f894--------------------------------)
    ·阅读时间9分钟·2024年5月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f8058b6fb5ad17e0cdf1fd34fe4db5ef.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8058b6fb5ad17e0cdf1fd34fe4db5ef.png)'
- en: Llama Guard. Image created by author with Adobe Photoshop’s AI image generation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Llama Guard。图像由作者使用Adobe Photoshop的AI图像生成工具创建。
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Responsible AI is a big umbrella term that has seen increased interest since
    the rise of ChatGPT and Large Language Models (LLMs).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 责任AI是一个广泛的术语，自从ChatGPT和大型语言模型（LLMs）崛起以来，受到了更多的关注。
- en: In general, the term means that AI systems should not harm humans. In the case
    of LLMs, this can mean for example that language models should not produce hateful
    responses or help the user with illegal activities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，这个术语意味着AI系统不应对人类造成伤害。就LLMs而言，这可能意味着例如语言模型不应产生仇恨性回应或协助用户进行非法活动。
- en: Llama Guard is an LLM-based safeguard for chatbots, developed by Meta. It is
    part of Meta’s [Purple Llama](https://llama.meta.com/purple-llama/) umbrella project
    for responsible AI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Llama Guard是一个基于LLM的聊天机器人安全保护工具，由Meta开发。它是Meta的[Purple Llama](https://llama.meta.com/purple-llama/)责任AI项目的一部分。
- en: Meta recently released Llama Guard 2\. This is an update of the old Llama Guard
    version 1, which was based on Llama 2.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Meta最近发布了Llama Guard 2。这是旧版Llama Guard 1的更新，后者是基于Llama 2的。
- en: Llama Guard 2 is a trained LLM that acts as a **binary classifier**, classifying
    user questions and also LLM responses as either **unsafe or safe**. The model
    is **based on the new Llama 3** and can be freely downloaded from Hugging Face
    after accepting Meta’s Llama 3 community license agreement [1].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Llama Guard 2是一个经过训练的LLM，充当**二元分类器**，将用户问题以及LLM的回应分类为**不安全或安全**。该模型**基于新的Llama
    3**，在接受Meta的Llama 3社区许可协议后，可以从Hugging Face自由下载[1]。
