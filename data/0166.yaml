- en: Adaption of Generative Methods for Anonymization will Revolutionize Data Sharing
    and Privacy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成方法在匿名化中的应用将彻底改变数据共享和隐私保护。
- en: 原文：[https://towardsdatascience.com/adaption-of-generative-methods-for-anonymization-will-revolutionize-data-sharing-and-privacy-d35b6fe704a2?source=collection_archive---------10-----------------------#2024-01-17](https://towardsdatascience.com/adaption-of-generative-methods-for-anonymization-will-revolutionize-data-sharing-and-privacy-d35b6fe704a2?source=collection_archive---------10-----------------------#2024-01-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/adaption-of-generative-methods-for-anonymization-will-revolutionize-data-sharing-and-privacy-d35b6fe704a2?source=collection_archive---------10-----------------------#2024-01-17](https://towardsdatascience.com/adaption-of-generative-methods-for-anonymization-will-revolutionize-data-sharing-and-privacy-d35b6fe704a2?source=collection_archive---------10-----------------------#2024-01-17)
- en: Taking a break from the generative AI hype around LLMs and foundation models,
    let’s explore how synthetic data created by more traditional generative AI models
    are set for mainstream adoption.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摆脱围绕大语言模型和基础模型的生成AI热潮，让我们来探讨由传统生成AI模型创建的合成数据如何准备迎接主流应用。
- en: '[](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[![Arne
    Rustad](../Images/e7c612d19955630dea1acd258aa303cc.png)](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)
    [Arne Rustad](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[![Arne
    Rustad](../Images/e7c612d19955630dea1acd258aa303cc.png)](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)
    [Arne Rustad](https://arnerustad.medium.com/?source=post_page---byline--d35b6fe704a2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)
    ·10 min read·Jan 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d35b6fe704a2--------------------------------)
    ·阅读时间10分钟·2024年1月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7c6f4001341b66d28a52ff9ac1699da4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c6f4001341b66d28a52ff9ac1699da4.png)'
- en: Image generated by Arne Rustad using DALLE-3.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由Arne Rustad使用DALLE-3生成的图像。
- en: '**Data is as valuable as gold, and sharing it responsibly presents both immense
    opportunities and significant challenges for organizations and society. To ethically
    process data and avoid legal repercussions, organizations must ensure they do
    not violate the privacy of individuals contributing their data**. **Despite the
    vast potential of data sharing, traditional anonymization methods are becoming
    increasingly inadequate to tackle the challenges presented by our information-saturated
    digital age. By instead harnessing advanced generative methods we can create realistic
    but privacy-compliant synthetic data that retains the utility of the original
    data. Join us as we unveil the gateway to a wealth of untapped data opportunities.**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据如同黄金一样宝贵，负责任地共享数据为组织和社会带来了巨大的机遇与挑战。为了在伦理上处理数据并避免法律后果，组织必须确保不侵犯那些提供数据的个人的隐私**。**尽管数据共享具有巨大的潜力，但传统的匿名化方法已逐渐无法应对我们信息饱和的数字时代所带来的挑战。通过利用先进的生成方法，我们可以创建既符合隐私要求又保持原始数据实用性的合成数据。加入我们，一起揭开这扇通向丰富数据机会的大门。**'
- en: In this article, we specifically emphasize the use of synthetic data in business
    contexts, addressing a gap we have identified in existing literature. While our
    focus here is on the corporate sphere, the insights and applications of synthetic
    data are equally relevant to other organizations and individuals engaged in data
    sharing, especially within the research community.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中，我们特别强调了合成数据在商业环境中的应用，解决了我们在现有文献中发现的一个空白。虽然我们在这里的重点是企业领域，但合成数据的洞见和应用对其他参与数据共享的组织和个人同样具有重要意义，尤其是在研究社区中。
- en: Why do you even need anonymization?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么你需要匿名化呢？
- en: The goal of anonymization is to prevent re-identification of individuals by
    making it impossible, or at least highly unlikely, to connect the data to or divulge
    information about a specific individual. Anonymizing data before sharing it has
    an intrinsic moral value in respecting the privacy of individuals, but as the
    public becomes more and more concerned with how their data is used, and governments
    introduce stricter regulations ([GDPR](https://gdpr.eu/what-is-gdpr/), [CCPA](https://oag.ca.gov/privacy/ccpa)
    etc.), it has become something all organizations need to pay attention to unless
    they want to risk massive reputation losses, law suites, and fines.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 匿名化的目标是通过使数据与特定个人无法关联或至少极不可能关联，从而防止个人重新识别。匿名化数据并在分享前处理它，具有内在的道德价值，因为它尊重个人隐私。但随着公众对数据使用的关注日益增加，政府也引入了更严格的法规（如[GDPR](https://gdpr.eu/what-is-gdpr/)、[CCPA](https://oag.ca.gov/privacy/ccpa)等），这已经成为所有组织需要关注的事情，除非他们愿意冒着巨大的声誉损失、诉讼和罚款的风险。
- en: At the same time, by not daring to leverage the full potential of big data and
    data sharing, organizations risk overlooking significant business opportunities,
    innovative advancements, and potential cost-savings. It also hampers our ability
    to solve larger societal challenges. Utilizing anonymized data presents a secure
    and compliant way to harness the value of your data as it is exempt from the restrictions
    of GDPR.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，如果不敢充分利用大数据和数据共享的潜力，组织将面临忽视重大商业机会、创新进展和潜在成本节约的风险。这也阻碍了我们解决更大社会问题的能力。利用匿名化数据提供了一种安全且合规的方式来挖掘数据的价值，因为它不受GDPR等法规的限制。
- en: The underestimated challenge of anonymization
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 被低估的匿名化挑战
- en: The task of anonymizing data is a complex and often underestimated challenge.
    Far too many believe anonymization to be as easy as removing direct identifiers
    such as name, social security number, and address. However, humans are often more
    distinguishable than commonly assumed. In a groundbreaking study from the year
    2000, computer scientist Latanya Sweeny demonstrated that just three pieces of
    information — date of birth, gender, and zip code — could uniquely identify 87%
    of the U.S population¹. Bridging the gap to more recent times, a 2019 study published
    in the Nature journal further underscores this point, revealing that in a database
    of 7 million individuals, merely 15 data points were sufficient to identify 99.98%
    of them².
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据匿名化的任务是一个复杂且常常被低估的挑战。许多人认为匿名化只需要去除直接标识符，如姓名、社会保障号和地址。然而，人的身份往往比常见的假设更加易于辨识。在2000年进行的一项开创性研究中，计算机科学家Latanya
    Sweeny证明了仅凭三项信息——出生日期、性别和邮政编码——就可以唯一识别87%的美国人口¹。跨越到更近的时代，2019年《自然》期刊发表的一项研究进一步强调了这一点，揭示在一个包含700万人的数据库中，仅15个数据点就足以识别其中99.98%的人²。
- en: In the age of big data and in a time where we both willingly and unwillingly
    share more information about ourselves than ever before, anonymization is much
    more fragile and risky than it initially seems.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在大数据时代以及我们无论是自愿还是非自愿地分享个人信息的时代，数据匿名化比最初看起来更为脆弱和具有风险。
- en: For a dataset to be adequately anonymized it must not only have a low reidentification
    risk when analyzed by itself, but also when cross-referenced with all the other
    information freely available on the web. This includes publicly available datasets,
    personal details we freely share on social platforms, and potentially even the
    stolen sensitive information about us that is available on the dark web. In other
    words, an anonymized dataset must also be resistant to linkage attacks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使数据集充分匿名化，它不仅必须在单独分析时具有较低的重新识别风险，而且在与网络上自由可用的所有其他信息交叉引用时，也应具有较低的风险。这些信息包括公开的数据库、我们在社交平台上自由分享的个人细节，甚至可能包括被盗的、在暗网上可获取的关于我们的敏感信息。换句话说，一个匿名化的数据集还必须能抵抗关联攻击。
- en: Netflix’s unpleasant experience with failed anonymization should serve as a
    wake-up call
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Netflix在数据匿名化失败中的不愉快经历应该成为警钟
- en: A textbook example of this occurred in 2006 when Netflix, aiming to enhance
    its movie recommendation algorithm, released what they believed to be an anonymized
    dataset for a public competition. The dataset contained ratings from 480,000 users
    across 18,000 movies. Despite the users being anonymized and even intentional
    errors systematically inserted into the data, it proved insufficient. A paper
    published by researchers from the University of Texas demonstrated how many users
    could easily be re-identified by cross-referencing with publicly accessible movie
    ratings on IMDB, inadvertently exposing the user’s complete movie viewing history.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，Netflix为了增强其电影推荐算法，发布了他们认为是匿名化数据集的公开竞赛。该数据集包含了来自480,000个用户对18,000部电影的评分。尽管用户已被匿名化，并且故意在数据中插入了系统性错误，但这一举措仍然不足以保证隐私安全。德克萨斯大学的研究人员发布了一篇论文，展示了如何通过与IMDB上公开的电影评分进行交叉引用，轻松地重新识别出许多用户，从而无意中暴露了用户完整的电影观看历史。
- en: This incident might seem harmless, but bear in mind that our movie tastes can
    sometimes reveal deep insights into our personal lives, such as sexual orientation
    or political beliefs. As such, when Netflix attempted to initiate a similar competition
    in 2009, they were forced to cancel it due to a class-action lawsuit, highlighting
    the serious privacy risks involved³.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这起事件看似无害，但请记住，我们的电影口味有时可以揭示我们个人生活中的深层次信息，比如性取向或政治信仰。因此，当Netflix在2009年尝试发起类似的竞赛时，他们因集体诉讼而被迫取消，突显了其中涉及的严重隐私风险³。
- en: '![](../Images/2331afb35f03f85a1623b42afd061c6a.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2331afb35f03f85a1623b42afd061c6a.png)'
- en: 'Figure 1: A simplified example of how data linkage was performed on the Netflix
    prize dataset. *Please note that the method from the paper did not rely on exact
    matches. Figure created by authors.*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：简化示例，展示了如何在Netflix竞赛数据集上进行数据关联。*请注意，论文中的方法并不依赖于精确匹配。图由作者创建。*
- en: After reviewing the challenges associated with anonymization, it should be unsurprising
    that conventional anonymization techniques often need to be very invasive to even
    be marginally effective. As traditional methods anonymize through removing or
    obscuring information contained in the original data, the result is often a huge
    loss in data utility.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在回顾与匿名化相关的挑战后，不难理解，传统的匿名化技术通常需要非常具有侵入性才能勉强有效。由于传统方法通过去除或模糊化原始数据中的信息来实现匿名化，结果往往会导致数据效用的巨大损失。
- en: Synthetic data — an alternative to traditional anonymization
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据——传统匿名化的替代方案
- en: Artificial intelligence has been used to create synthetic data for a long time,
    but the invention of variational autoencoders (VAE), generative adversarial networks
    (GAN), and diffusion models, in respectively 2013, 2014, and 2015, were significant
    milestones on the path to creating realistic synthetic data. Since then, lots
    of incremental advancements from the scientific community have enabled us to precisely
    capture the complex statistical patterns in our datasets, whether they are tabular,
    time series, images, or other formats.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能已经被用于创建合成数据很长时间了，但变分自编码器（VAE）、生成对抗网络（GAN）和扩散模型分别在2013年、2014年和2015年的发明，标志着创建真实合成数据的重要里程碑。从那时起，科学界的许多渐进式进展使我们能够精确捕捉数据集中的复杂统计模式，无论这些数据是表格型的、时间序列的、图像形式的，还是其他格式。
- en: The abovementioned models are generative methods. Generative methods are a class
    of machine learning techniques that can create new data by capturing the patterns
    and structures of existing data. They do not merely replicate existing data but
    instead create unique and diverse examples that resemble the original in terms
    of underlying features and relationships. Think of it as a new generation of data,
    like how each new generation of humans resembles their ancestors.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上述模型属于生成方法。生成方法是一类机器学习技术，通过捕捉现有数据的模式和结构，可以创建新的数据。它们不仅仅是复制现有的数据，而是创造出独特且多样化的例子，这些例子在潜在特征和关系方面与原始数据相似。可以把它想象成一种新一代的数据，就像每一代人类都与他们的祖先相似一样。
- en: The introduction of generative methods to the mainstream public through OpenAI’s
    chat robot Chat-GPT and image generator DALLE-2 was nothing short of a tremendous
    success. People were amazed with the ability of these tools to effectively perform
    tasks many believed were reserved for human intelligence and creativity. This
    has propelled Generative AI into becoming one of the most used buzz words of the
    year. Whilst these new foundation models are game changers and may even revolutionize
    our society, more traditional generative methods still have a vital role to play.
    Gartner has estimated that by 2030, synthetic data will completely overshadow
    real data in AI models⁴, and for data sharing and data augmentation of specific
    datasets, traditional methods such as GAN, VAE, and diffusion models (not foundational)
    are, at least for now, still the best choice.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过OpenAI的聊天机器人Chat-GPT和图像生成器DALLE-2，生成方法成功地进入了主流公众视野。人们对这些工具能够有效地完成许多人认为只有人类智力和创造力才能完成的任务感到惊讶。这使得生成性AI成为今年最常用的热词之一。尽管这些新的基础模型具有革命性的潜力，甚至可能改变我们的社会，但传统的生成方法依然扮演着至关重要的角色。Gartner估计，到2030年，合成数据将在AI模型中完全超越真实数据⁴，尤其是在特定数据集的数据共享和数据增强方面，传统方法如GAN、VAE和扩散模型（非基础性模型）至少在目前仍然是最佳选择。
- en: Unlike traditional anonymization techniques, generative methods do not destroy
    valuable information.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与传统的匿名化技术不同，生成方法不会破坏有价值的信息。
- en: Synthetic data from generative methods thus offers an optimal solution, combining
    the best of both worlds. Advanced generative methods can learn the complex patterns
    inherent in real-world data, enabling them to produce realistic yet fictitious
    new examples. This effectively avoids the risky one-to-one relation to the original
    dataset that traditional methods suffer from. On aggregate level the statistical
    properties are retained, meaning we can interact with these synthetic dataset
    as if we would actual data, whether this is to compute summary statistics or train
    machine learning models.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 生成方法的合成数据因此提供了一个最佳解决方案，结合了两者的优势。先进的生成方法能够学习现实数据中固有的复杂模式，使得它们能够生成逼真但虚构的新样本。这有效避免了传统方法在一对一映射到原始数据集时所面临的风险。从整体上看，统计特性得以保留，这意味着我们可以像操作真实数据一样与这些合成数据集进行互动，无论是用于计算汇总统计还是训练机器学习模型。
- en: Synthetic data will create value for a multitude of industries
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据将为多个行业创造价值
- en: 'The use of AI-generated synthetic data offers a solution for privacy-regulated
    businesses to share data, which was previously difficult due to privacy concerns.
    These industries include, but are not at all limited to:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI生成的合成数据为隐私受限的企业提供了解决方案，使得数据共享成为可能，这在过去由于隐私问题而困难重重。这些行业包括但绝不限于：
- en: '**Healthcare:** Currently, researchers often face lengthy and cumbersome processes
    to access real patient data, significantly slowing down the pace of medical advancements.
    Synthetic medical records present a transformative solution for accelerating medical
    research while safeguarding patient confidentiality. Additionally, generating
    synthetic data offers an effective way to address biases in healthcare datasets
    by intentionally augmenting underrepresented groups, thereby contributing to more
    inclusive research outcomes.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗健康：** 目前，研究人员通常面临着访问真实患者数据的漫长而繁琐的过程，极大地拖慢了医学进展的步伐。合成医疗记录为加速医学研究并保护患者隐私提供了变革性的解决方案。此外，生成合成数据为解决医疗数据集中的偏差提供了有效途径，通过有意增强代表性不足的群体，从而促进更具包容性的研究成果。'
- en: '**Financial services:** Transactional data, inherently sensitive and identifiable,
    presents a unique challenge in the financial sector. Synthetic data arises as
    a key solution, enabling both internal and external data sharing while effectively
    addressing privacy issues. Moreover, its utility extends to augmenting limited
    or skewed datasets, an aspect particularly crucial in enhancing fraud detection
    and anti-money laundering efforts.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融服务：** 交易数据本质上是敏感且可识别的，这在金融领域带来了独特的挑战。合成数据成为关键解决方案，能够在有效解决隐私问题的同时，实现内部和外部数据共享。此外，合成数据还可以用于增强有限或不平衡的数据集，特别是在增强欺诈检测和反洗钱工作方面具有重要作用。'
- en: 'In general, all businesses can utilize synthetic datasets to improve privacy,
    and we encourage you to think of how synthetic data can benefit you specifically.
    To help you grasp the potential of synthetic data we include a few selected use
    cases:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，所有企业都可以利用合成数据集来提升隐私保护，我们鼓励你思考合成数据如何具体对你产生帮助。为了帮助你理解合成数据的潜力，我们提供了一些精选的应用案例：
- en: '**Third-party sharing:** In scenarios where a company needs third-party analysis
    on customer or user data, synthetic datasets provide a viable alternative to sharing
    sensitive information. This approach can be particularly beneficial during a selection
    phase when evaluating multiple external partners or to enable immediate project
    start-up, bypassing the time-consuming legal processes required for sharing real
    data.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三方共享：** 在公司需要第三方分析客户或用户数据的场景中，合成数据集提供了一个可行的替代方案，以避免共享敏感信息。这种方法在选择阶段特别有益，尤其是在评估多个外部合作伙伴时，或者为了启用项目的快速启动，绕过共享真实数据所需的耗时法律程序。'
- en: '**Internal data sharing:** Even internally, navigating the complexities of
    sharing sensitive information, such as employee and HR data is often challenging
    due to strict regulations. Synthetic data provides a solution, allowing company
    leadership to improve internal knowledge transfer and data sharing while ensuring
    the privacy of individual employees. This method is equally advantageous for handling
    datasets with sensitive customer information. By employing synthetic data, organizations
    can securely distribute these datasets more widely within the company. Enabling
    expansive sharing, this approach empowers a larger segment of the organization
    to engage in problem-solving and decision-making, thereby boosting overall efficiency
    and collaboration while simultaneously upholding the utmost respect for privacy.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部数据共享：** 即使在内部，处理敏感信息的共享，如员工和人力资源数据，往往由于严格的法规而具有挑战性。合成数据提供了一种解决方案，使公司领导能够在确保员工隐私的前提下，改善内部知识转移和数据共享。这一方法对于处理含有敏感客户信息的数据集同样具有优势。通过使用合成数据，组织可以更广泛地在公司内部分发这些数据集。通过扩展共享，这种方法使更多的组织成员能够参与问题解决和决策制定，从而提升整体效率与协作，同时充分尊重隐私。'
- en: '**Retain data insights longer:** Under the stringent regulations of GDPR, organizations
    are required to delete user data after its intended processing purpose or upon
    user request. However, this necessary compliance poses the risk of losing valuable
    insights contained within the data. Synthetic data offers an innovative resolution
    to this challenge. It preserves the essence and utility of the original data whilst
    adhering to legal requirements. Thereby ensuring that the value of the data is
    preserved for future analytical and AI-driven pursuits.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延长数据洞察的保留时间：** 根据GDPR的严格规定，组织需要在用户数据完成预定处理目的后，或根据用户请求删除数据。然而，这一合规要求可能带来丧失数据中宝贵洞察的风险。合成数据为这一挑战提供了创新的解决方案。它在遵守法律要求的同时，保留了原始数据的本质和实用性，从而确保数据的价值得以保留，用于未来的分析和人工智能驱动的工作。'
- en: Combining synthetic data with privacy enhancing tests and technologies is the
    future juggernaut
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将合成数据与隐私增强测试和技术结合起来是未来的强大推动力。
- en: Synthetic data stands as a very promising solution for addressing data privacy
    and accessibility challenges, yet it is not foolproof. The accuracy of generative
    models is paramount; a poorly calibrated model can lead to synthetic data that
    inadequately reflects real-world conditions or, in some cases, too closely resembles
    the original datasets, thereby jeopardizing privacy. Recognizing this, robust
    methods have been developed to verify the output quality of synthetic data, both
    with respect to utility and privacy. These critical evaluations are imperative
    for effectively leveraging synthetic data, ensuring sensitive information is not
    inadvertently exposed. Most reputable synthetic data providers recognize this
    necessity and inherently include such quality assurance processes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据作为解决数据隐私和可访问性挑战的有前景的解决方案，尽管如此，它并非完美无缺。生成模型的准确性至关重要；如果模型调校不当，可能导致合成数据无法充分反映现实条件，或者在某些情况下，合成数据过于接近原始数据集，从而危及隐私。意识到这一点，已经开发出强有力的方法来验证合成数据的输出质量，既考虑其实用性，也考虑隐私性。这些关键的评估对于有效利用合成数据至关重要，确保敏感信息不会无意中泄露。大多数知名的合成数据提供商都认识到这一必要性，并在其过程中内建了质量保证措施。
- en: A promising enhancement is the combination of differential privacy with synthetic
    data generators. Differential privacy is a rigorous mathematical definition of
    privacy and if used correctly, provides a strong guarantee that individual privacy
    is preserved during statistical analysis.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有前景的增强方式是将差分隐私与合成数据生成器相结合。差分隐私是隐私的严格数学定义，如果正确使用，它能提供强有力的保障，确保在统计分析过程中个人隐私得到保护。
- en: Differentially private models are machine learning models designed to preserve
    privacy by incorporating differential privacy techniques during training or inference.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 差分隐私模型是通过在训练或推理过程中融入差分隐私技术来设计的机器学习模型，旨在保护隐私。
- en: This is particularly beneficial for datasets containing distinct outliers or
    when an elevated level of privacy assurance needs to be guaranteed. Differentially
    private models also enable sharing of the data synthesizer model itself, not merely
    the synthetic data it generates. However, it is important to underscore that such
    sharing necessitates the application of differential privacy methods throughout
    the model’s training process. In contrast, standard data synthesizers typically
    cannot safely be shared, as they may inadvertently reveal sensitive information
    when subjected to advanced machine learning techniques aimed at extracting information.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于包含明显异常值的数据集，或者需要保证更高隐私级别的情况特别有利。差分隐私模型还支持共享数据生成器模型本身，而不仅仅是其生成的合成数据。然而，重要的是要强调，这种共享需要在模型训练过程中应用差分隐私方法。相比之下，标准数据生成器通常不能安全共享，因为它们在接受旨在提取信息的先进机器学习技术时，可能无意中泄露敏感信息。
- en: '![](../Images/49cf9c9ef10f029e2714906338a6a204.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49cf9c9ef10f029e2714906338a6a204.png)'
- en: 'Figure 2: Visualization of differential privacy in synthetic data generation
    using the Netflix example. Figure created by authors.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：使用 Netflix 示例可视化合成数据生成中的差分隐私。图表由作者创建。
- en: In Figure 2, we exemplify the principle of differentially private models using
    the case of the Netflix dataset. The core idea here is to cap the influence of
    a single data record upon the learned data distribution by the differentially
    private data synthesizer. Put simply, if we were to retrain the model on the same
    dataset, minus the data from one individual, the resultant data distribution would
    not show substantial deviation. The maximum influence of a single observation
    is a quantifiable parameter of the differentially private model. This leads to
    a trade-off between privacy and utility, but a satisfactory compromise can often
    be found, ensuring that both privacy and utility are upheld to a satisfactory
    degree.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 2 中，我们以 Netflix 数据集为例，展示了差分隐私模型的原理。这里的核心思想是，通过差分隐私数据生成器来限制单个数据记录对学习数据分布的影响。简单来说，如果我们在同一数据集上重新训练模型，去除某个个体的数据，那么最终的数据显示不会有显著的偏差。单个观测值的最大影响是差分隐私模型的一个可量化参数。这导致了隐私和效用之间的权衡，但通常可以找到一个令人满意的折中方案，确保隐私和效用都能得到充分的保障。
- en: AI-generated synthetic data is ready for mainstream adoption
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI生成的合成数据已经准备好迎接主流应用
- en: Synthetic data is rapidly asserting itself as a crucial technology for enhancing
    privacy, set to become a mainstay in modern data management. Its utility extends
    beyond simply safeguarding privacy, serving as a conduit to a wealth of untapped
    data potential — a prospect being leveraged by numerous forward-thinking businesses.
    In this article, we have highlighted the benefits of synthetic data in facilitating
    secure data sharing. Yet, its potential in data augmentation is perhaps even more
    exciting. By enabling data imputation and rebalancing, synthetic data can profoundly
    boost the efficiency of machine learning algorithms, effectively delivering significant
    added value with minimal investment of cost or effort. We invite you to explore
    the myriad of ways in which synthetic data can transform your business operations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据正在迅速确立自己作为增强隐私的重要技术，预计将在现代数据管理中成为主流。它的作用不仅仅是保护隐私，还能作为通向丰富的未开发数据潜力的桥梁——这一前景正被许多具有前瞻性的企业所利用。在本文中，我们突出了合成数据在促进安全数据共享方面的优势。然而，它在数据增强中的潜力也许更令人兴奋。通过支持数据填充和重平衡，合成数据可以显著提高机器学习算法的效率，有效地以最小的成本和努力提供显著的附加价值。我们邀请您探索合成数据如何在多种方式上转变您的业务运营。
- en: About the authors
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于作者
- en: '[**Arne Rustad**](https://www.linkedin.com/in/arne-rustad/) is a Data Scientist
    at BearingPoint in Oslo, with experience from multiple generative AI projects.
    He wrote his master’s thesis on synthetic data generation for tabular data where
    he developed a new Generative Adversarial Network (GAN) model achieving state-of-the-art
    performance. Arne obtained his master’s thesis in Physics and Mathematics from
    the Norwegian University of Science and Technology (NTNU). Email address: [arne.rustad@bearingpoint.com](mailto:arne.rustad@bearingpoint.com).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Arne Rustad**](https://www.linkedin.com/in/arne-rustad/) 是奥斯陆BearingPoint的数据科学家，参与多个生成型人工智能项目，拥有丰富经验。他的硕士论文研究了表格数据的合成数据生成，提出了一种新的生成对抗网络（GAN）模型，达到了最先进的性能。Arne获得了挪威科技大学（NTNU）物理学与数学硕士学位。电子邮件地址：[arne.rustad@bearingpoint.com](mailto:arne.rustad@bearingpoint.com)。'
- en: '[**Helene Semb**](https://www.linkedin.com/in/helene-semb-705888160/)is a Data
    Scientist at BearingPoint in Oslo, with machine learning experience in computer
    vision and object detection. Helene recently obtained her master’s degree in Cybernetics
    and Robotics from the Norwegian University of Science and Technology (NTNU). Email
    address: [helene.semb@bearingpoint.com](mailto:helene.semb@bearingpoint.com).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Helene Semb**](https://www.linkedin.com/in/helene-semb-705888160/) 是奥斯陆BearingPoint的数据科学家，拥有计算机视觉和物体检测方面的机器学习经验。Helene最近获得了挪威科技大学（NTNU）控制学与机器人学硕士学位。电子邮件地址：[helene.semb@bearingpoint.com](mailto:helene.semb@bearingpoint.com)。'
- en: References
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] L. Sweeney, [Simple demographics often identify people uniquely](https://privacytools.seas.harvard.edu/sites/projects.iq.harvard.edu/files/privacytools/files/paper1.pdf)
    (2000), Health (San Francisco)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] L. Sweeney, [简单的 demographic 信息通常能唯一识别个人](https://privacytools.seas.harvard.edu/sites/projects.iq.harvard.edu/files/privacytools/files/paper1.pdf)（2000年），《健康》（旧金山）'
- en: '[2] L. Rocher, J. Hendrickx and Y. De Montjoye, [Estimating the success of
    re-identifications in incomplete datasets using generative models](https://www.nature.com/articles/s41467-019-10933-3;)
    (2019), Nature communications'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] L. Rocher, J. Hendrickx 和 Y. De Montjoye, [使用生成模型估计在不完整数据集中的重新识别成功率](https://www.nature.com/articles/s41467-019-10933-3;)（2019年），《自然通讯》'
- en: '[3] Wired, [Netflix Cancels Recommendation Contest After Privacy Lawsuit](https://www.wired.com/2010/03/netflix-cancels-contest/)
    (2010, March 12)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Wired, [Netflix因隐私诉讼取消推荐竞赛](https://www.wired.com/2010/03/netflix-cancels-contest/)（2010年3月12日）'
- en: '[4] Gartner, [Is Synthetic Data the Future of AI?](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai)
    (2022, June 22)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Gartner, [合成数据是人工智能的未来吗？](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai)（2022年6月22日）'
