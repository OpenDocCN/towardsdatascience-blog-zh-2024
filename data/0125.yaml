- en: Binary Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二分类
- en: 原文：[https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12](https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12](https://towardsdatascience.com/binary-classification-unpacking-the-real-significance-and-limitations-of-traditional-metrics-810069be630c?source=collection_archive---------11-----------------------#2024-01-12)
- en: Unpacking the Real Significance and Limitations of Traditional Metrics
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆解传统指标的真正意义与局限性
- en: '[](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[![gabriel
    costa](../Images/7ae80a70ac22128573243d5cb9764102.png)](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    [gabriel costa](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[![gabriel
    costa](../Images/7ae80a70ac22128573243d5cb9764102.png)](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    [gabriel costa](https://medium.com/@costaleirbag?source=post_page---byline--810069be630c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    ·9 min read·Jan 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--810069be630c--------------------------------)
    ·9 分钟阅读·2024年1月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'The work of classification can be seen as a way of summarizing the complexity
    of structures into finite classes, and it is often useful to make life boring
    enough that we can reduce such structures into *two single types*. These labels
    may have obvious interpretations, as in the case where we differentiate Statisticians
    from Data Scientists (possibly using income as a unique plausible feature), or
    they may even be a suffocating attempt to reduce experimental evidence into sentences,
    rejecting or not a null hypothesis. Embracing the metalanguage, we attribute a
    classification label to the work itself of sum up stuff into two different types:
    **Binary Classification**. This work is an attempt at a deeper description of
    this specific label, *bringing a probabilistic interpretation of what the decision
    process means and the metrics we use to evaluate our results.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 分类工作的本质可以看作是将结构的复杂性总结为有限的类别，这种方法常常对简化生活非常有用，使我们能够将复杂的结构简化为*两种单一类型*。这些标签可能有明显的解释，比如我们通过收入这一独特且合理的特征来区分统计学家和数据科学家；也可能是压抑的尝试，将实验证据简化为一句话，用来接受或拒绝零假设。拥抱元语言，我们将分类标签归属于将信息总结成两种不同类型的工作：**二分类**。本工作旨在对这一特定标签进行更深的描述，*为决策过程带来概率解释，并分析我们用来评估结果的指标。*
- en: Modeling populations as distributions
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将种群建模为分布
- en: When we try to describe and differentiate an object, we aim to find specific
    characteristics that highlight its uniqueness. *It is expected that for many attributes
    this difference is not consistently accurate across a population.*
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们试图描述并区分一个对象时，我们的目标是找到突出其独特性的特征。*预计对于许多属性，这种差异在整个种群中并不总是准确一致的。*
- en: 'For an usual problem of two classes with different n features (V1, … Vn), we
    can se how these feature values distribute and try to make conclusions from them:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个常见的具有不同 n 个特征（V1, … Vn）的二分类问题，我们可以查看这些特征值的分布，并试图从中得出结论：
- en: '![](../Images/b5ab6ecf21e310b75e2beb2c58d51dcf.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5ab6ecf21e310b75e2beb2c58d51dcf.png)'
- en: 'Figure 1: Distribution of 8 different features Vn for two different classes
    (negative class: red; positive class: blue). This data is from a Kaggle challenge
    which is referenced at the end of the text.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：两类（负类：红色；正类：蓝色）不同特征 Vn 的分布。此数据来自于 Kaggle 挑战，文末有相关引用。
- en: If the task were to use one of those features to guide our decision process,
    the strategy of deciding, given an individual’s *v_n* value,
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务是使用这些特征中的一个来指导我们的决策过程，给定个体的 *v_n* 值来决定，
- en: it would be intuitive to predict the class with the highest frequency (or highest
    probability, if our histograms are good estimators of our distributions). For
    instance, if v4 measure for a individual were higher than 5, then it would be
    very likely that it is a positive.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 预测类别时，直觉上可以选择频率最高的类别（或者如果我们的直方图是良好的分布估计器，则选择概率最高的类别）。例如，如果某个个体的v4测量值大于5，那么它很可能是正类。
- en: However, *we can do more than that*, and take advantage different features,
    so that we can synthesize the information into a single distribution. **This is
    the job of the score function *S(x)***. The score function will do a regression
    to squeeze the feature distributions in one unique distribution ***P(s, y)***,
    which can be conditioned to each of the classes, with ***P(s|y=0)* for negatives**
    *(y=0)* and ***P(s|y=1)* for positives** *(y=1)*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，*我们可以做得更多*，利用不同的特征，将信息合成成一个单一的分布。**这正是得分函数 *S(x)* 的任务**。得分函数将进行回归，将特征分布压缩到一个唯一的分布
    ***P(s, y)***，并且可以根据每个类别进行条件化，***P(s|y=0)* 表示负类** *(y=0)* 和 ***P(s|y=1)* 表示正类**
    *(y=1)*。
- en: From this single distribution, **we choose** **a decision threshold t** that
    determines whether our estimate for a given point — which is represented by *ŷ*
    — will be positive or negative. **If s is greater than *t*, we assign a positive
    label; otherwise, a negative.**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个单一的分布中，**我们选择** **一个决策阈值 t**，该阈值决定我们对给定点的估计——用 *ŷ* 表示——是正类还是负类。**如果 s 大于
    *t*，我们就赋予正类标签；否则，赋予负类标签。**
- en: '![](../Images/1d44cfd6bb8e63197363e22a89615bc7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d44cfd6bb8e63197363e22a89615bc7.png)'
- en: 'Figure 2: graphical illustration of binary classification process. The score
    function squeezes the n-dimensional feature space into a distribution P(s, y).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：二分类过程的图示。得分函数将n维特征空间压缩为分布 P(s, y)。
- en: '***Given the distribution******P(s, y, t)*** *where s, y and t represents the
    values of the score, class and threshold respectively,* ***we have a complete
    description of our classifier.***'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '***给定分布******P(s, y, t)*** *其中 s、y 和 t 分别代表分数、类别和阈值的值，* ***我们就得到了分类器的完整描述。***'
- en: Metrics for our classifier (marginal and conditional distributions)
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们分类器的度量标准（边际和条件分布）
- en: '*Developing metrics for our classifier can be regarded as the pursuit of quantifying
    the discriminative nature of p(s|P) and p(s|N).*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*为我们的分类器开发度量标准可以看作是量化 p(s|P) 和 p(s|N) 区分能力的追求。*'
- en: Typically will be a overlap over the two distributions *p(s|P)* and *p(s|N)*
    that makes a perfect classification impossible. So, given a threshold, one could
    ask what is the probability *p(s > t|N)* — False Positive Rate (FPR) — that we
    are misclassifying negative individuals as positives, for example.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，两个分布 *p(s|P)* 和 *p(s|N)* 会有重叠，导致无法完美分类。因此，给定一个阈值，我们可以问一下 *p(s > t|N)*
    — 假阳性率（FPR） — 也就是我们将负类个体错误分类为正类的概率，例如。
- en: 'Surely we can pile up a bunch of metrics and even give names — inconsistently
    — for each of them. But, for all purposes, it will be sufficient define four probabilities
    and their associated rates for the classifier:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以堆砌大量的度量标准，甚至给它们起名——尽管这些命名可能不一致——但为了所有的目的，我们只需定义四个概率及其相关的比率来表示分类器的性能：
- en: '**True Positive Rate (*tpr*)**: *p(s > t|P) = TP/(TP+FN)*;'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**真正阳性率 (*tpr*)**: *p(s > t|P) = TP/(TP+FN)*;'
- en: '**False Positive Rate (*fpr*):** *p(s > t|N) = FP/(FP+TN)*;'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**假阳性率 (*fpr*):** *p(s > t|N) = FP/(FP+TN)*;'
- en: '**True Negative Rate (*tnr*):** *p(s ≤ t|N) = TN/(FP+TN)*;'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**真正阴性率 (*tnr*):** *p(s ≤ t|N) = TN/(FP+TN)*;'
- en: '**False Negative Rate (*fnr*):** *p(s ≤ t|P) = FN/(TP+FN)*.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**假阴性率 (*fnr*):** *p(s ≤ t|P) = FN/(TP+FN)*.'
- en: If you are already familiar with the subject, you may have noticed that *these
    are the metrics that we define from confusion matrix of our classifier*. As this
    matrix is defined for each chosen decision threshold, we can view it as a representation
    of the conditional distribution *P(ŷ, y|t)*, where each of these objects is part
    of a class of confusion matrices that completely describe the performance of our
    classifier.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经熟悉这个主题，你可能会注意到，*这些是我们从分类器的混淆矩阵中定义的度量标准*。因为该矩阵是为每个选择的决策阈值定义的，我们可以将其视为条件分布
    *P(ŷ, y|t)* 的一种表示，其中这些对象是完全描述我们分类器性能的混淆矩阵类别的一部分。
- en: '![](../Images/6a5663e68de330b06703f6189c7735c9.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a5663e68de330b06703f6189c7735c9.png)'
- en: 'Figure 3: Each confusion matrix can be viewed as a conditional *p(ŷ, y|t),
    and* a class of all possible confusion matrices becomes a complete description
    of the classifier’s performance.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：每个混淆矩阵可以视为一个条件 *p(ŷ, y|t)，并且* 所有可能的混淆矩阵组成一个完整的分类器性能描述。
- en: 'Therefore, the error ratios *fpr* and *fnr* are metrics that quantifies how
    and how much the two conditional score distributions intersect:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，错误比率 *fpr* 和 *fnr* 是量化两个条件得分分布交集方式和交集程度的指标：
- en: '![](../Images/15e9c69be544b6caf8b2aaaeb74a15e6.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15e9c69be544b6caf8b2aaaeb74a15e6.png)'
- en: 'Figure 4: the performance estimators for a classifier are different measures
    used to describe the overlap or separation between the two distributions, p(s|P)
    and p(s|N).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：分类器的性能估计量是不同的度量，用来描述两个分布 p(s|P) 和 p(s|N) 之间的重叠或分离。
- en: 'Summarizing performance: the ROC curve'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能总结：ROC 曲线
- en: '*Since the ratios are constrained* by *tpr* + *fnr* = 1 and *fpr* + *tnr* =
    1, this would mean that w*e have just 2 degrees of freedom to describe our performance*.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*由于比率受到 *tpr* + *fnr* = 1 和 *fpr* + *tnr* = 1 的约束*，这意味着我们只有 2 个自由度来描述我们的性能*。'
- en: The ROC curve is a curve parameterized by *t*, described by *(x(t), y(t)) =
    (fpr(t), tpr(t))* as points against orthogonal axes. This will provide a digestible
    summary to visualize the performance of our classifier for all different threshold
    values, rather than just a single one.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线是由 *t* 参数化的曲线，用 *(x(t), y(t)) = (fpr(t), tpr(t))* 表示为与正交轴相对的点。这将为我们提供一个简明的总结，来可视化分类器在所有不同阈值下的性能，而不仅仅是一个单一的阈值。
- en: The best choice of ***t*** is not generally known in advance but must be determined
    as part of the classifier construction. — ROC Curves for Continuous Data (2009,
    Chapman and Hall).
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最佳的 ***t*** 值通常是未知的，必须作为分类器构建的一部分来确定。——《连续数据的ROC曲线》(2009, Chapman and Hall)。
- en: We are aiming to explore the concept of treating probability distributions,
    so let's imagine *what would be the base case for a completely inefficient classifier.*
    Since the effectiveness of our predictions hinges on the discriminative nature
    *p(s|P)* and *p(s|N)* are, in the case where *p(s|P) = p(s|N) = p(s)*, we encounter
    a prime example of this inefficiency.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是探索将概率分布作为处理对象的概念，因此让我们想象一下*对于一个完全无效的分类器，基本情形会是什么样的*。由于我们预测的有效性依赖于判别性质，*p(s|P)*
    和 *p(s|N)*，当 *p(s|P) = p(s|N) = p(s)* 时，我们就遇到了这种无效性的典型例子。
- en: 'If we do the exercise of modeling each of these conditionals as gaussians with
    means separated by different values, we can see how the performance varies clearly:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们进行将每个条件视为均值分离不同值的高斯模型化的练习，我们可以清晰地看到性能是如何变化的：
- en: '![](../Images/c9469a4a07ec4f96ca8f33cb2fb04275.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9469a4a07ec4f96ca8f33cb2fb04275.png)'
- en: 'Figure 5: The performance of a classifier improves as score distributions become
    more discriminative.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：当得分分布变得更加具备判别力时，分类器的性能提高。
- en: This visualization will serve as a valuable aid in comprehending the probabilistic
    interpretation of a crucial classifier metric — named Area Under the Curve (AUC)
    — that we will delve into later.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这种可视化将作为一个宝贵的辅助工具，帮助我们理解一个关键分类器度量的概率解释——称为曲线下面积（AUC），我们稍后将深入探讨这一点。
- en: Some properties of the ROC curve
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ROC 曲线的一些特性
- en: The ROC curve can be described as a function *y = h(x)* where *x* and *y* are
    the false and true positive rates respectively, which are in turn parameterized
    by *t* in the form *x(t) = p(s > t|N)* and and *y(t) = p(s > t|P)*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线可以描述为函数 *y = h(x)*，其中 *x* 和 *y* 分别是真阳性率和假阳性率，而它们又由 *t* 参数化，形式为 *x(t) =
    p(s > t|N)* 和 *y(t) = p(s > t|P)*。
- en: 'We can take advantage of this to derive the following properties:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这一点推导出以下特性：
- en: '***y = h(x) is a monotone increasing function that lies above the line defined
    by (0, 0) and (1, 1);***'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***y = h(x) 是一个单调递增的函数，位于由 (0, 0) 和 (1, 1) 定义的直线之上；***'
- en: '***The ROC curve is unaltered if the classification scores undergo a strictly
    increasing transformation;***'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***如果分类得分经过严格递增的变换，ROC 曲线不会改变；***'
- en: '![](../Images/9c111b8bd9edefdaf4d0406cd739c011.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c111b8bd9edefdaf4d0406cd739c011.png)'
- en: 'Figure 6: A monotonically increasing transformation applied to the score distribution
    does not alter the ROC curve, as it preserves the order of the regression.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：对得分分布施加单调递增的变换不会改变 ROC 曲线，因为它保持了回归的顺序。
- en: '**This property is what makes the calibration process for a classifier possible.**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个特性使得分类器的校准过程成为可能。**'
- en: 3\. ***For a well-defined slope of ROC at the point with threshold value t:***
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. ***对于阈值t点的ROC曲线的明确斜率：***
- en: '![](../Images/f837e538b46b20c86912cb92e4f3d8bf.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f837e538b46b20c86912cb92e4f3d8bf.png)'
- en: '***where p(t|P) represents the density distribution for the cumulative distribution
    p(s ≤ t | P) (and same for p(t|N)).***'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '***其中p(t|P)表示累积分布p(s ≤ t | P)的密度分布（对于p(t|N)也是如此）。***'
- en: 'Binary Classification as Hypothesis Testing: justifying our approach'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元分类作为假设检验：为我们的方法提供正当性
- en: When viewing the classification process through a Bayesian inference lens, our
    objective is to deduce the posterior probability *p(P|t)*, which represents the
    odds of a point with threshold value *t* belonging to the positive class. Therefore,
    **the slope derivative defined on property 3 can be viewed as the likelihood ratio
    *L(t).***
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当从贝叶斯推理的角度来看分类过程时，我们的目标是推导后验概率*p(P|t)*，它表示一个具有阈值*t*的点属于正类的概率。因此，**定义在属性3上的斜率导数可以看作是似然比*L(t)。***
- en: This ratio *[L(t)]* tell us how much probable is a value of t of the classifier
    to have occurred in population P than in population N, which in turn can be interpreted
    as a measure of confidence in allocation to population P. — ROC Curves for Continuous
    Data (2009, Chapman and Hall).
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个比率*[L(t)]*告诉我们，分类器的t值在总体P中比在总体N中发生的可能性有多大，这反过来可以解释为分配到总体P的置信度度量。——《连续数据的ROC曲线》(2009年，Chapman和Hall)。
- en: This is an important fact because, by establishing an equivalence relationship
    between the binary classification process and hypothesis testing, we have a justification
    for why we classify based on a threshold.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个重要的事实，因为通过建立二元分类过程和假设检验之间的等价关系，我们为为什么基于阈值进行分类提供了正当性。
- en: 'If we formulate the classification problem with the *null hypothesis H0 that
    the individual belongs to population N against the alternative H1 that he belongs
    to population P*, we can draw the relationship:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用*零假设H0（个体属于总体N）对立于备择假设H1（个体属于总体P）*来表述分类问题，我们可以得出以下关系：
- en: '![](../Images/a7f611c319c6a896fb27d9548d706474.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7f611c319c6a896fb27d9548d706474.png)'
- en: 'Figure 7: The connection between the Binary Classification process and Hypothesis
    Testing is visualized through the confusion matrix. The marginal ratio metrics
    are related to the standard alpha and beta values in Hypothesis Testing.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：二元分类过程与假设检验之间的联系通过混淆矩阵可视化。边际比率度量与假设检验中的标准α和β值相关。
- en: 'The **Neyman-Pearson Lemma** establishes that the most powerful test — which
    achieves the highest *1-β* value — with a significance level *α*, possesses a
    region *R* encompassing all *s* values of *S* for which:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**Neyman-Pearson引理**确立了最强检验——即具有最高*1-β*值的检验——在显著性水平*α*下，拥有一个包含所有* s *值的区域*R*，该区域满足：'
- en: '![](../Images/0fb1caf9c90e053cf9bdcbed5b2e3079.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fb1caf9c90e053cf9bdcbed5b2e3079.png)'
- en: where *α* is sufficient to determine *k* by the condition *p(s* ∈ *R|N) = α.*
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*α*足以通过条件*p(s* ∈ *R|N) = α*来确定*k*。
- en: This implies that when we score the population in a manner where *L(s)* is monotonically
    increasing, a one-to-one relationship between *s* and *k* ensures that choosing
    a rule that exceeds a particular threshold is the optimal decision.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，当我们以*L(s)*单调递增的方式对总体进行评分时，*s*和*k*之间的一一对应关系确保选择一个超过特定阈值的规则是最佳决策。
- en: 'For our fictitious cases where our classifier assigns a normal distribution
    for each class, it''s direct the likelihood will satisfy this condition:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们虚构的案例，其中分类器为每个类别分配正态分布，似然直接满足这一条件：
- en: '![](../Images/5675ac3396f75ae4ed22aa74a237e118.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5675ac3396f75ae4ed22aa74a237e118.png)'
- en: 'Figure 8: the likelihood ratio is strictly increasing (and, more precisely,
    exponentially) for the case of binormal distribution of scores.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：对于分数的双正态分布情况，似然比是严格递增的（更精确地说，是指数级递增）。
- en: This is not always the case for a real-world problem, where score distributions
    are not necessarily well-behaved in this sense. We can use the *Kaggle* dataset
    to understand this, estimating the density of our conditionals by Kernel Density
    Estimation (KDE).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实问题中，情况并非总是如此，因为评分分布不一定在此意义上表现良好。我们可以使用*Kaggle*数据集来理解这一点，通过核密度估计（KDE）来估算条件概率的密度。
- en: '![](../Images/89a056e1b2baeb8734a3932afdf2a67f.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89a056e1b2baeb8734a3932afdf2a67f.png)'
- en: 'Figure 9: This is the assignment of scores made by a logistic regression in
    a balanced data situation. The classifier was trained without parameter tuning.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：这是在平衡数据情况下，逻辑回归模型给出的评分分配。该分类器在没有参数调整的情况下进行了训练。
- en: '![](../Images/49ec9627282ae6bc704c6e8f4198dfe9.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49ec9627282ae6bc704c6e8f4198dfe9.png)'
- en: 'Figure 10: for a real case (Kaggle dataset), we can see that the likelihood
    is not necessarily monotonic.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：对于一个实际案例（Kaggle数据集），我们可以看到，似然比并不一定是单调递增的。
- en: '**This means that higher scores are not necessarily associated with a greater
    chance of the individual being from a positive class.**'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**这意味着较高的分数不一定与个体属于正类的概率增加相关。**'
- en: '**ROC-AUC probabilistic interpretation, and why we should take care with it**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ROC-AUC的概率解释，以及为什么我们需要谨慎对待它**'
- en: The *Area Under the Curve (AUC)* is probably the most widely used value to summarize
    the results expressed by a ROC curve. *It is defined as the integral of y(x) from
    0 to 1*, as the name suggests. Notably, a perfect classifier’s performance is
    epitomized by the point (0, 1) on the orthogonal axis, denoting zero probability
    of misclassification negative points and an unambiguous assurance of correctly
    classifying positives.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*曲线下面积 (AUC)* 可能是最广泛使用的值，用于总结ROC曲线表达的结果。*它被定义为从0到1的y(x)积分*，正如其名称所示。值得注意的是，完美分类器的表现由正交轴上的点(0,
    1)体现，表示零概率的负类误分类，并明确保证正确分类正类。'
- en: The approach treated on figure 5 give us a hint that the probabilistic interpretation
    of a good fit must have to do with consistency in assigning high score values
    for positive individuals and low score for negatives ones. This is exactly the
    case, since one can prove — as referred in [1] — that *the AUC is equivalent to
    the probability of a positive individual have a score value (Sp) higher than a
    negative individual score (Sn):*
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5 中的处理方法给我们提供了一个提示，即良好拟合的概率解释必须与为正类个体分配较高的分数和值为负类个体分配较低的分数的连贯性相关。这正是情况所在，因为有证明——如[1]中提到——*AUC等同于正类个体的得分（Sp）高于负类个体得分（Sn）的概率：*
- en: '![](../Images/a108b375acccbb36861e8533a4aa65e3.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a108b375acccbb36861e8533a4aa65e3.png)'
- en: 'The critical point to consider is this: AUC is designed to provide a single-number
    estimate of your classifier’s performance. However, when it comes to making practical
    decisions, a threshold *t* must be chosen to suit the specific requirements of
    your problem. The challenge arises because, as discussed earlier, the optimal
    decision based on a threshold occurs when the likelihood ratio is monotonically
    increasing, which is not always the case in practice.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要考虑的一点是：AUC旨在提供一个单一的数字来估算分类器的表现。然而，在实际决策时，必须选择一个适合你问题特定需求的阈值 *t*。挑战在于，如前所述，基于阈值的最佳决策发生在似然比单调递增时，而在实践中这并不总是如此。
- en: '*Consequently, even if you have a high AUC value, very close to 1, it may not
    be sufficient to determine whether your classifier is truly capable of optimal
    classification based on a decision boundary. In such cases,* ***achieving a high
    AUC value alone may not guarantee the effectiveness of your classifier in practical
    decision-making scenarios.***'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*因此，即使你拥有一个接近1的高AUC值，也不足以确定你的分类器是否能够基于决策边界进行最佳分类。在这种情况下，* ***单单达到一个高AUC值并不能保证分类器在实际决策情境中的有效性。***'
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This probability interpretation of binary classification may offers a profound
    understanding of the intricacies involved in the process. By modeling populations
    as distributions, we can make informed decisions based on the likelihood of an
    individual belonging to a particular class. The ROC curve serves as a valuable
    tool for **summarize** how the choice of threshold impacts classification efficiency.
    Furthermore, **the connection between binary classification and hypothesis testing
    emphasizes the reason why we classify by threshold values**. It is essential to
    remember that while the Area Under the Curve (AUC) is a commonly used performance
    metric, **it may not always guarantee optimal practical decision-making**, underscoring
    the significance of choosing the right threshold. **This probabilistic interpretation
    enriches our understanding of binary classification, making it a powerful framework
    for tackling real-world problems.**
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类的这种概率解释可能提供了对该过程复杂性更深刻的理解。通过将人群建模为分布，我们可以基于个体属于某个特定类别的概率做出明智的决策。ROC 曲线作为一个有价值的工具，**总结**了阈值选择如何影响分类效率。此外，**二分类与假设检验之间的联系强调了我们为什么通过阈值来进行分类**。需要记住的是，尽管曲线下面积（AUC）是常用的性能评估指标，**它并不总能保证最佳的实际决策**，这突显了选择正确阈值的重要性。**这种概率解释丰富了我们对二分类的理解，使其成为解决实际问题的强大框架。**
- en: Acknowledgements
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: Special thanks to Renato Vicente, who introduced me to visualizing the classifier
    through the space of confusion matrices, and encouraged me to write this article.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢Renato Vicente，他让我通过混淆矩阵空间来可视化分类器，并鼓励我撰写本文。
- en: '*All images and graphs are by the author.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有图片和图表均由作者提供。*'
- en: '*Also, you can find me on* [***Linkedin***](https://www.linkedin.com/in/gcosta98/)*.*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*另外，你可以在* [***Linkedin***](https://www.linkedin.com/in/gcosta98/)*找到我。*'
- en: References
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Krzanowski, Wojtek J., and David J. Hand. *ROC curves for continuous data*.
    Crc Press, 2009'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Krzanowski, Wojtek J., and David J. Hand. *连续数据的ROC曲线*。Crc Press，2009年'
- en: '[2] Muschelli, John (2019–12–23). “ROC and AUC with a binary predictor: a potentially
    misleading metric”. *Journal of Classification*. Springer Science and Business
    Media LLC. **37** (3): 696–708\. [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1007/s00357–019–09345–1](https://doi.org/10.1007%2Fs00357-019-09345-1).
    [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier)) [0176–4268](https://www.worldcat.org/issn/0176-4268).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Muschelli, John (2019–12–23). “ROC和AUC与二元预测变量：一个可能具有误导性的指标”。*分类学期刊*。Springer
    Science and Business Media LLC. **37** (3): 696–708\. [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1007/s00357–019–09345–1](https://doi.org/10.1007%2Fs00357-019–09345–1)。
    [ISSN](https://en.wikipedia.org/wiki/ISSN_(identifier)) [0176–4268](https://www.worldcat.org/issn/0176-4268)。'
- en: Dataset
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: '[Credit Card Fraud (kaggle.com)](https://www.kaggle.com/datasets/joebeachcapital/credit-card-fraud)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[信用卡欺诈 (kaggle.com)](https://www.kaggle.com/datasets/joebeachcapital/credit-card-fraud)'
