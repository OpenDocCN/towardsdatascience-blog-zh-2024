- en: 'Quantum Machine Learning with Python: Kernel Methods and Neural Networks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行量子机器学习：核方法与神经网络
- en: 原文：[https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12](https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12](https://towardsdatascience.com/quantum-machine-learning-with-python-kernel-methods-and-neural-networks-d60738aa99e1?source=collection_archive---------3-----------------------#2024-03-12)
- en: '[](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Xavier
    Vasques](../Images/5517ccd82bb4744fc0bff5be9ba399e4.png)](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    [Xavier Vasques](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Xavier
    Vasques](../Images/5517ccd82bb4744fc0bff5be9ba399e4.png)](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    [Xavier Vasques](https://xaviervasques.medium.com/?source=post_page---byline--d60738aa99e1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    ·15 min read·Mar 12, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d60738aa99e1--------------------------------)
    ·15分钟阅读·2024年3月12日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6926b4f6dbcce2f545ddac86fa1016d0.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6926b4f6dbcce2f545ddac86fa1016d0.png)'
- en: Photo by Annamária Borsos (used with permission)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由Annamária Borsos拍摄（经许可使用）
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Quantum Machine Learning (QML) represents a fascinating convergence of quantum
    computing and machine learning technologies. With quantum computing’s potential
    in mathematics and data processing with complex structure, QML could revolutionize
    areas like drug discovery, finance, and beyond. This blog delves into the innovative
    realms of quantum neural networks (QNNs) and quantum kernel techniques, showcasing
    their unique capabilities through practical Python examples. The blog will not
    detail the mathematical concepts. For more information do not hesitate to read
    my latest book *Machine Learning Theory and Applications: Hands-on Use Cases with
    Python on Classical and Quantum Machines,* Wiley, 2024.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 量子机器学习（QML）代表了量子计算和机器学习技术的一个迷人融合。随着量子计算在数学和复杂结构数据处理方面的潜力，QML有可能革新药物发现、金融等多个领域。本博客深入探讨了量子神经网络（QNNs）和量子核技术的创新领域，通过实际的Python示例展示了它们的独特能力。博客中不会详细介绍数学概念。如需了解更多信息，请随时阅读我最新的书籍《*机器学习理论与应用：在经典与量子机器上的Python实战用例*》，Wiley，2024年。
- en: Quantum kernel methods, introduce a quantum-enhanced way of processing data.
    By mapping classical data into quantum feature space, these methods utilize the
    superposition and entanglement properties of quantum mechanics to perform classifications
    or regression tasks. The use of quantum kernel estimator and quantum variational
    classifier examples illustrates the practical application of these concepts. QNNs,
    leveraging quantum states for computation, offer a novel approach to neural network
    architecture. The Qiskit framework facilitates the implementation of both quantum
    kernel methods and QNNs, enabling the exploration of quantum algorithms’ efficiency
    in learning and pattern recognition.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 量子核方法引入了一种量子增强的数据处理方式。通过将经典数据映射到量子特征空间，这些方法利用量子力学的叠加和纠缠特性来执行分类或回归任务。使用量子核估计器和量子变分分类器的示例展示了这些概念的实际应用。量子神经网络（QNNs）利用量子态进行计算，提供了一种全新的神经网络架构方法。Qiskit框架支持量子核方法和QNN的实现，使得探索量子算法在学习和模式识别中的效率成为可能。
- en: Incorporating Python code examples, this blog aims to provide comprehensive
    code examples of QML for readers to explore its promising applications, and the
    challenges it faces. Through these examples, readers can start practicing and
    gain an appreciation for the transformative potential of quantum computing in
    machine learning and the exciting possibilities that lie ahead.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合 Python 代码示例，本博客旨在为读者提供全面的 QML 代码示例，帮助他们探索其有前景的应用和所面临的挑战。通过这些示例，读者可以开始实践并理解量子计算在机器学习中的变革潜力以及未来的激动人心的可能性。
- en: First, install qiskit
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先，安装 qiskit
- en: We will use the open-source SDK Qiskit ([https://qiskit.org](https://qiskit.org/))
    which allows working with quantum computers. Qiskit supports Python version 3.6
    or later.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用开源 SDK Qiskit ([https://qiskit.org](https://qiskit.org/))，它允许与量子计算机进行交互。Qiskit
    支持 Python 3.6 及更高版本。
- en: 'In our environment, we can install Qiskit with pip:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的环境中，我们可以使用 pip 安装 Qiskit：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can also install qiskit-machine-learning using pip:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用 pip 安装 qiskit-machine-learning：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Documentation can be found on GitHub: [https://github.com/Qiskit/qiskit-machine-learning/](https://github.com/Qiskit/qiskit-machine-learning/).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 文档可以在 GitHub 上找到：[https://github.com/Qiskit/qiskit-machine-learning/](https://github.com/Qiskit/qiskit-machine-learning/)。
- en: 'To run our code, we can use either simulators or real hardware even if I strongly
    recommend the use of hardware or push the limits of simulators to improve research
    in this field. While studying the Qiskit documentation, you will encounter references
    to the Qiskit Runtime primitives, which serve as implementations of the Sampler
    and Estimator interfaces found in the qiskit.primitives module. These interfaces
    facilitate the seamless interchangeability of primitive implementations with minimal
    code modifications. The initial release of Qiskit Runtime comprises two essential
    primitives:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行我们的代码，我们可以使用模拟器或实际硬件，尽管我强烈推荐使用硬件，或推动模拟器的极限以促进该领域的研究。在学习 Qiskit 文档时，您将遇到
    Qiskit Runtime 原语的相关内容，这些原语是 qiskit.primitives 模块中 Sampler 和 Estimator 接口的实现。这些接口通过最小的代码修改，便于原语实现的无缝互换。Qiskit
    Runtime 的初始版本包含两个基本原语：
- en: 'Sampler: This primitive generates quasi-probabilities based on input circuits.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sampler（采样器）：这个原语基于输入电路生成准概率。
- en: 'Estimator: This primitive calculates expectation values derived from input
    circuits and observables.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Estimator（估计器）：这个原语计算由输入电路和可观察量导出的期望值。
- en: 'For more comprehensive insights, detailed information is available in the following
    resource: [https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.](https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更全面的见解，详细信息可以在以下资源中找到：[https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.](https://qiskit.org/ecosystem/ibm-runtime/tutorials/how-to-getting-started-with-sampler.html.)
- en: Quantum Kernel Methods
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量子核方法
- en: Venturing into quantum approaches for supervised machine learning poses a novel
    research direction. Classical machine learning extensively utilizes kernel methods,
    among which the support vector machine (SVM) for classification stands out for
    its widespread application.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 探索用于监督式机器学习的量子方法是一个新颖的研究方向。经典机器学习广泛利用核方法，其中支持向量机（SVM）分类方法因其广泛应用而脱颖而出。
- en: SVMs, known for their role in binary classification, have increasingly been
    applied to multiclass problems. The essence of binary SVM involves devising a
    hyperplane to linearly separate n-dimensional data points into two groups, aiming
    for an optimal margin that distinctively classifies the data into its respective
    categories. This hyperplane, effective in either the original feature space or
    a transformed higher-dimensional kernel space, is selected for its capacity to
    maximize the separation between classes, which involves an optimization problem
    to maximize the margin, defined as the distance from the nearest data point to
    the hyperplane on either side. This leads to the formulation of a maximum-margin
    classifier. The critical data points on the boundary are termed support vectors,
    and the margin represents a zone typically devoid of data points. An optimal hyperplane
    too proximate to the data points, indicating a slender margin, undermines the
    model’s predictive robustness and generalization capability.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM），因其在二分类中的作用而著名，近年来越来越多地应用于多分类问题。二分类SVM的核心是通过构造一个超平面，将n维数据点线性地分成两组，目的是寻找到一个最佳的边界，使数据能够清晰地被分类到各自的类别中。这个超平面可以有效地在原始特征空间或转换后的高维核空间中选择，选取标准是能够最大化类之间的分隔，这涉及一个优化问题，即最大化边距，边距定义为从最近的数据点到超平面两侧的距离。这导致了最大边距分类器的形成。边界上的关键数据点被称为支持向量，而边距则是通常没有数据点的区域。如果一个最优超平面离数据点过近，表示边距狭窄，则会削弱模型的预测鲁棒性和泛化能力。
- en: To navigate multiclass SVM challenges, methods like the all-pair strategy, which
    conducts a binary classification for each pair of classes, have been introduced.
    Beyond straightforward linear classification, nonlinear classifications can be
    achieved through the kernel trick. This technique employs a kernel function to
    elevate inputs into a more expansive, higher-dimensional feature space, facilitating
    the separation of data that is not linearly separable in the input space. The
    kernel function essentially performs an inner product in a potentially vast Euclidian
    space, known as the feature space. The goal of nonlinear SVM is to achieve this
    separation by mapping data to a higher dimension using a suitable mapping. Selecting
    an appropriate feature map becomes crucial for data that cannot be addressed by
    linear methods alone. This is where quantum can jump into it. Quantum kernel methods,
    blending classical kernel strategies with quantum innovations, carve out new avenues
    in machine learning. Early quantum kernel approaches have focused on encoding
    data points into inner products or amplitudes in Hilbert space through quantum
    feature maps. The complexity of the quantum circuit implementing the feature map
    scales linearly or polylogarithmically with the dataset size.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决多分类SVM的挑战，引入了类似全对策略（all-pair strategy）的方法，该方法对每一对类别进行二分类。除了简单的线性分类外，还可以通过核技巧实现非线性分类。这一技术通过核函数将输入映射到一个更广阔的高维特征空间，从而促进了在输入空间中无法线性分隔的数据的分离。核函数本质上是在一个可能非常庞大的欧几里得空间中执行内积运算，这个空间被称为特征空间。非线性SVM的目标是通过使用合适的映射将数据映射到一个更高维度，从而实现数据的分离。选择合适的特征映射对于那些不能仅通过线性方法解决的数据至关重要。在这一点上，量子技术可以发挥作用。量子核方法将经典核策略与量子创新相结合，为机器学习开辟了新的途径。早期的量子核方法主要集中在通过量子特征映射将数据点编码为内积或希尔伯特空间中的幅度。实现特征映射的量子电路的复杂度与数据集的大小呈线性或对数线性增长。
- en: Quantum Kernel with ZZFeatureMaps
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有ZZFeatureMaps的量子核
- en: 'In this first example, we will use the ZZFeatureMap with linear entanglement,
    we will repeat the data encoding step two times, and we will use feature reduction
    with principal component analysis. You can of course use other feature reduction,
    data rescaling or feature selection techniques to improve the accuracy of your
    models. We will use the breast cancer dataset that you can find here: [https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv](https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一个例子中，我们将使用带有线性纠缠的ZZFeatureMap，我们将数据编码步骤重复两次，并使用主成分分析进行特征降维。当然，你可以使用其他特征降维、数据重新缩放或特征选择技术来提高模型的准确性。我们将使用乳腺癌数据集，你可以在这里找到：[https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv](https://github.com/xaviervasques/hephaistos/blob/main/data/datasets/breastcancer.csv)
- en: Let’s describe the steps of the Python script below. This Python script demonstrates
    an application of integrating quantum computing techniques with traditional machine
    learning to classify breast cancer data. It represents a hybrid approach, where
    quantum-enhanced features are used within a classical machine learning workflow.
    The goal is to predict breast cancer diagnosis (benign or malignant) based on
    a set of features extracted from the breast mass characteristics.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们描述一下下面Python脚本的步骤。此Python脚本演示了将量子计算技术与传统机器学习相结合以分类乳腺癌数据的应用。它代表了一种混合方法，在经典机器学习工作流中使用量子增强特征。目标是根据从乳腺肿块特征提取的一组特征来预测乳腺癌的诊断结果（良性或恶性）。  '
- en: The way of doing quantum kernel machine learning is very similar to what we
    do classically as data scientists. We import the necessary libraries (Pandas,
    NumPy, scikit-learn) and Qiskit for quantum computing and kernel estimation, we
    load the data, preprocess the data and separate the data into features (X) and
    target labels (y). A specific step is the quantum feature mapping. The script
    sets up a quantum feature map using the ZZFeatureMap from Qiskit, configured with
    specified parameters for feature dimension, repetitions, and entanglement type.
    Quantum feature maps are critical for translating classical data into quantum
    states, enabling the application of quantum computing principles for data analysis.
    Then, the quantum kernel setup consists in configuring a quantum kernel with a
    fidelity-based approach. It serves as a new method to compute the similarity between
    data points in the feature space defined by quantum states and potentially capturing
    complex patterns. The last step comes back to a classic machine learning pipeline
    with data rescaling with standard scaler, dimension reduction using principal
    component analysis and the use of support vector classifier (SVC) which utilizes
    the quantum kernel for classification. We evaluate the model using 5-fold cross-validation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '进行量子核机器学习的方式与我们作为数据科学家做的经典机器学习非常相似。我们导入必要的库（Pandas、NumPy、scikit-learn）和用于量子计算和核估计的Qiskit，加载数据，预处理数据并将数据分为特征（X）和目标标签（y）。一个具体的步骤是量子特征映射。该脚本使用Qiskit中的ZZFeatureMap设置量子特征图，并配置特征维度、重复次数和纠缠类型等参数。量子特征图对于将经典数据转换为量子态至关重要，从而实现量子计算原理在数据分析中的应用。接着，量子核的设置包含基于保真度的方法来配置量子核。它作为一种新的方法，用于计算数据点在由量子态定义的特征空间中的相似性，并有可能捕捉复杂的模式。最后一步回到经典机器学习流程，通过标准化缩放数据、使用主成分分析进行降维，并使用支持向量分类器（SVC）进行分类，SVC利用量子核进行分类。我们使用5折交叉验证来评估模型。  '
- en: Let’s code.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们开始编写代码。  '
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will obtain a mean score validation score of 0.63.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获得一个平均分验证得分为0.63。
- en: 'This code is executed with the local simulator. To run on real hardware, replace
    the following lines:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '这段代码在本地模拟器上执行。要在真实硬件上运行，请替换以下几行：  '
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: by
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 'by  '
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Quantum Kernel Training
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '量子核训练  '
- en: This part will explore the method of Quantum Kernel Alignment (QKA) for the
    purpose of binary classification. QKA iteratively adjusts a quantum kernel that’s
    parameterized to fit a dataset, aiming for the largest possible margin in Support
    Vector Machines (SVM). For further details on QKA, reference is made to the preprint
    titled “Covariant quantum kernels for data with group structure.” The Python script
    below is a comprehensive example of integrating traditional machine learning techniques
    with quantum computing for the prediction accuracy in classifying breast cancer
    diagnosis. It employs a dataset of breast cancer characteristics to predict the
    diagnosis (benign or malignant).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '本部分将探索量子核对齐（QKA）方法，用于二分类任务。QKA通过迭代调整参数化的量子核，以适应数据集，旨在支持向量机（SVM）中实现尽可能大的间隔。有关QKA的更多细节，请参考名为《适用于具有群结构数据的协变量子核》的预印本。下面的Python脚本是一个综合示例，展示了如何将传统机器学习技术与量子计算相结合，以提高乳腺癌诊断分类的预测准确性。它使用乳腺癌特征数据集来预测诊断结果（良性或恶性）。  '
- en: The machine learning pipeline is similar to the one used in the quantum kernel
    with ZZFeatureMaps section. The difference is that we will constructs a custom
    quantum circuit, integrating a rotational layer with a ZZFeatureMap, to prepare
    the quantum state representations of the data. The quantum kernel estimation step
    utilizes Qiskit primitives and algorithms for optimizing the quantum kernel’s
    parameters using a quantum kernel trained (QKT) and an optimizer.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该机器学习管道与使用ZZFeatureMaps部分中的量子核类似。不同之处在于，我们将构建一个自定义量子电路，将旋转层与ZZFeatureMap结合，以准备数据的量子态表示。量子核估计步骤利用Qiskit原语和算法，通过量子核训练（QKT）和优化器来优化量子核的参数。
- en: Let’s code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们开始编码。  '
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will obtain the following output: 0.6526315789473685'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将获得以下输出：0.6526315789473685  '
- en: As you certainly observed, there is time differences in execution between QKT
    and using a quantum kernel with a predefined feature map like ZZFeatureMap even
    if we reduced the dataframe size by sampling 1/3 of the data and setting the maximum
    iteration for SPSA to 10\. QKT involves not only the use of a quantum kernel but
    also the optimization of parameters within the quantum feature map or the kernel
    itself to improve model performance. This optimization process requires iterative
    adjustments to the parameters, where each iteration involves running quantum computations
    to evaluate the performance of the current parameter set. This iterative nature
    significantly increases computational time. When using a predefined quantum kernel
    like the ZZFeatureMap, the feature mapping is fixed, and there’s no iterative
    optimization of quantum parameters involved. The quantum computations are performed
    to evaluate the kernel between data points, but without the added overhead of
    adjusting and optimizing quantum circuit parameters. This approach is more straightforward
    and requires fewer quantum computations, making it faster. Each step of the optimization
    process in QKT requires evaluating the model’s performance with the current quantum
    kernel, which depends on the quantum feature map parameters at that step. This
    means multiple evaluations of the kernel matrix, each of which requires a substantial
    number of quantum computations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '正如您所观察到的，尽管我们通过对数据进行采样，仅保留三分之一的数据并将SPSA的最大迭代次数设置为10，但QKT和使用像ZZFeatureMap这样的预定义特征映射的量子核在执行时间上仍然存在差异。QKT不仅涉及量子核的使用，还涉及量子特征映射或量子核本身参数的优化，以提高模型性能。这个优化过程需要对参数进行迭代调整，每次迭代都需要运行量子计算来评估当前参数集的性能。这种迭代特性显著增加了计算时间。而使用像ZZFeatureMap这样的预定义量子核时，特征映射是固定的，不涉及量子参数的迭代优化。量子计算是用来评估数据点之间的核，但没有调整和优化量子电路参数的额外开销。这种方法更为直接，所需的量子计算较少，因此更快。QKT中的每个优化步骤都需要评估当前量子核的模型性能，这取决于该步骤中的量子特征映射参数。这意味着需要多次评估核矩阵，每次评估都需要大量的量子计算。  '
- en: Quantum Neural Networks
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**量子神经网络**  '
- en: This Python script below incorporates quantum neural networks (QNNs) into a
    machine learning pipeline. In the script, we need to configure the quantum feature
    map and ansatz (a quantum circuit structure), construct a quantum circuit by appending
    the feature map and ansatz to a base quantum circuit (this setup is crucial for
    creating quantum neural networks that process input data quantum mechanically)
    and create a QNN using the quantum circuit designed for binary classification.
    Before coming back to the classic machine learning pipeline with data rescaling,
    data reduction and model evaluation, we employ a quantum classifier which integrates
    the QNN with a classical optimization algorithm (COBYLA) for training. A callback
    function is defined to visualize the optimization process, tracking the objective
    function value across iterations.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '下面的Python脚本将量子神经网络（QNNs）集成到机器学习管道中。在这个脚本中，我们需要配置量子特征映射和量子电路结构（ansatz），通过将特征映射和量子电路结构附加到基础量子电路上来构建量子电路（此设置对创建处理输入数据的量子神经网络至关重要），并使用为二分类设计的量子电路创建QNN。在回到经典机器学习管道之前，包括数据重缩放、数据降维和模型评估，我们采用了一个量子分类器，该分类器将QNN与经典优化算法（COBYLA）集成以进行训练。定义了一个回调函数来可视化优化过程，跟踪目标函数值在各个迭代过程中的变化。  '
- en: Let’s code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们开始编码。  '
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We obtain the following results:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '我们获得了以下结果：  '
- en: 'Cross-validation scores: [0.34210526 0.4122807 0.42982456 0.21929825 0.50442478]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '交叉验证得分：[0.34210526 0.4122807 0.42982456 0.21929825 0.50442478]  '
- en: 'Mean cross-validation score: 0.3815867101381773'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的平均得分：0.3815867101381773
- en: 'Standard deviation of cross-validation scores: 0.09618163326986424'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证分数的标准差：0.09618163326986424
- en: '![](../Images/194a9fd37a05cf66d9a3ee867de7e44a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/194a9fd37a05cf66d9a3ee867de7e44a.png)'
- en: As we can see, in this specific dataset, QNN doesn’t provide a very good classification
    score.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，在这个特定数据集上，QNN并没有提供非常好的分类分数。
- en: Conclusion
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This idea of this blog is to make it easy to start using quantum machine learning.
    Quantum Machine Learning is an emerging field at the intersection of quantum computing
    and machine learning that holds the potential to revolutionize how we process
    and analyze vast datasets by leveraging the inherent advantages of quantum mechanics.
    As we showed in our paper *Application of quantum machine learning using quantum
    kernel algorithms on multiclass neuron M-type classification* published in Nature
    Scientific Report, a crucial aspect of optimizing QML models, including Quantum
    Neural Networks (QNNs), involves pre-processing techniques such as feature rescaling,
    feature extraction, and feature selection.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本博客的目的是让大家更容易开始使用量子机器学习。量子机器学习是量子计算与机器学习交叉领域中的一个新兴领域，具有潜力通过利用量子力学的固有优势来革新我们处理和分析庞大数据集的方式。正如我们在《*使用量子核算法进行量子机器学习在多类神经元
    M 型分类中的应用*》一文中所展示的那样，这篇文章已发表于《自然科学报告》，优化量子机器学习模型（包括量子神经网络，QNN）的一项关键内容涉及预处理技术，如特征重缩放、特征提取和特征选择。
- en: These techniques are not only essential in classical machine learning but also
    present significant benefits when applied within the quantum computing framework,
    enhancing the performance and efficiency of quantum machine learning algorithms.
    In the quantum realm, feature extraction techniques like Principal Component Analysis
    (PCA) can be quantum-enhanced to reduce the dimensionality of the data while retaining
    most of its significant information. This reduction is vital for QML models due
    to the limited number of qubits available on current quantum hardware.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术不仅在经典机器学习中至关重要，而且在量子计算框架内应用时也能带来显著的好处，提升量子机器学习算法的性能和效率。在量子领域，特征提取技术如主成分分析（PCA）可以通过量子增强来降低数据的维度，同时保留大部分重要信息。这种维度的减少对于量子机器学习（QML）模型至关重要，因为目前的量子硬件上可用的量子比特数量有限。
- en: Quantum feature extraction can efficiently map high-dimensional data into a
    lower-dimensional quantum space, enabling quantum models to process complex datasets
    with fewer resources. Selecting the most relevant features is also a way for optimizing
    quantum circuit complexity and resource allocation. In quantum machine learning,
    feature selection helps in identifying and utilizing the most informative features,
    reducing the need for extensive quantum resources.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 量子特征提取能够有效地将高维数据映射到较低维的量子空间，使得量子模型能够以更少的资源处理复杂的数据集。选择最相关的特征也是优化量子电路复杂度和资源分配的一种方式。在量子机器学习中，特征选择有助于识别和利用最具信息量的特征，减少对大量量子资源的需求。
- en: This process not only simplifies the quantum models but also enhances their
    performance by focusing the computational efforts on the features that contribute
    the most to the predictive accuracy of the model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程不仅简化了量子模型，还通过将计算努力集中在对模型预测准确性贡献最大的特征上，提升了模型的性能。
- en: '**Sources**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源**'
- en: '[*Machine Learning Theory and Applications: Hands-on Use Cases with Python
    on Classical and Quantum Machines,* Wiley, 2024](https://www.amazon.fr/Machine-Learning-Theory-Applications-Hands-ebook/dp/B0CS8MMSB4/ref=sr_1_2?__mk_fr_FR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1SIBDYLGUX7XR&dib=eyJ2IjoiMSJ9.IV7g17el89GNQznK4WE3TFa0RaOwsRf3n53jTAydpJXjqj4juibAmhXCmZv4JjLLjmbjY0nFBPuzH_p0TYDq_8QTq6SXsh_o3U9b6VT2U_FD5takpiI6ctH05JelH-XQ2mItrIX02LcvRu2jHDE6RDe20qR9DNLG5lY5gi93vbYlPY2ahKtCH5imnzLE4jgLSuU81s5qAaRPPD13MwhwPofgaJ9FqbYbtxrHFAKjPfE.VdY_00svNarbBN4C07OopzZlgOZEVb3AIKSlz_hDA2Y&dib_tag=se&keywords=xavier+vasques&qid=1710253907&sprefix=xavier+vasques%2Caps%2C104&sr=8-2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[*机器学习理论与应用：在经典和量子计算机上使用 Python 的实践案例,* Wiley, 2024](https://www.amazon.fr/Machine-Learning-Theory-Applications-Hands-ebook/dp/B0CS8MMSB4/ref=sr_1_2?__mk_fr_FR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1SIBDYLGUX7XR&dib=eyJ2IjoiMSJ9.IV7g17el89GNQznK4WE3TFa0RaOwsRf3n53jTAydpJXjqj4juibAmhXCmZv4JjLLjmbjY0nFBPuzH_p0TYDq_8QTq6SXsh_o3U9b6VT2U_FD5takpiI6ctH05JelH-XQ2mItrIX02LcvRu2jHDE6RDe20qR9DNLG5lY5gi93vbYlPY2ahKtCH5imnzLE4jgLSuU81s5qAaRPPD13MwhwPofgaJ9FqbYbtxrHFAKjPfE.VdY_00svNarbBN4C07OopzZlgOZEVb3AIKSlz_hDA2Y&dib_tag=se&keywords=xavier+vasques&qid=1710253907&sprefix=xavier+vasques%2Caps%2C104&sr=8-2)'
- en: '*Vasques, X., Paik, H. & Cif, L. Application of quantum machine learning using
    quantum kernel algorithms on multiclass neuron M-type classification. Sci Rep
    13, 11541 (2023).* [*https://doi.org/10.1038/s41598-023-38558-z*](https://doi.org/10.1038/s41598-023-38558-z)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*Vasques, X., Paik, H. & Cif, L. 使用量子核算法在多类神经元 M 型分类中的量子机器学习应用。Sci Rep 13,
    11541 (2023).* [*https://doi.org/10.1038/s41598-023-38558-z*](https://doi.org/10.1038/s41598-023-38558-z)'
- en: This dataset used is licensed under a Creative Commons Attribution 4.0 International
    (CC BY 4.0) license.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本数据集使用的是创意共享署名 4.0 国际版（CC BY 4.0）许可证。
