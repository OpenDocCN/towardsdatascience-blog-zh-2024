- en: Robust One-Hot Encoding
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳健的独热编码
- en: 原文：[https://towardsdatascience.com/robust-one-hot-encoding-930b5f8943af?source=collection_archive---------4-----------------------#2024-04-26](https://towardsdatascience.com/robust-one-hot-encoding-930b5f8943af?source=collection_archive---------4-----------------------#2024-04-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/robust-one-hot-encoding-930b5f8943af?source=collection_archive---------4-----------------------#2024-04-26](https://towardsdatascience.com/robust-one-hot-encoding-930b5f8943af?source=collection_archive---------4-----------------------#2024-04-26)
- en: Production grade one-hot encoding techniques in Python and R
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python和R中的生产级独热编码技术
- en: '[](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)[![Hans
    Christian Ekne](../Images/c85483d8b5dd89584b996b321b7f4a45.png)](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)
    [Hans Christian Ekne](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)[![Hans
    Christian Ekne](../Images/c85483d8b5dd89584b996b321b7f4a45.png)](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)
    [Hans Christian Ekne](https://medium.com/@hc.ekne?source=post_page---byline--930b5f8943af--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)
    ·11 min read·Apr 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--930b5f8943af--------------------------------)
    ·阅读时间11分钟·2024年4月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3b472814a17418f0804ebfbcc8a1e9db.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b472814a17418f0804ebfbcc8a1e9db.png)'
- en: Image generated by the author using DALL-E / or Dali?;)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者使用DALL-E生成/还是Dali？;)
- en: Have you faced a crash in your machine learning production environments?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否在机器学习生产环境中遇到过崩溃？
- en: It’s not fun, and especially when it comes to issues that could be avoided.
    One issue that frequently causes problems is one-hot encoding of data. Drawing
    from my own experience, I’ve learned that many of these issues can largely be
    avoided by following a few best practices related to one-hot encoding. In this
    article I will briefly introduce the topic with a few simple examples and share
    some best practices to ensure stability of your machine learning models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不有趣，尤其是当涉及到可以避免的问题时。一个经常引起问题的原因是数据的独热编码。通过我自己的经验，我发现很多这些问题在遵循一些与独热编码相关的最佳实践时是可以大大避免的。在这篇文章中，我将简要介绍这个话题，并通过一些简单的示例分享一些最佳实践，以确保你的机器学习模型的稳定性。
- en: One-hot encoding
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 独热编码
- en: What is one-hot encoding?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是独热编码？
- en: One-hot encoding is the practice of turning a factor variable that is stored
    in a column into dummy variables stored over multiple columns and represented
    as 0s and 1s. A simple example illustrates the concept.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 独热编码是将存储在一列中的因子变量转化为多个列中的虚拟变量，并以0和1的形式表示的做法。一个简单的例子说明了这个概念。
- en: 'Consider for example this dataset with some numbers and some columns for colours:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑这个包含一些数字和颜色列的数据集：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Or more visually:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者更直观地展示：
- en: '![](../Images/de251ce1de486b95f24cf64ab9c324bd.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de251ce1de486b95f24cf64ab9c324bd.png)'
- en: Training data with 3 columns / image by author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据，包含3列/图像由作者提供
- en: 'The column `color_1_`could also be represented like in the table below:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`color_1_`列也可以像下面的表格一样表示：'
- en: '![](../Images/17f1d9b0fd2a6e5438855cd8aa8dbabf.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17f1d9b0fd2a6e5438855cd8aa8dbabf.png)'
- en: One-hot encoded representation of “color_1_” / image by author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “color_1_”的独热编码表示 / 图像由作者提供
- en: Changing `color_1_` from a one-column compact representation of a categorical
    variable into a multi-column binary representation is what we call one-hot encoding.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将`color_1_`从一个单列的紧凑表示转化为多列的二进制表示，这就是我们所说的独热编码（one-hot encoding）。
- en: Why do we use it?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我们要使用它？
- en: There are multiple reasons to use one-hot encoding. They could be related to
    avoiding implicit ordering, improving model performance, or just making the data
    compatible with various algorithms.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用独热编码有多个原因。它们可能与避免隐含排序、提高模型性能，或只是使数据与各种算法兼容有关。
- en: For example, when you encode a categorical variable like colour, into a numerical
    structure, (e.g. 1 for black, 2 for green, 3 for red) without converting it to
    dummy variables, a model could mistakenly misinterpret the data to imply an order
    ( black < green < red) when no such order exists.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你将一个类别变量（如颜色）编码成数值结构时（例如：黑色为1，绿色为2，红色为3），如果不将其转换为虚拟变量，模型可能会错误地将数据误解为存在顺序关系（黑色
    < 绿色 < 红色），而实际上并不存在这种顺序。
- en: Also, when training neural nets, it is best practice to normalize the data before
    sending it into the neural net, and with categorical variables, one-hot encoding
    can be a good method. Other linear models, like logistic and linear regression
    assume linear relationships and numerical inputs so for this class of models,
    one-hot encoding can be a good idea as well.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在训练神经网络时，最佳实践是在将数据输入神经网络之前对数据进行标准化，对于类别变量，独热编码是一种不错的方法。其他线性模型，如逻辑回归和线性回归，假设输入是线性关系和数值型数据，因此对于这一类模型，独热编码也是一个好方法。
- en: In addition, the process of doing one-hot encoding forces us to ensure we don’t
    feed unseen factor levels into our machine learning models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，进行独热编码的过程迫使我们确保不会将未见过的因子级别输入到我们的机器学习模型中。
- en: Ultimately, one-hot encoding makes it easier for the machine learning models
    to interpret the data and thus make better predictions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，独热编码使得机器学习模型更容易理解数据，从而做出更好的预测。
- en: The main reasons why one-hot encoding fails
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 独热编码失败的主要原因
- en: The way we build traditional machine learning models is to first train the models
    on a “training dataset” — typically a dataset of historic values — and then later
    we generate predictions on a new dataset, the “inference dataset.” If the columns
    of the training dataset and the inference dataset don’t match, your machine learning
    algorithm will usually fail. This is primarily due to either missing or new factor
    levels in the inference dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建传统机器学习模型的方式是，首先在“训练数据集”上训练模型——通常是一个历史数据集——然后在新的数据集（即“推理数据集”）上生成预测。如果训练数据集和推理数据集的列不匹配，机器学习算法通常会失败。主要原因是推理数据集中缺少列或包含新的因子级别。
- en: 'The first problem: Missing factors'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一个问题：缺失因子
- en: 'For the following examples, assume that you used the dataset above to train
    your machine learning model. You one-hot encoded the dataset into dummy variables,
    and your fully transformed training data looks like below:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下示例，假设你使用上面的数据集来训练机器学习模型。你将数据集进行独热编码转换成虚拟变量，并且你的完全转换后的训练数据如下所示：
- en: '![](../Images/3838878fe8c718db9f2226fa542dc159.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3838878fe8c718db9f2226fa542dc159.png)'
- en: Transformed training dataset with pd.get_dummies / image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pd.get_dummies`转换后的训练数据集 / 图片来自作者
- en: 'Now, let’s introduce the inference dataset, this is what you would use for
    making predictions. Let’s say it is given like below:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们引入推理数据集，这就是你用于进行预测的数据集。假设它是如下所示：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/9647cc2c91077b979ff0ab9f045c0c76.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9647cc2c91077b979ff0ab9f045c0c76.png)'
- en: Inference data with 3 columns / image by author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 推理数据集（包含3列）/ 图片来自作者
- en: Using a naive one-hot encoding strategy like we used above (`pd.get_dummies`)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们上面使用的简单独热编码策略（`pd.get_dummies`）
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This would transform your inference dataset in the same way, and you obtain
    the dataset below:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以相同的方式转换你的推理数据集，你会得到如下的数据集：
- en: '![](../Images/beb8f6bd286cd54bd9ff34350c8cefda.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/beb8f6bd286cd54bd9ff34350c8cefda.png)'
- en: Transformed inference dataset with pd.get_dummies / image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pd.get_dummies`转换后的推理数据集 / 图片来自作者
- en: 'Do you notice the problems? The first problem is that the inference dataset
    is missing the columns:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你注意到问题了吗？第一个问题是推理数据集中缺少以下列：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you ran this in a model trained with the “training dataset” it would usually
    crash.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个用“训练数据集”训练的模型中运行这段代码，通常会崩溃。
- en: 'The second problem: New factors'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二个问题：新因子
- en: 'The other problem that can occur with one-hot encoding is if your inference
    dataset includes new and unseen factors. Consider again the same datasets as above.
    If you examine closely, you see that the inference dataset now has a new column:
    `color_2__orange.`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能发生的独热编码问题是，如果推理数据集中包含了新的、未见过的因子。再次考虑上面的数据集。如果你仔细检查，你会发现推理数据集现在有了一个新列：`color_2__orange`。
- en: This is the opposite problem as previously, and our inference dataset contains
    new columns which our training dataset didn’t have. This is actually a common
    occurrence and can happen if one of your factor variables had changes. For example,
    if the colours above represent colours of a car, and a car producer suddenly started
    making orange cars, then this data might not be available in the training data,
    but could nonetheless show up in the inference data. In this case you need a robust
    way of dealing with the issue.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与之前问题相反的情况，我们的推理数据集包含了训练数据集中没有的新列。这实际上是一个常见的情况，如果你的某个因子变量发生了变化，就可能会发生这种情况。例如，如果上面提到的颜色代表汽车的颜色，而一个汽车生产商突然开始生产橙色的汽车，那么这些数据可能在训练数据中不可用，但仍然可能出现在推理数据中。在这种情况下，你需要一种健壮的方式来处理这个问题。
- en: One could argue, well why don’t you list all the columns in the transformed
    training dataset as columns that would be needed for your inference dataset? The
    problem here is that you often don’t know what factor levels are in the training
    data upfront.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会争论，为什么不直接将转化后的训练数据集中的所有列列为推理数据集所需的列呢？这里的问题是，通常你无法事先知道训练数据中的因子水平。
- en: For example, new levels could be introduced regularly, which could make it difficult
    to maintain. On top of that comes the process of then matching your inference
    dataset with the training data, so you would need to check all actual transformed
    column names that went into the training algorithm, and then match them with the
    transformed inference dataset. If any columns were missing you would need to insert
    new columns with 0 values and if you had extra columns, like the `color_2__orange`
    columns above, those would need to be deleted. This is a rather cumbersome way
    of solving the issue, and thankfully there are better options available.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，新的水平可能会定期引入，这可能使得维护变得困难。此外，还需要将推理数据集与训练数据进行匹配，因此你需要检查所有实际转化后的列名，这些列名是用于训练算法的，然后将它们与转化后的推理数据集进行匹配。如果有任何列缺失，你需要插入新列并填充
    0 值，如果有多余的列，比如上面的`color_2__orange`列，那么需要删除这些列。这是一种相当繁琐的解决问题的方法，幸好有更好的选择可供使用。
- en: The solution
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: The solution to this problem is rather straightforward, however many of the
    packages and libraries that attempt to streamline the process of creating prediction
    models fail to implement it well. The key lies in having a function or class that
    is first fitted on the training data, and then use that same instance of the function
    or class to transform both the training dataset and the inference dataset. Below
    we explore how this is done using both Python and R.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的方法相对直接，然而许多试图简化预测模型创建过程的包和库并未很好地实现它。关键在于拥有一个先在训练数据上进行拟合的函数或类，然后使用该函数或类的相同实例来转化训练数据集和推理数据集。下面我们将探索如何使用
    Python 和 R 来完成这一操作。
- en: In Python
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 中
- en: Python is arguably one the best programming language to use for machine learning,
    largely due to its extensive network of developers and mature package libraries,
    and its ease of use, which promotes rapid development.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Python 无疑是进行机器学习的最佳编程语言之一，这主要得益于其广泛的开发者网络和成熟的包库，以及它的易用性，促进了快速开发。
- en: Regarding the issues related to one-hot encoding we described above, they can
    be mitigated by using the widely available and tested scikit-learn library, and
    more specifically the `sklearn.preprocessing.OneHotEncoder` class. So, let’s see
    how we can use that on our training and inference datasets to create a robust
    one-hot encoding.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们上述描述的与独热编码相关的问题，它们可以通过使用广泛可用且经过测试的 scikit-learn 库来缓解，尤其是使用`sklearn.preprocessing.OneHotEncoder`类。因此，让我们看看如何在我们的训练和推理数据集上使用它来创建一个健壮的独热编码。
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This produces a final `DataFrame`of transformed values as shown below:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个最终的 `DataFrame`，如下面所示：
- en: '![](../Images/f305e941d89808c5f5ac9eb6977727f2.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f305e941d89808c5f5ac9eb6977727f2.png)'
- en: Transformed training dataset with sklearn / image by author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 sklearn 转化后的训练数据集 / 作者提供的图片
- en: If we break down the code above, we see that the first step is to initialize
    the an instance of the encoder class. We use the option `handle_unknown='ignore'`
    so that we avoid issues with unknow values for the columns when we use the encoder
    to transform on our inference dataset.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们分解上面的代码，我们会看到第一步是初始化编码器类的实例。我们使用`handle_unknown='ignore'`选项，以便在使用编码器转化推理数据集时避免出现未知值的问题。
- en: After that, we combine a fit and transform action into one step with the `fit_transform`
    method. And finally, we create a new data frame from the encoded data and concatenate
    it with the rest of the original dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将`fit`和`transform`操作合并为一步，使用`fit_transform`方法。最后，我们从编码后的数据创建一个新的数据框，并将其与原始数据集的其余部分拼接在一起。
- en: Now the task remains to use the encoder to transform our inference dataset.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务是使用编码器来转换我们的推断数据集。
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Unlike earlier, when we used the naive `pandas.get_dummies` ,we now see that
    our new `final_inference_df` dataset has the same columns as our training dataset.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前我们使用简单的`pandas.get_dummies`时不同，现在我们看到我们的新数据集`final_inference_df`具有与训练数据集相同的列。
- en: '![](../Images/cd25ea429be35479ec782fb89827e12e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd25ea429be35479ec782fb89827e12e.png)'
- en: Transformed Inference dataset with the correct columns / image by author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 转换后的推断数据集，具有正确的列 / 图片来源：作者
- en: In addition to what we showed in the code above, the `OneHotEncoder` class from
    `sklearn.preprocessing` has a lot of other functionality that can be useful as
    well.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们在上面的代码中展示的内容之外，`sklearn.preprocessing`中的`OneHotEncoder`类还有很多其他功能，也同样非常有用。
- en: For example, it allows you set the `min_frequency` and `max_categories` options.
    As its name implies the `min_frequency` options allow you to specify the minimum
    frequency below which a category will be considered infrequent and then grouped
    together with other infrequent categories, or the `max_categories` option which
    limits the total number of categories. The latter can be especially useful if
    you don’t want to create too many columns in your training dataset.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，它允许你设置`min_frequency`和`max_categories`选项。顾名思义，`min_frequency`选项允许你指定一个最低频率，低于该频率的类别将被视为不常见，并与其他不常见类别一起分组，或者是`max_categories`选项，它限制了类别的总数。如果你不希望在训练数据集中创建过多的列，这后一种选项特别有用。
- en: 'For a full overview of the functionality, visit the documentation pages here:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解完整功能概述，请访问以下文档页面：
- en: '[](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?source=post_page-----930b5f8943af--------------------------------#sklearn.preprocessing.OneHotEncoder)
    [## sklearn.preprocessing.OneHotEncoder'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?source=post_page-----930b5f8943af--------------------------------#sklearn.preprocessing.OneHotEncoder)
    [## sklearn.preprocessing.OneHotEncoder'
- en: 'Examples using sklearn.preprocessing.OneHotEncoder: Release Highlights for
    scikit-learn 1.4 Release Highlights for…'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用sklearn.preprocessing.OneHotEncoder的示例：scikit-learn 1.4版本发布亮点……
- en: scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?source=post_page-----930b5f8943af--------------------------------#sklearn.preprocessing.OneHotEncoder)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?source=post_page-----930b5f8943af--------------------------------#sklearn.preprocessing.OneHotEncoder)
- en: In R
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在R中
- en: 'Several of my clients use R for running machine learning models in production
    — and it has a lot of great features. Before `polars` came out for Python, R’s
    `data.table` package was superior to what `pandas` could offer in terms of speed
    and efficiency. However, R doesn’t have access to the same type of production
    level packages as `scikit-learn` for python. (There are a few libraries, but they
    are not as mature as `scikit-learn`.) In addition, while some packages might have
    the required functionality, they require loads of other packages to run and can
    introduce dependency conflicts into your code. Consider running the line below
    in a docker container build with the r-base image:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我的几个客户使用R在生产环境中运行机器学习模型——而且R有很多优秀的功能。在`polars`发布之前，R的`data.table`包在速度和效率上优于`pandas`所能提供的。然而，R无法访问像Python中`scikit-learn`这样的生产级别的包。（虽然有一些库，但它们不像`scikit-learn`那样成熟。）此外，尽管某些包可能具有所需的功能，但它们需要大量其他包的支持，并可能会引入依赖冲突。考虑在使用r-base镜像构建的docker容器中运行下面的命令：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It takes forever to install and takes up a lot of space on your container image.
    Our solution in this case — instead of using functions from a pre-built package
    like `recipes` — is to introduce our own simple function implemented using the
    `data.table` package:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 它安装时间非常长，而且占用了你容器镜像的大量空间。在这种情况下，我们的解决方案是——不使用像`recipes`这样预构建包中的函数——而是引入我们自己实现的简单函数，使用`data.table`包：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s go through this function and see how it works on our training and inference
    datasets. (R is slightly different from Python and instead of using a class, we
    use a parent function instead, which works in a similar way.)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细研究这个函数，看看它在我们的训练和推断数据集上是如何工作的。（R 与 Python 稍有不同，我们不使用类，而是使用一个父函数，其工作方式类似。）
- en: 'First, we need to create an instance of the function:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个函数的实例：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then, just like with the `OneHotEncoder` class from sklearn.preprocessing, we
    also have a fit function inside our `OneHotEncoder`. We use the fit function on
    the training data, supplying both the training dataset and the columns we want
    to one-hot encode.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，就像`sklearn.preprocessing`中的`OneHotEncoder`类一样，我们的`OneHotEncoder`中也有一个适配函数。
    我们在训练数据上使用适配函数，提供训练数据集和我们想要进行独热编码的列。
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The fit function simply loops through all the columns we want to use to for
    training and finds all the unique values each of the columns contain. This list
    of columns and their potential values is then used in the transform function.
    We now have a instance of a fitted one-hot encoder function and we can save it
    for later use using a R `.RDS` file.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 适配函数简单地循环遍历我们想要用于训练的所有列，并找到每个列包含的所有唯一值。 然后，在转换函数中使用这些列及其潜在值。 现在我们有一个已安装的独热编码器函数实例，我们可以使用
    R 的`.RDS`文件将其保存以备将来使用。
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To generate the one-hot encoded dataset we need for training, we run the transform
    function on the training data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成我们需要用于训练的独热编码数据集，我们在训练数据上运行转换函数：
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The transform function is a little bit more complicated than the fit function,
    and the first thing it does is to convert the supplied columns into factors —
    using the original unique values of the columns as factor levels. Then, we loop
    through each of the predictor columns and create `model.matrix` objects of the
    data. These are then added back to the original dataset and the original factor
    column is removed. We also make sure to set any of the missing values to 0.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 转换函数比拟拟适配函数稍微复杂一些，它首先将提供的列转换为因子 — 使用列的原始唯一值作为因子水平。 然后，我们循环遍历每个预测列，并创建数据的`model.matrix`对象。
    然后，将这些对象添加回原始数据集，并删除原始因子列。 我们还确保将任何缺失值设置为 0。
- en: 'We now get the exact same dataset as before:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们得到了与之前完全相同的数据集：
- en: '![](../Images/f305e941d89808c5f5ac9eb6977727f2.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f305e941d89808c5f5ac9eb6977727f2.png)'
- en: Transformed training dataset using R algorithm / image by author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 R 算法转换的训练数据集 / 作者提供的图片
- en: 'And finally, when we need to one-hot encode our inference dataset, we then
    run the same instance of the encoder function on that dataset:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们需要对我们的推断数据集进行独热编码时，我们在该数据集上运行编码器函数的相同实例：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This process ensures we have the same columns in our `transformed_inference_data`
    as we do in our `transformed_training_data`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程确保我们在`transformed_inference_data`中有与`transformed_training_data`中相同的列。
- en: Further considerations
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步考虑
- en: Before we conclude there are a few extra considerations to mention. As with
    many other things in machine learning there isn’t always an easy answer as to
    when and how to use a specific technique. Even though it clearly mitigates some
    issues, new problems can also arise when doing one-hot encoding. Most commonly,
    these are related to how to deal with high cardinality categorical variables and
    how to deal with memory issues because of increasing the table size.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们总结之前，有一些额外的考虑事项需要提及。 与机器学习中的许多其他事物一样，关于何时以及如何使用特定技术并没有总是一个简单的答案。 尽管它显然可以缓解一些问题，但在进行独热编码时也可能出现新问题。
    最常见的问题与如何处理高基数分类变量以及由于增加表格大小而导致的内存问题有关。
- en: In addition, there are alternative coding techniques such as label encoding,
    embeddings, or target encodings which sometimes could be preferable to one-hot
    encoding.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有替代编码技术，如标签编码、嵌入或目标编码，有时可能更适合于独热编码。
- en: Each of these topics is rich enough to warrant a dedicated article, so we will
    leave those for the interested reader to explore further.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每个主题都足够丰富，值得撰写一篇专门的文章，因此我们将这些内容留给有兴趣进一步探索的读者。
- en: Conclusion
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have shown how naive use of one-hot encoding techniques can lead to mistakes
    and problems with inference data, and we have also seen how to mitigate and resolve
    those issues using both Python and R. If left unresolved, poor management of one-hot
    encoding can potentially lead to crashes and problems with your inference, so
    it is strongly recommended to use more robust techniques—like either sklearn’s
    `OneHotEncoder` or the R function we developed.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了如何错误地使用 one-hot 编码技术可能导致推理数据中的错误和问题，也展示了如何通过 Python 和 R 来减轻和解决这些问题。如果不解决，one-hot
    编码的管理不当可能会导致崩溃和推理问题，因此强烈建议使用更稳健的技术——例如 sklearn 的 `OneHotEncoder` 或我们开发的 R 函数。
- en: Thanks for reading!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: '*All the code presented and used in the article can be found in the following
    Github repo:* [*https://github.com/hcekne/robust_one_hot_encoding*](https://github.com/hcekne/robust_one_hot_encoding)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*文中展示并使用的所有代码可以在以下 GitHub 仓库找到：* [*https://github.com/hcekne/robust_one_hot_encoding*](https://github.com/hcekne/robust_one_hot_encoding)'
- en: '*If you enjoyed reading this article and would like to access more content
    from me please feel free to connect with me on LinkedIn at* [*https://www.linkedin.com/in/hans-christian-ekne-1760a259/*](https://www.linkedin.com/in/hans-christian-ekne-1760a259/)
    *or visit my webpage at* [*https://www.ekneconsulting.com/*](https://www.ekneconsulting.com/)
    *to explore some of the services I offer. Don’t hesitate to reach out via email
    at hce@ekneconsulting.com*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢阅读这篇文章并希望访问更多我的内容，欢迎通过 LinkedIn 与我联系，链接为* [*https://www.linkedin.com/in/hans-christian-ekne-1760a259/*](https://www.linkedin.com/in/hans-christian-ekne-1760a259/)
    *，或者访问我的个人网站* [*https://www.ekneconsulting.com/*](https://www.ekneconsulting.com/)
    *，了解我提供的一些服务。如有任何疑问，请通过电子邮件 hce@ekneconsulting.com 随时与我联系。*'
