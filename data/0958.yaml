- en: Feature Engineering with Microsoft Fabric and Dataflow Gen2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Microsoft Fabric 和 Dataflow Gen2 进行特征工程
- en: 原文：[https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15](https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15](https://towardsdatascience.com/feature-engineering-with-microsoft-fabric-and-dataflow-gen2-1471d22014b9?source=collection_archive---------11-----------------------#2024-04-15)
- en: Fabric Madness part 3
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fabric Madness 第三部分
- en: '[](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)[![Roger
    Noble](../Images/869b5b0f237f24b119ca6c41c2e31162.png)](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)
    [Roger Noble](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)[![Roger
    Noble](../Images/869b5b0f237f24b119ca6c41c2e31162.png)](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)
    [Roger Noble](https://medium.com/@roger_noble?source=post_page---byline--1471d22014b9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)
    ·11 min read·Apr 15, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1471d22014b9--------------------------------)
    ·阅读时间11分钟·2024年4月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6a72c6bcc90ff02e9f300c48d9df2afc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a72c6bcc90ff02e9f300c48d9df2afc.png)'
- en: Image by author and ChatGPT. “Design an illustration, featuring a Paralympic
    basketball player in action, this time the theme is on data pipelines” prompt.
    ChatGPT, 4, OpenAI, 15April. 2024\. [https://chat.openai.com.](https://chat.openai.com./)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者和 ChatGPT 提供。“设计一张插图，展示一名残奥篮球运动员在比赛中的动作，本次主题为数据管道”提示。ChatGPT，4，OpenAI，2024年4月15日。[https://chat.openai.com.](https://chat.openai.com./)
- en: In the [previous post](https://medium.com/towards-data-science/feature-engineering-with-microsoft-fabric-and-pyspark-16d458018744),
    we discussed how to use Notebooks with PySpark for feature engineering. While
    spark offers a lot of flexibility and power, it can be quite complex and requires
    a lot of code to get started. Not everyone is comfortable with writing code or
    has the time to learn a new programming language, which is where Dataflow Gen2
    comes in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[上一篇文章](https://medium.com/towards-data-science/feature-engineering-with-microsoft-fabric-and-pyspark-16d458018744)中，我们讨论了如何使用
    PySpark 和 Notebooks 进行特征工程。虽然 Spark 提供了很大的灵活性和强大功能，但它相当复杂，需要大量代码来入门。并不是每个人都愿意编写代码，或者有时间学习一种新的编程语言，这就是
    Dataflow Gen2 的用武之地。
- en: What is Dataflow Gen2?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Dataflow Gen2？
- en: Dataflow Gen2 is a low-code data transformation and integration engine that
    allows you to create data pipelines for loading data from a wide variety of sources
    into Microsoft Fabric. It’s based on Power Query, which is integrated into many
    Microsoft products, such as Excel, Power BI, and Azure Data Factory. Dataflow
    Gen2 is a great tool for creating data pipelines without code via a visual interface,
    making it easy to create data pipelines quickly. If you are already familiar with
    Power Query or are not afraid of writing code, you can also use the underlying
    M (“Mashup”) language to create more complex transformations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Dataflow Gen2 是一个低代码数据转换和集成引擎，允许您创建数据管道，将数据从各种来源加载到 Microsoft Fabric 中。它基于 Power
    Query，Power Query 已集成到许多 Microsoft 产品中，如 Excel、Power BI 和 Azure Data Factory。Dataflow
    Gen2 是一个通过可视化界面创建数据管道的优秀工具，能够让您轻松、快速地创建数据管道。如果您已经熟悉 Power Query 或不怕编写代码，您还可以使用底层的
    M（“Mashup”）语言来创建更复杂的转换。
- en: In this post, we will walk through how to use Dataflow Gen2 to create the same
    features needed to train our machine learning model. We will use the same dataset
    as in the previous post, which contains data about college basketball games.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将演示如何使用 Dataflow Gen2 创建训练机器学习模型所需的特征。我们将使用与上一篇文章相同的数据集，该数据集包含有关大学篮球比赛的数据。
- en: '![](../Images/9612ef75cfbd3ebf67434d7e9b667e29.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9612ef75cfbd3ebf67434d7e9b667e29.png)'
- en: Fig. 1 — The final result. Image by author.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1 — 最终结果。图片由作者提供。
- en: The Challenge
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战
- en: 'There are two datasets that we will be using to create our features: the regular
    season games and the tournament games. These two datasets are also split into
    the Men’s and Women’s tournaments, which will need to be combined into a single
    dataset. In total there are four csv files, that need to be combined and transformed
    into two separate tables in the Lakehouse.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个数据集来创建我们的特征：常规赛比赛数据和锦标赛比赛数据。这两个数据集还分别拆分为男篮和女篮比赛数据，最终需要将它们合并为一个单独的数据集。总共有四个
    csv 文件，需要将其合并并转换为两个独立的表格存储在 Lakehouse 中。
- en: 'Using Dataflows there are multiple ways to solve this problem, and in this
    post I want to show three different approaches: a no code approach, a low code
    approach and finally a more advanced all code approach.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Dataflows 有多种方法可以解决这个问题，在这篇文章中，我将展示三种不同的方法：无代码方法、低代码方法以及最终的更高级的全代码方法。
- en: The no code approach
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无代码方法
- en: The first and simplest approach is to use the Dataflow Gen2 visual interface
    to load the data and create the features.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个也是最简单的方法是使用 Dataflow Gen2 可视化界面加载数据并创建特征。
- en: The Data
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: The data we are looking at is from the 2024 US college basketball tournaments,
    which was obtained from the on-going March Machine Learning Mania 2024 Kaggle
    competition, the details of which can be found [here](https://www.kaggle.com/competitions/march-machine-learning-mania-2024/overview),
    and is licensed under CC BY 4.0
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所查看的数据来自 2024 年美国大学篮球锦标赛，这些数据是从正在进行的 2024 年三月机器学习狂潮（March Machine Learning
    Mania）Kaggle 竞赛中获得的，详细信息请见 [此处](https://www.kaggle.com/competitions/march-machine-learning-mania-2024/overview)，并且此数据已根据
    CC BY 4.0 授权协议发布。
- en: Loading the data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据加载
- en: The first step is to get the data from the Lakehouse, which can be done by selecting
    the “Get Data” button in the Home ribbon and then selecting **More…** from the
    list of data sources.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从 Lakehouse 获取数据，这可以通过在“开始”选项卡中点击“获取数据”按钮，然后从数据源列表中选择 **更多…** 来实现。
- en: '![](../Images/09e6830ca797495bd419893e0cb18b0e.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09e6830ca797495bd419893e0cb18b0e.png)'
- en: Fig. 2 — Choosing a data source. Image by author.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2 — 选择数据源。图片由作者提供。
- en: From the list, select **OneLake data hub** to find the Lakehouse and then once
    selected, find the csv file in the Files folder.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从列表中选择 **OneLake 数据中心**，找到 Lakehouse，然后在文件夹中找到 csv 文件。
- en: '![](../Images/79af66f24ffb07087bd9b233f519caa0.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79af66f24ffb07087bd9b233f519caa0.png)'
- en: Fig. 3 — Select the csv file. Image by author.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3 — 选择 csv 文件。图片由作者提供。
- en: 'This will create a new query with four steps, which are:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个包含四个步骤的新查询，具体步骤如下：
- en: 'Source: A function that queries the Lakehouse for all the contents.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来源：一个查询 Lakehouse 中所有内容的函数。
- en: 'Navigation 1: Converts the contents of the Lakehouse into a table.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导航 1：将 Lakehouse 中的内容转换为表格。
- en: 'Navigation 2: Filters the table to retrieve the selected csv file by name.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导航 2：通过名称过滤表格以检索选定的 csv 文件。
- en: 'Imported CSV: Converts the binary file into a table.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入的 CSV：将二进制文件转换为表格。
- en: '![](../Images/b2fd1a2b8f2b1f429cc45716b45bb3a2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2fd1a2b8f2b1f429cc45716b45bb3a2.png)'
- en: Fig. 4 — Initial load. Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 — 初始加载。图片由作者提供。
- en: Now that the data is loaded we can start with some basic data preparation to
    get it into a format that we can use to create our features. The first thing we
    need to do is set the column names to be based on the first row of the dataset.
    This can be done by selecting the “Use first row as headers” option in either
    the Transform group on the Home ribbon or in the Transform menu item.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载完成后，我们可以开始进行一些基本的数据准备，将数据转换为可以用来创建特征的格式。首先需要做的是将列名设置为基于数据集的第一行。这可以通过在“开始”选项卡的“转换”组中或在“转换”菜单项中选择“使用第一行作为标题”选项来完成。
- en: The next step is to rename the column “WLoc” to “location” by either selecting
    the column in the table view, or by right clicking on the column and selecting
    “Rename”.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将“WLoc”列重命名为“location”，可以通过选择表格视图中的该列，或右键点击该列并选择“重命名”来实现。
- en: The location column contains the location of the game, which is either “H” for
    home, “A” for away, or “N” for neutral. For our purposes, we want to convert this
    to a numerical value, where “H” is 1, “A” is -1, and “N” is 0, as this will make
    it easier to use in our model. This can be done by selecting the column and then
    using the **Replace values…** transform in the Transform menu item.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: location 列包含比赛地点，值为“H”代表主场，“A”代表客场，或“N”代表中立场地。为了方便我们的分析，我们希望将这些值转换为数值，其中“H”表示
    1，“A”表示 -1，“N”表示 0，这样更方便在模型中使用。这可以通过选择该列，然后在“转换”菜单项中使用 **替换值…** 转换来实现。
- en: '![](../Images/3026952f8952ad4f14af39db338e6cc0.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3026952f8952ad4f14af39db338e6cc0.png)'
- en: Fig. 5 — Replace Values. Image by author.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5 — 替换值。图片来自作者。
- en: This will need to be done for the other two location values as well.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于其他两个位置值也需要进行相同的操作。
- en: Finally, we need to change the data type of the location column to be a Whole
    number instead of Text. This can be done by selecting the column and then selecting
    the data type from the drop down list in the Transform group on the Home ribbon.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要将位置列的数据类型从文本更改为整数。这可以通过选择该列，然后在“主页”功能区的“转换”组中，从下拉列表中选择数据类型来完成。
- en: '![](../Images/6a798ea01fb3197b4ffcacc135a69f88.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a798ea01fb3197b4ffcacc135a69f88.png)'
- en: Fig. 6 — Final data load. Image by author.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6 — 最终数据加载。图片来自作者。
- en: Instead of repeating the rename step for each of the location types, a little
    bit of M code can be used to replace the values in the location column. This can
    be done by selecting the previous transform in the query (Renamed columns) and
    then selecting the Insert step button in the formula bar. This will add a new
    step, and you can enter the following code to replace the values in the location
    column.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免对每种位置类型重复重命名步骤，我们可以使用一些 M 代码来替换位置列中的值。可以通过选择查询中的前一个转换步骤（重命名列），然后在公式栏中选择“插入步骤”按钮来实现。这将添加一个新步骤，您可以输入以下代码来替换位置列中的值。
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Adding features
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加特征
- en: We’ve got the data loaded, but it’s still not right for our model. Each row
    in the dataset represents a game between two teams, and includes the scores and
    statistics for both the winning and losing team in a single wide table. We need
    to create features that represent the performance of each team in the game and
    to have a row per team per game.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经加载了数据，但它仍然不符合我们的模型要求。数据集中的每一行代表两支队伍之间的一场比赛，包含了胜利队伍和失败队伍的得分和统计信息，并且这些信息都在同一张宽表格中。我们需要创建能够表示每支队伍在比赛中的表现的特征，并且每场比赛每支队伍需要有一行数据。
- en: To do this we need to split the data into two tables, one for the winning team
    and one for the losing team. The simplest way to do this is to create a new query
    for each team and then merge them back together at the end. There are a few ways
    that this could be done, however to keep things simple and understandable (especially
    if we ever need to come back to this later), we will create two references to
    the source query and then append them together again, after doing some light transformations.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们需要将数据拆分成两张表，一张用于胜利队伍，另一张用于失败队伍。最简单的方法是为每支队伍创建一个新的查询，然后在最后将它们合并。虽然有几种方法可以做到这一点，但为了保持简单和易于理解（尤其是当我们以后需要回到这个步骤时），我们将创建两个源查询的引用，然后在进行一些轻微的转换后，再将它们合并。
- en: Referencing a column can be done either from the Queries panel on the left,
    or by selecting the context menu of the query if using Diagram view. This will
    create a new query that references the original query, and any changes made to
    the original query will be reflected in the new query. I did this twice, once
    for the winning team and once for the losing team and then renamed the columns
    by prefixing them with “T1_” and “T2_” respectively.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 引用列可以通过左侧的查询面板完成，或者在使用图示视图时，通过选择查询的上下文菜单来完成。这将创建一个引用原始查询的新查询，并且对原始查询所做的任何更改都会反映到新查询中。我做了两次操作，一次用于胜利队伍，一次用于失败队伍，然后通过分别为它们加上“
    T1_” 和 “T2_” 前缀来重命名列。
- en: '![](../Images/eaa71856383445c2c54e32569ebd31f8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaa71856383445c2c54e32569ebd31f8.png)'
- en: Fig. 7 — Split the dataset. Image by author.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7 — 拆分数据集。图片来自作者。
- en: Once the column values are set, we can then combine the two queries back together
    by using Append Queries and then create our first feature, which is the point
    difference between the two teams. This can be done by selecting the T1_Score and
    T2_Score columns and then selecting “Subtract” from the “Standard” group on the
    Add column ribbon.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦列的值设置完毕，我们就可以通过使用“附加查询”将两个查询合并在一起，然后创建我们的第一个特征，即两支队伍之间的得分差。这可以通过选择 T1_Score
    和 T2_Score 列，然后在“添加列”功能区的“标准”组中选择“减法”来完成。
- en: 'Now that’s done, we can then load the data into the Lakehouse as a new table.
    The final result should look something like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，我们就可以将数据作为新表加载到 Lakehouse 中。最终的结果应该如下所示：
- en: '![](../Images/b1e0440221e77afad699b89e8a1ee67d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1e0440221e77afad699b89e8a1ee67d.png)'
- en: Fig. 8 — All joined up. Image by author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8 — 所有连接起来。图片来自作者。
- en: There are a few limitations with the no code approach, the main one is that
    it’s not easy to reuse queries or transformations. In the above example we would
    need to repeat the same steps another three times to load each of the individual
    csv files. This is where copy / paste comes in handy, but it’s not ideal. Let’s
    look at a low code approach next.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 无代码方法存在一些局限性，主要问题在于不容易重复使用查询或转换。在上述示例中，我们需要再重复三次相同的步骤，以加载每一个单独的 csv 文件。此时，复制/粘贴就变得非常方便，但这并不是最理想的方式。接下来我们来看看低代码方法。
- en: The low code approach
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 低代码方法
- en: In the low code approach we will use a combination of the visual interface and
    the M language to load and transform the data. This approach is more flexible
    than the no code approach, but still doesn’t require a lot of code to be written.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在低代码方法中，我们将结合使用可视化界面和 M 语言来加载和转换数据。这种方法比无代码方法更灵活，但仍然不需要编写大量代码。
- en: Loading the data
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: The goal of the low code approach is to reduce the number of repeated queries
    that are needed and to make it easier to reuse transformations. To do this we
    will take advantage of the fact that Power Query is a functional language and
    that we can create functions to encapsulate the transformations that we want to
    apply to the data. When we first loaded the data from the Lakehouse there were
    four steps that were created, the second step was to convert the contents of the
    Lakehouse into a table, with each row containing a reference to a binary csv file.
    We can use this as the input into a function, which will load the csv into a new
    table, using the Invoke custom function transformation for each row of the table.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 低代码方法的目标是减少所需的重复查询次数，并使得转换的重用变得更加容易。为此，我们将利用 Power Query 是一种函数式语言的特点，创建函数来封装我们想要应用于数据的转换操作。当我们第一次从
    Lakehouse 加载数据时，创建了四个步骤，第二步是将 Lakehouse 的内容转换为一个表格，每一行包含一个指向二进制 csv 文件的引用。我们可以将这个作为函数的输入，这个函数将使用“调用自定义函数”转换来加载
    csv 到一个新表格中。
- en: '![](../Images/38cb149e20c76260a93ed2ba7fc2ddf4.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38cb149e20c76260a93ed2ba7fc2ddf4.png)'
- en: Fig. 9 — Lakehouse query with the binary csv files in a column called Content.
    Image by author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9 — 使用名为“Content”的列中的二进制 csv 文件进行 Lakehouse 查询。图片来自作者。
- en: 'To create the function, select “Blank query” from the Get data menu, or right
    click the Queries panel and select “New query” > “Blank query”. In the new query
    window, enter the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建函数，请从“获取数据”菜单中选择“空查询”，或者右键点击查询面板，选择“新建查询” > “空查询”。在新查询窗口中，输入以下代码：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The code of this function has been copied from our initial no code approach,
    but instead of loading the csv file directly, it takes a parameter called **TableContents**,
    reads it as a csv file `Csv.Document` and then sets the first row of the data
    to be the column headers `Table.PromoteHeaders`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的代码是从我们最初的无代码方法中复制过来的，但它不是直接加载 csv 文件，而是接受一个名为**TableContents**的参数，将其读取为一个
    csv 文件`Csv.Document`，然后将数据的第一行设置为列标题`Table.PromoteHeaders`。
- en: We can then use the Invoke custom function transformation to apply this function
    to each row of the Lakehouse query. This can be done by selecting the “Invoke
    custom function” transformation from the Add column ribbon and then selecting
    the function that we just created.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用“调用自定义函数”转换来将这个函数应用到 Lakehouse 查询的每一行。这可以通过从“添加列”功能区中选择“调用自定义函数”转换，并选择我们刚刚创建的函数来完成。
- en: '![](../Images/93db46a8fd3ec467e7c6ccb9c13d3605.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93db46a8fd3ec467e7c6ccb9c13d3605.png)'
- en: Fig. 10 — Invoke custom function. Image by author.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10 — 调用自定义函数。图片来自作者。
- en: This will create a new column in the Lakehouse query, with the entire contents
    of the csv file loaded into a table, which is represented as `[Table]` in the
    table view. We can then use the expand function on the column heading to expand
    the table into individual columns.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这将会在 Lakehouse 查询中创建一个新列，其中 csv 文件的所有内容会加载到一个表格中，并在表格视图中显示为`[Table]`。然后，我们可以使用列标题上的展开功能，将表格展开为单独的列。
- en: '![](../Images/a2f6d83805e7ca0cf3ab9814c6746ac0.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2f6d83805e7ca0cf3ab9814c6746ac0.png)'
- en: Fig. 11 — Expand columns. Image by author.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11 — 展开列。图片来自作者。
- en: The result effectively combines the two csv files into a single table, which
    we can then continue to create our features from as before.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果有效地将两个 csv 文件合并为一个单独的表格，然后我们可以像之前一样继续创建我们的特征。
- en: There are still some limitations with this approach, while we’ve reduced the
    number of repeated queries, we still need to duplicate everything for both the
    regular season and tournament games datasets. This is where the all code approach
    comes in.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法仍然有一些局限性，尽管我们减少了重复查询的数量，但我们仍然需要为常规赛和锦标赛数据集分别复制所有内容。这里就是全代码方法的作用。
- en: The all code approach
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全代码方法
- en: The all code approach is the most flexible and powerful approach, but also requires
    the most amount of code to be written. This approach is best suited for those
    who are comfortable with writing code and want to have full control over the transformations
    that are applied to the data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 全代码方法是最灵活和最强大的方法，但也需要编写最多的代码。这个方法最适合那些熟悉编写代码的人，他们希望完全控制应用于数据的转换。
- en: Essentially what we’ll do is grab all the M code that was generated in each
    of the queries and combine them into a single query. This will allow us to load
    all the csv files in a single query and then apply the transformations to each
    of them in a single step. To get all the M code, we can select each query and
    then click on the Advanced Editor from the Home ribbon, which displays all the
    M code that was generated for that query. We can then copy and paste this code
    into a new query and then combine them all together.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们会提取每个查询中生成的所有 M 代码，并将它们合并成一个单一的查询。这将允许我们在一个查询中加载所有 CSV 文件，然后在一个步骤中对每个文件应用转换。要获取所有的
    M 代码，我们可以选择每个查询，然后点击主页功能区中的高级编辑器，这样就会显示出该查询生成的所有 M 代码。然后，我们可以将这些代码复制并粘贴到新的查询中，并将它们全部合并。
- en: 'To do this, we need to create a new blank query and then enter the following
    code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要创建一个新的空白查询，然后输入以下代码：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Note: the Lakehouse connection values have been removed*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：Lakehouse 连接值已被移除*'
- en: 'What’s happening here is that we’re:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生的事情是，我们：
- en: Loading the data from the Lakehouse;
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Lakehouse 加载数据；
- en: Filtering the rows to only include the csv files that match the TourneyType
    parameter;
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤行，仅包括与 `TourneyType` 参数匹配的 CSV 文件；
- en: Loading the csv files into tables;
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 CSV 文件加载到表格中；
- en: Expanding the tables into columns;
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将表格扩展为列；
- en: Renaming the columns;
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重命名列；
- en: Changing the data types;
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改数据类型；
- en: Combining the two tables back together;
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两张表重新合并；
- en: Calculating the point difference between the two teams.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算两支队伍之间的得分差。
- en: Using the query is then as simple as selecting it, and then invoking the function
    with the TourneyType parameter.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用查询非常简单，只需选择它，然后使用 `TourneyType` 参数调用函数。
- en: '![](../Images/6fb312c0bced0e91a3e7141022d951e5.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6fb312c0bced0e91a3e7141022d951e5.png)'
- en: Fig. 12 — Invoke function. Image by author.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12 — 调用函数。图片由作者提供。
- en: This will create a new query with the function as it’s source, and the data
    loaded and transformed. It’s then just a case of loading the data into the Lakehouse
    as a new table.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的查询，使用函数作为源，并加载并转换数据。然后，只需将数据作为新表加载到 Lakehouse 中即可。
- en: '![](../Images/91ea5a15eb7ff19de63185d8fee0d1a8.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91ea5a15eb7ff19de63185d8fee0d1a8.png)'
- en: Fig. 13 — Function load. Image by author.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13 — 函数加载。图片由作者提供。
- en: As you can see, the LoadTournamentData function is invoked with the parameter
    “RegularSeasonDetailedResults” which will load both the Men’s and Women’s regular
    season games into a single table.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`LoadTournamentData` 函数使用了参数“RegularSeasonDetailedResults”，该参数会将男子和女子常规赛的比赛数据加载到同一个表格中。
- en: Conclusion
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: And that’s it!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！
- en: Hopefully this post has given you a good overview of how to use Dataflow Gen2
    to prepare data and create features for your machine learning model. Its low code
    approach makes it easy to create data pipelines quickly, and it contains a lot
    of powerful features that can be used to create complex transformations. It’s
    a great first port of call for anyone who needs to transform data, but more importantly,
    has the benefit of not needing to write complex code that is prone to errors,
    is hard to test, and is difficult to maintain.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这篇文章能为你提供如何使用 Dataflow Gen2 准备数据并为机器学习模型创建特征的概述。其低代码方法使得快速创建数据管道变得非常简单，并且包含了许多强大的功能，可以用于创建复杂的转换。对于需要转换数据的人来说，这是一个很好的起点，更重要的是，它的好处在于不需要编写容易出错、难以测试且难以维护的复杂代码。
- en: At the time of writing, Dataflows Gen2 are unsupported with the Git integration,
    and so it’s not possible to version control or share the dataflows. This feature
    is expected to be [released in Q4 2024](https://learn.microsoft.com/en-us/fabric/release-plan/data-factory#git-df).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Dataflows Gen2 尚不支持 Git 集成，因此无法对数据流进行版本控制或共享。预计此功能将在[2024年第四季度发布](https://learn.microsoft.com/en-us/fabric/release-plan/data-factory#git-df)。
- en: '*Originally published at* [*https://nobledynamic.com*](https://nobledynamic.com/posts/fabric-madness-3/)
    *on April 15, 2024.*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发布于* [*https://nobledynamic.com*](https://nobledynamic.com/posts/fabric-madness-3/)
    *2024年4月15日。*'
