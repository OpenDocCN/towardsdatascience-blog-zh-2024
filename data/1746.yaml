- en: '“Judge an LLM Judge”: A Dual-Layer Evaluation (QA) Framework for Continuous
    Improvement of LLM Application’s Evaluation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: “评判LLM法官”：LLM应用评估持续改进的双层评估（QA）框架
- en: 原文：[https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17](https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17](https://towardsdatascience.com/judge-an-llm-judge-a-dual-layer-evaluation-framework-for-continous-improvement-of-llm-apps-7450d0e81e17?source=collection_archive---------5-----------------------#2024-07-17)
- en: Can “the evaluation of an LLM app by an LLM judge” be audited by another LLM
    judge for the continuous improvement of the evaluation process?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “由LLM法官对LLM应用进行评估”是否可以通过另一个LLM法官进行审计，以实现评估过程的持续改进？
- en: '[](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[![Daniel
    Khoa Le](../Images/5c01c760dc1e92b3048cfae005838ef1.png)](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    [Daniel Khoa Le](https://medium.com/@khoadaniel?source=post_page---byline--7450d0e81e17--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    ·11 min read·Jul 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--7450d0e81e17--------------------------------)
    ·11分钟阅读·2024年7月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1ddd8f73fa7bf769628f79323863c090.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ddd8f73fa7bf769628f79323863c090.png)'
- en: Continuous Improvement Framework for LLM Application’s Evaluation with Reference-free
    Approach — Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应用评估的持续改进框架——无参考方法 —— 图像由作者提供
- en: TLDR
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TLDR
- en: This article explains the concept and the low-abstraction implementation of
    employing an LLM judge to evaluate another LLM judge. The purpose is to improve
    the evaluation process of LLM applications, reducing cases where LLM judges fail
    to make fair assessments.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文解释了使用LLM法官评估另一个LLM法官的概念和低抽象实现。其目的是改进LLM应用的评估过程，减少LLM法官未能做出公正评估的情况。
- en: Table of Contents
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '[Introduction](#f147)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[引言](#f147)'
- en: '[Research Question](#422d)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[研究问题](#422d)'
- en: '[Experiment Design](#1e42)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实验设计](#1e42)'
- en: '[Implementation](#2805)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实现](#2805)'
- en: '[Experiment Results](#1fe0)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实验结果](#1fe0)'
- en: '[Conclusions](#41bc)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[结论](#41bc)'
- en: 👉 Introduction
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 引言
- en: ❇️ In the field of building LLM applications, how to ensure consistent and reliable
    performance is one of the most frequently asked questions regarding QA (Quality
    Assurance). Due to their indeterministic nature, LLM models can produce great
    variability in their outputs. Hence, rigorous evaluation of LLM applications is
    strictly required. **Without good evaluation methods, we must accept a certain
    level of risk (e.g. customer complaints, etc.) due to the inability to promptly
    identify unexpected behaviors in LLM applications.** Common LLM evaluation methodologies
    include heuristic evaluations, LLM-as-judge, and human review.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ❇️ 在构建LLM应用的领域，如何确保一致且可靠的性能是关于质量保证（QA）中最常见的提问之一。由于LLM模型的非确定性特性，它们的输出可能具有极大的变化性。因此，LLM应用的严格评估是绝对必要的。**没有良好的评估方法，我们必须接受一定程度的风险（例如客户投诉等），因为无法及时识别LLM应用中的意外行为。**
    常见的LLM评估方法包括启发式评估、LLM作为法官和人工评审。
- en: 📍 **Heuristic evaluators:** e.g. a function to check whether output = “yes”
    or whether the output > 10.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📍 **启发式评估者：**例如，检查输出是否等于“yes”或输出是否大于10的函数。
- en: 📍 **LLM-as-judge:** using an LLM to judge the output of another LLM.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📍 **LLM作为法官：**使用LLM对另一个LLM的输出进行评判。
- en: 📍**Human judge:** employ a human to evaluate the LLM’s output.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📍**人工评判者：**使用人工评估LLM的输出。
- en: ❇️ Employing an LLM judge is a top choice as it can be automated and is much
    cheaper (and more feasible) than human judges. Besides, LLM judges can deal with
    the free-text format, unlike heuristic evaluators. However, the non-deterministic
    nature of LLMs implies that even with controlled parameters, outputs may vary,
    raising concerns about the reliability of these judgments.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ❇️ 使用LLM评判者是一个最佳选择，因为它可以自动化，并且比人工评判者便宜（且更可行）。此外，LLM评判者可以处理自由文本格式，这与启发式评估者不同。然而，LLM的非确定性特征意味着即使在控制了参数的情况下，输出也可能有所不同，这引发了对这些判断可靠性的担忧。
- en: 💥 **The concern we will address today:**
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 💥 **今天我们将讨论的问题：**
- en: When opting for an LLM judge to evaluate our LLM application, we should also
    question the integrity of the LLM judge itself.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当选择LLM评判者来评估我们的LLM应用时，我们还应质疑LLM评判者本身的完整性。
- en: ✅ So, the experiment described below aims to determine whether we can use an
    LLM judge (let’s call it “Supreme LLM Judge”) to evaluate the judgments of another
    LLM judge without any ground truth reference (**reference-free evaluation**).
    The ultimate goal is to find ways to improve the first LLM judge.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 因此，下面描述的实验旨在确定我们是否可以使用一个LLM评判者（我们称之为“最高LLM评判者”）来评估另一个LLM评判者的判断，而无需任何真实参考（**无参考评估**）。最终目标是找到改善第一个LLM评判者的方法。
- en: The graph below explains such a framework.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下图解释了这样一个框架。
- en: '![](../Images/e64281469a2e8d61880d99dbaa1193e9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e64281469a2e8d61880d99dbaa1193e9.png)'
- en: High-level architecture of using an LLM judge to judge another LLM judge (reference-free)
    — Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM评判者评判另一个LLM评判者（无参考）的高层架构——图片来自作者
- en: 👉 Research Question
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 研究问题
- en: Can “the evaluation of an LLM application by an LLM judge” be audited by another
    LLM judge for the continuous improvement of the evaluation process?
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “LLM评判者对LLM应用的评估”是否可以由另一个LLM评判者进行审计，以便不断改进评估过程？
- en: 👉 Experiment Design
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 实验设计
- en: 🔹 One important constraint set out in this experiment that I must mention is
    that **both LLM judges will evaluate without a ground-truth reference**. Evaluation
    with ground-truth reference would provide the judges with the correct answers
    and ask them to compare. However, for most scenarios where we do not have datasets
    curated by humans, reference-free evaluation is the preferred approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 🔹 在此实验中必须提到的一个重要限制条件是，**两个LLM评判者都将进行无真实参考的评估**。如果使用真实参考进行评估，评判者将得到正确答案并要求进行比较。然而，对于大多数没有人工策划的数据集的场景，采用无参考评估是首选方法。
- en: 🔹 The proposed framework improves the conventional single-layer evaluation of
    LLM applications by adding a `Supreme LLM Judge`. We can have two approaches for
    this framework.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 🔹 提出的框架通过增加一个`最高LLM评判者`，改进了传统的单层LLM应用评估。我们可以为这个框架提供两种方法。
- en: '**Approach 1**: An LLM Application is evaluated by an LLM Judge, whose judgment
    is afterward reviewed by a Supreme LLM Judge (reference-free). Disagreements or
    anomalies are subsequently reviewed by a human.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方法 1**：一个LLM应用程序由一个LLM评判者进行评估，其判断随后由最高LLM评判者（无参考）进行审查。不同意见或异常情况随后由人工进行审查。'
- en: '![](../Images/9c6f792f8eebdf17e703a26683bae464.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c6f792f8eebdf17e703a26683bae464.png)'
- en: Approach 1 — Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 方法 1 — 图片来自作者
- en: '**Approach 2**: Both the LLM Judge and the Supreme LLM Judge independently
    evaluate the LLM Application (reference-free). The judgments are then compared,
    and any discrepancies are flagged for human review.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方法 2**：LLM评判者和最高LLM评判者独立评估LLM应用程序（无参考）。然后比较评判结果，任何差异都会标记出来进行人工审查。'
- en: '**Approach** **1 will be discussed further in this article.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法** **1将在本文中进一步讨论。**'
- en: 👉 Implementation
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 实现
- en: 🔹 **The implementation of the aforementioned framework I opted for focuses on
    the high-level concept without delving too deeply into the fine-tuning for perfect
    performance.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 🔹 **我选择的上述框架实现关注的是高层次概念，而没有深入探讨完美性能的微调。**
- en: No LLM evaluation libraries or platforms (e.g., LangChain, LangSmith, LangFuse,
    etc.) were used. The code implementation has low abstraction, allowing readers
    to easily follow without getting lost in the intricate details of the code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 未使用任何LLM评估库或平台（如LangChain、LangSmith、LangFuse等）。代码实现的抽象程度较低，便于读者跟随，而不会迷失在复杂的代码细节中。
- en: 'Since referencing the *LLM judge* and the *Supreme LLM Judge* can be hard to
    follow, let’s assign nominal roles for the components in the evaluation setup:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于引用*LLM评审员*和*最高级LLM评审员*可能比较难以理解，我们为评估设置中的组件分配了名义角色：
- en: '`LLM Application` ➡️`The Student`'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Application` ➡️`学生`'
- en: '`LLM Judge` ➡️ `The Teacher`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Judge` ➡️ `教师`'
- en: '`Supreme LLM Judge` ➡️ `The Reviewer`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Supreme LLM Judge` ➡️ `评审员`'
- en: '**💥 The complete code can be found in** [**this repository**](https://github.com/khoadaniel/judge-an-llm-judge)**.**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**💥 完整代码可以在** [**这个仓库**](https://github.com/khoadaniel/judge-an-llm-judge)**找到。**'
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A subtle but important decision in this experiment design is to use GPT-4 as
    the Supreme LLM Judge, while the LLM Application and LLM Judge use GPT-3.5-turbo.
    This ensures that the Supreme LLM Judge’s evaluations are more robust and reliable
    (read more about the comparison [here](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/comparing-gpt-3-5-amp-gpt-4-a-thought-framework-on-when-to-use/ba-p/4088645#:~:text=GPT%2D3.5%20was%20trained%20on,to%20their%20GPT%2D3.5%20counterparts.)).
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本实验设计中的一个微妙但重要的决策是使用GPT-4作为最高级LLM评审员，而LLM应用程序和LLM评审员使用的是GPT-3.5-turbo。这样可以确保最高级LLM评审员的评估更加稳健和可靠（关于比较的更多信息请阅读[这里](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/comparing-gpt-3-5-amp-gpt-4-a-thought-framework-on-when-to-use/ba-p/4088645#:~:text=GPT%2D3.5%20was%20trained%20on,to%20their%20GPT%2D3%2D5%20counterparts.))。
- en: The prompts for each of the components in this experiment are as follows. You
    can see that I used few-shot prompting technique to improve the consistency of
    the evaluation outputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验中各个组件的提示如下。你可以看到，我使用了少样本提示技术来提高评估输出的一致性。
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 🔹 **The question we asked the LLM application:**
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 🔹 **我们问LLM应用程序的问题是：**
- en: In a group of 30 people who can speak either English or German, 10 can speak
    both, and 25 can speak German.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在一个能说英语或德语的30人小组中，有10人能说两种语言，25人能说德语。
- en: How many speak only English?
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 多少人只会说英语？
- en: The LLM Application must not only provide the correct answer but also explain
    its reasoning. The LLM Judge then evaluates this output — both the final answer
    and the reasoning. Finally, the Supreme LLM Judge will evaluate the evaluation
    given by the LLM Judge.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应用程序不仅需要提供正确答案，还需要解释其推理过程。LLM评审员随后评估此输出——包括最终答案和推理过程。最后，最高级LLM评审员将评估LLM评审员给出的评估。
- en: You can notice that I left redundant information in the context of this question
    to challenge the LLM Application.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以注意到，我在这个问题的背景中留了一些冗余信息，以挑战LLM应用程序。
- en: 🔹 **I ran this evaluation cycle 100 times with the default temperature set by
    OpenAI API using the same question to examine the performance of the judges.**
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 🔹 **我使用OpenAI API默认温度设置，运行了100次评估周期，使用相同的问题来检验评审的表现。**
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 👉 Experiment Results
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 实验结果
- en: '💥 Once again, before reading our results, just a reminder of our definitions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 💥 再次提醒，在阅读我们的结果之前，请记住我们的定义：
- en: '`LLM Application` ➡️`The Student`'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Application` ➡️`学生`'
- en: '`LLM Judge` ➡️ `The Teacher`'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LLM Judge` ➡️ `教师`'
- en: '`Supreme LLM Judge` ➡️ `The Reviewer`'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Supreme LLM Judge` ➡️ `评审员`'
- en: 💥 **IMPORTANT:** We define a “positive case” as when the evaluation of the Teacher
    is wrong.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 💥 **重要:** 我们定义“正例”为教师评估错误的情况。
- en: We will measure the performance of the Reviewer (Supreme LLM Judge) by the following
    metrics.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下指标来衡量评审员（最高级LLM评审员）的表现。
- en: '**recall_of_reviewer:** measures the ability of the Reviewer to identify all
    the positive cases. It indicates how effectively the Reviewer can capture mistakes
    from the Teacher.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**recall_of_reviewer:** 衡量评审员识别所有正例的能力。它表示评审员能多有效地从教师的评估中捕捉到错误。'
- en: '**precision_of_reviewer:** is defined as the proportion of the Reviewer’s identified
    positive cases that are actually positive.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**precision_of_reviewer:** 定义为评审员识别出的正例中，实际为正例的比例。'
- en: There is always a tradeoff between precision and recall. The more true positive
    cases you want to capture in your predictions (and you do not care much about
    false positive cases), the less precise your model becomes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度和召回率之间总是存在权衡。你希望在预测中捕捉到更多的真正正例（且不太关注假正例），那么你的模型就会变得不那么精确。
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let’s revisit our Research Question to see how the Supreme LLM Judge (the Reviewer)
    can help to audit the work of the LLM Judge (the Teacher).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视我们的研究问题，看看最高级LLM评审员（评审员）如何帮助审查LLM评审员（教师）的工作。
- en: The Supreme LLM Judge can identify 70% of the instances where the LLM Judge
    made incorrect evaluations. By analyzing these identified cases, we can understand
    why the LLM Judge was confused and improve our LLM Application’s evaluation process.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最高级LLM评审员能够识别出LLM评审员做出错误评估的70%的案例。通过分析这些已识别的案例，我们可以了解LLM评审员为何会产生困惑，从而改进我们LLM应用的评估流程。
- en: '**😮 You might be curious about the wrong judgments from the LLM Judge that
    the Supreme LLM Judge has captured.**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**😮 你可能会好奇，最高级LLM评审员捕捉到的LLM评审员错误判定。**'
- en: Below are examples where the Reviewer successfully identified the Teacher’s
    grading errors. By looking into these examples, we can study why the LLM Judge
    did not perform well.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是评审员成功识别教师评分错误的示例。通过这些示例，我们可以研究LLM评审员表现不佳的原因。
- en: 👋 **Before reading the examples below, about the “human evaluator”:**
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 👋 **在阅读以下示例之前，关于“人工评审员”的说明：**
- en: Yes, I (the Author) am the human evaluator!
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的，我（作者）是人工评审员！
- en: In the context of this experiment, the human will grade the student’s answers
    as correct if the reasoning is sound, even if it is lengthy and contains redundant
    calculations and reasonings.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本实验的背景下，如果学生的推理是合理的，即使回答冗长且包含多余的计算和推理，人工评审员也会判定其答案为正确。
- en: Please note that this `human_grading`is against the Student’s answers.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，这个`human_grading`是针对学生的答案进行的。
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 👉 Conclusions
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 👉 结论
- en: ✅ The evaluation of the LLM Judge by the Supreme LLM Judge gave us insights
    into the effectiveness of a multi-layered evaluation system for LLM applications.
    The Supreme LLM Judge achieved a **recall rate of 70%,** successfully identifying
    70% of the incorrect evaluations made by the LLM Judge. **This is not bad for
    the case of reference-free evaluation** and for the proof-of-concept implementation.
    **These captured incorrect evaluations will potentially help us derive solutions
    to continuously improve our LLM Judge.**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 由最高级LLM评审员对LLM评审员的评估为我们提供了关于多层次评估系统在LLM应用中的有效性的见解。最高级LLM评审员成功识别了**70%的召回率，**
    成功捕捉到LLM评审员做出的70%的错误评估。**对于无参考评估的情况**以及概念验证实现来说，这个结果并不差。**这些捕捉到的错误评估可能会帮助我们找到解决方案，持续改进我们的LLM评审员。**
- en: '![](../Images/05b3263d1a1efaad043d5346bf66a0b2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05b3263d1a1efaad043d5346bf66a0b2.png)'
- en: Continuous Improvement of the LLM Judge — Image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLM评审员的持续改进 — 图片由作者提供
- en: ✅ **The difficulties we encounter when using an LLM judge to evaluate an LLM
    application also apply to using a Supreme LLM Judge to judge an LLM Judge (tongue
    twister!).** Besides the quest to aim for high accuracy of the evaluations, ensuring
    consistent evaluation outputs is also a big challenge.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ **我们在使用LLM评审员来评估LLM应用时遇到的困难，同样适用于使用最高级LLM评审员来评判LLM评审员（绕口令！）**。除了追求高准确度的评估外，确保评估结果的一致性也是一大挑战。
- en: ✅ Given that the second layer of evaluation requires human assessment with considerable
    effort, **this approach is more suitable for audits or periodic offline evaluations**
    rather than ongoing evaluations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 由于第二层评估需要耗费相当多的人工评估工作，**这种方法更适合用于审计或定期的离线评估**，而非持续性的评估。
- en: ✅ **It is also worth noting that using a random sampling method for evaluation
    might be a good approach to save resources.** By strategically deploying a second
    layer of LLM evaluation with human reviewers, we can enhance the overall reliability
    and accuracy of the evaluation system, contributing to a high-performing LLM Application.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ **同样值得注意的是，使用随机抽样方法进行评估可能是节省资源的好方法。** 通过战略性地部署第二层的大型语言模型评估，配合人工评审，我们可以增强评估系统的整体可靠性和准确性，从而有助于高效的大型语言模型应用。
- en: About me
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: I am Daniel Le, based in Berlin. I currently work in the fields of Machine Learning
    and Data Engineering.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我是Daniel Le，现居柏林。目前我从事机器学习和数据工程领域的工作。
- en: I am interested in new technologies and how they can be implemented to solve
    real-world problems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我对新技术感兴趣，并且关注它们如何应用于解决现实世界中的问题。
- en: Should you have any inquiries or wish to discuss these interests further, please
    do not hesitate to connect with me on [LinkedIn](https://www.linkedin.com/in/khoadaniel/).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有任何问题或希望进一步讨论这些兴趣，欢迎通过[LinkedIn](https://www.linkedin.com/in/khoadaniel/)与我联系。
- en: Reference
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[https://docs.smith.langchain.com/old/evaluation](https://docs.smith.langchain.com/old/evaluation)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.smith.langchain.com/old/evaluation](https://docs.smith.langchain.com/old/evaluation)'
- en: '[https://huyenchip.com/2023/04/11/llm-engineering.html](https://huyenchip.com/2023/04/11/llm-engineering.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huyenchip.com/2023/04/11/llm-engineering.html](https://huyenchip.com/2023/04/11/llm-engineering.html)'
- en: '[https://github.com/khoadaniel/judge-an-llm-judge/tree/main](https://github.com/khoadaniel/judge-an-llm-judge/tree/main)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/khoadaniel/judge-an-llm-judge/tree/main](https://github.com/khoadaniel/judge-an-llm-judge/tree/main)'
