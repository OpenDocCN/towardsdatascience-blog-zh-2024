- en: 'Why Your Service Engineers Need a Chatbot: The Future of Troubleshooting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么你的服务工程师需要一个聊天机器人：故障排除的未来
- en: 原文：[https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29](https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29](https://towardsdatascience.com/logiq-service-engineer-chatbot-04e229beee5c?source=collection_archive---------4-----------------------#2024-09-29)
- en: '![](../Images/8ede3be3aba1187f0602522551c573a0.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ede3be3aba1187f0602522551c573a0.png)'
- en: 'Image: [The New Yorker / Widows](https://www.behance.net/gallery/73239099/The-New-Yorker-Widows)
    © [Matt Chinworth](https://www.behance.net/mattchinworth) | CC BY-NC-ND 4.0'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片：[The New Yorker / Widows](https://www.behance.net/gallery/73239099/The-New-Yorker-Widows)
    © [Matt Chinworth](https://www.behance.net/mattchinworth) | CC BY-NC-ND 4.0
- en: As part of the Google AI Sprint 2024, I built a multimodal chatbot with Gemini
    1.5 and here’s how it can revolutionize appliance support
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作为2024年Google AI Sprint的一部分，我构建了一个多模态聊天机器人，结合了Gemini 1.5，下面是它如何彻底改变家电支持的方式
- en: '[](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)[![Ashwin
    Raj](../Images/7bfb5e302bba2c12beafb6e09268832d.png)](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)
    [Ashwin Raj](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)[![Ashwin
    Raj](../Images/7bfb5e302bba2c12beafb6e09268832d.png)](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)
    [Ashwin Raj](https://thisisashwinraj.medium.com/?source=post_page---byline--04e229beee5c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)
    ·8 min read·Sep 29, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page---byline--04e229beee5c--------------------------------)
    ·8分钟阅读·2024年9月29日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Across industries, effective troubleshooting is crucial for maintaining smooth
    operations, ensuring customer satisfaction, and optimizing the efficiency of service
    processes. However, troubleshooting appliances on-site can be a challenging task.
    With various models and countless potential issues, service engineers often find
    themselves sifting through manuals or searching online for solutions, an approach
    that can be both frustrating and time-consuming.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在各行各业中，故障排除对于维持平稳运营、确保客户满意度以及优化服务流程效率至关重要。然而，现场故障排除家电设备可能是一项具有挑战性的任务。由于有各种型号和无数潜在问题，服务工程师常常不得不翻阅手册或在线搜索解决方案，这种方法既令人沮丧，又费时费力。
- en: This is where chatbots equipped with comprehensive servicing knowledge and access
    to the latest troubleshooting manuals can transform the experience. While one
    might assume that Retrieval-Augmented Generation (RAG) would be an ideal solution
    for such tasks, it often falls short in this scenario. This is because these handbooks
    often contain elements such as tables, images, and diagrams, which are difficult
    to extract and summarization may miss the knotty details typically found in them,
    making it unfit for production rollout.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是配备全面服务知识并能访问最新故障排除手册的聊天机器人能够改变体验的地方。虽然人们可能认为检索增强生成（RAG）是此类任务的理想解决方案，但在这种情况下，它往往力不从心。因为这些手册通常包含表格、图片和图表等元素，而这些元素难以提取，且总结可能会忽略其中的复杂细节，使得它不适合用于生产部署。
- en: In this article, we will work towards building a chatbot using Gemini to help
    onsite service engineers find the right information in a faster, more intuitive
    manner. We will also explore the advanced features offered by Gemini, such as
    context caching and File API integration for multimodal prompting. In the end,
    we will wrap this chatbot in a Streamlit interface, for easier interaction.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将着手构建一个使用Gemini的聊天机器人，帮助现场服务工程师更快速、更直观地找到所需信息。我们还将探讨Gemini提供的高级功能，如上下文缓存和文件API集成，以支持多模态提示。最后，我们将把这个聊天机器人封装在Streamlit界面中，以便于交互。
- en: Before you Begin
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你开始之前
- en: 'To build the chatbot, we’ll be using Gemini, Python 3, and Streamlit. Start
    by installing Streamlit on your local machine by running the below command:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建聊天机器人，我们将使用Gemini、Python 3和Streamlit。首先，通过运行以下命令在你的本地机器上安装Streamlit：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For the database, we’ll rely on SQLite which comes preinstalled with Python.
    We will also need a Gemini API key to run inferences using Gemini 1.5 Flash. If
    you don’t have an API key yet, you can create one for free from this [link](https://ai.google.dev/gemini-api/docs/api-key).
    Once you have set up your key, install the Google AI Python SDK by running:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据库，我们将依赖于Python预装的SQLite。我们还需要一个Gemini API密钥，以便使用Gemini 1.5 Flash进行推理。如果你还没有API密钥，你可以通过这个[链接](https://ai.google.dev/gemini-api/docs/api-key)免费创建一个。一旦你设置了密钥，运行以下命令安装Google
    AI Python SDK：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can find the source code & additional resources on my GitHub repo [here](https://github.com/thisisashwinraj/LogIQ-Service-Engineer-Assistant)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我的GitHub仓库[这里](https://github.com/thisisashwinraj/LogIQ-Service-Engineer-Assistant)找到源代码和其他资源。
- en: '***Acknowledgement:*** *Google Cloud credits are provided for this project,
    as part of #AISprint 2024*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***致谢：*** *本项目提供了Google Cloud的信用额度，作为#AISprint 2024的一部分*'
- en: Architecture
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: Before the implementation, let us examine the system architecture in detail.
    The process begins by fetching the required product manual from a database and
    passing it to Gemini. This acts as the knowledge base for our chatbot, providing
    essential troubleshooting information for the selected appliance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现之前，让我们详细检查系统架构。该过程从从数据库中提取所需的产品手册并传递给Gemini开始。这充当我们的聊天机器人的知识库，为所选电器提供必要的故障排除信息。
- en: '![](../Images/7565ffd5e34ede62623634e9e9b8703d.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7565ffd5e34ede62623634e9e9b8703d.png)'
- en: Image by Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: Once the documents are loaded, we leverage Gemini’s multimodal document processing
    capabilities to extract the required information from the product manual. Now,
    when a user interacts with the chatbot, the model combines the uploaded service
    manual data, chat history, and other contextual cues to deliver precise and insightful
    responses to the user’s queries.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文档加载完成，我们利用Gemini的多模态文档处理能力，从产品手册中提取所需的信息。现在，当用户与聊天机器人互动时，模型将结合上传的服务手册数据、聊天历史和其他上下文信息，提供准确而深刻的回答，解答用户的查询。
- en: To enhance performance, we’ll implement context caching, which optimizes response
    time for recurring queries. Finally, we’ll wrap this architecture in a simple
    yet intuitive Streamlit web application, allowing service engineers to seamlessly
    engage with the chat agent and access the information they need.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高性能，我们将实现上下文缓存，优化重复查询的响应时间。最后，我们将把这个架构封装在一个简单且直观的Streamlit Web应用程序中，允许服务工程师无缝地与聊天代理互动，并访问他们需要的信息。
- en: Loading Service Manuals into the Database
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将服务手册加载到数据库中
- en: 'To begin building the chatbot, the first step is to load the troubleshooting
    guides into our database for reference. Since these files are unstructured in
    nature, we can’t store them directly in our database. Instead, we store their
    filepaths:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建聊天机器人，第一步是将故障排除指南加载到我们的数据库中以供参考。由于这些文件本身没有结构，我们无法直接将它们存储在数据库中。相反，我们存储它们的文件路径：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this project, we’ll store the manuals in a local directory, and save their
    file paths in a SQLite database. For better scalability however, its recommended
    to use an object storage service, such as Google Cloud Storage to store these
    files & maintain URLs to the files in a database service like Google Cloud SQL
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们将在本地目录中存储手册，并将它们的文件路径保存在SQLite数据库中。然而，为了更好的可扩展性，建议使用对象存储服务，例如Google
    Cloud Storage来存储这些文件，并在像Google Cloud SQL这样的数据库服务中维护文件的URL。
- en: Building the Conversational Agent with Gemini
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Gemini构建对话代理
- en: Once the product manual is loaded into the database, the next step is to build
    the agent using 1.5 Flash. This lightweight model is part of the Gemini family
    and has been fine-tuned through a process known as “distillation,” where the most
    essential knowledge and skills from a larger model are transferred to a smaller,
    more efficient model to support various high-volume tasks at scale.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦产品手册加载到数据库中，下一步是使用1.5 Flash构建代理。这个轻量级模型是Gemini家族的一部分，并通过一种称为“蒸馏”的过程进行了微调，其中来自更大模型的最重要的知识和技能被转移到一个更小、更高效的模型中，以支持各种高容量任务的规模。
- en: '![](../Images/e0b374608d80284f7b5c0abd18a97431.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0b374608d80284f7b5c0abd18a97431.png)'
- en: Image from [The Keyword](https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/#gemini-model-updates)
    by Google
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[The Keyword](https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/#gemini-model-updates)的图片，来源于Google
- en: Optimized for speed and operational efficiency, the 1.5 Flash model is highly
    proficient in multimodal reasoning and features a context window of up to 1 million
    tokens, making it the ideal choice for our service engineer’s use case.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高速度和操作效率，1.5 Flash模型在多模态推理方面非常高效，具有最多可达100万个令牌的上下文窗口，成为我们服务工程师使用场景的理想选择。
- en: Multimodal Document Processing with 1.5 Flash
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用1.5 Flash进行多模态文档处理
- en: 'To run inference on our service manuals, we first need to upload the files
    to Gemini. The Gemini API supports uploading media files separately from the prompt
    input, enabling us to reuse files across multiple requests. The File API supports
    up to 20 GB of files per project, with a maximum of 2 GB per file:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要对我们的服务手册进行推理，首先需要将文件上传到Gemini。Gemini API支持将媒体文件与提示输入分开上传，使我们能够在多个请求中重复使用文件。File
    API每个项目支持最多20 GB的文件，每个文件最大支持2 GB：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To upload a file, we use the upload_file() method, which takes as parameter
    the path (path to the file to be uploaded), name (filename in the destination,
    defaulting to a system-generated ID), mime_type (specifying the MIME type of the
    document, which’ll be inferred if unspecified), and the display_name.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要上传文件，我们使用upload_file()方法，该方法的参数包括路径（要上传的文件路径）、名称（目标文件名，默认为系统生成的ID）、mime_type（指定文档的MIME类型，如果未指定，将进行推断）和display_name。
- en: Before proceeding, we need to verify that the API has successfully stored the
    uploaded file by checking its metadata. If the file’s state is PROCESSING, it
    cannot yet be used for inference. Once the state changes to ACTIVE, the file is
    ready for use. A FAILED state, indicates file processing was unsuccessful.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们需要通过检查文件的元数据来验证API是否成功存储了上传的文件。如果文件的状态是PROCESSING，则尚不能用于推理。一旦状态变为ACTIVE，文件即可使用。如果状态为FAILED，表示文件处理未成功。
- en: Conversational Response Generation
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对话式响应生成
- en: After uploading the service manual, the next step is to leverage Gemini 1.5’s
    multimodal document processing capabilities for response generation. The chat
    feature of the API allows us to collect multiple rounds of questions and responses,
    facilitating in-depth analysis of issues & step-by-step resolution.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上传服务手册后，下一步是利用Gemini 1.5的多模态文档处理能力来生成响应。API的聊天功能允许我们收集多轮问题和答案，便于深入分析问题并逐步解决。
- en: '![](../Images/1540dd9ce6db00580a566619f3debedd.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1540dd9ce6db00580a566619f3debedd.png)'
- en: Image by Author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: When initializing the model, it’s important to provide specific guidelines and
    context to shape the chatbot’s behavior throughout the interaction. This is done
    by supplying system instruction to the model. System instructions help maintain
    context, guide the style of interaction, ensure consistency, and set boundaries
    for the chatbot’s responses, while trying to prevent hallucination.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化模型时，提供具体的指导方针和上下文以塑造聊天机器人的行为至关重要。这是通过向模型提供系统指令来完成的。系统指令有助于维持上下文，指导互动风格，确保一致性，并为聊天机器人的响应设定边界，同时尽量避免幻觉现象。
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can further control the model’s response generation by tuning the model parameters
    through the GenerationConfig class. In our application, we’ve set the max_output_tokens
    to 1500, defining the maximum token limit for each response, and the temperature
    to 0.4, to maintain determinism in the response.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调整GenerationConfig类中的模型参数，进一步控制模型的响应生成。在我们的应用中，我们已将max_output_tokens设置为1500，定义了每个响应的最大令牌限制，并将temperature设置为0.4，以保持响应的确定性。
- en: Long context optimization with Context Caching
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用上下文缓存进行长上下文优化
- en: In many cases, especially with recurring queries against the same document,
    we end up sending the same input tokens repeatedly to the model. While this approach
    may work, it's not optimal for large-scale, production-level rollouts
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，尤其是对于同一文档的重复查询，我们最终会将相同的输入令牌反复发送给模型。尽管这种方法可能有效，但对于大规模的生产级应用来说，它并不是最优选择。
- en: This is where Gemini’s context caching feature becomes essential, offering a
    more efficient solution by reducing both costs and latency for high-token workloads.
    With context caching, instead of sending same input tokens with every request,
    we can refer to the cached tokens for the subsequent requests
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Gemini 的上下文缓存功能变得至关重要的地方，通过减少高 Token 工作负载的成本和延迟，提供更高效的解决方案。通过上下文缓存，我们可以在后续请求中引用缓存的
    Token，而不是每次请求都发送相同的输入 Token。
- en: '![](../Images/1b41ca56dd2eb7728e323325dc577207.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b41ca56dd2eb7728e323325dc577207.png)'
- en: Image by Author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: In this project, we cache both the system instruction and the service manual
    file. At scale, using cached tokens significantly reduces the cost compared to
    repeatedly passing the same data. By default the Time-to-Live (TTL) for these
    cached tokens is 1 hour, though it can be adjusted as required. Once the TTL expires,
    the cached tokens are automatically removed from Gemini’s context
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们缓存了系统指令和服务手册文件。在大规模使用时，使用缓存的 Token 相比重复传输相同的数据显著降低了成本。默认情况下，这些缓存 Token
    的生存时间（TTL）为 1 小时，但可以根据需要进行调整。一旦 TTL 到期，缓存的 Token 将自动从 Gemini 的上下文中移除。
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It’s important to note that context caching is only available for an input token
    count of 32,768 or more. If token count is below this threshold, you’ll need to
    rely on the standard multimodal prompting capabilities of Gemini 1.5 Flash.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，只有当输入 Token 数量达到 32,768 或更多时，上下文缓存才可用。如果 Token 数量低于此阈值，则需要依赖 Gemini 1.5
    Flash 的标准多模态提示功能。
- en: Integrating Chatbot with Streamlit
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成聊天机器人与 Streamlit
- en: With our chatbot’s response generation capabilities in place, the final step
    is to wrap it in a Streamlit app to create an intuitive user interface for the
    users.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的聊天机器人响应生成能力就位后，最后一步是将其包装成一个 Streamlit 应用，创建一个直观的用户界面供用户使用。
- en: '![](../Images/d5221aaf47c78a7a5d1a43c8f0552755.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5221aaf47c78a7a5d1a43c8f0552755.png)'
- en: Image by Author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The interface features a dropdown where the users can select the brand, and
    model of the appliance they are working with. After making the selection & clicking
    the “Configure chatbot” button, the app will post the corresponding service manual
    to Gemini and present the chat interface. From thereon, the engineer can enter
    their queries & the chatbot will provide relevant response
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 界面具有一个下拉菜单，用户可以选择他们正在使用的家电品牌和型号。选择后点击“配置聊天机器人”按钮，应用将把相应的服务手册传递给 Gemini，并展示聊天界面。从此，工程师可以输入他们的问题，聊天机器人将提供相关的回复。
- en: Future Scope
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来展望
- en: Looking ahead, there are several promising directions to explore. The future
    iterations of the chatbot could integrate voice support, allowing engineers to
    communicate more naturally with the chatbot to get their queries addressed.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，有几个有前景的方向值得探索。聊天机器人的未来版本可以集成语音支持，允许工程师与聊天机器人进行更自然的交流，从而解决他们的问题。
- en: Additionally, expanding the system to incorporate predictive diagnostics can
    enable engineers to preemptively identify potential issues before they lead to
    equipment failures. By continuing to evolve this tool, the goal is to create a
    comprehensive support system for service engineers, ultimately improving the customer
    experience, thus transforming the troubleshooting eco-system
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，扩展系统以纳入预测性诊断功能，可以使工程师预先识别潜在问题，避免其导致设备故障。通过不断发展这个工具，目标是为服务工程师创建一个全面的支持系统，最终提升客户体验，从而改变故障排除的生态系统。
- en: With that, we have reached the end of this article. If you have any questions
    or believe I have made any mistake, please feel free to reach out to me! You can
    get in touch with me via [Email](mailto:rajashwin733@gmail.com) or [LinkedIn](https://www.linkedin.com/in/thisisashwinraj/).
    Until then, happy learning!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经结束了本文。如果您有任何问题或认为我有任何错误，请随时与我联系！您可以通过[电子邮件](mailto:rajashwin733@gmail.com)或[LinkedIn](https://www.linkedin.com/in/thisisashwinraj/)与我取得联系。直到那时，祝您学习愉快！
