- en: 'Einstein Notation: A New Lens on Transformers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爱因斯坦符号：Transformer 新视角
- en: 原文：[https://towardsdatascience.com/einstein-notation-a-new-lens-on-transformers-761390a7960b?source=collection_archive---------1-----------------------#2024-11-20](https://towardsdatascience.com/einstein-notation-a-new-lens-on-transformers-761390a7960b?source=collection_archive---------1-----------------------#2024-11-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/einstein-notation-a-new-lens-on-transformers-761390a7960b?source=collection_archive---------1-----------------------#2024-11-20](https://towardsdatascience.com/einstein-notation-a-new-lens-on-transformers-761390a7960b?source=collection_archive---------1-----------------------#2024-11-20)
- en: Transforming the Math of the Transformer Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换 Transformer 模型的数学
- en: '[](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)[![Dr.
    Christoph Mittendorf](../Images/466a7a53b8261f4df61461090dcfc743.png)](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)
    [Dr. Christoph Mittendorf](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)[![Dr.
    Christoph Mittendorf](../Images/466a7a53b8261f4df61461090dcfc743.png)](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)
    [Dr. Christoph Mittendorf](https://medium.com/@ch.mittendorf?source=post_page---byline--761390a7960b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)
    ·8 min read·Nov 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--761390a7960b--------------------------------)
    ·8 分钟阅读·2024年11月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/27d78cf2967592bbfc4e2308237ab91d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27d78cf2967592bbfc4e2308237ab91d.png)'
- en: Transformer (Created by author using FLUX1-schnell)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer（由作者使用 FLUX1-schnell 创建）
- en: In this article, we’ll embark on a playful journey through the world of transformers,
    unraveling the complexities of their architecture using the Einstein notation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将通过一段有趣的旅程，探索 Transformer 世界，利用爱因斯坦符号解开其架构的复杂性。
- en: '**Introduction**:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**引言**：'
- en: Transformer models have revolutionized the field of natural language processing
    (and beyond), achieving state-of-the-art results on a variety of tasks. They have
    impressive performance but the underlying mathematical operations can be complex
    and difficult to grasp — especially without breaking down the individual layers.
    In this article, I propose using the Einstein notation to express the mathematical
    operations within a transformer model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 模型在自然语言处理（及其他领域）中引发了革命，在各种任务上都取得了最先进的成果。它们表现出色，但其底层数学运算可能复杂且难以理解，尤其是如果没有分解每一层的操作。在本文中，我提议使用爱因斯坦符号来表达
    Transformer 模型中的数学运算。
- en: Note that the Einstein notation is normally used in Physics and Mathematics
    such as in General Relativity, Electromagnetism, Quantum and Fluid Mechanics but
    also in Linear Algebra to represent matrix operations in a more compact form.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，爱因斯坦符号通常用于物理学和数学领域，如广义相对论、电磁学、量子力学和流体力学，也用于线性代数中，以更紧凑的形式表示矩阵运算。
- en: The goal is to write the mathematical operations of every layer in a concise
    and elegant way. By leveraging implicit summation over repeated indices, Einstein
    notation can simplify the representation of tensor operations, making it (potentially)
    easier to understand and therefore implement the individual layers of the transformer
    models…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是以简洁优雅的方式编写每一层的数学运算。通过利用对重复指标的隐式求和，爱因斯坦符号可以简化张量运算的表示，使其（可能）更容易理解，从而更容易实现 Transformer
    模型的各个层次…
