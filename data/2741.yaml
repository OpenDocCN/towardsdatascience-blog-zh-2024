- en: 'Bessel’s Correction: Why Do We Divide by n−1 Instead of n in Sample Variance?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝塞尔修正：为什么在样本方差中我们除以 n−1 而不是 n？
- en: 原文：[https://towardsdatascience.com/bessels-correction-why-do-we-divide-by-n-1-instead-of-n-in-sample-variance-30b074503bd9?source=collection_archive---------1-----------------------#2024-11-11](https://towardsdatascience.com/bessels-correction-why-do-we-divide-by-n-1-instead-of-n-in-sample-variance-30b074503bd9?source=collection_archive---------1-----------------------#2024-11-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/bessels-correction-why-do-we-divide-by-n-1-instead-of-n-in-sample-variance-30b074503bd9?source=collection_archive---------1-----------------------#2024-11-11](https://towardsdatascience.com/bessels-correction-why-do-we-divide-by-n-1-instead-of-n-in-sample-variance-30b074503bd9?source=collection_archive---------1-----------------------#2024-11-11)
- en: Understanding the Unbiased Estimation of Population Variance
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解总体方差的无偏估计
- en: '[](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)[![Aman
    Agrawal](../Images/635e092ab62ac181bc70b0548641e945.png)](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)
    [Aman Agrawal](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)[![Aman
    Agrawal](../Images/635e092ab62ac181bc70b0548641e945.png)](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)
    [Aman Agrawal](https://medium.com/@amannagrawall002?source=post_page---byline--30b074503bd9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)
    ·8 min read·Nov 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--30b074503bd9--------------------------------)
    ·阅读时间 8 分钟 ·2024年11月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In statistics, a common point of confusion for many learners is why we divide
    by n−1 when calculating sample variance, rather than simply using n, the number
    of observations in the sample. This choice may seem small but is a critical adjustment
    that corrects for a natural bias that occurs when we estimate the variance of
    a population from a sample. Let’s walk through the reasoning in simple language,
    with examples to understand why dividing by n−1, known as Bessel’s correction,
    is necessary.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，许多学习者常常困惑的一个问题是，为什么在计算样本方差时要除以 n−1，而不是直接使用样本中的观察数 n。这个选择看起来很小，但它是一个重要的调整，用来修正从样本估计总体方差时出现的自然偏差。我们用简单的语言通过一些例子来讲解，为什么除以
    n−1（称为贝塞尔修正）是必要的。
- en: The core concept of correction (in Bessel’s correction), is that we tend to
    correct our estimation, but a clear question is estimation of what? So by applying
    Bessel’s correction we tend to correct the estimation of deviations calculated
    from our assumed sample mean, our assumed sample mean will rarely ever co-inside
    with the actual population mean, so it’s safe to assume that in 99.99% (even more
    than that in real) cases our sample mean would not be equal to the population
    mean. We do all the calculations based on this assumed sample mean, that is we
    estimate the population parameters through the mean of this sample.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 贝塞尔修正的核心概念是我们倾向于修正我们的估计，但一个明确的问题是，我们估计的是什么？因此，通过应用贝塞尔修正，我们倾向于修正从假设的样本均值计算出的偏差估计值，而我们的假设样本均值很少与实际的总体均值完全一致，因此可以安全假设，在99.99%的情况下（在实际中甚至更多），我们的样本均值不会等于总体均值。我们所有的计算都是基于这个假设的样本均值进行的，即我们通过该样本的均值来估计总体参数。
- en: Reading further down the blog, one would get a clear intuition that why in all
    of those 99.99% cases (in all the cases except leaving the one, in which sample
    mean = population mean), we tend to underestimate the deviations from actual deviations,
    so to compensate this underestimation error, diving by a smaller number than ’n’
    do the job, so diving by n-1 instead of n, accounts for the compensation of the
    underestimation that is done in calculating the deviations from the sample mean.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 继续阅读博客下文，你会直观地明白为什么在所有99.99%的情况下（除了那个样本均值=总体均值的情况），我们倾向于低估实际偏差，因此为了弥补这个低估误差，除以比’n’更小的数就能解决问题，因此除以n-1而不是n，正是为了弥补在计算样本均值偏差时的低估。
- en: '*Start reading down from here and you’ll eventually understand…*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*从这里开始阅读，你最终会理解……*'
- en: Sample Variance vs. Population Variance
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 样本方差与总体方差
- en: When we have an entire population of data points, the variance is calculated
    by finding the mean (average), then determining how each point deviates from this
    mean, squaring these deviations, summing them up, and finally dividing by n, the
    total number of points in the population. This gives us the **population variance**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有整个数据总体时，方差是通过首先计算均值（平均值），然后确定每个数据点偏离该均值的程度，平方这些偏差，求和，最后除以n（总体中的数据点总数）来计算的。这给我们的是**总体方差**。
- en: 'However, if we don’t have data for an entire population and are instead working
    with just a sample, we estimate the population variance. But here lies the problem:
    when using only a sample, we don’t know the true population mean (denoted as μ),
    so we use the **sample mean** (x_bar) instead.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们没有整个总体的数据，而是仅仅使用一个样本，我们需要估算总体方差。但问题在于：当只使用样本时，我们不知道真实的总体均值（记作μ），所以我们使用**样本均值**（x_bar）代替。
- en: The Problem of Underestimation
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 低估问题
- en: 'To understand why we divide by n−1 in the case of samples, we need to look
    closely at what happens when we use the sample mean rather than the population
    mean. For real-life applications, relying on sample statistics is the only option
    we have. Here’s how it works:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么在样本情况下我们除以n−1，我们需要仔细观察使用样本均值而非总体均值时会发生什么。对于实际应用来说，依赖样本统计是我们唯一的选择。下面是其工作原理：
- en: When we calculate variance in a sample, we find each data point’s deviation
    from the sample mean, square those deviations, and then take the average of these
    squared deviations. However, the sample mean is usually not exactly equal to the
    population mean. Due to this difference, using the sample mean tends to **underestimate**
    the true spread or variance in the population.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们计算样本方差时，我们会找到每个数据点与样本均值的偏差，平方这些偏差，然后取这些平方偏差的平均值。然而，样本均值通常不等于总体均值。由于这种差异，使用样本均值倾向于**低估**总体的实际分布或方差。
- en: Let’s break it down with all possible cases that can happen (three different
    cases), I’ll give a detailed walkthrough on the first case, same principle applies
    to the other two cases as well, detailed walkthrough has been given for case 1.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过所有可能发生的情况（共三种不同情况）来分析，我会详细讲解第一种情况，其他两种情况遵循相同的原理，详细解析已给出第一种情况。
- en: 1\. When the Sample Mean is Less Than the Population Mean (x_bar < population
    mean)
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 当样本均值小于总体均值（x_bar < 总体均值）
- en: If our sample mean (x_bar) is less than the population mean (μ), then many of
    the points in the sample will be closer to (x_bar) than they would be to μ. As
    a result, the distances (deviations) from the mean are smaller on average, leading
    to a smaller variance calculation. This means we’re underestimating the actual
    variance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的样本均值（x_bar）小于总体均值（μ），那么样本中的许多数据点将比它们距离μ更接近x_bar。因此，距离（偏差）均值的距离平均来说会更小，从而导致更小的方差计算。这意味着我们低估了实际的方差。
- en: Explanation of the graph given below — The smaller normal distribution is of
    our sample and the bigger normal distribution is of our population (in the above
    case where x_bar < population mean), the plot would look like the one shown below.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图的解释——较小的正态分布是我们的样本，而较大的正态分布是我们的总体（在上面的情况中，x_bar < 总体均值），图形如下所示。
- en: As we have data points of our sample, because that’s what we can collect, can’t
    collect all the data points of the population because that’s simply not possible.
    For all the data points in our sample in this case, from negative infinity, to
    the mid point of x_bar and population mean, the absolute or squared difference
    (deviations) between the sample points and population mean would be greater than
    the absolute or squared difference (deviations) between sample points and sample
    mean and on the right side of the midpoint till positive infinity, the deviations
    calculated with respect to sample mean would be greater than the deviations calculated
    using population mean. The region is indicated in the graph below for the above
    case, due to the symmetric nature of the normal curve we can surely say that the
    underestimation zone would be larger than the overestimation zone which is also
    highlighted in the graph below, which results in an overall underestimation of
    the deviations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只能收集样本中的数据点，无法收集总体的所有数据点，因为那是不可能的。在我们的样本数据点中，从负无穷大到 x_bar 和总体均值的中点，样本点与总体均值之间的绝对差异或平方差（偏差）会大于样本点与样本均值之间的绝对差异或平方差，在中点右侧直到正无穷大，基于样本均值计算的偏差会大于基于总体均值计算的偏差。下图显示了上述情况的区域，由于正态曲线的对称性，我们可以肯定地说，低估区间会大于高估区间，这也在下图中得到了突出显示，这导致偏差的总体低估。
- en: So to compensate the underestimation, we divide the deviations by a number smaller
    than sample size ’n’, which is ‘n-1’ which is known as Bessel’s correction.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了弥补低估，我们将偏差除以一个小于样本大小 ’n’ 的数字，即 ‘n-1’，这被称为贝塞尔修正。
- en: '![](../Images/af601db7d0cccb4f9dc2785abb6fed78.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af601db7d0cccb4f9dc2785abb6fed78.png)'
- en: Plot produced by python code using matplotlib library, Image Source (Author)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Python 代码使用 matplotlib 库生成的图，图片来源（作者）
- en: 2\. When the Sample Mean is Greater Than the Population Mean
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 当样本均值大于总体均值时
- en: 'If the sample mean is greater than the population mean, we have the reverse
    situation: data points on the low end of the sample will be closer to x_bar than
    to μ, still resulting in an underestimation of variance.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果样本均值大于总体均值，我们会遇到相反的情况：样本中较低端的数据点会比 μ 更接近 x_bar，仍然导致方差的低估。
- en: Based on the details laid above, it’s clear that in this case also underestimation
    zone is larger than the overestimation zone, so in this case also we will account
    for this underestimation by dividing the deviations by ‘n-1’ instead of n.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 基于以上的细节，很明显在这种情况下，低估区间也大于高估区间，因此我们在这种情况下也会通过将偏差除以 ‘n-1’ 而不是 n 来弥补这种低估。
- en: '![](../Images/c7a44ed394443cbfc327d90472ac7683.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7a44ed394443cbfc327d90472ac7683.png)'
- en: Plot produced by python code using matplotlib library, Image Source (Author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Python 代码使用 matplotlib 库生成的图，图片来源（作者）
- en: 3\. When the Sample Mean is Exactly Equal to the Population Mean (0.000001%)
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 当样本均值与总体均值完全相等时（0.000001%）
- en: This case is rare, and only if the sample mean is perfectly aligned with the
    population mean would our estimate be unbiased. However, this alignment almost
    never happens by chance, so we generally assume that we’re underestimating.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况比较少见，只有当样本均值与总体均值完全对齐时，我们的估计才是无偏的。然而，这种对齐几乎从未偶然发生，因此我们通常假设我们在低估。
- en: Clearly, deviations calculated for the sample points with respect to sample
    mean are exactly the same as the deviations calculated with respect to the population
    mean, because the sample mean and population mean both are equal. This would yield
    no underestimation or overestimation zone.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，计算的样本点相对于样本均值的偏差与计算的相对于总体均值的偏差完全相同，因为样本均值和总体均值是相等的。这将不会产生低估或高估区间。
- en: '![](../Images/2e601657a56e521423d65f889c102c78.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e601657a56e521423d65f889c102c78.png)'
- en: Plot produced by python code using matplotlib library, Image Source (Author)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Python 代码使用 matplotlib 库生成的图，图片来源（作者）
- en: In short, any difference between x_bar and μ (which almost always occurs) leads
    us to underestimate the variance. This is why we need to make a correction by
    dividing by n−1, which accounts for this bias.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，任何样本均值 x_bar 和总体均值 μ 之间的差异（几乎总是发生的）都会导致我们低估方差。这就是为什么我们需要通过除以 n−1 来进行修正，以弥补这种偏差。
- en: 'Why Dividing by n−1 Corrects This Bias: Bessel’s Correction'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么除以 n−1 可以纠正这种偏差：贝塞尔修正
- en: Dividing by n−1 is called **Bessel’s correction** and compensates for the natural
    underestimation bias in sample variance. When we divide by n−1, we’re effectively
    making a small adjustment that spreads out our variance estimate, making it a
    better reflection of the true population variance.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 除以n−1称为**贝塞尔修正**，它补偿了样本方差中自然的低估偏差。当我们除以n−1时，实际上是在做一个小的调整，使我们的方差估计更接近真实的总体方差。
- en: One can relate all this to degrees of freedom too , some knowledge of dofs are
    required to understand from the viewpoint of degrees of freedom-
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切也可以与自由度相关联，从自由度的角度理解这些知识是需要一定自由度知识的。
- en: In a sample, one degree of freedom is “used up” by calculating the sample mean.
    This leaves us with n−1 independent data points that contribute information about
    the variance, which is why we divide by n−1 rather than n.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本中，一个自由度被“消耗”用于计算样本均值。这使得我们只剩下n−1个独立的数据点来提供关于方差的信息，这也是为什么我们要用n−1而不是n来除。
- en: Why Does This Adjustment Matter More with Small Samples?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这种调整在小样本中更为重要？
- en: 'If our sample size is very small, the difference between dividing by n and
    n−1 becomes more significant. For instance, if you have a sample size of 10:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的样本量非常小，除以n与除以n−1之间的差异会变得更加显著。例如，如果你的样本量是10：
- en: Dividing by n would mean dividing by 10, which may greatly underestimate the
    variance.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果除以n，意味着除以10，这样可能会大大低估方差。
- en: Dividing by n−1 or 9, provides a better estimate, compensating for the small
    sample.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除以n−1或9，能够提供更好的估计，弥补小样本带来的偏差。
- en: But if your sample size is large (say, 10,000), the difference between dividing
    by 10,000 or 9,999 is tiny, so the impact of Bessel’s correction is minimal.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果你的样本量很大（比如10,000），除以10,000或9,999的差异微乎其微，因此贝塞尔修正的影响也就非常小。
- en: Consequences of Not Using Bessel’s Correction
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不使用贝塞尔修正的后果
- en: If we don’t use Bessel’s correction, our sample variance will generally underestimate
    the population variance. This can have cascading effects, especially in statistical
    modelling and hypothesis testing, where accurate variance estimates are crucial
    for drawing reliable conclusions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不使用贝塞尔修正，我们的样本方差通常会低估总体方差。这可能会产生连锁反应，尤其是在统计建模和假设检验中，准确的方差估计对于得出可靠结论至关重要。
- en: 'For instance:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '**Confidence intervals**: Variance estimates influence the width of confidence
    intervals around a sample mean. Underestimating variance could lead to narrower
    intervals, giving a false impression of precision.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信区间**：方差估计会影响围绕样本均值的置信区间宽度。低估方差可能导致置信区间过窄，从而给人一种过于精确的错误印象。'
- en: '**Hypothesis tests**: Many statistical tests, such as the t-test, rely on accurate
    variance estimates to determine if observed effects are significant. Underestimating
    variance could make it harder to detect true differences.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假设检验**：许多统计检验，如t检验，依赖于准确的方差估计来确定观察到的效应是否显著。低估方差可能会让我们更难发现真正的差异。'
- en: Why Not Divide by n−2 or n−3?
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么不除以n−2或n−3？
- en: The choice to divide by n−1 isn’t arbitrary. While we won’t go into the detailed
    proof here, it’s grounded in mathematical theory. Dividing by n−1 provides an
    unbiased estimate of the population variance when calculated from a sample. Other
    adjustments, such as n−2, would overcorrect and lead to an overestimation of variance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 选择除以n−1并非随意。虽然我们这里不会深入证明，但这一选择是基于数学理论的。从样本计算总体方差时，除以n−1能够提供无偏的估计。其他调整，比如n−2，会过度修正并导致方差的高估。
- en: A Practical Example to Illustrate Bessel’s Correction
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个实际的例子来说明贝塞尔修正
- en: Imagine you have a small population with a mean weight of 70 kg. Now let’s say
    you take a sample of 5 people from this population, and their weights (in kg)
    are 68, 69, 70, 71, and 72\. The sample mean is exactly 70 kg — identical to the
    population mean by coincidence.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个小的群体，平均体重为70公斤。现在假设你从这个群体中抽取了5个人作为样本，他们的体重（单位：公斤）分别是68、69、70、71和72。样本均值恰好是70公斤——与总体均值完全一致，这是巧合。
- en: 'Now suppose we calculate the variance:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们计算方差：
- en: 'Without Bessel’s correction: we’d divide the sum of squared deviations by n=5.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果不使用贝塞尔修正：我们将把平方偏差的总和除以n=5。
- en: 'With Bessel’s correction: we divide by n−1=4.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用贝塞尔修正时：我们除以n−1=4。
- en: Using Bessel’s correction in this way slightly increases our estimate of the
    variance, making it closer to what the population variance would be if we calculated
    it from the whole population instead of just a sample.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式使用贝塞尔修正会稍微增加我们对方差的估计，使其更接近如果我们从整个总体计算方差时的值，而不是仅仅从样本中计算。
- en: Conclusion
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Dividing by n−1 when calculating sample variance may seem like a small change,
    but it’s essential to achieve an unbiased estimate of the population variance.
    This adjustment, known as Bessel’s correction, accounts for the underestimation
    that occurs due to relying on the sample mean instead of the true population mean.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算样本方差时使用n−1进行除法，可能看起来只是一个小变化，但它对于获得无偏的总体方差估计至关重要。这个调整，即贝塞尔修正，弥补了由于依赖样本均值而不是总体均值导致的低估问题。
- en: 'In summary:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：
- en: Using n−1 compensates for the fact that we’re basing variance on a sample mean,
    which tends to underestimate true variability.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用n−1补偿了我们基于样本均值计算方差的事实，而样本均值往往低估了真实的变异性。
- en: The correction is especially important with small sample sizes, where dividing
    by n would significantly distort the variance estimate.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当样本量较小时，贝塞尔修正尤为重要，因为直接用n除法会显著扭曲方差估计。
- en: This practice is fundamental in statistics, affecting everything from confidence
    intervals to hypothesis tests, and is a cornerstone of reliable data analysis.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这一做法是统计学中的基础，影响从置信区间到假设检验的各个方面，是可靠数据分析的基石。
- en: By understanding and applying Bessel’s correction, we ensure that our statistical
    analyses reflect the true nature of the data we study, leading to more accurate
    and trustworthy conclusions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过理解和应用贝塞尔修正，我们确保我们的统计分析能够反映我们研究数据的真实特征，从而得出更准确、更可信的结论。
