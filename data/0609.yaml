- en: How to Generate Instruction Datasets from Any Documents for LLM Fine-Tuning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何从任何文档中生成LLM微调的指令数据集
- en: 原文：[https://towardsdatascience.com/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91?source=collection_archive---------0-----------------------#2024-03-06](https://towardsdatascience.com/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91?source=collection_archive---------0-----------------------#2024-03-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91?source=collection_archive---------0-----------------------#2024-03-06](https://towardsdatascience.com/how-to-generate-instruction-datasets-from-any-documents-for-llm-fine-tuning-abb319a05d91?source=collection_archive---------0-----------------------#2024-03-06)
- en: Generate high-quality synthetic datasets economically using lightweight libraries
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用轻量级库经济高效地生成高质量的合成数据集
- en: '[](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)[![Yanli
    Liu](../Images/31342655ab635eb38e3ce501235f1b89.png)](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)
    [Yanli Liu](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)[![Yanli
    Liu](../Images/31342655ab635eb38e3ce501235f1b89.png)](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)
    [Yanli Liu](https://medium.com/@yanli.liu?source=post_page---byline--abb319a05d91--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)
    ·7 min read·Mar 6, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--abb319a05d91--------------------------------)
    ·阅读时间7分钟·2024年3月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Large Language Models (LLMs) are capable and general-purpose tools, but often
    they lack domain-specific knowledge, which is frequently stored in enterprise
    repositories.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大语言模型（LLM）是功能强大且通用的工具，但它们通常缺乏特定领域的知识，而这些知识常常储存在企业的仓库中。
- en: Fine-tuning a custom LLM with your own data can bridge this gap, and data preparation
    is the first step in this process. It is also a crucial step that can significantly
    influence your fine-tuned model’s performance.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自己的数据进行定制化LLM（大语言模型）微调可以弥补这一差距，而数据准备是这一过程的第一步。这也是一个至关重要的步骤，能够显著影响微调模型的表现。
- en: However, manually creating datasets can be an expensive and time-consuming.
    Another approach is leveraging an LLM to generate synthetic datasets, often using
    high-performance models such as GPT-4, which can turn out to be very costly.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，手动创建数据集可能是昂贵且耗时的。另一种方法是利用LLM生成合成数据集，通常使用高性能模型如GPT-4，但这可能会非常昂贵。
- en: In this article, I aim to bring to your attention to a cost-efficient alternative
    for automating the creation of instruction datasets from various documents. This
    solution involves utilizing a lightweight open-source library called Bonito.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我旨在向您介绍一种成本效益高的替代方案，用于自动化从各种文档中创建指令数据集。这个解决方案涉及使用一个名为 Bonito 的轻量级开源库。
- en: '![](../Images/3a550f1c96686c676fda82d9b9c908ab.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a550f1c96686c676fda82d9b9c908ab.png)'
- en: Image generated by author using Bing chat powered by DALL.E 3
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者使用Bing聊天生成，Bing聊天由DALL.E 3驱动
- en: Getting Started with Bonito, the Open-Source Solution
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 Bonito，开源解决方案
- en: Understanding Instructions
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解指令
