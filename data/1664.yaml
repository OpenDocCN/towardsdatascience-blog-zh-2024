- en: Neural Network (MLP) for Time Series Forecasting in Practice
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œï¼ˆMLPï¼‰åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„å®è·µåº”ç”¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08](https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08](https://towardsdatascience.com/neural-network-mlp-for-time-series-forecasting-in-practice-04c47c1e3711?source=collection_archive---------0-----------------------#2024-07-08)
- en: A Practical Example for Feature Engineering and Constructing an MLP Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‰¹å¾å·¥ç¨‹å’Œæ„å»º MLP æ¨¡å‹çš„å®ç”¨ç¤ºä¾‹
- en: '[](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Daniel
    J. TOTH](../Images/a7fd7d723abdba92c493c3dd9aeb2273.png)](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    [Daniel J. TOTH](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Daniel
    J. TOTH](../Images/a7fd7d723abdba92c493c3dd9aeb2273.png)](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    [Daniel J. TOTH](https://tothjd.medium.com/?source=post_page---byline--04c47c1e3711--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    Â·16 min readÂ·Jul 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--04c47c1e3711--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 16 åˆ†é’ŸÂ·2024 å¹´ 7 æœˆ 8 æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**Introduction**'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ä»‹ç»**'
- en: Time series and more specifically time series forecasting is a very well known
    data science problem among professionals and business users alike.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—ï¼Œå°¤å…¶æ˜¯æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œæ˜¯æ•°æ®ç§‘å­¦é¢†åŸŸä¸€ä¸ªéå¸¸è‘—åçš„é—®é¢˜ï¼Œå—ä¸“ä¸šäººå£«å’Œå•†ä¸šç”¨æˆ·çš„å¹¿æ³›å…³æ³¨ã€‚
- en: Several forecasting methods exist, which may be grouped as statistical or machine
    learning methods for comprehension and a better overview, but as a matter of fact,
    the demand for forecasting is so high that the available options are abundant.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨å¤šç§é¢„æµ‹æ–¹æ³•ï¼Œå¯ä»¥å°†å®ƒä»¬å½’ç±»ä¸ºç»Ÿè®¡æ–¹æ³•æˆ–æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œä¾¿äºç†è§£å’Œæ¦‚è§ˆï¼Œä½†å®é™…ä¸Šï¼Œé¢„æµ‹éœ€æ±‚å¦‚æ­¤ä¹‹é«˜ï¼Œç°æœ‰çš„é€‰é¡¹ç§ç±»ç¹å¤šã€‚
- en: Machine learning methods are considered state-of-the-art approach in time series
    forecasting and are increasing in popularity, due to the fact that they are able
    to capture complex non-linear relationships within the data and generally yield
    higher accuracy in forecasting [1]. One popular machine learning field is the
    landscape of neural networks. Specifically for time series analysis, recurrent
    neural networks have been developed and applied to solve forecasting problems
    [2].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ æ–¹æ³•è¢«è®¤ä¸ºæ˜¯æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶ä¸”å› èƒ½å¤Ÿæ•æ‰æ•°æ®ä¸­çš„å¤æ‚éçº¿æ€§å…³ç³»è€Œè¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œé€šå¸¸èƒ½æä¾›æ›´é«˜çš„é¢„æµ‹å‡†ç¡®æ€§[1]ã€‚å…¶ä¸­ï¼Œç¥ç»ç½‘ç»œé¢†åŸŸæ˜¯ä¸€ä¸ªå¹¿å—å…³æ³¨çš„æœºå™¨å­¦ä¹ åˆ†æ”¯ã€‚ç‰¹åˆ«æ˜¯åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œå·²ç»è¢«å¼€å‘å¹¶åº”ç”¨äºè§£å†³é¢„æµ‹é—®é¢˜[2]ã€‚
- en: Data science enthusiasts might find the complexity behind such models intimidating
    and being one of you I can tell that I share that feeling. However, this article
    aims to show that
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç§‘å­¦çˆ±å¥½è€…å¯èƒ½ä¼šè§‰å¾—è¿™äº›æ¨¡å‹èƒŒåçš„å¤æ‚æ€§ä»¤äººæœ›è€Œç”Ÿç•ï¼Œä½œä¸ºå…¶ä¸­çš„ä¸€å‘˜ï¼Œæˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œæˆ‘ä¹Ÿæœ‰åŒæ ·çš„æ„Ÿè§‰ã€‚ç„¶è€Œï¼Œæœ¬æ–‡æ—¨åœ¨å±•ç¤º
- en: despite the latest developments in machine learning methods, it is not necessarily
    worth pursuing the most complex application when looking for a solution for a
    particular problem. Well-established methods enhanced with powerful feature engineering
    techniques could still provide satisfactory results.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å°½ç®¡æœºå™¨å­¦ä¹ æ–¹æ³•çš„æœ€æ–°è¿›å±•éå¸¸æ˜¾è‘—ï¼Œä½†åœ¨å¯»æ±‚ç‰¹å®šé—®é¢˜çš„è§£å†³æ–¹æ¡ˆæ—¶ï¼Œå¹¶ä¸ä¸€å®šéœ€è¦è¿½æ±‚æœ€å¤æ‚çš„åº”ç”¨ã€‚ç»è¿‡å¼ºåŒ–çš„æˆç†Ÿæ–¹æ³•ä¸å¼ºå¤§çš„ç‰¹å¾å·¥ç¨‹æŠ€æœ¯ç»“åˆï¼Œä¾ç„¶èƒ½å¤Ÿæä¾›ä»¤äººæ»¡æ„çš„ç»“æœã€‚
- en: More specifically, I apply a Multi-Layer Perceptron model and share the code
    and results, so you can get a hands-on experience on engineering time series features
    and forecasting effectively.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘åº”ç”¨äº†å¤šå±‚æ„ŸçŸ¥å™¨æ¨¡å‹ï¼Œå¹¶åˆ†äº«äº†ä»£ç å’Œç»“æœï¼Œè®©ä½ èƒ½å¤Ÿäº²è‡ªä½“éªŒå¦‚ä½•æœ‰æ•ˆåœ°è¿›è¡Œæ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹å’Œé¢„æµ‹ã€‚
- en: '**Goal of the Article**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æœ¬æ–‡ç›®æ ‡**'
- en: 'More precisely what I aim at to provide for fellow self-taught professionals,
    could be summarized in the following points:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å‡†ç¡®åœ°è¯´ï¼Œæˆ‘æƒ³ä¸ºè‡ªå­¦çš„ä¸“ä¸šäººå£«æä¾›çš„å†…å®¹å¯ä»¥æ€»ç»“ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š
- en: forecasting based on real-world problem / data
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºäºå®é™…é—®é¢˜/æ•°æ®è¿›è¡Œé¢„æµ‹
- en: how to engineer time series features for capturing temporal patterns
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä¸ºæ•æ‰æ—¶é—´æ¨¡å¼å·¥ç¨‹åŒ–æ—¶é—´åºåˆ—ç‰¹å¾
- en: 'build an MLP model capable of utilizing mixed variables: floats and integers
    (treated as categoricals via embedding)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ„å»ºä¸€ä¸ªèƒ½å¤Ÿåˆ©ç”¨æ··åˆå˜é‡ï¼ˆæµ®åŠ¨å’Œæ•´æ•°ï¼Œé€šè¿‡åµŒå…¥å¤„ç†ä¸ºç±»åˆ«å˜é‡ï¼‰çš„MLPæ¨¡å‹
- en: use MLP for point forecasting
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨MLPè¿›è¡Œç‚¹é¢„æµ‹
- en: use MLP for multi-step forecasting
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨MLPè¿›è¡Œå¤šæ­¥é¢„æµ‹
- en: assess feature importance using permutation feature importance method
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç½®æ¢ç‰¹å¾é‡è¦æ€§æ–¹æ³•è¯„ä¼°ç‰¹å¾é‡è¦æ€§
- en: retrain model for a subset of grouped features (multiple groups, trained for
    individual groups) to refine the feature importance of grouped features
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é’ˆå¯¹ä¸€ç»„åˆ†ç»„ç‰¹å¾ï¼ˆå¤šä¸ªç»„ï¼Œåˆ†åˆ«é’ˆå¯¹æ¯ä¸ªç»„è¿›è¡Œè®­ç»ƒï¼‰é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä»¥ç»†åŒ–åˆ†ç»„ç‰¹å¾çš„é‡è¦æ€§
- en: evaluate the model by comparing to an `UnobservedComponents` model
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸`UnobservedComponents`æ¨¡å‹è¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼°æ¨¡å‹
- en: '**Key Technical Terms**'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å…³é”®æŠ€æœ¯æœ¯è¯­**'
- en: 'Please note, that this article assumes the prior knowledge of some key technical
    terms and do not intend to explain them in details. Find those key terms below,
    with references provided, which could be checked for clarity:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæœ¬æ–‡å‡å®šè¯»è€…å·²ç»å…·å¤‡ä¸€äº›å…³é”®æŠ€æœ¯æœ¯è¯­çš„åŸºç¡€çŸ¥è¯†ï¼Œå¹¶ä¸æ‰“ç®—è¯¦ç»†è§£é‡Šè¿™äº›æœ¯è¯­ã€‚ä»¥ä¸‹åˆ—å‡ºäº†è¿™äº›å…³é”®æœ¯è¯­ï¼Œå¹¶æä¾›äº†å‚è€ƒï¼Œè¯»è€…å¯æŸ¥é˜…ä»¥ä¾¿ç†è§£ï¼š
- en: '**Time Series** [3]'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ—¶é—´åºåˆ—** [3]'
- en: '**Prediction** [4] â€” in this context it will be used to distinguish model outputs
    in the training period'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹** [4] â€” åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå°†ç”¨äºåŒºåˆ†è®­ç»ƒæœŸé—´çš„æ¨¡å‹è¾“å‡º'
- en: '**Forecast** [4] â€” in this context it will be used to distinguish model outputs
    in the test period'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹** [4] â€” åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒå°†ç”¨äºåŒºåˆ†æµ‹è¯•æœŸé—´çš„æ¨¡å‹è¾“å‡º'
- en: '**Feature Engineering** [5]'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å·¥ç¨‹** [5]'
- en: '**Autocorrelation** [6]'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è‡ªç›¸å…³** [6]'
- en: '**Partial Autocorrelation** [6]'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åè‡ªç›¸å…³** [6]'
- en: '**MLP (Multi-Layer Perceptron)** [7]'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**MLPï¼ˆå¤šå±‚æ„ŸçŸ¥å™¨ï¼‰** [7]'
- en: '**Input Layer** [7]'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥å±‚** [7]'
- en: '**Hidden Layer** [7]'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éšè—å±‚** [7]'
- en: '**Output Layer** [7]'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¾“å‡ºå±‚** [7]'
- en: '**Embedding** [8]'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åµŒå…¥** [8]'
- en: '**State Space Models** [9]'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**çŠ¶æ€ç©ºé—´æ¨¡å‹** [9]'
- en: '**Unobserved Components Model** [9]'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœªè§‚å¯Ÿåˆ°çš„ç»„ä»¶æ¨¡å‹** [9]'
- en: '**RMSE (Root Mean Squared Error)** [10]'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰** [10]'
- en: '**Feature Importance** [11]'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾é‡è¦æ€§** [11]'
- en: '**Permutation Feature Importance** [11]'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç½®æ¢ç‰¹å¾é‡è¦æ€§** [11]'
- en: '**Data Exploration**'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ¢ç´¢**'
- en: The essential packages used during the analysis are `numpy` and `pandas` for
    data manipulation, `plotly` for interactive charts, `statsmodels` for statistics
    and state space modeling and finally, `tensorflow` for MLP architcture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ†æè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ ¸å¿ƒåŒ…åŒ…æ‹¬ï¼šç”¨äºæ•°æ®å¤„ç†çš„`numpy`å’Œ`pandas`ï¼Œç”¨äºäº¤äº’å¼å›¾è¡¨çš„`plotly`ï¼Œç”¨äºç»Ÿè®¡å’ŒçŠ¶æ€ç©ºé—´å»ºæ¨¡çš„`statsmodels`ï¼Œä»¥åŠç”¨äºMLPæ¶æ„çš„`tensorflow`ã€‚
- en: '*Note: due to technical limitations, I will provide the code snippets for interactive
    plotting, but the figures will be static presented here.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šç”±äºæŠ€æœ¯é™åˆ¶ï¼Œæˆ‘å°†æä¾›äº¤äº’å¼ç»˜å›¾çš„ä»£ç ç‰‡æ®µï¼Œä½†æ­¤å¤„å±•ç¤ºçš„å›¾è¡¨å°†æ˜¯é™æ€çš„ã€‚*'
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The data is loaded automatically using `opendatasets`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é€šè¿‡`opendatasets`è‡ªåŠ¨åŠ è½½ã€‚
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Keep in my mind, that data cleaning was an essential first step in order to
    progress with the analysis. If you are interested in the details and also in state
    space modeling, please refer to my previous article [here](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007).
    â˜šğŸ“° In a nutshell, the following steps were conducted:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œæ•°æ®æ¸…ç†æ˜¯åˆ†æçš„å…³é”®ç¬¬ä¸€æ­¥ã€‚å¦‚æœä½ å¯¹ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œç‰¹åˆ«æ˜¯çŠ¶æ€ç©ºé—´å»ºæ¨¡ï¼Œè¯·å‚è€ƒæˆ‘ä¹‹å‰çš„æ–‡ç« [è¿™é‡Œ](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007)ã€‚â˜šğŸ“°
    ç®€è€Œè¨€ä¹‹ï¼Œè¿›è¡Œäº†ä»¥ä¸‹æ­¥éª¤ï¼š
- en: Identifying gaps, when specific timestamps are missing (only single steps were
    identified)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯†åˆ«ç¼ºå¤±çš„æ—¶é—´æˆ³ï¼ˆä»…è¯†åˆ«äº†å•æ­¥ç¼ºå¤±ï¼‰
- en: Perform imputation (using mean of previous and next records)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œæ’è¡¥ï¼ˆä½¿ç”¨å‰åè®°å½•çš„å‡å€¼ï¼‰
- en: Identifying and dropping duplicates
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯†åˆ«å¹¶åˆ é™¤é‡å¤é¡¹
- en: Set timestamp column as index for dataframe
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ—¶é—´æˆ³åˆ—è®¾ç½®ä¸ºæ•°æ®æ¡†çš„ç´¢å¼•
- en: Set dataframe index frequency to hourly, because it is a requirement for further
    processing
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®æ¡†çš„ç´¢å¼•é¢‘ç‡è®¾ç½®ä¸ºæ¯å°æ—¶ï¼Œå› ä¸ºè¿™æ˜¯è¿›ä¸€æ­¥å¤„ç†çš„è¦æ±‚
- en: After preparing the data, letâ€™s explore it by drawing 5 random timestamp samples
    and compare the time series at different scales.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡†å¤‡å¥½æ•°æ®åï¼Œæˆ‘ä»¬é€šè¿‡ç»˜åˆ¶5ä¸ªéšæœºæ—¶é—´æˆ³æ ·æœ¬æ¥æ¢ç´¢æ•°æ®ï¼Œå¹¶æ¯”è¾ƒä¸åŒå°ºåº¦ä¸‹çš„æ—¶é—´åºåˆ—ã€‚
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0a11e7108055273a11e5804af3946d3c.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a11e7108055273a11e5804af3946d3c.png)'
- en: 'Random sampling of dataset and visuals at different time scales. Source: author'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†çš„éšæœºæŠ½æ ·å’Œä¸åŒæ—¶é—´å°ºåº¦çš„å¯è§†åŒ–ã€‚æ¥æºï¼šä½œè€…
- en: State Space Modeling
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: çŠ¶æ€ç©ºé—´å»ºæ¨¡
- en: 'By closely examining this simple, yet effective plot, for me it is clearly
    visible, that the analysis should address several seasonal effects:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»”ç»†åˆ†æè¿™ä¸ªç®€å•ä½†æœ‰æ•ˆçš„å›¾è¡¨ï¼Œæˆ‘å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œåˆ†æåº”è¯¥è€ƒè™‘å‡ ä¸ªå­£èŠ‚æ€§æ•ˆåº”ï¼š
- en: energy consumption â€” in general â€” peak in mid summer and mid winter, regardless
    of the year selected
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: èƒ½æºæ¶ˆè€—â€”â€”é€šå¸¸â€”â€”åœ¨å¤å­£å’Œå†¬å­£çš„ä¸­æœŸè¾¾åˆ°å³°å€¼ï¼Œæ— è®ºé€‰æ‹©å“ªä¸ªå¹´ä»½
- en: a weekly minimum pattern seems to emerge on Mondays
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å‘¨ä¸€ä¼¼ä¹ä¼šå‡ºç°æ¯å‘¨æœ€å°å€¼æ¨¡å¼
- en: there is a daily minimum during the nights, maximum during the days
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å¤œé—´æœ‰ä¸€ä¸ªæ¯æ—¥æœ€ä½å€¼ï¼Œç™½å¤©æœ‰ä¸€ä¸ªæ¯æ—¥æœ€é«˜å€¼ã€‚
- en: 'Further analysis would reveal, that the yearly pattern of the dataset has 2
    harmonics, as the winter and summer peaks have different levels. As a result,
    the following state space model has been considered, where the periods are measured
    in hours (see model summary as well below):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥åˆ†æä¼šæ­ç¤ºï¼Œæ•°æ®é›†çš„å¹´åº¦æ¨¡å¼æœ‰2ä¸ªè°æ³¢ï¼Œå› ä¸ºå†¬å­£å’Œå¤å­£çš„å³°å€¼æ°´å¹³ä¸åŒã€‚å› æ­¤ï¼Œè€ƒè™‘äº†ä»¥ä¸‹çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œå…¶ä¸­å‘¨æœŸä»¥å°æ—¶ä¸ºå•ä½ï¼ˆè§ä¸‹æ–‡æ¨¡å‹æ€»ç»“ï¼‰ï¼š
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Without getting too much ahead of myself, let me note, that this model approximates
    the total energy consumption for the last 365 days with an error of ~2%, which
    is fairly accurate from a business perspective I believe. The MLP model constructed
    below will be evaluated by comparing it to the abovementioned state space model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸æå‰è¿‡å¤šå±•å¼€çš„æƒ…å†µä¸‹ï¼Œæˆ‘æƒ³æŒ‡å‡ºï¼Œæ¨¡å‹è¿‘ä¼¼äº†è¿‡å»365å¤©çš„æ€»èƒ½æºæ¶ˆè€—ï¼Œè¯¯å·®çº¦ä¸º~2%ï¼Œä»å•†ä¸šè§’åº¦æ¥çœ‹ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ç›¸å½“å‡†ç¡®çš„ã€‚ä¸‹é¢æ„å»ºçš„MLPæ¨¡å‹å°†é€šè¿‡ä¸ä¸Šè¿°çŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ¯”è¾ƒæ¥è¯„ä¼°ã€‚
- en: Feature Engineering
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç‰¹å¾å·¥ç¨‹
- en: 'Before constructing the MLP model, we should make the unique trend and seasonal
    effects available for the model to learn it. That is achieved by adding new features
    to the dataset, derived from the original 1D time series data. Derived features
    for capturing already identified or unidentified patterns include:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„å»ºMLPæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬åº”ä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°ç‹¬ç‰¹çš„è¶‹åŠ¿å’Œå­£èŠ‚æ€§æ•ˆåº”ã€‚è¿™å¯ä»¥é€šè¿‡å‘æ•°æ®é›†æ·»åŠ æ–°ç‰¹å¾æ¥å®ç°ï¼Œè¿™äº›ç‰¹å¾æ˜¯ä»åŸå§‹çš„1Dæ—¶é—´åºåˆ—æ•°æ®æ´¾ç”Ÿè€Œæ¥çš„ã€‚ä¸ºæ•æ‰å·²ç»è¯†åˆ«æˆ–æœªè¯†åˆ«çš„æ¨¡å¼ï¼Œæ´¾ç”Ÿç‰¹å¾åŒ…æ‹¬ï¼š
- en: Lags
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ»å
- en: Differences
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å·®å¼‚
- en: Rolling means
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ»šåŠ¨å‡å€¼
- en: Rolling standard deviations
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ»šåŠ¨æ ‡å‡†å·®
- en: Hour of the day
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€å¤©ä¸­çš„å°æ—¶
- en: Day of week
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€å‘¨ä¸­çš„å¤©æ•°
- en: Labeling weekends
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ ‡è®°å‘¨æœ«
- en: Such derived â€” and numerical â€” features could be considered in multiple intervals.
    In order to determine which intervals a model would benefit, it is highly recommended
    to check the autocorrelation properties of the dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ´¾ç”Ÿçš„â€”â€”ä»¥åŠæ•°å€¼å‹â€”â€”ç‰¹å¾å¯ä»¥åœ¨å¤šä¸ªæ—¶é—´é—´éš”ä¸­è¿›è¡Œè€ƒè™‘ã€‚ä¸ºäº†ç¡®å®šæ¨¡å‹åœ¨å“ªäº›æ—¶é—´é—´éš”ä¸­èƒ½å¤Ÿè·ç›Šï¼Œå¼ºçƒˆå»ºè®®æ£€æŸ¥æ•°æ®é›†çš„è‡ªç›¸å…³ç‰¹æ€§ã€‚
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/2db5e7d8a24a253430c45eadd4fb3031.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2db5e7d8a24a253430c45eadd4fb3031.png)'
- en: 'Autocorrelation and partial autocorrelation plots of time series. Source: author'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—çš„è‡ªç›¸å…³å’Œéƒ¨åˆ†è‡ªç›¸å…³å›¾ã€‚æ¥æºï¼šä½œè€…
- en: 'The dataset is highly autocorrelated, which makes sense as the values vary
    mostly between 10K MW and 20K MW with a smooth transition from hour to hour. However,
    focusing on partial autocorrelations as shown on the plot below, a significant
    correlation seems to be present in the multiples of 24 hours and in the last couple
    of hours. As a result, the derived features can be mainly classified as:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†å…·æœ‰å¾ˆé«˜çš„è‡ªç›¸å…³æ€§ï¼Œè¿™å¾ˆåˆç†ï¼Œå› ä¸ºå€¼å¤§å¤šåœ¨10K MWåˆ°20K MWä¹‹é—´æ³¢åŠ¨ï¼Œä¸”ä»ä¸€ä¸ªå°æ—¶åˆ°ä¸‹ä¸€ä¸ªå°æ—¶çš„è¿‡æ¸¡å¹³æ»‘ã€‚ç„¶è€Œï¼Œä¸“æ³¨äºä¸‹å›¾æ‰€ç¤ºçš„éƒ¨åˆ†è‡ªç›¸å…³æ€§ï¼Œä¼¼ä¹åœ¨24å°æ—¶çš„å€æ•°ä»¥åŠæœ€åå‡ ä¸ªå°æ—¶ä¸­å­˜åœ¨æ˜¾è‘—çš„ç›¸å…³æ€§ã€‚å› æ­¤ï¼Œæ´¾ç”Ÿç‰¹å¾ä¸»è¦å¯ä»¥åˆ†ç±»ä¸ºï¼š
- en: Daily (multiples of 24 hours),
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯æ—¥ï¼ˆ24å°æ—¶çš„å€æ•°ï¼‰ï¼Œ
- en: Hourly (focusing on the last couple of hours) and
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯å°æ—¶ï¼ˆä¸“æ³¨äºæœ€åå‡ ä¸ªå°æ—¶ï¼‰å’Œ
- en: Categorical features
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç‰¹å¾
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Constructing the MLP Model**'
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æ„å»ºMLPæ¨¡å‹**'
- en: 'Generating the above detailed features, the input shapes are known and the
    MLP model can be constructed. It is important to notice, that we are dealing with
    mixed datatypes: floats and integers. Please also note, that while all features
    are of numerical type, the integer inputs are fundamentally categorical features
    and should be treated as such.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸Šè¿°è¯¦ç»†ç‰¹å¾åï¼Œè¾“å…¥å½¢çŠ¶å·²çŸ¥ï¼Œå¯ä»¥æ„å»ºMLPæ¨¡å‹ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å¤„ç†çš„æ˜¯æ··åˆæ•°æ®ç±»å‹ï¼šæµ®åŠ¨å‹å’Œæ•´æ•°å‹ã€‚è¿˜è¯·æ³¨æ„ï¼Œå°½ç®¡æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯æ•°å€¼ç±»å‹ï¼Œæ•´æ•°å‹è¾“å…¥æœ¬è´¨ä¸Šæ˜¯åˆ†ç±»ç‰¹å¾ï¼Œåº”å½“è§†ä¸ºåˆ†ç±»ç‰¹å¾æ¥å¤„ç†ã€‚
- en: There is an option to encode the categories with e.g. one hot encoding technique,
    but that would significantly increase the number of features as each categorical
    column should be expanded to as many columns as many categories exist (minus one)
    [12]. I deliberately chose embedding instead to limit the number of features on
    the expense, that the model input layer will be more complex as the categoricals
    are converted to vectors via embedding first and then combined with the float
    inputs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä½¿ç”¨ä¾‹å¦‚ç‹¬çƒ­ç¼–ç æŠ€æœ¯å¯¹ç±»åˆ«è¿›è¡Œç¼–ç ï¼Œä½†è¿™ä¼šæ˜¾è‘—å¢åŠ ç‰¹å¾çš„æ•°é‡ï¼Œå› ä¸ºæ¯ä¸ªç±»åˆ«åˆ—éƒ½åº”è¯¥æ‰©å±•ä¸ºä¸ç±»åˆ«æ•°ç›¸ç­‰çš„åˆ—æ•°ï¼ˆå‡å»ä¸€ä¸ªï¼‰[12]ã€‚æˆ‘æ•…æ„é€‰æ‹©äº†åµŒå…¥æ–¹æ³•ï¼Œä»¥é™åˆ¶ç‰¹å¾æ•°é‡ï¼Œè™½ç„¶è¿™æ ·åšä¼šä½¿å¾—æ¨¡å‹çš„è¾“å…¥å±‚æ›´åŠ å¤æ‚ï¼Œå› ä¸ºç±»åˆ«æ•°æ®é¦–å…ˆé€šè¿‡åµŒå…¥è½¬æ¢ä¸ºå‘é‡ï¼Œå†ä¸æµ®åŠ¨è¾“å…¥ç»“åˆã€‚
- en: Please see the graph after the code section for clarity. The architecture has
    been built using rule of thumbs, as the hyperparameter tuning is out of scope
    for this article. However, if you are interested in a general framework how it
    can be done, please check ğŸ“°â˜› [my previous article](https://medium.com/towards-data-science/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d)
    (I tuned an XGBoost model with Optuna as a tool for Bayesian search of optimal
    hyperparameter values).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æŸ¥çœ‹ä»£ç éƒ¨åˆ†åçš„å›¾è¡¨ä»¥è·å¾—æ›´æ¸…æ™°çš„ç†è§£ã€‚è¯¥æ¶æ„æ˜¯ä½¿ç”¨ç»éªŒæ³•åˆ™æ„å»ºçš„ï¼Œå› ä¸ºè¶…å‚æ•°è°ƒä¼˜ä¸åœ¨æœ¬æ–‡èŒƒå›´å†…ã€‚ç„¶è€Œï¼Œå¦‚æœä½ å¯¹å¦‚ä½•è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜çš„é€šç”¨æ¡†æ¶æ„Ÿå…´è¶£ï¼Œè¯·æŸ¥çœ‹ğŸ“°â˜›
    [æˆ‘ä¹‹å‰çš„æ–‡ç« ](https://medium.com/towards-data-science/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d)ï¼ˆåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä½¿ç”¨Optunaä½œä¸ºè´å¶æ–¯æœç´¢å·¥å…·è°ƒä¼˜äº†XGBoostæ¨¡å‹çš„æœ€ä½³è¶…å‚æ•°ï¼‰ã€‚
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/d1e93289f78adc2ad27fe54af42aa5d8.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1e93289f78adc2ad27fe54af42aa5d8.png)'
- en: 'MLP architecture created by using Tensorflow/Keras. Source: author'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Tensorflow/Kerasåˆ›å»ºçš„MLPæ¶æ„ã€‚æ¥æºï¼šä½œè€…
- en: As far as point forecasts goes, the results are ridiculously accurate. This
    is a good sign, that the feature engineering principles applied are correctly
    capturing the underlying patterns in the data and the model was able to generalize
    it.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å°±ç‚¹é¢„æµ‹è€Œè¨€ï¼Œç»“æœéå¸¸å‡†ç¡®ã€‚è¿™æ˜¯ä¸€ä¸ªå¥½å…†å¤´ï¼Œè¯´æ˜æ‰€åº”ç”¨çš„ç‰¹å¾å·¥ç¨‹åŸåˆ™æ­£ç¡®åœ°æ•æ‰äº†æ•°æ®ä¸­çš„æ½œåœ¨æ¨¡å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿå°†å…¶æ³›åŒ–ã€‚
- en: '![](../Images/181dd0c122d63276258e6f6f5576e070.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/181dd0c122d63276258e6f6f5576e070.png)'
- en: 'Baseline MLP model point-forecasts vs. test data. Source: author'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†MLPæ¨¡å‹çš„ç‚¹é¢„æµ‹ä¸æµ‹è¯•æ•°æ®å¯¹æ¯”ã€‚æ¥æºï¼šä½œè€…
- en: The point forecasts overlap with the test set and the two figure traces are
    indistinguishable from each other. More precisely, the RMSE of the predictions
    (training set) and forecasts (test set) are approx. 19.3 and 18.9 respectively
    (in the ballpark of 0.1% in relative terms).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹é¢„æµ‹ä¸æµ‹è¯•é›†é‡å ï¼Œä¸”ä¸¤ä¸ªå›¾å½¢è½¨è¿¹å‡ ä¹æ— æ³•åŒºåˆ†ã€‚æ›´ç²¾ç¡®åœ°è¯´ï¼Œé¢„æµ‹ï¼ˆè®­ç»ƒé›†ï¼‰å’Œé¢„æµ‹å€¼ï¼ˆæµ‹è¯•é›†ï¼‰çš„RMSEåˆ†åˆ«çº¦ä¸º19.3å’Œ18.9ï¼ˆç›¸å¯¹è¯¯å·®çº¦ä¸º0.1%ï¼‰ã€‚
- en: '**Feature Importance**'
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾é‡è¦æ€§**'
- en: 'What led the model to be accurate? Are all derived features equally important
    or is there a subset which has a greater weight in determining the outcome? These
    are valid questions for two distinct reasons:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯ä»€ä¹ˆä½¿å¾—æ¨¡å‹å‡†ç¡®ï¼Ÿæ‰€æœ‰æ´¾ç”Ÿç‰¹å¾æ˜¯å¦åŒæ ·é‡è¦ï¼Œè¿˜æ˜¯æœ‰ä¸€ä¸ªå­é›†åœ¨å†³å®šç»“æœæ—¶å…·æœ‰æ›´å¤§çš„æƒé‡ï¼Ÿè¿™ä¸¤ä¸ªé—®é¢˜æœ‰å…¶æœ‰æ•ˆæ€§ï¼ŒåŸå› æœ‰äºŒï¼š
- en: In real-world scenarios and in the case of big data, the resources for training
    the model is limited and the amount of data used could make a significant difference
    if the model could be trained at all
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨å®é™…åœºæ™¯ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨å¤§æ•°æ®æƒ…å†µä¸‹ï¼Œè®­ç»ƒæ¨¡å‹çš„èµ„æºæœ‰é™ï¼Œæ‰€ä½¿ç”¨çš„æ•°æ®é‡å¯èƒ½å¯¹æ˜¯å¦èƒ½å¤Ÿè®­ç»ƒæ¨¡å‹äº§ç”Ÿé‡å¤§å½±å“ã€‚
- en: Without any explanation, the model works as a black box, which creates uncertainty
    regarding its perfomance. Neural Networks are especially prone to be black box
    models and interpreting them is a field of its own [11]
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœæ²¡æœ‰ä»»ä½•è§£é‡Šï¼Œæ¨¡å‹å°±åƒä¸€ä¸ªé»‘ç®±ï¼Œè¿™ä¼šå¸¦æ¥å…³äºå…¶æ€§èƒ½çš„ä¸ç¡®å®šæ€§ã€‚ç¥ç»ç½‘ç»œå°¤å…¶å®¹æ˜“æˆä¸ºé»‘ç®±æ¨¡å‹ï¼Œè§£é‡Šå®ƒä»¬æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„é¢†åŸŸ[11]ã€‚
- en: There is an abundance of techniques to interpret models, each has its pros and
    cons. I selected the permutation feature importance method to give some insights
    on model interpretation however, a key takeway from my analysis is that such
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰æœ‰å¤§é‡çš„æ¨¡å‹è§£é‡ŠæŠ€æœ¯ï¼Œæ¯ç§æ–¹æ³•éƒ½æœ‰å…¶ä¼˜ç¼ºç‚¹ã€‚æˆ‘é€‰æ‹©äº†æ’åˆ—ç‰¹å¾é‡è¦æ€§æ–¹æ³•ï¼Œä»¥ä¾¿ä¸ºæ¨¡å‹è§£é‡Šæä¾›ä¸€äº›è§è§£ã€‚ç„¶è€Œï¼Œæˆ‘åˆ†æä¸­çš„ä¸€ä¸ªå…³é”®ç»“è®ºæ˜¯ï¼Œ
- en: model interpretation techniques are only interpreting the model in scope and
    not necessarily the underlying process itself. Reality could be very different
    from feature importance analysis, hence it should not be taken as ground truth
    of causal relationship between independent variables and the target variable.
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¨¡å‹è§£é‡ŠæŠ€æœ¯ä»…ä»…æ˜¯åœ¨ç‰¹å®šèŒƒå›´å†…è§£é‡Šæ¨¡å‹ï¼Œè€Œä¸ä¸€å®šæ˜¯è§£é‡Šå…¶èƒŒåçš„è¿‡ç¨‹ã€‚ç°å®å¯èƒ½ä¸ç‰¹å¾é‡è¦æ€§åˆ†æå¤§ç›¸å¾„åº­ï¼Œå› æ­¤ä¸åº”å°†å…¶è§†ä¸ºè‡ªå˜é‡ä¸ç›®æ ‡å˜é‡ä¹‹é—´å› æœå…³ç³»çš„æœ€ç»ˆçœŸç›¸ã€‚
- en: Let me explain that with my analysis results. Permuting features one at a time,
    recalculating the RMSE score and recording the relative change in RMSE compared
    to forecasts using the original data will give the relative importance of features
    [13].
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ç”¨æˆ‘çš„åˆ†æç»“æœæ¥è§£é‡Šè¿™ä¸€ç‚¹ã€‚é€ä¸€ç½®æ¢ç‰¹å¾ï¼Œé‡æ–°è®¡ç®—RMSEå¾—åˆ†å¹¶è®°å½•ç›¸å¯¹äºä½¿ç”¨åŸå§‹æ•°æ®çš„é¢„æµ‹RMSEçš„ç›¸å¯¹å˜åŒ–ï¼Œå°†ç»™å‡ºç‰¹å¾çš„ç›¸å¯¹é‡è¦æ€§[13]ã€‚
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/2564e8b61f4fb48c7d19a4b671007da9.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2564e8b61f4fb48c7d19a4b671007da9.png)'
- en: 'Permutation feature importance histogram. Source: author'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ç½®æ¢ç‰¹å¾é‡è¦æ€§ç›´æ–¹å›¾ã€‚æ¥æºï¼šä½œè€…
- en: Hourly-, daily lags and differences seem important and maybe the hourly rolling
    means as well. However, the daily and hourly rolling standards just as well as
    the categorical features seem negligible, relative to the aforementioned features.
    One caveat of permutation feature importance is that it does not take into account
    multicollinearity and consequently may give inaccurate results. Remember, the
    features have been derived from a dataset with high autocorrelation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯å°æ—¶å’Œæ¯æ—¥æ»åä»¥åŠå·®å¼‚ä¼¼ä¹å¾ˆé‡è¦ï¼Œä¹Ÿè®¸æ¯å°æ—¶çš„æ»šåŠ¨å‡å€¼ä¹Ÿå¾ˆé‡è¦ã€‚ç„¶è€Œï¼Œæ¯æ—¥å’Œæ¯å°æ—¶æ»šåŠ¨æ ‡å‡†ä»¥åŠåˆ†ç±»ç‰¹å¾ä¼¼ä¹ç›¸å¯¹è¾ƒå°ï¼Œå¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œä¸ä¸Šè¿°ç‰¹å¾ç›¸æ¯”ã€‚ç½®æ¢ç‰¹å¾é‡è¦æ€§çš„ä¸€é¡¹è­¦å‘Šæ˜¯ï¼Œå®ƒæ²¡æœ‰è€ƒè™‘å¤šé‡å…±çº¿æ€§ï¼Œå› æ­¤å¯èƒ½ä¼šç»™å‡ºä¸å‡†ç¡®çš„ç»“æœã€‚è¯·è®°ä½ï¼Œè¿™äº›ç‰¹å¾æ˜¯ä»å…·æœ‰é«˜è‡ªç›¸å…³çš„æ•°æ®é›†ä¸­æ¨å¯¼å‡ºæ¥çš„ã€‚
- en: 'One possible way to handle the situation is following `scikit learn` â€˜s guidance:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†è¿™ç§æƒ…å†µçš„ä¸€ç§å¯èƒ½æ–¹å¼æ˜¯éµå¾ª`scikit learn`çš„æŒ‡å¯¼ï¼š
- en: perform hierarchical clustering on the Spearman rank-order correlations, pick
    a threshold, and keep a single feature from each cluster. [13]
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¯¹Spearmanç­‰çº§é¡ºåºç›¸å…³æ€§æ‰§è¡Œå±‚æ¬¡èšç±»ï¼Œé€‰æ‹©ä¸€ä¸ªé˜ˆå€¼ï¼Œå¹¶ä»æ¯ä¸ªç°‡ä¸­ä¿ç•™ä¸€ä¸ªç‰¹å¾ã€‚[13]
- en: 'However, I would like to focus on highlighting the inaccuracy and adding more
    insights to the dataset by training alternative models with the grouped features
    one group at a time. The same MLP architecture was used for this purpose with
    adjustments only applied on the input layer to accomodate a subset of data. The
    following groups were created in the feature engineering section and tested here
    (train/test dataset RMSE results also reported respectively):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘æƒ³ä¸“æ³¨äºçªå‡ºä¸å‡†ç¡®ä¹‹å¤„ï¼Œå¹¶é€šè¿‡é€ä¸€è®­ç»ƒæ›¿ä»£æ¨¡å‹ä»¥åˆ†ç»„ç‰¹å¾æ¥ä¸ºæ•°æ®é›†æ·»åŠ æ›´å¤šæ´è§ã€‚ä¸ºæ­¤ä½¿ç”¨äº†ç›¸åŒçš„MLPæ¶æ„ï¼Œä»…å¯¹è¾“å…¥å±‚è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”æ•°æ®çš„å­é›†ã€‚ä»¥ä¸‹ç»„åœ¨ç‰¹å¾å·¥ç¨‹éƒ¨åˆ†åˆ›å»ºå¹¶åœ¨æ­¤æµ‹è¯•ï¼ˆè®­ç»ƒ/æµ‹è¯•æ•°æ®é›†çš„RMSEç»“æœä¹Ÿåˆ†åˆ«æŠ¥å‘Šï¼‰ï¼š
- en: daily lags (942 and 994)
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯æ—¥æ»åï¼ˆ942 å’Œ 994ï¼‰
- en: daily differences (1792 and 1952)
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯æ—¥å·®å¼‚ï¼ˆ1792 å’Œ 1952ï¼‰
- en: hourly lags (686 and 611)
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯å°æ—¶æ»åï¼ˆ686 å’Œ 611ï¼‰
- en: daily rolling means and standard deviations (1710 and 1663)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ—¥å¸¸æ»šåŠ¨å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ1710 å’Œ 1663ï¼‰
- en: hourly rolling means and standard deviations (84.4 and 75.5)
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯å°æ—¶æ»šåŠ¨å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ84.4 å’Œ 75.5ï¼‰
- en: 'It is clear that the alternative models show results not anticipated from simple
    permutation feature importance analysis, without handling multicollinearity: e.g.
    daily rolling features yielded better scores than daily differences and the model
    trained on hourly rolling features has the best performance out of the alternative
    models, close to the baseline model (RMSE reported in percentage ~0.5% vs. ~0.1%
    respectively).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œæ›¿ä»£æ¨¡å‹æ˜¾ç¤ºçš„ç»“æœä¸ç®€å•çš„ç½®æ¢ç‰¹å¾é‡è¦æ€§åˆ†æé¢„æœŸä¸åŒï¼Œä¸”æœªå¤„ç†å¤šé‡å…±çº¿æ€§ï¼šä¾‹å¦‚ï¼Œæ¯æ—¥æ»šåŠ¨ç‰¹å¾çš„å¾—åˆ†ä¼˜äºæ¯æ—¥å·®å¼‚ï¼Œä¸”è®­ç»ƒäºæ¯å°æ—¶æ»šåŠ¨ç‰¹å¾çš„æ¨¡å‹åœ¨æ‰€æœ‰æ›¿ä»£æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ï¼Œæ¥è¿‘åŸºçº¿æ¨¡å‹ï¼ˆRMSEåˆ†åˆ«ä¸ºç™¾åˆ†æ¯”~0.5%å’Œ~0.1%ï¼‰ã€‚
- en: A Note on a Specific Anomaly in the Data
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸­çš„ç‰¹å®šå¼‚å¸¸è¯´æ˜
- en: I would like to highlight a very specific case of anomaly observed at 14:00
    on 20th October 2008\. This is the highest ever recorded value with no apparent
    cause, no similar datapoints before or after in the dataset.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³å¼ºè°ƒ2008å¹´10æœˆ20æ—¥14:00è§‚å¯Ÿåˆ°çš„ä¸€ä¸ªéå¸¸ç‰¹æ®Šçš„å¼‚å¸¸æƒ…å†µã€‚ è¿™æ˜¯æœ‰å²ä»¥æ¥è®°å½•çš„æœ€é«˜å€¼ï¼Œä¸”æ²¡æœ‰æ˜æ˜¾çš„åŸå› ï¼Œæ•°æ®é›†ä¸­ä¹‹å‰å’Œä¹‹åæ²¡æœ‰ç±»ä¼¼çš„æ•°æ®ç‚¹ã€‚
- en: Yet, the baseline model powered by feature engineering was able to predict that
    datapoint and is not considered an outlier!
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç”±ç‰¹å¾å·¥ç¨‹é©±åŠ¨çš„åŸºçº¿æ¨¡å‹èƒ½å¤Ÿé¢„æµ‹è¯¥æ•°æ®ç‚¹ï¼Œå¹¶ä¸”ä¸è¢«è®¤ä¸ºæ˜¯å¼‚å¸¸å€¼ï¼
- en: '![](../Images/fe5663c1e874d9c4bcbf0d8dd541ab3c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe5663c1e874d9c4bcbf0d8dd541ab3c.png)'
- en: 'Baseline MLP model point-predictions and the observed potential anomaly. Source:
    author'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºçº¿MLPæ¨¡å‹çš„ç‚¹é¢„æµ‹å’Œè§‚å¯Ÿåˆ°çš„æ½œåœ¨å¼‚å¸¸ã€‚æ¥æºï¼šä½œè€…
- en: 'From which features the model was able to predict that point? Letâ€™s use our
    alternative models for inference. The best alternative (hourly rolling features)
    seems extremely accurate in the vicinity, but could only explain the phenomenon
    partially:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹æ˜¯å¦‚ä½•é¢„æµ‹è¯¥æ•°æ®ç‚¹çš„å‘¢ï¼Ÿè®©æˆ‘ä»¬ä½¿ç”¨æ›¿ä»£æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æœ€ä½³çš„æ›¿ä»£æ¨¡å‹ï¼ˆæ¯å°æ—¶æ»šåŠ¨ç‰¹å¾ï¼‰åœ¨è¯¥ç‚¹é™„è¿‘ä¼¼ä¹éå¸¸å‡†ç¡®ï¼Œä½†åªèƒ½éƒ¨åˆ†è§£é‡Šè¿™ä¸€ç°è±¡ï¼š
- en: '![](../Images/1d891089cfb4b6494f8ac7e5afc5959e.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d891089cfb4b6494f8ac7e5afc5959e.png)'
- en: 'Alternative MLP model (utilizing hourly rolling features) point-predictions
    and the observed potential anomaly. Source: author'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ›¿ä»£çš„ MLP æ¨¡å‹ï¼ˆåˆ©ç”¨æ¯å°æ—¶æ»šåŠ¨ç‰¹å¾ï¼‰ç‚¹é¢„æµ‹å’Œè§‚å¯Ÿåˆ°çš„æ½œåœ¨å¼‚å¸¸ã€‚æ¥æºï¼šä½œè€…
- en: 'The second best alternative is the one utilizing hourly lags, but it has absolutely
    no answer why that happened:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒå¥½çš„æ›¿ä»£æ–¹æ¡ˆæ˜¯åˆ©ç”¨æ¯å°æ—¶æ»åçš„æ¨¡å‹ï¼Œä½†å®ƒå®Œå…¨æ²¡æœ‰è§£é‡Šä¸ºä½•ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼š
- en: '![](../Images/4d699078a9afb2b07b740af85194b30d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d699078a9afb2b07b740af85194b30d.png)'
- en: 'Alternative MLP model (utilizing hourly lag features) point-predictions and
    the observed potential anomaly. Source: author'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æ›¿ä»£çš„ MLP æ¨¡å‹ï¼ˆåˆ©ç”¨æ¯å°æ—¶æ»åç‰¹å¾ï¼‰ç‚¹é¢„æµ‹å’Œè§‚å¯Ÿåˆ°çš„æ½œåœ¨å¼‚å¸¸ã€‚æ¥æºï¼šä½œè€…
- en: Making a long story short, the daily differences might contain important information
    regarding the underlying patterns. Although utilizing the daily differences group
    solely gives higher predictions, the baseline model seemingly found a good balance
    of weights for the features.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼Œæ¯æ—¥å·®å¼‚å¯èƒ½åŒ…å«æœ‰å…³æ½œåœ¨æ¨¡å¼çš„é‡è¦ä¿¡æ¯ã€‚å°½ç®¡å•ç‹¬ä½¿ç”¨æ¯æ—¥å·®å¼‚ç»„ä¼šç»™å‡ºæ›´é«˜çš„é¢„æµ‹å€¼ï¼Œä½†åŸºå‡†æ¨¡å‹ä¼¼ä¹æ‰¾åˆ°äº†ç‰¹å¾æƒé‡çš„è‰¯å¥½å¹³è¡¡ã€‚
- en: '![](../Images/c0f627ebf8eb29789a55dda1e01f9faf.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0f627ebf8eb29789a55dda1e01f9faf.png)'
- en: 'Alternative MLP model (utilizing daily difference features) point-predictions
    and the observed potential anomaly. Source: author'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æ›¿ä»£çš„ MLP æ¨¡å‹ï¼ˆåˆ©ç”¨æ¯æ—¥å·®å¼‚ç‰¹å¾ï¼‰ç‚¹é¢„æµ‹å’Œè§‚å¯Ÿåˆ°çš„æ½œåœ¨å¼‚å¸¸ã€‚æ¥æºï¼šä½œè€…
- en: Multi-step Prediction Model
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤šæ­¥é¢„æµ‹æ¨¡å‹
- en: Finally, the model architecture has been modified to yield multi-step predictions.
    The forecasting period is one year, as suggested by the dataset publisher [14].
    Given all uncertainties in such a process with special regard to weather conditions,
    it might not make sense to consider such a long forecasting period. However, it
    is an intersting exercise to evaluate the multi-step modelâ€™s performance to the
    state space model, which explicitly models the trend and seasonal effects observed
    across the year (see next section).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ¨¡å‹æ¶æ„å·²è¢«ä¿®æ”¹ï¼Œä»¥ç”Ÿæˆå¤šæ­¥é¢„æµ‹ã€‚é¢„æµ‹æœŸä¸ºä¸€å¹´ï¼Œå¦‚æ•°æ®é›†å‘å¸ƒè€…æ‰€å»ºè®®çš„[14]ã€‚è€ƒè™‘åˆ°è¿™ç§è¿‡ç¨‹ä¸­çš„æ‰€æœ‰ä¸ç¡®å®šæ€§ï¼Œç‰¹åˆ«æ˜¯å¤©æ°”æ¡ä»¶æ–¹é¢ï¼Œè€ƒè™‘è¿™ä¹ˆé•¿çš„é¢„æµ‹æœŸå¯èƒ½æ²¡æœ‰æ„ä¹‰ã€‚ç„¶è€Œï¼Œè¿™å¯¹äºè¯„ä¼°å¤šæ­¥æ¨¡å‹ä¸çŠ¶æ€ç©ºé—´æ¨¡å‹çš„è¡¨ç°æ˜¯ä¸€ä¸ªæœ‰è¶£çš„ç»ƒä¹ ï¼Œåè€…æ˜ç¡®å»ºæ¨¡äº†è·¨å¹´è§‚å¯Ÿåˆ°çš„è¶‹åŠ¿å’Œå­£èŠ‚æ€§æ•ˆåº”ï¼ˆè§ä¸‹ä¸€èŠ‚ï¼‰ã€‚
- en: 'The key points for implementing a multi-step model are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç°å¤šæ­¥æ¨¡å‹çš„å…³é”®ç‚¹å¦‚ä¸‹ï¼š
- en: the target was a series of vectors (next 8766 hours defined for ech step)
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ˜¯ä¸€ä¸ªå‘é‡åºåˆ—ï¼ˆä¸ºæ¯ä¸ªæ­¥éª¤å®šä¹‰çš„æ¥ä¸‹æ¥çš„ 8766 å°æ—¶ï¼‰
- en: as a result, the prediction or forecast is the next 8766 hours (approx. one
    year) for the last row of inputs
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯ï¼Œé¢„æµ‹æˆ–é¢„æŠ¥æ˜¯æ¥ä¸‹æ¥ 8766 å°æ—¶ï¼ˆå¤§çº¦ä¸€å¹´ï¼‰çš„æœ€åä¸€è¡Œè¾“å…¥æ•°æ®
- en: due to resource limitations I had to limit the training data for the last year
    of the former training dataset
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”±äºèµ„æºé™åˆ¶ï¼Œæˆ‘ä¸å¾—ä¸é™åˆ¶å‰ä¸€è®­ç»ƒæ•°æ®é›†çš„æœ€åä¸€å¹´çš„è®­ç»ƒæ•°æ®ã€‚
- en: the output layer was modified accordingly, to give the desired vector output
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å‡ºå±‚å·²ç›¸åº”ä¿®æ”¹ï¼Œä»¥ç»™å‡ºæ‰€éœ€çš„å‘é‡è¾“å‡º
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For a visual evaluation, one could see the model was trying to generalize the
    patterns:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¯è§†åŒ–è¯„ä¼°ï¼Œå¯ä»¥çœ‹å‡ºæ¨¡å‹è¯•å›¾å¯¹æ¨¡å¼è¿›è¡Œæ³›åŒ–ï¼š
- en: '![](../Images/2c6c7c1d334527dfc742b07d89445916.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c6c7c1d334527dfc742b07d89445916.png)'
- en: 'Multistep MLP model predictions and forecasts vs. original data. Source: author'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ­¥ MLP æ¨¡å‹çš„é¢„æµ‹ä¸åŸå§‹æ•°æ®çš„å¯¹æ¯”ã€‚æ¥æºï¼šä½œè€…
- en: MLP vs. State Space Model
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLP ä¸çŠ¶æ€ç©ºé—´æ¨¡å‹
- en: 'Due to generalization of the data, the RMSE score increased significantly:
    1982 and 2017 for the train and test dataset respectively. However, in order the
    properly evaluate the multi-step MLP, we should use another model for comparison.
    As I mentioned in the previous section, state space models gives fairly understandable
    approximations of the trend and seasonal effects observed across the year. This
    feature make them relatively easily interpretable, unlike neural networks. The
    primary reason is that hidden layers have many connections and understanding how
    they are activated is not a straightforward process. [11].'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ•°æ®çš„æ³›åŒ–ï¼ŒRMSE å¾—åˆ†æ˜¾è‘—å¢åŠ ï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¾—åˆ†åˆ†åˆ«ä¸º 1982 å’Œ 2017ã€‚ç„¶è€Œï¼Œä¸ºäº†æ­£ç¡®è¯„ä¼°å¤šæ­¥ MLPï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚æ­£å¦‚æˆ‘åœ¨å‰ä¸€èŠ‚ä¸­æåˆ°çš„ï¼ŒçŠ¶æ€ç©ºé—´æ¨¡å‹æä¾›äº†å¯¹è·¨å¹´è§‚å¯Ÿåˆ°çš„è¶‹åŠ¿å’Œå­£èŠ‚æ€§æ•ˆåº”çš„ç›¸å½“å¯ç†è§£çš„è¿‘ä¼¼ã€‚è¿™ä¸€ç‰¹ç‚¹ä½¿å¾—å®ƒä»¬ç›¸å¯¹å®¹æ˜“è§£é‡Šï¼Œä¸åƒç¥ç»ç½‘ç»œã€‚ä¸»è¦åŸå› æ˜¯éšè—å±‚æœ‰å¾ˆå¤šè¿æ¥ï¼Œç†è§£å®ƒä»¬æ˜¯å¦‚ä½•è¢«æ¿€æ´»çš„å¹¶ä¸æ˜¯ä¸€ä¸ªç›´æ¥çš„è¿‡ç¨‹ã€‚[11]
- en: 'In [my previous article](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007),
    â˜šğŸ“° I used a simplified, yet meaningful evaluation method: comparing the total
    energy consumption within the last year. Practically, that is the area under the
    curve of the energy consumption time series. The values for the original data
    and model forecasts can be compared directly. For the `UnobservedComponents` model:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[æˆ‘ä¹‹å‰çš„æ–‡ç« ](https://medium.com/analytics-vidhya/multi-seasonal-time-series-analysis-decomposition-and-forecasting-with-python-609409570007)ä¸­ï¼Œâ˜šğŸ“°æˆ‘ä½¿ç”¨äº†ä¸€ç§ç®€åŒ–ä½†æœ‰æ„ä¹‰çš„è¯„ä¼°æ–¹æ³•ï¼šæ¯”è¾ƒè¿‡å»ä¸€å¹´å†…çš„æ€»èƒ½è€—ã€‚å®é™…ä¸Šï¼Œè¿™æ˜¯èƒ½è€—æ—¶é—´åºåˆ—ä¸‹çš„æ›²çº¿é¢ç§¯ã€‚å¯ä»¥ç›´æ¥æ¯”è¾ƒåŸå§‹æ•°æ®å’Œæ¨¡å‹é¢„æµ‹çš„å€¼ã€‚å¯¹äº`UnobservedComponents`æ¨¡å‹ï¼š
- en: '[PRE10]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For the MLP model:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºMLPæ¨¡å‹ï¼š
- en: '[PRE12]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In short: it is -1.912% vs. -2.159% in favor of the MLP model. Please note,
    that this has been achieved by utilizing an MLP architecture using some simple
    rule of thumbs, not even considering hyperparameter tuning or some effective model
    training features, e.g. reducing the learning rate when the evaluation metric
    reaches a plateau or early stopping.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼šå®ƒæ˜¯-1.912% vs. -2.159%ï¼Œåå‘äºMLPæ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œè¿™æ˜¯é€šè¿‡ä½¿ç”¨MLPæ¶æ„å¹¶ç»“åˆä¸€äº›ç®€å•çš„ç»éªŒæ³•åˆ™å®ç°çš„ï¼Œç”šè‡³æ²¡æœ‰è€ƒè™‘è¶…å‚æ•°è°ƒä¼˜æˆ–æŸäº›æœ‰æ•ˆçš„æ¨¡å‹è®­ç»ƒç‰¹å¾ï¼Œä¾‹å¦‚åœ¨è¯„ä¼°æŒ‡æ ‡è¾¾åˆ°å¹³å°æœŸæ—¶å‡å°‘å­¦ä¹ ç‡æˆ–æå‰åœæ­¢ã€‚
- en: The results should be fairly convincing that indeed, utilizing relatively simple
    neural network architectures combined with powerful feature engineering techniques,
    accurate forecasting tools are within reach for a data scientist early in his
    or her seniority level.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœåº”è¯¥æ˜¯ç›¸å½“ä»¤äººä¿¡æœçš„ï¼Œç¡®å®ï¼Œé€šè¿‡åˆ©ç”¨ç›¸å¯¹ç®€å•çš„ç¥ç»ç½‘ç»œæ¶æ„ç»“åˆå¼ºå¤§çš„ç‰¹å¾å·¥ç¨‹æŠ€æœ¯ï¼Œå‡†ç¡®çš„é¢„æµ‹å·¥å…·å·²ç»åœ¨æ•°æ®ç§‘å­¦å®¶çš„åˆçº§é˜¶æ®µè§¦æ‰‹å¯å¾—ã€‚
- en: Resources
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: èµ„æº
- en: 'Data source:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¥æºï¼š
- en: '[https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)
    (CC0)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)
    (CC0)'
- en: 'Notebook (only code, without outputs): [https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215](https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬”è®°æœ¬ï¼ˆä»…ä»£ç ï¼Œä¸åŒ…å«è¾“å‡ºï¼‰ï¼š[https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215](https://gist.github.com/danielandthelions/2e6f0edd30902113ad10fd9f20bda215)
- en: References
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] [https://preset.io/blog/time-series-forecasting-a-complete-guide/](https://preset.io/blog/time-series-forecasting-a-complete-guide/)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://preset.io/blog/time-series-forecasting-a-complete-guide/](https://preset.io/blog/time-series-forecasting-a-complete-guide/)'
- en: '[2] [https://www.ibm.com/topics/recurrent-neural-networks](https://www.ibm.com/topics/recurrent-neural-networks)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://www.ibm.com/topics/recurrent-neural-networks](https://www.ibm.com/topics/recurrent-neural-networks)'
- en: '[3] [https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/](https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/](https://www.timescale.com/blog/time-series-analysis-what-is-it-how-to-use-it/)'
- en: '[4] [https://plat.ai/blog/difference-between-prediction-and-forecast/](https://plat.ai/blog/difference-between-prediction-and-forecast/)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://plat.ai/blog/difference-between-prediction-and-forecast/](https://plat.ai/blog/difference-between-prediction-and-forecast/)'
- en: '[5] [https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/](https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/](https://dotdata.com/blog/practical-guide-for-feature-engineering-of-time-series-data/)'
- en: '[6] [https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/](https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/](https://statisticsbyjim.com/time-series/autocorrelation-partial-autocorrelation/)'
- en: '[7] [https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)'
- en: '[8] [https://jina.ai/news/embeddings-in-depth/](https://jina.ai/news/embeddings-in-depth/)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://jina.ai/news/embeddings-in-depth/](https://jina.ai/news/embeddings-in-depth/)'
- en: '[9] Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and
    practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3\. Accessed
    on 7th July 2024'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Hyndman, R.J., & Athanasopoulos, G. (2021) ã€ŠForecasting: principles and
    practiceã€‹ï¼Œç¬¬ä¸‰ç‰ˆï¼ŒOTextsï¼šæ¾³å¤§åˆ©äºšå¢¨å°”æœ¬ã€‚OTexts.com/fpp3ã€‚è®¿é—®æ—¶é—´ï¼š2024å¹´7æœˆ7æ—¥'
- en: '[10] [https://statisticsbyjim.com/regression/root-mean-square-error-rmse/](https://statisticsbyjim.com/regression/root-mean-square-error-rmse/)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [https://statisticsbyjim.com/regression/root-mean-square-error-rmse/](https://statisticsbyjim.com/regression/root-mean-square-error-rmse/)'
- en: '[11] [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)'
- en: '[12] [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)'
- en: '[13] [https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] [https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance)'
- en: '[14] [https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] [https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption/)'
