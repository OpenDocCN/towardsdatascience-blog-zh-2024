- en: 'The Machine Learning Guide for Predictive Accuracy: Interpolation and Extrapolation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测准确度的机器学习指南：插值与外推
- en: 原文：[https://towardsdatascience.com/the-machine-learning-guide-for-predictive-accuracy-interpolation-and-extrapolation-45dd270ee871?source=collection_archive---------4-----------------------#2024-07-04](https://towardsdatascience.com/the-machine-learning-guide-for-predictive-accuracy-interpolation-and-extrapolation-45dd270ee871?source=collection_archive---------4-----------------------#2024-07-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-machine-learning-guide-for-predictive-accuracy-interpolation-and-extrapolation-45dd270ee871?source=collection_archive---------4-----------------------#2024-07-04](https://towardsdatascience.com/the-machine-learning-guide-for-predictive-accuracy-interpolation-and-extrapolation-45dd270ee871?source=collection_archive---------4-----------------------#2024-07-04)
- en: Evaluating machine learning models beyond training data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估超越训练数据的机器学习模型
- en: '[](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)[![Ryota
    Kiuchi, Ph.D.](../Images/5459c434848898345d932320c4a01312.png)](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)
    [Ryota Kiuchi, Ph.D.](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)[![Ryota
    Kiuchi, Ph.D.](../Images/5459c434848898345d932320c4a01312.png)](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)
    [Ryota Kiuchi, Ph.D.](https://rkiuchir.medium.com/?source=post_page---byline--45dd270ee871--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)
    ·13 min read·Jul 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--45dd270ee871--------------------------------)
    ·13 分钟阅读·2024年7月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In recent years, data-driven approaches such as machine learning (ML) and deep
    learning (DL) have been applied to a wide range of tasks including machine translation
    and personal customized recommendations. These technologies reveal some patterns
    within the given training dataset by analyzing numerous data. However, if the
    given dataset has some biases and does not include the data that you want to know
    or predict, it might be difficult to get the correct answer from the trained model.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，数据驱动的方法，如机器学习（ML）和深度学习（DL），已经被应用于广泛的任务，包括机器翻译和个性化推荐。这些技术通过分析大量数据，从给定的训练数据集中揭示出一些模式。然而，如果给定的数据集存在偏差，并且不包含你希望了解或预测的数据，那么从训练后的模型中获得正确答案可能会很困难。
- en: '![](../Images/941658a16eabebab03560ebfa237dbf8.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/941658a16eabebab03560ebfa237dbf8.png)'
- en: Photo by [Stephen Dawson](https://unsplash.com/@dawson2406?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Stephen Dawson](https://unsplash.com/@dawson2406?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Let’s think about the case of ChatGPT. The latest version of ChatGPT at this
    time is ChatGPT 4o, and this model is trained on data until June 2023 (at the
    period of this article). Therefore, if you ask about something that happened in
    2024 not included in the training data, you will not get an accurate answer. This
    is well-known as “hallucination,” and OpenAI added the preprocessing procedure
    to return a fixed answer as “unanswerable” for such kinds of questions. On the
    other hand, ChatGPT’s training data is also basically based on documents written
    in English, so it is not good at local domain knowledge outside of English-native
    countries such as Japan and France. Therefore, many companies and research groups
    put a lot of effort into customizing their LLM by including the region or domain-specific
    knowledge using RAG (Retrieval-Augmented Generation) or fine-tuning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们思考一下ChatGPT的案例。此时最新版本的ChatGPT是ChatGPT 4o，该模型是在2023年6月之前的数据上进行训练的（本文发布时的情况）。因此，如果你询问2024年发生的、训练数据中未包含的事情，你将无法获得准确的答案。这种情况被称为“幻觉”，OpenAI已经增加了预处理程序，在此类问题上返回固定的“无法回答”答案。另一方面，ChatGPT的训练数据基本上是基于英文文档的，因此它在非英语母语国家（如日本和法国）中的地方性领域知识上不太擅长。因此，许多公司和研究团队投入大量精力，通过使用RAG（检索增强生成）或微调，将地区或领域特定的知识融入到他们的LLM中。
- en: Hence, identifying what training data is used is important for understanding
    the applicability and limitations of AI models. On the other hand, one of the
    biggest challenges in data-driven approaches is that these technologies often
    need to perform beyond the range of the training dataset. These demands are typically
    seen in new product development in material science, predicting the effects of
    new pharmaceutical compounds, and predicting consumer behavior when launching
    products in the markets. These scenarios require the correct predictions in the
    sparse area and outside of the training data, which refer to interpolation and
    extrapolation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，识别所使用的训练数据对于理解AI模型的适用性和局限性非常重要。另一方面，数据驱动方法面临的最大挑战之一是，这些技术通常需要在训练数据集的范围之外进行操作。这些需求通常出现在新产品开发、材料科学中的新药物化合物效果预测，以及在市场上推出产品时预测消费者行为等领域。这些场景要求在稀疏区域和训练数据之外做出正确的预测，这涉及到插值和外推。
- en: '![](../Images/4fc75309a8d53d6ae33f3b7315e6bf84.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fc75309a8d53d6ae33f3b7315e6bf84.png)'
- en: Photo by [Elevate](https://unsplash.com/@elevatebeer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Elevate](https://unsplash.com/@elevatebeer?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Interpolation involves making predictions within the known data range. If the
    training data is densely and uniformly distributed, accurate predictions can be
    obtained within that range. However, in practice, preparing such data is uncommon.
    On the other hand, extrapolation refers to making predictions outside the known
    data points’ range. Although predictions in such areas are highly desired, data-driven
    approaches typically struggle the most. Consequently, it is significantly important
    to understand the performance of both interpolation and extrapolation for each
    algorithm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 插值是指在已知数据范围内进行预测。如果训练数据分布密集且均匀，则可以在该范围内获得准确的预测。然而，在实际应用中，准备这种数据并不常见。另一方面，外推是指在已知数据点范围之外进行预测。尽管在这些区域内的预测是高度期望的，但数据驱动的方法通常在此方面最为困难。因此，理解每个算法在插值和外推方面的表现非常重要。
- en: '![](../Images/60d5eb36eebb5fa24ed0c4f4c92269d2.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60d5eb36eebb5fa24ed0c4f4c92269d2.png)'
- en: Created by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者创建
- en: 'This article examines various machine learning algorithms for their interpolation
    and extrapolation capabilities. We prepare an artificial training dataset and
    evaluate these capabilities by visualizing each model’s prediction results. The
    target of machine learning algorithms are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本文考察了各种机器学习算法的插值和外推能力。我们准备了一个人工训练数据集，并通过可视化每个模型的预测结果来评估这些能力。机器学习算法的目标如下：
- en: Symbolic Regressor
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符号回归器
- en: SVR (Support Vector Regression)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVR（支持向量回归）
- en: Gaussian Process Regressor (GPR)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯过程回归器（GPR）
- en: Decision Tree Regressor
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树回归器
- en: Random Forest Regressor
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林回归器
- en: XGBoost
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost
- en: LightGBM
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LightGBM
- en: In addition, we also evaluate ensemble models such as Voting Regressor and Stacking
    Regressor.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还评估了集成模型，如投票回归器和堆叠回归器。
- en: Codes
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Full of codes are available from below:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码请见以下链接：
- en: '[](https://github.com/rkiuchir/blog_TDS/tree/main/02_compare_regression?source=post_page-----45dd270ee871--------------------------------)
    [## blog_TDS/02_compare_regression at main · rkiuchir/blog_TDS'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/rkiuchir/blog_TDS/tree/main/02_compare_regression?source=post_page-----45dd270ee871--------------------------------)
    [## blog_TDS/02_compare_regression at main · rkiuchir/blog_TDS'
- en: Blog Contents for Towards Data Science. Contribute to rkiuchir/blog_TDS development
    by creating an account on GitHub.
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据科学之道博客内容。通过在GitHub上创建帐户，贡献于rkiuchir/blog_TDS的开发。
- en: github.com](https://github.com/rkiuchir/blog_TDS/tree/main/02_compare_regression?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/rkiuchir/blog_TDS/tree/main/02_compare_regression?source=post_page-----45dd270ee871--------------------------------)'
- en: Data Generation and Preprocessing
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据生成与预处理
- en: 'Firstly, we generate the artificial data using a simple nonlinear function
    that is slightly modified from the [symbolic regressor’s tutorial in gplearn](https://gplearn.readthedocs.io/en/stable/examples.html)
    by adding the exponential term. This function consists of linear, quadratic, and
    exponential terms, defined as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用一个简单的非线性函数生成人工数据，该函数是从[gplearn中的符号回归教程](https://gplearn.readthedocs.io/en/stable/examples.html)稍作修改而来，修改部分为添加了指数项。该函数包含线性、二次和指数项，定义如下：
- en: '![](../Images/0172ad132b748c46722140f59278115d.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0172ad132b748c46722140f59278115d.png)'
- en: 'where *x₀* and *x₁* take a range of -1 to 1\. The plane of ground truth is
    as shown below:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*x₀*和*x₁*的范围为-1到1。实际值的平面如下所示：
- en: Since we examine the performance of each ML model in terms of interpolation
    and extrapolation, different datasets will be needed for each case.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在插值和外推方面评估每个机器学习模型的表现，因此每种情况都需要不同的数据集。
- en: For interpolation, we evaluate the model performance within the same range as
    with the training dataset. Thus, each model will be trained with discretized data
    points within the range of -1 to 1 and evaluated the predicted surface within
    the same range.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于插值，我们在与训练数据集相同的范围内评估模型的表现。因此，每个模型都将在-1到1的范围内使用离散化的数据点进行训练，并在相同的范围内评估预测表面。
- en: On the other hand, for extrapolation, the capability of the model within the
    range outside of the training dataset will be required. We will train the model
    using the discretized data points within the range of -0.5 to 1 for both *x₀*
    and *x₁* and assess the predicted surface within the range of -1 to 1\. Consequently,
    the difference between the ground truth and predicted surface in the range of
    -1 to -0.5 for both *x₀* and *x₁* reveals the model capability in terms of extrapolation.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，对于外推，模型在训练数据集范围外的能力是必需的。我们将使用在-0.5到1的范围内离散化的数据点来训练模型，涵盖*x₀*和*x₁*，并在-1到1的范围内评估预测表面。因此，在-1到-0.5的范围内，*x₀*和*x₁*的实际值与预测表面之间的差异揭示了模型在外推方面的能力。
- en: 'In this article, the impact of the number of points for the training dataset
    will also be evaluated by examining two cases: 20 and 100 points.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，还将通过检查20个点和100个点这两种情况，评估训练数据集点数的影响。
- en: 'For example, 100 data points are generated as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，100个数据点如下生成：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Introduction to Machine Learning Algorithms
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法简介
- en: 'In this article, we evaluate the performance of interpolation and extrapolation
    for the major 7 machine learning algorithms. In addition, the 6 ensemble models
    using 7 algorithms are also considered. Each algorithm has different structures
    and aspects, that introduce pros and cons for predicting performance. Here we
    summarize the characteristics of each algorithm as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们评估了七种主要机器学习算法在插值和外推方面的表现。此外，还考虑了使用这七种算法的六种集成模型。每种算法都有不同的结构和特点，这些特点会对预测性能产生优缺点。我们在此总结了每种算法的特点如下：
- en: '**Symbolic Regression**'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**符号回归**'
- en: A trained model is expressed as the mathematical expressions fitted based on
    the genetic algorithms
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练后的模型通过基于遗传算法拟合的数学表达式来表示。
- en: Model is defined as the function, contributing high interpretability
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型被定义为函数，具有很高的可解释性。
- en: Appropriate for the task that target variable can be expressed as a function
    of features
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合于目标变量可以表示为特征函数的任务。
- en: Good at interpolation but may have some potential in extrapolation
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 擅长插值，但在外推方面可能有一定的潜力。
- en: '[](/find-hidden-laws-within-your-data-with-symbolic-regression-ebe55c1a4922?source=post_page-----45dd270ee871--------------------------------)
    [## Find Hidden Laws Within Your Data with Symbolic Regression'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/find-hidden-laws-within-your-data-with-symbolic-regression-ebe55c1a4922?source=post_page-----45dd270ee871--------------------------------)
    [## 使用符号回归发现数据中的隐藏规律'
- en: Automatically discover fundamental formulas like Kepler and Newton
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动发现基本公式，如开普勒定律和牛顿定律
- en: towardsdatascience.com](/find-hidden-laws-within-your-data-with-symbolic-regression-ebe55c1a4922?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/find-hidden-laws-within-your-data-with-symbolic-regression-ebe55c1a4922?source=post_page-----45dd270ee871--------------------------------)
- en: '**2\. Support Vector Regression (SVR)**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 支持向量回归（SVR）**'
- en: Based on a Support Vector Machine (SVM) that can efficiently handle the nonlinear
    relationship in the high dimensional spaces using the kernel method
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于支持向量机（SVM），可以通过核方法有效处理高维空间中的非线性关系
- en: Using different types of kernels such as linear, RBF, polynomial, and sigmoid
    kernels, a model can express complex data patterns
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同类型的核函数，如线性核、RBF核、多项式核和 sigmoid 核，模型可以表达复杂的数据模式
- en: Good at interpolation but less stable in extrapolation
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 擅长插值，但在外推时稳定性较差
- en: '[](/the-complete-guide-to-support-vector-machine-svm-f1a820d8af0b?source=post_page-----45dd270ee871--------------------------------)
    [## The Complete Guide to Support Vector Machine (SVM)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/the-complete-guide-to-support-vector-machine-svm-f1a820d8af0b?source=post_page-----45dd270ee871--------------------------------)
    [## 支持向量机（SVM）完全指南'
- en: Understand its inner workings and implement SVMs in four different scenarios
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解其内部原理，并在四种不同场景下实现支持向量机（SVM）
- en: towardsdatascience.com](/the-complete-guide-to-support-vector-machine-svm-f1a820d8af0b?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/the-complete-guide-to-support-vector-machine-svm-f1a820d8af0b?source=post_page-----45dd270ee871--------------------------------)
- en: '**3\. Gaussian Process Regression (GPR)**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 高斯过程回归（GPR）**'
- en: Based on the Bayesian method, the prediction is expressed as the probability
    which includes the predicted value and its uncertainty
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于贝叶斯方法，预测结果以概率形式表示，包括预测值及其不确定性
- en: Thanks to the uncertainty estimation, GPR used for Bayesian Optimization
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于不确定性估计，GPR 被用于贝叶斯优化
- en: Using different types of kernels such as linear, RBF, polynomial, and sigmoid
    kernels, a model can express complex data patterns
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同类型的核函数，如线性核、RBF核、多项式核和 sigmoid 核，模型可以表达复杂的数据模式
- en: Good at interpolation, and some potential for extrapolation selecting appropriate
    kernel selection
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 擅长插值，选择合适的核函数后，也具有一定的外推潜力
- en: '[](/quick-start-to-gaussian-process-regression-36d838810319?source=post_page-----45dd270ee871--------------------------------)
    [## Quick Start to Gaussian Process Regression'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/quick-start-to-gaussian-process-regression-36d838810319?source=post_page-----45dd270ee871--------------------------------)
    [## 高斯过程回归快速入门'
- en: A quick guide to understanding Gaussian process regression (GPR) and using scikit-learn’s
    GPR package
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一份快速指南，帮助理解高斯过程回归（GPR）并使用 scikit-learn 的 GPR 包
- en: towardsdatascience.com](/quick-start-to-gaussian-process-regression-36d838810319?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/quick-start-to-gaussian-process-regression-36d838810319?source=post_page-----45dd270ee871--------------------------------)
- en: '**4\. Decision Tree**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 决策树**'
- en: Simple tree-shape algorithm which successively splits the data
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的树状算法，通过不断分割数据
- en: Easy to understand and interpret but tends to overfit
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于理解和解释，但容易过拟合
- en: Step-like estimation for interpolation and not good at extrapolation
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤状估计适用于插值，但不擅长外推
- en: '[](/decision-tree-in-machine-learning-e380942a4c96?source=post_page-----45dd270ee871--------------------------------)
    [## Decision Tree in Machine Learning'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/decision-tree-in-machine-learning-e380942a4c96?source=post_page-----45dd270ee871--------------------------------)
    [## 机器学习中的决策树'
- en: A decision tree is a flowchart-like structure in which each internal node represents
    a test on a feature (e.g. whether…
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决策树是一种类似流程图的结构，其中每个内部节点表示对特征的测试（例如是否…
- en: towardsdatascience.com](/decision-tree-in-machine-learning-e380942a4c96?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/decision-tree-in-machine-learning-e380942a4c96?source=post_page-----45dd270ee871--------------------------------)
- en: '**5\. Random Forest**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 随机森林**'
- en: An ensemble-based algorithm which is called “Bagging” consisting of multiple
    decision trees
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种基于集成的算法，称为“Bagging”，由多个决策树组成
- en: By combining multiple diverse trees, this algorithm can reduce overfitting risk
    and have a high interpolation performance
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过结合多个不同的树，该算法能够降低过拟合的风险，并且具有较高的插值性能
- en: More stable predictions than single decision trees but not good at extrapolation
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比单个决策树具有更稳定的预测，但不擅长外推
- en: '[](/understanding-random-forest-58381e0602d2?source=post_page-----45dd270ee871--------------------------------)
    [## Understanding Random Forest'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/understanding-random-forest-58381e0602d2?source=post_page-----45dd270ee871--------------------------------)
    [## 理解随机森林'
- en: How the Algorithm Works and Why it Is So Effective
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法如何工作以及为什么如此有效
- en: towardsdatascience.com](/understanding-random-forest-58381e0602d2?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/understanding-random-forest-58381e0602d2?source=post_page-----45dd270ee871--------------------------------)
- en: '**6\. XGBoost**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. XGBoost**'
- en: An ensemble-based algorithm which is called “Boosting” combines multiple decision
    trees by sequentially reducing errors
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种基于集成的算法，叫做“提升法”，通过顺序减少错误将多个决策树结合起来
- en: Commonly used for competition such as Kaggle because of the good prediction
    performance
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于优秀的预测性能，通常用于Kaggle等竞赛
- en: More stable predictions than single decision trees but not good at extrapolation
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比单个决策树具有更稳定的预测，但不擅长外推
- en: '[](https://medium.com/sfu-cspmp/xgboost-a-deep-dive-into-boosting-f06c9c41349?source=post_page-----45dd270ee871--------------------------------)
    [## XGBoost: A Deep Dive into Boosting'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/sfu-cspmp/xgboost-a-deep-dive-into-boosting-f06c9c41349?source=post_page-----45dd270ee871--------------------------------)
    [## XGBoost：深入了解提升法'
- en: Every day we hear about the breakthroughs in Artificial Intelligence. However,
    have you wondered what challenges it…
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每天我们都听到关于人工智能突破的消息。然而，你有没有想过它面临的挑战是什么……
- en: medium.com](https://medium.com/sfu-cspmp/xgboost-a-deep-dive-into-boosting-f06c9c41349?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/sfu-cspmp/xgboost-a-deep-dive-into-boosting-f06c9c41349?source=post_page-----45dd270ee871--------------------------------)
- en: '**7\. LightGBM**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. LightGBM**'
- en: Similar to XGBoost, but with faster training speed and memory efficiency, which
    is more suitable for the larger datasets
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于XGBoost，但具有更快的训练速度和更高的内存效率，更适用于较大的数据集
- en: More stable predictions than single decision trees but not good at extrapolation
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比单个决策树具有更稳定的预测，但不擅长外推
- en: '[](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc?source=post_page-----45dd270ee871--------------------------------)
    [## What is LightGBM, How to implement it? How to fine tune the parameters?'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc?source=post_page-----45dd270ee871--------------------------------)
    [## 什么是LightGBM，如何实现它？如何调整参数？'
- en: Hello,
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你好，
- en: medium.com](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc?source=post_page-----45dd270ee871--------------------------------)
- en: '**8\. Voting Regressor**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**8\. 投票回归器**'
- en: An ensemble learning method combining predictions from multiple models
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种集成学习方法，通过结合多个模型的预测进行预测
- en: Mixing different model characteristics, which contribute to more robust predictions
    than a single model
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合不同模型的特性，能提供比单一模型更稳健的预测
- en: 'Evaluated in three combinations in this article:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本文中评估了三种组合：
- en: – Support Vector Regressor + Random Forest
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 支持向量回归器 + 随机森林
- en: – Gaussian Process Regressor + Random Forest
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 高斯过程回归器 + 随机森林
- en: – Random Forest + XGBoost
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 随机森林 + XGBoost
- en: '[](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
    [## VotingRegressor'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
    [## VotingRegressor'
- en: 'Gallery examples: Plot individual and voting regression predictions'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例图库：绘制单个和投票回归预测
- en: scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
- en: '**9\. Stacking Regressor**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**9\. 堆叠回归器**'
- en: An ensemble learning method that uses predictions from multiple models as input
    for a final prediction model, “meta-model”
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种集成学习方法，使用多个模型的预测作为最终预测模型的输入，称为“元模型”
- en: Meta model covers individual model weaknesses and combines each model's strengths
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元模型覆盖单个模型的弱点，并结合每个模型的优点
- en: 'Evaluated in three combinations in this article:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本文中评估了三种组合：
- en: '– Base model: Support Vector Regressor + Random Forest; Meta-model: Random
    Forest'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 基础模型：支持向量回归 + 随机森林；元模型：随机森林
- en: '– Base model: Gaussian Process Regressor + Random Forest; Meta-model: Random
    Forest'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 基础模型：高斯过程回归 + 随机森林；元模型：随机森林
- en: '– Base model: Random Forest + XGBoost; Meta-model: Random Forest'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 基础模型：随机森林 + XGBoost；元模型：随机森林
- en: '[](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
    [## StackingRegressor'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
    [## StackingRegressor'
- en: 'Gallery examples: Combine predictors using stacking'
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 画廊示例：使用堆叠法组合预测器
- en: scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html?source=post_page-----45dd270ee871--------------------------------)'
- en: Using these algorithms, we will evaluate both interpolation and extrapolation
    performance with the dataset we generated earlier. In the following sections,
    the training methods and evaluation approaches for each model will be explained.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些算法，我们将评估使用我们之前生成的数据集的插值和外推性能。在接下来的部分中，将解释每个模型的训练方法和评估方法。
- en: Model Training and Evaluation
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练与评估
- en: Preprocessing
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理
- en: Basically, except for tree-based approaches such as Random Forest, XGBoost,
    and LightGBM, most machine learning algorithms require feature scaling. However,
    since we only use two features such as *x₀* and *x₁* which take the same range,
    -1 to 1 (interpolation) or -0.5 to 1 (extrapolation) in this practice, we will
    skip the feature scaling.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，除了基于树的方法，如随机森林、XGBoost 和 LightGBM，大多数机器学习算法都需要特征缩放。然而，由于我们在这个实践中只使用了两个特征，如*x₀*和*x₁*，它们的范围相同，分别为-1到1（插值）或-0.5到1（外推），因此我们将跳过特征缩放。
- en: Model Training
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: For simplicity, the default hyper parameters are used for all algorithms except
    LightGBM of which default parameters are suitable for the larger dataset.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为简化起见，除 LightGBM 外，所有算法都使用默认超参数，LightGBM 的默认参数适用于较大的数据集。
- en: As introduced in the earlier section, we will use different datasets for the
    evaluation of interpolation and extrapolation during model training.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将在模型训练期间使用不同的数据集来评估插值和外推。
- en: Evaluation and Visualization
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估与可视化
- en: After model training, we will predict using very finely discretized data. Based
    on these predicted values, the prediction surface will be drawn using the [Plotly
    surface function](https://plotly.com/python/3d-surface-plots/).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练后，我们将使用非常细致的数据进行预测。基于这些预测值，将使用[Plotly表面函数](https://plotly.com/python/3d-surface-plots/)绘制预测曲面。
- en: 'These procedures are done by the following code:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过程由以下代码完成：
- en: '[PRE1]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Evaluation of Interpolation Performance
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 插值性能评估
- en: The prediction surfaces for each algorithm are shown for training data cases
    of 100 and 20 points respectively.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 每个算法的预测曲面分别展示了100个和20个训练数据点的情况。
- en: '100 Training Points:'
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 100 个训练点：
- en: The original interactive figures can be viewed from [here](https://chart-studio.plotly.com/~rkiuchi/87)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 原始交互式图形可以从[这里](https://chart-studio.plotly.com/~rkiuchi/87)查看
- en: '![](../Images/d6738a6729ec30307118a6d37ce47b23.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6738a6729ec30307118a6d37ce47b23.png)'
- en: '20 Training Points:'
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20 个训练点：
- en: The original interactive figures can be viewed from [here](https://chart-studio.plotly.com/~rkiuchi/89)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 原始交互式图形可以从[这里](https://chart-studio.plotly.com/~rkiuchi/89)查看
- en: '![](../Images/a5f138d525a873a3a2daeb3f6986afb3.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5f138d525a873a3a2daeb3f6986afb3.png)'
- en: 'Here are the summarized features for each algorithm:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是每个算法的总结特征：
- en: Symbolic Regressor
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号回归
- en: This algorithm performs almost perfectly in interpolation with 100 data points,
    but moderately good with 20 data points. This is because the Symbolic Regressor
    approximates the mathematical expressions and the simple functional form is used
    in this practice. Thanks to this feature, the predicted surface is notably smooth
    which is different from the tree-based algorithms explained later.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法在使用100个数据点进行插值时几乎完美，但在使用20个数据点时表现中等。这是因为符号回归近似数学表达式，并且在这个实践中使用了简单的函数形式。由于这个特性，预测曲面显得特别平滑，这与后面介绍的基于树的算法有所不同。
- en: Support Vector Regressor (SVR), Gaussian Process Regressor (GPR)
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量回归（SVR）、高斯过程回归（GPR）
- en: For kernel-based algorithms SVR and GPR, although the predicted surfaces slightly
    differ from the ground truth, interpolation performance is generally good with
    100 data points. In addition, the prediction surface obtained from these models
    is smooth similar to one estimated by Symbolic Regressor. However, in the case
    of 20 points, there is a significant difference between the predicted surface
    and the ground truth especially for SVR.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于核的算法SVR和GPR，尽管预测的表面与真实值略有不同，但在100个数据点的情况下，插值性能通常较好。此外，这些模型得到的预测表面平滑，类似于符号回归器估算的表面。然而，在20个数据点的情况下，尤其是对于SVR，预测表面与真实值之间存在显著差异。
- en: Decision Tree, Random Forest, XGBoost, LightGBM
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树、随机森林、XGBoost、LightGBM
- en: Firstly, the prediction surfaces estimated by these five tree-based models are
    not smooth but more step-like shapes. This characteristic arises from the structure
    and learning method of decision trees. Decision trees split the data recursively
    based on a threshold for one of the features. Each data point is assigned to some
    leaf nodes whose values are represented as the average value of the data points
    in that node. Therefore, the prediction values are constant within each leaf node,
    resulting in a step-like prediction surface.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这五个基于树的模型估算的预测表面并不平滑，而是呈现出更多阶梯状的形态。这一特征源于决策树的结构和学习方法。决策树通过基于某一特征的阈值递归地划分数据。每个数据点会被分配到某个叶节点，节点内的值表示该节点中数据点的平均值。因此，预测值在每个叶节点内是恒定的，导致了阶梯状的预测表面。
- en: The estimates of a single decision tree clearly show this characteristic. On
    the other hand, ensemble methods like Random Forests, XGBoost, and LightGBM, which
    consist of many decision trees within a single model, generate relatively smoother
    prediction surfaces due to the more different thresholds based on the many different
    shapes of decision trees.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 单个决策树的估算清楚地展示了这一特性。另一方面，像随机森林、XGBoost和LightGBM等集成方法，由于每个模型内部包含许多决策树，生成的预测表面相对平滑，因为许多不同形状的决策树基于不同的阈值。
- en: Voting Regressor, Stacking Regressor
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Voting Regressor, Stacking Regressor
- en: The Voting Regressor combines the results of two algorithms by averaging them.
    For combinations like Random Forest + SVR, and Random Forest + GPR, the prediction
    surfaces reflect characteristics that mix the kernel-based and tree-based models.
    On the other hand, the combination of tree-based models like Random Forest and
    XGBoost relatively reduces the step-like shape prediction surface than one estimated
    from the single model.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Voting Regressor通过平均两个算法的结果来组合它们。对于如随机森林+SVR和随机森林+GPR的组合，预测表面反映了基于核和基于树的模型特性的混合。另一方面，像随机森林和XGBoost这样的树基模型组合相较于单一模型估算的预测表面，相对减少了阶梯状形态。
- en: The Stacking Regressor, which uses a meta-model to compute final predictions
    based on the outputs of multiple models, also shows step-like surfaces, because
    of the Random Forest used as the meta-model. This characteristic will be changed
    if kernel-based algorithms like SVR or GPR are used as the meta-model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Stacking Regressor使用一个元模型基于多个模型的输出计算最终预测，表现出阶梯状的预测表面，因为其元模型使用的是随机森林。若使用基于核的算法，如SVR或GPR，作为元模型，则此特性会发生变化。
- en: Evaluation of Extrapolation Performance
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 外推性能评估
- en: As explained earlier, each model is trained with data ranging from -0.5 to 1
    for both *x₀* and *x₁* and those performances will be evaluated within the range
    of -1 to 1\. Therefore, we get to know the extrapolation ability to inspect the
    prediction surface with the range of -1 to -0.5 for both *x₀* and *x₁.*
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，每个模型的训练数据都包含 *x₀* 和 *x₁* 范围从 -0.5 到 1 的值，且这些性能将在 -1 到 1 的范围内进行评估。因此，我们可以通过检查预测表面在
    *x₀* 和 *x₁* 范围从 -1 到 -0.5 的外推能力来了解模型的外推表现。
- en: The prediction surfaces for each algorithm are shown for training data cases
    of 100 and 20 points respectively.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 每个算法的预测表面分别显示了100和20个训练数据点的情况。
- en: '100 Training Points:'
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 100个训练点：
- en: The original interactive figures can be viewed from [here](https://chart-studio.plotly.com/~rkiuchi/91)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的互动图表可以从[这里](https://chart-studio.plotly.com/~rkiuchi/91)查看
- en: '![](../Images/a2352079e0966edba848a71e21f702ba.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2352079e0966edba848a71e21f702ba.png)'
- en: '20 Training Points:'
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20个训练点：
- en: The original interactive figures can be viewed from [here](https://chart-studio.plotly.com/~rkiuchi/93)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的互动图表可以从[这里](https://chart-studio.plotly.com/~rkiuchi/93)查看
- en: '![](../Images/8b2bef5db2a4e1cf26276c879f3848cf.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b2bef5db2a4e1cf26276c879f3848cf.png)'
- en: Symbolic Regressor
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号回归器
- en: The predicted surface within the area of extrapolation obtained by the Symbolic
    Regressor which is trained with 100 data points is almost accurately estimated
    similar to the interpolation evaluation. However, with only 20 training data points
    used, the predicted surface differs from the ground truth especially in the edge
    of the surface, indicating that the obtained functional form is not well estimated.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用100个数据点训练的符号回归器在外推范围内获得的预测曲面几乎与插值评估相似，准确地估算。然而，仅使用20个训练数据点时，预测曲面与真实值存在较大差异，尤其是在曲面边缘，表明得到的函数形式估算不准确。
- en: Support Vector Regressor (SVR), Gaussian Process Regressor (GPR)
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量回归器（SVR），高斯过程回归器（GPR）
- en: Although both SVR and GPR are kernel-based algorithms, the obtained results
    are totally different. For both of 20 and 100 data points, while the predicted
    surface from SVR is well not estimated, GPR predicts almost perfectly even within
    the range of extrapolation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管SVR和GPR都是基于核的算法，但得到的结果完全不同。对于20个和100个数据点，SVR的预测曲面估算得不理想，而GPR即使在外推范围内也几乎完美地预测了。
- en: Decision Tree, Random Forest, XGBoost, LightGBM
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树，随机森林，XGBoost，LightGBM
- en: Although there are some differences among the results from these tree-based
    models, the predicted surfaces are constant in the range of extrapolation. This
    is because that decision trees rely on splits and no splits are generated in extrapolation
    regions, which cause constant values.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些基于树的模型的结果存在一些差异，但在外推范围内的预测曲面是稳定的。这是因为决策树依赖于分割，而在外推区域没有生成分割，这导致了常数值。
- en: Voting Regressor, Stacking Regressor
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 投票回归器，堆叠回归器
- en: As seen above, the kernel-based algorithms have better performance compared
    to the tree-based ones. The Voting Regressor with the combination of Random Forest
    and XGBoost, and all three Stacking Regressors whose meta-model is Random Forest
    predict constant in the range of extrapolation. On the other hand, the prediction
    surfaces derived from the Voting Regressor with the combination of Random Forest
    + SVR, and Random Forest + GPR have the blended characteristics of kernel-based
    and tree-based models.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，基于核的算法相比于基于树的算法具有更好的性能。结合随机森林和XGBoost的投票回归器，以及所有三个以随机森林为元模型的堆叠回归器在外推范围内预测稳定。另一方面，结合随机森林+SVR和随机森林+GPR的投票回归器的预测曲面，具有基于核和基于树的模型的混合特征。
- en: Summary
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we evaluated the interpolation and extrapolation performance
    of the various machine learning algorithms. Since the ground truth data we used
    is expressed as a simple functional foam, symbolic regressor and kernel-based
    algorithms provide a better performance, especially for extrapolation than tree-based
    algorithms. However, more complex tasks that cannot be expressed in mathematical
    formulas might bring different results.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们评估了各种机器学习算法的插值和外推性能。由于我们使用的真实数据是以简单的函数形式表示的，符号回归器和基于核的算法在外推方面提供了比基于树的算法更好的性能。然而，对于无法通过数学公式表达的更复杂任务，可能会得出不同的结果。
- en: Thank you so much for reading this article! I hope this article helps you understand
    the interpolation and extrapolation performance of machine learning models, making
    it easier to select and apply the right models for your projects.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢阅读这篇文章！希望这篇文章能帮助你理解机器学习模型的插值和外推性能，使你更容易为你的项目选择和应用合适的模型。
- en: '***Your clap to this article and subscription to*** [***my newsletter***](https://rkiuchir.medium.com/subscribe)
    ***would motivate me a lot!***'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '***你对这篇文章的点赞和对*** [***我的新闻通讯***](https://rkiuchir.medium.com/subscribe) ***的订阅将给我带来极大的动力！***'
- en: Links
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链接
- en: Other articles
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他文章
- en: '[](/how-openais-sora-is-changing-the-game-an-insight-into-its-core-technologies-bd1ad17170df?source=post_page-----45dd270ee871--------------------------------)
    [## How OpenAI’s Sora is Changing the Game: An Insight into Its Core Technologies'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-openais-sora-is-changing-the-game-an-insight-into-its-core-technologies-bd1ad17170df?source=post_page-----45dd270ee871--------------------------------)
    [## OpenAI的Sora如何改变游戏规则：深入了解其核心技术'
- en: A masterpiece of state of the art technologies
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一项尖端技术的杰作
- en: towardsdatascience.com](/how-openais-sora-is-changing-the-game-an-insight-into-its-core-technologies-bd1ad17170df?source=post_page-----45dd270ee871--------------------------------)
    [](/create-interactive-globe-earthquake-plot-in-python-b0b52b646f27?source=post_page-----45dd270ee871--------------------------------)
    [## Create “Interactive Globe + Earthquake Plot in Python
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-openais-sora-is-changing-the-game-an-insight-into-its-core-technologies-bd1ad17170df?source=post_page-----45dd270ee871--------------------------------)
    [](/create-interactive-globe-earthquake-plot-in-python-b0b52b646f27?source=post_page-----45dd270ee871--------------------------------)
    [## 在 Python 中创建“交互式地球仪 + 地震图”
- en: 'How to create a cool interactive figure in Python: the Globe plotted by Plotly.'
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在 Python 中创建一个酷炫的交互式图形：由 Plotly 绘制的地球仪。
- en: towardsdatascience.com](/create-interactive-globe-earthquake-plot-in-python-b0b52b646f27?source=post_page-----45dd270ee871--------------------------------)
    [](/pandas-cheat-sheet-for-data-preprocessing-cd1bcd607426?source=post_page-----45dd270ee871--------------------------------)
    [## Pandas Cheat Sheet for Data Preprocessing
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/create-interactive-globe-earthquake-plot-in-python-b0b52b646f27?source=post_page-----45dd270ee871--------------------------------)
    [](/pandas-cheat-sheet-for-data-preprocessing-cd1bcd607426?source=post_page-----45dd270ee871--------------------------------)
    [## Pandas 数据预处理备忘单
- en: Practical guide about how to preprocess data with Pandas
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于如何使用 Pandas 预处理数据的实用指南
- en: towardsdatascience.com](/pandas-cheat-sheet-for-data-preprocessing-cd1bcd607426?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/pandas-cheat-sheet-for-data-preprocessing-cd1bcd607426?source=post_page-----45dd270ee871--------------------------------)
- en: Personal website
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 个人网站
- en: '[](https://rkiuchir.github.io/?source=post_page-----45dd270ee871--------------------------------)
    [## R. Kiuchi — Seismology'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rkiuchir.github.io/?source=post_page-----45dd270ee871--------------------------------)
    [## R. Kiuchi — 地震学'
- en: Edit description
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编辑描述
- en: rkiuchir.github.io](https://rkiuchir.github.io/?source=post_page-----45dd270ee871--------------------------------)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: rkiuchir.github.io](https://rkiuchir.github.io/?source=post_page-----45dd270ee871--------------------------------)
