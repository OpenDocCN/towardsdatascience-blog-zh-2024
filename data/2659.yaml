- en: Minimum Viable MLE
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小可行机器学习模型（MLE）
- en: 原文：[https://towardsdatascience.com/minimum-viable-mle-306877dd6030?source=collection_archive---------9-----------------------#2024-10-31](https://towardsdatascience.com/minimum-viable-mle-306877dd6030?source=collection_archive---------9-----------------------#2024-10-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/minimum-viable-mle-306877dd6030?source=collection_archive---------9-----------------------#2024-10-31](https://towardsdatascience.com/minimum-viable-mle-306877dd6030?source=collection_archive---------9-----------------------#2024-10-31)
- en: Building a minimal production-ready sentiment analysis model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个最小化的生产就绪情感分析模型
- en: '[](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)[![Lenix
    Carter](../Images/d25c86c00d6b2ee64b70cae8297fd761.png)](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)
    [Lenix Carter](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)[![Lenix
    Carter](../Images/d25c86c00d6b2ee64b70cae8297fd761.png)](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)
    [Lenix Carter](https://medium.com/@lenixc210?source=post_page---byline--306877dd6030--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)
    ·7 min read·Oct 31, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--306877dd6030--------------------------------)
    ·阅读时长7分钟·2024年10月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/27789732b7a4449b4ff94b4e82876275.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27789732b7a4449b4ff94b4e82876275.png)'
- en: Photo by [Stephen Dawson](https://unsplash.com/@dawson2406?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Stephen Dawson](https://unsplash.com/@dawson2406?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: What is a production-ready model?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是生产就绪模型？
- en: We hear a lot about productionized machine learning, but what does it really
    mean to have a model that can thrive in real-world applications?There are plenty
    of things that go into, and contribute, to the efficacy of a machine learning
    model in production. For the sake of this article we will be focusing on five
    of them.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常听到“生产化的机器学习”，但要让模型在实际应用中茁壮成长究竟意味着什么呢？在生产中，许多因素都影响并有助于机器学习模型的效能。为了本文的目的，我们将重点关注其中的五个因素。
- en: '**Reproducibility**'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可复现性**'
- en: '**Monitoring**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**'
- en: '**Testing**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试**'
- en: '**Automation**'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化**'
- en: '**Version Control**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制**'
- en: Serving Inferences
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提供推断
- en: The most important part of building a production-ready machine learning model
    is being able to access it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 构建生产就绪机器学习模型最重要的部分是能够访问它。
- en: For this purpose, we build a fastapi client that serves sentiment analysis responses.
    We utilize pydantic to ensure structure for the input and output. The model that
    we use is the base sentiment analysis pipeline from huggingface’s transformers
    library, allowing us to begin testing with a pre-trained model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们构建了一个FastAPI客户端，用于提供情感分析的响应。我们利用Pydantic来确保输入和输出的结构化。我们使用的模型是来自Huggingface的Transformers库中的基本情感分析管道，这使我们能够使用预训练模型开始进行测试。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To ensure that our work is reproducible, we can use a requirements.txt file
    and pip.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们的工作是可复现的，我们可以使用requirements.txt文件和pip。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To install this, initialize [venv in your files](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)
    and run:`pip install -r requirements.txt`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装此项，请初始化[您的文件中的venv](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)并运行：`pip
    install -r requirements.txt`。
- en: 'To host this API simply run: `uvicorn main:app --reload`.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要托管此API，只需运行：`uvicorn main:app --reload`。
- en: 'Now you have an api that you can query using:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您拥有一个可以通过以下方式查询的API：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: or any API tool you wish (i.e. [Postman](https://www.postman.com/)). You should
    get a result back that includes the text query, the sentiment predicted, and the
    confidence of the prediction.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您想要的任何API工具（即[Postman](https://www.postman.com/)）。您应该能收到一个返回结果，其中包括文本查询、预测的情感以及预测的置信度。
- en: We will be using GitHub for CI/CD later, so I would recommend [initializing
    and using git in this directory](https://git-scm.com/docs/gittutorial).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后将使用 GitHub 进行 CI/CD，因此我建议在此目录中[初始化并使用 git](https://git-scm.com/docs/gittutorial)。
- en: We now have a locally hosted machine learning inference API.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个本地托管的机器学习推理 API。
- en: Further Improving Reproducibility
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步提高可复现性
- en: To allow our code to have more consistent execution, we will utilize Docker.
    Docker simulates a lightweight environment that allows applications to run in
    isolated containers, similar to virtual machines. This isolation ensures that
    applications can execute consistently across any computer with Docker installed,
    regardless of the underlying system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们的代码能够更一致地执行，我们将使用 Docker。Docker 模拟了一个轻量级的环境，允许应用程序在隔离的容器中运行，类似于虚拟机。这种隔离确保应用程序能够在任何安装了
    Docker 的计算机上稳定执行，而不受底层系统的影响。
- en: Firstly, [set up Docker for your given operating system.](https://docs.docker.com/desktop/)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，[为你的操作系统设置 Docker](https://docs.docker.com/desktop/)。
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: At this point, you should have the directory as below.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该拥有如下的目录结构。
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, you can build the image and run this API using:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以构建镜像并使用以下命令运行这个 API：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You should now be able to query just as you did before.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该能够像之前一样进行查询。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We now have a containerized, locally hosted machine learning inference API.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有一个容器化的、本地托管的机器学习推理 API。
- en: Adding Basic Monitoring
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加基础监控
- en: In machine learning applications, monitoring is crucial for understanding model
    performance and ensuring it meets expected accuracy and efficiency. Tools like
    [Prometheus](https://prometheus.io/docs/tutorials/getting_started/) help track
    metrics such as prediction latency, request counts, and model output distributions,
    enabling you to identify issues like model drift or resource bottlenecks. This
    proactive approach ensures that your ML models remain effective over time and
    can adapt to changing data or usage patterns. In our case, we are focused on prediction
    time, requests, and gathering information about our queries.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习应用中，监控对于理解模型性能以及确保其达到预期的准确性和效率至关重要。像[Prometheus](https://prometheus.io/docs/tutorials/getting_started/)这样的工具帮助跟踪诸如预测延迟、请求计数和模型输出分布等指标，使你能够识别诸如模型漂移或资源瓶颈等问题。这种主动的方法确保你的机器学习模型随着时间的推移保持有效，并能够适应不断变化的数据或使用模式。在我们的案例中，我们专注于预测时间、请求和收集查询信息。
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Utilizing a Custom Model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用自定义模型
- en: While the process of building and fine-tuning a model is not the intent of this
    project, it is important to understand how a model can be added to this process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管构建和微调模型的过程并不是本项目的目的，但理解如何将模型添加到此过程中非常重要。
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To make sure that we can query our new model that we have trained we have to
    update a few of our existing files. For instance, in `main.py` we now use the
    model from `./model` and load it as a pretrained model. Additionally, for comparison’s
    sake, we add now have two endpoints to use, `/predict/naive` and `predict/trained`.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们能够查询我们训练的新模型，我们需要更新一些现有的文件。例如，在`main.py`中，我们现在使用来自`./model`的模型，并将其加载为预训练模型。此外，为了对比，我们现在有两个可用的端点，`/predict/naive`和`predict/trained`。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We also must update our Dockerfile to include our model files.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须更新我们的 Dockerfile，以包含我们的模型文件。
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Importantly, if you are using git, make sure that you add the `pytorch_model.bin`
    file to [git lfs](https://git-lfs.com/), so that you can push to GitHub. git lfs
    allows you to use version control on very large files.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，如果你使用 git，确保将`pytorch_model.bin`文件添加到[git lfs](https://git-lfs.com/)，这样你就可以推送到
    GitHub。git lfs 允许你对非常大的文件使用版本控制。
- en: Adding Testing and CI/CD
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加测试和 CI/CD
- en: CI/CD and testing streamline the deployment of machine learning models by ensuring
    that code changes are automatically integrated, tested, and deployed, which reduces
    the risk of errors and enhances model reliability. This process promotes continuous
    improvement and faster iteration cycles, allowing teams to deliver high-quality,
    production-ready models more efficiently. Firstly, we create two very basic tests
    to ensure that our model is performing acceptably.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD 和测试通过确保代码更改自动集成、测试和部署，从而简化了机器学习模型的部署，这减少了错误的风险并提高了模型的可靠性。这个过程促进了持续改进和更快的迭代周期，使团队能够更高效地交付高质量、准备投入生产的模型。首先，我们创建了两个非常基础的测试，确保我们的模型表现得足够好。
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To test your code, you can simply run `pytest` or `python -m pytest` while your
    endpoint is running.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试你的代码，你可以在端点运行时简单地执行`pytest`或`python -m pytest`。
- en: However, we will add automated testing CI/CD (continuous integration and continuous
    delivery) when pushed to GitHub.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当推送到 GitHub 时，我们将添加自动化测试 CI/CD（持续集成与持续交付）。
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Our final project structure should appear as below.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终的项目结构应如下所示。
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now, whenever we push to GitHub, it will run an automated process that checks
    out the code, sets up a Python 3.9 environment, installs dependencies, and runs
    our tests using pytest.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当我们推送到 GitHub 时，它将运行一个自动化过程，检出代码，设置 Python 3.9 环境，安装依赖，并使用 pytest 运行我们的测试。
- en: Conclusion
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this project, we’ve developed a production-ready sentiment analysis API that
    highlights key aspects of deploying machine learning models. While it doesn’t
    encompass every facet of the field, it provides a representative sampling of essential
    tasks involved in the process. By examining these components, I hope to clarify
    concepts you may have encountered but weren’t quite sure how they fit together
    in a practical setting.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们开发了一个生产就绪的情感分析 API，突出了部署机器学习模型的关键方面。虽然它并不涵盖该领域的每个方面，但它提供了涉及这一过程的基本任务的代表性样本。通过检查这些组件，我希望能澄清你可能遇到过的概念，但不确定它们如何在实际环境中配合工作。
