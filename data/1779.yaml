- en: LangChain’s Parent Document Retriever — Revisited
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain的父文档检索器 — 重新审视
- en: 原文：[https://towardsdatascience.com/langchains-parent-document-retriever-revisited-1fca8791f5a0?source=collection_archive---------4-----------------------#2024-07-22](https://towardsdatascience.com/langchains-parent-document-retriever-revisited-1fca8791f5a0?source=collection_archive---------4-----------------------#2024-07-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/langchains-parent-document-retriever-revisited-1fca8791f5a0?source=collection_archive---------4-----------------------#2024-07-22](https://towardsdatascience.com/langchains-parent-document-retriever-revisited-1fca8791f5a0?source=collection_archive---------4-----------------------#2024-07-22)
- en: Enhance retrieval with context using your vector database only
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅使用你的向量数据库增强上下文检索
- en: '[](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)[![Omri
    Eliyahu Levy](../Images/7200edb7c45b097970034fc6f740a8bd.png)](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)
    [Omri Eliyahu Levy](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)[![Omri
    Eliyahu Levy](../Images/7200edb7c45b097970034fc6f740a8bd.png)](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)
    [Omri Eliyahu Levy](https://medium.com/@omri-levy?source=post_page---byline--1fca8791f5a0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)
    ·6 min read·Jul 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1fca8791f5a0--------------------------------)
    ·6分钟阅读·2024年7月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '**TL;DR** — We achieve the same functionality as LangChains’ Parent Document
    Retriever ([link](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/))
    by utilizing metadata queries. You can explore the code [here](https://gist.github.com/omriel1/7243ce233eb2986ed2749de6ae79ecb7).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**TL;DR** — 我们通过使用元数据查询实现与LangChain的父文档检索器相同的功能（[链接](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/)）。你可以在[这里](https://gist.github.com/omriel1/7243ce233eb2986ed2749de6ae79ecb7)查看代码。'
- en: Introduction to RAG
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG简介
- en: Retrieval-augmented generation (RAG) is currently one of the hottest topics
    in the world of LLM and AI applications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）目前是LLM和AI应用领域最热门的话题之一。
- en: 'In short, RAG is a technique for grounding a generative models’ response on
    chosen knowledge sources. It comprises two phases: retrieval and generation.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，RAG是一种将生成模型的响应基于选定知识源进行“立足”的技术。它包括两个阶段：检索和生成。
- en: In the retrieval phase, given a user’s query, we retrieve pieces of relevant
    information from a predefined knowledge source.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在检索阶段，给定用户的查询，我们从预定义的知识源中检索相关信息。
- en: Then, we insert the retrieved information into the prompt that is sent to an
    LLM, which (ideally) generates an answer to the user’s question based on the provided
    context.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将检索到的信息插入到发送给LLM的提示中，该模型（理想情况下）根据提供的上下文生成对用户问题的回答。
- en: A commonly used approach to achieve efficient and accurate retrieval is through
    the usage of embeddings. In this approach, we preprocess users’ data (let’s assume
    plain text for simplicity) by splitting the documents into chunks (such as pages,
    paragraphs, or sentences). We then use an embedding model to create a meaningful,
    numerical representation of these chunks, and store them in a vector database.
    Now, when a query comes in, we embed it as well and perform a similarity search
    using the vector database to retrieve the relevant information
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常用的方法来实现高效准确的检索是通过使用嵌入。在这种方法中，我们通过将文档拆分成块（例如页面、段落或句子）来预处理用户的数据（假设为纯文本）。然后，我们使用嵌入模型为这些块创建有意义的数值表示，并将它们存储在向量数据库中。现在，当查询到来时，我们也对其进行嵌入，并使用向量数据库执行相似性搜索，以检索相关信息。
- en: '![](../Images/bba1888e550d749b3f7d751f75b4661a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bba1888e550d749b3f7d751f75b4661a.png)'
- en: Image by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'If you are completely new to this concept, I’d recommend [deeplearning.ai](https://www.deeplearning.ai/)
    great course, [LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您完全不熟悉这个概念，我推荐[deeplearning.ai](https://www.deeplearning.ai/)的精彩课程，[LangChain:
    与您的数据对话](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)。'
- en: What is “Parent Document Retrieval”?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是“父文档检索”？
- en: “Parent Document Retrieval” or “Sentence Window Retrieval” as referred by others,
    is a common approach to enhance the performance of retrieval methods in RAG by
    providing the LLM with a broader context to consider.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “父文档检索”或其他人所称的“句子窗口检索”，是一种通过提供更广泛的上下文供 LLM 考虑来增强 RAG 检索方法性能的常见方法。
- en: In essence, we divide the original documents into relatively small chunks, embed
    each one, and store them in a vector database. Using such small chunks (a sentence
    or a couple of sentences) helps the embedding models to better reflect their meaning
    [1].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们将原始文档分成相对较小的块，嵌入每一个块，并将它们存储在向量数据库中。使用这些小块（一句话或几句话）有助于嵌入模型更好地反映其含义[1]。
- en: Then, **at retrieval time, we do not return the most similar chunk as found
    by the vector database only, but also its surrounding context** (chunks) **in
    the original document**. That way, the LLM will have a broader context, which,
    in many cases, helps generate better answers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，**在检索时，我们不仅返回由向量数据库找到的最相似块，还返回其在原文档中的周围上下文**（块）**。这样，LLM 将拥有更广泛的上下文，在许多情况下有助于生成更好的答案。**
- en: 'LangChain supports this concept via Parent Document Retriever [2]. The Parent
    Document Retriever allows you to: (1) retrieve the full document a specific chunk
    originated from, or (2) pre-define a larger “parent” chunk, for each smaller chunk
    associated with that parent.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 通过父文档检索器[2]支持这一概念。父文档检索器允许您：(1) 检索特定块来源的完整文档，或 (2) 为与父文档关联的每个较小块预先定义一个更大的“父”块。
- en: 'Let’s explore the example from [LangChains’ docs](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从[LangChains 文档](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/)中探讨一个例子：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In my opinion, there are two disadvantages of the LangChains’ approach:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，LangChains 方法有两个缺点：
- en: The need to manage external storage to benefit from this useful approach, either
    in memory or another persistent store. Of course, for real use cases, the InMemoryStore
    used in the various examples will not suffice.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要管理外部存储，以便利用这一有用的方法，无论是内存还是其他持久化存储。当然，对于真实的使用案例，多个示例中使用的 InMemoryStore 是不够的。
- en: The “parent” retrieval isn’t dynamic, meaning we cannot change the size of the
    surrounding window on the fly.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “父文档”检索不是动态的，意味着我们无法动态调整周围窗口的大小。
- en: Indeed, a few questions have been raised regarding this issue [3].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，关于这个问题已经提出了一些问题[3]。
- en: Here I’ll also mention that Llama-index has its own [SentenceWindowNodeParser](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/)
    [4], which generally has the same disadvantages.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我还要提到，Llama-index 有自己的[SentenceWindowNodeParser](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/)
    [4]，它通常具有相同的缺点。
- en: In what follows, I’ll present another approach to achieve this useful feature
    that addresses the two disadvantages mentioned above. In this approach, we’ll
    be only using the vector store that is already in use.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将介绍另一种方法，以实现这个有用的功能，并解决上述提到的两个缺点。在这种方法中，我们将仅使用已经在使用的向量存储。
- en: Alternative Implementation
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代实现
- en: To be precise, we’ll be using a vector store that supports the option to perform
    metadata queries only, without any similarity search involved. Here, I’ll present
    an implementation for **ChromaDB** and **Milvus**. This concept can be easily
    adapted to any vector database with such capabilities. I’ll refer to **Pinecone**
    for example in the end of this tutorial.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 精确地说，我们将使用支持仅执行元数据查询选项的向量存储，而不涉及任何相似性搜索。在这里，我将为**ChromaDB**和**Milvus**呈现一个实现示例。这个概念可以轻松适配任何具备此功能的向量数据库。在本教程的最后，我将以**Pinecone**为例进行说明。
- en: '**The general concept**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般概念**'
- en: 'The concept is straightforward:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念很简单：
- en: '**Construction:** Alongside each chunk, save in its metadata the *document_id*
    it was generated from and also the *sequence_number* of the chunk.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建：**在每个块旁边，保存其元数据中生成该块的*document_id*，以及该块的*sequence_number*。'
- en: '**Retrieval:** After performing the usual similarity search (assuming for simplicity
    only the top 1 result), we obtain the *document_id* and the *sequence_number*
    of the chunk from the metadata of the retrieved chunk. Retrieve all chunks with
    surrounding sequence numbers that have the same *document_id*.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索：** 在执行常规的相似性搜索之后（为了简单起见，假设只返回前 1 个结果），我们从检索到的块的元数据中获取 *document_id* 和
    *sequence_number*。然后，检索所有具有相同 *document_id* 的周围序列号的块。'
- en: 'For example, assuming you’ve indexed a document named ***example.pdf*** in
    80 chunks. Then, for some query, you find that the closest vector is the one with
    the following metadata:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你已经将一个名为 ***example.pdf*** 的文档分成 80 个块进行索引。那么，对于某个查询，你会发现最接近的向量是具有以下元数据的那个：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can easily get all vectors from the same document with sequence numbers
    from 15 to 25.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松地获取来自同一文档、序列号从 15 到 25 的所有向量。
- en: Let’s see the code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码。
- en: 'Here, I’m using:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我使用的是：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The only interesting thing to notice below is the metadata associated with each
    chunk, which will allow us to perform the search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下面唯一值得注意的是与每个块相关的元数据，这将帮助我们执行搜索。
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, lets implement the actual retrieval in Milvus and Chroma. Note that I’ll
    use the LangChains’ objects and not the native clients. I do this because I assume
    developers might want to keep LangChains’ useful abstraction. On the other hand,
    it will require us to perform some minor hacks to bypass these abstractions in
    a database-specific way, so you should take that into consideration. Anyway, the
    concept remains the same.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 Milvus 和 Chroma 中实现实际的检索。请注意，我将使用 LangChains 的对象，而不是原生客户端。这样做是因为我假设开发人员可能希望保留
    LangChains 的有用抽象层。另一方面，这将要求我们做一些小的修改，以数据库特定的方式绕过这些抽象层，因此你应该考虑这一点。无论如何，概念保持不变。
- en: Again, let’s assume for simplicity we want only the most similar vector (“top
    1”). Next, we’ll extract the associated document_id and its sequence number. This
    will allow us to retrieve the surrounding window.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 再次假设为了简化，我们只需要最相似的向量（“前 1 个”）。接下来，我们将提取相关的 document_id 及其序列号。这将帮助我们检索周围的窗口。
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, for the window/parent retrieval, we’ll dig under the Langchain abstraction,
    in a database-specific way.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于窗口/父级检索，我们将在 Langchain 的抽象层下，采用数据库特定的方式进行操作。
- en: 'For Milvus:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Milvus：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For Chroma:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Chroma：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'and don’t forget to sort it by the sequence number:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了按序列号排序：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For your convenience, you can explore the full code [here](https://gist.github.com/omriel1/7243ce233eb2986ed2749de6ae79ecb7).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，你可以在[这里](https://gist.github.com/omriel1/7243ce233eb2986ed2749de6ae79ecb7)查看完整代码。
- en: Pinecone (and others)
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pinecone（及其他）
- en: As far as I know, there’s no native way to perform such a metadata query in
    Pinecone, but you can natively fetch vectors by their ID ([https://docs.pinecone.io/guides/data/fetch-data](https://docs.pinecone.io/guides/data/fetch-data)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 据我所知，Pinecone 没有原生方法来执行此类元数据查询，但你可以通过它们的 ID 原生地获取向量（[https://docs.pinecone.io/guides/data/fetch-data](https://docs.pinecone.io/guides/data/fetch-data)）。
- en: 'Hence, we can do the following: each chunk will get a unique ID, which is essentially
    a concatenation of the document_id and the sequence number. Then, given a vector
    retrieved in the similarity search, you can dynamically create a list of the IDs
    of the surrounding chunks and achieve the same result.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以做以下操作：每个块将获得一个唯一 ID，该 ID 本质上是文档 ID 和序列号的连接。然后，给定通过相似性搜索检索到的向量，你可以动态创建周围块的
    ID 列表，从而实现相同的结果。
- en: Limitations
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制
- en: It’s worth mentioning that vector databases were not designed to perform “regular”
    database operations and usually not optimized for that, and each database will
    perform differently. Milvus, for example, will support building indices over scalar
    fields (“metadata”) which can optimize these kinds of queries.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，向量数据库并非为了执行“常规”数据库操作而设计，通常也没有针对这类操作进行优化，并且每个数据库的表现都不相同。例如，Milvus 将支持在标量字段（“元数据”）上建立索引，从而优化这类查询。
- en: Also, note that it requires additional query to the vector database. First we
    retrieved the most similar vector, and then we performed additional query to get
    the surrounding chunks in the original document.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意，这需要向向量数据库发送额外的查询。首先我们检索到最相似的向量，然后我们执行额外的查询，以获取原始文档中周围的块。
- en: And of course, as seen from the code examples above, the implementation is vector
    database-specific and is not supported natively by the LangChains’ abstraction.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，正如上面的代码示例所示，实现是特定于向量数据库的，并且 LangChains 的抽象层本身不支持这种实现。
- en: Conclusion
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this blog we introduced an implementation to achieve sentence-window retrieval,
    which is a useful retrieval technique used in many RAG applications. In this implementation
    we’ve used only the vector database which is already in use anyway, and also support
    the option to modify dynamically the the size of the surrounding window retrieved.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们介绍了一种实现方式，用于实现句子窗口检索，这是一种在许多RAG应用中都非常有用的检索技术。在这个实现中，我们仅使用了已经在使用中的向量数据库，并且还支持动态修改检索到的周围窗口大小的选项。
- en: References
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] ARAGOG: Advanced RAG Output Grading, [https://arxiv.org/pdf/2404.01037](https://arxiv.org/pdf/2404.01037),
    section 4.2.2'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] ARAGOG: 高级RAG输出评分，[https://arxiv.org/pdf/2404.01037](https://arxiv.org/pdf/2404.01037)，第4.2.2节'
- en: '[2] [https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/)'
- en: '[3] Some related issues:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] 一些相关问题：'
- en: '- [https://github.com/langchain-ai/langchain/issues/14267](https://github.com/langchain-ai/langchain/issues/14267)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '- [https://github.com/langchain-ai/langchain/issues/14267](https://github.com/langchain-ai/langchain/issues/14267)'
- en: '- [https://github.com/langchain-ai/langchain/issues/20315](https://github.com/langchain-ai/langchain/issues/20315)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '- [https://github.com/langchain-ai/langchain/issues/20315](https://github.com/langchain-ai/langchain/issues/20315)'
- en: '- [https://stackoverflow.com/questions/77385587/persist-parentdocumentretriever-of-langchain](https://stackoverflow.com/questions/77385587/persist-parentdocumentretriever-of-langchain)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '- [https://stackoverflow.com/questions/77385587/persist-parentdocumentretriever-of-langchain](https://stackoverflow.com/questions/77385587/persist-parentdocumentretriever-of-langchain)'
- en: '[4] [https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_window/)'
