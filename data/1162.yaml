- en: What Is a Latent Space?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是潜在空间？
- en: 原文：[https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08](https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08](https://towardsdatascience.com/what-is-a-latent-space-065eb8e3f859?source=collection_archive---------8-----------------------#2024-05-08)
- en: A Concise explanation for the general reader
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 给普通读者的简明解释
- en: '[](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)[![Jaroslaw
    Drapala](../Images/34de3c52fc32005e36930135254ae45e.png)](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)
    [Jaroslaw Drapala](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)[![Jaroslaw
    Drapala](../Images/34de3c52fc32005e36930135254ae45e.png)](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)
    [Jaroslaw Drapala](https://medium.com/@jaroslaw.drapala?source=post_page---byline--065eb8e3f859--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)
    ·7 min read·May 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--065eb8e3f859--------------------------------)
    ·7分钟阅读·2024年5月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6459ac32968bd8e1cdb2a456efdfb382.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6459ac32968bd8e1cdb2a456efdfb382.png)'
- en: Photo by [Lennon Cheng](https://unsplash.com/@lennonzf?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Lennon Cheng](https://unsplash.com/@lennonzf?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Have you ever wondered how **generative AI** gets its work done? How does it
    create images, manage text, and perform other tasks?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有想过**生成式AI**是如何完成工作的？它是如何创建图像、处理文本并执行其他任务的？
- en: The crucial concept you really need to understand is **latent space**. Understanding
    what the latent space is paves the way for comprehending generative AI.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你真正需要理解的关键概念是**潜在空间**。理解潜在空间是什么，为理解生成式AI铺平了道路。
- en: Let me walk you through few examples to explain the essence of a latent space.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我通过几个例子来向你解释潜在空间的本质。
- en: '**Example 1.** *Finding a better way to represent heights and weights data.*'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**示例1.** *寻找更好的方式来表示身高和体重数据。*'
- en: Throughout my numerous medical data research projects, I gathered a lot of measurements
    of patients’ *weights* and *heights*. The figure below shows the distribution
    of measurements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我众多的医学数据研究项目中，我收集了大量关于患者*体重*和*身高*的测量数据。下面的图显示了这些测量数据的分布情况。
- en: '![](../Images/cc14590d30b7dffb78a3fb47cca64b81.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc14590d30b7dffb78a3fb47cca64b81.png)'
- en: Measurements of heights and weights of 11808 cardiac patients.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 11808名心脏病患者的身高和体重测量数据。
- en: You can consider each point as a compressed version of information about a real
    person. All details such as facial features, hairstyle, skin tone, and gender
    are no longer available, leaving only *weight* and *height* values.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把每个点看作是关于一个真实人物的信息的压缩版。所有细节，如面部特征、发型、肤色和性别等都不再可用，只留下*体重*和*身高*值。
- en: Is it possible to reconstruct the original data using only these two values?
    Sure, if your expectations aren’t too high. You simply need to replace all the
    discarded information with a standard template object to fill in the gaps. The
    template object is customized based on the preserved information, which in this
    case includes only *height* and *weight*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 是否可以仅通过这两个值重建原始数据？当然可以，前提是你的期望不要过高。你只需要用一个标准的模板对象来替换所有丢弃的信息，以填补空白。模板对象是根据保留的信息定制的，在这种情况下只包括*身高*和*体重*。
- en: '![](../Images/91a360dbe30c2cfb6da55e9892529b7b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91a360dbe30c2cfb6da55e9892529b7b.png)'
- en: '`[Photograph of the author taken by [Kamil Winiarz](http://linkedin.com/in/kamilwiniarz)]`'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`[作者的照片，由 [Kamil Winiarz](http://linkedin.com/in/kamilwiniarz) 拍摄]`'
- en: Let’s delve into the space defined by the *height* and *weight* axes. Consider
    a point with coordinates of 170 cm for height and 70 kg for weight. Let this point
    serve as a reference figure and position it at the origin of the axes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨由*身高*和*体重*轴定义的空间。考虑一个坐标为身高170厘米、体重70公斤的点。让这个点作为参考图形，并将其放置在坐标轴的原点。
- en: '![](../Images/0c9587ccaf54e1e9544da41f6f9d78c3.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c9587ccaf54e1e9544da41f6f9d78c3.png)'
- en: Moving horizontally keeps your *weight* constant while altering your *height*.
    Likewise, moving up and down keeps your *height* the same but changes your *weight*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 水平移动保持你的*体重*恒定，同时改变你的*身高*。同样，垂直移动保持你的*身高*不变，但会改变你的*体重*。
- en: It might seem tricky because when you move in one direction, you have to think
    about two things simultaneously. Is there a way to improve this?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来有些棘手，因为当你朝一个方向移动时，你必须同时考虑两件事。有没有什么方法可以改进这个问题？
- en: Take a look at the same dataset colour-coded by *BMI*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 看看同一数据集按*BMI*着色的效果。
- en: '![](../Images/1fc0ed91cc20c930949c59292c480b54.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fc0ed91cc20c930949c59292c480b54.png)'
- en: The colors nearly align with the lines. This suggests that we could consider
    other axes that might be more convenient for generating human figures.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色几乎与线条对齐。这表明我们可以考虑其他可能更方便的轴，以便生成更符合需求的人物。
- en: We might name one of these axes ‘*Zoom*’ because it maintains a constant *BMI*,
    with the only change being the scale of the figure. Likewise, the second axis
    could be labeled *BMI*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会将其中一条轴命名为‘*缩放*’，因为它保持恒定的*BMI*，唯一变化的是图形的比例。同样，第二条轴可以标为*BMI*。
- en: '![](../Images/da371892311df874797e63aa25bb0b33.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da371892311df874797e63aa25bb0b33.png)'
- en: The new axes offer **a more convenient perspective on the data**, making it
    easier to explore. You can specify a target BMI value and then simply adjust the
    size of the figure along the ‘*Zoom*’ axis.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 新的轴提供了**更便捷的数据视角**，使得数据探索变得更加容易。你可以指定一个目标BMI值，然后只需沿着‘*缩放*’轴调整图形的大小。
- en: 'Looking to add more detail and realism to your figures? Consider additional
    features, such as *gender*, for instance. But from now on, I can’t offer similar
    visualizations that encompass all aspects of the data due to the lack of dimensions.
    I’m only able to display the distribution of three selected features: two features
    are depicted by the positions of points on the axes, with the third being indicated
    by color.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想为你的图形增加更多细节和真实感吗？可以考虑加入更多特征，比如*性别*。但从现在开始，由于缺乏维度，我无法提供涵盖所有数据方面的类似可视化。我只能展示三项选定特征的分布：两个特征通过点在坐标轴上的位置来表示，第三个特征则通过颜色来指示。
- en: '![](../Images/5d32175fb2803768c1d4d1b7ddd3b6f4.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d32175fb2803768c1d4d1b7ddd3b6f4.png)'
- en: To improve the previous human figure generator, you can create separate templates
    for males and females. Then generate a female in yellow-dominant areas and a male
    where blue prevails.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进之前的人物生成器，你可以为男性和女性创建单独的模板。然后，在黄色主导的区域生成女性，在蓝色占主导的区域生成男性。
- en: As more features are taken into account, the figures become increasingly realistic.
    Notice also that a figure can be generated for every point, even those not present
    in the dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随着更多特征的考虑，生成的人物变得越来越逼真。还要注意，即使是数据集中没有的点，也能生成相应的人物。
- en: This is what I would call *a top-down approach* to generate synthetic human
    figures. It involves selecting measurable features and identifying the optimal
    axes (directions) for exploring the data space. In the machine learning community,
    the first is called **feature selection**, and the second is termed **feature
    extraction**. Feature extraction can be carried out using specialized algorithms,
    e.g., PCA¹ (***P****rincipal* ***C****omponent* ***A****nalysis*), allowing the
    identification of directions that represent the data more naturally.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我所称的*自上而下的方法*来生成合成的人类图形。它包括选择可衡量的特征，并识别用于探索数据空间的最佳轴（方向）。在机器学习领域，第一个过程称为**特征选择**，第二个过程则称为**特征提取**。特征提取可以通过使用专门的算法来进行，例如PCA¹（***主成分分析*，*P*riniciple
    *C*omponent *A*nalysis），它有助于识别那些更自然地表示数据的方向。
- en: The mathematical space from which we generate synthetic objects is termed the
    **latent space** for two reasons. At first, the points (vectors) in this space
    are simply compressed, imperfect numerical **representations of the original objects**,
    much like shadows. Secondly, the axes defining the latent space often bear little
    resemblance to the originally measured features. The second reason will be better
    demonstrated in the next examples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成合成对象的数学空间被称为**潜在空间**，原因有二。首先，这个空间中的点（向量）仅仅是原始对象的压缩、不完美的数值**表示**，就像阴影一样。其次，定义潜在空间的轴通常与原始测量特征几乎没有相似性。第二个原因将在接下来的示例中得到更好的展示。
- en: '**Example 2.** *Aging of human faces.*'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**示例 2.** *人脸的衰老。*'
- en: Twoday’s generative AI follows *a bottom-up approach*, where both feature selection
    and extraction are performed automatically from the raw data. Consider a vast
    dataset comprising images of faces, where the raw features consist of the colors
    of all pixels in each image, represented as numbers ranging from 0 to 255\. A
    generative model like GAN² (***G****enerative* ***A****dversarial* ***N****etwork*)
    can identify (learn) a low-dimensional set of features where we can find the directions
    that interest us the most.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的生成式 AI 采用*自下而上的方法*，在这种方法中，特征选择和提取是从原始数据中自动进行的。考虑一个包含面部图像的大型数据集，其中原始特征是每张图像中所有像素的颜色，表示为从
    0 到 255 的数字。像 GAN² 这样的生成模型（***G****enerative* ***A****dversarial* ***N****etwork*）可以识别（学习）一组低维特征，在这些特征中，我们可以找到最感兴趣的方向。
- en: Imagine you want to develop an app that takes your image and shows you a younger
    or older version of yourself. To achieve this, you need to sort all latent space
    representations of images (latent space vectors) according to age. Then, for each
    age group, you have to determine the average vector.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想开发一个应用程序，上传你的图像并展示你更年轻或更年长的版本。为了实现这一目标，你需要根据年龄对所有图像的潜在空间表示（潜在空间向量）进行排序。然后，对于每个年龄组，你需要确定平均向量。
- en: If all goes well, the average vectors would align along a curve, which you can
    consider to approximate the age value axis.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，平均向量将沿着一条曲线排列，你可以将这条曲线视为年龄值轴的近似。
- en: Now, you can determine the latent space representation of your image (**encoding**
    step) and then move it along the age direction as you wish. Finally, you **decode**
    it to generate a synthetic image portraying the older (or younger) version of
    yourself. The idea of the **decoding** step here is similar to what I showed you
    in Example 1, but theoretically and computationally much more advanced.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以确定图像的潜在空间表示（**编码**步骤），然后按照你想要的方式沿着年龄方向移动它。最后，你可以**解码**它，以生成一个合成图像，展现你更年长（或更年轻）版本的样子。这里的**解码**步骤的思路类似于我在示例
    1 中展示的内容，但在理论和计算上更为先进。
- en: The latent space allows exploration into other interesting dimensions, such
    as *hair length*, *smile*, *gender*, and more.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间允许探索其他有趣的维度，例如*发长*、*笑容*、*性别*等。
- en: Example 3\. Arranging words and phrases based on their meanings.
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 3. 根据词语和短语的含义进行排序。
- en: 'Let’s say you’re doing a study on predatory behavior in nature and society
    and you’ve got a ton of text material to analyze. For automating the filtering
    of relevant articles, you can encode words and phrases into the latent space.
    Following the top-down approach, let this latent space be based on two dimensions:
    *Predatoriness* and *Size*. In a real-world scenario, you’d need more dimensions.
    I only took two so you could see the latent space for yourself.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在进行一项关于自然界和社会中捕食行为的研究，并且你有大量的文本材料需要分析。为了自动筛选相关的文章，你可以将词语和短语编码到潜在空间中。采用自上而下的方法，假设这个潜在空间基于两个维度：*捕食性*和*大小*。在实际情况下，你可能需要更多的维度。我这里只取了两个，方便你自己看到潜在空间的样子。
- en: 'Below, you can see some words and phrases represented (embedded) in the introduced
    latent space. Using an analogy to physics: you can think of each word or phrase
    as being loaded with two types of charges: *predatoriness* and *size*. Words/phrases
    with similar charges are located close to each other in the latent space.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，你可以看到一些词语和短语在引入的潜在空间中的表示（嵌入）。用物理学的类比来理解：你可以把每个词语或短语看作带有两种电荷：*捕食性*和*大小*。具有相似电荷的词语/短语会在潜在空间中靠得很近。
- en: '![](../Images/6815730634ec6a9a7faea2cc1f148d19.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6815730634ec6a9a7faea2cc1f148d19.png)'
- en: Every word/phrase is assigned numerical coordinates in the latent space.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每个词语/短语在潜在空间中都有一个数值坐标。
- en: '![](../Images/dc0b39c528888f17c6e3b055a0b1c879.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc0b39c528888f17c6e3b055a0b1c879.png)'
- en: 'These vectors are **latent space representations** of words/phrases and are
    referred to as **embeddings**. One of the great things about embeddings is that
    you can perform algebraic operations on them. For example, if you add the vectors
    representing ‘sheep’ and ‘spider’, you’ll end up close to the vector representing
    ‘politician’. This justifies the following elegant algebraic expression:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这些向量是**潜在空间表示**的单词/短语，通常被称为**嵌入**。嵌入的一个优点是你可以对它们进行代数运算。例如，如果你将代表“羊”和“蜘蛛”的向量相加，你会得到一个接近代表“政治家”的向量。这就证明了下面这个优雅的代数表达式：
- en: '![](../Images/025153092b42930f014549c33c32c83c.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/025153092b42930f014549c33c32c83c.png)'
- en: Do you think this equation makes sense?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为这个方程有意义吗？
- en: Try out the latent space representation used by ChatGPT. This could be really
    entertaining.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试一下 ChatGPT 使用的潜在空间表示方法。这可能会非常有趣。
- en: '![](../Images/7ec7262d772fb4bdda6bcbcc04bc1ba7.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ec7262d772fb4bdda6bcbcc04bc1ba7.png)'
- en: Final words
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结语
- en: The latent space represents data in a manner that highlights properties essential
    for the current task. Many AI methods, especially generative models and deep neural
    networks, operate on the latent space representation of data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间以一种突出当前任务所需属性的方式表示数据。许多AI方法，特别是生成模型和深度神经网络，都在数据的潜在空间表示上进行操作。
- en: An AI model learns the latent space from data, projects the original data into
    this space (encoding step), performs operations within it, and finally reconstructs
    the result into the original data format (decoding step).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个AI模型从数据中学习潜在空间，将原始数据投射到这个空间中（编码步骤），在其中进行操作，最后将结果重构成原始数据格式（解码步骤）。
- en: My intention was to help you understand the concept of the latent space. To
    delve deeper into the subject, I suggest exploring more mathematically advanced
    sources. If you have good mathematical skills, I recommend following [the blog
    of Jakub Tomczak](https://jmtomczak.github.io/), where he discusses hot topics
    in the field of generative AI and offers thorough explanations of **generative
    models**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我的目的是帮助你理解潜在空间的概念。为了更深入地探讨这一主题，我建议你阅读一些更具数学深度的资料。如果你具备良好的数学基础，我推荐你关注[Jakub Tomczak的博客](https://jmtomczak.github.io/)，他在博客中讨论了生成式人工智能领域的热门话题，并且对**生成模型**进行了详细的讲解。
- en: '*Unless otherwise noted, all images are by the author.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均为作者提供。*'
- en: References
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Deisenroth, Marc Peter, A. Aldo Faisal, Cheng Soon Ong. [Mathematics for
    machine learning](https://www.google.com/url?sa=t&rct=j&opi=89978449&url=https%3A%2F%2Fmml-book.github.io%2Fbook%2Fmml-book.pdf&ved=2ahUKEwjy8PaJ7PiFAxUHLRAIHXMpCWMQFnoECBUQAQ&usg=AOvVaw17xiHCSrqWJgf-0E-XLdOq).
    Cambridge University Press, 2020.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Deisenroth, Marc Peter, A. Aldo Faisal, Cheng Soon Ong. [机器学习数学](https://www.google.com/url?sa=t&rct=j&opi=89978449&url=https%3A%2F%2Fmml-book.github.io%2Fbook%2Fmml-book.pdf&ved=2ahUKEwjy8PaJ7PiFAxUHLRAIHXMpCWMQFnoECBUQAQ&usg=AOvVaw17xiHCSrqWJgf-0E-XLdOq).
    剑桥大学出版社, 2020。'
- en: '[2] Jakub M. Tomczak. [Deep Generative Modeling](https://link.springer.com/book/10.1007/978-3-030-93158-2).
    Springer, 2022'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Jakub M. Tomczak. [深度生成建模](https://link.springer.com/book/10.1007/978-3-030-93158-2).
    施普林格出版社, 2022。'
