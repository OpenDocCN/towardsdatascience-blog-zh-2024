- en: How to Build a Streaming Agent with Burr, FastAPI, and React
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Burr、FastAPI和React构建流媒体代理
- en: 原文：[https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25](https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25](https://towardsdatascience.com/how-to-build-a-streaming-agent-with-burr-fastapi-and-react-e2459ef527a8?source=collection_archive---------3-----------------------#2024-07-25)
- en: An overview of how to leverage streaming using open source tools applied to
    building a simple agentic chat bot
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何利用开源工具构建一个简单的代理聊天机器人，使用流媒体技术。
- en: '[](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)[![Stefan
    Krawczyk](../Images/150405abaad9590e1dc2589168ed2fa3.png)](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)
    [Stefan Krawczyk](https://medium.com/@stefan.krawczyk?source=post_page---byline--e2459ef527a8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)
    ·12 min read·Jul 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--e2459ef527a8--------------------------------)
    ·阅读时间12分钟·2024年7月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f76e421b3ba109b434f51c1d43eb0ba0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f76e421b3ba109b434f51c1d43eb0ba0.png)'
- en: The model of our agentic application. We’ll show how you can build this with
    streaming so you can create a great user experience. Image by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代理应用模型。我们将展示如何通过流媒体构建这个模型，让你能够创造出出色的用户体验。图片由作者提供。
- en: In this post we will go over how to build an agentic chatbot that streams responses
    to the user, leveraging [Burr](https://github.com/dagworks-inc/burr)’s (I’m an
    author) streaming capabilities, [FastAPI’s](https://fastapi.tiangolo.com/) [StreamingResponse](https://fastapi.tiangolo.com/advanced/custom-response/?h=streamingresponse#using-streamingresponse-with-file-like-objects),
    and server-sent-events (SSEs) queried by [React](https://react.dev/). All of these
    are open source tools. This is aimed at those who want to learn more about streaming
    in Python and how to add interactivity to their agent/application. While the tools
    we use will be fairly specific, the lessons should be applicable to a wide range
    of streaming response implementations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将介绍如何构建一个代理聊天机器人，通过流媒体将响应传递给用户，利用[Burr](https://github.com/dagworks-inc/burr)（我也是作者）的流媒体功能，[FastAPI](https://fastapi.tiangolo.com/)的[StreamingResponse](https://fastapi.tiangolo.com/advanced/custom-response/?h=streamingresponse#using-streamingresponse-with-file-like-objects)以及由[React](https://react.dev/)查询的服务器推送事件（SSEs）。这些都是开源工具。本文面向那些希望了解如何在Python中使用流媒体，以及如何为他们的代理/应用程序添加交互性的人。虽然我们使用的工具相对具体，但所学的内容应该适用于广泛的流媒体响应实现方式。
- en: First, we’ll talk about why streaming is important. Then we’ll go over the open-source
    tooling we use. We’ll walk through an example, and point you out to code that
    you can use to get started, then share more resources and alternate implementations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将讨论流媒体的重要性。接着，我们将介绍我们使用的开源工具。我们将通过一个示例讲解，并提供你可以使用的代码，帮助你入门，之后分享更多资源和替代实现方案。
- en: You can follow along with the Burr + FastAPI code [here](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)
    and the frontend code [here](https://github.com/DAGWorks-Inc/burr/blob/main/telemetry/ui/src/examples/StreamingChatbot.tsx).
    You can also run this example (you’ll need an OPENAI_API_KEY env variable) by
    running `pip install “burr[start]” && burr`, then navigating to localhost:7241/demos/streaming-chatbot;
    the browser will open automatically, just click demos/streaming-chatbot on the
    left. Note this example requires `burr>=0.23.0`.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过[Burr + FastAPI 代码](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)和前端代码[这里](https://github.com/DAGWorks-Inc/burr/blob/main/telemetry/ui/src/examples/StreamingChatbot.tsx)跟着一起操作。你也可以通过运行
    `pip install “burr[start]” && burr`，然后访问 localhost:7241/demos/streaming-chatbot
    来运行这个示例（你需要一个 OPENAI_API_KEY 环境变量）；浏览器会自动打开，点击左侧的 demos/streaming-chatbot 即可。注意，这个示例要求
    `burr>=0.23.0`。
- en: Why Streaming?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用流式传输？
- en: While streaming media through the web is a technology from [the 90s](https://en.wikipedia.org/wiki/Streaming_media#:~:text=Online%20streaming%20was%20initially%20popularised,being%20offered%20since%20the%202010s.),
    and is now ubiquitous (video games, streaming TV, music, etc…), the recent surge
    in generative AI applications has seen an interest in serving and rendering streaming
    text, word by word.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然通过网络流式传输媒体是[90年代](https://en.wikipedia.org/wiki/Streaming_media#:~:text=Online%20streaming%20was%20initially%20popularised,being%20offered%20since%20the%202010s.)的技术，并且如今已无处不在（视频游戏、流媒体电视、音乐等），但最近生成式
    AI 应用的兴起使得逐字流式传输文本的兴趣重新回到了人们的视野。
- en: LLMs are a fun technology (perhaps even useful), but relatively slow to run,
    and users don’t like waiting. Luckily, it is possible to stream the results so
    that a user sees an LLM’s response as it is being generated. Furthermore, given
    the generally robotic and stuffy nature of LLMs, streaming can make them appear
    more interactive, almost as if they’re thinking.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 是一种有趣的技术（甚至可能是有用的），但运行相对较慢，用户不喜欢等待。幸运的是，可以通过流式传输结果，让用户在 LLM 的响应生成过程中实时看到结果。此外，鉴于
    LLM 的普遍机械且呆板的特性，流式传输可以使其看起来更具互动性，几乎就像它们在思考一样。
- en: A proper implementation will allow streaming communication across multiple service
    boundaries, enabling intermediate proxies to augment/store the streaming data
    as it is presented to the user.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个正确的实现将允许跨多个服务边界进行流式通信，使得中间代理能够在将数据呈现给用户时增强/存储流式数据。
- en: '![](../Images/9f99df7ca53e3a575dacdc8d977ef642.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f99df7ca53e3a575dacdc8d977ef642.png)'
- en: A simple display of a chatbot architecture. Image by author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的聊天机器人架构展示。图片由作者提供。
- en: While none of this is rocket science, the same tools that make web development
    easy and largely standardized (OpenAPI / FastAPI / React + friends, etc…) all
    have varying degrees of support, meaning that you often have multiple choices
    that are different than what you’re used to. Streaming is often an afterthought
    in framework design, leading to various limitations that you might not know until
    you’re halfway through building.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些都不是火箭科学，但使网页开发变得简单且高度标准化的工具（如 OpenAPI / FastAPI / React + 朋友们等）在流式传输支持上存在不同程度的差异，这意味着你常常会遇到与自己习惯的工具不同的选择。流式传输通常是框架设计中的事后考虑，导致一些限制，直到你开发到一半时才会发现。
- en: Let’s go over some of the tools we’ll use to implement the stack above, then
    walk through an example.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解一些将用来实现上面技术栈的工具，然后一起看个例子。
- en: The Open Source Tools
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源工具
- en: The tools we’ll leverage to build this are nicely decoupled from each other
    — you can swap like with like if you want and still apply the same lessons/code.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来构建这个的工具相互解耦得很好——如果你愿意，可以互换相似的工具，依然可以应用相同的教训/代码。
- en: Burr
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Burr
- en: '[Burr](https://github.com/DAGWorks-Inc/burr/) is a lightweight Python library
    you use to build applications as state machines. You construct your application
    out of a series of actions (these can be either decorated functions or objects),
    which declare inputs from state, as well as inputs from the user. These specify
    custom logic (delegating to any framework), as well as instructions on how to
    update state. State is immutable, which allows you to inspect it at any given
    point. Burr handles orchestration, monitoring, persistence, etc…).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[Burr](https://github.com/DAGWorks-Inc/burr/) 是一个轻量级的 Python 库，用于构建作为状态机的应用程序。你可以通过一系列动作（这些可以是装饰过的函数或对象）构建你的应用程序，这些动作声明来自状态的输入，以及来自用户的输入。这些定义了自定义逻辑（可以委托给任何框架），以及如何更新状态的指令。状态是不可变的，这允许你在任何时候检查它。Burr
    处理编排、监控、持久化等工作。'
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You run your Burr actions as part of an application — this allows you to string
    them together with a series of (optionally) conditional transitions from action
    to action.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你将Burr操作作为应用程序的一部分运行——这允许你将它们通过一系列（可选的）条件转换串联起来，从一个动作到另一个动作。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Burr comes with a user-interface that enables monitoring/telemetry, as well
    as hooks to persist state/execute arbitrary code during execution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Burr配有一个用户界面，可以进行监控/遥测，并且提供挂钩功能来持久化状态/在执行过程中执行任意代码。
- en: 'You can visualize this as a flow chart, i.e. graph / state machine:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将其视为一个流程图，即图形/状态机：
- en: '![](../Images/f987bc5eedaa49d7f5a17e860b10a6e0.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f987bc5eedaa49d7f5a17e860b10a6e0.png)'
- en: Burr gives you this image for free. Image by author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Burr免费为你提供这张图片。图片由作者提供。
- en: 'And monitor it using the local telemetry debugger:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用本地遥测调试器进行监控：
- en: '![](../Images/daf833de5eef0cfd6bd0b09cdb576096.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/daf833de5eef0cfd6bd0b09cdb576096.png)'
- en: The OS telemetry UI tells you the state of your application at any given point
    in time. Image by author.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统遥测UI在任何给定时刻都会告诉你应用程序的状态。图像由作者提供。
- en: While the above example is a simple illustration, Burr is commonly used for
    Agents (like in this example), RAG applications, and human-in-the-loop AI interfaces.
    See the repository [examples](https://github.com/DAGWorks-Inc/burr/tree/main/examples)
    for a (more exhaustive) set of use-cases. We’ll go over streaming and a few more
    powerful features a little later.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然上述示例是一个简单的插图，但Burr通常用于代理（如本示例中所示）、RAG应用程序和人类环中AI接口。请参阅仓库中的[示例](https://github.com/DAGWorks-Inc/burr/tree/main/examples)以获取（更详尽的）使用案例。稍后我们将详细介绍流式传输和一些更强大的功能。
- en: FastAPI
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FastAPI
- en: '[FastAPI](https://fastapi.tiangolo.com/) is a framework that lets you expose
    python functions in a REST API. It has a simple interface — you write your functions
    then decorate them, and run your script — turning it into a server with self-documenting
    endpoints through [OpenAPI](https://www.openapis.org/).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[FastAPI](https://fastapi.tiangolo.com/)是一个框架，可以让你将Python函数暴露为REST API。它有一个简单的接口——你编写函数然后为其添加装饰器，最后运行脚本——它会变成一个带有自文档化端点的服务器，通过[OpenAPI](https://www.openapis.org/)进行描述。'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: FastAPI provides a myriad of benefits. It is async native, supplies documentation
    through OpenAPI, and is easy to deploy on any cloud provider. It is infrastructure
    agnostic and can generally scale horizontally (so long as consideration into state
    management is done). See [this page](https://fastapi.tiangolo.com/deployment/cloud/?h=deploy)
    for more information.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI提供了许多好处。它是原生支持异步的，通过OpenAPI提供文档，并且易于在任何云提供商上部署。它与基础设施无关，并且通常可以横向扩展（只要考虑到状态管理）。欲了解更多信息，请参见[此页面](https://fastapi.tiangolo.com/deployment/cloud/?h=deploy)。
- en: React
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: React
- en: React needs no introduction — it is an extremely popular tool that powers much
    of the internet. Even recent popular tools (such as next.js/remix) build on top
    of it. For more reading, see [react.dev](http://react.dev/). We will be using
    React along with [typescript](https://www.typescriptlang.org/) and [tailwind](https://tailwindcss.com/),
    but you can generally replace with your favorite frontend tools and be able to
    reuse much of this post.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: React无需介绍——它是一个极受欢迎的工具，支撑了互联网的许多部分。即便是最近流行的工具（如next.js/remix）也建立在它之上。欲了解更多信息，请访问[react.dev](http://react.dev/)。我们将使用React、[typescript](https://www.typescriptlang.org/)和[tailwind](https://tailwindcss.com/)，但你也可以替换为自己喜欢的前端工具，并且大部分内容都可以复用。
- en: Building a simple Agentic chatbot
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个简单的代理型聊天机器人
- en: 'Let’s build a simple *agentic* chatbot — it will be *agentic* as it actually
    makes two LLM calls:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个简单的*代理型*聊天机器人——它将是*代理型*的，因为它实际上会进行两次LLM调用：
- en: A call to determine the model to query. Our model will have a few “modes” —
    generate a poem, answer a question, etc…
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个调用，用于确定要查询的模型。我们的模型将有几个“模式”——生成诗歌、回答问题等……
- en: A call to the actual model (in this case prompt + model combination)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个调用，指向实际的模型（在本例中为提示+模型组合）
- en: With the OpenAI API this is more of a toy example — their models are impressive
    jacks of all trades. That said, this pattern of tool delegation shows up in a
    wide variety of AI systems, and this example can be extrapolated cleanly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenAI API时，这是一个玩具示例——他们的模型是令人印象深刻的多面手。也就是说，这种工具委托的模式在各种AI系统中都可以看到，且这个示例可以干净地外推。
- en: Modeling the Agent in Burr
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Burr中建模代理
- en: Modeling as a State Machine
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作为状态机建模
- en: 'To leverage Burr, we model our agentic application as a state machine. The
    basic flow of logic looks like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用Burr，我们将我们的代理型应用建模为一个状态机。基本的逻辑流程如下：
- en: '![](../Images/f76e421b3ba109b434f51c1d43eb0ba0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f76e421b3ba109b434f51c1d43eb0ba0.png)'
- en: We start at a user prompt input (top). Then we check for safety, and if it’s
    not safe, we go the specific response for “unsafe”. Otherwise we decide on the
    mode, and switch based on the value of the state field *mode*. Each of these returns
    a streaming response. Once they are done streaming, it circles back to prompt
    and waits for another user input… Image by author.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从用户输入的提示开始（顶部）。然后检查安全性，如果不安全，我们将进入“非安全”响应。否则，我们根据 *mode* 状态字段的值决定模式，并进行切换。每个操作都返回一个流式响应。流式传输完成后，它会返回到提示并等待另一个用户输入……图像由作者提供。
- en: To model this with Burr, we will first create corresponding actions, using the
    [streaming API](https://burr.dagworks.io/concepts/streaming-actions/). Then we’ll
    tie them together as an [application](https://burr.dagworks.io/concepts/state-machine/).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 Burr 中建模这一过程，我们首先将创建相应的操作，使用[流式 API](https://burr.dagworks.io/concepts/streaming-actions/)。然后我们将它们组合成一个[应用程序](https://burr.dagworks.io/concepts/state-machine/)。
- en: Streaming Actions
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流式操作
- en: In Burr, actions can leverage both a synchronous and asynchronous API. In this
    case we’ll be using [async](https://docs.python.org/3/library/asyncio.html). Streaming
    functions in Burr can also be mixed and match with non-streaming actions, but
    to simplify we will implement everything as streaming. So, whether it’s streaming
    from OpenAPI (which has its own [async streaming interface](https://www.asyncapi.com/tools/generator)),
    or returning a fixed *Sorry I cannot answer this question* response, it will still
    be implemented as a generator.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Burr 中，操作可以同时使用同步和异步 API。在这个例子中，我们将使用[异步](https://docs.python.org/3/library/asyncio.html)。Burr
    中的流式函数也可以与非流式操作混合使用，但为了简化，我们将一切都实现为流式操作。因此，无论是从 OpenAPI 流式传输（它有自己的[异步流式接口](https://www.asyncapi.com/tools/generator)），还是返回一个固定的
    *抱歉，我无法回答这个问题* 的响应，它仍然会作为生成器实现。
- en: For those who are unfamiliar, [generators](https://wiki.python.org/moin/Generators)
    are a Python construct that enables efficient, lazy evaluation over a sequence
    of values. They are created by the `yield` keyword, which cedes control from the
    function back to the caller, until the next item is needed. [Async generators](https://peps.python.org/pep-0525/)
    function similarly, except they also cede control of the event loop on yield.
    Read more about [synchronous generators](https://wiki.python.org/moin/Generators)
    and [asynchronous generators](https://peps.python.org/pep-0525/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不熟悉的人，[生成器](https://wiki.python.org/moin/Generators)是 Python 中的一种结构，可以高效地、懒惰地对一系列值进行评估。它们通过
    `yield` 关键字创建，`yield` 会将控制权从函数交还给调用者，直到需要下一个项目时才会继续执行。[异步生成器](https://peps.python.org/pep-0525/)的功能类似，不过它们在
    `yield` 时还会将事件循环的控制权交出。阅读更多关于[同步生成器](https://wiki.python.org/moin/Generators)和[异步生成器](https://peps.python.org/pep-0525/)的内容。
- en: 'Streaming actions in Burr are implemented as a generator that yields tuples,
    consisting of:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Burr 中的流式操作作为生成器实现，生成包含元组的流，其中包括：
- en: The intermediate result (in this case, delta token in the message)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 中间结果（在此情况下，消息中的增量标记）
- en: The final state update, if it is complete, or None if it is still generating
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果状态更新已完成，则为最终状态更新，若仍在生成中，则为 None
- en: 'Thus the final yield will indicate that the stream is complete, and output
    a final result for storage/debugging later. A basic response that proxies to OpenAI
    with some custom prompt manipulation looks like this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最终的 yield 将表明流已完成，并输出最终结果，以便稍后进行存储/调试。一个基本的响应，代理到 OpenAI 并进行一些自定义提示处理，长这样：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the example, we also have a few other streaming actions — these will represent
    the “terminal” actions — actions that will trigger the workflow to pause when
    the state machine completes them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们还有一些其他的流式操作——这些操作将代表“终端”操作——即在状态机完成时触发工作流暂停的操作。
- en: Building an Application
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建应用程序
- en: 'To build the application, we’re first going to build a graph. We’ll be using
    the [Graph API](https://burr.dagworks.io/concepts/state-machine/#graph-api) for
    Burr, allowing us to decouple the shape of the graph from other application concerns.
    In a web service the graph API is a very clean way to express state machine logic.
    You can build it once, globally, then reuse it per individual application instances.
    The graph builder looks like this — note it refers to the function *chat_response*
    from above:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建应用程序，我们首先将构建一个图形。我们将使用 Burr 的[图形 API](https://burr.dagworks.io/concepts/state-machine/#graph-api)，使我们能够将图形的形状与其他应用程序关注点解耦。在
    Web 服务中，图形 API 是一种非常简洁的方式来表达状态机逻辑。你可以全局构建一次，然后在每个单独的应用实例中重复使用它。图形构建器是这样的——请注意它引用了上面提到的
    *chat_response* 函数：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we can add this together in an Application — which exposes the right
    execution methods for the server to interact with:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将这些内容组合到一个应用程序中——它暴露了正确的执行方法，以便服务器与之交互：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When we want to run it, we can call out to [astream_results](https://burr.dagworks.io/concepts/streaming-actions/#usage).
    This takes in a set of *halting conditions*, and returns an [AsyncStreamingResultContainer](https://burr.dagworks.io/reference/actions/#burr.core.action.AsyncStreamingResultContainer)(a
    generator that caches the result and ensures Burr tracking is called), as well
    as the action that triggered the halt.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要运行它时，我们可以调用[astream_results](https://burr.dagworks.io/concepts/streaming-actions/#usage)。这个方法接受一组*停止条件*，并返回一个[AsyncStreamingResultContainer](https://burr.dagworks.io/reference/actions/#burr.core.action.AsyncStreamingResultContainer)(一个缓存结果的生成器，并确保调用
    Burr 跟踪)，以及触发停止的动作。
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Exposing in a Web Server
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Web 服务器中暴露
- en: Now that we have the Burr application, we’ll want to integrate with FastAPI’s
    [streaming response API](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse)
    using server-sent-events (SSEs). While we won’t dig too much into SSEs, the TL;DR
    is that they function as a one way (server → client) version of web-sockets. You
    can read more in the links at the end.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了 Burr 应用程序，我们希望通过使用服务器推送事件 (SSEs) 将其与 FastAPI 的[流式响应 API](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse)集成。虽然我们不会深入讨论
    SSEs，简而言之，它们作为 WebSocket 的单向（服务器 → 客户端）版本工作。你可以通过文末的链接了解更多信息。
- en: 'To use these in FastAPI, we declare an endpoint as a function that returns
    a StreamingResponse — a class that wraps a generator. The standard is to provide
    streaming responses in a special shape, “data: <contents> \n\n”. Read more about
    why [here](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events).
    While this is largely meant for the [EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource)
    API (which we will be bypassing in favor of fetch and [getReader()](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/getReader)),
    we will keep this format for standards (and so that anyone using the EventSource
    API can reuse this code).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '要在 FastAPI 中使用这些内容，我们声明一个端点作为一个返回 StreamingResponse 的函数——StreamingResponse
    是一个包装生成器的类。标准做法是以一种特殊的格式提供流式响应，“data: <contents> \n\n”。关于为什么这么做，可以[点击这里](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events)了解更多。虽然这个标准主要是针对
    [EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource) API（我们将绕过它，选择使用
    fetch 和[getReader()](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/getReader)），但我们将保持这一格式以遵循标准（这样任何使用
    EventSource API 的人都能复用这段代码）。'
- en: We have separately implemented `_get_application`, a utility function to get/load
    an application by ID.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经单独实现了 `_get_application`，这是一个通过 ID 获取/加载应用程序的工具函数。
- en: The function will be a POST endpoint, as we are adding data to the server, although
    could easily be a PUT as well.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 该功能将是一个 POST 端点，因为我们正在向服务器添加数据，尽管也可以轻松改为 PUT。
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that we define a generator inside the function that wraps the Burr result
    and turns it into SSE-friendly outputs. This allows us to impose some structure
    on the result, which we will use on the frontend. Unfortunately, we will have
    to parse it on our own, as fastAPI does not enable strict typing of a StreamingResponse.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在函数内部定义了一个生成器，它包装了 Burr 结果并将其转换为适合 SSE 的输出。这使我们能够对结果施加一些结构，后端将使用这些结构。不幸的是，我们将不得不自行解析它，因为
    fastAPI 不支持对 StreamingResponse 进行严格的类型定义。
- en: Furthermore, we actually yield the entire state at the beginning, prior to execution.
    While this is not strictly necessary (we can also have a separate API for chat
    history), it will make rendering easier.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们实际上会在执行前，最开始就输出整个状态。虽然这并非严格必要（我们也可以有一个单独的 API 用于聊天历史），但它会让渲染更加容易。
- en: To test this you can use the requests library [Response.iter_lines](https://requests.readthedocs.io/en/latest/user/advanced/#body-content-workflow)
    API.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试这一点，你可以使用 requests 库的[Response.iter_lines](https://requests.readthedocs.io/en/latest/user/advanced/#body-content-workflow)
    API。
- en: Building a UI
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建用户界面
- en: Now that we have a server, our state machine, and our LLM lined up, let’s make
    it look nice! This is where it all ties together. While you can download and play
    with the entirety of the code in [the example](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi),
    we will be focusing in on the function that queries the API when you click “send”.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了服务器、状态机和 LLM，让我们让它看起来更好！这就是一切整合的地方。虽然你可以下载并玩转完整的代码，[示例](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)中有全部内容，但我们将专注于在点击“发送”时查询
    API 的函数。
- en: '![](../Images/a31aeb84cbc323ece54bc65f05a68bad.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a31aeb84cbc323ece54bc65f05a68bad.png)'
- en: This is what the UI looks like. You can run this via the packaged Telemetry
    UI that Burr comes with. Image by author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 UI 的样子。你可以通过 Burr 附带的打包 Telemetry UI 运行这个。图像来自作者。
- en: 'First, let’s query our API using fetch (obviously adjust this to your endpoint,
    in this case we’re proxying all /api calls to another server…):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用 fetch 查询我们的 API（显然，你需要根据你的端点调整，当前我们将所有的 /api 调用代理到另一个服务器）：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This looks like a plain old API call, leveraging the typescript [async API](https://blog.logrocket.com/async-await-typescript/).
    This extracts a *reader* object, which will help us stream results as they come
    in.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像一个普通的 API 调用，利用了 TypeScript 的 [async API](https://blog.logrocket.com/async-await-typescript/)。它提取了一个
    *reader* 对象，帮助我们随着结果的到来进行流式传输。
- en: Let’s define some data types to leverage the structure we created above. In
    addition to the `ChatItem` data types (which was generated using [openapi-typescript-codegen](https://www.npmjs.com/package/openapi-typescript-codegen)),
    we’ll also define two classes, which correspond to the data types returned by
    the server.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一些数据类型，以便利用我们上面创建的结构。除了 `ChatItem` 数据类型（这是通过 [openapi-typescript-codegen](https://www.npmjs.com/package/openapi-typescript-codegen)
    生成的），我们还将定义两个类，它们对应服务器返回的数据类型。
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we’ll iterate through the reader and parse. This assumes the following
    state variables in react:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将遍历读取器并进行解析。这假设在 React 中存在以下状态变量：
- en: '`setCurrentResponse`/`currentResponse`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setCurrentResponse`/`currentResponse`'
- en: '`setDisplayedChatHistory`'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setDisplayedChatHistory`'
- en: We read through, splitting on “data:”, then looping through splits and parsing/reacting
    depending on the event type.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过“data:”进行拆分，然后循环遍历拆分结果，并根据事件类型进行解析/反应。
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We’ve left out some cleanup/error handling code (to clear, initialize the state
    variables before/after requests, handle failure, etc…) — you can see more in the
    example.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们省略了一些清理/错误处理代码（例如在请求之前/之后清除、初始化状态变量、处理失败等）——你可以在示例中看到更多内容。
- en: Finally, we can render it (note this refers to additional state variables that
    are set/unset outside of the code above, as well as a ChatMessage react component
    that simply displays a chat message with the appropriate icon.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以渲染它（请注意，这指的是在上面的代码之外设置/取消设置的额外状态变量，以及一个简单显示聊天消息和相应图标的 ChatMessage React
    组件）。
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We finally have our whole app! For all the [code click here](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终完成了整个应用程序！要查看所有的[代码，点击这里](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)。
- en: Alternate SSE Tooling
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 替代的 SSE 工具
- en: 'Note that what we presented above is just one approach to streaming with FastAPI/react/Burr.
    There are a host of other tools you can use, including:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们上面展示的仅仅是使用 FastAPI/react/Burr 进行流式传输的一种方法。你还可以使用其他许多工具，包括：
- en: The [EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource)
    API — standard but limited to get/ requests
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[EventSource](https://developer.mozilla.org/en-US/docs/Web/API/EventSource)
    API——标准但仅限于 get/ 请求'
- en: The [FetchEventSource](https://github.com/Azure/fetch-event-source) API (appears
    unmaintained, but well built)
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FetchEventSource](https://github.com/Azure/fetch-event-source) API（看起来不再维护，但构建得很好）'
- en: As well as a host of other blog posts (that are awesome! I read these to get
    started). These will give you a better sense of architecture as well.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以及其他一些很棒的博客文章（我看这些文章来入门）。这些文章也能帮助你更好地理解架构。
- en: '[Stream OpenAI with FastAPI and Consuming it with React.js](https://medium.com/@hxu296/serving-openai-stream-with-fastapi-and-consuming-with-react-js-part-1-8d482eb89702)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 FastAPI 流式传输 OpenAI 并通过 React.js 消费它](https://medium.com/@hxu296/serving-openai-stream-with-fastapi-and-consuming-with-react-js-part-1-8d482eb89702)'
- en: '[Streaming with FastAPI](https://www.vidavolta.io/streaming-with-fastapi/)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 FastAPI 流式传输](https://www.vidavolta.io/streaming-with-fastapi/)'
- en: Wrapping Up
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this post we covered a lot — we went over Burr, FastAPI, and React, talked
    about how to build a streaming *agentic* chatbot using the OpenAI API, built out
    the entire stack, and streamed data all the way through! While you may not use
    every one of the technologies, the individual pieces should be able to work on
    their own.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讲解了很多内容——我们介绍了 Burr、FastAPI 和 React，讨论了如何使用 OpenAI API 构建一个流式 *代理*
    聊天机器人，构建了整个堆栈，并进行了数据流式传输！虽然你可能不会使用所有的技术，但每个单独的部分应该都能独立工作。
- en: 'To download and play with this example, you can run:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载并尝试这个示例，你可以运行：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note you’ll need an [API key from OpenAI](http://platform.openai.com/) for this
    specific demo. You will find the Burr + FastAPI code [here](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/streaming-fastapi)
    and the frontend code [here](https://github.com/DAGWorks-Inc/hamilton/tree/main/telemetry/ui/src/examples/StreamingChatbot.tsx).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要一个来自[OpenAI的API密钥](http://platform.openai.com/)来运行这个特定的示例。您可以在[Burr +
    FastAPI代码](https://github.com/DAGWorks-Inc/hamilton/tree/main/examples/streaming-fastapi)中找到相关代码，在[前端代码](https://github.com/DAGWorks-Inc/hamilton/tree/main/telemetry/ui/src/examples/StreamingChatbot.tsx)中也可以找到。
- en: Additional Resources
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外资源
- en: '[Github repository for Burr](http://github.com/dagworks-inc/burr) (give us
    a star if you like what you see!)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Burr的Github仓库](http://github.com/dagworks-inc/burr)（如果您喜欢看到的内容，请给我们点个星！）'
- en: '[FastAPI guide](https://fastapi.tiangolo.com/)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FastAPI指南](https://fastapi.tiangolo.com/)'
- en: '[Example + README](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[示例 + README](https://github.com/DAGWorks-Inc/burr/tree/main/examples/streaming-fastapi)'
