- en: Track Computer Vision Experiments with MLflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MLflow追踪计算机视觉实验
- en: 原文：[https://towardsdatascience.com/track-computer-vision-experiments-with-mlflow-3852f557b27a?source=collection_archive---------4-----------------------#2024-12-26](https://towardsdatascience.com/track-computer-vision-experiments-with-mlflow-3852f557b27a?source=collection_archive---------4-----------------------#2024-12-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/track-computer-vision-experiments-with-mlflow-3852f557b27a?source=collection_archive---------4-----------------------#2024-12-26](https://towardsdatascience.com/track-computer-vision-experiments-with-mlflow-3852f557b27a?source=collection_archive---------4-----------------------#2024-12-26)
- en: Discover how to set up an efficient MLflow environment to track your experiments,
    compare and choose the best model for deployment
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现如何设置高效的MLflow环境，以跟踪你的实验，比较并选择最适合部署的模型
- en: '[](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)[![Yağmur
    Çiğdem Aktaş](../Images/3b51de551bed7355f467272fc4bd6c50.png)](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)
    [Yağmur Çiğdem Aktaş](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)[![Yağmur
    Çiğdem Aktaş](../Images/3b51de551bed7355f467272fc4bd6c50.png)](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)
    [Yağmur Çiğdem Aktaş](https://yagmurcigdemaktas.medium.com/?source=post_page---byline--3852f557b27a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)
    ·9 min read·Dec 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--3852f557b27a--------------------------------)
    ·9分钟阅读·2024年12月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Training and fine-tuning various models is a basic task for every computer vision
    researcher. Even for easy ones, we do a hyper-parameter search to find the optimal
    way of training the model over our custom dataset. Data augmentation techniques
    (which include many different options already), the choice of optimizer, learning
    rate, and the model itself. Is it the best architecture for my case? Should I
    add more layers, change the architecture, and many more questions will wait to
    be asked and searched?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和微调各种模型是每个计算机视觉研究人员的基础任务。即使是简单的模型，我们也会进行超参数搜索，以找到在我们自定义数据集上训练模型的最佳方式。数据增强技术（已包括许多不同的选项）、优化器的选择、学习率以及模型本身。这个架构对我来说是最合适的吗？我是否应该添加更多的层，改变架构，很多问题都等待着被提问和探索？
- en: 'While searching for an answer to all these questions, I used to save the model
    training process log files and output checkpoints in different folders in my local,
    change the output directory name every time I ran a training, and compare the
    final metrics manually one-by-one. Tackling the experiment-tracking process in
    such a manual way has many disadvantages: it’s old school, time and energy-consuming,
    and prone to errors.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在寻找所有这些问题的答案时，我曾将模型训练过程的日志文件和输出检查点保存在本地的不同文件夹中，每次运行训练时都更改输出目录名称，并手动一项一项比较最终的指标。以如此手动的方式处理实验跟踪过程有许多缺点：它是老派的，耗时耗力，且容易出错。
- en: In this blog post, I will show you how to use MLflow, one of the best tools
    to track your experiment, allowing you to log whatever information you need, visualize
    and compare the different training experiments you have accomplished, and decide
    which training is the optimal choice in a user- (and eyes-) friendly environment!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我将向你展示如何使用MLflow，这是一个追踪实验的最佳工具之一，能够记录你需要的任何信息，直观地比较你完成的不同训练实验，并在一个用户友好（也符合眼睛友好）环境中，帮助你决定哪个训练是最佳选择！
