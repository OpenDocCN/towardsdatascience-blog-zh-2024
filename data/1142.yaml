- en: Text to Knowledge Graph Made Easy with Graph Maker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Graph Maker 将文本转换为知识图谱
- en: 原文：[https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07](https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07](https://towardsdatascience.com/text-to-knowledge-graph-made-easy-with-graph-maker-f3f890c0dbe8?source=collection_archive---------0-----------------------#2024-05-07)
- en: An open-source library for building knowledge graphs from text corpus using
    open-source LLMs like Llama 3 and Mixtral.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个开源库，用于使用 Llama 3 和 Mixtral 等开源 LLM 从文本语料库构建知识图谱。
- en: '[](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Rahul
    Nayak](../Images/9f8aa2f9af4e02b31c114222756489e5.png)](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    [Rahul Nayak](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Rahul
    Nayak](../Images/9f8aa2f9af4e02b31c114222756489e5.png)](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    [Rahul Nayak](https://medium.com/@rahul.nyk?source=post_page---byline--f3f890c0dbe8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    ·11 min read·May 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f3f890c0dbe8--------------------------------)
    ·阅读时长 11 分钟·2024年5月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f16f965b89f5a55a880765fbab232f08.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f16f965b89f5a55a880765fbab232f08.png)'
- en: Image generated by the Author using Adobe Photoshop
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 Adobe Photoshop 生成
- en: In this article, I will share a Python library — the Graph Maker — that can
    create a Knowledge Graph from a corpus of text as per a given Ontology. The Graph
    Maker uses open-source LLMs like Llama3, Mistral, Mixtral or Gemma to extract
    the KG.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将分享一个 Python 库——Graph Maker，它可以根据给定的本体从文本语料库中创建知识图谱。Graph Maker 使用像
    Llama3、Mistral、Mixtral 或 Gemma 这样的开源 LLM 来提取知识图谱。
- en: We will go through the basics of ‘Why’ and ‘What’ of the Graph Maker, a brief
    recap of the previous article, and how the current approach addresses some of
    its challenges. I will share the GitHub repository at the end of this article.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回顾 Graph Maker 的基本概念，简要回顾上一篇文章，以及当前方法如何解决其中的一些挑战。我将在文章结尾分享 GitHub 仓库。
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: This article is a sequel to the article I wrote a few months ago about how to
    convert any text into a Graph.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章是我几个月前写的关于如何将任何文本转换为图的文章的续集。
- en: '[](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
    [## How to Convert Any Text Into a Graph of Concepts'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
    [## 如何将任何文本转换为概念图'
- en: A method to convert any text corpus into a Knowledge Graph using Mistral 7B.
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Mistral 7B 将任何文本语料库转换为知识图谱的方法。
- en: towardsdatascience.com](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a?source=post_page-----f3f890c0dbe8--------------------------------)
- en: The article received an overwhelming response. The GitHub repository shared
    in the article has more than 180 Forks and more than 900 Stars. The article itself
    was read by more than 80K readers on the Medium. Recently the article was attributed
    in the following paper published by Prof Markus J. Buehler at MIT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章收到了热烈的反响。文中分享的 GitHub 仓库已有超过 180 个 Fork 和超过 900 个 Stars。文章本身在 Medium 上的阅读量超过了
    80K。最近，这篇文章在麻省理工学院（MIT）Markus J. Buehler 教授发表的以下论文中被引用。
- en: '[](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)
    [## Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based
    Representation…'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)
    [## 加速科学发现：通过生成性知识提取和基于图的表示…'
- en: Leveraging generative Artificial Intelligence (AI), we have transformed a dataset
    comprising 1,000 scientific papers…
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过利用生成型人工智能（AI），我们将一个包含1,000篇科学论文的数据集进行了转化……
- en: arxiv.org](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2403.11996?source=post_page-----f3f890c0dbe8--------------------------------)'
- en: This is a fascinating paper that demonstrates the gigantic potential of Knowledge
    Graphs in the era of AI. It demonstrates how KGs can be used, not only to retrieve
    knowledge but also to discover new knowledge. Here is one of my favourite excerpts
    from this paper.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一篇引人入胜的论文，展示了在人工智能时代知识图谱的巨大潜力。它展示了知识图谱不仅可以用来检索知识，还可以用来发现新知识。这里是我最喜欢的论文摘录之一。
- en: “For instance, we will show how this approach can relate seemingly disparate
    concepts such as Beethoven’s 9th symphony with bio-inspired materials science”
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “例如，我们将展示这种方法如何将看似不相关的概念联系起来，比如贝多芬的第九交响曲与仿生材料科学之间的关系。”
- en: These developments are a big reaffirmation of the ideas I presented in the previous
    article and encouraged me to develop the ideas further.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些进展是对我在上一篇文章中提出的观点的重大确认，并鼓励我进一步发展这些想法。
- en: I also received numerous feedback from fellow techies about the challenges they
    encountered while using the repository, and suggestions for improving the idea.
    I incorporated some of these suggestions into a new Python package I share here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我还收到了许多同行技术人员的反馈，分享了他们在使用这个仓库时遇到的挑战，以及改善这个想法的建议。我将其中一些建议融入到我在这里分享的新的Python包中。
- en: Before we discuss the working of the package — The Graph Maker — let us discuss
    the ‘Why’ and the ‘What’ of it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论这个包——图形制作器——的工作原理之前，让我们先讨论一下它的“为什么”和“什么”。
- en: A Brief Recap
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简要回顾
- en: We should probably start with ‘Why Graphs’. However, We discussed this briefly
    in my [previous article](https://medium.com/towards-data-science/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a).
    Feel free to hop onto that article for a refresher. However, let us briefly discuss
    the key concepts that are relevant to our current discussion here.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能应该从“为什么是图形”开始。然而，我们在我的[上一篇文章](https://medium.com/towards-data-science/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a)中简要讨论了这个问题。请随时跳转到那篇文章进行复习。不过，让我们简要讨论一下与我们当前讨论相关的关键概念。
- en: '**TL;DR this section if you are already well versed in the lore of Knowledge
    Graphs.**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**TL;DR 如果你已经熟悉知识图谱的背景，可以跳过这一部分。**'
- en: Here is an illustration that sums up the idea of Knowledge Graphs neatly.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个插图，简洁地总结了知识图谱的理念。
- en: '![](../Images/59d71971200611f5a682adfa61e54a89.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59d71971200611f5a682adfa61e54a89.png)'
- en: 'Source: [https://arxiv.org/abs/2403.11996](https://arxiv.org/abs/2403.11996)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://arxiv.org/abs/2403.11996](https://arxiv.org/abs/2403.11996)
- en: To create a KG, we need two pieces of information.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个知识图谱，我们需要两条信息。
- en: '**Knowledge Base**: This can be a corpus of text, a code base, a collection
    of articles, etc.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**知识库**：这可以是一个文本语料库、一套代码库、一系列文章等。'
- en: '**Ontology**: The categories of the entities, and the types of their relationships
    we care about. I am probably oversimplifying the definition of ontology here but
    it works for our purpose.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**本体**：我们关心的实体类别及其关系类型。我可能在这里对本体的定义做了过于简化的解释，但这足以满足我们的目的。'
- en: Here is a simple ontology
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个简单的本体。
- en: '**Entities**: *Person, Place*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**实体**：*Person, Place*'
- en: '**Relationships:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**关系：**'
- en: '*Person —* related to → *Person*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*Person* — 相关于 → *Person*'
- en: '*Person* — lives in → *Place'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*Person* — 居住在 → *Place*'
- en: Person* — visits → *Place*
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*Person* — 访问 → *Place*'
- en: Given these two pieces of information, we can build a KG from a text that mentions
    people and places. However, let’s say our knowledge base is about a clinical study
    of prescription drugs and their interactions. We might use a different ontology
    where Compounds, Usage, Effects, Reactions etc may form our ontology.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这两条信息，我们可以从提到人物和地点的文本中构建一个知识图谱。然而，假设我们的知识库是关于处方药及其相互作用的临床研究。我们可能会使用一个不同的本体，其中可能包含化合物、用途、效果、反应等作为我们的本体。
- en: In the previous article, we discussed [**How we can extract a Knowledge Graph
    using an LLM, without supplying it with an ontology**](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a).
    The idea was to let the LLM discover the ontology best suited for the given corpus
    of text by itself.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一篇文章中，我们讨论了[**如何在不提供本体的情况下，通过LLM提取知识图谱**](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a)。这个方法的核心思想是让LLM自主发现最适合给定文本语料的本体。
- en: Although this approach lacks the rigour of the traditional methods of generating
    KGs, it has its merits. It can generate KGs with unstructured data more easily
    than traditional methods. The KGs that it generates are, in some sense, also unstructured.
    However, they are easier to build and are richer in information. They are well
    suited for GRAG (Graph Retrieval Augmented Generation) like applications.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法缺乏传统生成KG的严谨性，但它也有其优点。与传统方法相比，它可以更容易地生成来自非结构化数据的KG。它生成的KG在某种程度上也是非结构化的。然而，它们更易于构建，并且信息更为丰富。它们非常适合像GRAG（图谱检索增强生成）这样的应用。
- en: Why The Graph Maker?
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择图谱构建工具？
- en: Let me list a few challenges and observations I received in the feedback for
    my previous article. It will help us understand the challenges in creating KGs
    with LLMs. Let us use the Wikipedia summary of the **Lord of the Rings** books.
    One cant not love the Lord of the Rings after all!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我列出一些我在之前的文章反馈中收到的挑战和观察结果。这将帮助我们理解用LLM创建KG时的挑战。让我们使用《**指环王**》的维基百科摘要。毕竟，没有人能不爱《指环王》！
- en: Meaningful Entities
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有意义的实体
- en: Given a free run, the entities that the LLM extracts can be too diverse in their
    categories. It mistakes by marking abstract concepts as entities. For example
    in the text “Bilbo Baggins celebrates his birthday and leaves the Ring to Frodo”,
    the LLM may extract “Bilbo Baggins celebrates his birthday” or “Celebrates his
    birthday” as ‘Action’. But it may be more useful if it extracts “Birthday” as
    an ‘Event’.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在自由运行的情况下，LLM提取的实体可能在其类别上过于多样。它会错误地将抽象概念标记为实体。例如，在“比尔博·巴金斯庆祝他的生日并把戒指交给弗罗多”这段文字中，LLM可能会提取“比尔博·巴金斯庆祝他的生日”或“庆祝他的生日”作为‘动作’。但如果它提取“生日”作为‘事件’，可能会更有用。
- en: '**Consistent Entities**'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**一致的实体**'
- en: 'It can also mistake marking the same entity differently in different contexts.
    For example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可能会在不同的上下文中错误地标记同一实体。例如：
- en: '**‘*Sauron’***, **‘*the Dark Lord Sauron’***and***‘the Dark Lord’***Should
    not be extracted as different entities. Or if they are extracted as different
    entities, they should be connected with an equivalence relationship.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**‘*索伦*’**，**‘*黑暗领主索伦*’** 和 ***‘黑暗领主’*** 不应被提取为不同的实体。或者，如果它们被提取为不同的实体，它们应该通过等价关系连接。'
- en: '**Resilience in parsing**'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**解析的韧性**'
- en: The output of the LLMs is, by nature, indeterministic. To extract the KG from
    a large document, we must split the corpus into smaller text chunks and then generate
    subgraphs for every chunk. To build a consistent graph, the LLM must output JSON
    objects as per the given schema consistently for every subgraph. Missing even
    one may affect the connectivity of the entire graph adversely.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大语言模型）的输出本质上是非确定性的。为了从大文档中提取知识图谱（KG），我们必须将语料库分割成较小的文本块，然后为每个文本块生成子图。为了构建一致的图谱，LLM必须按照给定的架构一致地输出JSON对象。如果缺少任何一个，可能会不利地影响整个图谱的连通性。
- en: Although LLMs are getting better at responding with well-formatted JSON objects,
    It is still far from perfect. LLMs with limited context windows may also generate
    incomplete responses.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM在响应时能够更好地生成格式良好的JSON对象，但它仍远未完美。具有有限上下文窗口的LLM也可能生成不完整的响应。
- en: '**Categorisation of the Entities**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**实体的分类**'
- en: LLMs can error generously when recognising entities. This is a bigger problem
    when the context is domain-specific, or when the entities are not named in standard
    English. NER models can do better at that, but they too are limited to the data
    they are trained on. Moreover, they can’t understand the relations between the
    entities.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别实体时，LLM可能会出现较大的错误。当上下文是领域特定的，或者实体没有标准英语命名时，这个问题尤为严重。命名实体识别（NER）模型在这方面做得更好，但它们也受到所训练数据的限制。此外，它们无法理解实体之间的关系。
- en: To coerce an LLM to be consistent with categories is an art in prompt engineering.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 强迫LLM在分类上保持一致是一门提示工程中的艺术。
- en: '**Implied relations**'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**隐含关系**'
- en: 'Relations can be explicitly mentioned, or implied by the context. For example:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 关系可以被明确提到，也可以通过上下文隐含。例如：
- en: '“Bilbo Baggins celebrates his birthday and leaves the Ring to Frodo” implies
    the relationships:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: “比尔博·巴金斯庆祝他的生日并把戒指交给弗罗多”隐含了以下关系：
- en: '*Bilbo Baggins* → Owner → *Ring*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*比尔博·巴金斯* → 所有者 → *戒指*'
- en: '*Bilbo Baggins* → heir → *Frodo*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*比尔博·巴金斯* → 继承人 → *弗罗多*'
- en: '*Frodo* → Owner → *Ring*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*弗罗多* → 所有者 → *戒指*'
- en: Here I think LLMs at some point in time will become better than any traditional
    method of extracting relationships. But as of now, this is a challenge that needs
    clever prompt engineering.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为，大型语言模型（LLMs）在某个时刻会超越任何传统的关系提取方法。但目前来说，这是一个需要巧妙提示工程的挑战。
- en: The Graph Maker
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图谱生成器
- en: The graph maker library I share here improves upon the previous approach by
    travelling halfway between the rigour and the ease — halfway between the structure
    and the lack of it. It does remarkably better than the previous approach I discussed
    on most of the above challenges.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里分享的图谱生成库在以往方法的基础上做出了改进，通过在严谨性和简易性之间走了一条折中的路——在结构化和非结构化之间走了一条折中的路。与我之前讨论的方式相比，它在上述大部分挑战中表现得更加出色。
- en: As opposed to the previous approach, where the LLM is free to discover the ontology
    by itself, the graph maker tries to coerce the LLM to use a user-defined ontology.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的方法不同，在之前的方法中，LLM可以自行发现本体，而图谱生成器则尝试强制LLM使用用户定义的本体。
- en: We can install the knowledge graph maker library with a simple pip command
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单的pip命令安装知识图谱生成库。
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
    [## knowledge-graph-maker'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
    [## knowledge-graph-maker'
- en: Create a knowledge graph out of any text using a given ontology
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用给定的本体从任何文本中创建知识图谱。
- en: pypi.org](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: pypi.org](https://pypi.org/project/knowledge-graph-maker/?source=post_page-----f3f890c0dbe8--------------------------------)
- en: Here is how it works in 5 easy steps.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是它如何通过5个简单步骤工作的。
- en: These steps are coded in a notebook that I share at the end of this article.
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些步骤的代码已包含在我在本文最后分享的笔记本中。
- en: 1\. Define the Ontology of your Graph
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 定义你的图谱本体。
- en: The library understands the following schema for the Ontology. Behind the scenes,
    ontology is a pydantic model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 该库理解以下本体模式。在幕后，本体是一个Pydantic模型。
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I have tuned the prompts to yield results that are consistent with the given
    ontology. I think it does a pretty good job at it. However, it is still not 100%
    accurate. The accuracy depends on the model we choose to generate the graph, the
    application, the ontology, and the quality of the data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经调整了提示，以使结果与给定的本体一致。我认为它做得相当不错。不过，它仍然不是100%准确。准确度取决于我们选择的生成图谱的模型、应用程序、本体和数据的质量。
- en: 2\. Split the text into chunks.
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 将文本拆分成块。
- en: We can use as large a corpus of text as we want to create large knowledge graphs.
    However, LLMs have a finite context window right now. So we need to chunk the
    text appropriately and create the graph one chunk at a time. The chunk size that
    we should use depends on the model context window. The prompts that are used in
    this project eat up around 500 tokens. The rest of the context can be divided
    into input text and output graph. In my experience, smaller chunks of 200 to 500
    tokens generate a more detailed graph.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用尽可能大的文本语料库来创建大型知识图谱。然而，目前LLMs有一个有限的上下文窗口。所以我们需要适当地将文本拆分成块，并逐块地创建图谱。我们应该使用的块大小取决于模型的上下文窗口。此项目中使用的提示大约消耗500个tokens，其余的上下文可以分为输入文本和输出图谱。根据我的经验，较小的200到500个tokens的块会生成更详细的图谱。
- en: 3\. Convert these chunks into Documents.
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 将这些块转换为文档。
- en: The document is a pydantic model with the following schema
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该文档是一个Pydantic模型，具有以下模式。
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The metadata we add to the document here is tagged to every relation that is
    extracted out of the document.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在文档中添加的元数据会被标记到每个从文档中提取出的关系上。
- en: We can add the context of the relation, for example, the page number, chapter,
    the name of the article, etc. into the metadata. More often than not, Each node
    pairs have multiple relations with each other across multiple documents. The metadata
    helps contextualise these relationships.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将关系的上下文（例如，页码、章节、文章名称等）添加到元数据中。通常情况下，每对节点在多个文档中有多个关系。元数据有助于为这些关系提供上下文。
- en: 4\. Run the Graph Maker.
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 运行图谱生成器。
- en: The Graph Maker directly takes a list of documents and iterates over each of
    them to create one subgraph per document. The final output is the complete graph
    of all the documents.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图谱生成器直接接受一个文档列表，并对每个文档进行迭代，为每个文档创建一个子图。最终输出是所有文档的完整图谱。
- en: Here is a simple example of how to achieve this.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个简单的例子，展示如何实现这一点。
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The Graph Makers run each document through the LLM and parse the response to
    create the complete graph. The final graph is as a list of edges, where every
    edge is a pydantic model like the following.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图形制造者将每个文档输入LLM，并解析响应以创建完整的图形。最终图形是由一系列边组成，每一条边都是像下面这样的pydantic模型。
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: I have tuned the prompts so they generate fairly consistent JSONs now. In case
    the JSON response fails to parse, the graph maker also tries to manually split
    the JSON string into multiple strings of edges and then tries to salvage whatever
    it can.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我已调整了提示，使它们现在能生成相对一致的JSON。如果JSON响应解析失败，图形制造者还会尝试手动将JSON字符串拆分成多条边字符串，然后尽力恢复它能找到的部分。
- en: 5\. Save to Neo4j
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 保存到Neo4j
- en: We can save the model to Neo4j either to create an RAG application, run Network
    algorithms, or maybe just visualise the graph using [the Bloom](https://neo4j.com/product/bloom/)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将模型保存到Neo4j中，既可以创建RAG应用程序，运行网络算法，也可以仅仅是通过[Bloom](https://neo4j.com/product/bloom/)来可视化图形。
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Each edge of the graph is saved to the database as a transaction. If you are
    running this code for the first time, then set the `create_indices` to true. This
    prepares the database by setting up the uniqueness constraints on the nodes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图形的每一条边都会作为事务保存到数据库中。如果你是第一次运行这段代码，请将`create_indices`设置为true。这会通过设置节点的唯一性约束来准备数据库。
- en: '***5.1 Visualise, just for fun if nothing else*** In the previous article,
    we visualised the graph using networkx and pyvis libraries. Here, because we are
    already saving the graph to Neo4J, we can leverage Bloom directly to visualise
    the graph.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '***5.1 可视化，至少为了好玩*** 在上一篇文章中，我们使用networkx和pyvis库可视化了图形。在这里，因为我们已经将图形保存到Neo4J，我们可以直接利用Bloom来可视化图形。'
- en: To avoid repeating ourselves, let us generate a different visualisation from
    what we did in the previous article.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免重复，我们将在本篇文章中生成与上一篇不同的可视化效果。
- en: Let’s say we like to see how the relations between the characters evolve through
    the book.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想查看书中人物之间关系是如何发展的。
- en: We can do this by tracking how the edges are added to the graph incrementally
    while the graph maker traverses through the book. To enable this, the Edge model
    has an attribute called ‘order’. This attribute can be used to add a temporal
    or chronological dimension to the graph.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过追踪图形在图表制造者浏览书籍时逐步添加的边来实现这一点。为了实现这一点，边模型有一个叫做“order”的属性。这个属性可以用来为图形添加时间性或顺序维度。
- en: In our example, the graph maker automatically adds the sequence number in which
    a particular text chunk occurs in the document list, to every edge it extracts
    from that chunk. So to see how the relations between the characters evolve, we
    just have to cross section the graph by the order of the edges.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，图形制造者会自动将特定文本块在文档列表中出现的顺序号添加到它从该块提取的每一条边上。所以要查看人物之间关系如何发展，我们只需按边的顺序对图形进行交叉截面。
- en: Here is an animation of these cross-sections.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这些交叉截面的动画。
- en: '![](../Images/ef0062beb0ec37c82d0bcaa3403679f3.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef0062beb0ec37c82d0bcaa3403679f3.png)'
- en: Animation generated by the Author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作者生成的动画
- en: Graph and RAG
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图形和RAG
- en: The best application of this kind of KG is probably in RAG. There are umpteen
    articles on Medium on how to augment your RAG applications with Graphs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这种KG的最佳应用可能是在RAG中。在Medium上有大量的文章讨论如何通过图形增强你的RAG应用。
- en: Essentially Graphs offer a plethora of different ways to retrieve knowledge.
    Depending on how we design the Graph and our application, some of these techniques
    can be more powerful than simple semantic search.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，图形提供了多种不同的知识检索方式。根据我们如何设计图形和应用程序，其中一些技术可能比简单的语义搜索更强大。
- en: At the very basic, we can add embedding vectors into our nodes and relationships,
    and run a semantic search against the vector index for retrieval. However, I feel
    the real power of the Graphs for RAG applications is when we mix Cypher queries
    and Network algorithms with Semantic Search.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从最基本的角度来看，我们可以将嵌入向量添加到节点和关系中，并对向量索引进行语义搜索以进行检索。然而，我觉得图形在RAG应用中的真正力量是当我们将Cypher查询和网络算法与语义搜索结合时。
- en: I have been exploring some of these techniques myself. I am hoping to write
    about them in my next article.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我自己也在探索一些这些技术。我希望在下一篇文章中写到它们。
- en: The Code
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码
- en: Here is the GitHub Repository. Please feel free to take it for a spin. I have
    also included an example Python notebook in the repository that can help you get
    started quickly.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是GitHub仓库。欢迎随意试用。我还在仓库中包含了一个示例Python笔记本，帮助你快速入门。
- en: Please note that you will need to add your [GROQ credentials](https://console.groq.com/keys)
    in the ***.env*** file before you can get started.
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请注意，在开始之前，你需要在***.env***文件中添加你的[GROQ凭证](https://console.groq.com/keys)。
- en: '[](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
    [## GitHub - rahulnyk/graph_maker'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
    [## GitHub - rahulnyk/graph_maker'
- en: Contribute to rahulnyk/graph_maker development by creating an account on GitHub.
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在GitHub上创建账户，参与rahulnyk/graph_maker的开发。
- en: github.com](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/rahulnyk/graph_maker?source=post_page-----f3f890c0dbe8--------------------------------)
- en: Initially, I developed this codebase for a few of my pet projects. I feel it
    can be helpful for many more applications. If you use this library for your applications,
    please share it with me. I would love to learn about your use cases.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我为一些个人项目开发了这个代码库。我觉得它对更多的应用也会很有帮助。如果你在应用中使用这个库，请与我分享。我非常希望了解你的使用案例。
- en: Also if you feel you can contribute to this open source project, please do so
    and make it your own.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得自己可以为这个开源项目做出贡献，请随时参与，并将其做成自己的项目。
- en: I hope you find the graph maker useful. Thanks for reading.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得图表生成器有用。感谢阅读。
- en: I am a learner of architecture (not the buildings… the tech kind). In the past,
    I have worked with Semiconductor modelling, Digital circuit design, Electronic
    Interface modelling, and the Internet of Things.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一名架构学习者（不是建筑物的那种…是技术类型的）。过去，我曾从事半导体建模、数字电路设计、电子接口建模和物联网相关工作。
- en: Currently, Data and Consumer Analytics @Walmart Keeps me busy.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，沃尔玛的数据与消费者分析工作让我忙碌不已。
- en: Thanks
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 谢谢
