- en: Beyond the Blind Zone
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越盲区
- en: 原文：[https://towardsdatascience.com/beyond-the-blind-zone-706ba4b171c5?source=collection_archive---------10-----------------------#2024-04-05](https://towardsdatascience.com/beyond-the-blind-zone-706ba4b171c5?source=collection_archive---------10-----------------------#2024-04-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/beyond-the-blind-zone-706ba4b171c5?source=collection_archive---------10-----------------------#2024-04-05](https://towardsdatascience.com/beyond-the-blind-zone-706ba4b171c5?source=collection_archive---------10-----------------------#2024-04-05)
- en: Inpainting radar gaps with deep learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用深度学习修复雷达盲区
- en: '[](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)[![Fraser
    King](../Images/7d24cfc8432660d0a09c0acabd79ebb6.png)](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)
    [Fraser King](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)[![Fraser
    King](../Images/7d24cfc8432660d0a09c0acabd79ebb6.png)](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)
    [Fraser King](https://medium.com/@frasertheking?source=post_page---byline--706ba4b171c5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)
    ·19 min read·Apr 5, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--706ba4b171c5--------------------------------)
    ·19分钟阅读·2024年4月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3fdf81845653284f63fa771d0ef57350.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fdf81845653284f63fa771d0ef57350.png)'
- en: Overview
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this post, we review high-level details from our recent work on image inpainting
    of radar blind zones. We discuss the main science problems, inpainting techniques,
    model architecture decisions, fidelity metrics, uncertainties, and finish with
    an analysis of model explainability (XAI), in the hope that this information can
    help others when planning future, similar projects. This work was recently published
    in the American Meteorologic Society’s Artificial Intelligence for Earth Sciences
    (AIES) [https://doi.org/10.1175/AIES-D-23-0063.1](https://doi.org/10.1175/AIES-D-23-0063.1),
    which we recommend readers view for additional project details.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们回顾了最近关于雷达盲区图像修复的工作中的高层次细节。我们讨论了主要的科学问题、修复技术、模型架构决策、准确性指标、不确定性，并最后分析了模型的可解释性（XAI），希望这些信息能够帮助他人在规划未来类似项目时提供帮助。此项工作最近发表在美国气象学会的《地球科学人工智能（AIES）》期刊中，
    [https://doi.org/10.1175/AIES-D-23-0063.1](https://doi.org/10.1175/AIES-D-23-0063.1)，我们建议读者查看以获取更多项目细节。
- en: Motivation
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: Radar observations are powerful sources of information for tasks like precipitation
    forecasting. These systems are used by millions of people daily to help plan their
    lives, and their predictive accuracy has large economic impacts to agriculture,
    tourism, and the outdoor recreation industry. But how do these systems work? In
    a nutshell, these predictive models relate precipitation rates to power backscatter
    measurements from a radar signal interacting with falling hydrometeors in the
    atmosphere (Fig. 1). With a large enough reference dataset, we can take the information
    produced by the radar profile (along with some atmospheric state variables) and
    back-out an estimate of surface precipitation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 雷达观测是进行降水预测等任务的强大信息来源。这些系统每天被数百万用户使用，帮助他们规划生活，并且它们的预测准确性对农业、旅游业和户外休闲产业具有巨大经济影响。但这些系统是如何工作的呢？简而言之，这些预测模型将降水率与雷达信号与大气中降水气象物体相互作用时的回波功率测量联系起来（图1）。通过足够大的参考数据集，我们可以利用雷达资料（以及一些大气状态变量）反推出地面降水的估计值。
- en: '![](../Images/428f33fcb7a69a74219ec8f0319157f3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/428f33fcb7a69a74219ec8f0319157f3.png)'
- en: '**Figure 1:** a) Reflectivity profile showing the power backscattered by the
    cloud; b) Vertical profile of the snowfall rate estimates in the cloud; and c)
    surface snowfall rates extrapolated down from the lowest precipitating cloud layer
    shown in b). Image retrieved from King et al., 2020 ([https://doi.org/10.1029/2019EA000776](https://doi.org/10.1029/2019EA000776)).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1：** a) 反射率剖面图，显示云层反向散射的功率；b) 云中降雪率估算的垂直剖面；c) 从b)所示最低降水云层推算出的地面降雪率。图片来自King等人，2020年（[https://doi.org/10.1029/2019EA000776](https://doi.org/10.1029/2019EA000776)）。'
- en: 'Unlike vertical-pointing surface radar instruments which are stationary, satellites
    are unrestricted in space and can provide a much richer, comprehensive view of
    global precipitation patterns due to their orbit. However, unlike surface radars,
    satellite instruments exhibit a unique type of measurement problem since they
    point down towards the Earth: a radar blind zone. As implied by its name, the
    blind zone is a portion of the radar profile that the satellite cannot directly
    observe. As the downward pointed radar signal reaches the Earth’s surface, the
    backscatter from the ground produces an attenuated signal that becomes saturated
    with noise (and therefore unobserved). A comparison between surface and spaceborne
    radars (and the corresponding blind zone) is illustrated in Fig. 2.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与垂直指向的地面雷达仪器静止不动不同，卫星在太空中没有限制，并且由于其轨道可以提供更丰富、全面的全球降水模式视图。然而，与地面雷达不同，卫星仪器由于指向地球而表现出一种独特的测量问题：雷达盲区。顾名思义，盲区是卫星无法直接观察的雷达剖面的一部分。当向下指向的雷达信号到达地球表面时，来自地面的反向散射产生的信号被衰减，并且饱和在噪声中（因此无法观察到）。图2展示了地面雷达与空间雷达之间的比较（以及相应的盲区）。
- en: '![](../Images/430ec51b523cca2df63b7702bdcee143.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/430ec51b523cca2df63b7702bdcee143.png)'
- en: '**Figure 2:** Multi-panel of coincident vertical reflectivity profiles from
    a surface radar, CloudSat and the Global Precipitation Measurement mission, along
    with their respective radar blind zones. Image retrieved from Kidd et al., 2021
    ([https://doi.org/10.3390/rs13091708](https://doi.org/10.3390/rs13091708)).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2：** 多面板的垂直反射率剖面图，来自地面雷达、CloudSat和全球降水测量任务，以及它们各自的雷达盲区。图片来自Kidd等人，2021年（[https://doi.org/10.3390/rs13091708](https://doi.org/10.3390/rs13091708)）。'
- en: While the size of the blind zone region can vary, it is a common issue on active
    spaceborne systems (e.g. GPM, CloudSat) that will persist as a source of uncertainty
    in future Earth observing missions (e.g. EarthCARE and AOS). Additionally, although
    this region is just a small subset of the full profile (only about 4% of CloudSat’s
    vertical extent, for instance), this 0–2 km of the atmosphere can contain large
    quantities of precipitating cloud (Lamer et al., 2020). Therefore, by masking
    this region, we are potentially missing a large quantity of snow (or overestimating
    snow in the case of virga), further increasing the uncertainty of an already uncertain
    estimate of surface snow accumulation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管盲区的大小可能会有所不同，但它是活动空间系统（例如GPM、CloudSat）上常见的问题，并将在未来的地球观测任务（例如EarthCARE和AOS）中持续作为不确定性的来源。此外，尽管该区域仅占整个剖面的一小部分（例如，仅占CloudSat垂直范围的约4%），但大气的0-2公里范围内可能包含大量降水云（Lamer等人，2020）。因此，通过掩盖该区域，我们可能会遗漏大量雪（或在虚幻雨的情况下高估雪量），从而进一步增加已经存在的不确定性的地面积雪量估算误差。
- en: '*… the blind zone leads to reflectivity being underestimated by up to 1 dB,
    the number of events being altered by +/- 5% and the precipitation amount being
    underestimated by 9 to 11 percentage points (Maahn et al., 2014).*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*…盲区导致反射率被低估最多1 dB，事件数量变化幅度为+/- 5%，降水量低估了9到11个百分点（Maahn等人，2014）。*'
- en: '**What can we do about this?**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们能做些什么？**'
- en: Our Solution
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的解决方案
- en: At its core, the ideas behind image inpainting have been around for decades
    for use in things like image restoration (e.g. removing a scratch on a family
    photo), or object removal (removing a tourist in a picture from your last vacation)
    (Guillemot and Le Meur, 2013). Originally, this type of repair was a costly endeavour
    that was done by hand by a trained artist (Fig. 2), but as has become increasingly
    clear in recent years, computers are quite skilled at this task too (with much
    shorter training times compared to a human)!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，图像修复的思想已经存在数十年，应用于图像修复（例如，去除家庭照片上的划痕）或物体移除（例如，去除你度假时照片中的游客）（Guillemot
    和 Le Meur，2013）。最初，这种类型的修复是一项昂贵的工作，需要由受过训练的艺术家手工完成（图 2），但近年来越来越明显的是，计算机也非常擅长这项任务（与人类相比，训练时间短得多）！
- en: '![](../Images/8fd0c522bdefa88df8d4a0bfc274bba3.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fd0c522bdefa88df8d4a0bfc274bba3.png)'
- en: '**Figure 3:** Painting restoration by hand by a trained professional. Image
    courtesy of Ana Alba.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3：** 由受过训练的专业人士手工修复画作。图片由 Ana Alba 提供。'
- en: While the first iterations of these techniques like structure-based linear interpolation,
    texture-synthesis-based Efros interpolation, and diffusion-based Laplace or Navier-Stokes
    interpolation can work well in certain contexts, they often fell short when dealing
    with large gaps. The differences between these techniques are shown in Fig. 4
    where an elephant mask is inpainted in the center of the image. These techniques
    rely heavily on information/patterns from the edges of the targeted inpainting
    region and are often unable to effectively make use information from the scene’s
    global context when making intelligent predictions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些技术的早期迭代，如基于结构的线性插值、基于纹理合成的Efros插值，以及基于扩散的拉普拉斯或纳维-斯托克斯插值，在某些情况下可以很好地工作，但在处理大面积缺失时往往效果不佳。图
    4 展示了这些技术之间的差异，其中大象的掩模被填充到图像的中心。这些技术通常严重依赖于目标修复区域边缘的图像信息/模式，并且在进行智能预测时，往往无法有效利用场景的全局上下文信息。
- en: '![](../Images/cfee9ef65e81acff2d979d9d7a73d2a4.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfee9ef65e81acff2d979d9d7a73d2a4.png)'
- en: '**Figure 4:** Object removal application a) mask and inpainting results with
    methods from different categories; b) anisotropic diffusion, c) exemplar-base;
    d) patch sparse representation, e) hybrid with one global energy minimization;
    and f) patch offsets. Image retrieved from Guillemot and Le Meur, 2013 ([https://doi.org/10.1109/MSP.2013.2273004](https://doi.org/10.1109/MSP.2013.2273004)).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4：** 物体移除应用 a) 不同类别方法的掩模和修复结果；b) 各向异性扩散，c) 示例基础；d) 补丁稀疏表示，e) 与全局能量最小化的混合；f)
    补丁偏移。图片来源：Guillemot 和 Le Meur, 2013 ([https://doi.org/10.1109/MSP.2013.2273004](https://doi.org/10.1109/MSP.2013.2273004))。'
- en: However, the field of computer vision has flourished in recent decades, primarily
    driven by advances in computing power and the development of newer, more efficient
    machine learning techniques. Generative approaches using Generative Adversarial
    Networks (GANs) for instance have been very popular recently with OpenAI’s [DALL-E](https://openai.com/dall-e-2),
    or Stability.ai’s [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release),
    producing incredibly realistic images based on a simple text prompt. There has
    also been some work previously attempting to use similar methods for inpainting,
    but there exists a trade-off between realism and fidelity/stability for inpainting
    taskings (Lugmayr et al., 2017; Geiss and Hardin, 2021).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，近年来计算机视觉领域迅猛发展，主要得益于计算能力的提升和更新、更高效的机器学习技术的出现。例如，使用生成对抗网络（GAN）的生成方法近年来非常流行，OpenAI
    的 [DALL-E](https://openai.com/dall-e-2) 或 Stability.ai 的 [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)
    可以基于简单的文本提示生成令人惊叹的真实图像。之前也有一些尝试使用类似方法进行修复的工作，但在修复任务中，现实感与保真度/稳定性之间存在一定的权衡（Lugmayr
    等，2017；Geiss 和 Hardin，2021）。
- en: For instance, while you might generate a region of an image that looks great
    to the human eye, the actual pixel values are not necessarily correct if compared
    to a reference image and may vary quite a bit based on the provided random noise/seed
    (Fig. 5). This is not unexpected, though, as these techniques are not necessarily
    constructed with such constraints in mind and exist for other purposes.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，虽然你可能生成了一个从人眼来看非常不错的图像区域，但如果与参考图像进行比较，实际的像素值不一定是正确的，并且可能会根据提供的随机噪声/种子变化较大（图
    5）。不过，这并不令人意外，因为这些技术并非以此类约束为设计目标，而是为其他目的而存在。
- en: '![](../Images/f6a99a28b7fd4d2291878e4d597054fe.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6a99a28b7fd4d2291878e4d597054fe.png)'
- en: '**Figure 5:** A set of examples from the *Denoising Diffusion Probabilistic
    Models (DDPM) project for image inpainting introduced in* Lugmayr et al., 2017
    ([https://doi.org/10.1109/CVPR52688.2022.01117](https://doi.org/10.1109/CVPR52688.2022.01117)).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 5：** 来自*Lugmayr 等人，2017年（[https://doi.org/10.1109/CVPR52688.2022.01117](https://doi.org/10.1109/CVPR52688.2022.01117)）的图像修复项目的去噪扩散概率模型（DDPM）示例集。'
- en: 'Instead, we focus on another machine learning architecture in this work: the
    U-Net. U-Nets are a class of Convolutional Neural Networks (CNNs), that ingest
    information in the form of an image (typically) and produce an output that is
    of the same dimensions. Often used for image segmentation, the encoder-decoder
    architecture of the U-Net allow the model to learn both local and global features
    of an image (context that is often quite valuable for correctly interpreting an
    image’s content during inpainting). We will use this architecture to teach the
    model to learn about latent features in aloft cloud to predict near surface reflectivity
    data in the aforementioned radar blind zone.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在本工作中我们专注于另一种机器学习架构：U-Net。U-Net是一类卷积神经网络（CNN），它以图像（通常是图像）的形式输入信息，并生成与输入相同维度的输出。U-Net通常用于图像分割，其编码器-解码器架构使得模型能够学习图像的局部和全局特征（这种上下文对于正确解读图像内容，特别是在图像修复过程中，通常非常有价值）。我们将使用这种架构来教导模型学习高空云中的潜在特征，以预测前述雷达盲区的近地面反射率数据。
- en: Data
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: 'The data used in this project comes from primary two sources:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目使用的数据主要来自两个来源：
- en: '[**ARM KaZR CloudSat-aligned reflectivity**](https://www.arm.gov/capabilities/science-data-products/vaps/kazrarsclcloudsat)'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[**ARM KaZR CloudSat对准反射率**](https://www.arm.gov/capabilities/science-data-products/vaps/kazrarsclcloudsat)'
- en: '[**ERA-5**](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5)'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[**ERA-5**](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5)'
- en: Both datasets are publicly available (governed by the [Creative Commons Attribution
    4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/))
    and are collocated at two Arctic locations in northern Alaska, USA at North Slope
    and Oliktok Point (Fig. 6). Since we are focused on snowfall, we limit our observations
    to cold periods below 2 degrees C. Further, data is split in contiguous training/validation/testing
    chunks to avoid overfitting from autocorrelation as shown in Fig. 6.c. We are
    using radar reflectivity data from the ARM KaZR, along with temperature, specific
    humidity, u-component wind, and v-component wind from ERA-5.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个数据集是公开可用的（由[知识共享署名 4.0 国际版（CC BY 4.0）](https://creativecommons.org/licenses/by/4.0/)授权），并位于美国阿拉斯加北部的两个北极地点——北坡和奥利克托克点（图
    6）。由于我们关注的是降雪，因此我们将观测限制在2摄氏度以下的寒冷时期。此外，为了避免由于自相关导致的过拟合，数据被划分为连续的训练/验证/测试块，如图6.c所示。我们使用来自ARM
    KaZR的雷达反射率数据，以及来自ERA-5的温度、比湿、u分量风和v分量风数据。
- en: '![](../Images/d4585b57b89a6d6cfbaff626021b8056.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4585b57b89a6d6cfbaff626021b8056.png)'
- en: '**Figure 6:** a) Study site locations; b) surface MET temperature timeseries
    at NSA and OLI; and c) data splitting methods used for model training. Image by
    author.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 6：** a) 研究地点位置；b) NSA和OLI的地面气象温度时间序列；c) 用于模型训练的数据拆分方法。图像由作者提供。'
- en: Our Model
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的模型
- en: What type of U-Net should be used for this task? We experimented with a variety
    of different U-Nets in this project, including the UNet++ model from Zhou et al.,
    2018 and the 3Net+ from Huang et al., 2020\. But let’s talk about the model architecture
    for a moment. For instance, why use these methods over a just a traditional U-Net?
    First let’s review how U-Nets work.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在此任务中应使用哪种类型的U-Net？我们在本项目中尝试了多种不同的U-Net，包括Zhou等人，2018年的UNet++模型和Huang等人，2020年的3Net+。但让我们先聊聊模型架构。例如，为什么使用这些方法而不是传统的U-Net？首先，我们回顾一下U-Net是如何工作的。
- en: U-Nets are primarily thought of in three parts, an encoder path, a bottleneck
    layer, and a decoder path. The encoder is responsible for taking your initially
    high-resolution image, and through a series of convolutions and pooling steps,
    trades spatial information for rich feature information (learning about the latent
    context of your image). Depending on how deep your network is, these latent features
    are encoded most densely in the lowest dimensionality bottleneck layer at the
    base of the U. At this point, the image array may be only a fraction of the size
    of the original, and while you’ve lost most of the spatial information, the model
    has identified a set of embeddings that represent what it sees as key elements.
    Then, in the decoder path, the reverse occurs. The low-resolution, feature-rich
    arrays in the bottleneck layer are downsampled until the feature information has
    been transformed back into spatial information (resulting in a final image that
    has the same dimensions as the original).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: U-Net 通常被认为由三个部分组成：编码器路径、瓶颈层和解码器路径。编码器负责处理最初的高分辨率图像，通过一系列卷积和池化步骤，将空间信息转换为丰富的特征信息（学习图像的潜在上下文）。根据网络的深度，这些潜在特征在
    U 形网络底部的最低维瓶颈层中被最密集地编码。在这一点上，图像数组的大小可能只有原始图像的一个小部分，尽管你已经丧失了大部分空间信息，但模型已经识别出一组嵌入，代表它认为的关键元素。然后，在解码器路径中，反向过程发生。瓶颈层中低分辨率、特征丰富的数组会被下采样，直到特征信息被转化回空间信息（生成一个最终图像，其尺寸与原始图像相同）。
- en: One of the key differences between a U-Net, U-Net++ and 3Net+, is how each variation
    handles skip connections (Fig. 7). Skip connections allow these models to “skip”
    some data directly across the encoder path to be used in the decoder, which helps
    in conveying low-level feature information during decoding and produces a more
    stable model that converges in meaningful ways. In a vanilla U-Net for example,
    these connections simply concatenate feature maps from the contracting encoder
    path to the corresponding level in the decoding expansive path.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: U-Net、U-Net++ 和 3Net+ 之间的关键区别之一在于每种变体如何处理跳跃连接（图 7）。跳跃连接允许这些模型直接将一些数据从编码器路径跳跃到解码器中使用，这有助于在解码过程中传递低级特征信息，并生成一个更稳定的模型，使其能够以有意义的方式收敛。例如，在一个普通的
    U-Net 中，这些连接只是将来自收缩编码器路径的特征图与解码扩展路径中相应的层连接起来。
- en: '![](../Images/d375e4f7f7a8acf030ae34c5433dfb51.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d375e4f7f7a8acf030ae34c5433dfb51.png)'
- en: '**Figure 7:** Comparisons between a) U-Net; b) U-Net++; and c) 3Net+ model
    architectures. Image retrieved from Huang et al., 2020 ([https://doi.org/10.48550/arXiv.2004.08790](https://doi.org/10.48550/arXiv.2004.08790)).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 7：** a) U-Net；b) U-Net++；以及 c) 3Net+ 模型架构的比较。图像来源于 Huang 等人，2020（[https://doi.org/10.48550/arXiv.2004.08790](https://doi.org/10.48550/arXiv.2004.08790)）。'
- en: The UNet++ introduces a series of nested and dense skip pathways that attempt
    to address the issue of the unknown depth of the optimal architecture in a traditional
    U-Net. Instead of just having direct connections from the encoder to the decoder,
    the UNet++ has multiple skip pathways. For a given level in the encoder, there
    are skip connections to all subsequent levels in the decoder, creating a dense
    set of connections. These nested skip connections are designed to capture and
    fuse features at various semantic levels more effectively than the vanilla U-Net,
    however this comes at the cost of a larger model (more parameters) and increased
    training times.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: UNet++ 引入了一系列嵌套和密集的跳跃路径，试图解决传统 U-Net 中最优架构的未知深度问题。UNet++ 不仅仅是从编码器到解码器有直接连接，它有多个跳跃路径。对于编码器中的每个层级，都有跳跃连接到解码器中的所有后续层级，形成一个密集的连接集。这些嵌套的跳跃连接旨在比普通的
    U-Net 更有效地捕捉和融合不同语义层次的特征，然而这也带来了模型变大（更多参数）和训练时间增加的代价。
- en: The 3Net+ builds on ideas of both previous techniques and is the architecture
    used in our final model (Fig. 8). This method breaks the skip connections into
    a series of across-skip connections (similar to the vanilla U-Net), inter-skip
    connections, and intra-skip connections. These inter- and intra- skip connections
    make full use of multi-scale features in the scene by passing information in a
    manner which incorporates low-level details with high-level semantics from feature
    maps in full scales, but with fewer parameters to the U-Net++ model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 3Net+基于前述技术的思想，并且是我们最终模型（图 8）中使用的架构。该方法将跳跃连接分解为一系列跨跳跃连接（类似于经典的U-Net）、跳跃间连接和跳跃内连接。这些跳跃间和跳跃内连接通过传递信息，结合特征图中的低级细节与高级语义，有效利用了场景中的多尺度特征，同时相比于U-Net++模型，使用了更少的参数。
- en: '![](../Images/bef457d14bf4a1db66331064820d8da4.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bef457d14bf4a1db66331064820d8da4.png)'
- en: '**Figure 8:** a) 128x128 chunks of input KaZR and ERA-5 variables; and b) our
    model’s 3Net+ architecture with deep supervision layers. Image by author.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 8：** a) 128x128大小的KaZR和ERA-5输入变量块；b) 我们模型的3Net+架构及深度监督层。图像由作者提供。'
- en: Further, our model makes use of deep supervision to learn hierarchical representations
    from the full-scale aggregated feature maps at each level of the decoder. This
    helps the model learn to correctly position clouds within the blind zone by examining
    the wider context of the scene. In the remaining sections we will compare the
    skill of this 3Net+ model trained on just reflectivity (herein denoted as 3+_1),
    another version trained on reflectivity and ERA5 data (3+_5) and two linear inpainting
    techniques using repeating extrapolation (REP) and marching average (MAR) methods.
    For additional details on how these are implemented, please refer to our AIES
    paper.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的模型利用深度监督从解码器每一层的全尺度聚合特征图中学习层次化表示。这帮助模型通过检查场景的更广泛上下文来正确定位盲区中的云。在接下来的部分中，我们将比较仅在反射率上训练的3Net+模型（以下简称为3+_1），另一个在反射率和ERA5数据上训练的版本（3+_5），以及两种使用重复外推（REP）和滑动平均（MAR）方法的线性修补技术。有关这些方法如何实现的更多细节，请参考我们的AIES论文。
- en: Fidelity
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保真度
- en: To comprehensively evaluate model performance in blind zone reconstructive accuracy,
    we will first examine a handful of common cases, followed by a more general statistical
    analysis of the full test dataset. Note that all results shown from here on out
    are strictly taken from the unseen test set of observations.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估模型在盲区重建准确性方面的表现，我们将首先检查一些常见的案例，随后对整个测试数据集进行更一般性的统计分析。请注意，从此以后展示的所有结果均严格来源于未见的测试集观测数据。
- en: Case Studies
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究
- en: Examples of inpainted blind zone reflectivity values (taken from both NSA and
    OLI) for REP, MAR, 3+ 1 and 3+ 5 models, along with the corresponding target KaZR
    VAP product (i.e. the ground truth) in the far left column are shown below in
    Figs. 9/10.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 展示了REP、MAR、3+_1 和 3+_5模型的盲区反射率值的示例（取自NSA和OLI），以及对应的目标KaZR VAP产品（即地面真实值）在最左侧列中的数据，见图9/10。
- en: This first set of examples highlights cases of near surface reflectivity gradients
    and cloud gaps that are common at both locations. The black dashed line indicates
    the 1.2 km blind zone threshold (values below this are masked and reconstructed
    by each model), and the shaded regions indicate areas of high uncertainty in the
    inpainted U-Net predictions (more on this later in the Monte Carlo Dropout section).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这第一组示例突出显示了在两个位置都常见的近地表反射率梯度和云隙的情况。黑色虚线表示1.2公里的盲区阈值（低于此值的区域被遮蔽并由各模型重建），阴影区域表示在U-Net预测中修补部分的高不确定性区域（后续将在蒙特卡罗丢弃部分详细讨论）。
- en: '![](../Images/67beb050c487cf93946cc99aa5f3e2cc.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67beb050c487cf93946cc99aa5f3e2cc.png)'
- en: '**Figure 9:** Examples a)-e) of inpainted blind zone reflectivity values (taken
    from both NSA and OLI) for REP, MAR, 3+_1 and 3+_5 models, along with the corresponding
    target KaZR VAP product (i.e. the ground truth) in the far left column. This set
    of examples highlights cases of near surface reflectivity gradients and cloud
    gaps. Image by author.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 9：** 展示了REP、MAR、3+_1 和 3+_5模型的盲区反射率值的示例（取自NSA和OLI），以及对应的目标KaZR VAP产品（即地面真实值）在最左侧列中的数据。这组示例突出显示了近地表反射率梯度和云隙的情况。图像由作者提供。'
- en: We find that the linear models (REP and MAR) perform well for deep, homogeneous
    systems, but fall short in more complex cases. Further, due to their reliance
    on blind zone threshold reflectivities, reflectivity gradients (vertical and horizontal)
    are missed by REP and MAR (and usually captured using the U-Nets). Finally, shallow,
    Arctic mixed-phase clouds can also be resolved using U-Nets, along with cloud
    gaps and cases of virga (Fig. 10), which is exciting as this has substantial implications
    to surface snowfall quantities.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，线性模型（REP和MAR）在深层均匀系统中表现良好，但在更复杂的情况下表现不佳。此外，由于它们依赖于盲区阈值反射率，REP和MAR未能捕捉到反射率梯度（垂直和水平），而这些梯度通常是通过U-Net捕捉到的。最后，浅层的北极混合相云也可以通过U-Net解决，包括云隙和雨丝的情况（图10），这令人兴奋，因为这对地面降雪量有着重要的影响。
- en: '![](../Images/bbc422502db91e68dc004abfda2a21c1.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bbc422502db91e68dc004abfda2a21c1.png)'
- en: '**Figure 10:** The same as Fig. 9, now focusing on shallow snowfall and virga
    cases for each model’s inpainted predictions. Image by author.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**图10：** 与图9相同，现在关注于每个模型的补全预测中的浅层降雪和雨丝情况。图像由作者提供。'
- en: The most challenging cases to accurately model are those with sparse reflectivity
    profiles and distant cloud. For instance, consider Fig. 11 showing two similar
    cases at NSA occurring in different years. To the human eye, both locations have
    very similar cloud structures, however one has a shallow near surface cloud in
    the blind zone while the other does not. The linear inpainting techniques are
    clearly well outside of their comfort zone here and will always produce the same
    “no cloud” output as we see in a). However, the U-Net models are still able to
    resolve cloud presence in cases such as this, with the 3+_5 model using the additional
    context from ERA-5 to better understand that the atmospheric conditions in this
    case likely result in blind zone cloud.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 准确建模最具挑战性的情况是那些具有稀疏反射率剖面和遥远云层的情况。例如，考虑图11中展示的两个在不同年份发生在NSA的类似案例。从人的眼睛来看，这两个地点的云结构非常相似，然而一个在盲区内有一个浅层近地面云，而另一个则没有。线性补全技术在这里显然已超出了它们的舒适区，并且总是产生与a)中所见相同的“无云”输出。然而，U-Net模型仍然能够解决此类情况中的云存在问题，3+_5模型通过使用来自ERA-5的附加上下文，更好地理解在这种情况下，大气条件可能导致盲区云的形成。
- en: '![](../Images/a94a0fd2e2e36458dcbefc8f0f7d5dfe.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a94a0fd2e2e36458dcbefc8f0f7d5dfe.png)'
- en: '**Figure 11:** a) Example of a case where a cloud aloft (with mean reflectivity
    near -20 dBZ) has no near surface activity in the blind zone; and b) a similar
    cloud structure to a), except in this case there does exist a near surface band
    of reflectivity in a shallow cloud that is correctly identified using the 3+_5
    model. Image by author.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11：** a) 一个例子，展示了一个高空云（其平均反射率约为-20 dBZ），在盲区内没有近地面活动；b) 一个与a)类似的云结构，除了在这种情况下，确实存在一个近地面反射率带，在浅层云中，通过3+_5模型能够正确识别。图像由作者提供。'
- en: Robustness
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳健性
- en: As we can see in Fig. 12 a), the U-Net PSD curves are closer to observations
    compared to the linear methods. Further, the nonlinear reconstructions produce
    a more realistic lowest cloud echo height (shown in the probability density plots
    of b), suggesting that we are better capturing cloud positions. Finally, the entire
    blind zone structure is summarized in c)-g), where the linear methods are able
    to capture general macro-scale trends in reflectivity but fall short of capturing
    the fine-scale variability. We do note that the U-Net models have a slight “cold”
    bias towards -60 dBZ due to their tendency to produce “safer” estimates closer
    to “no cloud” over much rarer, high intensity snowfall events.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如图12 a)所示，U-Net的PSD曲线与观测值相比，较线性方法更接近。此外，非线性重建产生了更为真实的最低云回波高度（如b)中的概率密度图所示），这表明我们能更好地捕捉云的位置。最后，整个盲区结构在c)-g)中得到了总结，其中线性方法能够捕捉到反射率的宏观尺度趋势，但未能捕捉到精细尺度的变化。我们注意到，U-Net模型在-60
    dBZ附近存在轻微的“冷”偏差，这是由于它们倾向于给出更接近“无云”更为“安全”的估计，而高强度的降雪事件则较为罕见。
- en: '![](../Images/c3d1eb566f9d18bfd765ffbd0f64e748.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3d1eb566f9d18bfd765ffbd0f64e748.png)'
- en: '**Figure 12:** Cloud structure metrics including a) vertical power spectral
    density curves; b) lowest reflectivity echo layer probability density plot; and
    c) 2d reflectivity histograms. Image by author.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**图12：** 云结构度量，包括：a) 垂直功率谱密度曲线；b) 最低反射率回波层概率密度图；c) 2D反射率直方图。图像由作者提供。'
- en: 'Further, improving our predictions of surface snowfall and virga cases would
    have substantial hydrologic implications and reduce our uncertainty in snow accumulation
    quantities. So, we performed checks to see how well three cases were reconstructed
    with our model using probability of detection (POD) and false alarm rate (FAR):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，改善我们对地面降雪和虚假降雪情况的预测将对水文产生重大影响，并减少我们对雪积量的不确定性。因此，我们进行了检查，看看我们的模型在使用探测概率（POD）和误报率（FAR）时如何重建三个情况：
- en: Blind zone cloud presence (i.e. was any cloud detected)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 盲区云层存在（即是否检测到任何云层）
- en: Shallow snowfall (i.e. was there snowfall at the surface but not at the blind
    zone threshold)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 浅层降雪（即地面上有降雪，但在盲区阈值以下没有降雪）
- en: Virga (i.e. was there snowfall detected at the blind zone threshold but not
    at the surface)
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚假降雪（即在盲区阈值上检测到降雪，但在地面没有降雪）
- en: The critical success index (CSI) for each of these metrics is shown in the performance
    diagram below (Fig. 13), with the 3+_5 model performing the best overall. Shallow
    snowfall cases were typically the hardest to reconstruct, as we saw these cases
    can be quite tricky to get right (Fig. 11).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 每个指标的关键成功指数（CSI）如下面的性能图（图13）所示，其中3+_5模型的整体表现最佳。浅层降雪的情况通常是最难重建的，因为我们看到这些情况通常很难准确重建（图11）。
- en: '![](../Images/6c899e8750bee385130f6461048b4685.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c899e8750bee385130f6461048b4685.png)'
- en: '**Figure 13:** Cloud, shallow snowfall and virga detection performance diagram
    for each model. Image by author.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**图13：** 各模型的云层、浅层降雪和虚假降雪检测性能图。图片来源：作者。'
- en: Explainability
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性
- en: To add further trust in the model’s decision-making process, we also performed
    a series of [eXplainable Artificial Intelligence (XAI)](/what-is-explainable-ai-xai-afc56938d513#:~:text=Explainable%20AI%20refers%20to%20methods,be%20understood%20by%20human%20experts.)
    tests (i.e., thinking towards a mechanistic interpretation of model behaviour).
    These tests were aimed at connecting model behaviour to logical physical processes
    to both inspire confidence in the model and provide additional insights for potentially
    enhancing future retrievals. If we can learn about previously unknown connections
    in the data, that can be very valuable! Separately, each individual XAI method
    gives a slightly different “local” explination of the decision-making process,
    and it is therefore useful to incorporate multiple tests to derive a more robust
    understanding.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步增加对模型决策过程的信任，我们还进行了系列的[可解释人工智能（XAI）](https://wiki.example.org/what-is-explainable-ai-xai-afc56938d513#:~:text=Explainable%20AI%20refers%20to%20methods,be%20understood%20by%20human%20experts.)测试（即以机械化的方式理解模型行为）。这些测试旨在将模型行为与逻辑的物理过程联系起来，以激发对模型的信心，并为可能改善未来的回收提供额外的见解。如果我们能够发现数据中以前未知的关联，这将非常有价值！另外，每个单独的XAI方法给出的是“局部”的决策过程解释，因此结合多种测试以获得更稳健的理解是很有用的。
- en: Feature Maps
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征图
- en: The first, most basic, test we considered were feature/activation maps. By examining
    the values of the reLU activator in different levels of the encoder path of Fig.
    8.b, we get a rough idea of where the model is looking in an image for a given
    input. As shown in Fig.14 below, the e1 encoder layer of the 3+_5 model typically
    looked along cloud edges, at reflectivity gradients and directly along the blind
    zone threshold.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑的第一个、最基本的测试是特征/激活图。通过检查图8.b中编码器路径不同层次的reLU激活值，我们可以大致了解模型在给定输入的图像中注视的位置。如下面图14所示，3+_5模型的e1编码器层通常关注云层边缘、反射率梯度以及盲区阈值的位置。
- en: '![](../Images/2fb9255e81b9dfed726a26212cbc6758.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fb9255e81b9dfed726a26212cbc6758.png)'
- en: '**Figure 14:** a) Example reflectivity input to the 3+_5 model; and b) the
    set of 32 feature maps produced by the e1 encoder layer of the model. Image by
    author.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**图14：** a) 输入到3+_5模型的反射率示例；b) 模型e1编码器层生成的32个特征图。图片来源：作者。'
- en: Drop Channel Importance
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 丢弃通道重要性
- en: One of the biggest questions in this project was whether ERA-5 was providing
    useful context to the model. If we can use a more simplistic U-Net that only relies
    on reflectivity for instance (i.e. the 3+_1 model), then we should do so, as this
    would be more computationally efficient. However, if the additional atmospheric
    state variables from ERA-5 provide the model with useful context for inpainting
    complex systems, then the use of this more complex model may be warranted.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的一个最大问题是 ERA-5 是否为模型提供了有用的背景。如果我们能够使用一个更简单的 U-Net 模型，仅依赖反射率（例如 3+_1 模型），那么我们应该这样做，因为这样更具计算效率。然而，如果
    ERA-5 的额外大气状态变量为模型提供了有用的背景来涂色复杂系统，那么使用这个更复杂的模型可能是有必要的。
- en: Since we only have a handful of inputs in this case (1 mandatory (radar) and
    4 supplementary (temperature, humidity, u-wind, and v-wind), we can do an exhaustive
    search of the input space to evaluate their marginal contributions to accuracy.
    More formally, this drop-channel approach uses the below formula (Eq. 1/ Eq. 2)
    to calculate marginal contributions of importance from the provided inputs. Note
    that this technique does not consider potential nonlinear interactions between
    inputs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在本例中我们只有少量的输入（1 个必需的（雷达）和 4 个辅助的（温度、湿度、u-风和v-风）），我们可以对输入空间进行穷举搜索，以评估它们对准确性的边际贡献。更正式地说，这种丢弃通道方法使用下面的公式（公式
    1 / 公式 2）来计算提供的输入的边际重要性贡献。请注意，这种技术并未考虑输入之间可能的非线性相互作用。
- en: '![](../Images/eaec56ae5cf66e13cceea7a0f26cfe60.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaec56ae5cf66e13cceea7a0f26cfe60.png)'
- en: '**Eq. 1 / Eq. 2:** Used in calculating marginal importance from N inputs. Image
    by author.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**公式 1 / 公式 2：** 用于计算来自 N 个输入的边际重要性。图片来源：作者。'
- en: If we perform a series of this test runs (25 epochs) and examine changes in
    the validation loss, we can gain some rough insight into which inputs are most
    useful. The results of these tests are shown below in Fig. 15, where we note a
    trend of decreasing validation loss as we add more ERA-5 inputs (suggesting that
    none of the inputs are wholly unimportant). Further, the marginal contributions
    to validation loss suggest that the wind data is the most influential overall.
    We believe that this importance may stem from that fact that in the upper troposphere,
    wind patterns can hint at mesoscale atmospheric dynamics, such as the presence
    of high or low-pressure systems, fronts, and jet streams (which are of course
    linked to cloud/hydrometeor formation).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们执行一系列此类测试运行（25 个周期），并检查验证损失的变化，我们可以大致了解哪些输入最有用。这些测试的结果如下图 15 所示，我们注意到随着我们添加更多
    ERA-5 输入，验证损失呈下降趋势（这表明没有任何输入完全不重要）。此外，边际贡献到验证损失的结果表明，风数据总体上是最具影响力的。我们认为这种重要性可能源于这样一个事实：在对流层上层，风模式可以暗示中尺度大气动力学，如高压或低压系统、锋面和急流（这些当然与云/水气象的形成有关）。
- en: '![](../Images/c184566fd3f2516c6f00d0a71c52e881.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c184566fd3f2516c6f00d0a71c52e881.png)'
- en: '**Figure 15:** Input channel combination contributions to inpainting performance
    in 3Net+ models. Image by author.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 15：** 输入通道组合对 3Net+ 模型涂色性能的贡献。图片来源：作者。'
- en: Saliency Maps
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显著性图
- en: Finally, we also examined saliency maps for a handful of cases (Fig. 16), to
    further compare the differences in importance between the 3+_5 and 3+_1 models.
    These pixel attribution vanilla gradient saliency maps are inspired by the work
    of Simonyan et al., 2014, and provide additional insight into areas the model
    identifies as crucial contributors of information for inpainting accuracy using
    a given input. These saliency maps are generated by running an image through the
    network and subsequently extracting the gradients of the output based on the input
    across all channels. While simplistic, this method is particularly useful for
    visualizing which parts of the observed image are most valuable in inpainting
    the blind zone reflectivity values, allowing for direct plotting of the activation
    gradients.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还检查了一些案例的显著性图（图 16），以进一步比较 3+_5 和 3+_1 模型之间的重要性差异。这些像素归因的原生梯度显著性图灵感来自 Simonyan
    等人（2014）的工作，并为模型识别为涂色准确性贡献重要信息的区域提供了额外的洞察。这些显著性图是通过将图像输入到网络中，然后提取基于输入在所有通道上输出的梯度来生成的。尽管这种方法简化，但它对于可视化观察图像中哪些部分在涂色盲区反射值时最有价值非常有用，允许直接绘制激活梯度。
- en: '![](../Images/ab1f00f285d909031eb129497ba5ef34.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab1f00f285d909031eb129497ba5ef34.png)'
- en: '**Figure 16:** Vanilla gradient saliency maps for both the 3+_1 and 3+_5 models,
    along with the corresponding ERA5 atmospheric state variables for a handful of
    cases at NSA. Image by author.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 16：** 3+_1 和 3+_5 模型的原始梯度显著性图，以及在 NSA 的一些案例中对应的 ERA5 大气状态变量。图片由作者提供。'
- en: For multilayer clouds that intersect with the blind zone cut-off (e.g. Fig.
    16.a), both models focus on the top of the cloud and the 1.2 km boundary threshold,
    as these systems often continue to extend down to the surface with similar reflectivity
    intensities. Both models also typically focus on and around cloud gaps in deeper
    systems (e.g. Fig. 16.b), however, a distinct halo of importance towards the tropopause
    is noticeable in the 3+_5 model. This recurring feature is likely incorporating
    upper troposphere wind and humidity data into predictions of near surface reflectivity.
    Interestingly, the 3+_1 model does not solely focus on the areas of high reflectivity
    in the scene but also on the regions around the cloud.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于与盲区切割区域交叉的多层云（例如图 16.a），两个模型都聚焦于云的顶部和 1.2 公里的边界阈值，因为这些系统通常会延伸至地面，并具有相似的反射率强度。两个模型通常还会关注并围绕深层系统中的云间隙（例如图
    16.b），然而，3+_5 模型中明显出现了一个重要的环带，指向平流层。这一反复出现的特征可能将上层对流层的风和湿度数据纳入了对近地面反射率的预测。有趣的是，3+_1
    模型并不仅仅专注于场景中高反射率区域，还关注云周围的区域。
- en: Applications
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用
- en: The motivating goal of this work is to eventually apply a surface trained U-Net
    to spaceborne observations. While additional work needs to be completed on resolution-matching
    between these two systems, we performed early tests against coincident CloudSat-CPR
    observations near NSA. The idea here being that both systems (while not perfectly
    overlapped), will be observing similar portions of the same storm system. We consider
    a handful of examples and include one below for a shallow cumuliform snowfall
    case.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作的主要目标是最终将训练好的表面 U-Net 应用于空间观测。尽管在这两个系统之间的分辨率匹配方面还需要完成额外的工作，但我们已针对靠近 NSA 的重合
    CloudSat-CPR 观测进行了早期测试。这里的想法是，尽管这两个系统（虽然并未完全重叠）将观测到相同风暴系统的相似部分。我们考虑了一些示例，并在下方包括了一个浅层积云降雪案例。
- en: '![](../Images/21fe4f2052e4c25ceb85aa247b6fffc7.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21fe4f2052e4c25ceb85aa247b6fffc7.png)'
- en: '**Figure 17:** a) Map depicting a CloudSat overpass granule path (red), 128-step
    site-coincident CloudSat footprint near NSA, and white point showing the closest
    observed profile to the site (black circle represents a 50 km radius around the
    site); b) CloudSat reflectivity profile of a shallow cumuliform system, with the
    region between the two dashed lines representing the blue (coincident) portion
    of the overpass in a), and the white shaded region showing the satellite blind
    zone; c) Vertical NSA KaZR reflectivity profile, with the corresponding overpass
    period from b) shown in the region between the two dashed lines; d) A closeup
    of the KaZR CloudSat coincident profile from c); e) The CloudSat-NSA coincident
    profile from b); and f-h) The REP, MAR and 3+_1 inpainted blind zone scenes, respectively,
    when provided with e) as input. Image by author.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 17：** a) 显示 CloudSat 过境颗粒路径（红色）、128 步站点重合的 CloudSat 足迹以及显示最接近站点的观测轮廓的白色点（黑圆圈代表站点周围
    50 公里的半径）；b) 浅层积云系统的 CloudSat 反射率轮廓，两个虚线之间的区域表示 a) 中的蓝色（重合）部分，白色阴影区域显示卫星盲区；c)
    垂直 NSA KaZR 反射率轮廓，b) 中的对应过境时期显示在两个虚线之间的区域；d) 来自 c) 的 KaZR CloudSat 重合轮廓的特写；e)
    来自 b) 的 CloudSat-NSA 重合轮廓；f-h) 分别为提供 e) 作为输入时的 REP、MAR 和 3+_1 修复盲区场景。图片由作者提供。'
- en: In this example, we noted that both the spaceborne and surface radars observed
    a shallow cloud about 3 km tall (however CloudSat misses the increased reflectivity
    gradient below the blind zone due to surface clutter). When this region is reconstructed
    using both the traditional techniques and our U-Net, we find the U-Net is the
    only method that can accuratly represent the band of increased reflectivity around
    1 km. More formally, if we look at the structure between the nearest CloudSat
    observation to the site (white dashed line) to each of the closest reconstructed
    regions, Pearson correlations are substantially improved using the U-Net (r_MAR=0.13
    to r_3+_1=0.74).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们注意到，空间borne和地面雷达都观测到大约 3 公里高的浅层云（然而 CloudSat 因表面杂波错过了盲区下方的反射率梯度增加）。当使用传统技术和我们的
    U-Net 重建该区域时，我们发现 U-Net 是唯一能够准确表示大约 1 公里范围内反射率增加带的方法。更正式地说，如果我们查看最接近该站点的 CloudSat
    观测值（白色虚线）与每个最接近重建区域之间的结构，使用 U-Net 时 Pearson 相关性显著提高（r_MAR=0.13 到 r_3+_1=0.74）。
- en: While these examples don’t comprise a comprehensive anaylsis allowing us to
    say something about general performance, they do indicate that we see skill consistent
    with what we have previous noted when looking at the simulated surface blind zone.
    Further application work to spaceborne instruments is ongoing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些示例并未构成一个全面的分析，无法让我们对整体性能做出结论，但它们确实表明我们观察到的技能与我们在查看模拟的表面盲区时所注意到的一致。进一步的空间borne仪器应用工作正在进行中。
- en: Final Notes
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终备注
- en: Before we finish up this already long post, I wanted to highlight a few of the
    other features we built into the model and provide some training code examples
    for those interested in developing their own inpainting model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这篇已经很长的文章之前，我想强调一些我们在模型中加入的其他特性，并为那些有兴趣开发自己修补模型的人提供一些训练代码示例。
- en: Monte Carlo Dropout
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 蒙特卡洛 Dropout
- en: Unlike traditional Bayesian methods, we do not directly produce a physically-based
    uncertainty estimate using a U-Net. To get a rough idea of model confidence and
    stability, we decided to introduce a dropout at inference layer to the model based
    on the work of Gal and Ghahramani, 2016 which allows us to generate a distribution
    of inpainted predictions for each test case. These distributions allow us to produce
    confidence intervals for each inpainted pixel, and further refine our estimates
    to regions that model is more certain of when inpainting. An example of this is
    shown below in Fig. 17.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的贝叶斯方法不同，我们并没有直接使用 U-Net 来生成基于物理的无关度估计。为了大致了解模型的信心和稳定性，我们决定在推理层引入 Dropout，基于
    Gal 和 Ghahramani 2016 年的研究，这使我们能够为每个测试案例生成修补预测的分布。这些分布使我们能够为每个修补的像素生成置信区间，并进一步精细化我们的估计，聚焦于模型在修补时更有信心的区域。下图
    17 展示了一个例子。
- en: '![](../Images/6f708001b2ccb77735357449f51301ce.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f708001b2ccb77735357449f51301ce.png)'
- en: '**Figure 18:** Monte Carlo dropout example outputs (n=50 iterations). Image
    by author.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 18：** 蒙特卡洛 Dropout 示例输出（n=50 次迭代）。图像由作者提供。'
- en: We typically use N=50 iterations per case, and as we can see above, the areas
    with the highest uncertainty are typically cloud edges and cloud gaps, as the
    model often hallucinates when positioning these features.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常对每个案例使用 N=50 次迭代，正如我们上面看到的，通常具有最高不确定性的区域是云边缘和云隙，因为模型在定位这些特征时常常会出现幻觉。
- en: Training Statistics
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练统计
- en: Model training for this project was completed on two sets of hardware, including
    a Linux-based GPU computing cluster on Microsoft Azure, and a high-performance
    desktop running Windows 11 (additional system details in Table 1). An extensive
    Bayesian hyperparameter sweep was also performed over the course of 2 days. Further,
    batch normalization is applied along with early stopping (n=20), dropout and L2
    regularization (ridge regression) to help mitigate overfitting during the training
    process. Learning rate decay is also applied at two epochs (450 and 475), allowing
    the model to more easily settle into a local loss minima near the end of the training
    phase. All training runs and hyperparameter sweeps are saved online using the
    [Weights & Biases cloud storage option](https://wandb.ai), to monitor model learning
    rates and stability over time.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的模型训练在两种硬件环境中完成，包括基于Linux的GPU计算集群（托管在Microsoft Azure上）和一台运行Windows 11的高性能桌面计算机（更多系统细节见表1）。在两天的时间里，还进行了广泛的贝叶斯超参数搜索。此外，在训练过程中应用了批量归一化、早停（n=20）、dropout和L2正则化（岭回归）来帮助缓解过拟合问题。学习率衰减也在两个周期（450和475）应用，使模型能够更容易地在训练阶段结束时接近局部损失最小值。所有的训练运行和超参数搜索结果都通过[Weights
    & Biases云存储选项](https://wandb.ai)在线保存，以便监控模型的学习率和稳定性。
- en: '![](../Images/2fa4de49f4643bec06b12735d6f575ec.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fa4de49f4643bec06b12735d6f575ec.png)'
- en: '**Table 1:** Summary details of hardware used for model training. Image by
    author.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1：** 用于模型训练的硬件摘要详情。图片由作者提供。'
- en: Example Code
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例代码
- en: 'A link to the GitHub is here: [https://github.com/frasertheking/blindzone_inpainting](https://github.com/frasertheking/blindzone_inpainting)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub链接如下：[https://github.com/frasertheking/blindzone_inpainting](https://github.com/frasertheking/blindzone_inpainting)
- en: However, I wanted to provide an overview of the actual 3Net+ implementation
    (with variable depth) in Tensorflow below for those interested in playing around
    with it.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我想为那些有兴趣尝试的人提供一个实际的3Net+实现概览（具有可变深度），该实现是基于Tensorflow的。
- en: '[PRE0]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Future
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来
- en: I know this was a long post, and we covered a lot of stuff, but I want to give
    a quick summary of everything we’ve covered for those who have made this far (or
    those who skipped to the end).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这篇文章很长，我们涵盖了很多内容，但我想快速总结一下我们讨论的所有内容，特别是对那些读到这里的读者（或者跳到最后的读者）。
- en: The satellite radar blind zone is an ongoing problem on satellite-based Earth
    observing precipitation missions, with critical implications to global water-energy
    budget calculations. In order to overcome common issues with traditional linear
    inpainting methods for filling in this region, we opted to use a nonlinear, deeply
    supervised U-Net for radar blind zone inpainting. The U-Net outperforms linear
    techniques across nearly all metrics and can even reconstruct complex cloud structures
    like multilayer clouds, cloud gaps and shallow cloud. Further, using a variety
    of XAI techniques, we saw that information directly at the blind zone threshold
    and along the tropopause (especially wind information) was found to be very useful
    in the model’s decision-making process. While we don’t suggest that these models
    fully replace current physically-based solutions, we believe they offer a unique
    new perspective that can be used to supplement other retrievals in future missions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 卫星雷达盲区是卫星地球观测降水任务中的一个持续问题，对全球水能预算计算有重要影响。为了克服传统线性插值方法在填补该区域时常见的问题，我们选择了使用非线性、深度监督的U-Net进行雷达盲区插值。U-Net在几乎所有评估指标上都优于线性技术，甚至能够重建复杂的云结构，如多层云、云隙和浅层云。此外，通过使用各种可解释人工智能（XAI）技术，我们发现位于盲区阈值附近以及对流层顶沿线（尤其是风信息）的数据对模型的决策过程非常有用。尽管我们不建议这些模型完全替代当前基于物理的解决方案，但我们认为它们提供了一个独特的新视角，可以在未来的任务中补充其他回收方法。
- en: We are currently working on a follow-up project to this with direct applications
    to CloudSat-CPR observations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前正在进行一个跟进项目，直接应用于CloudSat-CPR观测。
- en: Referernces
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Gal, Y., & Ghahramani, Z. (2016). Dropout as a Bayesian Approximation: Representing
    Model Uncertainty in Deep Learning (arXiv:1506.02142). arXiv. [https://doi.org/10.48550/arXiv.1506.02142](https://doi.org/10.48550/arXiv.1506.02142)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Gal, Y., & Ghahramani, Z. (2016). Dropout作为贝叶斯近似：在深度学习中表示模型不确定性（arXiv:1506.02142）。arXiv.
    [https://doi.org/10.48550/arXiv.1506.02142](https://doi.org/10.48550/arXiv.1506.02142)
- en: Geiss, A., & Hardin, J. C. (2021). Inpainting radar missing data regions with
    deep learning. Atmospheric Measurement Techniques, 14(12), 7729–7747\. [https://doi.org/10.5194/amt-14-7729-2021](https://doi.org/10.5194/amt-14-7729-2021)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Geiss, A., & Hardin, J. C. (2021). 使用深度学习修复雷达缺失数据区域。大气测量技术，14(12)，7729–7747\.
    [https://doi.org/10.5194/amt-14-7729-2021](https://doi.org/10.5194/amt-14-7729-2021)
- en: 'Guillemot, C., & Le Meur, O. (2014). Image Inpainting: Overview and Recent
    Advances. *IEEE Signal Processing Magazine*, *31*(1), 127–144\. [https://doi.org/10.1109/MSP.2013.2273004](https://doi.org/10.1109/MSP.2013.2273004)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Guillemot, C., & Le Meur, O. (2014). 图像修复：概述与最新进展。*IEEE信号处理杂志*，*31*(1)，127–144\.
    [https://doi.org/10.1109/MSP.2013.2273004](https://doi.org/10.1109/MSP.2013.2273004)
- en: 'Huang, H., Lin, L., Tong, R., Hu, H., Zhang, Q., Iwamoto, Y., Han, X., Chen,
    Y.-W., & Wu, J. (2020). UNet 3+: A Full-Scale Connected UNet for Medical Image
    Segmentation (arXiv:2004.08790). arXiv. [https://doi.org/10.48550/arXiv.2004.08790](https://doi.org/10.48550/arXiv.2004.08790)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 'Huang, H., Lin, L., Tong, R., Hu, H., Zhang, Q., Iwamoto, Y., Han, X., Chen,
    Y.-W., & Wu, J. (2020). UNet 3+: 一种全规模连接的UNet医学图像分割方法 (arXiv:2004.08790)。arXiv.
    [https://doi.org/10.48550/arXiv.2004.08790](https://doi.org/10.48550/arXiv.2004.08790)'
- en: Kidd, C., Graham, E., Smyth, T., & Gill, M. (2021). Assessing the Impact of
    Light/Shallow Precipitation Retrievals from Satellite-Based Observations Using
    Surface Radar and Micro Rain Radar Observations. Remote Sensing, 13(9), Article
    9\. [https://doi.org/10.3390/rs13091708](https://doi.org/10.3390/rs13091708)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Kidd, C., Graham, E., Smyth, T., & Gill, M. (2021). 使用表面雷达和微雨雷达观测评估卫星观测的浅层/轻度降水反演的影响。遥感，13(9)，文章9\.
    [https://doi.org/10.3390/rs13091708](https://doi.org/10.3390/rs13091708)
- en: King, F., & Fletcher, C. G. (2020). Using CloudSat-CPR Retrievals to Estimate
    Snow Accumulation in the Canadian Arctic. Earth and Space Science, 7(2), e2019EA000776\.
    [https://doi.org/10.1029/2019EA000776](https://doi.org/10.1029/2019EA000776)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: King, F., & Fletcher, C. G. (2020). 使用CloudSat-CPR检索估算加拿大北极地区的积雪量。地球与空间科学，7(2)，e2019EA000776\.
    [https://doi.org/10.1029/2019EA000776](https://doi.org/10.1029/2019EA000776)
- en: 'Lamer, K., Kollias, P., Battaglia, A., & Preval, S. (2020). Mind the gap —
    Part 1: Accurately locating warm marine boundary layer clouds and precipitation
    using spaceborne radars. Atmospheric Measurement Techniques, 13(5), 2363–2379\.
    [https://doi.org/10.5194/amt-13-2363-2020](https://doi.org/10.5194/amt-13-2363-2020)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Lamer, K., Kollias, P., Battaglia, A., & Preval, S. (2020). 注意差距 — 第1部分：利用卫星雷达准确定位温暖海洋边界层云和降水。大气测量技术，13(5)，2363–2379\.
    [https://doi.org/10.5194/amt-13-2363-2020](https://doi.org/10.5194/amt-13-2363-2020)
- en: 'Lugmayr, A., Danelljan, M., Romero, A., Yu, F., Timofte, R., & Van Gool, L.
    (2022). RePaint: Inpainting using Denoising Diffusion Probabilistic Models. 2022
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 11451–11461\.
    [https://doi.org/10.1109/CVPR52688.2022.01117](https://doi.org/10.1109/CVPR52688.2022.01117)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 'Lugmayr, A., Danelljan, M., Romero, A., Yu, F., Timofte, R., & Van Gool, L.
    (2022). RePaint: 使用去噪扩散概率模型进行图像修复。2022年IEEE/CVF计算机视觉与模式识别大会（CVPR），11451–11461\.
    [https://doi.org/10.1109/CVPR52688.2022.01117](https://doi.org/10.1109/CVPR52688.2022.01117)'
- en: 'Maahn, M., Burgard, C., Crewell, S., Gorodetskaya, I. V., Kneifel, S., Lhermitte,
    S., Van Tricht, K., & van Lipzig, N. P. M. (2014). How does the spaceborne radar
    blind zone affect derived surface snowfall statistics in polar regions? Journal
    of Geophysical Research: Atmospheres, 119(24), 13,604–13,620\. [https://doi.org/10.1002/2014JD022079](https://doi.org/10.1002/2014JD022079)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Maahn, M., Burgard, C., Crewell, S., Gorodetskaya, I. V., Kneifel, S., Lhermitte,
    S., Van Tricht, K., & van Lipzig, N. P. M. (2014). 太空雷达盲区如何影响极地地区衍生的地表降雪统计数据？《地球物理研究：大气》,
    119(24), 13,604–13,620\. [https://doi.org/10.1002/2014JD022079](https://doi.org/10.1002/2014JD022079)
- en: 'Simonyan, K., Vedaldi, A., & Zisserman, A. (2014). Deep Inside Convolutional
    Networks: Visualising Image Classification Models and Saliency Maps (arXiv:1312.6034).
    arXiv. [https://doi.org/10.48550/arXiv.1312.6034](https://doi.org/10.48550/arXiv.1312.6034)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Simonyan, K., Vedaldi, A., & Zisserman, A. (2014). 深入卷积神经网络：可视化图像分类模型与显著性图 (arXiv:1312.6034)。arXiv.
    [https://doi.org/10.48550/arXiv.1312.6034](https://doi.org/10.48550/arXiv.1312.6034)
- en: 'Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., & Liang, J. (2018). UNet++: A
    Nested U-Net Architecture for Medical Image Segmentation (arXiv:1807.10165). arXiv.
    [https://doi.org/10.48550/arXiv.1807.10165](https://doi.org/10.48550/arXiv.1807.10165)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., & Liang, J. (2018). UNet++：一种用于医学图像分割的嵌套U-Net架构
    (arXiv:1807.10165)。arXiv. [https://doi.org/10.48550/arXiv.1807.10165](https://doi.org/10.48550/arXiv.1807.10165)
