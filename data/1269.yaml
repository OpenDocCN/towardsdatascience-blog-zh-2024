- en: Using LLMs to Learn From YouTube
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLMs从YouTube学习
- en: 原文：[https://towardsdatascience.com/using-llms-to-learn-from-youtube-4454934ff3e0?source=collection_archive---------1-----------------------#2024-05-21](https://towardsdatascience.com/using-llms-to-learn-from-youtube-4454934ff3e0?source=collection_archive---------1-----------------------#2024-05-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-llms-to-learn-from-youtube-4454934ff3e0?source=collection_archive---------1-----------------------#2024-05-21](https://towardsdatascience.com/using-llms-to-learn-from-youtube-4454934ff3e0?source=collection_archive---------1-----------------------#2024-05-21)
- en: '![](../Images/e89496c5a1c58b96a670f468d04c9c69.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e89496c5a1c58b96a670f468d04c9c69.png)'
- en: Image created by author using Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用Midjourney制作
- en: A conversational question-answering tool built using LangChain, Pinecone, Flask,
    React and AWS
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个使用LangChain、Pinecone、Flask、React和AWS构建的对话式问答工具
- en: '[](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)[![Alok
    Suresh](../Images/13c5a5d18cff88db8d5c6e903177c03b.png)](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)
    [Alok Suresh](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)[![Alok
    Suresh](../Images/13c5a5d18cff88db8d5c6e903177c03b.png)](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)
    [Alok Suresh](https://medium.com/@suresha?source=post_page---byline--4454934ff3e0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)
    ·17 min read·May 21, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4454934ff3e0--------------------------------)
    ·阅读时间17分钟·2024年5月21日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Have you ever encountered a podcast or a video you wanted to watch, but struggled
    to find the time due to its length? Have you wished for an easy way to refer back
    to specific sections of content in this form ?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾遇到过想要观看的播客或视频，但因其长度而难以找到时间？你是否希望能有一种简单的方法来回顾该内容的特定部分？
- en: This is an issue I’ve faced many times when it comes to YouTube videos of popular
    podcasts like The Diary of a CEO. Indeed, a lot of the information covered in
    podcasts such as this is readily available through a quick Google search. But
    listening to an author’s take on something they are passionate about, or hearing
    about a successful entrepreneur’s experience from their perspective tends to provide
    much more insight and clarity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在处理像《CEO日记》这样的流行播客的YouTube视频时经常遇到的问题。实际上，这类播客中涵盖的很多信息，通过快速的Google搜索就能轻松找到。但听作者谈论他们对某些话题的看法，或者听一位成功企业家从他们的视角讲述自己的经历，往往能提供更多的见解和清晰度。
- en: 'Motivated by this problem and a desire to educate myself on LLM-powered applications
    and their development, I decided to build a chatbot which allows users to ask
    questions about the content of YouTube videos using the RAG (Retrieval Augmented
    Generation) framework. In the rest of this post, I’ll talk through my experience
    developing this application using LangChain, Pinecone, Flask, and React, and deploying
    it with AWS:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 受这一问题以及希望自我教育有关LLM驱动应用及其开发的愿望的驱动，我决定构建一个聊天机器人，允许用户使用RAG（检索增强生成）框架询问有关YouTube视频内容的问题。在本文的其余部分，我将介绍我使用LangChain、Pinecone、Flask、React开发此应用程序，并使用AWS进行部署的经验：
- en: '![](../Images/dabe57eb81469c898bca326bc2e88548.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dabe57eb81469c898bca326bc2e88548.png)'
- en: I’ve limited code snippets to those that I think will be most useful. For anyone
    interested, the complete codebase for the application can be found [here](https://github.com/suresha97/ChatYTT/tree/main).
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我将代码片段限制为我认为最有用的那些。对于有兴趣的人，应用程序的完整代码库可以在[这里](https://github.com/suresha97/ChatYTT/tree/main)找到。
- en: Backend
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后端
- en: We’ll be using the transcripts of YouTube videos as the source from which the
    LLM generates answers to user-defined questions. To facilitate this, the backend
    will need a method of retrieving and appropriately storing these for use in real
    time, as well as one for using them to generate answers. We also want a way of
    storing chat histories so that users can refer back to them at a later time. Let’s
    see how the backend can be developed to satisfy all of these requirements now.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用YouTube视频的转录文本作为源，从中生成LLM对用户定义问题的答案。为了实现这一点，后端需要一种方法来实时检索并适当存储这些文本，以便用于生成答案。同时，我们还需要一种存储聊天历史记录的方法，以便用户能够在后续时间查看。现在，看看如何开发后端以满足所有这些需求。
- en: Response generation
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回应生成
- en: 'Since this is a conversational question-answering tool, the application must
    be able to generate answers to questions while taking both the relevant context
    *and* chat history into account. This can be achieved using Retrieval Augmented
    Generation with Conversation Memory, as illustrated below:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个对话式问答工具，应用程序必须能够在考虑到相关上下文*和*聊天历史的情况下生成问题的答案。可以通过使用带有对话记忆的检索增强生成（RAG）方法来实现这一点，如下所示：
- en: '![](../Images/d42fbc44892a532842fd1efa30543943.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d42fbc44892a532842fd1efa30543943.png)'
- en: 'For clarity, the steps involved are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，涉及的步骤如下：
- en: '**Question summarisation**: The current question and the chat history are condensed
    into a standalone question using an appropriate prompt asking the LLM to do so.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问题总结**：当前问题和聊天历史将通过适当的提示缩减为一个独立的问题，要求LLM执行这一操作。'
- en: '**Semantic search**: Next, the YouTube transcript chunks that are most relevant
    to this condensed question must be retrieved. The transcripts themselves are stored
    as embeddings, which are numerical representations of words and phrases, learned
    by an embedding model that captures their content and semantics. During the semantic
    search, the components of each transcript whose embeddings are most similar to
    those of the condensed question are retrieved.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**语义搜索**：接下来，必须检索与简化问题最相关的YouTube转录文本块。转录文本本身被存储为嵌入，嵌入是单词和短语的数值表示，由嵌入模型学习，这个模型捕捉它们的内容和语义。在语义搜索过程中，每个转录文本的组件，其嵌入与简化问题的嵌入最为相似，会被检索出来。'
- en: '**Context-aware generation**: These retrieved transcript chunks are then used
    as the context within another prompt to the LLM asking it to answer the condensed
    question. Using the condensed question ensures that the generated answer is relevant
    to the current question as well as previous questions asked by the user during
    the chat.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**上下文感知生成**：这些检索到的转录文本块随后作为上下文出现在另一个向LLM发送的提示中，要求它回答简化后的问题。使用简化问题可以确保生成的答案不仅与当前问题相关，还与用户在对话中先前提出的问题相关。'
- en: Data Pipeline
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据管道
- en: Before moving on to the implementation of the process outlined above, let’s
    take a step back and focus on the YouTube video transcripts themselves. As discussed,
    they must be stored as embeddings to efficiently search for and retrieve them
    during the semantic search phase of the RAG process. Let’s go through the source,
    method of retrieval and method of storage for these now.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续实施上述过程之前，让我们先回顾一下YouTube视频的转录文本。正如前面讨论的，这些文本必须以嵌入的形式存储，以便在RAG过程的语义搜索阶段高效检索和使用它们。现在，让我们一起了解这些转录文本的来源、检索方法和存储方法。
- en: '**Source**: YouTube provides access to metadata like video IDs, as well as
    autogenerated transcripts through its Data API. To begin with, I’ve selected [this](https://www.youtube.com/watch?v=vOvLFT4v4LQ&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2)
    playlist from The Diary of a CEO podcast, in which various money experts and entrepreneurs
    discuss personal finance, investing, and building successful businesses.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**来源**：YouTube通过其数据API提供视频ID等元数据，并提供自动生成的转录文本。首先，我选择了[这个](https://www.youtube.com/watch?v=vOvLFT4v4LQ&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2)来自《CEO日记》播客的播放列表，其中多位财经专家和企业家讨论个人财务、投资以及如何建立成功的企业。'
- en: '**Retrieval:** I make use of one class responsible for [retrieving metadata](https://github.com/suresha97/ChatYTT/blob/main/chatytt/youtube_data/playlist_data_loader.py)
    on YouTube videos like Video IDs by interacting directly with the YouTube Data
    API, and another which uses the [youtube-transcript-API](https://pypi.org/project/youtube-transcript-api/)
    Python package to [retrieve the video transcripts](https://github.com/suresha97/ChatYTT/blob/main/chatytt/youtube_data/transcript_fetcher.py).
    These transcripts are then stored as JSON files in an S3 bucket in their raw form.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索：** 我使用一个类，通过直接与 YouTube 数据 API 交互来[检索 YouTube 视频的元数据](https://github.com/suresha97/ChatYTT/blob/main/chatytt/youtube_data/playlist_data_loader.py)，例如视频
    ID；另外一个类则使用 [youtube-transcript-API](https://pypi.org/project/youtube-transcript-api/)
    Python 包来[获取视频的字幕](https://github.com/suresha97/ChatYTT/blob/main/chatytt/youtube_data/transcript_fetcher.py)。这些字幕随后以原始形式存储为
    JSON 文件在 S3 存储桶中。'
- en: '**Storage:** Next, the transcripts need to be converted to embeddings and stored
    in a vector database. However, a pre-requisite to this step is splitting them
    into chunks so that upon retrieval, we get segments of text that are of the highest
    relevance to each question while also minimising the length of the LLM prompt
    itself. To satisfy this requirement I define a custom S3JsonFileLoader class [here](https://github.com/suresha97/ChatYTT/blob/main/chatytt/embeddings/s3_json_document_loader.py)
    (due to some issues with LangChain’s out-of-the-box version), and make use of
    the [text splitter object](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)
    to split the transcripts at load time. I then make use of LangChain’s interface
    to the Pinecone Vectorstore (my vector store of choice for efficient storage,
    search and retrieval of the transcript embeddings) to store the transcript chunks
    as embeddings expected by OpenAI’s gpt-3.5-turbo model:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**存储：** 接下来，字幕需要转换为嵌入并存储到向量数据库中。然而，这一步的前提是将其拆分成若干段，以便在检索时能获取到与每个问题最相关的文本片段，同时尽量减少
    LLM 提示本身的长度。为了满足这一要求，我定义了一个自定义的 S3JsonFileLoader 类 [在这里](https://github.com/suresha97/ChatYTT/blob/main/chatytt/embeddings/s3_json_document_loader.py)（由于
    LangChain 自带版本存在一些问题），并利用 [文本拆分器对象](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)
    在加载时拆分字幕。然后，我利用 LangChain 与 Pinecone 向量存储（我选择的高效存储、搜索和检索字幕嵌入的向量存储）接口，将字幕片段作为 OpenAI
    的 gpt-3.5-turbo 模型所期望的嵌入进行存储：'
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can also make use of a few AWS services to automate these steps using a
    workflow configured to run periodically. I do this by implementing each of the
    three steps mentioned above in separate AWS Lamba Functions (a form of serverless
    computing, which provisions and utilises resources as needed at runtime), and
    defining the order of their execution using AWS Step Functions (a serverless orchestration
    tool). This workflow is then executed by an Amazon EventBridge schedule which
    I’ve set to run once a week so that any new videos added to the playlist are retrieved
    and processed automatically:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以利用一些 AWS 服务，通过配置定期运行的工作流来自动化这些步骤。我通过将上述提到的三个步骤分别实现为 AWS Lambda 函数（这是一种无服务器计算方式，根据需要在运行时调配和利用资源），并使用
    AWS Step Functions（无服务器编排工具）定义它们的执行顺序来实现这一点。然后，使用我设置为每周运行一次的 Amazon EventBridge
    调度来执行该工作流，以便自动获取并处理任何新添加到播放列表中的视频：
- en: '![](../Images/9d3baac2678cfdc95ae37ac3461e78e6.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d3baac2678cfdc95ae37ac3461e78e6.png)'
- en: Note that I have obtained permission from the The Diary of a CEO channel, to
    use the transcripts of videos from the playlist mentioned above. Anyone wishing
    to use third party content in this way, should first obtain permission from the
    original owners.
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请注意，我已经获得了《CEO 日记》频道的许可，使用上述播放列表中视频的字幕。任何希望以这种方式使用第三方内容的人，都应首先获得原始所有者的许可。
- en: Implementing RAG
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现 RAG
- en: 'Now that the transcripts for our playlist of choice are periodically being
    retrieved, converted to embeddings and stored, we can move on to the implementation
    of the core backend functionality for the application i.e. the process of generating
    answers to user-defined questions using RAG. Luckily, LangChain has a ConversationalRetrievalChain
    that does exactly that out of the box! All that’s required is to pass in the query,
    chat history, a vector store object that can be used to retrieve transcripts chunks,
    and an LLM of choice into this chain like so:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的播放列表转录本正在定期被检索、转换为嵌入并存储，我们可以继续实现应用程序的核心后端功能，即使用RAG生成用户定义问题的答案的过程。幸运的是，LangChain
    提供了一个内置的 ConversationalRetrievalChain 来完成这一任务！所需做的仅仅是将查询、聊天历史、一个可以用来检索转录本片段的向量存储对象以及一个选择的LLM传递到这个链中，如下所示：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I’ve also implemented the functionality of this chain from scratch, as described
    in LangChain’s tutorials, using both LangChain Expression Language [here](https://github.com/suresha97/ChatYTT/blob/main/chatytt/chains/custom/conversational_qa_lcel_chain.py)
    and SequentialChain [here](https://github.com/suresha97/ChatYTT/blob/main/chatytt/chains/custom/conversational_qa_sequential_chain.py)
    . These may provide more insight into all of the actions taking place under the
    hood in the chain used above.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我还从头实现了这个链的功能，正如 LangChain 的教程中所描述的那样，使用了 LangChain 表达式语言 [这里](https://github.com/suresha97/ChatYTT/blob/main/chatytt/chains/custom/conversational_qa_lcel_chain.py)
    和 SequentialChain [这里](https://github.com/suresha97/ChatYTT/blob/main/chatytt/chains/custom/conversational_qa_sequential_chain.py)
    。这些可能会提供更多关于在上面的链中发生的所有操作的洞察。
- en: Saving Chat History
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存聊天历史
- en: 'The backend can generate answers to questions now, but it would also be nice
    to store and retrieve chat history so that users can refer to old chats as well.
    Since this is a known access pattern of the same item for different users I decided
    to use DynamoDB, a NoSQL database known for its speed and cost efficiency in handling
    unstructured data of this form. In addition, the boto3 SDK simplifies interaction
    with the database, requiring just a few functions for storing and retrieving data:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 后端现在可以生成问题的答案，但最好也能存储和检索聊天历史，以便用户可以参考旧的聊天记录。由于这是一个不同用户访问同一项数据的已知访问模式，我决定使用 DynamoDB，这是一个以处理这种形式的非结构化数据的速度和成本效率著称的
    NoSQL 数据库。此外，boto3 SDK 简化了与数据库的交互，只需要几个函数来存储和检索数据：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Exposing Logic via an API
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 API 暴露逻辑
- en: 'We have now covered all of the core functionality, but the client side of the
    app with which the user interacts will need some way of triggering and making
    use of these processes. To facilitate this, each of the three pieces of logic
    (generating answers, saving chat history, and retrieving chat history) are exposed
    through separate endpoints within a Flask API, which will be called by the front
    end:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了所有核心功能，但用户与之交互的应用程序客户端需要某种方式来触发并利用这些过程。为了便于此，每个三大逻辑部分（生成答案、保存聊天历史、检索聊天历史）都通过
    Flask API 内部的单独端点暴露，前端将调用这些端点：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Lastly, I use AWS Lambda to wrap the three endpoints in a [single function](https://github.com/suresha97/ChatYTT/blob/main/server/lambda_handler.py)
    that is then triggered by an API Gateway resource, which routes requests to the
    correct endpoint by constructing an appropriate payload for each as needed. The
    flow of this setup now looks as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我使用 AWS Lambda 将三个端点包装成一个 [单一函数](https://github.com/suresha97/ChatYTT/blob/main/server/lambda_handler.py)，然后通过
    API Gateway 资源触发该函数，API Gateway 会根据需要构造适当的负载，将请求路由到正确的端点。这种设置的流程如下所示：
- en: '![](../Images/4c9a5431cecd5d35c0d1530b6378003e.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c9a5431cecd5d35c0d1530b6378003e.png)'
- en: Frontend
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前端
- en: With the backend for the app complete, I’ll briefly cover the implementation
    of the user interface in React, giving special attention to the interactions with
    the server component housing the API above.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成应用程序的后端后，我将简要介绍 React 中用户界面的实现，特别关注与包含上述 API 的服务器组件的交互。
- en: 'I make use of dedicated functional components for each section of the app,
    covering all of the typical requirements one might expect in a chatbot application:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我为应用程序的每个部分使用了专用的功能组件，涵盖了在聊天机器人应用程序中可能期望的所有典型需求：
- en: A container for user inputs with a send chat button.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于用户输入的容器，并带有发送聊天按钮。
- en: A chat feed in which user inputs and answers are displayed.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个聊天流，其中显示用户输入和答案。
- en: A sidebar containing chat history, a new chat button and a save chat button.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含聊天历史、一个新聊天按钮和一个保存聊天按钮的侧边栏。
- en: 'The interaction between these components and the flow of data is illustrated
    below:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件之间的交互以及数据流的过程如下图所示：
- en: '![](../Images/f765c74fd06a1ee00f201f96d3216938.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f765c74fd06a1ee00f201f96d3216938.png)'
- en: 'The API calls to each of the three endpoints and the subsequent change of state
    of the relevant variables on the client side, are defined in separate functional
    components:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个端点的 API 调用及相关变量在客户端状态的变化，都在独立的功能组件中定义：
- en: 'The logic for retrieving the generated answer to each question:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索每个问题生成答案的逻辑：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '2\. Saving chat history when the user clicks the save chat button:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 当用户点击保存聊天按钮时，保存聊天历史：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '3\. Retrieving chat history when the app first loads up:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 当应用程序首次加载时，检索聊天历史：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For the UI itself, I chose something very similar to ChatGPT’s own interface
    housing a central chat feed component, and a sidebar containing supporting content
    like chat histories. Some quality-of-life features for the user include automatic
    scrolling to the most recently created chat item, and previous chats loading upon
    sign-in (I have not included these in the article, but you can find their implementation
    in the relevant functional component [here](https://github.com/suresha97/ChatYTT/tree/main/client/src/components)).
    The final UI appears as shown below:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于用户界面，我选择了一个与 ChatGPT 界面非常相似的设计，中央是一个聊天流组件，旁边是一个包含聊天历史等支持内容的侧边栏。为了提升用户体验，一些功能包括自动滚动到最近创建的聊天项，以及在登录时加载之前的聊天记录（这些内容我没有在文章中包含，但你可以在相关的功能组件中找到其实现[在这里](https://github.com/suresha97/ChatYTT/tree/main/client/src/components)）。最终的用户界面如下所示：
- en: '![](../Images/a86a50109291a9161564dee2fdacf26b.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a86a50109291a9161564dee2fdacf26b.png)'
- en: 'Now that we have a fully functional UI, all that’s left is hosting it for use
    online which I’ve chosen to do with AWS Amplify. Among other things, Amplify is
    a fully managed web hosting service that handles resource provisioning and hosting
    of web applications. User authentication for the app is managed by Amazon Cognito
    allowing user sign-up and sign-on, alongside handling credential storage and management:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了一个功能完全的用户界面，剩下的就是将它部署到在线使用，我选择使用 AWS Amplify 来托管。除了其他功能外，Amplify 是一个完全托管的
    web 托管服务，它负责资源配置和 web 应用程序的托管。应用程序的用户身份验证由 Amazon Cognito 管理，允许用户注册和登录，同时处理凭证存储和管理：
- en: '![](../Images/deea70d1bf5d430b0bb988e66223257c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deea70d1bf5d430b0bb988e66223257c.png)'
- en: Comparison to ChatGPT responses
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 ChatGPT 回复的对比
- en: Now that we’ve discussed the process of building the app, let’s have a deep
    dive into the responses generated for some questions, and compare these to the
    same question posed to ChatGPT*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了应用程序构建的过程，让我们深入分析一些问题的回复，并将这些回复与 ChatGPT* 中提出的相同问题进行比较。
- en: Note that this type of comparison is inherently an “unfair” one since the underlying
    prompts to the LLM used in our application will contain additional context (in
    the form of relevant transcript chunks) retrieved from the semantic search step.
    However, it will allow us to qualitatively assess just how much of a difference
    the prompts created using RAG make, to the responses generated by the same underlying
    LLM.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种类型的比较本质上是不公平的，因为我们应用程序中使用的 LLM 的底层提示将包含额外的上下文（以相关的转录片段形式），这些片段是通过语义搜索步骤获取的。然而，它将帮助我们定性地评估使用
    RAG 创建的提示与由相同底层 LLM 生成的回复之间的差异有多大。
- en: '**All ChatGPT responses are from gpt-3.5, since this was the model used in
    the application.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**所有 ChatGPT 的回复均来自 gpt-3.5，因为这是应用程序中使用的模型。**'
- en: 'Example 1:'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 1：
- en: 'You want to learn about the contents in [this video](https://www.youtube.com/watch?v=vOvLFT4v4LQ&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&index=1)
    where Steven Bartlett chats to Morgan Housel, a financial writer and investor.
    Based on the title of the video, it looks like he’s against buying a house — but
    suppose you don’t have time to watch the whole thing to find out why. Here is
    a snippet of the conversation I had with the application asking about it:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过观看[这个视频](https://www.youtube.com/watch?v=vOvLFT4v4LQ&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&index=1)来了解内容，视频中
    Steven Bartlett 与财经作家及投资者 Morgan Housel 进行对话。从视频的标题来看，似乎他反对买房——但假设你没有时间观看完整的视频来找出原因。以下是我在应用程序中询问该问题时得到的对话片段：
- en: '![](../Images/3b7266647d4afd4f998fdbfe7fed81e4.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b7266647d4afd4f998fdbfe7fed81e4.png)'
- en: You can also see the conversation memory in action here, where in follow-up
    questions I make no mention of Morgan Housel explicitly or even the words “house”
    or “buying”. Since the summarised query takes previous chat history into account,
    the response from the LLM reflects previous questions and their answers. The portion
    of the video in which Housel mentions the points above can be found roughly an
    hour and a half into the podcast — around the [1:33:00–1:41:00 timestamp](https://youtu.be/vOvLFT4v4LQ?list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&t=5586).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在这里看到对话记忆的实际应用，在后续的问题中，我没有明确提到Morgan Housel，甚至没有提到“房子”或“购买”这两个词。由于总结的查询会考虑到先前的聊天记录，LLM的回答反映了之前的问题及其答案。Housel提到上述观点的部分大约在播客开始一个半小时后，可以在[1:33:00–1:41:00时间戳](https://youtu.be/vOvLFT4v4LQ?list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&t=5586)找到。
- en: I asked ChatGPT the same thing, and as expected got a very generic answer that
    is non-specific to Housel’s opinion.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我问了ChatGPT同样的问题，正如预期的那样，得到了一个非常通用的回答，并没有针对Housel的观点进行具体阐述。
- en: '![](../Images/5dd70a411ea8fd9f0becebf84bfd0012.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5dd70a411ea8fd9f0becebf84bfd0012.png)'
- en: It’s arguable that since the video came out after the model’s last “knowledge
    update” the comparison is flawed, but Housel’s opinions are also well documented
    in his book ‘The Psychology of Money’ which was published in 2020\. Regardless,
    the reliance on these knowledge updates further highlights the benefits of context-aware
    answer generation over standalone models.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，由于该视频是在模型的最后一次“知识更新”之后发布的，因此比较结果可能有偏差，但Housel的观点在他2020年出版的《金钱心理学》一书中也有详细记录。无论如何，这些对知识更新的依赖进一步突显了基于上下文的答案生成相比独立模型的优势。
- en: Example 2
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 2
- en: 'Below are some snippets from a chat about [this discussion](https://www.youtube.com/watch?v=x3e73Qn6NOo&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&index=4)
    with Alex Hormozi, a monetization and acquisitions expert. From the title of the
    video, it looks like he knows a thing or two about successfully scaling businesses
    so I ask for more details on this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与Alex Hormozi的[这次讨论](https://www.youtube.com/watch?v=x3e73Qn6NOo&list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2&index=4)中的一些片段，Alex
    Hormozi是一位货币化和收购专家。从视频标题来看，他似乎对如何成功扩展企业有一定的了解，因此我向他询问了更多的细节：
- en: '![](../Images/75e9ad41f70927529044b2b9a1a7454f.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75e9ad41f70927529044b2b9a1a7454f.png)'
- en: This seems like a reasonable answer, but let’s see if we can extract any more
    information from the same line of questioning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个回答看起来合情合理，但让我们看看是否能从同样的问题中提取更多信息。
- en: '![](../Images/27f33a139167e3a5a4db013ca0875b15.png)![](../Images/8369575cafd74f7be63e054395d263fe.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27f33a139167e3a5a4db013ca0875b15.png)![](../Images/8369575cafd74f7be63e054395d263fe.png)'
- en: Notice the level of detail the LLM is able to extract from the YouTube transcripts.
    All of the above can be found over a 15–20 minute portion of the video around
    the [17:00–35:00 timestamp.](https://www.youtube.com/watch?v=x3e73Qn6NOo&t=2106s)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，LLM能够从YouTube文字记录中提取的细节水平。上述内容可以在视频的15到20分钟部分找到，大约在[17:00–35:00时间戳](https://www.youtube.com/watch?v=x3e73Qn6NOo&t=2106s)。
- en: Again, the same question posed to ChatGPT returns a generic answer about the
    entrepreneur but lacks the detail made available through the context within the
    video transcripts.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，向ChatGPT提出相同的问题得到了关于企业家的通用回答，但缺乏视频文字记录中的背景信息细节。
- en: '![](../Images/f582a9f5f2b328ab6d0c402435afcf6a.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f582a9f5f2b328ab6d0c402435afcf6a.png)'
- en: Deployment
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: 'The final thing we’ll discuss is the process of deploying each of the components
    on AWS. The data pipeline, backend, and frontend are each contained within their
    own CloudFormation stacks (collections of AWS resources). Allowing these to be
    deployed in isolation like this, ensures that the entire app is not redeployed
    unnecessarily during development. I make use of AWS SAM (Serverless Application
    Model) to deploy the infrastructure for each component as code, leveraging the
    SAM template specification and CLI:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论在AWS上部署每个组件的过程。数据管道、后端和前端分别包含在各自的CloudFormation堆栈中（AWS资源集合）。像这样允许它们独立部署，确保在开发过程中不会不必要地重新部署整个应用。我使用AWS
    SAM（无服务器应用模型）将每个组件的基础设施作为代码进行部署，利用SAM模板规范和CLI：
- en: The SAM template specification — A short-hand syntax, that serves as an extension
    to AWS CloudFormation, for defining and configuring collections of AWS resources,
    how they should interact, and any required permissions.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAM模板规范 — 一种简写语法，作为AWS CloudFormation的扩展，用于定义和配置AWS资源集合、它们如何交互以及所需的权限。
- en: The SAM CLI — A command line tool used, among other things, for building and
    deploying resources as defined in a SAM template. It handles the packaging of
    application code and dependencies, converting the SAM template to CloudFormation
    syntax and deploying templates as individual stacks on CloudFormation.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAM CLI — 一个命令行工具，除了用于构建和部署按照 SAM 模板定义的资源外，还处理应用程序代码和依赖项的打包、将 SAM 模板转换为 CloudFormation
    语法，并将模板部署为 CloudFormation 上的单独堆栈。
- en: Rather than including the complete templates (resource definitions) of each
    component, I will highlight specific areas of interest for each service we’ve
    discussed throughout the post.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会包含每个组件的完整模板（资源定义），而是将突出每个我们在文章中讨论的服务的具体关注点。
- en: '**Passing sensitive environment variables to AWS resources:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**将敏感环境变量传递给 AWS 资源：**'
- en: 'External components like the Youtube Data API, OpenAI API and Pinecone API
    are relied upon heavily throughout the application. Although it is possible to
    hardcode these values into the CloudFormation templates and pass them around as
    ‘parameters’, a safer method is to create secrets for each in AWS SecretsManager
    and reference these secrets in the template like so:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 外部组件，如 Youtube 数据 API、OpenAI API 和 Pinecone API，在整个应用程序中被广泛依赖。虽然可以将这些值硬编码到 CloudFormation
    模板中并作为“参数”传递，但更安全的方法是为每个组件在 AWS SecretsManager 中创建密钥，并像这样在模板中引用这些密钥：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Defining a Lambda Function:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义 Lambda 函数：**'
- en: 'These units of serverless code form the backbone of the data pipeline and serve
    as an entry point to the backend for the web application. To deploy these using
    SAM, it’s as simple as defining the path to the code that the function should
    run when invoked, alongside any required permissions and environment variables.
    Here is an example of one of the functions used in the data pipeline:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这些无服务器代码单元构成了数据管道的骨干，并作为 Web 应用程序后端的入口点。使用 SAM 部署这些代码只需简单地定义当调用函数时应该运行的代码路径，以及任何所需的权限和环境变量。以下是数据管道中使用的一个函数示例：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Retrieving the definition of the data pipeline in Amazon States Language:**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索数据管道在 Amazon States Language 中的定义：**'
- en: 'In order to use Step Functions as an orchestrator for the individual Lambda
    functions in the data pipeline, we need to define the order in which each should
    be executed as well as configurations like max retry attempts in Amazon States
    Language. An easy way to do this is by using the [Workflow Studio](https://docs.aws.amazon.com/step-functions/latest/dg/workflow-studio.html)
    in the Step Functions console to diagrammatically create the workflow, and then
    take the autogenerated ASL definition of the workflow as a starting point that
    can be altered appropriately. This can then be linked in the CloudFormation template
    rather than being defined in place:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Step Functions 作为数据管道中各个 Lambda 函数的协调器，我们需要定义每个函数执行的顺序，以及诸如最大重试次数等配置项。一个简单的方法是使用
    Step Functions 控制台中的 [工作流工作室](https://docs.aws.amazon.com/step-functions/latest/dg/workflow-studio.html)以图形化方式创建工作流，然后将自动生成的
    ASL 工作流定义作为起点进行适当修改。然后可以在 CloudFormation 模板中链接它，而不是在模板中直接定义：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: See [here](https://github.com/suresha97/ChatYTT/blob/main/deploy/chatytt-workflows/statemachine/embedding_retriever.asl.json)
    for the ASL definition used for the data pipeline discussed in this post.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 [此处](https://github.com/suresha97/ChatYTT/blob/main/deploy/chatytt-workflows/statemachine/embedding_retriever.asl.json)
    查阅本文章中讨论的数据管道使用的 ASL 定义。
- en: '**Defining the API resource:**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义 API 资源：**'
- en: 'Since the API for the web app will be hosted separately from the front-end,
    we must enable CORS (cross-origin resource sharing) support when defining the
    API resource:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Web 应用程序的 API 将与前端分开托管，因此在定义 API 资源时，我们必须启用 CORS（跨源资源共享）支持：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This will allow the two resources to communicate freely with each other. The
    various endpoints made accessible through a Lambda function can be defined like
    so:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许这两个资源相互自由通信。通过 Lambda 函数使得可访问的各种端点可以这样定义：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Defining the React app resource:**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义 React 应用资源：**'
- en: 'AWS Amplify can build and deploy applications using a reference to the relevant
    Github repository and an appropriate access token:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Amplify 可以使用对相关 Github 仓库的引用和适当的访问令牌来构建和部署应用程序：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once the repository itself is accessible, Ampify will look for a configuration
    file with instructions on how to build and deploy the app:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦仓库本身可访问，Amplify 将查找一个包含构建和部署应用程序指令的配置文件：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As a bonus, it is also possible to automate the process of continuous deployment
    by defining a branch resource that will be monitored and used to re-deploy the
    app automatically upon further commits:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个附加功能，还可以通过定义一个分支资源来自动化持续部署过程，这个资源会被监控，并在进一步提交时自动重新部署应用：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'With deployment finalised in this way, it is accessible to anyone with the
    link made available from the AWS Amplify console. A recorded demo of the app being
    accessed like this can be found [here](https://github.com/suresha97/ChatYTT/blob/main/docs/Screen-2023-12-21-180035.mp4):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式完成部署后，任何拥有 AWS Amplify 控制台提供的链接的人都可以访问它。可以在[这里](https://github.com/suresha97/ChatYTT/blob/main/docs/Screen-2023-12-21-180035.mp4)找到一个应用被访问的演示录制：
- en: Conclusion
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'At a high level, we have covered the steps behind:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次看，我们已经涵盖了以下步骤：
- en: Building a data pipeline for the collection and storage of content as embeddings.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个用于收集和存储内容作为嵌入的 数据管道。
- en: Developing a backend server component which performs Retrieval Augmented Generation
    with Conversation Memory.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个后台服务器组件，执行带有对话记忆的检索增强生成。
- en: Designing a user interface for surfacing generated answers and chat histories.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个用户界面，用于展示生成的答案和聊天历史。
- en: How these components can be connected and deployed to create a solution that
    provides value and saves time.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些组件如何连接并部署以创建一个能够提供价值并节省时间的解决方案。
- en: We’ve seen how an application like this can be used to streamline and in some
    ways ‘optimise’ the consumption of content such as YouTube videos for learning
    and development purposes. But these methods can just as easily be applied in the
    workplace for internal use or for augmenting customer-facing solutions. This is
    why the popularity of LLMs, and the RAG technique in particular has garnered so
    much attention in many organisations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，像这样的应用程序如何被用来简化并在某些方面“优化”像 YouTube 视频这样的内容在学习和发展中的消费。但这些方法同样可以轻松地应用于工作场所的内部使用或增强面向客户的解决方案。这也是为什么大语言模型（LLM）及特别是
    RAG 技术在许多组织中获得如此多关注的原因。
- en: I hope this article has provided some insight into how these relatively new
    techniques can be utilised alongside more traditional tools and frameworks for
    developing user-facing applications.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章能够为如何将这些相对较新的技术与更多传统的工具和框架结合使用，在开发面向用户的应用程序中提供一些见解。
- en: Acknowledgements
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: I would like to thank The Diary of a CEO team, for their permission to use the
    transcripts of videos from this [playlist](https://www.youtube.com/playlist?list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2)
    in this project, and in the writing of this article.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢《CEO日记》团队，感谢他们允许在本项目中使用来自这个[播放列表](https://www.youtube.com/playlist?list=PL22egh3ok4cOaKRqIt6LwBRXcyiVcS5k2)的视频转录内容，并为撰写本文提供支持。
- en: All images, unless otherwise noted, are by the author.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 所有图片，除非另有注明，均由作者提供。
