- en: Data Dirtiness Score
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®è„ä¹±åº¦è¯„åˆ†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02](https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02](https://towardsdatascience.com/data-dirtiness-score-fe2ca5678d40?source=collection_archive---------1-----------------------#2024-03-02)
- en: New method to measure tabular dataset quality
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æµ‹é‡è¡¨æ ¼æ•°æ®é›†è´¨é‡çš„æ–°æ–¹æ³•
- en: '[](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)[![Simon
    Grah](../Images/f8fd00600db79bc910ff51e9f64503d0.png)](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)
    [Simon Grah](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)[![Simon
    Grah](../Images/f8fd00600db79bc910ff51e9f64503d0.png)](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)
    [Simon Grah](https://medium.com/@simon.grah?source=post_page---byline--fe2ca5678d40--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)
    Â·11 min readÂ·Mar 2, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--fe2ca5678d40--------------------------------)
    Â·é˜…è¯»æ—¶é—´ï¼š11åˆ†é’ŸÂ·2024å¹´3æœˆ2æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article, the first in a series on data cleaning practices involving Large
    Language Models (LLMs), focuses on quantifying the cleanliness or dirtiness of
    a dataset
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ˜¯å…³äºæ¶‰åŠå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ•°æ®æ¸…æ´—å®è·µç³»åˆ—æ–‡ç« çš„ç¬¬ä¸€ç¯‡ï¼Œé‡ç‚¹è®¨è®ºå¦‚ä½•é‡åŒ–æ•°æ®é›†çš„æ¸…æ´åº¦æˆ–è„ä¹±åº¦
- en: '![](../Images/4c8f68fd06ac2bc78782f13b1a251904.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c8f68fd06ac2bc78782f13b1a251904.png)'
- en: Photo by [Fabrizio Conti](https://unsplash.com/@conti_photos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥è‡ª[Fabizio Conti](https://unsplash.com/@conti_photos?utm_source=medium&utm_medium=referral)
    åœ¨[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Starting with the Why
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»ä¸ºä»€ä¹ˆå¼€å§‹
- en: This article introduces a concept for evaluating the dirtiness of a dataset,
    a topic that presents challenges due to the lack of a tangible score or loss function
    related to data cleaning. The primary objective here is to establish a metric
    that can effectively measure the cleanliness level of a dataset, translating this
    concept into a concrete optimisation problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç”¨äºè¯„ä¼°æ•°æ®é›†è„ä¹±åº¦çš„æ¦‚å¿µï¼Œè¿™ä¸ªè¯é¢˜ç”±äºç¼ºä¹ä¸æ•°æ®æ¸…æ´—ç›¸å…³çš„å…·ä½“è¯„åˆ†æˆ–æŸå¤±å‡½æ•°è€Œé¢ä¸´æŒ‘æˆ˜ã€‚è¿™é‡Œçš„ä¸»è¦ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªå¯ä»¥æœ‰æ•ˆè¡¡é‡æ•°æ®é›†æ¸…æ´åº¦çš„æŒ‡æ ‡ï¼Œå°†è¿™ä¸€æ¦‚å¿µè½¬åŒ–ä¸ºå…·ä½“çš„ä¼˜åŒ–é—®é¢˜ã€‚
- en: 'Data cleaning is defined as a two-phase process:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¸…æ´—å®šä¹‰ä¸ºä¸€ä¸ªä¸¤é˜¶æ®µè¿‡ç¨‹ï¼š
- en: First, **detecting data errors** such as formatting issues, duplicate records,
    and outliers;
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œ**æ£€æµ‹æ•°æ®é”™è¯¯**ï¼Œå¦‚æ ¼å¼é—®é¢˜ã€é‡å¤è®°å½•å’Œç¦»ç¾¤å€¼ï¼›
- en: Second, **fixing** these **errors**.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œ**ä¿®å¤**è¿™äº›**é”™è¯¯**ã€‚
- en: 'The evaluation of each phase typically relies on comparing a dirty dataset
    against a clean (ground truth) version, using classification metrics like recall,
    precision, and F1-score for error detection (see for example [Can Foundation Models
    Wrangle Your Data?](https://arxiv.org/abs/2205.09911), [Detecting Data Errors:
    Where are we and what needs to be done?](https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf))
    and accuracy or overlap-based metrics for data repair tasks (see [Automatic Data
    Repair: Are We Ready to Deploy?](https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463)
    or [HoloClean: Holistic Data Repairs with Probabilistic Inference](https://arxiv.org/abs/1702.00820)).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªé˜¶æ®µçš„è¯„ä¼°é€šå¸¸ä¾èµ–äºå°†è„ä¹±çš„æ•°æ®é›†ä¸æ¸…æ´ï¼ˆçœŸå®ï¼‰ç‰ˆæœ¬è¿›è¡Œæ¯”è¾ƒï¼Œä½¿ç”¨åˆ†ç±»æŒ‡æ ‡å¦‚å¬å›ç‡ã€ç²¾ç¡®åº¦å’ŒF1å¾—åˆ†è¿›è¡Œé”™è¯¯æ£€æµ‹ï¼ˆä¾‹å¦‚ï¼Œå‚è§[å¤§å‹åŸºç¡€æ¨¡å‹èƒ½å¤„ç†ä½ çš„æ•°æ®å—ï¼Ÿ](https://arxiv.org/abs/2205.09911)ï¼Œ[æ£€æµ‹æ•°æ®é”™è¯¯ï¼šæˆ‘ä»¬åœ¨å“ªå„¿ï¼Œéœ€è¦åšä»€ä¹ˆï¼Ÿ](https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf)ï¼‰ä»¥åŠç”¨äºæ•°æ®ä¿®å¤ä»»åŠ¡çš„å‡†ç¡®ç‡æˆ–é‡å åº¦åº¦é‡ï¼ˆä¾‹å¦‚ï¼Œå‚è§[è‡ªåŠ¨æ•°æ®ä¿®å¤ï¼šæˆ‘ä»¬å‡†å¤‡å¥½éƒ¨ç½²äº†å—ï¼Ÿ](https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463)æˆ–[HoloCleanï¼šé€šè¿‡æ¦‚ç‡æ¨ç†è¿›è¡Œæ•´ä½“æ•°æ®ä¿®å¤](https://arxiv.org/abs/1702.00820)ï¼‰ã€‚
- en: However, these metrics are task-specific and do not offer a unified measure
    for the overall cleanliness of a dataset that includes various types of errors.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡æ˜¯ä»»åŠ¡ç‰¹å®šçš„ï¼Œå¹¶æœªæä¾›ä¸€ä¸ªç»Ÿä¸€çš„è¡¡é‡æ ‡å‡†æ¥è¯„ä¼°åŒ…å«å„ç§é”™è¯¯ç±»å‹çš„æ•°æ®é›†çš„æ•´ä½“æ¸…æ´åº¦ã€‚
- en: This discussion is focused on **structured and tidy tabular datasets** (see
    [Tidy Data | Journal of Statistical Software](https://www.jstatsoft.org/article/view/v059i10)),
    **distinguishing data cleaning from broader data quality concerns** that include
    data governance, lineage, cataloguing, drift, and more.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬è®¨è®ºèšç„¦äº**ç»“æ„åŒ–ä¸”æ•´æ´çš„è¡¨æ ¼æ•°æ®é›†**ï¼ˆè§[ã€Šæ•´æ´æ•°æ® | ç»Ÿè®¡è½¯ä»¶æœŸåˆŠã€‹](https://www.jstatsoft.org/article/view/v059i10)ï¼‰ï¼Œ**å°†æ•°æ®æ¸…æ´—ä¸æ›´å¹¿æ³›çš„æ•°æ®è´¨é‡é—®é¢˜åŒºåˆ†å¼€æ¥**ï¼Œåè€…åŒ…æ‹¬æ•°æ®æ²»ç†ã€æ•°æ®æº¯æºã€ç›®å½•ç®¡ç†ã€æ•°æ®æ¼‚ç§»ç­‰ã€‚
- en: The score blueprint
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¯„åˆ†è“å›¾
- en: All the assumptions hereafter are the foundations the *Data Dirtiness Score*
    relies on. There are largely inspired by the article [How to quantify Data Quality?](/how-to-quantify-data-quality-743721bdba03).
    Of course, all of them could be debated and criticised but it is crucial to clearly
    state them to enhance discussions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ‰€æœ‰å‡è®¾éƒ½æ˜¯*æ•°æ®è„æ±¡è¯„åˆ†*æ‰€ä¾èµ–çš„åŸºç¡€ã€‚è¿™äº›å‡è®¾å¤§å¤šæ¥è‡ªæ–‡ç« [ã€Šå¦‚ä½•é‡åŒ–æ•°æ®è´¨é‡ï¼Ÿã€‹](/how-to-quantify-data-quality-743721bdba03)ã€‚å½“ç„¶ï¼Œæ‰€æœ‰è¿™äº›å‡è®¾éƒ½å¯ä»¥è¢«è¾©è®ºå’Œæ‰¹è¯„ï¼Œä½†æ˜ç¡®é™ˆè¿°è¿™äº›å‡è®¾å¯¹ä¿ƒè¿›è®¨è®ºè‡³å…³é‡è¦ã€‚
- en: '**Data errors are tied to violated constraints**, which arise from **expectations**
    about the data. For example, if the expectation is that the ID column should have
    no missing values, the presence of missing IDs would constitute a constraint violation.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®é”™è¯¯ä¸è¿åçº¦æŸæœ‰å…³**ï¼Œè¿™äº›çº¦æŸæ¥æºäºå¯¹æ•°æ®çš„**æœŸæœ›**ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœŸæœ›IDåˆ—ä¸åº”æœ‰ç¼ºå¤±å€¼ï¼Œé‚£ä¹ˆIDåˆ—ä¸­å­˜åœ¨ç¼ºå¤±å€¼å°±æ„æˆäº†çº¦æŸè¿åã€‚'
- en: No Expectation No Cry. **The absence of expectations means no impact on the
    score**. In other words, no data issues can be identified without predefined expectations,
    and thus, canâ€™t violate constraints that donâ€™t exist.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ— æœŸæœ›åˆ™æ— å¿§ã€‚**ç¼ºä¹æœŸæœ›æ„å‘³ç€ä¸ä¼šå¯¹è¯„åˆ†äº§ç”Ÿå½±å“**ã€‚æ¢å¥è¯è¯´ï¼Œè‹¥æ²¡æœ‰é¢„å®šä¹‰çš„æœŸæœ›ï¼Œå°±æ— æ³•è¯†åˆ«æ•°æ®é—®é¢˜ï¼Œå› æ­¤ä¹Ÿæ— æ³•è¿åä¸å­˜åœ¨çš„çº¦æŸã€‚
- en: '**Data issues should be locateable to specific cells**. The score relies on
    the ability to pinpoint errors to particular cells in the dataset.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®é—®é¢˜åº”èƒ½å®šä½åˆ°å…·ä½“å•å…ƒæ ¼**ã€‚è¯„åˆ†ä¾èµ–äºèƒ½å¤Ÿå°†é”™è¯¯ç²¾ç¡®å®šä½åˆ°æ•°æ®é›†ä¸­ç‰¹å®šå•å…ƒæ ¼çš„èƒ½åŠ›ã€‚'
- en: '**Confidence scores for data errors**. Not all data errors can be identified
    with the same level of certainty. Each detected issue should be tagged with a
    confidence level, indicating how likely it is that the identified issue is indeed
    an error. This approach acknowledges that some errors might be open to interpretation.
    Instead of using a continuous scale from 0 to 1, which might be too detailed,
    we suggest categorising this confidence level into four ordinal categories: `low`,
    `medium`, `high`, and `certain`. These categories correspond to probability values
    of 0.25, 0.5, 0.75, and 1, respectively.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ•°æ®é”™è¯¯çš„ç½®ä¿¡åº¦åˆ†æ•°**ã€‚å¹¶éæ‰€æœ‰æ•°æ®é”™è¯¯éƒ½èƒ½ä»¥ç›¸åŒçš„ç¡®å®šæ€§è¢«è¯†åˆ«ã€‚æ¯ä¸ªæ£€æµ‹åˆ°çš„é—®é¢˜åº”æ ‡è®°ä¸€ä¸ªç½®ä¿¡åº¦çº§åˆ«ï¼Œè¡¨ç¤ºè¯¥é—®é¢˜ç¡®å®æ˜¯ä¸€ä¸ªé”™è¯¯çš„å¯èƒ½æ€§æœ‰å¤šå¤§ã€‚è¿™ç§æ–¹æ³•æ‰¿è®¤ä¸€äº›é”™è¯¯å¯èƒ½å­˜åœ¨è§£é‡Šç©ºé—´ã€‚æˆ‘ä»¬å»ºè®®å°†ç½®ä¿¡åº¦çº§åˆ«åˆ†ä¸ºå››ä¸ªé¡ºåºç±»åˆ«ï¼š`ä½`ã€`ä¸­`ã€`é«˜`å’Œ`ç¡®å®š`ã€‚è¿™äº›ç±»åˆ«åˆ†åˆ«å¯¹åº”0.25ã€0.5ã€0.75å’Œ1çš„æ¦‚ç‡å€¼ã€‚'
- en: '**Uniform impact of cells on the overall score**. Each cell in a dataset has
    an equal potential impact on the dirtiness score. Addressing an issue related
    to a given cell may resolve issues in others, suggesting a uniform distribution
    of cell weights in the score calculation.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**å•å…ƒæ ¼å¯¹æ•´ä½“è¯„åˆ†çš„å‡åŒ€å½±å“**ã€‚æ•°æ®é›†ä¸­çš„æ¯ä¸ªå•å…ƒæ ¼å¯¹è„æ•°æ®è¯„åˆ†éƒ½æœ‰ç›¸åŒçš„æ½œåœ¨å½±å“ã€‚è§£å†³ä¸æŸä¸ªå•å…ƒæ ¼ç›¸å…³çš„é—®é¢˜å¯èƒ½ä¼šè§£å†³å…¶ä»–å•å…ƒæ ¼çš„é—®é¢˜ï¼Œè¿™è¡¨æ˜åœ¨è¯„åˆ†è®¡ç®—ä¸­å•å…ƒæ ¼çš„æƒé‡æ˜¯å‡åŒ€åˆ†å¸ƒçš„ã€‚'
- en: A toy example for illustration
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç®€åŒ–ç¤ºä¾‹ä»¥ä¾¿è¯´æ˜
- en: 'When examining a dataset, itâ€™s not uncommon to spot potential data quality
    issues at a glance. Consider the following simple dataset for analysis:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ£€æŸ¥æ•°æ®é›†æ—¶ï¼Œå‡­ä¸€çœ¼å°±èƒ½å‘ç°æ½œåœ¨çš„æ•°æ®è´¨é‡é—®é¢˜å¹¶ä¸ç½•è§ã€‚è¯·è€ƒè™‘ä»¥ä¸‹ç”¨äºåˆ†æçš„ç®€å•æ•°æ®é›†ï¼š
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This example from the book [Cleaning Data for Effective Data Science](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science)
    illustrates data quality issues within a dataset representing a 6th-grade class.
    This dataset includes multiple variables for each student, organised such that
    there are 6 students and 5 variables per student.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç¤ºä¾‹æ¥è‡ªä¹¦ç±[ã€Šæœ‰æ•ˆæ•°æ®ç§‘å­¦çš„æ•°æ®æ¸…æ´—ã€‹](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science)ï¼Œå®ƒå±•ç¤ºäº†ä¸€ä¸ªä»£è¡¨å…­å¹´çº§ç­çº§çš„æ•°æ®é›†ä¸­å­˜åœ¨çš„æ•°æ®è´¨é‡é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å«æ¯ä¸ªå­¦ç”Ÿçš„å¤šä¸ªå˜é‡ï¼Œç»„ç»‡æ–¹å¼æ˜¯æ¯ä¸ªå­¦ç”Ÿæœ‰6ä¸ªå­¦ç”Ÿå’Œ5ä¸ªå˜é‡ã€‚
- en: 'Upon inspection, certain entries might raise concerns due to apparent inconsistencies
    or errors:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ£€æŸ¥æ—¶ï¼ŒæŸäº›æ¡ç›®å¯èƒ½å› æ˜æ˜¾çš„ä¸ä¸€è‡´æ€§æˆ–é”™è¯¯è€Œå¼•èµ·å…³æ³¨ï¼š
- en: The entry for the student with `Student#` 2 (Lopez, Liam) appears to have an
    extra value in the `Favorite Color` column, which looks like two values ('blue,green')
    have been merged. Typically, this column should only contain a single value. Given
    the uncertainty, this issue is flagged with a `high`confidence level for further
    inspection.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦å·ä¸º`Student#` 2ï¼ˆLiam Lopezï¼‰çš„å­¦ç”Ÿæ¡ç›®ä¼¼ä¹åœ¨`Favorite Color`åˆ—ä¸­æœ‰ä¸€ä¸ªé¢å¤–çš„å€¼ï¼Œçœ‹èµ·æ¥åƒæ˜¯ä¸¤ä¸ªå€¼ï¼ˆ'blue,green'ï¼‰åˆå¹¶åœ¨äº†ä¸€èµ·ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™ä¸€åˆ—åº”åªåŒ…å«ä¸€ä¸ªå€¼ã€‚é‰´äºä¸ç¡®å®šæ€§ï¼Œè¯¥é—®é¢˜è¢«æ ‡è®°ä¸º`high`ç½®ä¿¡åº¦çº§åˆ«ï¼Œéœ€è¿›ä¸€æ­¥æ£€æŸ¥ã€‚
- en: The next student, Isabella Lee, lacks a `Favorite Color` value. Given that this
    column should not have any missing entries, this issue is identified with `certain`confidence
    for correction.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä½å­¦ç”Ÿï¼ŒIsabella Leeï¼Œç¼ºå°‘`Favorite Color`å€¼ã€‚é‰´äºè¯¥åˆ—ä¸åº”æœ‰ä»»ä½•ç¼ºå¤±é¡¹ï¼Œå› æ­¤è¯¥é—®é¢˜å·²è¢«ä»¥`certain`ç½®ä¿¡åº¦è¯†åˆ«ä¸ºéœ€è¦ä¿®æ­£ã€‚
- en: The record for student number 4, Mason Fisher, lists an age of `-1`, an implausible
    value. This might represent a sentinel value indicating missing data, as it is
    common practice to use such placeholders. However, ages should be positive integers,
    necessitating a review of this entry.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦å·ä¸º4çš„å­¦ç”ŸMason Fisherçš„è®°å½•åˆ—å‡ºäº†`-1`çš„å¹´é¾„ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸å¯ä¿¡çš„å€¼ã€‚è¿™å¯èƒ½ä»£è¡¨ä¸€ä¸ªè¡¨ç¤ºç¼ºå¤±æ•°æ®çš„å“¨å…µå€¼ï¼Œå› ä¸ºä½¿ç”¨è¿™ç§å ä½ç¬¦æ˜¯å¸¸è§åšæ³•ã€‚ç„¶è€Œï¼Œå¹´é¾„åº”è¯¥æ˜¯æ­£æ•´æ•°ï¼Œå› æ­¤éœ€è¦å®¡æŸ¥è¿™ä¸€æ¡ç›®ã€‚
- en: The row for student number 5, Olivia Gupta, while free from structural errors,
    presents an unusual case as several explanations are plausible. The `Favorite
    Color` and `First Name` fields might be swapped, considering `Olivia` can be both
    a name and a colour. Alternatively, the number `9` could represent a colour code,
    but this hypothesis lacks corroborating evidence. Moreover, an age of `102` for
    a 6th-grade student is highly improbable, suggesting potential typographical errors
    (e.g. `102` instead of `12`).
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦å·ä¸º5çš„å­¦ç”ŸOlivia Guptaæ‰€åœ¨çš„è¡Œè™½ç„¶æ²¡æœ‰ç»“æ„æ€§é”™è¯¯ï¼Œä½†å´å‘ˆç°å‡ºä¸€ä¸ªä¸å¯»å¸¸çš„æƒ…å†µï¼Œå› ä¸ºæœ‰å¤šä¸ªè§£é‡Šæ˜¯åˆç†çš„ã€‚`Favorite Color`å’Œ`First
    Name`å­—æ®µå¯èƒ½è¢«äº¤æ¢ï¼Œå› ä¸º`Olivia`æ—¢å¯ä»¥æ˜¯åå­—ï¼Œä¹Ÿå¯ä»¥æ˜¯é¢œè‰²ã€‚æ­¤å¤–ï¼Œæ•°å­—`9`å¯èƒ½è¡¨ç¤ºé¢œè‰²ä»£ç ï¼Œä½†è¿™ä¸€å‡è®¾ç¼ºä¹æ”¯æŒè¯æ®ã€‚è€Œä¸”ï¼Œä¸€åå…­å¹´çº§å­¦ç”Ÿçš„å¹´é¾„ä¸º`102`æ˜¯ä¸å¤ªå¯èƒ½çš„ï¼Œè¿™è¡¨æ˜å¯èƒ½å­˜åœ¨æ‹¼å†™é”™è¯¯ï¼ˆä¾‹å¦‚å°†`102`å†™æˆäº†`12`ï¼‰ã€‚
- en: The last row contains superfluous commas, indicating a possible data ingestion
    issue. However, aside from this formatting concern, the entry itself seems valid,
    leading to a `high`confidence level in identifying the nature of this error.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€åä¸€è¡ŒåŒ…å«å¤šä½™çš„é€—å·ï¼Œè¡¨ç¤ºå¯èƒ½å­˜åœ¨æ•°æ®æ‘„å–é—®é¢˜ã€‚ç„¶è€Œï¼Œé™¤äº†è¿™ä¸ªæ ¼å¼é—®é¢˜ä¹‹å¤–ï¼Œæ¡ç›®æœ¬èº«ä¼¼ä¹æœ‰æ•ˆï¼Œå› æ­¤åœ¨è¯†åˆ«è¯¥é”™è¯¯çš„æ€§è´¨æ—¶ï¼Œç»™å‡ºäº†`high`çš„ç½®ä¿¡åº¦çº§åˆ«ã€‚
- en: 'Following our guidelines to compute the dirtiness score, we can adopt a methodical
    approach by introducing a `DataIssue` class in Python, designed to encapsulate
    various aspects of a data issue:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘ä»¬çš„æŒ‡å¯¼æ–¹é’ˆè®¡ç®—æ•°æ®è„åº¦åˆ†æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¼•å…¥ä¸€ä¸ªPythonä¸­çš„`DataIssue`ç±»æ¥é‡‡ç”¨ç³»ç»ŸåŒ–çš„æ–¹æ³•ï¼Œè¯¥ç±»æ—¨åœ¨å°è£…æ•°æ®é—®é¢˜çš„å„ä¸ªæ–¹é¢ï¼š
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To locate specific errors, a `numpy` array of size `(6, 5)` is utilised, where
    each element corresponds to a cell in the dataset. This array consists of 0s and
    1s, with 1 indicating a potential issue in the corresponding cell of the dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®šä½ç‰¹å®šé”™è¯¯ï¼Œä½¿ç”¨ä¸€ä¸ªå¤§å°ä¸º`(6, 5)`çš„`numpy`æ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ å¯¹åº”æ•°æ®é›†ä¸­çš„ä¸€ä¸ªå•å…ƒæ ¼ã€‚è¯¥æ•°ç»„ç”±0å’Œ1ç»„æˆï¼Œ1è¡¨ç¤ºæ•°æ®é›†ä¸­ç›¸åº”å•å…ƒæ ¼å¯èƒ½å­˜åœ¨é—®é¢˜ã€‚
- en: 'All the identified data issues are instantiated hereafter:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å·²è¯†åˆ«çš„æ•°æ®é—®é¢˜å°†åœ¨æ­¤ä¹‹åå®ä¾‹åŒ–ï¼š
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The categorisation of multiple data errors into specific `DataIssue` instances
    can be somewhat subjective, similar to the nuances involved in bug reporting in
    software development. The fieldsâ€”`type_of_issue`, `expectation`, and `constraint_violated`â€”serve
    to elucidate the nature of the error, facilitating understanding during investigations
    or reviews.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å¤šä¸ªæ•°æ®é”™è¯¯å½’ç±»ä¸ºç‰¹å®šçš„`DataIssue`å®ä¾‹å¯èƒ½å¸¦æœ‰ä¸€å®šçš„ä¸»è§‚æ€§ï¼Œç±»ä¼¼äºè½¯ä»¶å¼€å‘ä¸­çš„é”™è¯¯æŠ¥å‘Šè¿‡ç¨‹ã€‚å­—æ®µâ€”`type_of_issue`ã€`expectation`å’Œ`constraint_violated`â€”æœ‰åŠ©äºé˜æ˜é”™è¯¯çš„æ€§è´¨ï¼Œä¾¿äºåœ¨è°ƒæŸ¥æˆ–å®¡æŸ¥æ—¶ç†è§£ã€‚
- en: For computing the dirtiness score, the critical elements are the locations of
    the errors and the associated confidence scores. In this example, the confidence
    scores are estimated based on the perceived certainty of an error's presence.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®è„åº¦åˆ†æ•°æ—¶ï¼Œå…³é”®å…ƒç´ æ˜¯é”™è¯¯çš„ä½ç½®å’Œç›¸å…³çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œç½®ä¿¡åº¦åˆ†æ•°æ˜¯åŸºäºå¯¹é”™è¯¯å­˜åœ¨æ€§çš„æ„ŸçŸ¥ç¡®å®šçš„ã€‚
- en: '*Repeated issues pointing to the same cells significantly increase the likelihood
    of a problem being present there.*'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æŒ‡å‘ç›¸åŒå•å…ƒæ ¼çš„é‡å¤é—®é¢˜æ˜¾è‘—å¢åŠ äº†é—®é¢˜å­˜åœ¨çš„å¯èƒ½æ€§ã€‚*'
- en: Now that we have all the information we need, letâ€™s see how to calculate the
    dirtiness score for this small data set.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ‹¥æœ‰æ‰€éœ€çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è®¡ç®—è¿™ä¸ªå°æ•°æ®é›†çš„è„åº¦åˆ†æ•°ã€‚
- en: Calculation of the Data Dirtiness Score
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®è„åº¦åˆ†æ•°
- en: '*The* Data Dirtiness Score *represents the* ***expected fraction of cells***
    *in a dataset* ***that contain errors****.*'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ•°æ®è„æ±¡å¾—åˆ†* *ä»£è¡¨äº†* ***æ•°æ®é›†ä¸­åŒ…å«é”™è¯¯çš„å•å…ƒæ ¼çš„é¢„æœŸæ¯”ä¾‹***ã€‚*'
- en: The theory and calculation for this score are elaborated in the `Score Theory`
    section of the appendix.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å¾—åˆ†çš„ç†è®ºå’Œè®¡ç®—è¯¦è§é™„å½•ä¸­çš„`å¾—åˆ†ç†è®º`éƒ¨åˆ†ã€‚
- en: By using confidence scores for various issues as estimates for the independent
    probability of an error in each cell, we can apply fundamental probability principles
    to calculate the likelihood of an issue per cell, and consequently, the *Data
    Dirtiness Score*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨é’ˆå¯¹å„ä¸ªé—®é¢˜çš„ç½®ä¿¡å¾—åˆ†ä½œä¸ºæ¯ä¸ªå•å…ƒæ ¼ä¸­é”™è¯¯ç‹¬ç«‹æ¦‚ç‡çš„ä¼°è®¡å€¼ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨åŸºæœ¬çš„æ¦‚ç‡åŸç†æ¥è®¡ç®—æ¯ä¸ªå•å…ƒæ ¼å‡ºç°é—®é¢˜çš„å¯èƒ½æ€§ï¼Œä»è€Œå¾—å‡º*æ•°æ®è„æ±¡å¾—åˆ†*ã€‚
- en: 'Below is a Python function to calculate this metric based on a list of identified
    data issues:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯ä¸€ä¸ªPythonå‡½æ•°ï¼Œç”¨äºæ ¹æ®å·²è¯†åˆ«çš„æ•°æ®é—®é¢˜åˆ—è¡¨è®¡ç®—è¯¥æŒ‡æ ‡ï¼š
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Letâ€™s compute the score for the data set presented earlier:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è®¡ç®—ä¹‹å‰å±•ç¤ºçš„æ•°æ®é›†çš„å¾—åˆ†ï¼š
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Data Dirtiness Score: 31.87%*'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ•°æ®è„æ±¡å¾—åˆ†ï¼š31.87%*'
- en: To improve (reduce) this score, a natural step is to tackle the simplest errors,
    such as correcting duplicate commas used as separators in the last row.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ”¹å–„ï¼ˆé™ä½ï¼‰è¿™ä¸€å¾—åˆ†ï¼Œä¸€ä¸ªè‡ªç„¶çš„æ­¥éª¤æ˜¯è§£å†³æœ€ç®€å•çš„é”™è¯¯ï¼Œä¾‹å¦‚çº æ­£æœ€åä¸€è¡Œä¸­ä½œä¸ºåˆ†éš”ç¬¦çš„é‡å¤é€—å·ã€‚
- en: 'Here is the new version of the dataset:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ•°æ®é›†çš„æ–°ç‰ˆæœ¬ï¼š
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Letâ€™s recompute the score once again to see the improvement.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†æ¬¡é‡æ–°è®¡ç®—å¾—åˆ†ï¼Œä»¥æŸ¥çœ‹æ”¹å–„æ•ˆæœã€‚
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Data Dirtiness Score: 15.21%*'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ•°æ®è„æ±¡å¾—åˆ†ï¼š15.21%*'
- en: Reevaluating the score post-correction reveals a significant improvement, halving
    the score due to the nature of the error affecting an entire row in a relatively
    small dataset.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº æ­£åé‡æ–°è¯„ä¼°å¾—åˆ†ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ”¹å–„ï¼Œç”±äºé”™è¯¯å½±å“äº†ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†ä¸­çš„æ•´ä¸ªè¡Œï¼Œå¾—åˆ†å‡å°‘äº†ä¸€åŠã€‚
- en: In conclusion, this measure provides a quantitative means of monitoring and
    improving the cleanliness of our dataset by correcting iteratively identified
    data errors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œè¿™ä¸€åº¦é‡ä¸ºç›‘æ§å’Œæ”¹è¿›æ•°æ®é›†çš„æ¸…æ´åº¦æä¾›äº†ä¸€ç§å®šé‡æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£çº æ­£å·²è¯†åˆ«çš„æ•°æ®é”™è¯¯ã€‚
- en: Next Steps and Challenges
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åç»­æ­¥éª¤ä¸æŒ‘æˆ˜
- en: 'Creating expectations or constraints for data can be challenging and costly
    due to the need for human labelling and domain knowledge. A solution is to automate
    the generation of constraints and data error detection, allowing humans to later
    review and adjust these automated constraints by either removing issues or modifying
    confidence scores. For that purpose, LLMs are really good candidates (cf. [Jellyfish:
    A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10),
    [Can language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)
    or [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸ºæ•°æ®åˆ›å»ºé¢„æœŸæˆ–çº¦æŸæ¡ä»¶å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§å¹¶ä¸”æˆæœ¬è¾ƒé«˜ï¼Œå› ä¸ºå®ƒéœ€è¦äººå·¥æ ‡æ³¨å’Œé¢†åŸŸçŸ¥è¯†ã€‚ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯è‡ªåŠ¨åŒ–ç”Ÿæˆçº¦æŸæ¡ä»¶å’Œæ•°æ®é”™è¯¯æ£€æµ‹ï¼Œä¹‹åç”±äººå·¥å®¡æŸ¥å¹¶è°ƒæ•´è¿™äº›è‡ªåŠ¨åŒ–çš„çº¦æŸæ¡ä»¶ï¼Œå¯ä»¥é€šè¿‡åˆ é™¤é—®é¢˜æˆ–ä¿®æ”¹ç½®ä¿¡å¾—åˆ†æ¥å®Œæˆã€‚ä¸ºæ­¤ï¼ŒLLMsï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰æ˜¯éå¸¸å¥½çš„å€™é€‰è€…ï¼ˆå‚è§
    [Jellyfish: A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10)ã€[Can
    language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)
    æˆ– [Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)ï¼‰ã€‚'
- en: The likelihood of certain constraints and violations isnâ€™t always crystal-clear,
    which necessitates a confidence score to account for this uncertainty. Even experts
    might not always agree on specific data issues, so when automation is involved
    in detecting these issues, having an estimated likelihood becomes particularly
    useful.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æŸäº›çº¦æŸæ¡ä»¶å’Œè¿è§„æƒ…å†µçš„å¯èƒ½æ€§å¹¶ä¸æ€»æ˜¯éå¸¸æ˜ç¡®ï¼Œè¿™å°±éœ€è¦ä¸€ä¸ªç½®ä¿¡å¾—åˆ†æ¥è€ƒè™‘è¿™ç§ä¸ç¡®å®šæ€§ã€‚å³ä¾¿æ˜¯ä¸“å®¶ï¼Œå¯¹äºç‰¹å®šçš„æ•°æ®é—®é¢˜ä¹Ÿå¯èƒ½å¹¶ä¸æ€»æ˜¯è¾¾æˆä¸€è‡´ï¼Œå› æ­¤ï¼Œå½“è‡ªåŠ¨åŒ–æŠ€æœ¯è¢«ç”¨äºæ£€æµ‹è¿™äº›é—®é¢˜æ—¶ï¼Œä¼°ç®—çš„å¯èƒ½æ€§å°±æ˜¾å¾—ç‰¹åˆ«æœ‰ç”¨ã€‚
- en: 'What about absent expectations or missed data errors? The effectiveness of
    error detection directly influences the cleanliness score and can lead to an overly
    optimistic value. However, thereâ€™s a counterargument to consider: errors that
    are more difficult to detect, and thus more concealed, might not be as critical
    in their impact on data usability or downstream applications. This suggests that
    such errors should be assigned a lower confidence score when identified as issues,
    reflecting their reduced significance. While this approach may not be without
    its flaws, it serves to limit the influence of these overlooked errors on the
    overall dirtiness score by weighting their importance accordingly.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆå¯¹äºç¼ºå¤±çš„æœŸæœ›æˆ–æ¼æ‰çš„æ•°æ®é”™è¯¯æ€ä¹ˆåŠï¼Ÿé”™è¯¯æ£€æµ‹çš„æœ‰æ•ˆæ€§ç›´æ¥å½±å“æ¸…æ´åº¦å¾—åˆ†ï¼Œå¯èƒ½å¯¼è‡´å¾—åˆ†è¿‡äºä¹è§‚ã€‚ç„¶è€Œï¼Œä¹Ÿæœ‰ä¸€ä¸ªåè®ºç‚¹éœ€è¦è€ƒè™‘ï¼šé‚£äº›æ›´éš¾æ£€æµ‹åˆ°ã€å› æ­¤æ›´éšè”½çš„é”™è¯¯ï¼Œå¯èƒ½å¯¹æ•°æ®å¯ç”¨æ€§æˆ–ä¸‹æ¸¸åº”ç”¨çš„å½±å“å¹¶ä¸é‚£ä¹ˆé‡è¦ã€‚è¿™è¡¨æ˜ï¼Œå½“è¿™äº›é”™è¯¯è¢«è¯†åˆ«ä¸ºé—®é¢˜æ—¶ï¼Œåº”è¯¥èµ‹äºˆè¾ƒä½çš„ç½®ä¿¡åº¦å¾—åˆ†ï¼Œåæ˜ å…¶è¾ƒä½çš„é‡è¦æ€§ã€‚å°½ç®¡è¿™ç§æ–¹æ³•å¹¶éæ²¡æœ‰ç¼ºé™·ï¼Œä½†å®ƒæœ‰åŠ©äºé€šè¿‡ç›¸åº”åœ°åŠ æƒè¿™äº›è¢«å¿½è§†çš„é”™è¯¯çš„é‡è¦æ€§ï¼Œä»è€Œé™åˆ¶å®ƒä»¬å¯¹æ€»ä½“è„æ±¡å¾—åˆ†çš„å½±å“ã€‚
- en: Another aspect to consider is the dynamic nature of the score. Addressing one
    issue could potentially affect other issues, raising questions about how to update
    the score efficiently without much hassle.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªéœ€è¦è€ƒè™‘çš„æ–¹é¢æ˜¯å¾—åˆ†çš„åŠ¨æ€ç‰¹æ€§ã€‚è§£å†³ä¸€ä¸ªé—®é¢˜å¯èƒ½ä¼šå½±å“å…¶ä»–é—®é¢˜ï¼Œè¿™å¼•å‘äº†å¦‚ä½•é«˜æ•ˆæ›´æ–°å¾—åˆ†è€Œä¸äº§ç”Ÿå¤ªå¤šéº»çƒ¦çš„é—®é¢˜ã€‚
- en: Thereâ€™s also the question of whether to include indexes and column names as
    part of the dataset cells when calculating the cleanliness score, as their accuracy
    can also affect the data cleaning process (see for example [Column Type Annotation
    using ChatGPT](https://arxiv.org/abs/2306.00745)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåœ¨è®¡ç®—æ¸…æ´åº¦å¾—åˆ†æ—¶ï¼Œæ˜¯å¦åº”å°†ç´¢å¼•å’Œåˆ—åä½œä¸ºæ•°æ®é›†å•å…ƒçš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä»¬çš„å‡†ç¡®æ€§ä¹Ÿä¼šå½±å“æ•°æ®æ¸…ç†è¿‡ç¨‹ï¼ˆä¾‹å¦‚ï¼Œå‚è§ [ä½¿ç”¨ChatGPTè¿›è¡Œåˆ—ç±»å‹æ ‡æ³¨](https://arxiv.org/abs/2306.00745)ï¼‰ã€‚
- en: Future articles in this series will explore various related topics, including
    a taxonomy of data errors, leveraging LLMs for automated issue detection, and
    strategies for data correction and repair. Stay tuned then!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç³»åˆ—çš„æœªæ¥æ–‡ç« å°†æ¢è®¨ä¸æ­¤ç›¸å…³çš„å„ç§ä¸»é¢˜ï¼ŒåŒ…æ‹¬æ•°æ®é”™è¯¯çš„åˆ†ç±»æ³•ã€åˆ©ç”¨LLMè¿›è¡Œè‡ªåŠ¨åŒ–é—®é¢˜æ£€æµ‹ï¼Œä»¥åŠæ•°æ®ä¿®æ­£å’Œä¿®å¤çš„ç­–ç•¥ã€‚æ•¬è¯·å…³æ³¨ï¼
- en: '-> Link to the 2nd article: [Data Quality Error Detection powered by LLMs](/automated-detection-of-data-quality-issues-54a3cb283a91).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: -> ç¬¬äºŒç¯‡æ–‡ç« é“¾æ¥ï¼š[LLMsé©±åŠ¨çš„æ•°æ®è´¨é‡é”™è¯¯æ£€æµ‹](/automated-detection-of-data-quality-issues-54a3cb283a91)ã€‚
- en: References
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[Can Foundation Models Wrangle Your Data?](https://arxiv.org/abs/2205.09911)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åŸºç¡€æ¨¡å‹èƒ½å¤„ç†ä½ çš„æ•°æ®å—ï¼Ÿ](https://arxiv.org/abs/2205.09911)'
- en: '[Detecting Data Errors: Where are we and what needs to be done?](https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ£€æµ‹æ•°æ®é”™è¯¯ï¼šæˆ‘ä»¬å¤„äºä»€ä¹ˆé˜¶æ®µï¼Œæ¥ä¸‹æ¥éœ€è¦åšä»€ä¹ˆï¼Ÿ](https://cs.uwaterloo.ca/~ilyas/papers/AbedjanVLDB2016.pdf)'
- en: '[Automatic Data Repair: Are We Ready to Deploy?](https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è‡ªåŠ¨åŒ–æ•°æ®ä¿®å¤ï¼šæˆ‘ä»¬å‡†å¤‡å¥½éƒ¨ç½²äº†å—ï¼Ÿ](https://www.semanticscholar.org/reader/5191f08424a3ec0cdaf2b3285860216caca57463)'
- en: '[HoloClean: Holistic Data Repairs with Probabilistic Inference](https://arxiv.org/abs/1702.00820)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HoloCleanï¼šé€šè¿‡æ¦‚ç‡æ¨ç†è¿›è¡Œå…¨å±€æ•°æ®ä¿®å¤](https://arxiv.org/abs/1702.00820)'
- en: '[Tidy Data | Journal of Statistical Software](https://www.jstatsoft.org/article/view/v059i10)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ•´æ´æ•°æ® | ç»Ÿè®¡è½¯ä»¶æœŸåˆŠ](https://www.jstatsoft.org/article/view/v059i10)'
- en: '[How to quantify Data Quality?](/how-to-quantify-data-quality-743721bdba03)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å¦‚ä½•é‡åŒ–æ•°æ®è´¨é‡ï¼Ÿ](/how-to-quantify-data-quality-743721bdba03)'
- en: '[Cleaning Data for Effective Data Science](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æœ‰æ•ˆæ•°æ®ç§‘å­¦çš„æ•°æ®æ¸…ç†](https://github.com/PacktPublishing/Cleaning-Data-for-Effective-Data-Science)'
- en: '[Jellyfish: A Large Language Model for Data Preprocessing](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ°´æ¯ï¼šä¸€ç§ç”¨äºæ•°æ®é¢„å¤„ç†çš„å¤§å‹è¯­è¨€æ¨¡å‹](https://www.semanticscholar.org/reader/7e17ef56273063dfa838de30b7cc0546b2e5ee10)'
- en: '[Can language models automate data wrangling?](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è¯­è¨€æ¨¡å‹èƒ½å¦è‡ªåŠ¨åŒ–æ•°æ®æ•´ç†ï¼Ÿ](http://josephorallo.webs.upv.es/escrits/MLJ-DataWranglingAutomation.pdf)'
- en: '[Large Language Models as Data Preprocessors](https://arxiv.org/abs/2308.16361)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä½œä¸ºæ•°æ®é¢„å¤„ç†å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹](https://arxiv.org/abs/2308.16361)'
- en: '[Column Type Annotation using ChatGPT](https://arxiv.org/abs/2306.00745)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä½¿ç”¨ChatGPTè¿›è¡Œåˆ—ç±»å‹æ ‡æ³¨](https://arxiv.org/abs/2306.00745)'
- en: Score theory
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¾—åˆ†ç†è®º
- en: Letâ€™s dive into the concept of calculating the *Data Dirtiness Score* for a
    dataset, denoted as ğ’Ÿ. This dataset comprises I rows, representing individuals,
    and J columns, representing different variables.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨å¦‚ä½•è®¡ç®—æ•°æ®é›†çš„*æ•°æ®è„æ±¡å¾—åˆ†*ï¼Œè¡¨ç¤ºä¸º ğ’Ÿã€‚è¯¥æ•°æ®é›†åŒ…å« I è¡Œï¼Œä»£è¡¨ä¸ªä½“ï¼Œä»¥åŠ J åˆ—ï¼Œä»£è¡¨ä¸åŒçš„å˜é‡ã€‚
- en: 'We introduce a matrix X, which is of the same dimensions as ğ’Ÿ, with I rows
    and J columns:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥ä¸€ä¸ªä¸ ğ’Ÿ ç»´åº¦ç›¸åŒçš„çŸ©é˜µ Xï¼Œå…·æœ‰ I è¡Œå’Œ J åˆ—ï¼š
- en: '![](../Images/9e7f620081e61c7931d40d94f0cbba78.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e7f620081e61c7931d40d94f0cbba78.png)'
- en: In this matrix, each element X_{ij} follows a Bernoulli distribution with parameter
    Ï€_{ij}. The value of X_{ij} is set to 0 if the cell (i, j) in dataset ğ’Ÿ is free
    from data issues, and 1 if there is an issue, with the probability ğ”¼[X_{ij}] =
    Ï€_{ij} indicating the likelihood of an issue being present.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªçŸ©é˜µä¸­ï¼Œæ¯ä¸ªå…ƒç´  X_{ij} éµå¾ªä¸€ä¸ªå‚æ•°ä¸º Ï€_{ij} çš„ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚å¦‚æœæ•°æ®é›† ğ’Ÿ ä¸­å•å…ƒæ ¼ (i, j) æ²¡æœ‰æ•°æ®é—®é¢˜ï¼Œåˆ™ X_{ij}
    çš„å€¼ä¸º 0ï¼›å¦‚æœæœ‰é—®é¢˜ï¼Œåˆ™ X_{ij} çš„å€¼ä¸º 1ï¼Œæ¦‚ç‡ ğ”¼[X_{ij}] = Ï€_{ij} è¡¨ç¤ºé—®é¢˜å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚
- en: 'Next, we define a random variable Y that represents the proportion of cells
    in ğ’Ÿ that are problematic. The formula for Y is given by:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªéšæœºå˜é‡ Yï¼Œè¡¨ç¤ºæ•°æ®é›† ğ’Ÿ ä¸­å­˜åœ¨é—®é¢˜çš„å•å…ƒæ ¼çš„æ¯”ä¾‹ã€‚Y çš„å…¬å¼å¦‚ä¸‹ï¼š
- en: '![](../Images/5b81b04e0127fadd5e595f155ada72ae.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b81b04e0127fadd5e595f155ada72ae.png)'
- en: 'The *Data Dirtiness Score* is then the expected value of Y:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®è„æ±¡åº¦åˆ†æ•°*æ˜¯ Y çš„æœŸæœ›å€¼ï¼š'
- en: '![](../Images/9751e5fc469f30e2848fb5cde58471e8.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9751e5fc469f30e2848fb5cde58471e8.png)'
- en: 'To connect this back to our earlier discussion, the link between the confidence
    scores for each cellâ€™s data error and the probabilities Ï€_{ij} is captured by
    the following relationship:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å°†æ­¤ä¸æˆ‘ä»¬ä¹‹å‰çš„è®¨è®ºè”ç³»èµ·æ¥ï¼Œæ¯ä¸ªå•å…ƒæ ¼æ•°æ®é”™è¯¯çš„ç½®ä¿¡åº¦åˆ†æ•°ä¸æ¦‚ç‡ Ï€_{ij} ä¹‹é—´çš„å…³ç³»ç”±ä»¥ä¸‹å…¬å¼è¡¨ç¤ºï¼š
- en: '![](../Images/6dd87d19370c09f8103e0cae7236a483.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6dd87d19370c09f8103e0cae7236a483.png)'
- en: This means that the probability of a cell being error-free is calculated as
    the product of the complements of the confidence scores for potential errors in
    that cell.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€ï¼Œå•å…ƒæ ¼æ— é”™è¯¯çš„æ¦‚ç‡æ˜¯é€šè¿‡è¯¥å•å…ƒæ ¼æ½œåœ¨é”™è¯¯çš„ç½®ä¿¡åº¦åˆ†æ•°çš„è¡¥æ•°ç›¸ä¹˜è®¡ç®—å‡ºæ¥çš„ã€‚
- en: If all confidence scores are set to 1, indicating absolute certainty of errors,
    the dirtiness score simplifies to the proportion of cells with errors in the dataset.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‰€æœ‰çš„ç½®ä¿¡åº¦åˆ†æ•°éƒ½è®¾ç½®ä¸º 1ï¼Œè¡¨ç¤ºå¯¹é”™è¯¯çš„ç»å¯¹ç¡®å®šæ€§ï¼Œåˆ™è„æ±¡åº¦åˆ†æ•°ç®€åŒ–ä¸ºæ•°æ®é›†ä¸­æœ‰é”™è¯¯çš„å•å…ƒæ ¼çš„æ¯”ä¾‹ã€‚
- en: 'Calculating the dirtiness score or the cleanliness score for a dataset essentially
    yields the same insight, just from different perspectives. The formula for the
    *Data Cleanliness Score* is simply one minus the *Data Dirtiness Score*:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ•°æ®é›†çš„è„æ±¡åº¦åˆ†æ•°æˆ–æ¸…æ´åº¦åˆ†æ•°æœ¬è´¨ä¸Šç»™å‡ºäº†ç›¸åŒçš„è§è§£ï¼Œåªæ˜¯ä»ä¸åŒçš„è§’åº¦æ¥çœ‹ã€‚*æ•°æ®æ¸…æ´åº¦åˆ†æ•°*çš„å…¬å¼åªæ˜¯ 1 å‡å» *æ•°æ®è„æ±¡åº¦åˆ†æ•°*ï¼š
- en: '![](../Images/b96f59c6e83b5836924288130a2d89f7.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b96f59c6e83b5836924288130a2d89f7.png)'
- en: In this way, a dataset with no errors at all would have a cleanliness score
    of 100% and a dirtiness score of 0%.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå®Œå…¨æ²¡æœ‰é”™è¯¯çš„æ•°æ®é›†å°†å…·æœ‰ 100% çš„æ¸…æ´åº¦åˆ†æ•°å’Œ 0% çš„è„æ±¡åº¦åˆ†æ•°ã€‚
- en: Changes
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å˜æ›´
- en: 'EDIT-2024â€“03â€“21: Convert confidence values to ordinal categories: `low`, `medium`,
    `high`, and `certain`. These represent probabilities of 0.25, 0.5, 0.75, and 1,
    respectively.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–è¾‘-2024â€“03â€“21ï¼šå°†ç½®ä¿¡åº¦å€¼è½¬æ¢ä¸ºåºæ•°ç±»åˆ«ï¼š`ä½`ã€`ä¸­`ã€`é«˜` å’Œ `ç¡®å®š`ã€‚è¿™äº›åˆ†åˆ«è¡¨ç¤ºæ¦‚ç‡ 0.25ã€0.5ã€0.75 å’Œ 1ã€‚
