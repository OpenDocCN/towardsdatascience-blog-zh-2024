- en: Evaluate RAGs Rigorously or Perish
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 严格评估RAG，或者失败
- en: 原文：[https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26](https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26](https://towardsdatascience.com/evaluate-rags-rigorously-or-perish-54f790557357?source=collection_archive---------6-----------------------#2024-04-26)
- en: Use the RAGAs framework with hyperparameter optimization to boost the quality
    of your RAG system.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用RAGAs框架和超参数优化提升你RAG系统的质量。
- en: '[](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)[![Jarek
    Grygolec, Ph.D.](../Images/a7982bd8f5ced5b36d4196f45102e59d.png)](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)
    [Jarek Grygolec, Ph.D.](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)[![Jarek
    Grygolec, Ph.D.](../Images/a7982bd8f5ced5b36d4196f45102e59d.png)](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)
    [Jarek Grygolec, Ph.D.](https://medium.com/@jgrygolec?source=post_page---byline--54f790557357--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)
    ·11 min read·Apr 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--54f790557357--------------------------------)
    ·11分钟阅读·2024年4月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/63cee95bd64080c5b1373fcf47e8460f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63cee95bd64080c5b1373fcf47e8460f.png)'
- en: This is a graphic depicting the idea of “LLMs Evaluating RAGs.” The author generated
    it using AI in Canva.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一幅展示“LLMs评估RAG”的图示。作者使用Canva中的AI生成了该图。
- en: '**TL;DR**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**简而言之**'
- en: If you develop a RAG system, you must choose between different design options.
    The ragas library can help you by generating synthetic evaluation data with answers
    grounded in your documents. This makes possible the rigorous evaluation of a RAG
    system with the classic split between train/validation/test sets, boosting the
    quality of your RAG system.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开发一个RAG系统，你必须在不同的设计选项之间做出选择。ragas库可以通过生成基于你文档的答案的合成评估数据来帮助你。这使得可能对RAG系统进行严格评估，采用经典的训练/验证/测试数据集划分，从而提升RAG系统的质量。
- en: '**Introduction**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**引言**'
- en: The development of a Retrieval Augmented Generation (RAG) system in practice
    involves making many decisions that are consequential for its ultimate quality,
    i.e., about text splitter, chunk size, overlap size, embedding model, metadata
    to store, distance metric for semantic search, top-k to rerank, reranker model,
    top-k to context, prompt engineering, etc.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际操作中，开发一个检索增强生成（RAG）系统需要做出许多决定，这些决定会直接影响其最终质量，例如关于文本分割器、块大小、重叠大小、嵌入模型、存储的元数据、语义搜索的距离度量、用于重排的top-k、重排模型、上下文的top-k、提示工程等。
- en: '**Reality:** In most cases, such decisions are not grounded in methodologically
    sound evaluation practices but rather driven by ad hoc judgments of developers
    and product owners, who often face deadlines.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**现实情况：** 在大多数情况下，这类决策并没有基于方法论上严谨的评估实践，而是由开发人员和产品负责人做出的临时判断，这些人往往面临截止日期的压力。'
- en: '**Gold Standard:** In contrast, the rigorous evaluation of the RAG system should
    involve:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**黄金标准：** 相比之下，RAG系统的严格评估应包括：'
- en: a large evaluation set so that performance metrics are estimated with low confidence
    intervals
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个大型评估集，以便能够以较低的置信区间估算性能指标
- en: diverse questions in an evaluation set
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估集中的多样化问题
- en: answers specific to the internal documents
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对内部文档的特定答案
- en: separate evaluation of retrieval and generation
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索和生成的独立评估
- en: evaluation of the RAG as the whole
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对整个RAG系统的评估
- en: train/validation/test split to ensure good generalization ability
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练/验证/测试数据集划分，以确保良好的泛化能力
- en: hyperparameter optimization
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数优化
- en: Most RAG systems are NOT evaluated rigorously up to the Gold Standard due to
    lack of evaluation sets with answers grounded in the private documents!
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于缺乏基于私有文档的答案评估集，大多数RAG系统未能达到黄金标准进行严格评估！
- en: The generic Large Language Model (LLM) benchmarks (GLUE, SuperGlue, MMLU, BIG-Bench,
    HELM, …) are not of much relevance to evaluate RAGs as the essence of RAGs is
    to extract information from internal documents unknown to LLMs. If you insist
    on using LLM benchmarks for RAG system evaluation, one route would be to select
    the task-specific to your domain and quantify the value added to the RAG system
    on top of the bare-bones LLM for this chosen task.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通用的大型语言模型（LLM）基准（如GLUE、SuperGlue、MMLU、BIG-Bench、HELM等）对于评估RAG系统的相关性不大，因为RAG的本质在于从LLM无法知晓的内部文档中提取信息。如果你坚持使用LLM基准来评估RAG系统，一种方法是选择与你领域特定的任务，并量化在这个选定任务上，RAG系统相较于基础LLM所增加的价值。
- en: The alternative to generic LLM benchmarks is to create human annotated test
    sets based on internal documents, so that the questions require access to these
    internal documents to answer correctly. Such a solution is generally prohibitively
    expensive. In addition, outsourcing annotation may be problematic for internal
    documents, as they are sensitive or contain private information and can’t be shared
    with outside parties.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通用LLM基准的替代方案是基于内部文档创建人工标注的测试集，使得问题的解答需要访问这些内部文档才能正确回答。这种解决方案通常成本高昂。此外，外包标注可能对内部文档造成问题，因为这些文档可能包含敏感或私人信息，不能与外部方共享。
- en: 'Here comes the [RAGAs framework](https://arxiv.org/abs/2309.15217) (Retrieval
    Augmented Generation Assessment) [1] for reference-free RAG evaluation, with Python
    implementation made available in **ragas** package:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是[RAGAs框架](https://arxiv.org/abs/2309.15217)（检索增强生成评估）[1]，用于无参考的RAG评估，并提供了**ragas**包的Python实现：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It provides essential **tools for rigorous RAG evaluation**:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了**严格RAG评估所需的工具**：
- en: generation of synthetic evaluation sets
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成评估集的生成
- en: metrics specialized for RAG evaluation
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专门用于RAG评估的度量标准
- en: prompt adaptation to deal with non-English languages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对非英语语言的提示调整
- en: integration with LangChain and Llama-Index
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与LangChain和Llama-Index的集成
- en: '**Synthetic Evaluation Sets**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成评估集**'
- en: 'The LLM enthusiasts, myself included, suggest using LLM as a solution to many
    problems. Here it means:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LLM爱好者，包括我自己，建议使用LLM作为解决许多问题的方案。这里的意思是：
- en: LLMs are not autonomous, but may be useful. RAGAs employs LLMs to generate synthetic
    evaluation sets to evaluate RAG systems.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LLM并非自主的，但可能是有用的。RAGAs利用LLM生成合成评估集来评估RAG系统。
- en: RAGAs framework follows up on the Evol-Instruct framework, which uses LLM to
    generate a diverse set of instruction data (i.e. Question — Answer pairs, QA)
    in the evolutionary process.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: RAGAs框架继承了Evol-Instruct框架，该框架使用LLM在演化过程中生成多样化的指令数据集（即问题—答案对，QA）。
- en: '![](../Images/b5af66112472251a8a853e06f092dc1a.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5af66112472251a8a853e06f092dc1a.png)'
- en: 'Picture 1: Depicting the evolution of questions in RAGAs. The author created
    this image in Canva and draw.io.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：描绘了RAGAs中问题演化的过程。作者在Canva和draw.io中创建了这张图。
- en: 'In the Evol-Instruct framework, LLM starts with an initial set of simple instructions
    and gradually rewrites them into more complex instructions, creating diverse instruction
    data. Can Xu et al. [2] argue that instruction data''s gradual, incremental evolution
    produces high-quality results. In RAGAs framework, instruction data generated
    and evolved by LLM are grounded in available documents. The ragas library currently
    implements three different types of instruction data evolution by depth, starting
    from the simple question:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在Evol-Instruct框架中，LLM从一组简单的初始指令开始，逐渐将其改写为更复杂的指令，创造多样化的指令数据。Can Xu等人[2]认为，指令数据的逐步、增量演化会产生高质量的结果。在RAGAs框架中，由LLM生成并演化的指令数据是基于现有文档的。ragas库目前实现了三种不同类型的指令数据演化方式，按深度演化，起始于简单问题：
- en: '**Reasoning:** Rewrite the question to increase the need for reasoning.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理：** 重写问题以增加推理的需求。'
- en: '**Conditioning:** Rewrite the question to introduce a conditional element.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件化：** 重写问题以引入一个条件元素。'
- en: '**Multi-Context:** Rewrite the question to require many documents or chunks
    to answer it.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多上下文：** 重写问题，要求多份文档或多个部分来回答。'
- en: In addition, ragas library also provides the option to generate conversations.
    Now, let’s see ragas in practice.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，ragas库还提供了生成对话的选项。现在，让我们来看一下ragas在实践中的应用。
- en: '**Examples of Question Evolutions**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题演化的示例**'
- en: We will use the Wikipedia page on Large Language Models [3] as the source document
    for ragas library to generate question — ground truth pairs, one for each evolution
    type available.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用关于大语言模型 [3] 的 Wikipedia 页面作为 ragas 库生成问题 — 真实答案对的源文档，每种演化类型都有一个问题 — 真实答案对。
- en: 'To ***run the code***: You can follow the code snippets in the article or access
    the notebook with all the related code on Github to run on Colab or locally:'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要***运行代码***：你可以按照文章中的代码片段，或者访问包含所有相关代码的 Github 笔记本，在 Colab 或本地运行：
- en: '[](https://github.com/gox6/colab-demos/blob/main/rags/evaluate-rags-rigorously-or-perish.ipynb?source=post_page-----54f790557357--------------------------------)
    [## colab-demos/rags/evaluate-rags-rigorously-or-perish.ipynb at main · gox6/colab-demos'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/gox6/colab-demos/blob/main/rags/evaluate-rags-rigorously-or-perish.ipynb?source=post_page-----54f790557357--------------------------------)
    [## colab-demos/rags/evaluate-rags-rigorously-or-perish.ipynb at main · gox6/colab-demos'
- en: 'Colab notebooks exploring topics in Data Science and AI, discussed on the blog:
    https://medium.com/@jgrygolec …'
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在博客中讨论的数据科学和人工智能主题的 Colab 笔记本：[https://medium.com/@jgrygolec](https://medium.com/@jgrygolec)
    …
- en: github.com](https://github.com/gox6/colab-demos/blob/main/rags/evaluate-rags-rigorously-or-perish.ipynb?source=post_page-----54f790557357--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/gox6/colab-demos/blob/main/rags/evaluate-rags-rigorously-or-perish.ipynb?source=post_page-----54f790557357--------------------------------)'
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running the above code, I received the following synthetic question — answer
    pairs based on the aforementioned Wikipedia page [3].
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码后，我基于前述的 Wikipedia 页面 [3] 收到了以下合成问答对。
- en: '![](../Images/1783cb7ec307e72fbe43b1371ae8015b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1783cb7ec307e72fbe43b1371ae8015b.png)'
- en: 'Table 1: Synthetic question — answer pairs generated using ragas library and
    GPT-3.5-turbo from the Wikipedia page on LLMs [3].'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：使用 ragas 库和 GPT-3.5-turbo 从 Wikipedia 页面生成的合成问答对 [3]。
- en: The results presented in Table 1 are very appealing. The *simple* evolution
    performs very well. In the case of the reasoning evolution, the first part of
    the question is answered perfectly, but the second part is left unanswered. Inspecting
    the Wikipedia page [3], there is no answer to the second part of the question
    in the document, so it can also be interpreted as the restraint from hallucinations,
    which is good. The *multi-context* question-answer pair seems very good. The conditional
    evolution type is acceptable if we look at the question-answer pair. One way of
    looking at these results is that there is always space for better prompt engineering
    behind evolutions. Another way is to use better LLMs, especially for the critic
    role, as is the default in the ragas library.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1 中展示的结果非常吸引人。*简单*的演化表现得非常好。在推理演化的情况下，问题的第一部分回答得非常完美，但第二部分没有回答。检查 Wikipedia
    页面 [3]，在文档中并没有找到第二部分问题的答案，因此这也可以解读为对幻觉的抑制，这是一个好现象。*多上下文*的问答对似乎也很好。如果我们看问答对，条件演化类型是可以接受的。解读这些结果的一种方式是，演化背后总是有更好的提示工程空间。另一种方式是使用更好的
    LLM，特别是在批评角色方面，正如 ragas 库中默认的那样。
- en: '**Metrics**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**指标**'
- en: The ragas library is able not only to generate the synthetic evaluation sets
    but also provides us with built-in metrics for component-wise evaluation as well
    as end-to-end evaluation of RAGs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ragas 库不仅能够生成合成评估集，还为我们提供了内置的指标，用于按组件评估以及对 RAG 的端到端评估。
- en: '![](../Images/3d5919921c133036f027312376838865.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d5919921c133036f027312376838865.png)'
- en: 'Picture 2: [RAG Evaluation Metrics in RAGAS](https://docs.ragas.io/en/latest/concepts/metrics/index.html).
    Image created by the author in draw.io.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '图片 2: [RAGAS 中的 RAG 评估指标](https://docs.ragas.io/en/latest/concepts/metrics/index.html)。图像由作者在
    draw.io 中创建。'
- en: 'As of this writing, RAGAS provides eight out-of-the-box metrics for RAG evaluation,
    see Picture 2, and likely new ones will be added. You are about to choose the
    metrics most suitable for your use case. However, I recommend to select the one
    most important metric, i.e.:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文撰写时，RAGAS 提供了八种开箱即用的 RAG 评估指标，见图片 2，并且可能会添加新的指标。你将选择最适合你使用场景的指标。不过，我建议选择最重要的一个指标，即：
- en: '***Answer Correctness***— the end-to-end metric with scores between 0 and 1,
    the higher the better, measuring the accuracy of the generated answer as compared
    to the ground truth.'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***答案正确性***— 端到端指标，得分介于 0 到 1 之间，分数越高越好，衡量生成答案与真实答案的准确度。'
- en: 'Focusing on one end-to-end metric helps to start the optimization of your RAG
    system as fast as possible. Once you achieve some improvements in quality, you
    can look at component-wise metrics, focusing on the most important one for each
    RAG component:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于一个端到端的指标有助于尽快开始优化你的RAG系统。一旦你在质量上取得了一些进展，就可以查看各个组件的指标，专注于每个RAG组件最重要的指标：
- en: '***Faithfulness*** — the generation metric with scores between 0 and 1, the
    higher the better, measuring the factual consistency of the generated answer relative
    to the provided context. It is about grounding the generated answer as much as
    possible in the provided context, and by doing so prevent hallucinations.'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***准确性*** — 生成指标，得分范围为0到1，分数越高越好，衡量生成答案相对于提供的上下文的事实一致性。它旨在尽可能多地将生成的答案与提供的上下文相结合，从而防止幻觉生成。'
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Context Relevance*** — the retrieval metric with scores between 0 and 1,
    the higher the better, measuring the relevancy of retrieved context relative to
    the question.'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***上下文相关性*** — 检索指标，得分范围为0到1，得分越高越好，衡量检索到的上下文相对于问题的相关性。'
- en: '**RAG Factory**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG工厂**'
- en: 'OK, so we have a RAG ready for optimisation… not so fast, this is not enough.
    To optimize RAG, we need the factory function to generate RAG chains with a given
    set of RAG hyperparameters. Here, we define this factory function in 2 steps:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，RAG已经准备好进行优化了……但不要太快，这还不够。为了优化RAG，我们需要一个工厂函数来生成具有给定RAG超参数的RAG链。在这里，我们将这个工厂函数分为2个步骤来定义：
- en: '**Step 1**: A function to store documents in the vector database.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1**：一个用于将文档存储到向量数据库中的函数。'
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Step 2:** A function to generate RAG in LangChain with document collection
    or the proper RAG factory function.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2**：一个用于在LangChain中生成RAG的函数，使用文档集合或合适的RAG工厂函数。'
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The former function *get_vectordb_collection* is incorporated into the latterfunction
    *get_chain*, which generates our RAG chain for a given set of parameters, i.e:
    embedding_model, llm_model, chunk_size, overlap_size, top_k, lambda_mult. With
    our factory function, we are just scratching the surface of possibilities of what
    hyperparameters of our RAG system we optimize. Note also that the RAG chain will
    require 2 arguments: *question* and *ground_truth*, where the latter is just passed
    through the RAG chain as required for evaluation using RAGAs.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的函数*get_vectordb_collection*已合并到后者函数*get_chain*中，该函数为给定参数集（即：embedding_model、llm_model、chunk_size、overlap_size、top_k、lambda_mult）生成我们的RAG链。通过我们的工厂函数，我们仅仅触及到优化我们RAG系统超参数的可能性。另请注意，RAG链将需要2个参数：*question*和*ground_truth*，其中后者将作为评估时所需的输入通过RAG链传递。
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**RAG Evaluation**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG评估**'
- en: To evaluate our RAG, we will use the diverse dataset of news articles from CNN
    and Daily Mail, which is available on Hugging Face [4]. Most articles in this
    dataset are below 1000 words. In addition, we will use a tiny extract from the
    dataset of just 100 news articles. This is all done to limit the costs and time
    needed to run the demo.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的RAG，我们将使用来自CNN和Daily Mail的多样化新闻文章数据集，该数据集可在Hugging Face [4] 上获得。该数据集中的大多数文章少于1000字。此外，我们将使用该数据集中的一个小片段，仅包含100篇新闻文章。所有这些都是为了限制运行演示所需的成本和时间。
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As we will consider many different RAG prototypes beyond the one defined above
    we need a function to collect answers generated by the RAG on our synthetic evaluation
    set:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将考虑多个不同的RAG原型，而不仅仅是上面定义的那个，我们需要一个函数来收集RAG在我们的合成评估集上生成的答案：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**RAG Optimisation with RAGAs and Optuna**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG优化与RAGAs和Optuna**'
- en: First, it is worth emphasizing that the proper optimization of the RAG system
    should involve global optimization, where all parameters are optimized simultaneously.
    This is in contrast to the sequential or greedy approach, where parameters are
    optimized one by one. The sequential approach ignores the fact that there can
    be interactions between the parameters, which can result in a sub-optimal solution.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，值得强调的是，RAG系统的适当优化应该涉及全局优化，其中所有参数同时优化。这与顺序或贪婪方法相对立，后者是逐个优化参数。顺序方法忽略了参数之间可能存在的相互作用，而这些相互作用可能导致次优解。
- en: 'Now, we are ready to optimize our RAG system. We will use the hyperparameter
    optimization framework [Optuna](https://optuna.org/). To this end, we define the
    objective function for Optuna’s study, specifying the allowed hyperparameter space
    and computing the evaluation metric. See the code below:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好优化我们的RAG系统。我们将使用超参数优化框架[Optuna](https://optuna.org/)。为此，我们定义Optuna研究的目标函数，指定允许的超参数空间并计算评估指标。请参见下面的代码：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Finally, with the objective function, we define and run the study to optimize
    our RAG system in Optuna. We can add our educated guesses of hyperparameters to
    the study with the method enqueue_trial and limit the study by time or number
    of trials. See [Optuna’s docs](https://optuna.readthedocs.io/en/stable/index.html)
    for more tips.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，利用目标函数，我们定义并运行了一个研究，旨在优化我们的 RAG 系统在 Optuna 中的表现。我们可以通过方法 enqueue_trial 将超参数的预设猜测添加到研究中，并通过时间或试验次数来限制研究的范围。更多技巧请参阅
    [Optuna 的文档](https://optuna.readthedocs.io/en/stable/index.html)。
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In our study, the educated guess wasn’t confirmed, but I’m sure it will get
    better with a rigorous approach like the one proposed above.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，预设猜测没有得到确认，但我相信通过像上述所提到的严谨方法，它会变得更好。
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Limitations of RAGAs**'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAGAs 的局限性**'
- en: 'After experimenting with ragas library to synthesize evaluation sets and evaluate
    RAGs I have some caveats:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试使用 ragas 库来合成评估集并评估 RAG 时，我有一些警告：
- en: The question may contain the answer.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题中可能包含答案。
- en: The ground truth is just the literal excerpt from the document.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准答案仅仅是文档中的字面摘录。
- en: Issues with RateLimitError as well as network overflows on Colab.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Colab 上出现 RateLimitError 问题以及网络溢出问题。
- en: Built-in evolutions are few, and there is no easy way to add new ones.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置的进化功能较少，且没有简单的方法来添加新的进化功能。
- en: There is room for improvement in documentation.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档还有提升的空间。
- en: The first 2 caveats are quality-related. The root cause may be in the LLM used,
    and obviously, GPT-4 gives better results than GPT-3.5-Turbo. At the same time,
    it seems that this could be improved by some prompt engineering for evolutions
    used to generate synthetic evaluation sets.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个警告是与质量相关的。根本原因可能在于使用的 LLM，显然，GPT-4 的结果优于 GPT-3.5-Turbo。同时，似乎通过对生成合成评估集所用进化的提示工程，能够改善这一点。
- en: For issues with rate-limiting and network overflows, it is advisable to use
    1) checkpointing during the generation of synthetic evaluation sets to prevent
    loss of created data and 2) exponential backoff to ensure you complete the whole
    task.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于速率限制和网络溢出问题，建议使用 1) 在生成合成评估集时进行检查点保存，以防丢失已创建的数据，和 2) 指数退避，以确保你能够完成整个任务。
- en: Finally, and most importantly, more built-in evolutions would be a welcome addition
    to the ragas package, not to mention the possibility of creating custom evolutions
    more easily.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，也是最重要的，更多的内置进化功能将是 ragas 包的一个受欢迎的补充，更不用说能够更容易地创建自定义进化功能的可能性。
- en: '**Other Useful Features of RAGAs**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAGAs 的其他有用功能**'
- en: '**Custom Prompts.** The Ragas package allows you to change the prompts in the
    provided abstractions. The docs describe an example of custom prompts for metrics
    in the evaluation task.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义提示。** Ragas 包允许你修改提供的抽象中的提示。文档中描述了评估任务中度量的自定义提示示例。'
- en: '**Automatic Language Adaptation.** RAGAs has you covered for non-English languages.
    It has a great feature called automatic language adaptation supporting RAG evaluation
    in the languages other than English, see the docs for more info.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动语言适应。** RAGAs 支持非英语语言的 RAG 评估，具有一个非常棒的功能——自动语言适应。更多信息请查看文档。'
- en: '**Conclusions**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**结论**'
- en: 'Despite RAGAs limitations, do NOT miss the most important thing:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 RAGAs 存在局限性，但不要忽视最重要的事情：
- en: RAGAs is already very useful tool despite its young age. It enables generation
    of synthetic evaluation set for rigorous RAG evaluation, a critical aspect for
    successful RAG development.
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管 RAGAs 是一个年轻的工具，但它已经非常有用了。它能够生成合成评估集，用于严格的 RAG 评估，这是成功开发 RAG 系统的关键方面。
- en: '**Please clap i**f you enjoyed this reading. I invite You to look at[**my other
    articles**](https://medium.com/@jgrygolec) and[**f**](https://medium.com/@jgrygolec/about)**ollow**
    me to get my new content.'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**如果你喜欢这篇文章，请鼓掌**。我邀请你查看[**我的其他文章**](https://medium.com/@jgrygolec)并[**关注**](https://medium.com/@jgrygolec/about)**我，以便获取我的新内容**。'
- en: '**Acknowledgments**'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**致谢**'
- en: 'This project & article would be impossible if I didn’t stand on the shoulders
    of giants. It is impossible to mention all influences, but the following were
    directly related:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我没有站在巨人的肩膀上，这个项目和文章是无法完成的。尽管不可能列举所有的影响，但以下几位与本研究直接相关：
- en: '[1] S. Es, J. James, L. Espinosa-Anke, S. Schockaert, RAGAS: Automated Evaluation
    of Retrieval Augmented Generation (2023), [arXiv:2309.15217](https://arxiv.org/abs/2309.15217)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] S. Es, J. James, L. Espinosa-Anke, S. Schockaert, RAGAS: 自动化评估检索增强生成 (2023),
    [arXiv:2309.15217](https://arxiv.org/abs/2309.15217)'
- en: '[2] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, D. Jiang, WizardLM:
    Empowering Large Language Models to Follow Complex Instructions (2023), [arXiv:2304.12244](https://arxiv.org/abs/2304.12244)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, D. Jiang, WizardLM：赋能大型语言模型以执行复杂指令（2023），[arXiv:2304.12244](https://arxiv.org/abs/2304.12244)'
- en: '[3] Community, Large Language Models, Wikipedia (2024), [https://en.wikipedia.org/wiki/Large_language_model](https://en.wikipedia.org/wiki/Large_language_model)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Community, Large Language Models, 维基百科（2024），[https://en.wikipedia.org/wiki/Large_language_model](https://en.wikipedia.org/wiki/Large_language_model)'
- en: '[4] CNN & Daily Mail Dataset available on Hugging Face, for more info, see:
    [https://huggingface.co/datasets/cnn_dailymail](https://huggingface.co/datasets/cnn_dailymail)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] CNN 和 Daily Mail 数据集可在 Hugging Face 上获取，更多信息请见：[https://huggingface.co/datasets/cnn_dailymail](https://huggingface.co/datasets/cnn_dailymail)'
