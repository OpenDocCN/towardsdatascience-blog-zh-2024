- en: Making LLMs Write Better and Better Code for Self-Driving Using LangProp
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LangProp让LLM写出越来越好的自动驾驶代码
- en: 原文：[https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25](https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25](https://towardsdatascience.com/making-llms-write-better-and-better-code-for-self-driving-using-langprop-99c6c3dc9508?source=collection_archive---------4-----------------------#2024-06-25)
- en: 'Analogy from classical machine learning: LLM (Large Language Model) = optimizer;
    code = parameters; LangProp = PyTorch Lightning'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来自经典机器学习的类比：LLM（大语言模型）= 优化器；代码 = 参数；LangProp = PyTorch Lightning
- en: '[](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Shu
    Ishida](../Images/3c2d6092188ab1e0427e63cd0f1fada6.png)](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    [Shu Ishida](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Shu
    Ishida](../Images/3c2d6092188ab1e0427e63cd0f1fada6.png)](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    [Shu Ishida](https://alacreme.medium.com/?source=post_page---byline--99c6c3dc9508--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    ·9 min read·Jun 25, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99c6c3dc9508--------------------------------)
    ·阅读时间：9分钟·2024年6月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: You have probably used ChatGPT to write your emails, summarize documents, find
    out information, or help you debug your code. But can we take a step further and
    make ChatGPT drive a car?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经使用ChatGPT来写电子邮件、总结文档、查找信息，或帮助调试代码。但我们能否更进一步，让ChatGPT来开车呢？
- en: This was the question we wanted to answer when I started my internship at [Wayve](https://wayve.ai/)
    in March last year. Wayve is an autonomous driving startup in London, applying
    end-to-end learning to the challenging problem of urban driving. At the time,
    the company was just about to launch its LLM research team, which has since successfully
    developed [LINGO-1](https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/?doing_wp_cron=1718832390.6593759059906005859375)
    and [LINGO-2](https://wayve.ai/thinking/lingo-2-driving-with-language/). [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
    had just come out, and [Voyager](https://github.com/MineDojo/Voyager) had not
    come out yet. And yet, the disruption caused by LLMs was palpable. The question
    was, how can we use this new technology to driving, a domain where language isn’t
    the main modality?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在去年3月开始在[Wayve](https://wayve.ai/)实习时想要回答的问题。Wayve是位于伦敦的自动驾驶创业公司，致力于将端到端学习应用于城市驾驶这一挑战性问题。当时，公司正要成立其LLM研究团队，并成功开发了[LINGO-1](https://wayve.ai/thinking/lingo-natural-language-autonomous-driving/?doing_wp_cron=1718832390.6593759059906005859375)和[LINGO-2](https://wayve.ai/thinking/lingo-2-driving-with-language/)。[AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)刚刚发布，[Voyager](https://github.com/MineDojo/Voyager)还没有发布。而LLM带来的变革已显而易见。问题是，如何将这项新技术应用于驾驶这一领域——一个语言不是主要模态的领域？
- en: In this blog post, I would like to give an overview of our paper [**LangProp**](https://arxiv.org/abs/2401.10314),
    which we presented at the LLM Agents workshop at ICLR (the International Conference
    on Learning Representations) last month (May 2024).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我想概述一下我们在上个月（2024年5月）在ICLR（国际学习表示会议）上的LLM代理研讨会中展示的论文[**LangProp**](https://arxiv.org/abs/2401.10314)。
- en: '[](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [## GitHub - shuishida/LangProp'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [## GitHub - shuishida/LangProp'
- en: Contribute to shuishida/LangProp development by creating an account on GitHub.
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在GitHub上创建账户，参与shuishida/LangProp的开发。
- en: 'github.com](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)
    [## LangProp: A code optimization framework using Large Language Models applied
    to driving'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/shuishida/LangProp?source=post_page-----99c6c3dc9508--------------------------------)
    [](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)
    [## LangProp：一个使用大型语言模型应用于驾驶的代码优化框架'
- en: We propose LangProp, a framework for iteratively optimizing code generated by
    large language models (LLMs), in both…
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们提出了LangProp，一个框架，用于迭代优化由大型语言模型（LLM）生成的代码，涵盖…
- en: arxiv.org](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2401.10314?source=post_page-----99c6c3dc9508--------------------------------)'
- en: 'Motivation: Let’s apply ML to code writing, literally.'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机：让我们将机器学习应用到代码编写中，字面意义上。
- en: 'The challenge of applying LLMs to driving comes in twofold: firstly, LLMs are,
    as the name says, very large models that require a lot of compute and can be slow
    to run, which makes them not-so-ideal for safety-critical real-time applications,
    such as autonomous driving; secondly, while language is good at high-level descriptions
    and serves as a sophisticated tool for logic, reasoning and planning, it doesn’t
    have the granularity and detail that is needed to describe observations and give
    spatial control actions.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM应用于驾驶的挑战有两方面：首先，正如名字所示，LLM是非常庞大的模型，需要大量计算资源，运行速度较慢，这使得它们不太适合用于安全关键的实时应用，例如自动驾驶；其次，虽然语言在高层次的描述中很有用，是逻辑、推理和规划的复杂工具，但它缺乏描述观察结果和给出空间控制动作所需的细节和粒度。
- en: We realised, however, that we don’t necessarily have to use LLMs for inferring
    driving actions. What we could do instead is to make LLMs write the code for driving
    itself.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们意识到，我们不一定非得使用LLM来推断驾驶动作。我们可以做的是让LLM编写驾驶的代码。
- en: If you have ever used ChatGPT to write code then this may sound like a terrible
    idea. The code that it writes seldom works out of the box, and often contains
    some errors. But what if we use LLMs to also detect bugs and automatically fix
    them, thereby iteratively improving the code quality?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经使用ChatGPT编写过代码，那么这听起来可能是个糟糕的主意。它编写的代码很少能直接使用，并且经常包含一些错误。但如果我们让LLM也检测错误并自动修复它们，从而迭代改进代码质量，会怎样呢？
- en: We took this idea a step further — instead of just fixing bugs, we designed
    a training framework that allows us to improve the code that the LLM generates
    towards an objective function of your choice. You can “train” your code to improve
    on a training dataset and try to reduce the losses. The code improvements can
    be quantified by running it on a validation dataset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个想法更进一步——不仅仅是修复错误，我们设计了一个训练框架，让我们能够根据你选择的目标函数改进大语言模型（LLM）生成的代码。你可以“训练”你的代码，通过训练数据集的优化来尝试减少损失。代码的改进可以通过在验证数据集上运行来量化。
- en: Does this start to sound like Machine Learning? Because it essentially is! But
    are we fine-tuning the LLM? No — in fact, there is no neural network that is being
    fine-tuned. Instead, we are fine-tuning the code itself!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这开始听起来像是机器学习了吗？因为它本质上就是！但我们在微调LLM吗？不——事实上，并没有神经网络正在进行微调。相反，我们是在微调代码本身！
- en: In LangProp, the “code” is the *parameters* of the model, and the LLM is the
    *optimizer* that guides the *parameters* to improve in the direction that reduces
    the loss. Why is this cool? Because by applying this thinking, we can now automate
    optimization of software themselves in a data-driven way! With deep learning,
    we witnessed the power of data-driven approaches to solving hard-to-describe problems.
    But so far, the application domain of machine learning has been constrained to
    models parametrized by numeric values. Now, they can deal with systems described
    in code, too.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangProp中，“代码”是模型的*参数*，而LLM是*优化器*，引导*参数*朝着减少损失的方向改进。这为什么酷呢？因为通过应用这种思维，我们现在可以以数据驱动的方式自动优化软件本身！通过深度学习，我们见证了数据驱动方法解决难以描述问题的强大能力。但到目前为止，机器学习的应用领域仅限于通过数值值参数化的模型。现在，它们也能够处理通过代码描述的系统了。
- en: If you have followed the history of Artificial Intelligence, this is an elegant
    way to unify the once popular approach of Symbolic AI with the more modern and
    successful Machine Learning approach. Symbolic AI was about having human experts
    describe a perfect model of the world in the form of logic and code. This had
    its limitations, as many complex tasks (e.g. object recognition) were beyond what
    human experts can feasibly describe with logic alone. Machine Learning, on the
    other hand, lets the data speak for itself and fits a model that best describes
    them in an automated way. This approach has been very successful in a wide range
    of disciplines, including pattern recognition, compression and function approximation.
    However, logic, reasoning, and long-term planning are fields where naively fitting
    a neural network on data often fails. This is because it is challenging to learn
    such complex operations in the modality of neural network parameter space. With
    LLMs and LangProp, we can finally apply the data-driven learning method to learn
    symbolic systems and automate their improvement.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您关注过人工智能的历史，这是一种优雅的方式，将曾经流行的符号人工智能方法与更现代、更成功的机器学习方法统一起来。符号人工智能的核心是让人类专家用逻辑和代码描述一个完美的世界模型。这种方法存在局限性，因为许多复杂任务（例如物体识别）超出了人类专家仅凭逻辑描述的能力。而机器学习则让数据本身发声，并以自动化的方式拟合出最能描述它们的模型。这种方法在包括模式识别、压缩和函数逼近等多个领域取得了巨大的成功。然而，逻辑、推理和长期规划是通过简单地在数据上拟合神经网络往往失败的领域。这是因为在神经网络参数空间中学习如此复杂的操作是具有挑战性的。通过LLMs和LangProp，我们最终可以应用数据驱动的学习方法来学习符号系统并自动化其改进。
- en: Disclaimer
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 免责声明
- en: Before we dive in further, I feel that some disclaimers are in order.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入之前，我觉得有必要做一些免责声明。
- en: This work on LangProp was conducted as an internship project at Wayve, and does
    not directly reflect the company’s Research & Development priorities or strategies.
    The purpose of this blog post is to describe LangProp as a paper, and everything
    in this blog post is written in the capacity of myself as an individual.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本项关于LangProp的工作是在Wayve作为实习项目进行的，并不直接反映该公司在研究与开发方面的优先级或战略。本博文的目的是描述LangProp作为一篇论文，所有内容均以个人身份撰写。
- en: While we demonstrated LangProp primarily for the case of autonomous driving,
    we also would like to stress its limitations, such as (a) it requires perfect
    observation of the environment, (b) we only made it work in a simulated environment
    and it is far from real-world deployment, (c) the generated driving code is not
    perfect nor sophisticated, and has many issues to be suitable for real-world deployment.
    We see LangProp as a research prototype that showcases the potential of LLMs applied
    to data-driven software optimization, not as a product for deployment.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然我们主要展示了LangProp在自动驾驶领域的应用，但我们也想强调其局限性，例如：（a）它要求对环境有完美的观察，（b）我们只在模拟环境中实现了它，距离实际部署还很远，（c）生成的驾驶代码既不完美也不复杂，并且存在许多问题，无法适应现实世界的部署。我们视LangProp为一个研究原型，展示了LLMs应用于数据驱动软件优化的潜力，而非可用于部署的产品。
- en: If you need further information on the limitations of LangProp, please check
    out the limitation section in the appendix of [our paper](https://arxiv.org/abs/2401.10314).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要更多关于LangProp局限性的信息，请查看[我们论文](https://arxiv.org/abs/2401.10314)附录中的局限性部分。
- en: With that said, let’s take a look at how LangProp works!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们来看看LangProp是如何工作的！
- en: How does LangProp work?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangProp是如何工作的？
- en: …we bring back Symbolic AI and Evolutionary Algorithms
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: …我们重新引入符号人工智能和进化算法
- en: '![](../Images/c4ff0907157b6d125d5dc66f17ebb19b.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4ff0907157b6d125d5dc66f17ebb19b.png)'
- en: An overview of the LangProp trainer. The LLM generates variations of code, which
    is then evaluated on the training dataset. Codes with high scores are kept. The
    LLM is provided with information about the failure modes of the code and rewrites
    them to achieve higher performance on the training metric. (image by the author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp训练器概述。LLM生成代码的变体，然后在训练数据集上进行评估。得分高的代码将被保留。LLM会提供关于代码失败模式的信息，并重写代码以在训练指标上实现更高的性能。（图像由作者提供）
- en: LangProp is designed like PyTorch Lightning — a LangProp module keeps track
    of the *parameters* (collection of scripts) that are trained and used for inference.
    In the training mode, a policy tracker keeps a record of the inputs, outputs,
    and any exceptions during the forward pass. The performance of the code is evaluated
    by an objective function. Based on the scores, the policy tracker re-ranks the
    scripts that currently exist, and passes the top k scripts to the LLM for refinement.
    At inference time, making a prediction is as simple as calling the code with the
    best score.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp 的设计类似于 PyTorch Lightning —— 一个 LangProp 模块跟踪被训练和用于推理的*参数*（脚本集合）。在训练模式下，一个策略跟踪器记录前向传递过程中的输入、输出以及任何异常情况。代码的性能通过目标函数进行评估。根据得分，策略跟踪器重新排序当前存在的脚本，并将前
    k 个脚本传递给 LLM 进行优化。在推理时，做出预测就像调用得分最高的代码一样简单。
- en: The LangProp trainer takes a LangProp module to be trained, a training dataset,
    and a validation dataset. The dataset can be any iterable object, including a
    PyTorch Dataset object, which makes applying LangProp to existing tasks easier.
    Once the training is finished, we can save a *checkpoint*, which is the collection
    of refined code along with some statistics for ranking the code.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp 训练器需要一个要训练的 LangProp 模块，一个训练数据集和一个验证数据集。数据集可以是任何可迭代对象，包括 PyTorch 数据集对象，这使得将
    LangProp 应用于现有任务更加容易。训练完成后，我们可以保存一个*检查点*，即经过优化的代码集合以及一些用于排名代码的统计信息。
- en: The mechanism we use to choose the best code and improve them is similar to
    evolutionary algorithms, in which samples are initially chosen randomly, but then
    the ones that are high-performing are kept and perturbed to spawn a new generation
    of fitter samples.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来选择最佳代码并改进它们的机制类似于进化算法，其中样本最初是随机选择的，但性能较高的样本会被保留，并经过扰动生成适应性更强的新一代样本。
- en: Applying LangProp to driving
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 LangProp 应用于驾驶
- en: '![](../Images/33980cea1ea0f6899272c51db1fe4d39.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33980cea1ea0f6899272c51db1fe4d39.png)'
- en: Overview of the LangProp driving agent in CARLA (image by the author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp 驾驶代理在 CARLA 中的概述（图片来自作者）
- en: Now let’s try using LangProp to drive in CARLA!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试使用 LangProp 在 CARLA 中进行驾驶！
- en: '[CARLA](https://carla.org/) is an open-sourced driving simulator used for autonomous
    driving research. There is a [leaderboard challenge](https://leaderboard.carla.org/)
    to benchmark your self-driving car agent. We tested LangProp on the standard routes
    and towns in this challenge.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[CARLA](https://carla.org/) 是一个开源的驾驶模拟器，用于自动驾驶研究。这里有一个[排行榜挑战](https://leaderboard.carla.org/)，可以对你的自动驾驶车辆代理进行基准测试。我们在此挑战的标准路线和城镇上测试了
    LangProp。'
- en: The good thing about formulating LangProp as a Machine Learning framework is
    that, now we can apply not just classic supervised learning but also imitation
    learning and reinforcement learning techniques.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将 LangProp 作为机器学习框架进行构思的好处在于，现在我们不仅可以应用经典的监督学习，还可以应用模仿学习和强化学习技术。
- en: Specifically, we start our training on an offline dataset (driving demonstrations
    from an expert that contains state and action pairs), and then perform online
    rollouts. During online rollout, we employ DAgger [1], which is a dataset aggregation
    technique where samples collected by online rollouts are labelled with expert
    labels and aggregated with the current dataset.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们首先在离线数据集上开始训练（包含专家驾驶演示的状态和动作对），然后进行在线回合。在在线回合过程中，我们采用 DAgger [1]，这是一种数据集聚合技术，在这种技术中，通过在线回合收集的样本会被标记上专家标签，并与当前数据集进行合并。
- en: The input to the model (the code) is a Python dictionary of the state of the
    environment, including the poses and velocities of the vehicle and surrounding
    actors, and the distances to the traffic light / stop sign. The output is the
    driving action, which is the speed and steering angle at which the vehicle should
    drive.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输入（代码）是一个包含环境状态的 Python 字典，包括车辆及周围角色的姿势和速度，以及与红绿灯/停车标志的距离。输出是驾驶动作，即车辆应以何种速度和转向角度行驶。
- en: Whenever there is an infraction, e.g. ignoring a traffic light or stop sign,
    collision with another vehicle, pedestrian or cyclist, or being stationary for
    too long, there is a penality to the performance scores. The training objective
    is to maximize the combined score of imitation learning scores (how well can the
    agent match the ground truth action labels) and the reinforcement learning scores
    (reducing the infraction penalty).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每当发生违规行为时，例如忽视交通信号灯或停车标志、与其他车辆、行人或骑行者发生碰撞，或停留过久，性能得分将受到惩罚。训练目标是最大化模仿学习得分（即代理如何与真实的动作标签匹配）和强化学习得分（减少违规惩罚）之和。
- en: LangProp driving agent in action
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangProp 驾驶代理正在执行任务
- en: Now watch the LangProp agent drive!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在观看 LangProp 代理的驾驶过程！
- en: A LangProp agent driving in CARLA, a driving simulation benchmark (video by
    the author)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp 代理在 CARLA 中的驾驶，一种驾驶仿真基准测试（视频由作者提供）
- en: We saw during training that, the initial driving policy that ChatGPT generates
    is very faulty. In particular, it often learns a naive policy that copies the
    previous velocity. This is a well-known phenomenon called causal confusion [2]
    in the field of imitation learning. If we just train with behavioral cloning on
    the offline dataset, such naive but simple policies obtain a high score compared
    to other more complex policies. This is why we need to use techniques such as
    DAgger and reinforcement learning to make sure that the policy performs in online
    rollout.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练过程中观察到，ChatGPT 生成的初始驾驶策略非常有缺陷。特别是，它经常学习到一种天真的策略，即复制之前的速度。这是模仿学习领域中一个著名的现象，叫做因果混淆
    [2]。如果我们仅仅在离线数据集上进行行为克隆训练，这种天真但简单的策略相比其他更复杂的策略会获得较高的分数。这也是为什么我们需要使用像 DAgger 和强化学习这样的技术，以确保策略能够在在线部署中有效。
- en: After an iteration or two, the model stops copying the previous velocity and
    starts moving forward, but is either overly cautious (i.e. stops whenever there
    is an actor nearby, even if they are not in collision course), or reckless (driving
    forward until it collides into an actor). After a couple more iterations, the
    model learns to keep a distance from the vehicle in front and even calculates
    this distance dynamically based on the relative velocities of the vehicles. It
    also predicts whether other actors (e.g. J-walking pedestrians) are on collision
    course with the vehicle by looking at the velocity and position vectors.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行了一两次迭代后，模型停止了复制之前的速度，并开始向前行驶，但要么过于谨慎（即每当附近有演员时就停下，即使他们没有与车辆发生碰撞的可能），要么鲁莽（一直向前行驶直到与演员发生碰撞）。经过几次迭代后，模型学会了保持与前方车辆的距离，并根据车辆之间的相对速度动态计算这个距离。它还通过观察速度和位置向量来预测其他演员（例如过马路的行人）是否与车辆处于碰撞轨迹上。
- en: In the experiments in [our paper](https://arxiv.org/abs/2401.10314), we show
    that the LangProp driving agent outperforms many of the previously implemented
    driving agents. We compare against both a PPO expert agent (Carla-Roach [3], TCP
    [4]) and researcher-implemented expert agents (TransFuser [5], InterFuser [6],
    TF++ [7]), and LangProp outperformed all expert agents except for TF++. All the
    expert agents were published after the GPT 3.5 training cutoff of September 2021,
    so this result is both surprising and exciting!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们论文中的实验 [我们的论文](https://arxiv.org/abs/2401.10314) 中，我们展示了 LangProp 驾驶代理超越了许多先前实现的驾驶代理。我们与
    PPO 专家代理（Carla-Roach [3], TCP [4]）和研究人员实现的专家代理（TransFuser [5], InterFuser [6],
    TF++ [7]）进行了比较，LangProp 超越了除了 TF++ 之外的所有专家代理。所有专家代理的发布都发生在 GPT 3.5 训练截止日期 2021
    年 9 月之后，因此这一结果既令人惊讶又令人兴奋！
- en: Closing remark
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: Thank you for joining me on the ride! While in this work we primarily explored
    the application of LangProp to autonomous driving in CARLA, we also showed that
    LangProp can be easily applied to more general problems, such as the typical RL
    environment of CartPole-v1\. LangProp works best in environments or problems where
    feedback on the performance can be obtained in the form of text or code, giving
    the model a richer semantic signal that is more than just numerical scores.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你与我一起体验这段旅程！虽然在这项工作中，我们主要探索了 LangProp 在 CARLA 中的自动驾驶应用，但我们也展示了 LangProp 可以轻松应用于更广泛的问题，例如典型的强化学习环境
    CartPole-v1。LangProp 在能够通过文本或代码的形式获得性能反馈的环境或问题中表现最佳，这为模型提供了更丰富的语义信号，而不仅仅是数字评分。
- en: There are endless possible applications of LangProp-like training to iteratively
    improve software based on data, and we are excited to see what will happen in
    this space!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LangProp 类似的训练方法在基于数据的迭代改进软件方面有无尽的应用前景，我们非常期待这个领域的未来发展！
- en: 'If you liked our work, please consider building on top of it and citing our
    paper:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢我们的工作，请考虑在此基础上进行构建并引用我们的论文：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: References
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Stéphane Ross, Geoffrey Gordon, and Drew Bagnell. “A reduction of imitation
    learning and structured prediction to no-regret online learning.” In *Proceedings
    of the fourteenth international conference on artificial intelligence and statistics*,
    *JMLR Workshop and Conference Proceedings*, 2011.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Stéphane Ross, Geoffrey Gordon, 和 Drew Bagnell. “将模仿学习和结构化预测简化为无悔在线学习。”
    在 *第十四届国际人工智能与统计会议论文集*，*JMLR工作坊与会议论文集*，2011年。'
- en: '[2] Pim De Haan, Dinesh Jayaraman, and Sergey Levine. “Causal confusion in
    imitation learning”. *Advances in Neural Information Processing Systems*, 2019.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Pim De Haan, Dinesh Jayaraman, 和 Sergey Levine. “模仿学习中的因果混淆。” *神经信息处理系统进展*，2019年。'
- en: '[3] Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, and Luc Van Gool.
    “End-to-end urban driving by imitating a reinforcement learning coach.” In P*roceedings
    of the IEEE/CVF international Conference on Computer Vision*, pp. 15222–15232,
    2021.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu, 和 Luc Van Gool.
    “通过模仿强化学习教练进行端到端城市驾驶。” 在 *IEEE/CVF国际计算机视觉会议论文集*，pp. 15222–15232，2021年。'
- en: '[4] Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, and Yu Qiao.
    “Trajectory-guided control prediction for end-to-end autonomous driving: A simple
    yet strong baseline.” *Advances in Neural Information Processing Systems*, 35:6119–6132,
    2022.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, 和 Yu Qiao.
    “基于轨迹引导的端到端自动驾驶控制预测：一个简单而强大的基准。” *神经信息处理系统进展*，35:6119–6132，2022年。'
- en: '[5] Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz,
    and Andreas Geiger. “Transfuser: Imitation with transformer-based sensor fusion
    for autonomous driving.” *IEEE Transactions on Pattern Analysis and Machine Intelligence*,
    2022.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu, Katrin Renz,
    和 Andreas Geiger. “Transfuser: 基于变换器的传感器融合模仿用于自动驾驶。” *IEEE模式分析与机器智能学报*，2022年。'
- en: '[6] Hao Shao, Letian Wang, Ruobing Chen, Hongsheng Li, and Yu Liu. “Safety-enhanced
    autonomous driving using interpretable sensor fusion transformer.” In *Conference
    on Robot Learning*, pp. 726–737\. PMLR, 2023.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Hao Shao, Letian Wang, Ruobing Chen, Hongsheng Li, 和 Yu Liu. “使用可解释的传感器融合变换器增强安全性的自动驾驶。”
    在 *机器人学习会议* 上，pp. 726–737。PMLR，2023年。'
- en: '[7] Jaeger, Bernhard, Kashyap Chitta, and Andreas Geiger. “Hidden biases of
    end-to-end driving models.” *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*. 2023.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Jaeger, Bernhard, Kashyap Chitta, 和 Andreas Geiger. “端到端驾驶模型的隐藏偏差。” *IEEE/CVF国际计算机视觉会议论文集*，2023年。'
