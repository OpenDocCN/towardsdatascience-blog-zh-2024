- en: 'TensorFlow Transform: Ensuring Seamless Data Preparation in Production'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Transform：确保生产中的数据准备无缝进行
- en: 原文：[https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08](https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08](https://towardsdatascience.com/tensorflow-transform-ensuring-seamless-data-preparation-in-production-99ffcf49f535?source=collection_archive---------7-----------------------#2024-07-08)
- en: Leveraging TensorFlow Transform for scaling data pipelines for production environments
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用TensorFlow Transform来扩展生产环境中的数据管道
- en: '[](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)[![Akila
    Somasundaram](../Images/5f3c58de8057c9c7ef42f6f5729fb395.png)](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)
    [Akila Somasundaram](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)[![Akila
    Somasundaram](../Images/5f3c58de8057c9c7ef42f6f5729fb395.png)](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)
    [Akila Somasundaram](https://medium.com/@akila29?source=post_page---byline--99ffcf49f535--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)
    ·10 min read·Jul 8, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--99ffcf49f535--------------------------------)
    ·阅读时长10分钟·2024年7月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/95b3c8120fb4d55756d5e7eb9f7f8d50.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/95b3c8120fb4d55756d5e7eb9f7f8d50.png)'
- en: Photo by [Suzanne D. Williams](https://unsplash.com/@scw1217?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Suzanne D. Williams](https://unsplash.com/@scw1217?utm_source=medium&utm_medium=referral)
    在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Data pre-processing is one of the major steps in any Machine Learning pipeline.
    Tensorflow Transform helps us achieve it in a distributed environment over a huge
    dataset.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理是任何机器学习管道中的主要步骤之一。TensorFlow Transform帮助我们在分布式环境中处理庞大的数据集。
- en: 'Before going further into Data Transformation, Data Validation is the first
    step of the production pipeline process, which has been covered in my article
    [Validating Data in a Production Pipeline: The TFX Way](https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce).
    Have a look at this article to gain better understanding of this article.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨数据转换之前，数据验证是生产管道过程的第一步，我在我的文章[生产管道中的数据验证：TFX方式](https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce)中已经讲解过。请阅读这篇文章，以便更好地理解本文内容。
- en: I have used Colab for this demo, as it is much easier (and faster) to configure
    the environment. If you are in the exploration phase, I would recommend Colab
    as well, as it would help you concentrate on the more important things.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这个演示中使用了Colab，因为它配置环境更简单（且更快）。如果你正处于探索阶段，我也建议使用Colab，因为它能帮助你专注于更重要的内容。
- en: ML Pipeline operations begins with data ingestion and validation, followed by
    transformation. The transformed data is trained and deployed. I have covered the
    validation part in my earlier [article](https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce),
    and now we will be covering the transformation section. To get a better understanding
    of pipelines in Tensorflow, have a look at the below article.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道操作从数据摄取和验证开始，然后是数据转换。转换后的数据进行训练并部署。我在之前的[文章](https://medium.com/towards-data-science/validating-data-in-a-production-pipeline-the-tfx-way-9770311eb7ce)中已经讲解了验证部分，现在我们将讨论数据转换部分。为了更好地理解TensorFlow中的管道，请查看下面的文章。
- en: '[](https://www.tensorflow.org/tfx?source=post_page-----99ffcf49f535--------------------------------)
    [## TFX | ML Production Pipelines | TensorFlow'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.tensorflow.org/tfx?source=post_page-----99ffcf49f535--------------------------------)
    [## TFX | 机器学习生产管道 | TensorFlow'
- en: Build and manage end-to-end production ML pipelines. TFX components enable scalable,
    high-performance data processing…
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建和管理端到端的生产级机器学习管道。TFX 组件支持可扩展的、高性能的数据处理……
- en: www.tensorflow.org](https://www.tensorflow.org/tfx?source=post_page-----99ffcf49f535--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.tensorflow.org](https://www.tensorflow.org/tfx?source=post_page-----99ffcf49f535--------------------------------)'
- en: As established earlier, we will be using Colab. So we just need to install the
    tfx library and we are good to go.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用 Colab。所以我们只需要安装 tfx 库，就可以开始了。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After installation restart the session to proceed.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 安装完成后，重启会话以继续。
- en: '![](../Images/9e7831e0446e0018e3319cf4a224a3cd.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e7831e0446e0018e3319cf4a224a3cd.png)'
- en: Next come the imports.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是导入部分。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We will be using the spaceship titanic dataset from Kaggle, as in the data validation
    article. This dataset is free to use for commercial and non-commercial purposes.
    You can access it from [here](https://www.kaggle.com/competitions/spaceship-titanic).
    A description of the dataset is shown in the below figure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自 Kaggle 的太空船泰坦尼克数据集，如数据验证文章中所示。该数据集可以用于商业和非商业目的，且免费使用。你可以从[这里](https://www.kaggle.com/competitions/spaceship-titanic)访问它。数据集的描述见下图。
- en: '![](../Images/b7f72d9f83df9040e86e6d07ea33beac.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7f72d9f83df9040e86e6d07ea33beac.png)'
- en: In order to begin with the data transformation part, it is recommended to create
    folders where the pipeline components would be placed (else they will be placed
    in the default directory). I have created two folders, one for the pipeline components
    and the other for our training data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始数据转换部分，建议创建文件夹来存放管道组件（否则它们将被放置在默认目录中）。我创建了两个文件夹，一个用于管道组件，另一个用于我们的训练数据。
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we create the InteractiveContext, and pass the path to the pipeline directory.
    This process also creates a sqlite database for storing the metadata of the pipeline
    process.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建 InteractiveContext，并传递管道目录的路径。此过程还会创建一个 sqlite 数据库，用于存储管道过程的元数据。
- en: InteractiveContext is meant for exploring each stage of the process. At each
    point, we can have a view of the artifacts that are created. When in a production
    environment, we will ideally be using a pipeline creation framework like Apache
    Beam, where this entire process will be executed automatically, without intervention.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: InteractiveContext 用于探索流程的每个阶段。在每个阶段，我们可以查看所创建的工件。在生产环境中，我们理想的做法是使用像 Apache
    Beam 这样的管道创建框架，在该框架中，整个过程会自动执行，无需人工干预。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we start with data ingestion. If your data is stored as a csv file, we
    can use CsvExampleGen, and pass the path to the directory where the data files
    are stored.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始数据导入。如果你的数据存储为 csv 文件，我们可以使用 CsvExampleGen，并传递数据文件所在目录的路径。
- en: Make sure the folder contains only the training data and nothing else. If your
    training data is divided into multiple files, ensure they have the same header.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 确保文件夹中只包含训练数据，且没有其他内容。如果你的训练数据分为多个文件，请确保它们具有相同的标题。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: TFX currently supports csv, tf.Record, BigQuery and some custom executors. More
    about it in the below link.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: TFX 当前支持 csv、tf.Record、BigQuery 和一些自定义执行器。更多信息请参见以下链接。
- en: '[](https://www.tensorflow.org/tfx/guide/examplegen?source=post_page-----99ffcf49f535--------------------------------)
    [## The ExampleGen TFX Pipeline Component | TensorFlow'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.tensorflow.org/tfx/guide/examplegen?source=post_page-----99ffcf49f535--------------------------------)
    [## ExampleGen TFX 管道组件 | TensorFlow'
- en: The ExampleGen TFX Pipeline component ingests data into TFX pipelines. It consumes
    external files/services to generate…
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ExampleGen TFX 管道组件将数据导入 TFX 管道。它使用外部文件/服务生成……
- en: www.tensorflow.org](https://www.tensorflow.org/tfx/guide/examplegen?source=post_page-----99ffcf49f535--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.tensorflow.org](https://www.tensorflow.org/tfx/guide/examplegen?source=post_page-----99ffcf49f535--------------------------------)'
- en: To execute the ExampleGen component, use context.run.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 ExampleGen 组件，使用 context.run。
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After running the component, this will be our output. It provides the execution_id,
    component details and where the component’s outputs are saved.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行组件后，这将是我们的输出。它提供了执行 ID、组件详情以及组件输出保存的位置。
- en: '![](../Images/f0b4d3c3cf0fc4c129d54772f83d7180.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0b4d3c3cf0fc4c129d54772f83d7180.png)'
- en: On expanding, we should be able to see these details.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 展开后，我们应该能够看到这些详情。
- en: '![](../Images/49e56a8f1feee2d880ff89ff157e3530.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49e56a8f1feee2d880ff89ff157e3530.png)'
- en: The directory structure looks like the below image. All these artifacts have
    been created for us by TFX. They are automatically versioned as well, and the
    details are stored in metadata.sqlite. The sqlite file helps maintain data provenance
    or data lineage.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 目录结构如下图所示。所有这些工件都是由TFX为我们创建的，它们也会自动进行版本控制，详细信息存储在metadata.sqlite中。sqlite文件有助于维护数据来源或数据血统。
- en: '![](../Images/2cb0dfd4007f0e3b58d2557279ec9744.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cb0dfd4007f0e3b58d2557279ec9744.png)'
- en: To explore these artifacts programatically, use the below code.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要以编程方式探索这些工件，可以使用以下代码。
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output would be the name of the files and the uri.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是文件名和uri。
- en: '![](../Images/26670b069b3c950fdfe9b6c7e8b2bb55.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26670b069b3c950fdfe9b6c7e8b2bb55.png)'
- en: Let us copy the train uri and have a look at the details inside the file. The
    file is stored as a zip file and is stored in TFRecordDataset format.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们复制训练的uri，并查看文件中的详细信息。该文件以zip格式存储，并以TFRecordDataset格式存储。
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The below code is obtained from Tensorflow, it is the standard code that can
    be used to pick up records from TFRecordDataset and returns the results for us
    to examine.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码来自Tensorflow，这是一个标准代码，可以用来从TFRecordDataset中获取记录，并返回供我们检查的结果。
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We requested for 3 records, and the output looks like this. Every record and
    its metadata are stored in dictionary format.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们请求了3条记录，输出如下。每条记录及其元数据都以字典格式存储。
- en: '![](../Images/3e08f502cbd1f52b2f642b0b57efee07.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e08f502cbd1f52b2f642b0b57efee07.png)'
- en: Next, we move ahead to the subsequent process, which is to generate the statistics
    for the data using StatisticsGen. We pass the outputs from the example_gen object
    as the argument.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们进入下一个步骤，即使用StatisticsGen生成数据的统计信息。我们将example_gen对象的输出作为参数传递。
- en: We execute the component using statistics.run, with statistics_gen as the argument.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用statistics.run来执行组件，并将statistics_gen作为参数。
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We can use context.show to view the results.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用context.show来查看结果。
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can see that it is very similar to the statistics generation that we have
    discussed in the TFDV article. The reason is, TFX uses TFDV under the hood to
    perform these operations. Getting familiar with TFDV will help understand these
    processes better.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，这与我们在TFDV文章中讨论的统计生成非常相似。原因是，TFX在底层使用TFDV来执行这些操作。熟悉TFDV有助于更好地理解这些过程。
- en: '![](../Images/ae1ebef42a6b57be00552e36e651e490.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae1ebef42a6b57be00552e36e651e490.png)'
- en: Next step is to create the schema. This is done using the SchemaGen by passing
    the statistics_gen object. Run the component and visualize it using context.show.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建schema。这是通过使用SchemaGen并传递statistics_gen对象来完成的。运行组件并使用context.show来可视化它。
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The output shows details about the underlying schema of the data. Again, same
    as in TFDV.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了数据底层模式的详细信息。同样，这与TFDV中的内容类似。
- en: '![](../Images/1f0aa75e2731fff473b691354d3683a7.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f0aa75e2731fff473b691354d3683a7.png)'
- en: If you need to make modifications to the schema presented here, make them using
    tfdv, and create a schema file. You can pass it using the ImportSchemaGen and
    ask tfx to use the new file.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要修改这里提供的schema，请使用tfdv进行修改，并创建一个schema文件。你可以通过ImportSchemaGen传递它，并要求tfx使用新文件。
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, we validate the examples using the ExampleValidator. We pass the statistics_gen
    and schema_gen as arguments.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用ExampleValidator来验证示例。我们将statistics_gen和schema_gen作为参数传递。
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This should be your ideal output to show that all is well.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该是你的理想输出，以显示一切正常。
- en: '![](../Images/c53b89c5ea10cc197c14f557d20ba447.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c53b89c5ea10cc197c14f557d20ba447.png)'
- en: At this point, our directory structure looks like the below image. We can see
    that for every step in the process, the corresponding artifacts are created.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们的目录结构如下图所示。我们可以看到，在每个过程步骤中，都会创建相应的工件。
- en: '![](../Images/764a04c84ebe42ad48477cbab52d717c.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/764a04c84ebe42ad48477cbab52d717c.png)'
- en: Let us move to the actual transformation part. We will now create the constants.py
    file to add all the constants that are required for the process.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入实际的转换部分。我们现在将创建constants.py文件，以添加处理过程中所需的所有常量。
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We will create all the constants and write it to the constants.py file. See
    the “%%writefile {_constants_module_file}”, this command does not let the code
    run, instead, it writes all the code in the given cell into the specified file.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建所有常量并写入constants.py文件。请看“%%writefile {_constants_module_file}”，此命令并不会让代码运行，而是将给定单元格中的所有代码写入指定的文件。
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Let us create the transform.py file, which will contain the actual code for
    transforming the data.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建transform.py文件，其中将包含用于转换数据的实际代码。
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, we will be using the tensorflow_transform library. The code for transformation
    process will be written under the preprocessing_fn function. It is mandatory we
    use the same name, as tfx internally searches for it during the transformation
    process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用tensorflow_transform库。变换过程的代码将在preprocessing_fn函数下编写。我们必须使用相同的名称，因为tfx在变换过程中会在内部查找它。
- en: '[PRE18]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have used a few standard scaling and encoding functions for this demo. The
    transform library actually hosts a whole lot of functions. Explore them here.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个演示中使用了一些标准的缩放和编码函数。实际上，变换库包含了许多函数，可以在这里探索它们。
- en: '[](https://www.tensorflow.org/tfx/transform/api_docs/python/tft?source=post_page-----99ffcf49f535--------------------------------)
    [## Module: tft | TFX | TensorFlow'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.tensorflow.org/tfx/transform/api_docs/python/tft?source=post_page-----99ffcf49f535--------------------------------)
    [## 模块：tft | TFX | TensorFlow'
- en: Init module for TF.Transform.
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TF.Transform的初始化模块。
- en: www.tensorflow.org](https://www.tensorflow.org/tfx/transform/api_docs/python/tft?source=post_page-----99ffcf49f535--------------------------------)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: www.tensorflow.org](https://www.tensorflow.org/tfx/transform/api_docs/python/tft?source=post_page-----99ffcf49f535--------------------------------)
- en: Now it is time to see the transformation process in action. We create a Transform
    object, and pass example_gen and schema_gen objects, along with the path to the
    transform.py we created.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候查看变换过程的实际操作了。我们创建一个Transform对象，并传入example_gen和schema_gen对象，以及我们创建的transform.py文件的路径。
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Run it and the transformation part is complete!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 运行它，变换部分就完成了！
- en: Take a look at the transformed data shown in the below image.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面图像中显示的变换数据。
- en: '![](../Images/1303ef6e4514391c58823b9c199134b4.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1303ef6e4514391c58823b9c199134b4.png)'
- en: Why not just use scikit-learn library or pandas to do this?
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么不直接使用scikit-learn库或pandas来做这些？
- en: This is your question now, right?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你现在的问题，对吧？
- en: This process is not meant for an individual wanting to preprocess their data
    and get going with model training. It is meant to be applied on large amounts
    of data (data that mandates distributed processing) and an automated production
    pipeline that can’t afford to break.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程并不适用于想要预处理数据并开始训练模型的个人用户。它是为大规模数据（需要分布式处理的数据）和无法中断的自动化生产管道而设计的。
- en: After applying the transform, your folder structure looks like this
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 应用变换后，你的文件夹结构如下所示：
- en: '![](../Images/605cd1b6d460c9c789304a9f8bd56bc8.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/605cd1b6d460c9c789304a9f8bd56bc8.png)'
- en: It contains pre and post transform details. Further, a transform graph is also
    created.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 它包含了变换前后的详细信息。此外，还创建了一个变换图。
- en: Remember, we scaled our numerical features using tft.scale_to_0_1\. Functions
    like this requires computing details that require analysis of the entire data
    (like the mean, minimum and maximum values in a feature). Analyzing data distributed
    over multiple machines, to get these details is performance intensive (especially
    if done multiple times). Such details are calculated once and maintained in the
    transform_graph. Any time a function needs them, it is directly fetched from the
    transform_graph. It also aids in applying transforms created during the training
    phase directly to serving data, ensuring consistency in the pre-processing phase.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们使用tft.scale_to_0_1对数值特征进行了缩放。像这样的函数需要计算一些细节，这些细节需要分析整个数据（例如特征的均值、最小值和最大值）。分析分布在多台机器上的数据以获取这些细节是性能密集型的（特别是如果多次执行时）。这些细节只会计算一次，并保存在transform_graph中。任何时候一个函数需要它们时，它都会直接从transform_graph中获取。这还有助于将训练阶段创建的变换直接应用于服务数据，确保预处理阶段的一致性。
- en: Another major advantage is of using Tensorflow Transform libraries is that every
    phase is recorded as artifacts, hence data lineage is maintained. Data Versioning
    is also automatically done when the data changes. Hence it makes experimentation,
    deployment and rollback easy in a production environment.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Tensorflow Transform库的另一个主要优势是，每个阶段都会被记录为工件，从而保持数据的血缘关系。当数据发生变化时，数据版本控制也会自动进行。因此，它使得在生产环境中进行实验、部署和回滚变得更加容易。
- en: That’s all to it. If you have any questions please jot them down in the comments
    section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。如果你有任何问题，请在评论区写下来。
- en: You can download the notebook and the data files used in this article from my
    GitHub repository using this [link](https://github.com/akila29/TF_Transform_Demo)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从我的GitHub仓库下载本文章中使用的笔记本和数据文件，点击这个[链接](https://github.com/akila29/TF_Transform_Demo)。
- en: What Next?
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来做什么？
- en: To get a better understanding of the pipeline components, read the below article.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 若想更好地理解管道组件，请阅读以下文章。
- en: '[](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?source=post_page-----99ffcf49f535--------------------------------)
    [## Understanding TFX Pipelines | TensorFlow'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?source=post_page-----99ffcf49f535--------------------------------)
    [## 了解 TFX 流水线 | TensorFlow'
- en: MLOps is the practice of applying DevOps practices to help automate, manage,
    and audit machine learning (ML) workflows…
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLOps 是将 DevOps 实践应用于机器学习（ML）工作流的实践，旨在帮助自动化、管理和审计机器学习工作流…
- en: www.tensorflow.org](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?source=post_page-----99ffcf49f535--------------------------------)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.tensorflow.org](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?source=post_page-----99ffcf49f535--------------------------------)'
- en: Thanks for reading my article. If you like it, please encourage by giving me
    a few claps, and if you are in the other end of the spectrum, let me know what
    can be improved in the comments. Ciao.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读我的文章。如果你喜欢它，请通过给我一些掌声来鼓励我；如果你有不同的看法，欢迎在评论中告诉我有哪些可以改进的地方。再见。
- en: Unless otherwise noted, all images are by the author.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供。
