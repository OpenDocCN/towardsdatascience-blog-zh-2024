- en: 'Mamba: SSM, Theory, and Implementation in Keras and TensorFlow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mambaï¼šSSMã€ç†è®ºåŠåœ¨Keraså’ŒTensorFlowä¸­çš„å®ç°
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546?source=collection_archive---------0-----------------------#2024-03-17](https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546?source=collection_archive---------0-----------------------#2024-03-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546?source=collection_archive---------0-----------------------#2024-03-17](https://towardsdatascience.com/mamba-ssm-theory-and-implementation-in-keras-and-tensorflow-32d6d4b32546?source=collection_archive---------0-----------------------#2024-03-17)
- en: Understanding how SSMs and Mamba work, along with how to get started with implementing
    it in Keras and TensorFlow.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äº†è§£SSMå’ŒMambaçš„å·¥ä½œåŸç†ï¼Œå¹¶å­¦ä¹ å¦‚ä½•å¼€å§‹åœ¨Keraså’ŒTensorFlowä¸­å®ç°å®ƒã€‚
- en: '[](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)[![Vedant
    Jumle](../Images/363dbdf8564c35060b3e57cbc6e55f16.png)](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)
    [Vedant Jumle](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)[![Vedant
    Jumle](../Images/363dbdf8564c35060b3e57cbc6e55f16.png)](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)
    [Vedant Jumle](https://medium.com/@vedantjumle?source=post_page---byline--32d6d4b32546--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)
    Â·13 min readÂ·Mar 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--32d6d4b32546--------------------------------)
    Â·é˜…è¯»æ—¶é—´13åˆ†é’ŸÂ·2024å¹´3æœˆ17æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2eef43d26c512f0bea0c67ca675348ef.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2eef43d26c512f0bea0c67ca675348ef.png)'
- en: 'Source: AI Generate (SDXL)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æºï¼šAIç”Ÿæˆï¼ˆSDXLï¼‰
- en: 'Submitted on 1st December, 2023 on arXiv, the paper titled [â€œMamba: Linear-Time
    Sequence Modeling with Selective State Spacesâ€](https://arxiv.org/abs/2312.00752)
    proposed an interesting approach to sequence modeling. The authors â€” [Albert Gu](https://arxiv.org/search/cs?searchtype=author&query=Gu%2C+A),
    [Tri Dao](https://arxiv.org/search/cs?searchtype=author&query=Dao%2C+T) â€” introduced,
    â€˜Mambaâ€™ that utilized â€˜selectiveâ€™ [state space models (SSM)](https://en.wikipedia.org/wiki/State-space_representation)
    to achieve results that compete with the performance of the, now ubiquitous, Transformer
    model.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¿™ç¯‡é¢˜ä¸º[â€œMamba: çº¿æ€§æ—¶é—´åºåˆ—å»ºæ¨¡ä¸é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´â€](https://arxiv.org/abs/2312.00752)çš„è®ºæ–‡äº2023å¹´12æœˆ1æ—¥æäº¤è‡³arXivï¼Œæå‡ºäº†ä¸€ç§æœ‰è¶£çš„åºåˆ—å»ºæ¨¡æ–¹æ³•ã€‚ä½œè€…ä»¬â€”â€”[Albert
    Gu](https://arxiv.org/search/cs?searchtype=author&query=Gu%2C+A)ã€[Tri Dao](https://arxiv.org/search/cs?searchtype=author&query=Dao%2C+T)â€”â€”ä»‹ç»äº†â€œMambaâ€æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨â€œé€‰æ‹©æ€§â€[çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰](https://en.wikipedia.org/wiki/State-space_representation)ï¼Œå–å¾—äº†ä¸å½“å‰æ— å¤„ä¸åœ¨çš„Transformeræ¨¡å‹æ€§èƒ½ç›¸åª²ç¾çš„æˆæœã€‚'
- en: Whatâ€™s so unique about Mamba?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mambaæœ‰ä»€ä¹ˆç‹¬ç‰¹ä¹‹å¤„ï¼Ÿ
- en: Transformers have seen recent popularity with the rise of Large Language Models
    (LLMs) like LLaMa-2, GPT-4, Claude, Gemini, etc., but it suffers from the problem
    of context window. The issue with transformers lies in itâ€™s core, the multi head-attention
    mechanism.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚LLaMa-2ã€GPT-4ã€Claudeã€Geminiç­‰çš„å´›èµ·ï¼ŒTransformerè¿‘å¹´æ¥å˜å¾—éå¸¸æµè¡Œï¼Œä½†å®ƒä¹Ÿé¢ä¸´ä¸Šä¸‹æ–‡çª—å£é—®é¢˜ã€‚Transformerçš„é—®é¢˜æ ¹æºåœ¨äºå…¶æ ¸å¿ƒçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚
- en: '*The main issue with multi-head attention sprouts from the fact that for input
    sequence length n, the time complexity and space complexity scales by O(nÂ²). This
    limits the length of the context window of an LLM. Because, to increase it by
    10x, we need to scale the hardware requirement (most notably GPU VRAM) by 100x.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¤šå¤´æ³¨æ„åŠ›çš„ä¸»è¦é—®é¢˜æºäºè¿™æ ·ä¸€ä¸ªäº‹å®ï¼šå¯¹äºè¾“å…¥åºåˆ—é•¿åº¦nï¼Œæ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦æŒ‰O(nÂ²)æ¯”ä¾‹å¢é•¿ã€‚è¿™é™åˆ¶äº†LLMçš„ä¸Šä¸‹æ–‡çª—å£é•¿åº¦ã€‚å› ä¸ºï¼Œè¦å°†å…¶å¢åŠ 10å€ï¼Œæˆ‘ä»¬éœ€è¦å°†ç¡¬ä»¶è¦æ±‚ï¼ˆå°¤å…¶æ˜¯GPU
    VRAMï¼‰å¢åŠ 100å€ã€‚*'
- en: Mamba, on the other hand, scales by ***O(n)!, i.e., Linearly****.*
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼ŒMambaçš„æ‰©å±•æŒ‰***O(n)!, å³çº¿æ€§***æ¯”ä¾‹å¢é•¿ã€‚
- en: '![](../Images/b097aae23543115f103cea34510def5e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b097aae23543115f103cea34510def5e.png)'
- en: Plot taken from the Mamba paper comparing FlashAttention and Mamba approach
    (indicated by scan(ours) in the legends)[1]
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å›¾æ‘˜è‡ªMambaè®ºæ–‡ï¼Œæ¯”è¾ƒäº†FlashAttentionå’ŒMambaæ–¹æ³•ï¼ˆåœ¨å›¾ä¾‹ä¸­ç”±scan(ours)æ ‡å‡ºï¼‰[1]
- en: This linear scaling is what has taken wind for researchers to speculate that
    Mamba might be the future of sequence modeling.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§çº¿æ€§ç¼©æ”¾å·²å¼•å‘ç ”ç©¶äººå‘˜çš„çŒœæµ‹ï¼Œå³Mambaå¯èƒ½æ˜¯åºåˆ—å»ºæ¨¡çš„æœªæ¥ã€‚
- en: 'The backbone of Mamba: State Space Models'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mambaçš„æ ¸å¿ƒï¼šçŠ¶æ€ç©ºé—´æ¨¡å‹
- en: The core of the Mamba model comes from the concept of State Space Models. ***State
    Space Models, like Transformers and RNN, process sequences of information, like
    text, audio signals, video frames, DNA sequences, etc.***
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Mambaæ¨¡å‹çš„æ ¸å¿ƒæ¥è‡ªäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ¦‚å¿µã€‚***çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œå¦‚Transformerså’ŒRNNï¼Œå¤„ç†ä¿¡æ¯åºåˆ—ï¼Œå¦‚æ–‡æœ¬ã€éŸ³é¢‘ä¿¡å·ã€è§†é¢‘å¸§ã€DNAåºåˆ—ç­‰ã€‚***
- en: 'State Space Models come from an idea of describing a physical system as a set
    of input, outputs, and variables. These variables are: *A, B, C, D.* The process
    of SSM involves calculation of an *internal state vector h(t), given an input
    x(t).* Then, we do a weighted sum of *h(t)* and *x(t)* where the weights are *A,
    B, C, & D*. In the simplest form (continuous time-invariant), the process formulation
    looks like:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: çŠ¶æ€ç©ºé—´æ¨¡å‹æ¥æºäºå°†ç‰©ç†ç³»ç»Ÿæè¿°ä¸ºä¸€ç»„è¾“å…¥ã€è¾“å‡ºå’Œå˜é‡çš„æ€æƒ³ã€‚è¿™äº›å˜é‡åŒ…æ‹¬ï¼š*Aã€Bã€Cã€D*ã€‚SSMçš„è¿‡ç¨‹æ¶‰åŠè®¡ç®—ç»™å®šè¾“å…¥x(t)çš„*å†…éƒ¨çŠ¶æ€å‘é‡h(t)*ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯¹*h(t)*å’Œ*x(t)*è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå…¶ä¸­æƒé‡ä¸º*Aã€Bã€Cå’ŒD*ã€‚åœ¨æœ€ç®€å•çš„å½¢å¼ï¼ˆè¿ç»­æ—¶é—´ä¸å˜ï¼‰ä¸‹ï¼Œè¿‡ç¨‹å…¬å¼å¦‚ä¸‹ï¼š
- en: '![](../Images/ebbbac8cb1eb8abaa8dbb62853c93240.png)![](../Images/047a1d371405fee92bb7ea7c58305c58.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebbbac8cb1eb8abaa8dbb62853c93240.png)![](../Images/047a1d371405fee92bb7ea7c58305c58.png)'
- en: 'source: wikipedia[6]'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æºï¼šwikipedia[6]
- en: '*h(t)* is often called the â€˜hiddenâ€™ or the â€˜latentâ€™ state, I will be sticking
    to calling it the â€˜hiddenâ€™ state for better clarity. **It is important to note
    that A, B, C, and D are learnt parameters in SSM.**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*h(t)*é€šå¸¸è¢«ç§°ä¸ºâ€œéšè—â€çŠ¶æ€æˆ–â€œæ½œåœ¨â€çŠ¶æ€ï¼Œä¸ºäº†æ›´æ¸…æ™°èµ·è§ï¼Œæˆ‘å°†åšæŒç§°å…¶ä¸ºâ€œéšè—â€çŠ¶æ€ã€‚**é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼ŒAã€Bã€Cå’ŒDæ˜¯SSMä¸­çš„å­¦ä¹ å‚æ•°ã€‚**'
- en: What are the variables?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å˜é‡æ˜¯ä»€ä¹ˆï¼Ÿ
- en: '**The variables, A, B, C & D, are learnt parameters,** and they can be described
    as:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**å˜é‡Aã€Bã€Cå’ŒDæ˜¯å­¦ä¹ å¾—åˆ°çš„å‚æ•°ï¼Œ** å®ƒä»¬å¯ä»¥æè¿°ä¸ºï¼š'
- en: 'A: How much should the previous hidden state (h) be considered to calculate
    the new hidden state'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aï¼šåœ¨è®¡ç®—æ–°çš„éšè—çŠ¶æ€æ—¶ï¼Œåº”è¯¥è€ƒè™‘å¤šå°‘å‰ä¸€ä¸ªéšè—çŠ¶æ€ï¼ˆhï¼‰ã€‚
- en: 'B: How much should the input (x) be consider to calculate the new hidden state.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bï¼šåœ¨è®¡ç®—æ–°çš„éšè—çŠ¶æ€æ—¶ï¼Œè¾“å…¥ï¼ˆxï¼‰åº”è€ƒè™‘å¤šå°‘ã€‚
- en: 'C: How much should the new hidden state be considered in calculating the output
    (y).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cï¼šåœ¨è®¡ç®—è¾“å‡ºï¼ˆyï¼‰æ—¶ï¼Œæ–°çš„éšè—çŠ¶æ€åº”è€ƒè™‘å¤šå°‘ã€‚
- en: 'D: How much should the input (x) be consider in calculating the output (y).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dï¼šåœ¨è®¡ç®—è¾“å‡ºï¼ˆyï¼‰æ—¶ï¼Œè¾“å…¥ï¼ˆxï¼‰åº”è€ƒè™‘å¤šå°‘ã€‚
- en: D comes in the end of the computations and does not affect how the hidden state
    is calculated. Hence, it is usually considered outside of ssm, and can be thought
    of as a skip connection.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Då‡ºç°åœ¨è®¡ç®—çš„æœ€åï¼Œå¹¶ä¸”ä¸å½±å“å¦‚ä½•è®¡ç®—éšè—çŠ¶æ€ã€‚å› æ­¤ï¼Œé€šå¸¸è®¤ä¸ºå®ƒåœ¨SSMä¹‹å¤–ï¼Œå¹¶ä¸”å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªè·³è·ƒè¿æ¥ã€‚
- en: Going from continuous spaces to discrete spaces
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»è¿ç»­ç©ºé—´åˆ°ç¦»æ•£ç©ºé—´çš„è½¬å˜
- en: The above formulation applies to a system where the input and output belong
    to a continuous space. But in cases, like language modeling, where the input and
    output belong to discrete spaces (token values in a vocabulary). Also, finding
    *h(t)* is analytically challenging. This can be achieved by performing a ***Zero-order
    hold***.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°å…¬å¼é€‚ç”¨äºè¾“å…¥å’Œè¾“å‡ºå±äºè¿ç»­ç©ºé—´çš„ç³»ç»Ÿã€‚ä½†åœ¨è¯¸å¦‚è¯­è¨€å»ºæ¨¡ç­‰æƒ…å†µä¸­ï¼Œè¾“å…¥å’Œè¾“å‡ºå±äºç¦»æ•£ç©ºé—´ï¼ˆè¯æ±‡è¡¨ä¸­çš„æ ‡è®°å€¼ï¼‰ã€‚æ­¤å¤–ï¼Œæ±‚è§£*h(t)*åœ¨è§£æä¸Šå…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™å¯ä»¥é€šè¿‡æ‰§è¡Œ***é›¶é˜¶ä¿æŒ***æ¥å®ç°ã€‚
- en: In a zero-order hold, every time an input is received, the model holds its value
    till the next input is received. This leads to a continuous input space.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é›¶é˜¶ä¿æŒä¸­ï¼Œæ¯æ¬¡æ¥æ”¶åˆ°è¾“å…¥æ—¶ï¼Œæ¨¡å‹ä¼šä¿æŒå…¶å€¼ç›´åˆ°æ¥æ”¶åˆ°ä¸‹ä¸€ä¸ªè¾“å…¥ã€‚è¿™å¯¼è‡´äº†ä¸€ä¸ªè¿ç»­çš„è¾“å…¥ç©ºé—´ã€‚
- en: '![](../Images/236f0dcd1ee1294b2e8064560a582f29.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/236f0dcd1ee1294b2e8064560a582f29.png)'
- en: How Zero order hold works
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶é˜¶ä¿æŒå¦‚ä½•å·¥ä½œ
- en: This length of â€˜holdâ€™ is determined by a new parameter called, *step size* ***âˆ†.
    It can be thought of as the resolution of the input.*** Ideally, âˆ† should be infinitesimal.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªâ€œä¿æŒâ€é•¿åº¦ç”±ä¸€ä¸ªæ–°çš„å‚æ•°å†³å®šï¼Œç§°ä¸º*æ­¥é•¿* ***âˆ†ã€‚å®ƒå¯ä»¥è¢«è§†ä¸ºè¾“å…¥çš„åˆ†è¾¨ç‡ã€‚*** ç†æƒ³æƒ…å†µä¸‹ï¼Œâˆ†åº”ä¸ºæ— ç©·å°ã€‚
- en: 'Mathematically, Zero-order hold can be described as:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ•°å­¦ä¸Šè®²ï¼Œé›¶é˜¶ä¿æŒå¯ä»¥æè¿°ä¸ºï¼š
- en: '![](../Images/3f6f0258965a22d4970d1e76a3cf457a.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f6f0258965a22d4970d1e76a3cf457a.png)'
- en: 'Finally, we can create a discrete SSM, as:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç¦»æ•£çš„SSMï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/dc4b655375a46584a07aed40155d829d.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4b655375a46584a07aed40155d829d.png)'
- en: 'Since, D is used with a skip connection outside of SSM, the output can be reduced
    to:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºDä¸SSMå¤–çš„è·³è·ƒè¿æ¥ä¸€èµ·ä½¿ç”¨ï¼Œè¾“å‡ºå¯ä»¥ç®€åŒ–ä¸ºï¼š
- en: '![](../Images/de141e5ed6870e82fe9f71fe77beb074.png)![](../Images/71c4d16a62a57ecd5732def8f4b79143.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de141e5ed6870e82fe9f71fe77beb074.png)![](../Images/71c4d16a62a57ecd5732def8f4b79143.png)'
- en: Involvement of DX(t) is considered as a skip connection, hence is goes from
    outside of SSM
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: DX(t) çš„æ¶‰åŠè¢«è§†ä¸ºè·³è·ƒè¿æ¥ï¼Œå› æ­¤å®ƒæ¥è‡ª SSM ä¹‹å¤–ã€‚
- en: SSM and recurrence
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SSM å’Œé€’å½’
- en: In SSMs, the hidden state is carried over to when the next input is received.
    This is similar to how Recurrent Neural Networks function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ SSM ä¸­ï¼Œéšè—çŠ¶æ€ä¼šè¢«ä¼ é€’åˆ°æ¥æ”¶åˆ°ä¸‹ä¸€ä¸ªè¾“å…¥æ—¶ã€‚è¿™ç±»ä¼¼äºé€’å½’ç¥ç»ç½‘ç»œçš„å·¥ä½œæ–¹å¼ã€‚
- en: '![](../Images/96f22333a7a3f5bd2ba29b117eef421f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96f22333a7a3f5bd2ba29b117eef421f.png)'
- en: Comparison of RNN and SSM
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: RNN å’Œ SSM çš„æ¯”è¾ƒ
- en: This recurrent format of SSM can be unwrapped, just like RNNs. But unlike RNNs,
    which are iterative and slow, SSM can process the input sequence in parallel (just
    like transformers) and this makes the training processes faster.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ SSM çš„é€’å½’æ ¼å¼å¯ä»¥åƒ RNN ä¸€æ ·å±•å¼€ã€‚ä½†ä¸è¿­ä»£ä¸”ç¼“æ…¢çš„ RNN ä¸åŒï¼ŒSSM å¯ä»¥å¹¶è¡Œå¤„ç†è¾“å…¥åºåˆ—ï¼ˆå°±åƒ Transformersï¼‰ï¼Œè¿™ä½¿å¾—è®­ç»ƒè¿‡ç¨‹æ›´å¿«ã€‚
- en: '![](../Images/22282dee4daeabed27c4669ba7ea486f.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22282dee4daeabed27c4669ba7ea486f.png)'
- en: Unrolled form of SSM
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: SSM çš„å±•å¼€å½¢å¼
- en: Note that â€˜Dâ€™ is used in a skip connection, which is outside of SSM.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œâ€˜Dâ€™ åœ¨è·³è·ƒè¿æ¥ä¸­ä½¿ç”¨ï¼Œå®ƒä½äº SSM ä¹‹å¤–ã€‚
- en: The key insight in how SSM make training fast is to use the variables *A, B,
    C* in a pre-computed convolutional kernel. [Maarten Grootendorst](https://maartengrootendorst.substack.com/i/141228095/the-convolution-representation)
    wrote a really good explanation on how this canonical â€˜convolutionalâ€™ kernel is
    constructed. But hereâ€™s a simple mathematical explanation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: SSM åŠ é€Ÿè®­ç»ƒçš„å…³é”®è§è§£æ˜¯ä½¿ç”¨é¢„å…ˆè®¡ç®—çš„å·ç§¯æ ¸ä¸­çš„å˜é‡ *A, B, C*ã€‚[Maarten Grootendorst](https://maartengrootendorst.substack.com/i/141228095/the-convolution-representation)
    å†™äº†ä¸€ç¯‡éå¸¸å¥½çš„è§£é‡Šï¼Œè®²è¿°äº†å¦‚ä½•æ„é€ è¿™ä¸ªæ ‡å‡†çš„â€˜å·ç§¯â€™æ ¸ã€‚ä½†è¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„æ•°å­¦è§£é‡Šã€‚
- en: 'Consider the output *y.* For a sequence length of *k*, the output for *y(k)*
    will be represented ***(assuming h0 = zero)***:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘è¾“å‡º *y.* å¯¹äºåºåˆ—é•¿åº¦ *k*ï¼Œè¾“å‡º *y(k)* å°†è¡¨ç¤ºä¸º***(å‡è®¾ h0 = é›¶)***ï¼š
- en: '![](../Images/16c7dd559c5978d453467fe139274186.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16c7dd559c5978d453467fe139274186.png)'
- en: 'Similarly, y3 can be represented as:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œy3 å¯ä»¥è¡¨ç¤ºä¸ºï¼š
- en: '![](../Images/b90cee1adec4657a3ffa7f67760b3abb.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b90cee1adec4657a3ffa7f67760b3abb.png)'
- en: 'Extrapolating the pattern, yk can be represented as:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨æ–­å‡ºæ¨¡å¼ï¼Œyk å¯ä»¥è¡¨ç¤ºä¸ºï¼š
- en: '![](../Images/9f7775b6a3bce55150dd393d1d9e44da.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f7775b6a3bce55150dd393d1d9e44da.png)'
- en: 'This formulation can be further reduced to:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å…¬å¼å¯ä»¥è¿›ä¸€æ­¥ç®€åŒ–ä¸ºï¼š
- en: '![](../Images/9d85bda2ef8d6da968ed73b8e48ace03.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d85bda2ef8d6da968ed73b8e48ace03.png)'
- en: The funny looking multiplication symbol represents a convolution operation,
    where the convolution kernel is K. Notice that K is not dependent on *x,* hence
    K can be pre-computed into a convolutional kernel, which makes the process faster.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¸ªçœ‹èµ·æ¥å¾ˆå¥‡æ€ªçš„ä¹˜æ³•ç¬¦å·è¡¨ç¤ºå·ç§¯æ“ä½œï¼Œå…¶ä¸­å·ç§¯æ ¸æ˜¯ Kã€‚æ³¨æ„åˆ° K ä¸ *x* æ— å…³ï¼Œå› æ­¤ K å¯ä»¥é¢„å…ˆè®¡ç®—ä¸ºå·ç§¯æ ¸ï¼Œè¿™ä½¿å¾—å¤„ç†è¿‡ç¨‹æ›´å¿«ã€‚
- en: Mamba and â€˜Selectiveâ€™ SSM
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mamba å’Œâ€œé€‰æ‹©æ€§â€SSM
- en: As good as the computational capacity of SSM sounds, it turns out to be pretty
    *meh* in metrics like accuracy compared to Transformers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ SSM çš„è®¡ç®—èƒ½åŠ›å¬èµ·æ¥å¾ˆå¼ºå¤§ï¼Œä½†ä¸ Transformers ç›¸æ¯”ï¼Œå®ƒåœ¨ç²¾åº¦ç­‰åº¦é‡æŒ‡æ ‡ä¸Šå´ç›¸å½“ *ä¸€èˆ¬*ã€‚
- en: '![](../Images/0e7755efdbec8214342ce450c6900185.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e7755efdbec8214342ce450c6900185.png)'
- en: The core issue lies with the variables, âˆ†, A, B, & C. Turns out that since we
    apply the same matrices to every input, they cannot really process the context
    of the sequence.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¸å¿ƒé—®é¢˜å‡ºåœ¨å˜é‡ âˆ†ã€Aã€B å’Œ C ä¸Šã€‚äº‹å®è¯æ˜ï¼Œç”±äºæˆ‘ä»¬å°†ç›¸åŒçš„çŸ©é˜µåº”ç”¨äºæ¯ä¸ªè¾“å…¥ï¼Œå®ƒä»¬å®é™…ä¸Šæ— æ³•å¤„ç†åºåˆ—çš„ä¸Šä¸‹æ–‡ã€‚
- en: SSMs are inflexible in the way they process data[4]
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: SSM åœ¨å¤„ç†æ•°æ®æ—¶ç¼ºä¹çµæ´»æ€§[4]
- en: So whatâ€™s so special about Mamba? In mamba, we use a process called â€˜selectiveâ€™
    SSM, where the variables, âˆ†, B, & C, are computed based on the input. ğŸ¤”. We do
    this by passing the current input through Linear layers, and take the output to
    be the âˆ†, B, & C.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆ Mamba æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼Ÿåœ¨ Mamba ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§å«åšâ€œé€‰æ‹©æ€§â€SSM çš„è¿‡ç¨‹ï¼Œå…¶ä¸­å˜é‡ âˆ†ã€B å’Œ C æ˜¯æ ¹æ®è¾“å…¥è®¡ç®—å‡ºæ¥çš„ã€‚ğŸ¤”ã€‚æˆ‘ä»¬é€šè¿‡å°†å½“å‰è¾“å…¥ä¼ é€’é€šè¿‡çº¿æ€§å±‚ï¼Œå¹¶å°†è¾“å‡ºä½œä¸º
    âˆ†ã€B å’Œ Cã€‚
- en: '![](../Images/d789181938ab7269cbd528b6982e3263.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d789181938ab7269cbd528b6982e3263.png)'
- en: But then this makes âˆ†, B, & C input dependent, hence meaning that they cannot
    be pre-computed ğŸ˜¢, fast convolution isnâ€™t going to work here. But, the authors
    discuss a method, which is based on *parallel associative scan.*
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä½¿å¾— âˆ†ã€B å’Œ C å˜å¾—ä¾èµ–äºè¾“å…¥ï¼Œå› æ­¤å®ƒä»¬ä¸èƒ½é¢„å…ˆè®¡ç®— ğŸ˜¢ï¼Œå¿«é€Ÿå·ç§¯åœ¨è¿™é‡Œè¡Œä¸é€šã€‚ä½†æ˜¯ï¼Œä½œè€…è®¨è®ºäº†ä¸€ç§åŸºäº *å¹¶è¡Œå…³è”æ‰«æ* çš„æ–¹æ³•ã€‚
- en: Parallel Associative Scan
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¹¶è¡Œå…³è”æ‰«æ
- en: Parallel associative scan is a powerful technique used in parallel computing
    to perform a prefix sum operation, which is a cumulative operation on a sequence
    of numbers. This operation is â€œassociativeâ€, meaning the way numbers are grouped
    in the operation doesnâ€™t change the result.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶è¡Œå…³è”æ‰«ææ˜¯ä¸€ç§åœ¨å¹¶è¡Œè®¡ç®—ä¸­ä½¿ç”¨çš„å¼ºå¤§æŠ€æœ¯ï¼Œç”¨äºæ‰§è¡Œå‰ç¼€å’Œæ“ä½œï¼Œè¿™æ˜¯ä¸€ç§å¯¹æ•°å­—åºåˆ—è¿›è¡Œç´¯ç§¯çš„æ“ä½œã€‚è¿™ä¸ªæ“ä½œæ˜¯â€œå…³è”çš„â€ï¼Œæ„å‘³ç€æ•°å­—åœ¨æ“ä½œä¸­çš„åˆ†ç»„æ–¹å¼ä¸ä¼šæ”¹å˜ç»“æœã€‚
- en: '![](../Images/dbbd700bf44fb468c40690bafbc4c22c.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbbd700bf44fb468c40690bafbc4c22c.png)'
- en: 'Parallel prefix sum is an example of associative scanning. (source: Nvidia)[7]'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶è¡Œå‰ç¼€å’Œæ˜¯å…³è”æ‰«æçš„ä¸€ä¸ªä¾‹å­ã€‚ï¼ˆæ¥æºï¼šNvidiaï¼‰[7]
- en: In the context of the Mamba model, by defining an associative operator, elements
    and associative operators for a parallel associative scan operation are obtained.
    This allows for solving problems on the whole time interval in parallel, resulting
    in logarithmic time complexity in the number of sub-intervals.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Mamba æ¨¡å‹çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œé€šè¿‡å®šä¹‰ä¸€ä¸ªå…³è”æ“ä½œç¬¦ï¼Œå¯ä»¥è·å¾—å¹¶è¡Œå…³è”æ‰«ææ“ä½œçš„å…ƒç´ å’Œå…³è”æ“ä½œç¬¦ã€‚è¿™ä½¿å¾—å¯ä»¥å¹¶è¡Œè§£å†³æ•´ä¸ªæ—¶é—´åŒºé—´çš„é—®é¢˜ï¼Œä»è€Œä½¿å­åŒºé—´çš„æ•°é‡çš„æ—¶é—´å¤æ‚åº¦è¾¾åˆ°å¯¹æ•°çº§åˆ«ã€‚
- en: Hardware aware algorithm
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•
- en: 'Along with associative scan, the authors also propose a hardware aware algorithm,
    where they use the quirks within Nvidia GPUs related to the speed of HBM and SRAM.
    They argue that the computation of SSM states can be sped up by:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†å…³è”æ‰«æå¤–ï¼Œä½œè€…è¿˜æå‡ºäº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•ï¼Œåœ¨è¯¥ç®—æ³•ä¸­ï¼Œä»–ä»¬åˆ©ç”¨äº†ä¸ Nvidia GPU ä¸­ HBM å’Œ SRAM é€Ÿåº¦ç›¸å…³çš„ç‰¹æ€§ã€‚ä»–ä»¬è®¤ä¸ºï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ä»¥åŠ é€Ÿ
    SSM çŠ¶æ€çš„è®¡ç®—ï¼š
- en: keeping the hidden state and A in the faster but less capacity ***SRAM*,**
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¿æŒéšè—çŠ¶æ€å’Œ A åœ¨é€Ÿåº¦è¾ƒå¿«ä½†å®¹é‡è¾ƒå°çš„ ***SRAM*** ä¸­ï¼Œ
- en: while computing âˆ†, B, & C, in the slower but larger capacity ***HBM***.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨é€Ÿåº¦è¾ƒæ…¢ä½†å®¹é‡è¾ƒå¤§çš„ ***HBM*** ä¸­è®¡ç®— âˆ†ã€B å’Œ Cã€‚
- en: They then transfer âˆ†, B, & C to the ***SRAM***, compute the new hidden state
    within ***SRAM***.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œä»–ä»¬å°† âˆ†ã€B å’Œ C è½¬ç§»åˆ° ***SRAM*** ä¸­ï¼Œåœ¨ ***SRAM*** å†…éƒ¨è®¡ç®—æ–°çš„éšè—çŠ¶æ€ã€‚
- en: And then write âˆ†, B & C back to ***HBM***.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶åå°† âˆ†ã€B å’Œ C å†™å›åˆ° ***HBM***ã€‚
- en: '![](../Images/daa8208bf094ec66ab66110f20dd51a1.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/daa8208bf094ec66ab66110f20dd51a1.png)'
- en: Illustration taken from the Mamba paper, it shows how the hardware aware algorithm
    works[1]
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç¤ºæ¥è‡ª Mamba è®ºæ–‡ï¼Œå±•ç¤ºäº†ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•å¦‚ä½•å·¥ä½œ[1]
- en: In the implementation section, I will not be discussing on how to work with
    the hardware aware algorithm, rather I will be only using parallel associative
    scan.
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨å®ç°éƒ¨åˆ†ï¼Œæˆ‘ä¸ä¼šè®¨è®ºå¦‚ä½•ä½¿ç”¨ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•ï¼Œè€Œæ˜¯åªä¼šä½¿ç”¨å¹¶è¡Œå…³è”æ‰«æã€‚
- en: Final Mamba architecture
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„ Mamba æ¶æ„
- en: With all of this in mind, letâ€™s explore and implement the Mamba architecture
    using Keras and TensorFlow.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°è¿™äº›ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Keras å’Œ TensorFlow æ¢ç´¢å¹¶å®ç° Mamba æ¶æ„ã€‚
- en: 'The Mamba architecture, after reading the paper and analysis of the code, can
    be broken into a few key components which are connected as:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é˜…è¯»è®ºæ–‡å¹¶åˆ†æä»£ç åï¼ŒMamba æ¶æ„å¯ä»¥åˆ†è§£ä¸ºå‡ ä¸ªå…³é”®ç»„ä»¶ï¼Œè¿™äº›ç»„ä»¶è¿æ¥å¦‚ä¸‹ï¼š
- en: '![](../Images/e663ed4dbf34650f50802a442192d16d.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e663ed4dbf34650f50802a442192d16d.png)'
- en: Breakdown of a mamba block
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba å—çš„æ‹†è§£
- en: The Mamba architecture consists of multiple stacked layers of â€˜Mamba blocksâ€™.
    Which, judging from the above illustration, consists of quite a few components.
    Another important thing to note is that the authors add the output from Selective
    SSM to the original input and then apply a *normalization* layer to it. This normalization
    can be either a Layer normalization or an [RMS normalization](https://arxiv.org/abs/1910.07467).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Mamba æ¶æ„ç”±å¤šä¸ªå †å çš„â€œMamba å—â€ç»„æˆã€‚ä»ä¸Šé¢çš„å›¾ç¤ºæ¥çœ‹ï¼Œå®ƒç”±ç›¸å½“å¤šçš„ç»„ä»¶ç»„æˆã€‚å¦ä¸€ä¸ªéœ€è¦æ³¨æ„çš„é‡è¦äº‹é¡¹æ˜¯ï¼Œä½œè€…å°†æ¥è‡ªé€‰æ‹©æ€§ SSM çš„è¾“å‡ºæ·»åŠ åˆ°åŸå§‹è¾“å…¥ä¸­ï¼Œç„¶åå¯¹å…¶åº”ç”¨
    *å½’ä¸€åŒ–* å±‚ã€‚æ­¤å½’ä¸€åŒ–å¯ä»¥æ˜¯å±‚å½’ä¸€åŒ–ï¼Œæˆ–è€…æ˜¯ [RMS å½’ä¸€åŒ–](https://arxiv.org/abs/1910.07467)ã€‚
- en: TensorFlow and Keras implementation
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow å’Œ Keras å®ç°
- en: 'Lets start with coding part of Mamba. We will using the following dependencies:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä» Mamba çš„ç¼–ç éƒ¨åˆ†å¼€å§‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä¾èµ–é¡¹ï¼š
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Imports:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥ï¼š
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To make the modeling argument processing easier, letâ€™s create a simple *ModelArgs*
    dataclass as a config class. This allows us to just pass the dataclass variable
    in the arguments when we are initializing the model.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–æ¨¡å‹å‚æ•°çš„å¤„ç†ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„ *ModelArgs* æ•°æ®ç±»ä½œä¸ºé…ç½®ç±»ã€‚è¿™æ ·ï¼Œåœ¨åˆå§‹åŒ–æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬åªéœ€å°†æ•°æ®ç±»å˜é‡ä½œä¸ºå‚æ•°ä¼ é€’å³å¯ã€‚
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Load the *bert-base-uncased* tokenizer:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½ *bert-base-uncased* åˆ†è¯å™¨ï¼š
- en: '[PRE3]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Before we implement our Mamba and SSM classes, we need to implement the parallel
    associative scan, the code looks like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å®ç° Mamba å’Œ SSM ç±»ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å®ç°å¹¶è¡Œå…³è”æ‰«æï¼Œä»£ç å¦‚ä¸‹ï¼š
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With this, we can implement the MambaBlock:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å®ç° MambaBlockï¼š
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Finally, a residual block to implement the external skip connection.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå®ç°å¤–éƒ¨è·³è·ƒè¿æ¥çš„æ®‹å·®å—ã€‚
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: With this, we can initialize our model. In this example, I will be demonstrating
    how to use the Mamba block to create a simple classification model, but it can
    be easily modified to become a language model. Letâ€™s load the *IMDB reviews dataset*
    for a simple sentiment classifier.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥åˆå§‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Mambaæ¨¡å—åˆ›å»ºä¸€ä¸ªç®€å•çš„åˆ†ç±»æ¨¡å‹ï¼Œä½†å®ƒå¯ä»¥å¾ˆå®¹æ˜“åœ°ä¿®æ”¹ä¸ºè¯­è¨€æ¨¡å‹ã€‚è®©æˆ‘ä»¬åŠ è½½*IMDBè¯„è®ºæ•°æ®é›†*æ¥è¿›è¡Œä¸€ä¸ªç®€å•çš„æƒ…æ„Ÿåˆ†ç±»å™¨ã€‚
- en: '[PRE7]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: First we create a function that will take the model args and return a model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°å°†æ¥æ”¶æ¨¡å‹å‚æ•°å¹¶è¿”å›ä¸€ä¸ªæ¨¡å‹ã€‚
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we can initialize our model, and summarize it:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆå§‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ€»ç»“ï¼š
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'For easier processing, lets pre-tokenize our data into a *numpy arrays*, then
    convert them into tf.data.Dataset objects:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´æ–¹ä¾¿åœ°å¤„ç†ï¼Œè®©æˆ‘ä»¬å…ˆå°†æ•°æ®è¿›è¡Œé¢„å¤„ç†æˆ*numpyæ•°ç»„*ï¼Œç„¶åå†è½¬æ¢ä¸ºtf.data.Datasetå¯¹è±¡ï¼š
- en: '[PRE11]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now the model can be trained:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ¨¡å‹å¯ä»¥è¿›è¡Œè®­ç»ƒï¼š
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can play around with the inference algorithm:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å°è¯•æ¨ç†ç®—æ³•ï¼š
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This model can be converted into a language model and algorithms like *beam
    search, top-k sampling, greedy sampling, etc.* can be used to generate language.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹å¯ä»¥è½¬åŒ–ä¸ºè¯­è¨€æ¨¡å‹ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨åƒ*æŸæœç´¢ã€top-ké‡‡æ ·ã€è´ªå¿ƒé‡‡æ ·*ç­‰ç®—æ³•æ¥ç”Ÿæˆè¯­è¨€ã€‚
- en: This code can be found on my [Github](https://github.com/maxDeCoder/Mamba-tf).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ®µä»£ç å¯ä»¥åœ¨æˆ‘çš„[Github](https://github.com/maxDeCoder/Mamba-tf)ä¸Šæ‰¾åˆ°ã€‚
- en: A lot of the code is inspired from the mambaâ€™s official implementation[2] and
    another pytorch implementation called â€˜mamba-tinyâ€™[3]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¤šä»£ç çµæ„Ÿæ¥æºäºmambaçš„å®˜æ–¹å®ç°[2]ä»¥åŠå¦ä¸€ä¸ªåä¸ºâ€˜mamba-tinyâ€™çš„pytorchå®ç°[3]
- en: Thank you for reading.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ã€‚
- en: Unless otherwise noted, all images are made by me.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±æˆ‘åˆ¶ä½œã€‚
- en: 'References:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å‚è€ƒèµ„æ–™ï¼š
- en: '[Mamba paper.](https://arxiv.org/abs/2312.00752)'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Mambaè®ºæ–‡](https://arxiv.org/abs/2312.00752)'
- en: '[Mamba original repository](https://github.com/state-spaces/mamba)'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[MambaåŸå§‹ä»“åº“](https://github.com/state-spaces/mamba)'
- en: '[A simpler Torch implementation of Mamba: mamba-tiny](https://github.com/PeaBrane/mamba-tiny)'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Mambaçš„ä¸€ä¸ªæ›´ç®€å•çš„Torchå®ç°ï¼šmamba-tiny](https://github.com/PeaBrane/mamba-tiny)'
- en: '[A simple explanation by Letitia on YouTube.](https://youtu.be/vrF3MtGwD0Y?si=st2Oipq3fli9tGhl)'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Letitiaåœ¨YouTubeä¸Šçš„ç®€å•è§£é‡Š](https://youtu.be/vrF3MtGwD0Y?si=st2Oipq3fli9tGhl)'
- en: '[Maarten Grootendorstâ€™s article on SSMs and Mamba](https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state)'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Maarten Grootendorstå…³äºSSMå’ŒMambaçš„æ–‡ç« ](https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state)'
- en: '[SSMs on wikipedia](https://en.wikipedia.org/wiki/SSM)'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ç»´åŸºç™¾ç§‘ä¸Šçš„SSM](https://en.wikipedia.org/wiki/SSM)'
- en: '[Nvidiaâ€™s tutorial on Parallel associative scan](https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda)'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Nvidiaå…³äºå¹¶è¡Œå…³è”æ‰«æçš„æ•™ç¨‹](https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda)'
- en: Want to connect? Please write to me at [vedantjumle@gmail.com](mailto:vedantjumle@gmail.com)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è¦è”ç³»æˆ‘å—ï¼Ÿè¯·é€šè¿‡[vedantjumle@gmail.com](mailto:vedantjumle@gmail.com)ç»™æˆ‘å†™ä¿¡ã€‚
