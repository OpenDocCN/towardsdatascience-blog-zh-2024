- en: Fine-Tune the Audio Spectrogram Transformer with Hugging Face Transformers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Hugging Face Transformers 微调音频光谱图变换器
- en: 原文：[https://towardsdatascience.com/fine-tune-the-audio-spectrogram-transformer-with-transformers-73333c9ef717?source=collection_archive---------4-----------------------#2024-08-21](https://towardsdatascience.com/fine-tune-the-audio-spectrogram-transformer-with-transformers-73333c9ef717?source=collection_archive---------4-----------------------#2024-08-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/fine-tune-the-audio-spectrogram-transformer-with-transformers-73333c9ef717?source=collection_archive---------4-----------------------#2024-08-21](https://towardsdatascience.com/fine-tune-the-audio-spectrogram-transformer-with-transformers-73333c9ef717?source=collection_archive---------4-----------------------#2024-08-21)
- en: Learn how to fine-tune the Audio Spectrogram Transformer model for audio classification
    of your own data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习如何微调音频光谱图变换器模型，以便进行您自己的数据音频分类
- en: '[](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)[![Marius
    Steger](../Images/9dff217a20fc1542eac8e52d32048114.png)](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)
    [Marius Steger](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)[![Marius
    Steger](../Images/9dff217a20fc1542eac8e52d32048114.png)](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)
    [Marius Steger](https://medium.com/@marius_s?source=post_page---byline--73333c9ef717--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)
    ·13 min read·Aug 21, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--73333c9ef717--------------------------------)
    ·13 分钟阅读·2024年8月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7f8ad4be45f2ff60c16110e638acb74c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f8ad4be45f2ff60c16110e638acb74c.png)'
- en: Fine-tuning an audio classification model instead of training from scratch can
    be more data efficient, leading to better results on the downstream task | *Image
    by author*
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 微调音频分类模型，而不是从头开始训练，能够更高效地使用数据，从而在下游任务中获得更好的结果 | *图像来自作者*
- en: Audio classification is one of the key tasks in audio understanding with Machine
    Learning and serves as a building block for many AI systems. It powers industry
    applications for [test data evaluation](https://renumics.com/use-cases/test-data)
    in the engineering domain, error and anomaly detection, or predictive maintenance.
    Pre-trained transformer models, like the Audio Spectrogram Transformer (AST)[1],
    provide a powerful foundation for these applications, offering robustness and
    flexibility.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 音频分类是机器学习中音频理解的关键任务之一，并为许多 AI 系统提供了构建基础。它驱动着工业领域的应用，例如[测试数据评估](https://renumics.com/use-cases/test-data)、错误和异常检测，或预测性维护。预训练的变换器模型，如音频光谱图变换器（AST）[1]，为这些应用提供了强大的基础，具有鲁棒性和灵活性。
- en: While training an AST model from scratch would require a huge amount of data,
    using a pretrained model that has already learned audio-specific features can
    be more efficient. Fine-tuning these models with data specific to our use case
    is essential to enable their use for our particular application. This process
    adapts the model’s capabilities to the unique characteristics of our dataset,
    such as classes and data distribution, ensuring the relevance of the results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从头开始训练一个 AST 模型需要大量数据，但使用已经学习了音频特征的预训练模型会更高效。通过使用特定于我们用例的数据微调这些模型，对于使其适用于我们的特定应用程序至关重要。这个过程将模型的能力调整为我们数据集的独特特征，如类别和数据分布，确保结果的相关性。
- en: '![](../Images/895d4939ab3d1eb6e2da381a10bcfbe0.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/895d4939ab3d1eb6e2da381a10bcfbe0.png)'
- en: The Audio Spectrogram Transformer predicts a class for an audio sample based
    on its spectrogram | *Image by author*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 音频光谱图变换器根据音频样本的光谱图预测类别 | *图像来自作者*
- en: The AST model, integrated with the Hugging Face 🤗 [Transformers](https://huggingface.co/docs/transformers/index)
    library, has become a popular choice due to its ease of use and strong performance
    in audio classification tasks. This guide will take us through the entire process
    of fine-tuning a pretrained AST model (“[*MIT/ast-finetuned-audioset-10–10–0.4593*](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)*”*)
    using our own data, demonstrated with the [ESC50 dataset](https://github.com/karolpiczak/ESC-50)[2].
    Using tools from the Hugging Face ecosystem and PyTorch as the backend, we will
    cover everything from data preparation and preprocessing to model configuration
    and training.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AST模型与Hugging Face 🤗 [Transformers](https://huggingface.co/docs/transformers/index)库集成，由于在音频分类任务中易于使用且性能强大，已成为热门选择。本指南将带领我们完成对预训练AST模型（“[*MIT/ast-finetuned-audioset-10–10–0.4593*](https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593)*”*）进行微调的整个过程，使用我们自己的数据，在[ESC50数据集](https://github.com/karolpiczak/ESC-50)[2]上进行演示。利用Hugging
    Face生态系统和PyTorch作为后端的工具，我们将涵盖从数据准备和预处理到模型配置和训练的所有内容。
- en: I am writing this guide based on my professional experience with the AST model
    and the Hugging Face ecosystem over the past years.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我根据过去几年与AST模型和Hugging Face生态系统的专业经验撰写了这份指南。
- en: This tutorial will guide us through the process of fine-tuning the AST on our
    own audio classification dataset with tooling from the Hugging Face ecosystem.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本教程将指导我们使用Hugging Face生态系统的工具对自己的音频分类数据集上的AST进行微调。
- en: We will load the data (1), preprocess the audios (2), setup audio augmentations
    (3), configure and initialize the AST model (4) and finally, configure and start
    a training (5).
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将加载数据（1），预处理音频（2），设置音频增强（3），配置和初始化AST模型（4），最后，配置和开始训练（5）。
- en: Step-by-Step Guide to Fine-Tune the AST
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调AST的逐步指南
- en: 'Before we start, install all the required packages with pip:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请使用pip安装所有必需的软件包：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 1\. Load Our Data in the Correct Format
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 以正确格式加载我们的数据
- en: To start, we’ll use the Hugging Face 🤗 [Datasets](https://huggingface.co/docs/datasets/index)
    library to manage our data. This library will assist us in preprocessing, storing,
    and accessing data during training, as well as performing waveform transformations
    and encoding into spectrograms on the fly.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用Hugging Face 🤗 [Datasets](https://huggingface.co/docs/datasets/index)库来管理我们的数据。该库将协助我们在训练过程中进行预处理、存储和访问数据，以及在需要时执行波形转换并实时编码为频谱图。
- en: 'Our data should be loaded into a `Dataset` object with the following structure:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据应加载到具有以下结构的`Dataset`对象中：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the following two sections I will demonstrate how to load a prepared dataset
    from the 🤗 Hub and also create a `*Dataset*` from local audio data and labels.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在接下来的两个部分中，我将演示如何从🤗 Hub加载准备好的数据集，以及如何从本地音频数据和标签创建一个`*Dataset*`。
- en: '**Loading a Dataset from the Hugging Face Hub:** If we don’t have an audio
    dataset locally, we can conveniently load one from the Hugging Face Hub using
    the `load_dataset` function.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**从Hugging Face Hub加载数据集：** 如果我们没有本地音频数据集，可以方便地使用`load_dataset`函数从Hugging Face
    Hub加载数据集。'
- en: 'In this guide we will load the ESC50 Audio Classification dataset for demonstration
    purposes:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，我们将加载ESC50音频分类数据集以进行演示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/d311793e7f3a774f4c6cbf257a504f74.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d311793e7f3a774f4c6cbf257a504f74.png)'
- en: The spectrograms (top) and waveforms (bottom) of different classes from the
    ESC50 Dataset | *Image by author (created with* [*Spotlight*](https://github.com/Renumics/spotlight)*)*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ESC50数据集中不同类别的频谱图（顶部）和波形图（底部）| *作者创建的图像（使用* [*Spotlight*](https://github.com/Renumics/spotlight)*)*
- en: '**Loading Local Audio Files and Labels:** We can load our audio files and associated
    labels into a `Dataset` object using a dictionary or a pandas DataFrame that contains
    file paths and labels. If we have a mapping of class names (strings) to label
    indices (integers), this information can be included during dataset construction.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**加载本地音频文件和标签：** 我们可以使用包含文件路径和标签的字典或pandas DataFrame将音频文件和相关标签加载到`Dataset`对象中。如果我们有类名（字符串）到标签索引（整数）的映射，这些信息可以在数据集构建过程中包含。'
- en: 'Here’s a practical example:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实际示例：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In this example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中：
- en: The `Audio` feature class automatically handles audio file loading and processing.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Audio`特征类会自动处理音频文件的加载和处理。'
- en: '`ClassLabel` helps manage categorical labels, making it easier to handle classes
    during training and evaluation.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ClassLabel`有助于管理分类标签，使在训练和评估过程中更容易处理类别。'
- en: '**Note:** For more information on loading audio with Hugging Face, have a look
    at the Datasets library [Docs](https://huggingface.co/docs/datasets/audio_load).'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 有关如何使用Hugging Face加载音频的更多信息，请查看Datasets库的[文档](https://huggingface.co/docs/datasets/audio_load)。'
- en: '**Inspecting the Dataset:** Once the dataset is successfully loaded, each audio
    sample is accessible via an `Audio` feature class, which optimizes data handling
    by loading it into memory only when needed. This efficient management saves computational
    resources and speeds up the training process.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**检查数据集：** 一旦数据集成功加载，每个音频样本都可以通过`Audio`特征类进行访问，`Audio`特征类通过仅在需要时将其加载到内存中来优化数据处理。这种高效的管理节省了计算资源，并加速了训练过程。'
- en: 'To get a better understanding of the data structure and ensure everything is
    loaded correctly, we can inspect individual samples in the dataset:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解数据结构并确保一切正确加载，我们可以检查数据集中单个样本：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Output example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输出示例：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This output shows the path, waveform data array, and the sampling rate for the
    audio file, along with its corresponding label.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出显示了音频文件的路径、波形数据数组以及采样率，并附上相应的标签。
- en: For the following steps, you can either use a prepared dataset as demo like
    we do or continue with your own dataset.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于接下来的步骤，您可以使用像我们这样准备好的数据集作为示例，也可以继续使用您自己的数据集。
- en: 2\. Preprocess the audio data
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 预处理音频数据
- en: 'If our dataset is from the Hugging Face Hub, we cast the `*audio*` and `*labels*`
    columns to the correct feature types:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的数据集来自Hugging Face Hub，我们将`*audio*`和`*labels*`列转换为正确的特征类型：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中：
- en: '**Audio Casting**: The `Audio` feature handles loading and processing audio
    files, resampling them to the desired sampling rate (16kHz in this case, sampling
    rate of the `ASTFeatureExtractor`).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音频转换：** `Audio`特征类处理音频文件的加载和处理，并将其重新采样到所需的采样率（此处为16kHz，即`ASTFeatureExtractor`的采样率）。'
- en: '**ClassLabel Casting**: The `ClassLabel` feature maps integers to labels and
    vice versa.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别标签转换：** `ClassLabel`特征将整数映射到标签，反之亦然。'
- en: '![](../Images/5406a4f6a58ec46f62f5875bafeab4cb.png)![](../Images/113a08208bca4a7f8e5b2e3d018054c5.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5406a4f6a58ec46f62f5875bafeab4cb.png)![](../Images/113a08208bca4a7f8e5b2e3d018054c5.png)'
- en: An audio array as waveform (left) and as spectrogram (right) | *Image by author*
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个音频数组作为波形（左）和频谱图（右） | *图片由作者提供*
- en: '**Preparing for AST Model Inputs:** The AST model requires spectrogram inputs,
    so we need to encode our waveforms into a format that the model can process. This
    is achieved using the `ASTFeatureExtractor`, which is instantiated from the configuration
    of the pretrained model we intend to fine-tune on our dataset.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**为AST模型输入做准备：** AST模型需要频谱图输入，因此我们需要将波形编码为模型可以处理的格式。这是通过使用`ASTFeatureExtractor`来实现的，该提取器是从我们打算在数据集上进行微调的预训练模型的配置中实例化的。'
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Note:** It is important to set the **mean** and **std** values for **normalization**
    in the feature extractor to the **values of our dataset**. We can calculate the
    values using the following block of code:'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 在特征提取器中设置**均值（mean）**和**标准差（std）**值以进行**归一化（normalization）**是非常重要的，这些值应当设为**我们数据集的值**。我们可以使用以下代码块来计算这些值：'
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Applying Transforms for Preprocessing:** We create a function to preprocess
    the audio data by encoding the audio arrays into the `input_values` format expected
    by the model. This function is set up to be applied dynamically, meaning it processes
    the data on-the-fly as each sample is loaded from the dataset.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用预处理转换：** 我们创建一个函数来预处理音频数据，将音频数组编码为模型期望的`input_values`格式。这个函数设置为动态应用，即在每个样本从数据集中加载时，它会实时处理数据。'
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Inspecting Transformed Data**: If we load a sample now, it will be transformed
    on the fly and the encoded audios are yielded as `*input_values*`*:*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**检查转换后的数据：** 如果我们现在加载一个样本，它将实时转换，编码后的音频将作为`*input_values*`输出：'
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Note**: It is crucial to verify that the transformation process maintains
    data integrity and that the spectrograms are correctly formed to avoid any issues
    during model training.'
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 验证转换过程是否保持数据完整性，并确保频谱图正确生成，以避免模型训练过程中出现任何问题，这是至关重要的。'
- en: '**Splitting the Dataset:** As last data preprocessing step, we split the dataset
    into a `train`and `test`-setwhile utilizing the labels for stratification. This
    ensures to maintain class distribution across both sets.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**拆分数据集：** 作为最后一步数据预处理，我们将数据集拆分为`train`和`test`集，同时利用标签进行分层抽样。这样可以确保两个数据集中的类别分布保持一致。'
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 3\. Add audio augmentations
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 添加音频增强
- en: Augmentations play a crucial role in increasing the robustness of machine learning
    models by introducing variability into the training data. This simulates different
    recording conditions and helps the model to better generalize to unseen data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 增强在通过引入训练数据的变化性来提高机器学习模型的鲁棒性方面起着至关重要的作用。这模拟了不同的录音条件，并帮助模型更好地对未见过的数据进行泛化。
- en: Before diving into the setup, here’s a visual comparison showing the **original**
    spectrogram of an audio file and its augmented version using the **AddBackgroundNoise**
    transformation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始设置之前，下面是一个视觉对比，展示了音频文件的**原始**频谱图和通过 **AddBackgroundNoise** 转换得到的增强版频谱图。
- en: '![](../Images/d3f6385a1580e5879d6a036094c54a5f.png)![](../Images/b3fa731cbc376356c42569f444f90b76.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3f6385a1580e5879d6a036094c54a5f.png)![](../Images/b3fa731cbc376356c42569f444f90b76.png)'
- en: The original spectrogram of an audio file (left) and the same audio with the
    AddBackgroundNoise transformation from [Audiomentations](https://github.com/iver56/audiomentations)
    library (right) | *Image by author*
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 音频文件的原始频谱图（左）和通过 [Audiomentations](https://github.com/iver56/audiomentations)
    库的 AddBackgroundNoise 转换增强后的音频（右）| *图片来源：作者*
- en: '**Note:** Augmentations are a very effective tool for increasing the robustness
    of training and reducing overfitting in machine learning models.'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 增强是提高训练鲁棒性和减少机器学习模型过拟合的有效工具。'
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, it’s important to **carefully consider the potential impact of each
    transformation**. For example, adding noise may be appropriate for speech datasets,
    as it can simulate real-world scenarios where background noise is present. However,
    for tasks such as sound classification, such enhancements could lead to class
    confusion, resulting in poor model performance.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，必须**仔细考虑每个转换的潜在影响**。例如，添加噪音对于语音数据集可能是合适的，因为它可以模拟现实世界中的背景噪音情况。然而，对于声音分类等任务，这些增强可能会导致类别混淆，从而导致模型性能下降。
- en: '**Setting Up Audio Augmentations:** To create a set of audio augmentations,
    we use the `Compose` class from the [Audiomentations](https://iver56.github.io/audiomentations/)
    library, which allows us to chain multiple augmentations.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**设置音频增强：** 为了创建一组音频增强，我们使用了来自 [Audiomentations](https://iver56.github.io/audiomentations/)
    库的 `Compose` 类，它允许我们将多个增强组合在一起。'
- en: 'Here’s how to set it up:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何设置它：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this setup:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设置中：
- en: The `p=0.8` parameter specifies that each augmentation in the `Compose` sequence
    has an 80% chance of being applied to any given audio sample. This probabilistic
    approach ensures variability in the training data, preventing the model from becoming
    overly dependent on any specific augmentation pattern and improving its ability
    to generalize.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p=0.8` 参数指定 `Compose` 序列中的每个增强在给定音频样本上有 80% 的概率被应用。这个概率方法确保了训练数据的变化性，防止模型过度依赖于任何特定的增强模式，并提高其泛化能力。'
- en: The `shuffle=True` parameter randomizes the order in which the augmentations
    are applied, adding another layer of variability.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle=True` 参数会随机化应用增强的顺序，增加了另一层变化性。'
- en: For a better understanding of these augmentations and detailed configuration
    options, check out the [**Audiomentations’** **docs**](https://iver56.github.io/audiomentations/).
    Additionally, there’s a great [🤗 **Space**](https://phrasenmaeher-audio-transformat-visualize-transformation-5s1n4t.streamlit.app/)
    where we can experiment with these audio transformations and hear and see their
    effects on the spectrograms.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 若要更好地理解这些增强及其详细配置选项，可以查看 [**Audiomentations 的文档**](https://iver56.github.io/audiomentations/)。此外，还有一个很棒的
    [🤗 **空间**](https://phrasenmaeher-audio-transformat-visualize-transformation-5s1n4t.streamlit.app/)，可以在其中实验这些音频转换，听到并看到它们对频谱图的影响。
- en: '**Integrating Augmentations into the Training Pipeline:** We apply these augmentations
    during the `preprocess_audio` transformation where we also encode the audio data
    into spectrograms.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**将增强集成到训练管道中：** 我们在 `preprocess_audio` 转换中应用这些增强，同时将音频数据编码为频谱图。'
- en: 'The new preprocessing with augmentation is given by:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 新的预处理与增强如下：
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This function applies the defined augmentations to each waveform and then uses
    the `ASTFeatureExtractor` to encode the augmented waveforms into model inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将定义的增强应用到每个波形，并使用 `ASTFeatureExtractor` 将增强后的波形编码为模型输入。
- en: '**Setting Transforms for Training and Validation Splits:** Finally, we set
    these transformations to be applied during the training and evaluation phases:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**设置训练和验证拆分的转换：** 最后，我们设置这些转换将在训练和评估阶段应用：'
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 4\. Configure and Initialize the AST for Fine-Tuning
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 配置并初始化 AST 进行微调
- en: To adapt the AST model to our specific audio classification task, we will need
    to adjust the model’s configuration. This is because our dataset has a different
    number of classes than the pretrained model, and these classes correspond to different
    categories. It requires replacing the pretrained classifier head with a new one
    for our multi-class problem.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将 AST 模型适应我们的特定音频分类任务，我们需要调整模型的配置。因为我们的数据集与预训练模型的类别数不同，而且这些类别对应不同的分类。我们需要用一个新的分类头替换预训练模型中的分类头，以解决我们的多类问题。
- en: The weights for the new classifier head will be randomly initialized, while
    the rest of the model’s weights will be loaded from the pretrained version. In
    this way, we benefit from the learned features of the pretraining and fine-tune
    on our data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 新的分类头的权重将被随机初始化，而模型其余部分的权重将从预训练版本加载。通过这种方式，我们可以从预训练的学习特征中受益，并在我们的数据上进行微调。
- en: 'Here’s how to set up and initialize the AST model with a new classification
    head:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何设置和初始化带有新分类头的 AST 模型：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Expected Output:** We will see warnings indicating that some weights, especially
    those in the classifier layers, are being reinitialized:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期输出：** 我们将看到一些警告，表明某些权重，特别是分类层中的权重，正在被重新初始化：'
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 5\. Setup Metrics and Start Training
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 设置评估指标并开始训练
- en: In the final step we will configure the training process with the 🤗 [Transformers](https://github.com/huggingface/transformers)
    library and use the 🤗 [Evaluate](https://github.com/huggingface/evaluate) library
    to define the evaluation metrics to assess the model’s performance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，我们将使用 🤗 [Transformers](https://github.com/huggingface/transformers) 库来配置训练过程，并使用
    🤗 [Evaluate](https://github.com/huggingface/evaluate) 库来定义评估指标，以评估模型的性能。
- en: '**1\. Configure Training Arguments:** The `TrainingArguments` class helps set
    up various parameters for the training process, such as learning rate, batch size,
    and number of epochs.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 配置训练参数：** `TrainingArguments` 类有助于设置训练过程中的各种参数，如学习率、批量大小和训练轮数。'
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**2\. Define Evaluation Metrics:** Define metrics such as accuracy, precision,
    recall, and F1 score to evaluate the model’s performance. The `compute_metrics`
    function will handle the calculations during training.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 定义评估指标：** 定义如准确率、精确度、召回率和 F1 分数等指标来评估模型的性能。`compute_metrics` 函数将在训练过程中处理这些计算。'
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**3\. Setup the Trainer:** Use the `Trainer` class from Hugging Face to handle
    the training process. This class integrates the model, training arguments, datasets,
    and metrics.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 设置 Trainer：** 使用 Hugging Face 的 `Trainer` 类来处理训练过程。该类集成了模型、训练参数、数据集和评估指标。'
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'With everything configured, we initiate the training process:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 配置完成后，我们启动训练过程：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/e14d2383267ae80949cd038f1e0f21b5.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e14d2383267ae80949cd038f1e0f21b5.png)'
- en: Example log of a training with audio-augmentations applied to the train-split
    | *Image by author*
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 应用音频增强的训练日志示例 | *图像由作者提供*
- en: (Not so optional:) Evaluate The Results
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '（非那么可选的）: 评估结果'
- en: To understand our model’s performance and find potential areas for improvement,
    it is essential to evaluate its predictions on train and test data. During training,
    metrics such as accuracy, precision, recall, and F1 score are logged to [TensorBoard](https://www.tensorflow.org/tensorboard),
    which allows us to inspect the model’s progress and performance over time.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解模型的表现并找出潜在的改进空间，评估其在训练和测试数据上的预测至关重要。在训练过程中，准确率、精确度、召回率和 F1 分数等指标会记录到 [TensorBoard](https://www.tensorflow.org/tensorboard)，这使我们能够检查模型随时间的进展和性能。
- en: '**Starting TensorBoard**: To visualize these metrics, initiate TensorBoard
    by running the following command in your terminal:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动 TensorBoard**：为了可视化这些指标，在终端运行以下命令启动 TensorBoard：'
- en: '[PRE21]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This provides a graphical representation of the model’s learning curve and metric
    improvements over time, helping to identify potential overfitting or underperformance
    early in the training process.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了一个图形化的表示，展示了模型的学习曲线和指标随时间的改进，帮助我们及早发现潜在的过拟合或性能不足。
- en: For **more detailed insights**, we can inspect the model’s predictions using
    [Renumics](https://renumics.com/)’ open-source tool, [**Spotlight**](https://renumics.com/open-source/spotlight).
    Spotlight enables us to explore and visualize the predictions alongside the data,
    helping us to identify patterns, potential biases, and miss-classifications on
    the level of single data points.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**更详细的见解**，我们可以使用 [Renumics](https://renumics.com/) 的开源工具 [**Spotlight**](https://renumics.com/open-source/spotlight)
    检查模型的预测。Spotlight 可以让我们探索和可视化预测以及数据，帮助我们识别单个数据点的模式、潜在偏见和错误分类。
- en: '![](../Images/07e84100feee6c38d3dbde8ed89c2a7f.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07e84100feee6c38d3dbde8ed89c2a7f.png)'
- en: The ESC50 dataset with audio embeddings and model predictions loaded in Spotlight.
    Try it yourself in this Hugging Face [Space](https://huggingface.co/spaces/renumics/spotlight-esc50-clap)
    | *Image by author*
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spotlight 中加载了带有音频嵌入和模型预测的 ESC50 数据集。在这个 Hugging Face [Space](https://huggingface.co/spaces/renumics/spotlight-esc50-clap)
    中尝试一下吧。| *作者提供的图片*
- en: '**Installing and Using Spotlight**:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**安装和使用 Spotlight**：'
- en: 'To get started with Spotlight, install it using pip and load your dataset for
    exploration:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Spotlight，请使用 pip 安装它并加载您的数据集进行探索：
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And load the ESC50 dataset for **interactive exploration** with one line of
    code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用一行代码加载 ESC50 数据集进行**交互式探索**：
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This tutorial focuses on setting up the fine-tuning pipeline. For a comprehensive
    **evaluation**, including **using Spotlight**, please refer to the other tutorials
    and resources provided below and at the end of this guide (Useful Links).
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本教程侧重于建立微调流程。有关全面的**评估**，包括**使用 Spotlight**，请参考下面提供的其他教程和资源以及本指南末尾的链接（有用链接）。
- en: 'Here are some examples of how to use Spotlight for model evaluation:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些如何使用 Spotlight 进行模型评估的示例：
- en: A blog post with demo on **Hands-On Voice Analytics with Transformers:** [Blog](https://renumics.com/blog/voice-analytics-with-transformers)
    & 🤗 [Space](https://huggingface.co/spaces/renumics/emodb-model-comparison)
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一篇关于**使用 Transformers 进行实时语音分析**的博文和演示：[博文](https://renumics.com/blog/voice-analytics-with-transformers)
    & 🤗 [Space](https://huggingface.co/spaces/renumics/emodb-model-comparison)
- en: A blog post and short example on **Fine-tuning image classification models from
    image search:** [Blog](https://itnext.io/image-classification-in-2023-8ab7dc552115)
    & [Use Case](https://renumics.com/next/docs/use-cases/image-fine-tuning)
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一篇关于**Fine-tuning image classification models from image search**的博文和简短示例：[博文](https://itnext.io/image-classification-in-2023-8ab7dc552115)
    & [使用案例](https://renumics.com/next/docs/use-cases/image-fine-tuning)
- en: 'A blog post and short example on **How to Automatically Find and Remove Issues
    in Your Image, Audio, and Text Classification Datasets**: [Blog](https://medium.com/@daniel-klitzke/finding-problematic-data-slices-in-unstructured-data-aeec0a3b9a2a)
    & [Use Case](https://renumics.com/next/docs/use-cases/audio-classification)'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一篇关于**如何自动查找和删除图像、音频和文本分类数据集中问题的文章**和简短示例：[博文](https://medium.com/@daniel-klitzke/finding-problematic-data-slices-in-unstructured-data-aeec0a3b9a2a)
    & [使用案例](https://renumics.com/next/docs/use-cases/audio-classification)
- en: Conclusion
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: By following the steps outlined in this guide, we’ll be able to fine-tune the
    Audio Spectrogram Transformer (AST) on any audio classification dataset. This
    includes setting up data preprocessing, applying effective audio augmentations,
    and configuring the model for the specific task. After training, we can evaluate
    the model’s performance using the defined metrics, ensuring it meets our requirements.
    Once the model is fine-tuned and validated, it can be used for inference.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过按照本指南中概述的步骤，我们将能够在任何音频分类数据集上微调音频频谱变换器（AST）。这包括设置数据预处理、应用有效的音频增强以及为特定任务配置模型。训练后，我们可以使用定义的指标评估模型的性能，确保它符合我们的要求。一旦模型经过微调和验证，就可以用于推断。
- en: More on the Topic
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于这个主题的更多内容
- en: This is the second in a **series of tutorials and blog posts** on the Audio
    Spectrogram Transformer for industrial audio classification use cases.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于用于工业音频分类用例的音频频谱变换器的**系列教程和博文**中的第二篇。
- en: 'Have a look at **part one**: [*How to Use SSAST Model Weigths in the HuggingFace
    Ecosystem?*](https://medium.com/itnext/how-to-use-ssast-model-weigths-in-the-huggingface-ecosystem-0f3fdc8d38da),'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看一看**第一部分**：[*如何在 HuggingFace 生态系统中使用 SSAST 模型权重？*](https://medium.com/itnext/how-to-use-ssast-model-weigths-in-the-huggingface-ecosystem-0f3fdc8d38da)，
- en: and watch [this list](https://medium.com/@marius_s/list/audio-classification-for-industry-use-cases-cb6d169a7d80)
    for upcoming posts.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并查看[这个列表](https://medium.com/@marius_s/list/audio-classification-for-industry-use-cases-cb6d169a7d80)以获取即将发布的文章。
- en: Stay tuned for further posts in this series, where we will examine specific
    challenges from real use cases and how to adapt the AST to handle them.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请继续关注本系列的后续文章，我们将探讨实际使用案例中的特定挑战以及如何调整AST以应对这些挑战。
- en: Useful Links
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有用的链接
- en: '**Download** **this guide** asnotebook from the Renumics [**Resource Page**](https://renumics.com/open-source/resources)**.**'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载** **本指南**作为笔记本，从Renumics的[**资源页面**](https://renumics.com/open-source/resources)**。**'
- en: A tutorial on how to use **Spotlight for audio model evaluation:** [**Blog**](https://renumics.com/blog/voice-analytics-with-transformers)
    & **🤗** [**Space**](https://huggingface.co/spaces/renumics/emodb-model-comparison)
    (Demo)
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于如何使用**Spotlight进行音频模型评估**的教程：[**博客**](https://renumics.com/blog/voice-analytics-with-transformers)
    & **🤗** [**空间**](https://huggingface.co/spaces/renumics/emodb-model-comparison)（演示）
- en: 'A tutorial on how to **train an acoustic event detection** **system** with
    Spotlight: [**Blog**](https://renumics.com/blog/acoustic-event-detection-annotation)'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于如何使用Spotlight **训练声学事件检测** **系统**的教程：[**博客**](https://renumics.com/blog/acoustic-event-detection-annotation)
- en: 'The **official 🤗 audio course**: [**Introduction**](https://huggingface.co/learn/audio-course/chapter0/introduction)
    & [**Fine-Tuning**](https://huggingface.co/learn/audio-course/chapter4/fine-tuning)'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**官方 🤗 音频课程**: [**介绍**](https://huggingface.co/learn/audio-course/chapter0/introduction)
    & [**微调**](https://huggingface.co/learn/audio-course/chapter4/fine-tuning)'
- en: Thanks for reading! My name is [Marius Steger](https://www.linkedin.com/in/marius-steger/),
    I’m a Machine Learning Engineer @[Renumics](https://renumics.com/) — We have developed
    [Spotlight](https://github.com/Renumics/spotlight), an Open Source tool that takes
    your data-centric AI workflow to the next level.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！我叫 [Marius Steger](https://www.linkedin.com/in/marius-steger/)，是[Renumics](https://renumics.com/)的机器学习工程师——我们开发了[Spotlight](https://github.com/Renumics/spotlight)，一款开源工具，能够将您的数据驱动AI工作流提升到一个新的水平。
- en: '![](../Images/cc655344170c51a9f0d18fa1a30b1164.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc655344170c51a9f0d18fa1a30b1164.png)'
- en: References
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Yuan Gong, Yu-An Chung, James Glass: [AST: Audio Spectrogram Transformer](https://arxiv.org/abs/2104.01778)
    (2021), arxiv'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Yuan Gong, Yu-An Chung, James Glass: [AST：音频谱图转换器](https://arxiv.org/abs/2104.01778)
    (2021), arxiv'
- en: '[2] Piczak, Karol J.: [ESC: Dataset for Environmental Sound Classification](https://dl.acm.org/doi/10.1145/2733373.2806390)
    (2015), ACM Press'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Piczak, Karol J.: [ESC：环境声音分类数据集](https://dl.acm.org/doi/10.1145/2733373.2806390)
    (2015), ACM出版社'
