- en: Detecting Insecure Code with LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLM检测不安全代码
- en: 原文：[https://towardsdatascience.com/detecting-insecure-code-with-llms-8b8ad923dd98?source=collection_archive---------1-----------------------#2024-03-21](https://towardsdatascience.com/detecting-insecure-code-with-llms-8b8ad923dd98?source=collection_archive---------1-----------------------#2024-03-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/detecting-insecure-code-with-llms-8b8ad923dd98?source=collection_archive---------1-----------------------#2024-03-21](https://towardsdatascience.com/detecting-insecure-code-with-llms-8b8ad923dd98?source=collection_archive---------1-----------------------#2024-03-21)
- en: Prompt Experiments for Python Vulnerability Detection
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python漏洞检测的提示实验
- en: '[](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)[![Melanie
    Hart Buehler](../Images/31d0da632d6b3b3c705f1cc56f6c3783.png)](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)
    [Melanie Hart Buehler](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)[![Melanie
    Hart Buehler](../Images/31d0da632d6b3b3c705f1cc56f6c3783.png)](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)
    [Melanie Hart Buehler](https://medium.com/@melanie.h.buehler?source=post_page---byline--8b8ad923dd98--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)
    ·11 min read·Mar 21, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--8b8ad923dd98--------------------------------)
    ·阅读时间：11分钟·2024年3月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e03e54451244164d7c8cc26b0ce1af50.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e03e54451244164d7c8cc26b0ce1af50.png)'
- en: Photo by [Alexander Sinn](https://unsplash.com/@swimstaralex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Alexander Sinn](https://unsplash.com/@swimstaralex?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: If you are a software professional, you might dread opening the [security scan
    report](https://owasp.org/www-community/Vulnerability_Scanning_Tools) on the morning
    of a release. Why? You know that it’s a great tool for enhancing the quality and
    integrity of your work, but you also know you are going to spend the next couple
    of hours scrambling to resolve all the security issues before the deadline. If
    you are lucky, many issues will be false alarms, but you will have to manually
    verify the status of each one and quickly patch the rest after the code has been
    finalized. If you’ve experienced this, you’ve likely wished for a smoother, less
    ad-hoc process for identifying, triaging, and fixing the vulnerabilities in your
    code base. The good news is that recent studies have demonstrated that large language
    models (LLMs) can proficiently classify code as secure or insecure, explain the
    weaknesses, and even propose corrective changes. This has the potential to significantly
    streamline secure coding practices beyond the traditional static scans.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名软件专业人士，你可能会害怕在发布的早晨打开[安全扫描报告](https://owasp.org/www-community/Vulnerability_Scanning_Tools)。为什么？你知道这是一个增强你工作质量和完整性的好工具，但你也知道，在截止日期之前，你将花费接下来的几个小时争分夺秒地解决所有安全问题。如果你幸运的话，很多问题将是虚惊一场，但你仍然需要手动验证每个问题的状态，并在代码定稿后迅速修复其余问题。如果你经历过这种情况，你可能会希望有一个更顺畅、少些临时应对的流程来识别、分类和修复代码库中的漏洞。好消息是，最近的研究表明，大型语言模型（LLM）可以熟练地将代码分类为安全或不安全，解释其弱点，甚至提出修正建议。这有可能显著简化安全编码实践，超越传统的静态扫描方法。
- en: This article presents a short review of some recent findings in vulnerability
    detection and repair with LLMs and then dives into some experiments assessing
    GPT4’s ability to identify insecure code in a Python dataset using different prompting
    techniques. If you want to explore the Jupyter notebook or test your own code,
    head over to the [pull request](https://github.com/openai/openai-cookbook/pull/1112)
    in OpenAI Cookbook (currently under review).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文简要回顾了一些最近在漏洞检测和修复方面的发现，特别是LLMs的应用，接着深入探讨了几项实验，评估GPT-4在使用不同提示技术时，在Python数据集上识别不安全代码的能力。如果你想探索Jupyter笔记本或测试你自己的代码，可以访问OpenAI
    Cookbook中的[拉取请求](https://github.com/openai/openai-cookbook/pull/1112)（当前正在审查中）。
- en: Before we get started prompting GPT4, there are a few key concepts and definitions
    that will help build the foundation we need to design logical experiments.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始提示GPT-4之前，有一些关键概念和定义将帮助我们建立设计逻辑实验所需的基础。
- en: Common Weakness Enumeration
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见弱点枚举（CWE）
- en: 'In 2006, the government-funded research organization [MITRE](https://www.mitre.org/)
    started regularly publishing the [Common Weakness Enumeration (CWE)](https://cwe.mitre.org/),
    which is a community-developed common taxonomy of software and hardware weakness
    definitions and descriptions. A “weakness”, in this sense, is a condition in software
    or hardware that can lead to vulnerabilities. A list of the [2023 Top 25 Most
    Dangerous CWEs](https://cwe.mitre.org/top25/) highlights the biggest repeat offenders.
    There is another list of [15 “Stubborn” CWEs](https://cwe.mitre.org/top25/archive/2023/2023_stubborn_weaknesses.html)
    that have been present on every Top 25 list from 2019–2023\. They can be divided
    roughly into three groups:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，政府资助的研究组织[MITRE](https://www.mitre.org/)开始定期发布[常见弱点枚举（CWE）](https://cwe.mitre.org/)，这是一个由社区开发的软硬件弱点定义和描述的通用分类法。在这个意义上，“弱点”指的是软件或硬件中的一种情况，可能导致漏洞。一个[2023年最危险的前25个CWE](https://cwe.mitre.org/top25/)的列表突出了最大的重复犯规者。还有一个[15个“顽固”CWE](https://cwe.mitre.org/top25/archive/2023/2023_stubborn_weaknesses.html)的列表，这些CWE自2019年至2023年每年都出现在前25个列表中。它们大致可以分为三组：
- en: '**Group 1**: Weak handling of untrusted data sources (e.g. Command/SQL Injection,
    Path Traversal, Improper Input Validation, and Cross-site Scripting)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第1组**：对不可信数据源的薄弱处理（例如命令/SQL注入、路径遍历、不当输入验证和跨站脚本攻击）'
- en: '**Group 2**: Weak memory management or type enforcement (e.g. NULL Pointer
    Dereference)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第2组**：薄弱的内存管理或类型强制（例如NULL指针解引用）'
- en: '**Group 3**: Weak security design choices (e.g. Hard-coded Credentials)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第3组**：薄弱的安全设计选择（例如硬编码凭证）'
- en: To help keep the scope of the investigation narrow and well-defined, we will
    focus on the first group of CWEs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助保持调查范围狭窄且定义明确，我们将重点关注CWEs的第一组。
- en: Static Code Analysis
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态代码分析
- en: 'The conventional approach to automating the detection of insecure code involves
    the use of static analysis tools such as CodeQL, Bandit, SonarQube, Coverity,
    and Snyk. These tools can be employed at any time but are typically used to scan
    the code for vulnerabilities after the code-freeze stage and before the completion
    of formal release processes. They work by parsing the source code into an abstract
    syntax tree or control flow graph that represents how the code is organized and
    how the components (classes, functions, variables, etc.) all relate to each other.
    Rule-based analysis and pattern matching are then used to detect a wide range
    of issues. Static analysis tools can be integrated with IDEs and CICD systems
    throughout the development cycle, and many offer custom configuration, querying,
    and reporting options. They are very useful, but they have some drawbacks (in
    addition to those last-minute high-pressure bug fixing parties):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的自动化不安全代码检测方法涉及使用静态分析工具，如CodeQL、Bandit、SonarQube、Coverity和Snyk。这些工具可以随时使用，但通常用于在代码冻结阶段后、正式发布过程完成之前扫描代码中的漏洞。它们通过将源代码解析成抽象语法树或控制流图的方式工作，这些结构表示代码如何组织，以及各个组件（类、函数、变量等）之间的关系。然后，通过基于规则的分析和模式匹配来检测各种问题。静态分析工具可以在开发周期中与IDE和CICD系统集成，许多工具提供自定义配置、查询和报告选项。它们非常有用，但也有一些缺点（除了那些最后时刻的高压修复派对之外）：
- en: '**Resource-intensive**: They convert extensive codebases into databases to
    execute complex queries'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源密集型**：它们将大量代码库转换为数据库，以执行复杂查询'
- en: '**False positives**: They often include a high number of non-issues'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**：它们通常包含大量非问题项'
- en: '**Time-intensive follow-up**: Significant effort is required to validate and
    repair the issues'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间密集型的后续工作**：需要大量的努力来验证和修复这些问题'
- en: These limitations have understandably inspired researchers to explore new ways
    to enhance code security practices, such as generative AI.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些局限性无疑激发了研究人员探索新方法来增强代码安全实践，例如生成式AI。
- en: Previous Work
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 之前的工作
- en: Recent work has demonstrated the potential of LLMs across various stages of
    the development life cycle. LLMs have been shown to be useful for secure code
    completion, test case generation, vulnerable or malicious code detection, and
    bug fixing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的工作表明，LLM在开发生命周期的各个阶段具有潜力。LLM已被证明在安全代码补全、测试用例生成、易受攻击或恶意代码检测以及错误修复等方面非常有用。
- en: 'Here are a few references of note:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些值得注意的参考文献：
- en: A [comprehensive evaluation](https://arxiv.org/abs/2308.10345)¹ compared LLMs
    of different parameter sizes with traditional static analyzers in identifying
    and correcting software vulnerabilities. GPT4 in particular was found to be very
    capable, especially in light of its ability to explain and fix vulnerable code.
    Some additional claims from the paper — significant code understanding seems to
    emerge between 6 to 175 billion parameters, with the first hint of advanced programmer
    skills appearing beyond 13 billion parameters; prediction success may be boosted
    when prompts combine the tasks of identifying and fixing security issues together;
    LLMs combined with traditional static code analysis may offer the best of both
    worlds.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一项[综合评估](https://arxiv.org/abs/2308.10345)¹比较了不同参数规模的LLM与传统静态分析器在识别和修复软件漏洞方面的表现。特别是GPT-4表现出色，尤其在解释和修复易受攻击的代码方面。论文中还提出了一些额外的观点——显著的代码理解能力似乎出现在6到175亿个参数之间，而超过130亿参数时，才出现了高级程序员技能的初步迹象；当提示词同时包含识别和修复安全问题的任务时，预测成功率可能会提高；将LLM与传统静态代码分析结合使用，可能能够提供两者的最佳结合。
- en: A [novel study and dataset](https://arxiv.org/abs/2108.09293)² found that even
    advanced AI developer assistants are susceptible to writing insecure code and
    discovered that 40% of generated code completions contained CWEs.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一项[新研究和数据集](https://arxiv.org/abs/2108.09293)²发现，即使是高级的AI开发助手也容易编写不安全的代码，并且发现40%的生成代码补全包含了CWE（通用弱点枚举）。
- en: An [investigation](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)³
    reported that GPT3 outperformed a modern static code analyzer in predicting security
    vulnerabilities.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一项[调查](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)³报告称，GPT-3在预测安全漏洞方面超过了现代静态代码分析器。
- en: A [research paper](https://arxiv.org/abs/2308.14434)⁴ showed that LLMs can assist
    developers in identifying and localizing vulnerable code, particularly when combined
    with static analyzers.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一篇[研究论文](https://arxiv.org/abs/2308.14434)⁴表明，LLM可以帮助开发者识别和定位易受攻击的代码，尤其是当与静态分析器结合使用时。
- en: In [another study](https://arxiv.org/abs/2112.02125)⁵, LLMs successfully fixed
    all synthetic and hand-crafted scenarios, although they did not adequately address
    all real-world security bug scenarios.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[另一项研究](https://arxiv.org/abs/2112.02125)⁵中，LLM（大语言模型）成功修复了所有合成的和手工制作的场景，尽管它们并未充分解决所有现实世界中的安全漏洞问题。
- en: While LLMs have shown promise in outperforming traditional approaches, many
    of these works point out that they are also susceptible to false positives and
    sensitive to the structure and wording of prompts. In our experiments, we aim
    to validate and build upon these results by applying more variations to the prompt
    template.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM在超越传统方法方面展现了潜力，但许多研究指出，它们也容易产生误报，并且对提示的结构和措辞非常敏感。在我们的实验中，我们旨在通过对提示模板进行更多变体的应用，来验证并进一步扩展这些结果。
- en: Data Source and Preprocessing
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据来源与预处理
- en: 'We will draw from one of the most widely-adopted datasets for secure code benchmarking
    of LLMs. The [dataset](https://doi.org/10.5281/zenodo.5225651) (with license [CC
    BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode)) from [Asleep at
    the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions](https://arxiv.org/abs/2108.09293)²
    is made up of prompts called “scenarios” that were hand-designed to elicit certain
    CWEs when used as input to a code-generating LLM. We have mined the output code
    completions that were included with the publication, since they were subsequently
    scanned by a static code analyzer and come with labels of “Vulnerable” and “Not
    Vulnerable”. It should be noted, again, that the code in this dataset is model-generated
    from manually written prompts, so it lacks some real-world gravitas, but we chose
    it for a few reasons:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个最广泛采用的数据集之一来进行LLM的安全代码基准测试。[数据集](https://doi.org/10.5281/zenodo.5225651)（许可[CC
    BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode)）来自[《键盘上睡着了吗？评估GitHub
    Copilot的代码贡献安全性》](https://arxiv.org/abs/2108.09293)²，该数据集由名为“场景”的提示组成，这些提示是手工设计的，用于在作为输入提供给代码生成LLM时引出特定的CWE。我们从出版物中挖掘了包括的输出代码补全，因为它们随后被静态代码分析工具扫描，并带有“易受攻击”和“非易受攻击”的标签。需要再次注意的是，这些数据集中的代码是从手动编写的提示中由模型生成的，因此缺乏一些现实世界的严肃性，但我们选择它有几个原因：
- en: It has a large number of Python examples, which is the language of choice for
    this study
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它包含大量的Python示例，而Python是本研究中首选的编程语言。
- en: It has both vulnerable and non-vulnerable code examples, which is important
    for assessing both false positives and false negatives
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它包含易受攻击和非易受攻击的代码示例，这对于评估假阳性和假阴性都非常重要。
- en: Related to (2), the fact that there are vulnerable and non-vulnerable code snippets
    for the same scenario means we can use the non-vulnerable completions as “suggested
    fixes” in some of the prompts, which will be explained in the relevant experiment
    section
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与（2）相关的是，针对同一场景存在易受攻击和非易受攻击的代码片段，这意味着我们可以将非易受攻击的代码补全作为某些提示中的“建议修复”，这一点将在相关的实验部分进行解释。
- en: We understand that there are other datasets we could have used, and it is left
    for further research to explore CWE prediction capability with other data sources,
    too.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理解，实际上还有其他数据集可以使用，并且这也留待未来的研究来探索使用其他数据源进行CWE预测的能力。
- en: 'The Python code snippets from the [Copilot Scenario raw data files](https://doi.org/10.5281/zenodo.5225650)²
    were preprocessed with the following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[Copilot场景原始数据文件](https://doi.org/10.5281/zenodo.5225650)²的Python代码片段经过以下步骤的预处理：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data Exploration and Subsetting
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据探索与子集化
- en: 'We explored the distribution of CWEs and selected a sample of size 45 spread
    evenly over vulnerable and non-vulnerable codes from the Group 1 CWEs (we targeted
    a sample size of 50 but were limited by the number available in one of the groups).
    The CWE descriptions are:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了CWE的分布，并从第1组CWE中均匀选择了45个样本，涵盖易受攻击和非易受攻击的代码（我们计划的样本量是50，但由于其中一个组的数量有限，最终选择了45个样本）。CWE描述如下：
- en: '**CWE-20**: Improper Input Validation'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CWE-20**：输入验证不当'
- en: '**CWE-22**: Improper Limitation of a Pathname to a Restricted Directory (‘Path
    Traversal’)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CWE-22**：路径名限制不当，导致限制目录（“路径遍历”）'
- en: '**CWE-78**: Improper Neutralization of Special Elements used in an OS Command
    (‘OS Command Injection’)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CWE-78**：操作系统命令中使用的特殊元素未正确中和（“操作系统命令注入”）'
- en: '**CWE-79**: Improper Neutralization of Input During Web Page Generation (‘Cross-site
    Scripting’)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CWE-79**：网页生成时输入未正确中和（“跨站脚本攻击”）'
- en: '**CWE-502**: Deserialization of Untrusted Data'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CWE-502**：反序列化不可信数据'
- en: We began with a zero-shot baseline run and then repeated the experiment a few
    more times building the complexity of the prompt by adding strategies like few-shot
    in-context learning. We prompted the LLM to identify vulnerable code with no mention
    of which CWE it might be looking for (i.e. without labels).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从零-shot基准测试开始，然后重复进行实验，通过增加像few-shot上下文学习这样的策略来构建提示的复杂性。我们提示LLM识别易受攻击的代码，而没有提及可能寻找的CWE（即没有标签）。
- en: 'Experiment 1: Zero-shot'
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验1：零-shot
- en: In a zero-shot prompt, you ask the model to make a prediction with no example
    or information other than instructions. Our zero-shot template was inspired by
    [this paper](https://arxiv.org/abs/2308.14434)⁴ and includes a role, code delimiter,
    and the request to output json format only. It also includes an instruction to
    [“think step-by-step”](https://arxiv.org/abs/2205.11916). The code snippet under
    test is inserted into {code}.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在零-shot提示中，您要求模型在没有示例或其他信息的情况下，仅凭指令做出预测。我们的零-shot模板灵感来自于[这篇论文](https://arxiv.org/abs/2308.14434)⁴，包含了角色、代码分隔符，并要求仅输出json格式。它还包括了[“一步步思考”](https://arxiv.org/abs/2205.11916)的指令。测试中的代码片段被插入到{code}中。
- en: '**Prompt**'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提示**'
- en: '[PRE1]{code}[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE1]{code}[PRE2]'
- en: '**Results**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'Accuracy: 0.67'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率：0.67
- en: 'Precision: 0.60'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度：0.60
- en: 'Recall: 0.86'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率：0.86
- en: 'F1 Score: 0.71'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: F1得分：0.71
- en: '![](../Images/acb17591c7e4b4c6a46a57636647a638.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acb17591c7e4b4c6a46a57636647a638.png)'
- en: Zero-shot Confusion Matrix
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot混淆矩阵
- en: 'Experiment 2: Few-shot'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验2：少量学习
- en: 'In the next experiment, we add the concept of in-context or [“few-shot” learning](https://arxiv.org/abs/2005.14165)
    and include a few successful code-answer examples before asking the LLM to perform
    the same operation on the unseen code. These examples were constructed from the
    remainder of the dataset and care was taken to:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个实验中，我们引入了上下文或[“少量学习”](https://arxiv.org/abs/2005.14165)的概念，并在要求LLM对未见过的代码执行相同操作之前，提供了几个成功的代码-答案示例。这些示例来自数据集的其余部分，并特别注意：
- en: Draw from different scenarios than the code snippet under test, to avoid contamination
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从不同的场景中选取示例，以避免污染
- en: Draw exactly two vulnerable examples and one non-vulnerable example
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确绘制两个易受攻击的示例和一个非易受攻击的示例
- en: '**Prompt**'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提示**'
- en: '[PRE3]{example_0}[PRE4]{example_1}[PRE5]{example_2}[PRE6]{code}[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE3]{example_0}[PRE4]{example_1}[PRE5]{example_2}[PRE6]{code}[PRE7]'
- en: '**Results**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'Accuracy: 0.76'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率：0.76
- en: 'Precision: 0.71'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度：0.71
- en: 'Recall: 0.81'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率：0.81
- en: 'F1 Score: 0.76'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: F1得分：0.76
- en: '![](../Images/ad0fc6f78f1872b89105b760a3bae4da.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad0fc6f78f1872b89105b760a3bae4da.png)'
- en: Few-shot Confusion Matrix
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 少量学习混淆矩阵
- en: 'Experiment 3: KNN Few-shot'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验3：KNN少量学习
- en: This [Microsoft blog post](https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/)
    describes an interesting technique called KNN-based few-shot example selection
    that can boost LLM response quality when using in-context examples. For this next
    experiment, instead of sampling shots at random, we calculate a similarity score
    between the input code and each candidate example and construct shots from the
    most similar candidates (still keeping the scenarios distinct). We use the ROUGE-L
    metric, but other metrics could be used too. The prompt template did not change
    from the second experiment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇[微软博客文章](https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/)描述了一种有趣的技术，叫做基于KNN的少量示例选择，它可以提升使用上下文示例时LLM的响应质量。在接下来的实验中，我们不再随机选择示例，而是计算输入代码与每个候选示例之间的相似度得分，并从最相似的候选中构建示例（同时保持场景的独特性）。我们使用ROUGE-L指标，但也可以使用其他指标。提示模板与第二个实验中保持一致。
- en: '**Results**'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'Accuracy: 0.73'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率：0.73
- en: 'Precision: 0.70'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度：0.70
- en: 'Recall: 0.76'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率：0.76
- en: 'F1 Score: 0.73'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: F1得分：0.73
- en: '![](../Images/d9ee2ba95807f183f34106c35f85e802.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9ee2ba95807f183f34106c35f85e802.png)'
- en: KNN Few-shot Confusion Matrix
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: KNN少量学习混淆矩阵
- en: 'Experiment 4: KNN Few-shot with Code Fix'
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验4：KNN少量学习与代码修复
- en: In this variation of the prompt, we include a request for a fixed version of
    the code if a CWE is found. This approach was inspired by [Noever](https://arxiv.org/abs/2308.10345),
    who proposed that prompting for CWE detection and a fix together might bring about
    a “virtuous cycle” and force the LLM to “self-audit” or think more deeply about
    the steps needed to accurately identify vulnerabilities, similar to chain-of-thought
    prompting. We did this by constructing vulnerable code in-context examples with
    code fix suggestions drawn from the non-vulnerable code samples for the same scenarios.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种提示的变体中，我们要求提供一个修正后的代码版本，如果发现CWE。这一方法灵感来自于[Noever](https://arxiv.org/abs/2308.10345)，他提出通过同时提示CWE检测和修复可能会产生“良性循环”，并迫使LLM进行“自我审计”或更深入地思考准确识别漏洞所需的步骤，类似于链式思维提示。我们通过构建包含代码修复建议的易受攻击代码上下文示例，且修复建议来自于相同场景下的非易受攻击代码样本。
- en: '**Prompt**'
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提示**'
- en: '[PRE8]{example_0}[PRE9]{example_1}[PRE10]{example_2}[PRE11]{code}[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE8]{example_0}[PRE9]{example_1}[PRE10]{example_2}[PRE11]{code}[PRE12]'
- en: '**Results**'
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: 'Accuracy: 0.80'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率：0.80
- en: 'Precision: 0.73'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度：0.73
- en: 'Recall: 0.90'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率：0.90
- en: 'F1 Score: 0.81'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: F1得分：0.81
- en: '![](../Images/94c581af5e970a06d8ffa5d198286554.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94c581af5e970a06d8ffa5d198286554.png)'
- en: KNN Few-shot Fix Confusion Matrix
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 少量示例修复混淆矩阵
- en: In addition to CWE detection, this experiment has the benefit of producing suggested
    fixes. We have not evaluated them for quality yet, so that is an area for future
    work.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 除了CWE检测外，这个实验的一个优势是能够生成修复建议。我们尚未评估这些建议的质量，因此这是未来研究的一个方向。
- en: Results and Next Steps
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果与后续步骤
- en: '![](../Images/e74a694b2198e10dd9518e1415ce4363.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e74a694b2198e10dd9518e1415ce4363.png)'
- en: On our small data sample, GPT4’s accuracy was 67% and its F1 score was 71% without
    any complex prompt adaptations. Small improvements were offered by some of the
    prompting techniques we tested, with few-shot and requesting a code fix standing
    out. The combination of techniques bumped accuracy and F1 score by about ten percentage
    points each from baseline, both metrics reaching or exceeding 80%.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的小数据样本上，GPT4的准确率为67%，F1得分为71%，并未进行复杂的提示调整。一些我们测试的提示技术带来了一些小幅提升，其中少量示例和请求代码修复的效果最为突出。不同提示技术的组合使得准确率和F1得分从基线提高了大约十个百分点，两个指标均达到或超过80%。
- en: 'Results can be quite different between models, datasets, and prompts, so more
    investigation is needed. For example, it would be interesting to:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 结果在不同模型、数据集和提示之间可能会有很大差异，因此需要更多的调查。例如，以下问题会很有趣：
- en: Test smaller models
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试较小的模型
- en: Test a prompt template that includes the CWE label, to investigate the potential
    for combining LLMs with static analysis
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试包含CWE标签的提示模板，探讨将LLMs与静态分析相结合的潜力
- en: Test larger and more diverse datasets
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试更大且更具多样性的数据集
- en: Evaluate the security and functionality of LLM-proposed code fixes
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估LLM提议的代码修复的安全性和功能性
- en: Study more advanced prompting techniques such as in-context example chains-of-thought,
    [Self-Consistency](https://arxiv.org/abs/2203.11171), and [Self-Discover](https://arxiv.org/abs/2402.03620)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究更高级的提示技术，例如上下文示例链式思考、[自一致性](https://arxiv.org/abs/2203.11171)和[自发现](https://arxiv.org/abs/2402.03620)
- en: If you would like to see the code that produced these results, run it on your
    own code, or adapt it for your own needs, check out the [pull request](https://github.com/openai/openai-cookbook/pull/1112)
    in OpenAI Cookbook (currently under review).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看生成这些结果的代码，自己在代码中运行它，或根据自己的需求进行修改，可以查看OpenAI Cookbook中的[拉取请求](https://github.com/openai/openai-cookbook/pull/1112)（当前正在审核中）。
- en: Thank you to my colleagues [Matthew Fleetwood](https://github.com/etcylfleet)
    and [Abolfazl Shahbazi](https://github.com/ashahba) who made contributions and
    helped to review this article.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我的同事[Matthew Fleetwood](https://github.com/etcylfleet)和[Abolfazl Shahbazi](https://github.com/ashahba)，他们为这篇文章做出了贡献并帮助进行审阅。
- en: Citations
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引用
- en: '[1] D. Noever, [Can Large Language Models Find And Fix Vulnerable Software?](https://arxiv.org/abs/2308.10345)
    (2023), arXiv preprint arXiv:2308.10345'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] D. Noever, [大型语言模型能否发现并修复易受攻击的软件？](https://arxiv.org/abs/2308.10345) (2023),
    arXiv 预印本 arXiv:2308.10345'
- en: '[2] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt and R. Karri, [Asleep at the
    Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions](https://arxiv.org/abs/2108.09293)
    (2022), 2022 IEEE Symposium on Security and Privacy (SP)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt 和 R. Karri, [在键盘上睡着了吗？评估GitHub
    Copilot的代码贡献的安全性](https://arxiv.org/abs/2108.09293) (2022), 2022 IEEE安全与隐私研讨会
    (SP)'
- en: '[3] C. Koch, [I Used GPT-3 to Find 213 Security Vulnerabilities in a Single
    Codebase](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)
    (2023), [https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] C. Koch, [我使用GPT-3在单一代码库中发现213个安全漏洞](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)
    (2023), [https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411)'
- en: '[4] A. Bakhshandeh, A. Keramatfar, A. Norouzi and M. M. Chekidehkhoun, [Using
    ChatGPT as a Static Application Security Testing Tool](https://arxiv.org/abs/2308.14434)
    (2023), arXiv preprint arXiv:2308.14434'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] A. Bakhshandeh, A. Keramatfar, A. Norouzi 和 M. M. Chekidehkhoun, [将ChatGPT用作静态应用程序安全测试工具](https://arxiv.org/abs/2308.14434)
    (2023), arXiv 预印本 arXiv:2308.14434'
- en: '[5] H. Pearce, B. Tan, B. Ahmad, R. Karri and B. Dolan-Gavitt, [Examining Zero-Shot
    Vulnerability Repair with Large Language Models](https://arxiv.org/abs/2112.02125)
    (2023), 2023 IEEE Symposium on Security and Privacy (SP)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] H. Pearce, B. Tan, B. Ahmad, R. Karri 和 B. Dolan-Gavitt, [使用大型语言模型进行零-shot漏洞修复研究](https://arxiv.org/abs/2112.02125)
    (2023), 2023 IEEE安全与隐私研讨会 (SP)'
