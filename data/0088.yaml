- en: Advanced Query Transformations to Improve RAG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高RAG的高级查询转换
- en: 原文：[https://towardsdatascience.com/advanced-query-transformations-to-improve-rag-11adca9b19d1?source=collection_archive---------1-----------------------#2024-01-10](https://towardsdatascience.com/advanced-query-transformations-to-improve-rag-11adca9b19d1?source=collection_archive---------1-----------------------#2024-01-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/advanced-query-transformations-to-improve-rag-11adca9b19d1?source=collection_archive---------1-----------------------#2024-01-10](https://towardsdatascience.com/advanced-query-transformations-to-improve-rag-11adca9b19d1?source=collection_archive---------1-----------------------#2024-01-10)
- en: Different approaches to query transformations
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同的查询转换方法
- en: '[](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)[![Iulia
    Brezeanu](../Images/f108eeec620ec9be40778dfaceca4e6c.png)](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)
    [Iulia Brezeanu](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)[![Iulia
    Brezeanu](../Images/f108eeec620ec9be40778dfaceca4e6c.png)](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)
    [Iulia Brezeanu](https://medium.com/@brezeanu.iulia?source=post_page---byline--11adca9b19d1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)
    ·9 min read·Jan 10, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--11adca9b19d1--------------------------------)
    ·9分钟阅读·2024年1月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/cf4e4da93073fd715a90c9c13ea7b63f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf4e4da93073fd715a90c9c13ea7b63f.png)'
- en: Image by author. AI Generated.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者。AI生成。
- en: Retrieval augmented generation has become one of the most discussed topics in
    generative AI literature. With the daily influx of blog articles and scientific
    papers, it can be challenging to stay updated. However, the popularity of RAG
    is well-deserved, as no other solution has proven as efficient for mitigating
    hallucinations in large language models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）已成为生成性AI文献中讨论最热的话题之一。随着每日涌现的大量博客文章和科学论文，保持更新变得越来越具有挑战性。然而，RAG的流行是当之无愧的，因为没有其他解决方案在减少大型语言模型的幻觉方面表现得如此高效。
- en: RAG enhances a language model’s general knowledge with reliable external sources
    like Wikipedia pages, private PDFs, etc. That’s why the most important step for
    RAG is to ensure that our retrieval finds the right documents to feed into the
    model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: RAG通过可靠的外部来源（如Wikipedia页面、私人PDF文件等）增强语言模型的通用知识。这也是RAG最重要的一步：确保我们的检索能够找到正确的文档并将其输入模型。
- en: We need RAG so much because we currently face limitations in fitting full documents
    into the context window. Reasons include restricted token length for model inputs,
    the proportional increase in computational cost, and issues like “lost in the
    middle” which refers to a phenomenon where models struggle to use information
    found in the middle of a long input context [2].
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常需要RAG，因为目前我们在将完整文档放入上下文窗口时面临一些限制。原因包括模型输入的令牌长度限制、计算成本的成比例增加，以及像“丢失在中间”这样的现象，指的是模型在处理长输入上下文时难以使用位于中间的信息[2]。
- en: '![](../Images/a088679fba8583bc205a0fcab1600398.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a088679fba8583bc205a0fcab1600398.png)'
- en: Relationship between model performance and the position of the relevant information
    in the context window.[2]
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能与上下文窗口中相关信息位置之间的关系。[2]
- en: If the retrieved documents are too long or irrelevant, as the saying goes, garbage
    in…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检索到的文档过长或不相关，正如俗话所说，垃圾进……
