- en: Comparison of Methods to Inform K-Means Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于指导K-Means聚类的方法比较
- en: 原文：[https://towardsdatascience.com/comparison-of-methods-to-inform-k-means-clustering-a830cdc8db50?source=collection_archive---------3-----------------------#2024-03-04](https://towardsdatascience.com/comparison-of-methods-to-inform-k-means-clustering-a830cdc8db50?source=collection_archive---------3-----------------------#2024-03-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/comparison-of-methods-to-inform-k-means-clustering-a830cdc8db50?source=collection_archive---------3-----------------------#2024-03-04](https://towardsdatascience.com/comparison-of-methods-to-inform-k-means-clustering-a830cdc8db50?source=collection_archive---------3-----------------------#2024-03-04)
- en: A Brief Tutorial
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简短教程
- en: '[](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)[![Chris
    Taylor](../Images/a5a0b096777cc262cc5adc3350fadab4.png)](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)
    [Chris Taylor](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)[![Chris
    Taylor](../Images/a5a0b096777cc262cc5adc3350fadab4.png)](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)
    [Chris Taylor](https://medium.com/@cjtayl2?source=post_page---byline--a830cdc8db50--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)
    ·12 min read·Mar 4, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--a830cdc8db50--------------------------------)
    ·12分钟阅读·2024年3月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/43b07d07fdaae134bb91af08c2cb97e1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43b07d07fdaae134bb91af08c2cb97e1.png)'
- en: Photo by [Nabeel Hussain](https://unsplash.com/@nabeelhussainphotos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片来自[Nabeel Hussain](https://unsplash.com/@nabeelhussainphotos?utm_source=medium&utm_medium=referral)，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: K-Means is a popular unsupervised algorithm for clustering tasks. Despite its
    popularity, it can be difficult to use in some contexts due to the requirement
    that the number of clusters (or k) be chosen before the algorithm has been implemented.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means是一种流行的无监督学习算法，常用于聚类任务。尽管它很受欢迎，但在某些情况下使用起来可能会很困难，因为需要在算法实现之前选择聚类的数量（或k值）。
- en: Two quantitative methods to address this issue are the elbow plot and the silhouette
    score. Some authors regard the elbow plot as “coarse” and recommend data scientists
    use the silhouette score [1]. Although general advice is useful in many situations,
    it is best to evaluate problems on a case-by-case basis to determine what is best
    for the data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 两种定量方法可以解决这个问题，分别是肘部法和轮廓系数。某些作者认为肘部法“粗糙”，并建议数据科学家使用轮廓系数[1]。尽管一般性的建议在许多情况下是有用的，但最好还是根据具体情况评估问题，找出最适合数据的解决方法。
- en: The purpose of this article is to provide a tutorial on how to implement k-means
    clustering using an elbow plot and silhouette score and how to evaluate their
    performance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的是提供一个教程，讲解如何使用肘部法和轮廓系数实现k-means聚类，并评估其性能。
- en: 'A Google Colab notebook containing the code reviewed in this article can be
    accessed through the following link:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章中审阅的代码可以通过以下链接访问，链接是一个Google Colab笔记本：
- en: '[https://colab.research.google.com/drive/1saGoBHa4nb8QjdSpJhhYfgpPp3YCbteU?usp=sharing](https://colab.research.google.com/drive/1saGoBHa4nb8QjdSpJhhYfgpPp3YCbteU?usp=sharing)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://colab.research.google.com/drive/1saGoBHa4nb8QjdSpJhhYfgpPp3YCbteU?usp=sharing](https://colab.research.google.com/drive/1saGoBHa4nb8QjdSpJhhYfgpPp3YCbteU?usp=sharing)'
- en: '**Description of Data**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据描述**'
- en: The Seeds dataset was originally published in a study by Charytanowiscz et al.
    [2] and can be accessed through the following link [https://archive.ics.uci.edu/dataset/236/seeds](https://archive.ics.uci.edu/dataset/236/seeds)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Seeds数据集最初由Charytanowiscz等人[2]在一项研究中发布，并可以通过以下链接访问：[https://archive.ics.uci.edu/dataset/236/seeds](https://archive.ics.uci.edu/dataset/236/seeds)
- en: The dataset is comprised of 210 entries and eight variables. One column contains
    information about a seed’s variety (i.e., 1, 2, or 3) and seven columns contain
    information about the geometric properties of the seeds. The properties include
    (a) area, (b) perimeter, (c) compactness, (d) kernel length, (e) kernel width,
    (f) asymmetry coefficient, and (g) kernel groove length.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含210个条目和八个变量。一列包含种子类别的信息（即1、2或3），七列包含关于种子几何属性的信息。这些属性包括（a）面积，（b）周长，（c）紧凑性，（d）种子长度，（e）种子宽度，（f）不对称系数，以及（g）种子沟槽长度。
- en: Before building the models, we’ll need to conduct an exploratory data analysis
    to ensure we understand the data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型之前，我们需要进行探索性数据分析，以确保我们理解数据。
- en: '**Exploratory Data Analysis**'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**探索性数据分析**'
- en: We’ll start by loading the data, renaming the columns, and setting the column
    containing seed variety to a categorical variable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从加载数据、重命名列并将包含种子种类的列设置为分类变量开始。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then we’ll display the structure of the dataframe and its descriptive statistics.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将展示数据框的结构及其描述性统计信息。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/c098de499eb25a79f86df3d96b6a08cd.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c098de499eb25a79f86df3d96b6a08cd.png)'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/214454cf04629a22934a5fdd37efa9c4.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/214454cf04629a22934a5fdd37efa9c4.png)'
- en: Fortunately, there are no missing data (which is rare when dealing with real-world
    data), so we can continue exploring the data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，没有缺失数据（这在处理实际数据时是罕见的），因此我们可以继续探索数据。
- en: An imbalanced dataset can affect quality of clusters, so let’s check how many
    instances we have from each variety of seed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不平衡的数据集可能会影响聚类的质量，因此让我们检查一下每种种子类别的实例数量。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Based on the output of the code, we can see that we are working with a balanced
    dataset. Specifically, the dataset is comprised of 70 seeds from each group.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 根据代码的输出，我们可以看到我们正在处理一个平衡的数据集。具体来说，数据集由每个组的70个种子组成。
- en: A useful visualization used during EDAs is the histogram since it can be used
    to determine the distribution of the data and detect the presence of skew. Since
    there are three varieties of seeds in the dataset, it might be beneficial to plot
    the distribution of each numeric variable grouped by the variety.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索性数据分析中，常用的可视化方法是直方图，因为它可以用来确定数据的分布情况，并检测是否存在偏态。由于数据集中有三种种子，因此绘制每个数值变量按种类分组的分布可能会很有帮助。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/3cfd7bc123a323e0d07ba844a3a6eee1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cfd7bc123a323e0d07ba844a3a6eee1.png)'
- en: One example of the histograms generated by the code
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码生成的直方图示例之一。
- en: From this plot, we can see there is some skewness in the data. To provide a
    more precise measure of skewness, we can used the `skew()` method.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中，我们可以看到数据存在一定的偏态。为了更精确地衡量偏态程度，我们可以使用`skew()`方法。
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Although there is some skewness in the data, none of the individual values appear
    to be extremely high (i.e., absolute values greater than 1), therefore, a transformation
    is not necessary at this time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据中存在一定的偏态，但没有任何单独的值显得非常高（即绝对值大于1），因此目前不需要进行数据转换。
- en: Correlated features can affect the k-means algorithm, so we’ll generate a heat
    map of correlations to determine if the features in the dataset are associated.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 相关特征可能会影响k均值算法，因此我们将生成一个相关性热图，来确定数据集中的特征是否相关。
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/eea20683301b97698f7531623509f242.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eea20683301b97698f7531623509f242.png)'
- en: There are strong (0.60 ≤ ∣*r*∣ <0.80) and very strong (0.80 ≤ ∣*r*∣ ≤ 1.00)
    correlations between some of the variables; however, the principal component analysis
    (PCA) we will conduct will address this issue.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变量之间存在强（0.60 ≤ ∣*r*∣ <0.80）和非常强（0.80 ≤ ∣*r*∣ ≤ 1.00）的相关性；然而，我们将进行的主成分分析（PCA）将解决这个问题。
- en: '**Data Preparation**'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据准备**'
- en: Although we won’t use them in the k-means algorithm, the Seeds dataset contains
    labels (i.e., ‘variety’ column). This information will be useful when we evaluate
    the performance of the implementations, so we’ll set it aside for now.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在k均值算法中不会使用这些标签，种子数据集包含标签（即“种类”列）。这些信息将在我们评估实现的性能时非常有用，因此我们暂时将其放置一旁。
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Before entering the data into the k-means algorithm, we’ll need to scale the
    data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据输入到k均值算法之前，我们需要对数据进行缩放。
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After scaling the data, we’ll conduct PCA to reduce the dimensions of the data
    and address the correlated variables we identified earlier.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在对数据进行缩放后，我们将进行主成分分析（PCA），以减少数据的维度并处理我们之前识别出的相关变量。
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The output of the code indicates that one dimension accounts for 72% of the
    variance, two dimensions accounts for 89% of the variance, and three dimensions
    accounts for 99% of the variance. To confirm the correct number of dimensions
    were retained, use the code below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出显示，第一维度解释了72%的方差，第二维度解释了89%的方差，第三维度解释了99%的方差。为了确认保留了正确的维度数量，可以使用以下代码。
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now the data are ready to be inputted into the k-means algorithm. We’re going
    to examine two implementations of the algorithm — one informed by an elbow plot
    and another informed by the Silhouette Score.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经准备好输入到k-means算法中。我们将检查该算法的两种实现——一种是通过肘部图 informed，另一种是通过轮廓系数（Silhouette
    Score） informed。
- en: K-Means Informed by Elbow Plot
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于肘部图的K-Means
- en: 'To generate an elbow plot, use the code snippet below:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成肘部图，请使用以下代码片段：
- en: '[PRE15]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The number of clusters is displayed on the x-axis and the inertia is displayed
    on the y-axis. Inertia refers to the sum of squared distances of samples to their
    nearest cluster center. Basically, it is a measure of how close the data points
    are to the mean of their cluster (i.e., the centroid). When inertia is low, the
    clusters are more dense and defined clearly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的数量显示在x轴上，惯性显示在y轴上。惯性指的是样本到其最近簇中心的平方距离之和。基本上，它是衡量数据点与其簇的均值（即质心）之间的接近程度。当惯性较低时，簇更密集，定义更清晰。
- en: '![](../Images/6ebd812bbbd25f0fd53361595919966e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ebd812bbbd25f0fd53361595919966e.png)'
- en: When interpreting an elbow plot, look for the section of the line that looks
    similar to an elbow. In this case, the elbow is at three. When k = 1, the inertia
    will be large, then it will gradually decrease as k increases.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释肘部图时，注意寻找线条看起来像肘部的部分。在这种情况下，肘部位于3。当k=1时，惯性将很大，然后随着k的增大逐渐减小。
- en: The “elbow” is the point where the decrease begins to plateau and the addition
    of new clusters does not result in a significant decrease in inertia.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: “肘部”是指下降开始趋于平稳，并且添加新的簇不会导致惯性显著减少的点。
- en: Based on this elbow plot, the value of k should be three. Using an elbow plot
    has been described as more of an art than a science, which is why it has been
    referred to as “coarse”.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个肘部图，k的值应该是3。使用肘部图被描述为更多的是一种艺术而非科学，这就是为什么它被称为“粗略”的原因。
- en: To implement the k-means algorithm when k = 3, we’ll run the following code.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要在k=3时实现k-means算法，我们将运行以下代码。
- en: '[PRE16]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The code below can be used to visualize the output of k-means clustering informed
    by the elbow plot.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可用于可视化通过肘部图 informed 的k-means聚类输出。
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/56420e8bc22d373e3e8d3037a9f09a7e.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56420e8bc22d373e3e8d3037a9f09a7e.png)'
- en: Since the data were reduced to three dimensions, they are plotted on a 3D plot.
    To gain additional information about the clusters, we can use `countplot` from
    the `Seaborn` package.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据已被降至三维，它们被绘制在三维图中。为了获得有关簇的更多信息，我们可以使用`countplot`，这是`Seaborn`包中的一个函数。
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/cda60bea498cb8ae89672050712b6cbf.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cda60bea498cb8ae89672050712b6cbf.png)'
- en: Earlier, we determined that each group was comprised of 70 seeds. The data displayed
    in this plot indicate k-means implemented with the elbow plot *may* have performed
    moderately well since each count of each group is around 70; however, there are
    better ways to evaluate performance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 早些时候，我们确定每个组由70个种子组成。此图中显示的数据表明，基于肘部图实现的k-means*可能*表现中等良好，因为每个组的计数都接近70；然而，还有更好的方法来评估性能。
- en: 'To provide a more precise measure of how well the algorithm performed, we will
    use three metrics: (a) Davies-Bouldin Index, (b) Calinski-Harabasz Index, and
    (c) Adjusted Rand Index. We’ll talk about how to interpret them in the Results
    and Analysis section, but the following code snippet can be used to calculate
    their values.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更精确的衡量算法性能的指标，我们将使用三种指标：（a）Davies-Bouldin指数，（b）Calinski-Harabasz指数和（c）调整Rand指数。我们将在结果和分析部分讨论如何解释这些指标，但以下代码片段可用于计算它们的值。
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**K-Means Informed by Silhouette Score**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**基于轮廓系数的K-Means**'
- en: A silhouette score is the mean silhouette coefficient over all the instances.
    The values can range from -1 to 1, with
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓系数是所有实例的平均轮廓系数。其值范围从-1到1，其中
- en: 1 indicating an instance is well inside its cluster
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示一个实例位于其簇的中心区域
- en: 0 indicating an instance is close to its cluster’s boundary
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示一个实例接近其所在簇的边界
- en: -1 indicates the instance could be assigned to the incorrect cluster.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1表示该实例可能被分配到错误的簇中。
- en: When interpreting the silhouette score, we should choose the number of clusters
    with the highest score.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释轮廓得分时，我们应选择得分最高的聚类数。
- en: To generate a plot of silhouette scores for multiple values of k, we can use
    the following code.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成多种k值的轮廓得分图，我们可以使用以下代码。
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/f3a56a5f7129d2a3e95225518808a8b4.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3a56a5f7129d2a3e95225518808a8b4.png)'
- en: The data indicate that k should equal two.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 数据显示k应等于2。
- en: Using this information, we can implement the K-Means algorithm again.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些信息，我们可以重新实现K-Means算法。
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: To generate a plot of the algorithm when k = 2, we can use the code presented
    below.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成当k = 2时算法的图表，我们可以使用以下代码。
- en: '[PRE23]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/794d6fc3863c5bf01a24632194677896.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/794d6fc3863c5bf01a24632194677896.png)'
- en: Similar to the K-Means implementation informed by the elbow plot, additional
    information can be gleaned using `countplot`from `Seaborn`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于由肘部图指导的K-Means实现，通过`Seaborn`的`countplot`可以获得更多信息。
- en: '![](../Images/23e7a00c1dbe2bbe696b452033da1cff.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23e7a00c1dbe2bbe696b452033da1cff.png)'
- en: Based on our understanding of the dataset (i.e., it includes three varieties
    of seeds with 70 samples from each category), an initial reading of the plot *may*
    suggest that the implementation informed by the silhouette score did not perform
    as well on the clustering task; however, we cannot use this plot in isolation
    to make a determination.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们对数据集的理解（即它包含三种不同品种的种子，每个品种有70个样本），初步阅读该图可能会表明由轮廓得分指导的实现并未在聚类任务中表现得那么好；然而，我们不能仅凭这张图做出判断。
- en: To provide a more robust and detailed comparison of the implementations, we
    will calculate the three metrics that were used on the implementation informed
    by the elbow plot.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更全面和详细的实现比较，我们将计算用于由肘部图指导的实现的三种指标。
- en: '[PRE24]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**Results and Analysis**'
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结果与分析**'
- en: To compare the results from both implementations, we can create a dataframe
    and display it as a table.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较两种实现的结果，我们可以创建一个数据框并将其显示为表格。
- en: '[PRE26]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/36efb4d22c637363266fc4112f9357c7.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36efb4d22c637363266fc4112f9357c7.png)'
- en: The metrics used to compare the implementations of k-means clustering include
    internal metrics (e.g., Davies-Bouldin, Calinski-Harabasz) which do not include
    ground truth labels and external metrics (e.g., Adjusted Rand Index) which do
    include external metrics. A brief description of the three metrics is provided
    below.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 用于比较k-means聚类实现的指标包括内部指标（例如，Davies-Bouldin，Calinski-Harabasz），这些指标不包含真实标签；以及外部指标（例如，调整兰德指数），这些指标包括外部度量。下面简要描述了这三种指标。
- en: 'Davies-Bouldin Index (DBI): The DBI captures the trade-off between cluster
    compactness and the distance between clusters. Lower values of DBI indicate there
    are tighter clusters with more separation between clusters [3].'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davies-Bouldin指数（DBI）：DBI捕捉了聚类紧凑性和聚类之间距离的权衡。较低的DBI值表示聚类更紧密且聚类之间分离度更高[3]。
- en: 'Calinski-Harabasz Index (CHI): The CHI measures cluster density and distance
    between clusters. Higher values indicate that clusters are dense and well-separated
    [4].'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calinski-Harabasz指数（CHI）：CHI衡量聚类密度和聚类之间的距离。较高的值表示聚类密集且分离良好[4]。
- en: 'Adjusted Rand Index (ARI): The ARI measures agreement between cluster labels
    and ground truth. The values of the ARI range from -1 to 1\. A score of 1 indicates
    perfect agreement between labels and ground truth; a scores of 0 indicates random
    assignments; and a score of -1 indicates worse than random assignment [5].'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整兰德指数（ARI）：ARI衡量聚类标签与真实标签之间的一致性。ARI的值范围从-1到1。得分为1表示标签与真实标签完全一致；得分为0表示随机分配；得分为-1表示比随机分配还要差[5]。
- en: When comparing the two implementations, we observed k-mean informed by the silhouette
    score performed best on the two internal metrics, indicating more compact and
    separated clusters. However, k-means informed by the elbow plot performed best
    on the external metric (i.e., ARI) which indicating better alignment with the
    ground truth labels.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较这两种实现时，我们观察到通过轮廓得分指导的k-means在两个内部指标上表现最佳，表明聚类更紧凑且分离度更大。然而，通过肘部图指导的k-means在外部指标（即ARI）上表现最佳，这表明它与真实标签的匹配度更高。
- en: Conclusion
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Ultimately, the best performing implementation will be determined by the task.
    If the task requires clusters that are cohesive and well-separated, then internal
    metrics (e.g., DBI, CHI) might be more relevant. If the task requires the clusters
    to align with the ground truth labels, then external metrics, like the ARI, may
    be more relevant.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，表现最佳的实现将由任务决定。如果任务要求聚类是内聚且分离良好的，那么内部指标（如DBI、CHI）可能更为相关。如果任务要求聚类与真实标签对齐，那么外部指标，如ARI，可能更为相关。
- en: The purpose of this project was to provide a comparison between k-means clustering
    informed by an elbow plot and the silhouette score, and since there wasn’t a defined
    task beyond a pure comparison, we cannot provide a definitive answer as to which
    implementation is better.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的目的是提供基于肘部图和轮廓得分的k-means聚类比较，且由于任务本身仅限于纯粹的比较，因此我们无法给出哪个实现更好的明确答案。
- en: Although the absence of a definitive conclusion may be frustrating, it highlights
    the importance of considering multiple metrics when comparing machine learning
    models and remaining focused on the project’s objectives.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管没有明确结论可能让人感到沮丧，但它突显了在比较机器学习模型时考虑多个指标的重要性，并保持专注于项目的目标。
- en: Thank you for taking the time to read this article. If you have any feedback
    or questions, please leave a comment.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您抽出时间阅读这篇文章。如果您有任何反馈或问题，请留下评论。
- en: References
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] A. Géron, Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow:
    Concepts, Tools, and Techniques to Build Intelligent Systems (2021), O’Reilly.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] A. Géron, 《动手学机器学习：使用Scikit-Learn、Keras和TensorFlow构建智能系统的概念、工具与技术》（2021），O''Reilly出版社。'
- en: '[2] M. Charytanowicz, J. Niewczas, P. Kulczycki, P. Kowalski, S. Łukasik, &
    S. Zak, Complete Gradient Clustering Algorithm for Features Analysis of X-Ray
    Images (2010), Advances in Intelligent and Soft Computing [https://doi.org/10.1007/978-3-642-13105-9_2](https://doi.org/10.1007/978-3-642-13105-9_2)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] M. Charytanowicz, J. Niewczas, P. Kulczycki, P. Kowalski, S. Łukasik, &
    S. Zak, X射线图像特征分析的完整梯度聚类算法（2010），《智能与软计算进展》[https://doi.org/10.1007/978-3-642-13105-9_2](https://doi.org/10.1007/978-3-642-13105-9_2)'
- en: '[3] D. L. Davies, D.W. Bouldin, A Cluster Separation Measure (1979), IEEE Transactions
    on Pattern Analysis and Machine Intelligence https://[doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1109/TPAMI.1979.4766909](https://doi.org/10.1109%2FTPAMI.1979.4766909)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] D. L. Davies, D.W. Bouldin, 一种聚类分离度量（1979），《IEEE模式分析与机器智能学报》https://[doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1109/TPAMI.1979.4766909](https://doi.org/10.1109%2FTPAMI.1979.4766909)'
- en: '[4] T. Caliński, J. Harabasz, A Dendrite Method for Cluster Analysis (1974)
    Communications in Statistics https://[doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1080/03610927408827101](https://doi.org/10.1080%2F03610927408827101)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] T. Caliński, J. Harabasz, 一种树状法聚类分析（1974），《统计学通讯》https://[doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1080/03610927408827101](https://doi.org/10.1080%2F03610927408827101)'
- en: '[5] N. X. Vinh, J. Epps, J. Bailey, Information Theoretic Measures for Clusterings
    Comparison: Variants, Properties, Normalization and Correction for Chance (2010),
    Journal of Machine Learning Research [https://www.jmlr.org/papers/volume11/vinh10a/vinh10a.pdf](https://www.jmlr.org/papers/volume11/vinh10a/vinh10a.pdf)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] N. X. Vinh, J. Epps, J. Bailey, 基于信息论的聚类比较度量：变体、属性、归一化与偶然性修正（2010），《机器学习研究学报》[https://www.jmlr.org/papers/volume11/vinh10a/vinh10a.pdf](https://www.jmlr.org/papers/volume11/vinh10a/vinh10a.pdf)'
