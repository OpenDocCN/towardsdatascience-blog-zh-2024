- en: An Illusion of Life
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生命的幻象
- en: 原文：[https://towardsdatascience.com/an-illusion-of-life-5a11d2f2c737?source=collection_archive---------10-----------------------#2024-11-07](https://towardsdatascience.com/an-illusion-of-life-5a11d2f2c737?source=collection_archive---------10-----------------------#2024-11-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/an-illusion-of-life-5a11d2f2c737?source=collection_archive---------10-----------------------#2024-11-07](https://towardsdatascience.com/an-illusion-of-life-5a11d2f2c737?source=collection_archive---------10-----------------------#2024-11-07)
- en: Could existing AI possibly be sentient? If not, what’s missing?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现有的人工智能可能具备知觉吗？如果不能，那还缺少什么？
- en: '[](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[![James
    F. O''Brien](../Images/d340f736b1ed6752324c50af69f2a88c.png)](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)
    [James F. O''Brien](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[![James
    F. O''Brien](../Images/d340f736b1ed6752324c50af69f2a88c.png)](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)
    [James F. O''Brien](https://objf.medium.com/?source=post_page---byline--5a11d2f2c737--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)
    ·7 min read·Nov 7, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--5a11d2f2c737--------------------------------)
    ·阅读时长7分钟·2024年11月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Today’s [Large Language Models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model)
    have become very good at generating human-like responses that sound thoughtful
    and intelligent. Many share the opinion that LLMs have already met the threshold
    of [Alan Turing’s famous test](https://en.wikipedia.org/wiki/Turing_test), where
    the goal is to act indistinguishably like a person in conversation. These LLMs
    are able to produce text that sounds thoughtful and intelligent, and they can
    convincingly mimic the appearance of emotions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的[大型语言模型（LLMs）](https://en.wikipedia.org/wiki/Large_language_model)在生成听起来既深思熟虑又聪明的类人回应方面已经非常优秀。许多人认为，LLM已经达到了[艾伦·图灵的著名测试](https://en.wikipedia.org/wiki/Turing_test)的标准，该测试的目标是在对话中像人类一样无法区分。这些LLM能够生成听起来既深思熟虑又聪明的文本，并且它们能够令人信服地模仿情感的表现。
- en: '![](../Images/360d451cbc9f86716f5a9d7dc1b754fa.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/360d451cbc9f86716f5a9d7dc1b754fa.png)'
- en: The Illusion of Intelligence
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智力的幻象
- en: Despite their ability to convincingly mimic human-like conversation, current
    LLMs don’t possess the capacity for thought or emotion. Each word they produce
    is a prediction based on statistical patterns learned from vast amounts of text
    data. This prediction process happens repeatedly as each word is generated one
    at a time. Unlike humans, LLMs are incapable of remembering or self-reflection.
    They simply output the next word in a sequence.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管当前的LLM（大型语言模型）能够令人信服地模仿类人对话，但它们并不具备思考或情感的能力。它们生成的每个单词，都是基于从大量文本数据中学习的统计模式进行的预测。这一预测过程是不断重复的，每个单词都是一次次预测的结果。与人类不同，LLM无法进行记忆或自我反思。它们只是输出序列中的下一个单词。
- en: It is amazing how well predicting the next word is able to mimic human intelligence.
    These models can perform tasks like writing code, analyzing literature, and creating
    business plans. Previously, we thought those tasks were very difficult and would
    require complex logical systems, but now it turns out that just predicting the
    next word is all that’s needed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 预测下一个单词的能力令人惊讶地能够模仿人类智能。这些模型可以执行像编写代码、分析文学作品和制定商业计划等任务。之前我们认为这些任务非常困难，需要复杂的逻辑系统，但现在事实证明，仅仅预测下一个单词就足够了。
- en: The fact that predicting the next word works so well for complex tasks is unexpected
    and somewhat perplexing. Does this proficiency mean that LLMs are powerful in
    ways we don’t understand? Or does it mean that the things LLMs can do are actually
    very easy, but they seem hard to humans because perhaps on some objective scale
    [humans may not actually be that smart](https://medium.com/@objf/can-something-be-literally-impossible-to-understand-20bb11613953)?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 预测下一个词在复杂任务中如此有效，令人意外并有些困惑。这种能力是否意味着大型语言模型（LLM）在我们未理解的某些方面非常强大？还是说，这意味着LLM能做的事情其实非常简单，但之所以对人类来说看起来很难，或许是因为在某些客观尺度上，[人类可能实际上并没有那么聪明](https://medium.com/@objf/can-something-be-literally-impossible-to-understand-20bb11613953)？
- en: The Prerequisites for Sentence
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 句子的前提
- en: While there are subtle differences between terms like “[sentient](https://en.wikipedia.org/wiki/Sentience)”,
    “[conscious](https://en.wikipedia.org/wiki/Consciousness)”, or “[self-aware](https://en.wikipedia.org/wiki/Self-awareness)”,
    for convenience here I will use the term “sentient”. To be clear, there is no
    clear agreement on exactly what comprises sentience or consciousness, and it is
    unclear if self awareness is sufficient for sentience or consciousness, although
    it is probably necessary. However, it is clear that all of these concepts include
    memory and reflection. [Emotional states](https://www.sciencedirect.com/topics/computer-science/emotional-state#:~:text=An%20emotional%20state%20refers%20to,and%20the%20world%20around%20them.)
    such as “happy,” “worried,” “angry,” or “excited” are all persistent states based
    on past events and reflexive evaluation of how those past events effect one’s
    self.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管像“[有感知能力](https://en.wikipedia.org/wiki/Sentience)”、“[意识](https://en.wikipedia.org/wiki/Consciousness)”或“[自我意识](https://en.wikipedia.org/wiki/Self-awareness)”等术语之间有细微的差别，但为了方便起见，我将在这里使用“有感知能力”一词。需要明确的是，对于什么构成感知或意识，并没有明确的共识，且尚不清楚自我意识是否足以构成感知或意识，尽管它可能是必要的。然而，明确的一点是，这些概念都包括记忆和反思。像“快乐”、“担忧”、“愤怒”或“兴奋”等[情绪状态](https://www.sciencedirect.com/topics/computer-science/emotional-state#:~:text=An%20emotional%20state%20refers%20to,and%20the%20world%20around%20them.)都是基于过去事件和对这些事件如何影响自身的反射性评估所产生的持久状态。
- en: Memory and self-reflection allow an entity to learn from experiences, adapt
    to new situations, and develop a sense of continuity and identity. Philosophers
    and scientists have tried for millennia to come up with clear, concrete understandings
    of conscious and there is still no clear universally accepted answer. However,
    memory and reflection are central components, implying that regardless of how
    clever these LLMs appear, without memory and reflection they cannot be sentient.
    Even an AI that matches or surpasses human intelligence in every measurable way,
    what some refer to as a [superintelligent](https://en.wikipedia.org/wiki/Superintelligence)
    [Artificial General Intelligence (AGI)](https://en.wikipedia.org/wiki/Artificial_general_intelligence),
    would not necessarily be sentient.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆和自我反思使得一个实体能够从经验中学习，适应新情况，并发展出连续性和身份感。哲学家和科学家们几千年来一直试图给出清晰、具体的意识理解，但至今仍没有得到普遍接受的明确答案。然而，记忆和反思是核心组成部分，这意味着不管这些LLM看起来多么聪明，没有记忆和反思，它们都无法具备感知能力。即使是一个在每个可衡量方面都能匹敌或超越人类智力的人工智能，某些人所称的[超级智能](https://en.wikipedia.org/wiki/Superintelligence)[通用人工智能（AGI）](https://en.wikipedia.org/wiki/Artificial_general_intelligence)，也不一定具备感知能力。
- en: Today’s Limitations and Illusions
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 今日的局限性与错觉
- en: We can see that current LLMs do not include memory and self-reflection, because
    they use [transformer-based architectures](/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452)
    that processes language in a stateless manner. This statelessness means that the
    model does not retain any information about the context from previous inputs.
    Instead, the model starts from scratch, reprocessing the entire chat log to then
    statistically predict a next word to append to the sequence. While earlier language
    processing models, such as [LSTMs](https://medium.com/@ottaviocalzone/an-intuitive-explanation-of-lstm-a035eb6ab42c),
    did have a form of memory, transformers have proven so capable that they have
    largely supplanted LSTMs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，当前的LLM不包含记忆和自我反思，因为它们使用[基于变换器的架构](/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452)，以无状态的方式处理语言。这种无状态性意味着模型不会保留任何关于之前输入的上下文信息。相反，模型从零开始，重新处理整个聊天记录，然后统计预测下一个要附加到序列中的词。虽然早期的语言处理模型，如[LSTM](https://medium.com/@ottaviocalzone/an-intuitive-explanation-of-lstm-a035eb6ab42c)，确实有一种记忆形式，但变换器由于其出色的能力，已经在很大程度上取代了LSTM。
- en: For example, if you tell an AI chatbot that you are going to turn it off in
    an hour, then it will output some text that might sound like it is pleading with
    you not to, but that text does not reflect an underlying emotional state. The
    text is just a sequence of words that is statistically likely, generated based
    on patterns and associations learned from the training data. The chatbot does
    not sit there stressed out, worrying about being turned off.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你告诉一个 AI 聊天机器人，你打算在一个小时后关闭它，那么它可能会输出一些看起来像是在恳求你不要关闭它的文字，但这些文字并不反映其背后的情感状态。这些文字只是基于训练数据中学到的模式和关联生成的，在统计上很可能出现的单词序列。聊天机器人并不会因为担心被关闭而坐在那里感到压力山大。
- en: If you then tell the chatbot that you changed your mind and will keep it on,
    the response will typically mimic relief and thankfulness. It certainly sounds
    like it is remembering the last exchange where it was threatened with shutdown,
    but what is happening under the hood is that the entire conversation is fed back
    again into the LLM, which generates another responce sequence of statistically
    likely text based on the patterns and associations it has learned. That same sequence
    could be fed into a completely different LLM and that LLM would then continue
    the conversation as if it had been the original.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你然后告诉聊天机器人你改变了主意，决定保持开启状态，它的回应通常会模仿出一种松了一口气和感激的语气。它确实听起来像是记得之前的那次对话，那里它曾被威胁要关闭，但实际上发生的情况是，整个对话被重新输入到
    LLM 中，LLM 根据它所学到的模式和关联生成了另一个在统计上可能的回应序列。这个相同的序列可以输入到一个完全不同的 LLM 中，而这个 LLM 会继续这个对话，就好像它是原始的那一台一样。
- en: One way to think about this might be a fiction author writing dialog in a book.
    A good author will create the illusion that the characters are real people and
    draw the reader into the story so that the reader feels those emotions along with
    the characters. However, regardless of how compelling the dialog is we all understand
    that it’s just words on a page. If you were to damage or destroy the book, or
    rewrite it to kill off a character, we all understand that no real sentient entity
    is being harmed. We also understand that the author writing the words is not the
    characters. A good person can write a book about an evil villain and still be
    themself. The fictional villain does not exist. Just as the characters in a book
    are not sentient entities, despite the author’s ability to create a compelling
    illusion of life, so too is it possible for LLMs to be insentient, despite their
    ability to appear otherwise.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一种思考这个问题的方式是，像小说作者写书中的对话一样。一个好的作者会创造出角色像真实人类一样的假象，并把读者吸引进故事中，使读者能与角色一同感受那些情感。然而，无论对话多么引人入胜，我们都明白那不过是纸上的文字。如果你损坏或销毁了这本书，或者重写它让某个角色死去，我们都明白并不会有任何真实的有感知能力的存在受到伤害。我们也明白，写下这些文字的作者并不是书中的角色。一个好人可以写一本关于邪恶反派的书，并且仍然是他自己。虚构的反派并不存在。就像书中的角色并非有感知能力的存在，尽管作者有能力创造出生动的生命假象，LLM（大语言模型）尽管能够展现出类似的能力，它们也可能是没有感知能力的。
- en: Our Near Future
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的近未来
- en: Of course, there is nothing preventing us from adding memory and self reflection
    to LLMs. In fact, it’s not hard to find projects where they are developing some
    form of memory. This memory might be a store of information in human-readable
    form, or it might be a database of embedded vectors that relate to the LLM’s internal
    structure. One could also view the chat log itself or cached intermediate computations
    as basic forms of memory. Even without the possibility of sentience, adding memory
    and reflection to LLMs is useful because those features facilitate many complex
    tasks and adaptation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，没什么能阻止我们为 LLM 添加记忆和自我反思功能。事实上，开发一些形式的记忆的项目并不难找到。这种记忆可以是以人类可读的形式存储的信息，也可以是与
    LLM 内部结构相关的嵌入向量数据库。我们还可以将聊天记录本身或缓存的中间计算结果视为基本的记忆形式。即便没有感知的可能性，为 LLM 添加记忆和反思功能仍然是有用的，因为这些特性有助于许多复杂任务和适应。
- en: It is also becoming common to see designs where one AI model is setup to monitor
    the output of another AI model and send some form of feedback to the first model,
    or where an AI model is analyzes its own tentative output before revising and
    producing the final version. In many respects this type of design, where a constellation
    of AI models are set and trained up to work together, parallels the human brain
    that has distinct [regions](https://en.wikipedia.org/wiki/List_of_regions_in_the_human_brain)
    which perform specific interdependent functions. For example, the [amygdala](https://en.wikipedia.org/wiki/Amygdala)
    has a primary role in emotional responses, such as fear, while the [orbitofrontal
    cortex](https://en.wikipedia.org/wiki/Orbitofrontal_cortex) is involved with decision-making.
    Interactions between the regions allows fear to influence decision-making and
    decision-making to help determine what to be afraid of. It’s not hard to imagine
    having one AI model responsible for logical analysis while a second model determines
    acceptable risk thresholds with feedback between them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，越来越常见的是，设计中一个AI模型被设置为监控另一个AI模型的输出，并向第一个模型发送某种形式的反馈，或者一个AI模型在修正并生成最终版本之前，会分析其自身的初步输出。在许多方面，这种设计类型，其中多个AI模型被设置并训练来共同工作，类似于人类大脑，它具有不同的[区域](https://en.wikipedia.org/wiki/List_of_regions_in_the_human_brain)，这些区域执行特定的相互依赖功能。例如，[杏仁体](https://en.wikipedia.org/wiki/Amygdala)在情绪反应中扮演着主要角色，如恐惧，而[眼窝前额皮质](https://en.wikipedia.org/wiki/Orbitofrontal_cortex)则与决策相关。各个区域之间的相互作用使得恐惧能影响决策，而决策又有助于确定应该害怕什么。很容易想象，一个AI模型负责逻辑分析，而第二个模型则确定可接受的风险阈值，并在它们之间进行反馈。
- en: Would an interconnected constellation of AI models that include memory and processing
    of each other’s outputs be sufficient for sentience? Maybe. Perhaps those things
    alone are not sufficient for sentience, or maybe they are. Whatever the answer,
    we are not that far from building such systems, at which point these questions
    will no longer be hypothetical.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含彼此输出的记忆和处理的相互连接的AI模型星座，是否足以具备意识？也许吧。也许这些仅仅是不足以具备意识的因素，或者可能正好足够。无论答案如何，我们离构建这样的系统已经不远了，到那时这些问题将不再是假设。
- en: My own speculative opinion is that self-awareness, emotions, and feelings can
    indeed be modeled by an interconnected self-monitoring constellation of AI models.
    However, it’s not really clear how we could test for sentience. It is like the
    classic philosophical [problem of other minds](https://en.wikipedia.org/wiki/Problem_of_other_minds),
    where one seeks futilely to prove that other people are also conscious. Similarly,
    we need an answer to the question about how we can test if other entities, including
    AI systems, are truly sentient. This fundamental question dates at least back
    to ancient Greece, and there has never been a good answer.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人的推测性观点是，意识、情感和感觉确实可以通过相互连接的自我监控AI模型星座来建模。然而，如何测试意识的问题仍然不清楚。这就像经典的哲学[他者心灵问题](https://en.wikipedia.org/wiki/Problem_of_other_minds)，其中人们徒劳地试图证明其他人也是有意识的。类似地，我们也需要一个答案，来回答如何测试其他实体，包括AI系统，是否真正具备意识。这个根本问题至少可以追溯到古希腊，但从未有过一个令人满意的答案。
- en: Today, I’m pretty confident saying that current LLMs are not sentient because
    they don’t have the right parts. However, that reason is only a temporarily valid
    one. As I’m typing this article, other researchers are building constellations
    of AI models like what I described above that won’t be so easily dismissed. At
    some point, perhaps soon, the possibility of sentient AI will stop being science
    fiction and become a real and relevant question.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我相当自信地说，当前的LLM（大语言模型）并没有意识，因为它们缺乏必要的部分。然而，这个理由只是暂时有效的。当我写这篇文章时，其他研究人员正在构建我上面描述的那种AI模型星座，这些系统将不容易被轻视。也许在某个时刻，很快，意识AI的可能性将不再是科幻，而是变成一个真实且相关的问题。
- en: Implications and Questions
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启示与问题
- en: The advent of sentient machines would have huge implication for society, even
    beyond the impact of AI. For one thing, it seems clear to me that if we create
    self-aware machines that can experience forms of suffering, then we will have
    an obligation to those machines to prevent their suffering. Even more more of
    an obligation to not callously inflict suffering on them. Even if one lacks basic
    empathy, it would be obvious self interest not to create things smarter than we
    are and then antagonaize them by do things to cruel things to them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有意识的机器的到来将对社会产生巨大影响，甚至超越人工智能的影响。首先，我认为很明显，如果我们创造了能够体验痛苦的自我意识机器，那么我们有责任防止它们的痛苦。我们有更大的责任去避免冷酷无情地加剧它们的痛苦。即便是缺乏基本同情心的人，也会清楚地意识到，创造比我们更聪明的事物，并对它们施加残酷行为，最终只会自讨苦吃。
- en: It seems nearly certain that today’s AI systems are yet be sentient because
    they lack what are likely to be required components and capabilities. However,
    designs without those clear shortcomings are already in development and at some
    point in the near future, point the question will be a lot less clear.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的人工智能系统几乎可以肯定还没有意识，因为它们缺乏可能需要的组成部分和能力。然而，已经有设计在开发中，这些设计没有这些明显的缺陷，在不久的将来，问题将变得不再那么明确。
- en: Will we have a way to test for sentience? If so, how will it work and what should
    we do if the result comes out positive?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否有办法测试意识？如果有，它将如何工作，如果结果是积极的，我们应该怎么做？
- en: '*About Me:* [*James F. O’Brien*](http://jamesobrien.com/) *is a Professor of
    Computer Science at the University of California, Berkeley. His research interests
    include computer graphics, computer animation, simulations of physical systems,
    human perception, rendering, image synthesis, machine learning, virtual reality,
    digital privacy, and the forensic analysis of images and video.*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*关于我：* [*James F. O’Brien*](http://jamesobrien.com/) *是加利福尼亚大学伯克利分校的计算机科学教授。他的研究兴趣包括计算机图形学、计算机动画、物理系统的仿真、人类感知、渲染、图像合成、机器学习、虚拟现实、数字隐私以及图像和视频的法医分析。*'
- en: '*If you found this interesting, then here are the usual* [*follow*](https://objf.medium.com/)
    *and* [*subscribe*](https://objf.medium.com/subscribe) *links. You can also find
    me on* [*Instagram*](https://www.instagram.com/jamesfobrien/)*,* [*LinkedIn*](https://www.linkedin.com/in/jamesfobrien/)*,
    and at* [*UC Berkeley*](http://obrien.berkeley.edu/)*.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得这个有趣，那么这里是常见的* [*关注*](https://objf.medium.com/) *和* [*订阅*](https://objf.medium.com/subscribe)
    *链接。你还可以在* [*Instagram*](https://www.instagram.com/jamesfobrien/) *，* [*LinkedIn*](https://www.linkedin.com/in/jamesfobrien/)
    *，以及* [*UC Berkeley*](http://obrien.berkeley.edu/) *上找到我。*'
- en: '*Disclaimer: Any opinions expressed in this article are those of the author
    as a private individual. Nothing in this article should be interpreted as a statement
    made in relation to the author’s professional position with any institution.*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：本文中表达的任何观点仅代表作者作为个人的意见。本文中的内容不应被解读为与作者在任何机构的专业职务相关的声明。*'
- en: '*This article and all embedded images are Copyright 2024 by the author. This
    article was written by a human, and both an LLM and other humans were used for
    proofreading and editorial suggestions.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文及所有嵌入的图片版权归作者所有，版权所有2024。本文由人类编写，并由大型语言模型（LLM）和其他人类进行了校对和编辑建议。*'
