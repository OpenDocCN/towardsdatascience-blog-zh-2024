- en: Evaluating Model Retraining Strategies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型再训练策略
- en: 原文：[https://towardsdatascience.com/evaluating-model-retraining-strategies-9c337d95409a?source=collection_archive---------2-----------------------#2024-10-20](https://towardsdatascience.com/evaluating-model-retraining-strategies-9c337d95409a?source=collection_archive---------2-----------------------#2024-10-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluating-model-retraining-strategies-9c337d95409a?source=collection_archive---------2-----------------------#2024-10-20](https://towardsdatascience.com/evaluating-model-retraining-strategies-9c337d95409a?source=collection_archive---------2-----------------------#2024-10-20)
- en: How data drift and concept drift matter to choose the right retraining strategy?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据漂移和概念漂移如何影响选择正确的再训练策略？
- en: '[](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)[![Reinhard
    Sellmair](../Images/0aaf2ae9c27f551f9ef6921d110318b5.png)](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)
    [Reinhard Sellmair](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)[![Reinhard
    Sellmair](../Images/0aaf2ae9c27f551f9ef6921d110318b5.png)](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)
    [Reinhard Sellmair](https://medium.com/@reinhard.sellmair?source=post_page---byline--9c337d95409a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)
    ·9 min read·Oct 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9c337d95409a--------------------------------)
    ·阅读时间9分钟·2024年10月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b6d9de178844a026183cbd16af50612d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6d9de178844a026183cbd16af50612d.png)'
- en: (created with Image Creator in Bing)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （由必应的图像生成器创建）
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: 'Many people in the field of MLOps have probably heard a story like this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多MLOps领域的人可能听过类似的故事：
- en: Company A embarked on an ambitious quest to harness the power of machine learning.
    It was a journey fraught with challenges, as the team struggled to pinpoint a
    topic that would not only leverage the prowess of machine learning but also deliver
    tangible business value. After many brainstorming sessions, they finally settled
    on a use case that promised to revolutionize their operations. With excitement,
    they contracted Company B, a reputed expert, to build and deploy a ML model. Following
    months of rigorous development and testing, the model passed all acceptance criteria,
    marking a significant milestone for Company A, who looked forward to future opportunities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 公司A开始了一项雄心勃勃的计划，旨在利用机器学习的力量。这是一段充满挑战的旅程，因为团队难以确定一个既能发挥机器学习优势，又能带来实际商业价值的主题。经过多次头脑风暴，他们最终确定了一个有望彻底改变他们运营的用例。满怀期待，他们与享有盛誉的公司B签订合同，由其负责构建和部署机器学习模型。在经过几个月的严格开发和测试后，模型通过了所有验收标准，标志着公司A的一项重要里程碑，他们期待未来的更多机会。
- en: However, as time passed, the model began producing unexpected results, rendering
    it ineffective for its intended use. Company A reached out to Company B for advice,
    only to learn that the changed circumstances required building a new model, necessitating
    an even higher investment as the original.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着时间的推移，模型开始产生意外结果，导致它在预期用途上失效。公司A联系了公司B寻求建议，才得知改变后的环境需要重新构建一个新的模型，这意味着需要更高的投资，甚至超过原始模型的成本。
- en: What went wrong? Was the model Company B created not as good as expected? Was
    Company A just unlucky that something unexpected happened?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 出了什么问题？公司B创建的模型是不是没有达到预期效果？还是公司A只是运气不好，发生了意外情况？
- en: Probably the issue was that even the most rigorous testing of a model before
    deployment does not guarantee that this model will perform well for an unlimited
    amount of time. The two most important aspects that impact a model’s performance
    over time are data drift and concept drift.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的问题是，即使在部署前对模型进行最严格的测试，也不能保证该模型能够在无限的时间内表现良好。影响模型随时间变化表现的两个最重要因素是数据漂移和概念漂移。
- en: '**Data Drift**: Also known as covariate shift, this occurs when the statistical
    properties of the input data change over time. If an ML model was trained on data
    from a specific demographic but the demographic characteristics of the input data
    change, the model’s performance can degrade. Imagine you taught a child multiplication
    tables until 10\. It can quickly give you the correct answers for what is 3 *
    7 or 4 * 9\. However, one time you ask what is 4 * 13, and although the rules
    of multiplication did not change it may give you the wrong answer because it did
    not memorize the solution.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据漂移**：也称为协变量漂移，指的是当输入数据的统计特性随时间发生变化时出现的现象。如果一个机器学习模型是在特定人群的数据上训练的，但输入数据的人群特征发生了变化，模型的性能可能会下降。假设你教一个孩子乘法表直到10。它能迅速告诉你3
    * 7或4 * 9的正确答案。然而，有一次你问它4 * 13，尽管乘法规则并没有变化，它可能会给出错误的答案，因为它没有记住这个解法。'
- en: '**Concept Drift**: This happens when the relationship between the input data
    and the target variable changes. This can lead to a degradation in model performance
    as the model’s predictions no longer align with the evolving data patterns. An
    example here could be spelling reforms. When you were a child, you may have learned
    to write “co-operate”, however now it is written as “cooperate”. Although you
    mean the same word, your output of writing that word has changed over time.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**概念漂移**：当输入数据与目标变量之间的关系发生变化时，称为概念漂移。这可能会导致模型性能下降，因为模型的预测不再与不断变化的数据模式相符。这里的一个例子可以是拼写改革。当你还是孩子时，你可能学会了写“co-operate”，但现在它被写作“cooperate”。虽然你指的是同一个词，但你写这个词的方式随时间发生了变化。'
- en: In this article I investigate how different scenarios of data drift and concept
    drift impact a model’s performance over time. Furthermore, I show what retraining
    strategies can mitigate performance degradation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我研究了不同的数据漂移和概念漂移场景如何影响模型随时间的性能表现。此外，我还展示了哪些重新训练策略能够缓解性能下降。
- en: 'I focus on evaluating retraining strategies with respect to the model’s prediction
    performance. In practice more aspects like:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我专注于评估关于模型预测性能的重新训练策略。实际上，还涉及更多的方面，如：
- en: '**Data Availability and Quality**: Ensure that sufficient and high-quality
    data is available for retraining the model.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可用性与质量**：确保有足够的高质量数据可用于重新训练模型。'
- en: '**Computational Costs**: Evaluate the computational resources required for
    retraining, including hardware and processing time.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算成本**：评估重新训练所需的计算资源，包括硬件和处理时间。'
- en: '**Business Impact**: Consider the potential impact on business operations and
    outcomes when choosing a retraining strategy.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务影响**：在选择重新训练策略时，要考虑对业务运营和结果的潜在影响。'
- en: '**Regulatory Compliance**: Ensure that the retraining strategy complies with
    any relevant regulations and standards, e.g. anti-discrimination.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性要求**：确保重新训练策略符合任何相关的法规和标准，例如反歧视法规。'
- en: need to be considered to identify a suitable retraining strategy.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的因素，以识别合适的重新训练策略。
- en: Data Synthetization
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据合成
- en: '![](../Images/64b1a6bc63bc5cff19c9d904e241f5fb.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64b1a6bc63bc5cff19c9d904e241f5fb.png)'
- en: (created with Image Creator in Bing)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (由Bing的图像创建工具生成)
- en: To highlight the differences between data drift and concept drift I synthesized
    datasets where I controlled to what extent these aspects appear.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了突出数据漂移和概念漂移之间的差异，我合成了数据集，并控制了这些方面出现的程度。
- en: I generated datasets in 100 steps where I changed parameters incrementally to
    simulate the evolution of the dataset. Each step contains multiple data points
    and can be interpreted as the amount of data that was collected over an hour,
    a day or a week. After every step the model was re-evaluated and could be retrained.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我生成了100个步骤的数据集，并逐步更改参数以模拟数据集的演变。每一步包含多个数据点，可以解释为在一小时、一天或一周内收集的数据量。每一步之后，模型都会重新评估，并可以重新训练。
- en: 'To create the datasets, I first randomly sampled features from a normal distribution
    where mean µ and standard deviation σ depend on the step number s:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建数据集，我首先从正态分布中随机抽取特征，其中均值µ和标准差σ依赖于步骤编号s：
- en: '![](../Images/21accb943cab84be5919b10c73d07ec3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21accb943cab84be5919b10c73d07ec3.png)'
- en: The data drift of feature xi depends on how much µi and σi are changing with
    respect to the step number s.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 特征xi的漂移取决于µi和σi在步骤编号s上变化的程度。
- en: 'All features are aggregated as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所有特征汇总如下：
- en: '![](../Images/89b0e66c590f9604e2abcc299b295eed.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89b0e66c590f9604e2abcc299b295eed.png)'
- en: Where ci are coefficients that describe the impact of feature xi on X. Concept
    drift can be controlled by changing these coefficients with respect to s. A random
    number ε which is not available for model training is added to consider that the
    features do not contain complete information to predict the target y.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ci 是描述特征 xi 对 X 影响的系数。概念漂移可以通过根据步骤 s 改变这些系数来控制。添加一个随机数 ε（在模型训练时无法获得），以考虑特征并不包含完整的信息来预测目标
    y。
- en: The target variable y is calculated by inputting X into a non-linear function.
    By doing this we create a more challenging task for the ML model since there is
    no linear relation between the features and the target. For the scenarios in this
    article, I chose a sine function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量 y 通过将 X 输入到非线性函数中计算得到。这样做会为机器学习模型创造一个更具挑战性的任务，因为特征与目标之间没有线性关系。本文中的情景，我选择了一个正弦函数。
- en: '![](../Images/1364afc8dbd6921c20ebc1c343ad6102.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1364afc8dbd6921c20ebc1c343ad6102.png)'
- en: Scenario Analysis
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情景分析
- en: '![](../Images/7879fabd0027dada605891831f21d422.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7879fabd0027dada605891831f21d422.png)'
- en: (created with Image Creator in Bing)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: (使用 Bing 的 Image Creator 创建)
- en: 'I created the following scenarios to analyze:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了以下情景进行分析：
- en: '**Steady State:** simulating no data or concept drift — parameters µ, σ, and
    c were independent of step s'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳态：**模拟无数据或概念漂移 — 参数 µ，σ，和 c 与步骤 s 无关'
- en: '**Distribution Drift:** simulating data drift — parameters µ, σ were linear
    functions of s, parameters c is independent of s'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布漂移：**模拟数据漂移 — 参数 µ，σ 是 s 的线性函数，参数 c 与 s 无关'
- en: '**Coefficient Drift:** simulating concept drift: parameters µ, σ were independent
    of s, parameters c are a linear function of s'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系数漂移：**模拟概念漂移：参数 µ，σ 与 s 独立，参数 c 是 s 的线性函数'
- en: '**Black Swan:** simulating an unexpected and sudden change — parameters µ,
    σ, and c were independent of step s except for one step when these parameters
    were changed'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑天鹅：**模拟一个意外且突然的变化 — 参数 µ，σ 和 c 除了在某一步骤中这些参数发生变化外，其它步骤与步骤 s 无关'
- en: The COVID-19 pandemic serves as a quintessential example of a Black Swan event.
    A Black Swan is characterized by its extreme rarity and unexpectedness. COVID-19
    could not have been predicted to mitigate its effects beforehand. Many deployed
    ML models suddenly produced unexpected results and had to be retrained after the
    outbreak.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: COVID-19 大流行是黑天鹅事件的典型例子。黑天鹅事件的特点是其极为罕见且出乎意料。COVID-19 无法提前预测，因此也无法减轻其影响。许多部署的机器学习模型在疫情爆发后突然产生了意想不到的结果，必须重新训练。
- en: 'For each scenario I used the first 20 steps as training data of the initial
    model. For the remaining steps I evaluated three retraining strategies:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个情景，我使用了前 20 步作为初始模型的训练数据。在剩余的步骤中，我评估了三种重新训练策略：
- en: '***None*:** No retraining — the model trained on the training data was used
    for all remaining steps.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***None*：**不进行重新训练 — 在所有剩余步骤中都使用基于训练数据训练的模型。'
- en: '***All Data*:** All previous data was used to train a new model, e.g. the model
    evaluated at step 30 was trained on the data from step 0 to 29.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***All Data*：**使用所有之前的数据训练新模型，例如，在步骤 30 评估的模型是基于步骤 0 到 29 的数据训练的。'
- en: '***Window*:** A fixed window size was used to select the training data, e.g.
    for a window size of 10 the training data at step 30 contained step 20 to 29.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Window*：**使用固定窗口大小选择训练数据，例如，对于窗口大小为 10，步骤 30 的训练数据包含步骤 20 到 29 的数据。'
- en: I used a XG Boost regression model and mean squared error (MSE) as evaluation
    metric.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了 XG Boost 回归模型，并以均方误差（MSE）作为评估指标。
- en: Steady State
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳态
- en: '![](../Images/30ca7f88807354199e0dd656fc593f86.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30ca7f88807354199e0dd656fc593f86.png)'
- en: Prediction error of steady state scenario
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 稳态情景的预测误差
- en: The diagram above shows the evaluation results of the steady state scenario.
    As the first 20 steps were used to train the models the evaluation error was much
    lower than at later steps. The performance of the *None* and *Window* retraining
    strategies remained at a similar level throughout the scenario. The *All Data*
    strategy slightly reduced the prediction error at higher step numbers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了稳态情景的评估结果。由于前 20 步用于训练模型，因此评估误差远低于后续步骤。在整个情景中，*None* 和 *Window* 重新训练策略的性能保持在相似水平。*All
    Data* 策略在较高步数时略微降低了预测误差。
- en: In this case *All Data*is the best strategy because it profits from an increasing
    amount of training data while the models of the other strategies were trained
    on a constant training data size.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，*All Data* 是最好的策略，因为它从不断增加的训练数据量中受益，而其他策略的模型则在固定的训练数据量上进行训练。
- en: Distribution Drift (Data Drift)
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布漂移（数据漂移）
- en: '![](../Images/7078ada35dc9de7ba1f329f1249c5572.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7078ada35dc9de7ba1f329f1249c5572.png)'
- en: Prediction error of distribution drift scenario
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 分布漂移场景的预测误差
- en: When the input data distributions changed, we can clearly see that the prediction
    error continuously increased if the model was not retrained on the latest data.
    Retraining on all data or on a data window resulted in very similar performances.
    The reason for this is that although *All Data*was using more data, older data
    was not relevant for predicting the most recent data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入数据分布发生变化时，我们可以清楚地看到，如果模型没有在最新数据上进行重训练，预测误差会持续增加。无论是在所有数据上进行重训练，还是在数据窗口上进行重训练，性能几乎相同。原因在于，尽管*所有数据*使用了更多的数据，但旧数据对于预测最新数据并不相关。
- en: Coefficient Drift (Concept Drift)
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系数漂移（概念漂移）
- en: '![](../Images/cd1fa6455b041e6e0dbc79a0c63b1a67.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd1fa6455b041e6e0dbc79a0c63b1a67.png)'
- en: Prediction error of coefficient drift scenario
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 系数漂移场景的预测误差
- en: Changing coefficients means that the importance of features changes over time.
    In this case we can see that the *None* retraining strategy had drastic increase
    of the prediction error. Additionally, the results showed that retraining on all
    data also lead to a continuous increase of prediction error while the *Window*
    retraining strategy kept the prediction error on a constant level.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 系数变化意味着特征的重要性随时间变化。在这种情况下，我们可以看到*无重训练*策略的预测误差急剧增加。此外，结果显示，在所有数据上进行重训练也导致预测误差的持续增加，而*窗口重训练*策略则保持预测误差在一个恒定水平。
- en: The reason why the *All Data* strategy performance also decreased over time
    was that the training data contained more and more cases where similar inputs
    resulted in different outputs. Hence, it became more challenging for the model
    to identify clear patterns to derive decision rules. This was less of a problem
    for the *Window*strategy since older data was ignore which allowed the model to
    “forget” older patterns and focus on most recent cases.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有数据*策略的表现随时间下降的原因是，训练数据中包含了越来越多类似输入却导致不同输出的情况。因此，模型在识别清晰模式并推导决策规则时变得更加困难。这对于*窗口*策略来说问题较小，因为忽略了旧数据，这使得模型能够“忘记”旧的模式，并专注于最新的情况。'
- en: Black Swan
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 黑天鹅
- en: '![](../Images/e662136c11e4449771ef27c39905d738.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e662136c11e4449771ef27c39905d738.png)'
- en: Prediction error of black swan event scenario
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 黑天鹅事件场景的预测误差
- en: The black swan event occurred at step 39, the errors of all models suddenly
    increased at this point. However, after retraining a new model on the latest data,
    the errors of the *All Data* and *Window* strategy recovered to the previous level.
    Which is not the case with the *None* retraining strategy, here the error increased
    around 3-fold compared to before the black swan event and remained on that level
    until the end of the scenario.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 黑天鹅事件发生在第39步，所有模型的误差在这一点突然增加。然而，在最新数据上重新训练一个新模型后，*所有数据*和*窗口*策略的误差恢复到了之前的水平。这在*无重训练*策略中并不适用，在这种策略下，误差比黑天鹅事件发生前增加了大约三倍，并一直保持在该水平直到场景结束。
- en: 'In contrast to the previous scenarios, the black swan event contained both:
    data drift and concept drift. It is remarkable that the *All Data* and *Window*
    strategy recovered in the same way after the black swan event while we found a
    significant difference between these strategies in the concept drift scenario.
    Probably the reason for this is that data drift occurred at the same time as concept
    drift. Hence, patterns that have been learned on older data were not relevant
    anymore after the black swan event because the input data has shifted.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的场景相比，黑天鹅事件包含了数据漂移和概念漂移。值得注意的是，*所有数据*和*窗口*策略在黑天鹅事件后以相同的方式恢复，而在概念漂移场景中我们发现这两者之间有显著的差异。其原因可能是数据漂移与概念漂移同时发生。因此，在旧数据上学习到的模式在黑天鹅事件之后不再相关，因为输入数据已经发生了变化。
- en: An example for this could be that you are a translator and you get requests
    to translate a language that you haven’t translated before (data drift). At the
    same time there was a comprehensive spelling reform of this language (concept
    drift). While translators who translated this language for many years may be struggling
    with applying the reform it wouldn’t affect you because you even didn’t know the
    rules before the reform.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以是一个例子：你是一个翻译员，收到请求翻译你以前没有翻译过的语言（数据漂移）。同时，该语言发生了全面的拼写改革（概念漂移）。虽然那些翻译这门语言多年的人可能在应用这些改革时遇到困难，但这对你没有影响，因为你甚至在改革前就不知道这些规则。
- en: To reproduce this analysis or explore further you can check out my [git repository](https://github.com/ReinhardSellmair/mlmm).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要复制此分析或进一步探索，您可以查看我的[git 仓库](https://github.com/ReinhardSellmair/mlmm)。
- en: Conclusion
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Identifying, quantifying, and mitigating the impact of data drift and concept
    drift is a challenging topic. In this article I analyzed simple scenarios to present
    basic characteristics of these concepts. More comprehensive analyses will undoubtedly
    provide deeper and more detailed conclusions on this topic.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 识别、量化并缓解数据漂移和概念漂移的影响是一个具有挑战性的课题。在本文中，我分析了简单的场景，以展示这些概念的基本特征。更全面的分析无疑将提供对这个课题更深入和更详细的结论。
- en: 'Here is what I learned from this project:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我从这个项目中学到的内容：
- en: Mitigating concept drift is more challenging than data drift. While data drift
    could be handled by basic retraining strategies concept drift requires a more
    careful selection of training data. Ironically, cases where data drift and concept
    drift occur at the same time may be easier to handle than pure concept drift cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解概念漂移比数据漂移更具挑战性。虽然数据漂移可以通过基本的再训练策略来处理，但概念漂移则需要更仔细地选择训练数据。具有讽刺意味的是，数据漂移和概念漂移同时发生的情况可能比纯粹的概念漂移情况更容易处理。
- en: A comprehensive analysis of the training data would be the ideal starting point
    of finding an appropriate retraining strategy. Thereby, it is essential to partition
    the training data with respect to the time when it was recorded. To make the most
    realistic assessment of the model’s performance, the latest data should only be
    used as test data. To make an initial assessment regarding data drift and concept
    drift the remaining training data can be split into two equally sized sets with
    the older data in one set and the newer data in the other. Comparing feature distributions
    of these sets allows to assess data drift. Training one model on each set and
    comparing the change of feature importance would allow to make an initial assessment
    on concept drift.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对训练数据进行全面分析将是找到合适的再训练策略的理想起点。因此，按照记录数据的时间对训练数据进行分区至关重要。为了对模型性能进行最真实的评估，最新的数据应仅用作测试数据。为了初步评估数据漂移和概念漂移，剩余的训练数据可以分成两个大小相等的集合，较旧的数据放在一个集合中，较新的数据放在另一个集合中。比较这些集合的特征分布可以评估数据漂移。分别在每个集合上训练一个模型，并比较特征重要性的变化，可以对概念漂移做出初步评估。
- en: No retraining turned out to be the worst option in all scenarios. Furthermore,
    in cases where model retraining is not taken into consideration it is also more
    likely that data to evaluate and/or retrain the model is not collected in an automated
    way. This means that model performance degradation may be unrecognized or only
    be noticed at a late stage. Once developers become aware that there is a potential
    issue with the model precious time would be lost until new data is collected that
    can be used to retrain the model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有场景中，不进行再训练是最差的选择。此外，在没有考虑到模型再训练的情况下，评估和/或再训练模型的数据也更可能没有以自动化方式收集。这意味着模型性能的退化可能无法被及时识别，或者直到较晚阶段才会被注意到。一旦开发者意识到模型可能存在问题，宝贵的时间将被浪费，直到收集到可以用来再训练模型的新数据。
- en: Identifying the perfect retraining strategy at an early stage is very difficult
    and may be even impossible if there are unexpected changes in the serving data.
    Hence, I think a reasonable approach is to start with a retraining strategy that
    performed well on the partitioned training data. This strategy should be reviewed
    and updated the time when cases occurred where it did not address changes in the
    optimal way. Continuous model monitoring is essential to quickly notice and react
    when the model performance decreases.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期阶段识别完美的再训练策略是非常困难的，如果服务数据发生了意外变化，这种识别甚至可能是不可能的。因此，我认为合理的做法是从一个在划分后的训练数据上表现良好的再训练策略开始。当出现未能以最佳方式应对变化的情况时，应及时审查并更新该策略。持续的模型监控对于快速发现并在模型性能下降时做出反应至关重要。
- en: '*If not otherwise stated all images were created by the author.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果没有特别说明，所有图片均由作者创建。*'
