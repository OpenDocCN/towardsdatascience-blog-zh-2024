- en: Evaluating performance of LLM-based Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估基于LLM的应用性能
- en: 原文：[https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30](https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30](https://towardsdatascience.com/evaluating-performance-of-llm-based-applications-be6073c02421?source=collection_archive---------8-----------------------#2024-09-30)
- en: '**Evaluation Framework for** real-world requirements'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**现实世界需求的评估框架**'
- en: '[](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[![Anurag
    Bhagat](../Images/3711a1fce6e2a45d649e534f08c3d0ca.png)](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)
    [Anurag Bhagat](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[![Anurag
    Bhagat](../Images/3711a1fce6e2a45d649e534f08c3d0ca.png)](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)
    [Anurag Bhagat](https://medium.com/@bhagatanurag03?source=post_page---byline--be6073c02421--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)
    ·7 min read·Sep 30, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--be6073c02421--------------------------------)
    ·阅读时长7分钟·2024年9月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dc652003ac88a941b6097d5613d410b4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc652003ac88a941b6097d5613d410b4.png)'
- en: '*Source: Generated with the help of AI (OpenAI’s Dall-E model)*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*来源：借助AI（OpenAI的Dall-E模型）生成*'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Ever since OpenAI’s ChatGPT took the world by storm in November 2022, Large
    Language Models (LLMs) have revolutionized various applications across industries,
    from natural language understanding to text generation. However, their performance
    needs rigorous and multidimensional evaluation metrics to ensure they meet the
    practical, real-world requirements of accuracy, efficiency, scalability, and ethical
    considerations. This article outlines a broad set of metrics and methods to measure
    the performance of LLM-based applications, providing insights into evaluation
    frameworks that balance technical performance with user experience and business
    needs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自从OpenAI的ChatGPT在2022年11月席卷全球以来，大型语言模型（LLMs）已经彻底改变了各行各业的多种应用，从自然语言理解到文本生成。然而，它们的性能需要严格且多维度的评估指标，以确保它们满足实际世界中准确性、效率、可扩展性和伦理考虑等方面的要求。本文概述了一套广泛的指标和方法，用于衡量基于LLM的应用性能，提供了平衡技术性能与用户体验和业务需求的评估框架的见解。
- en: This is not meant to be a comprehensive guide on all metrics to measure the
    performance of LLM applications, but it provides a view into key dimensions to
    look at and some examples of metrics. This will help you understand how to build
    your evaluation criterion, the final choice will depend on your actual use case.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文并不是关于衡量LLM应用性能的所有指标的全面指南，而是提供了一个关于需要关注的关键维度的视角，并列出了一些指标示例。这将帮助你理解如何构建评估标准，最终的选择将取决于你的实际应用场景。
- en: Even though this article focuses on LLM based applications, this could be extrapolated
    to other modalities as well.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本文侧重于基于LLM的应用，但这一点也可以推广到其他领域。
- en: 1\. Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 引言
- en: '1.1\. LLM-Based Applications: Definition and Scope'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1. LLM基础应用：定义与范围
- en: There is no dearth of Large Language Models(LLMs) today. LLMs such as GPT-4,
    Meta’s LLaMA, Anthropic’s Claude 3.5 Sonnet, or Amazon’s Titan Text Premier, are
    capable of understanding and generating human-like text, making them apt for multiple
    downstream applications like customer facing chatbots, creative content generation,
    language translation, etc.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，市面上不乏大型语言模型（LLMs）。像GPT-4、Meta的LLaMA、Anthropic的Claude 3.5 Sonnet，或者亚马逊的Titan
    Text Premier等LLM，都能够理解并生成类人文本，适用于多种下游应用，如面向客户的聊天机器人、创意内容生成、语言翻译等。
- en: 1.2\. Importance of Performance Evaluation
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2. 性能评估的重要性
- en: LLMs are non-trivial to evaluate, unlike traditional ML models, which have pretty
    standardized evaluation criteria and datasets. The black box nature of LLMs, as
    well as the multiplicity of downstream use cases warrants a multifaceted performance
    measurement across multiple considerations. Inadequate evaluation can lead to
    cost overruns, poor user experience, or risks for the organization deploying them.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的评估并不简单，不像传统的机器学习模型，后者有着相对标准化的评估标准和数据集。LLM的“黑箱”特性以及其下游使用案例的多样性，要求在多个考虑因素上进行多维度的性能测量。不充分的评估可能会导致成本超支、用户体验不佳，甚至给部署的组织带来风险。
- en: 2\. The four key dimensions of LLM Performance
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. LLM性能的四个关键维度
- en: '![](../Images/b3710797fed24fa0bee8b89a5044ad97.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3710797fed24fa0bee8b89a5044ad97.png)'
- en: 'Source: Generated with the help of AI (OpenAI’s Dall-E model)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：借助AI（OpenAI的Dall-E模型）生成
- en: There are 3 key ways to look at the performance of LLM based applications- namely
    accuracy, cost, and latency. It is additionally critical to make sure to have
    a set of criteria for Responsible AI to ensure the application is not harmful.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种关键方式来衡量基于LLM的应用性能——即准确性、成本和延迟。此外，确保拥有一套负责任的AI标准也至关重要，以确保应用不会造成伤害。
- en: Just like the bias vs. variance tradeoff we have in classical Machine Learning
    applications, for LLMs we have to consider the tradeoff between accuracy on one
    side and cost + latency on the other side. In general, it will be a balancing
    act, to create an application that is “accurate”(we will define what this means
    in a bit) while being fast enough and cost effective. The choice of LLM as well
    as the supporting application architecture will heavily depend on the end user
    experience we aim to achieve.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 就像经典机器学习应用中的偏差与方差权衡一样，对于LLM，我们必须考虑准确性与成本+延迟之间的权衡。通常，这将是一项平衡工作，旨在创建一个“准确”（稍后我们将定义这一点）且足够快速且具有成本效益的应用。LLM的选择以及支持的应用架构将极大地依赖于我们旨在实现的最终用户体验。
- en: '**2.1\. Accuracy**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2.1. 准确性**'
- en: I use the term “Accuracy” here rather loosely, as it has a very specific meaning,
    but gets the point across if used as an English word rather than a mathematical
    term.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里使用“准确性”这一术语时较为宽泛，因为它有一个非常具体的含义，但作为英语单词使用时，能够传达意思，而非数学术语。
- en: Accuracy of the application depends on the actual use case- whether the application
    is doing a classification task, if it’s creating a blob of text, or if it is being
    used for specialized tasks like Named Entity Recognition (NER), Retrieval Augmented
    Generation (RAG).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 应用的准确性取决于实际使用案例——无论是应用进行分类任务，还是创建文本块，或是用于命名实体识别（NER）、检索增强生成（RAG）等专业任务。
- en: '**2.1.1\. Classification use cases**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.1.1. 分类使用案例**'
- en: For classification tasks like sentiment analysis (positive/negative/neutral),
    topic modelling and Named Entity Recognition classical ML evaluation metrics are
    appropriate. They measure accuracy in terms of various dimensions across the confusion
    matrix. Typical measures include Precision, Recall, F1-Score etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于情感分析（正面/负面/中性）、主题建模和命名实体识别等分类任务，经典的机器学习评估指标是合适的。它们通过混淆矩阵的各个维度来衡量准确性。典型的度量标准包括精确率、召回率、F1值等。
- en: '**2.1.2\. Text generation use cases — including summarization and creative
    content**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.1.2. 文本生成使用案例——包括摘要和创意内容**'
- en: '[BLEU](https://en.wikipedia.org/wiki/BLEU), [ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)#:~:text=The%20metrics%20compare%20an%20automatically,produced%20summary%20and%20the%20reference)
    and [METEOR](https://en.wikipedia.org/wiki/METEOR) scores are common metrics used
    to evaluate text generation tasks, particularly for translation and summarization.
    To simplify, people also use F1 scores by combining BLEU and ROUGE scores. There
    are additional metrics like Perplexity which are particularly useful for evaluating
    LLMs themselves, but less useful to measure the performance of full blown applications.
    The biggest challenge with all the above metrics is that they focus on text similarity
    and not semantic similarity. Depending on the use case, text similarity may not
    be enough, and one should also use measures of semantic proximity like [SemScore](https://huggingface.co/blog/g-ronimo/semscore).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[BLEU](https://en.wikipedia.org/wiki/BLEU)、[ROUGE](https://en.wikipedia.org/wiki/ROUGE_(metric)#:~:text=The%20metrics%20compare%20an%20automatically,produced%20summary%20and%20the%20reference)
    和 [METEOR](https://en.wikipedia.org/wiki/METEOR) 分数是常用的文本生成任务评估指标，特别是用于翻译和摘要。为了简化，人们也会通过将BLEU和ROUGE分数结合使用F1分数。还有一些额外的指标，如困惑度（Perplexity），对于评估LLM本身特别有用，但对于评估完整应用的性能则不太有用。上述所有指标的最大挑战在于，它们关注的是文本相似度，而不是语义相似度。根据应用场景，文本相似度可能不足以满足需求，因此还应使用语义接近度的衡量标准，如[SemScore](https://huggingface.co/blog/g-ronimo/semscore)。'
- en: '**2.1.3\. RAG use cases — including summarization and creative content**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.1.3\. RAG应用场景 —— 包括摘要和创意内容**'
- en: In RAG based applications, evaluation requires advanced metrics to capture performance
    across retrieval as well as generation steps. For retrieval, one may use recall
    and precision to compare relevant and retrieved documents. For generation one
    may use additional metrics like Perplexity, Hallucination Rate, Factual Accuracy
    or Semantic coherence. [This Article](https://medium.com/@daniel.puenteviejo/key-metrics-for-evaluating-a-rag-system-f20b8bcae318)
    describes the key metrics that one might want to include in their evaluation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于RAG的应用中，评估需要先进的指标来捕捉检索和生成步骤的性能。在检索方面，可以使用召回率（recall）和精准率（precision）来比较相关文档和已检索文档。在生成方面，可以使用额外的指标，如困惑度（Perplexity）、幻觉率（Hallucination
    Rate）、事实准确性（Factual Accuracy）或语义一致性（Semantic coherence）。[这篇文章](https://medium.com/@daniel.puenteviejo/key-metrics-for-evaluating-a-rag-system-f20b8bcae318)描述了在评估中可能需要包括的关键指标。
- en: 2.2\. Latency (and Throughput)
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. 延迟（和吞吐量）
- en: In many situations, latency and throughput of an application determine its end
    usability, or use experience. In today’s generation of lightning fast internet,
    users do not want to be stuck waiting for a response, especially when executing
    critical jobs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，应用的延迟和吞吐量决定了其最终的可用性或使用体验。在如今这个网络速度飞快的时代，用户不愿意等待响应，尤其是在执行关键任务时。
- en: The lower the latency, the better the user experience in user-facing applications
    which require real time response. This may not be as important for workloads that
    execute in batches, e.g. transcription of customer service calls for later use.
    In general, both latency and throughput can be improved by horizontal or vertical
    scaling, but latency may still fundamentally depend on the way the overall application
    is architected, including the choice of LLM. A nice benchmark to use speed of
    different LLM APIs is [Artificial Analysis](https://artificialanalysis.ai/). This
    complements other leaderboards that focus on the quality of LLMs like LMSYS Chatbot
    Arena, Hugging Face open LLM leaderboards, and Stanford’s HELM which focus more
    on the quality of the outputs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟越低，用户面对面应用中的用户体验越好，这些应用需要实时响应。对于以批处理方式执行的工作负载（例如，用于后期使用的客户服务电话转录），这可能就不那么重要。通常，通过水平或垂直扩展可以改善延迟和吞吐量，但延迟仍然可能在根本上依赖于整体应用的架构方式，包括LLM（大语言模型）的选择。一个很好的基准工具来测试不同LLM
    API的速度是[人工分析](https://artificialanalysis.ai/)。这个工具与其他侧重于LLM质量的排行榜互为补充，如LMSYS聊天机器人竞技场、Hugging
    Face开放LLM排行榜和斯坦福的HELM，这些排行榜更多聚焦于输出质量。
- en: Latency is a key factor that will continue to push us towards Small Language
    Models for applications that require fast response time, where deployment on edge
    devices might be a necessity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是一个关键因素，它将继续推动我们朝着小型语言模型（Small Language Models）发展，特别是在需要快速响应时间的应用中，部署到边缘设备可能是必需的。
- en: 2.3\. Cost
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3\. 成本
- en: We are building LLM applications to solve business problems and create more
    efficiencies, with the hope of solving customer problems, as well as creating
    bottom line impact for our businesses. All of this comes at a cost, which could
    add up quickly for generative AI applications.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在构建LLM应用程序来解决业务问题并提高效率，旨在解决客户问题，同时为我们的业务创造底线影响。所有这些都需要成本，对于生成式AI应用程序来说，这些成本可能会迅速累积。
- en: 'In my experience, when people think of the cost of LLM applications, there
    is a lot of discussion about the cost of inference (which is based on #tokens),
    the cost of find tuning, or even the cost of pre-training a LLM. There is however
    limited discussion on the total cost of ownership, including infrastructure and
    personnel costs.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，当人们考虑LLM应用程序的成本时，通常会讨论推理成本（基于#tokens）、微调成本，甚至LLM预训练成本。然而，对于总拥有成本（包括基础设施和人员成本）的讨论却相对有限。
- en: The cost can vary based on the type of deployment (cloud, on-prem, hybrid),
    the scale of usage, and the architecture. It also varies a lot depending on the
    lifecycle of the application development.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 成本因部署类型（云端、本地、混合）、使用规模和架构的不同而有所不同。它也会根据应用程序开发的生命周期变化很大。
- en: '**Infrastructure costs** — includes inference, tuning costs, or potentially
    pre-training costs as well as the infrastructure — memory, compute, networking,
    and storage costs associated with the application. Depending on where one is building
    the application, these costs may not need to be managed separately, or bundled
    into one if one if using managed services like AWS Bedrock.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施成本**——包括推理、微调成本，或可能的预训练成本，以及与应用程序相关的基础设施——内存、计算、网络和存储成本。根据构建应用程序的位置，这些成本可能不需要单独管理，或者如果使用如AWS
    Bedrock等托管服务，则可以将其捆绑为一项成本。'
- en: '**Team and Personnel cost**- we may sometimes need an army of people to build,
    monitor, and improve these applications. This includes the engineers to build
    this (Data Scientists and ML Engineers, DevOps and MLOps engineers) as well as
    the cross functional teams of product/project managers, HR, Legal and Risk personnel
    who are involved in the design and development. We may also have annotation and
    labelling teams to provide us with high quality data.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**团队和人员成本**——我们有时可能需要一支庞大的团队来构建、监控和改进这些应用程序。这包括构建应用程序的工程师（数据科学家和ML工程师、DevOps和MLOps工程师），以及参与设计和开发的跨职能团队，如产品/项目经理、人力资源、法律和风险人员。我们可能还需要注释和标注团队为我们提供高质量的数据。'
- en: '**Other costs**- which may include the cost of data acquisition and management,
    customer interviews, software and licensing costs, Operational costs (MLOps/LLMOps),
    Security, and Compliance.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他成本**——可能包括数据获取和管理成本、客户访谈成本、软件和许可证费用、运营成本（MLOps/LLMOps）、安全性和合规性等。'
- en: 2.4\. Ethical and Responsible AI Metrics
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4\. 伦理与负责任的AI指标
- en: 'LLM based applications are still novel, many being mere proof of concepts.
    At the same time, they are becoming mainstream- I see AI integrated into so many
    applications I use daily, including Google, LinkedIn, Amazon shopping app, WhatsApp,
    InstaCart, etc. As the lines between human and AI interaction become blurrier,
    it becomes more essential that we adhere to responsible AI standards. The bigger
    problem is that these standards don’t exist today. Regulations around this are
    still being developed across the world (including the [Executive Order from the
    White House](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)).
    Hence, it’s crucial that application creators use their best judgment. Below are
    some of the key dimensions to keep in mind:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的应用程序仍然是新兴的，许多只是概念验证。然而，它们正在成为主流——我看到AI已经集成到我每天使用的许多应用中，包括Google、LinkedIn、亚马逊购物应用、WhatsApp、InstaCart等。随着人类与AI交互的界限变得越来越模糊，我们遵守负责任的AI标准变得更加重要。更大的问题是，这些标准目前并不存在。世界各地（包括[白宫的行政命令](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)）的相关法规仍在制定中。因此，应用程序创建者需要运用最好的判断力。以下是一些需要牢记的关键维度：
- en: '**Fairness and Bias**: Measures whether the model’s outputs are free from biases
    and fairness related to race, gender, ethnicity, and other dimensions.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平性和偏见**：衡量模型输出是否在种族、性别、民族和其他维度上不存在偏见和公平性问题。'
- en: '**Toxicity**: Measures the degree to which the model generates or amplifies
    harmful, offensive, or derogatory content.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有害内容**：衡量模型生成或放大有害、冒犯性或贬损内容的程度。'
- en: '**Explainability**: Assesses how explainable the model’s decisions are.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**：评估模型决策的可解释程度。'
- en: '**Hallucinations/Factual Consistency**: Ensures the model generates factually
    correct responses, especially in critical industries like healthcare and finance.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**幻觉/事实一致性**：确保模型生成事实正确的回应，尤其是在医疗和金融等关键行业中。'
- en: '**Privacy**: Measures the model’s ability to handle PII/PHI/other sensitive
    data responsibly, compliance with regulations like GDPR.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私**：衡量模型处理个人身份信息（PII）、受保护健康信息（PHI）及其他敏感数据的能力，确保符合如GDPR等法规的要求。'
- en: 3\. So are these metrics enough?
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 那么这些指标足够吗？
- en: 'Well… not really! While the four dimensions and metrics we discussed are essential
    and a good starting point, they are not always enough to capture the context,
    or unique user preferences. Given that humans are typically end consumers of the
    outputs, they are best positioned to evaluate the performance of LLM based applications,
    especially in complex or unknown scenarios. There are two ways to take human input:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯…其实并非如此！虽然我们讨论的四个维度和指标是非常重要的，并且是一个很好的起点，但它们并不总是足以捕捉到上下文或用户的独特偏好。考虑到人类通常是输出的最终消费者，他们最适合评估基于LLM的应用程序的表现，尤其是在复杂或未知场景中。获取人类反馈有两种方式：
- en: '**Direct via human-in-the-loop:** Human evaluators provide qualitative feedback
    on the outputs of LLMs, focusing on fluency, coherence, and alignment with human
    expectations. This feedback is crucial for improving the human-like behaviour
    of models.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直接通过人类参与**：人类评估者对LLM的输出提供定性反馈，关注流畅性、一致性以及与人类期望的一致性。这种反馈对于改进模型的人类化行为至关重要。'
- en: '**Indirect via secondary metrics:** A|B testing from end users can compare
    secondary metrics like user engagement and satisfaction. E.g., we can compare
    the performance of hyper-personalized marketing using generative AI by comparing
    click through rates and conversion rates.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**间接通过次级指标**：通过终端用户的A/B测试，可以比较次级指标，如用户参与度和满意度。例如，我们可以通过比较点击率和转化率，来评估使用生成式AI的超个性化营销的效果。'
- en: 4\. Conclusion
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 结论
- en: As a consultant, the answer to most questions is “It depends.”. This is true
    for evaluation criteria for LLM applications too. Depending on the use case/industry/function,
    one has to find the right balance of metrics across accuracy, latency, cost, and
    responsible AI. This should always be complemented by a human evaluation to make
    sure that we test the application in a real-world scenario. For example, medical
    and financial use cases will value accuracy and safety as well as attribution
    to credible sources, entertainment applications value creativity and user engagement.
    Cost will remain a critical factor while building the business case for an application,
    though the fast dropping cost of LLM inference might reduce barriers of entry
    soon. Latency is usually a limiting factor, and will require right model selection
    as well as infrastructure optimization to maintain performance.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作为顾问，大多数问题的答案是“视情况而定”。对于LLM应用的评估标准也是如此。根据不同的使用场景、行业和功能，必须在准确性、延迟、成本和负责任的AI之间找到合适的指标平衡。这应该始终辅以人类评估，以确保我们在实际场景中测试应用程序。例如，医疗和金融场景会重视准确性和安全性，以及来源的可信性，娱乐应用则重视创造力和用户参与度。在构建应用程序的商业案例时，成本将仍然是一个关键因素，尽管LLM推理成本的快速下降可能很快会降低准入门槛。延迟通常是一个限制因素，且需要通过正确的模型选择和基础设施优化来保持性能。
- en: All views in this article are the Author’s and don’t represent an endorsement
    of any products or services.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文中的所有观点均为作者个人观点，并不代表对任何产品或服务的支持。
