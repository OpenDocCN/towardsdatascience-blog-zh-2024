- en: 'Building a Semantic Book Search: Scale an Embedding Pipeline with Apache Spark
    and AWS EMR Serverless'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建语义图书搜索：使用Apache Spark和AWS EMR Serverless扩展嵌入管道
- en: 原文：[https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31](https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31](https://towardsdatascience.com/building-a-semantic-book-search-part-2-scaling-the-embedding-pipeline-with-apache-spark-and-aws-1d074ee9cb55?source=collection_archive---------8-----------------------#2024-01-31)
- en: '![](../Images/c41e10bbe243304d42ff3cdf276f15b0.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c41e10bbe243304d42ff3cdf276f15b0.png)'
- en: Image from Unsplash
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Unsplash
- en: Using OpenAI’s Clip model to support natural language search on a collection
    of 70k book covers
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenAI的Clip模型支持对70,000本书封面的自然语言搜索
- en: '[](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)[![Eva
    Revear](../Images/675266fccb503690d50d83b8c92f48b8.png)](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)
    [Eva Revear](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)[![Eva
    Revear](../Images/675266fccb503690d50d83b8c92f48b8.png)](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)
    [Eva Revear](https://medium.com/@erevear?source=post_page---byline--1d074ee9cb55--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)
    ·8 min read·Jan 31, 2024
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1d074ee9cb55--------------------------------)
    ·阅读时长8分钟·2024年1月31日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In a [previous post](https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea)
    I did a little PoC to see if I could use OpenAI’s Clip model to build a semantic
    book search. It worked surprisingly well, in my opinion, but I couldn’t help wondering
    if it would be better with more data. The previous version used only about 3.5k
    books, but there are millions in the [Openlibrary data set](https://openlibrary.org/data),
    and I thought it was worthwhile to try adding more options to the search space.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[上一篇文章](https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea)中，我做了一个小的PoC，看看能否使用OpenAI的Clip模型来构建语义图书搜索。依我看，效果出乎意料地好，但我不禁想，是否有更多数据会更好。之前的版本仅使用了大约3.5千本书，但在[Openlibrary数据集](https://openlibrary.org/data)中有数百万本书，我觉得尝试添加更多的搜索选项是值得的。
- en: However, the full dataset is about 40GB, and trying to handle that much data
    on my little laptop, or even in a Colab notebook was a bit much, so I had to figure
    out a pipeline that could manage filtering and embedding a larger data set.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，完整的数据集大约有40GB，试图在我的小笔记本电脑上，甚至在Colab笔记本中处理这么多数据有点困难，所以我不得不想办法构建一个管道来处理过滤和嵌入更大的数据集。
- en: TLDR; Did it improve the search? I think it did! We 15x’ed the data, which gives
    the search much more to work with. Its not perfect, but I thought the results
    were fairly interesting; although I haven’t done a formal accuracy measure.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: TLDR; 它改善了搜索吗？我认为是的！我们将数据量增加了15倍，这为搜索提供了更多可用数据。它还不完美，但我觉得结果相当有趣；虽然我没有做正式的准确度评测。
- en: This was one example I couldn’t get to work no matter how I phrased it in the
    last iteration, but works fairly well in the version with more data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个无论如何表述都无法在上一版本中运行的例子，但在使用更多数据的版本中效果相当不错。
- en: '![](../Images/607d576fe9f3cd3c251f1adee292b71f.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/607d576fe9f3cd3c251f1adee292b71f.png)'
- en: Image by author
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: If you’re curious you can try it out in [Colab](https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing)!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，可以在[Colab](https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing)上试试看！
- en: Overall, it was an interesting technical journey, with a lot of roadblocks and
    learning opportunities along the way. The tech stack still includes the OpenAI
    Clip model, but this time I leverage Apache Spark and AWS EMR to run the embedding
    pipeline.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这是一次有趣的技术旅程，过程中遇到了许多障碍和学习机会。技术栈仍然包括OpenAI的Clip模型，但这次我使用了Apache Spark和AWS
    EMR来运行嵌入管道。
- en: '**Tech Stack**'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**技术栈**'
- en: '![](../Images/23511f9399b09dea8df6e74c8f6e841d.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23511f9399b09dea8df6e74c8f6e841d.png)'
- en: Image by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: This seemed like a good opportunity to use Spark, as it allows us to parallelize
    the embedding computation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎是一个使用Spark的好机会，因为它允许我们将嵌入计算并行化。
- en: I decided to run the pipeline in EMR Serverless, which is a fairly new AWS offering
    that provides a serverless environment for EMR and manages scaling resources automatically.
    I felt it would work well for this use case — as opposed to spinning up an EMR
    on EC2 cluster — because this is a fairly ad-hoc project, I’m paranoid about cluster
    costs, and initially I was unsure about what resources the job would require.
    EMR Serverless makes it pretty easy to experiment with job parameters.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定在EMR Serverless中运行管道，这是AWS提供的一项相对较新的服务，提供了一个无服务器环境来运行EMR并自动管理资源的扩展。我认为这对于这个用例很合适——而不是在EC2集群上启动EMR——因为这是一个相对临时的项目，我对集群成本很敏感，而且最初我不确定这个作业需要什么资源。EMR
    Serverless使得实验作业参数变得非常简单。
- en: Below is the full process I went through to get everything up and running. I
    imagine there are better ways to manage certain steps, this is just what ended
    up working for me, so if you have thoughts or opinions, please do share!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我完成一切并使其运行的完整过程。我想可能有更好的方法来管理某些步骤，这只是对我有效的方式，如果你有想法或意见，请一定分享！
- en: Building an embedding pipeline job with Spark
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Spark构建嵌入管道作业
- en: The initial step was writing the Spark job(s). The full pipeline is broken out
    into two stages, the first takes in the initial data set and filters for recent
    fiction (within the last 10 years). This resulted in about 250k books, and around
    70k with cover images available to download and embed in the second stage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 初步步骤是编写Spark作业。整个管道分为两个阶段，第一个阶段获取初始数据集并筛选出近十年内的小说（过去10年）。这导致了大约25万本书籍，其中约7万本有封面图片可以下载并嵌入到第二阶段中。
- en: First we pull out the relevant columns from the raw data file.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从原始数据文件中提取相关列。
- en: Then do some general data transformation on data types, and filter out everything
    but English fiction with more than 100 pages.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后对数据类型进行一些通用的数据转换，并筛选出除英文小说（超过100页）以外的所有数据。
- en: The second stage grabs the first stage’s output dataset, and runs the images
    through the Clip model, downloaded from Hugging Face. The important step here
    is turning the various functions that we need to apply to the data into Spark
    UDFs. The main one of interest is get_image_embedding, which takes in the image
    and returns the embedding
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段获取第一阶段的输出数据集，并通过从Hugging Face下载的Clip模型处理图片。这里的关键步骤是将我们需要应用于数据的各种函数转化为Spark
    UDF。最关键的函数是get_image_embedding，它接受图片并返回嵌入信息。
- en: 'We register it as a UDF:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其注册为UDF：
- en: 'And call that UDF on the dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在数据集上调用UDF：
- en: Setting up the vector database
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置向量数据库
- en: As a last, optional, step in the code, we can setup a vector database, in this
    case Milvus, to load and query from. Note, I did not do this as part of the cloud
    job for this project, as I pickled my embeddings to use without having to keep
    a cluster up and running indefinitely. However, it is fairly simple to setup Milvus
    and load a Spark Dataframe to a collection.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作为代码中的最后一个可选步骤，我们可以设置一个向量数据库，在这个案例中是Milvus，用于加载和查询。请注意，我没有在此项目的云作业中执行此操作，因为我将我的嵌入数据序列化存储，以便不需要保持集群长时间运行。然而，设置Milvus并将Spark
    DataFrame加载到集合中是相当简单的。
- en: First, create a collection with an index on the image embedding column that
    the database can use for the search.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个集合，并在图像嵌入列上创建索引，数据库可以用来进行搜索。
- en: Then we can access the collection in the Spark script, and load the embeddings
    into it from the final Dataframe.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以在Spark脚本中访问该集合，并从最终的DataFrame中将嵌入加载到其中。
- en: Finally, we can simply embed the search text with the same method used in the
    UDF above, and hit the database with the embeddings. The database does the heavy
    lifting of figuring out the best matches
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用与上述UDF相同的方法将搜索文本嵌入，并使用嵌入信息查询数据库。数据库负责进行繁重的匹配工作，找出最佳匹配。
- en: Setting up the pipeline in AWS
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在AWS中设置管道
- en: '**Prerequisites**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件**'
- en: Now there’s a bit of setup to go through in order to run these jobs on EMR Serverless.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有一些设置需要完成，以便在 EMR Serverless 上运行这些作业。
- en: 'As prerequisites we need:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要以下先决条件：
- en: An S3 bucket for job scripts, inputs and outputs, and other artifacts that the
    job needs
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 S3 桶，用于存放作业脚本、输入和输出以及作业所需的其他工件
- en: An IAM role with Read, List, and Write permissions for S3, as well as Read and
    Write for Glue.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有 S3 读取、列出和写入权限的 IAM 角色，以及 Glue 的读取和写入权限。
- en: A trust policy that allows the EMR jobs to access other AWS services.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个信任策略，允许 EMR 作业访问其他 AWS 服务。
- en: 'There are great descriptions of the roles and permissions policies, as well
    as a general outline of how to get up and running with EMR Serverless in the AWS
    docs here: [Getting started with Amazon EMR Serverless](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/getting-started.html)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 文档中有关于角色和权限策略的详细描述，以及如何开始使用 EMR Serverless 的概述：[开始使用 Amazon EMR Serverless](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/getting-started.html)
- en: 'Next we have to setup an EMR Studio: [Create an EMR Studio](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-create-studio.html)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要设置一个 EMR Studio：[创建 EMR Studio](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-create-studio.html)
- en: '**Accessing the web via an Internet Gateway**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过互联网网关访问网页**'
- en: Another bit of setup that’s specific to this particular job is that we have
    to allow the job to reach out to the Internet, which the EMR application is not
    able to do by default. As we saw in the script, the job needs to access both the
    images to embed, as well as Hugging Face to download the model configs and weights.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特定于此作业的设置是，我们必须允许该作业访问互联网，而默认情况下 EMR 应用程序是无法做到这一点的。正如我们在脚本中看到的，作业需要访问要嵌入的图像，以及访问
    Hugging Face 以下载模型配置和权重。
- en: 'Note: There are likely more efficient ways to handle the model than downloading
    it to each worker (broadcasting it, storing it somewhere locally in the system,
    etc), but in this case, for a single run through the data, this is sufficient.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：可能有更高效的方式来处理模型，而不是将其下载到每个工作节点（例如广播、将其存储在系统中的某个地方等），但在这种情况下，对于一次数据运行，这就足够了。
- en: Anyway, allowing the machine the Spark job is running on to reach out to the
    Internet requires VPC with private subnets that have NAT gateways. All of this
    setup starts with accessing AWS VPC interface -> Create VPC -> selecting VPC and
    more -> selecting option for at least on NAT gateway -> clicking Create VPC.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，允许 Spark 作业运行的机器访问互联网需要配置具有 NAT 网关的私有子网的 VPC。所有这些设置都从访问 AWS VPC 界面开始 ->
    创建 VPC -> 选择 VPC 和更多选项 -> 选择至少一个 NAT 网关选项 -> 点击创建 VPC。
- en: '![](../Images/c949e2d8bba19e439972c50c44e0575e.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c949e2d8bba19e439972c50c44e0575e.png)'
- en: Image by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供
- en: The VPC takes a few minutes to set up. Once that is done we also need to create
    a security group in the security group interface, and attach the VPC we just created.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 设置需要几分钟。一旦完成，我们还需要在安全组界面中创建一个安全组，并将刚才创建的 VPC 附加到它。
- en: '**Creating the EMR Serverless application**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建 EMR Serverless 应用程序**'
- en: Now for the EMR Serverless application that will submit the job! Creating and
    launching an EMR studio should open a UI that offers a few options including creating
    an application. In the create application UI, select Use Custom settings -> Network
    settings. Here is where the VPC, the two private subnets, and the security group
    come into play.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，来看看将提交作业的 EMR Serverless 应用程序！创建并启动一个 EMR Studio 应该会打开一个界面，提供几个选项，包括创建应用程序。在创建应用程序的
    UI 中，选择使用自定义设置 -> 网络设置。在这里，VPC、两个私有子网和安全组将发挥作用。
- en: '![](../Images/ecdc638917b82e45aa67258591d2a561.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ecdc638917b82e45aa67258591d2a561.png)'
- en: Image by Author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供
- en: '**Building a virtual environment**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建虚拟环境**'
- en: 'Finally, the environment doesn’t come with many libraries, so in order to add
    additional Python dependencies we can either use native Python or create and package
    a virtual environment: [Using Python libraries with EMR Serverless](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/using-python-libraries.html).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，环境中没有太多库，因此为了添加额外的 Python 依赖项，我们可以使用本地 Python 或创建并打包一个虚拟环境：[在 EMR Serverless
    中使用 Python 库](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/using-python-libraries.html)。
- en: I went the second route, and the easiest way to do this is with Docker, as it
    allows us to build the virtual environment within the Amazon Linux distribution
    that’s running the EMR jobs (doing it in any other distribution or OS can become
    incredibly messy).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了第二种方式，最简单的方法是使用 Docker，因为它允许我们在运行 EMR 作业的 Amazon Linux 发行版中构建虚拟环境（在其他发行版或操作系统中做这件事可能会变得非常混乱）。
- en: 'Another warning: be careful to pick the version of EMR that corresponds to
    the version of Python that you are using, and choose package versions accordingly
    as well.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个警告：小心选择与您使用的 Python 版本对应的 EMR 版本，并相应地选择合适的包版本。
- en: The Docker process outputs the zipped up virtual environment as pyspark_dependencies.tar.gz,
    which then goes into the S3 bucket along with the job scripts.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 过程将打包好的虚拟环境输出为 pyspark_dependencies.tar.gz，然后将其与作业脚本一起上传到 S3 存储桶。
- en: We can then send this packaged environment along with the rest of the Spark
    job configurations
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将这个打包好的环境和其他 Spark 作业配置一起发送出去。
- en: Nice! We have the job script, the environmental dependencies, gateways, and
    an EMR application, we get to submit the job! Not so fast! Now comes the real
    fun, Spark tuning.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们有了作业脚本、环境依赖项、网关和一个 EMR 应用程序，我们可以提交作业了！不过，别着急！接下来才是真正有趣的部分：Spark 调优。
- en: As previously mentioned, EMR Serverless scales automatically to handle our workload,
    which typically would be great, but I found (obvious in hindsight) that it was
    unhelpful for this particular use case.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，EMR Serverless 会自动扩展以处理我们的工作负载，这通常是很好的，但我发现（事后看来是显而易见的）它对于这个特定的用例并没有什么帮助。
- en: A few tens of thousands of records is not at all “big data”; Spark wants terabytes
    of data to work through, and I was just sending essentially a few thousand image
    urls (not even the images themselves). Left to its own devices, EMR Serverless
    will send the job to one node to work through on a single thread, completely defeating
    the purpose of parallelization.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 几万条记录根本不算是“大数据”；Spark 需要处理的是 TB 级别的数据，而我发送的基本上只是几千个图片 URL（甚至连图片本身都没有）。如果让 EMR
    Serverless 自行决定，它会把任务发送到一个节点，在单线程中处理，完全违背了并行化的初衷。
- en: Additionally, while embedding jobs take in a relatively small amount of data,
    they expand it significantly, as the embeddings are quite large (512 in the case
    of Clip). Even if you leave that one node to churn away for a few days, it’ll
    run out of memory long before it finishes working through the full set of data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然嵌入作业处理的数据量相对较小，但它们会显著扩大数据量，因为嵌入体积相当大（在 Clip 的情况下是 512）。即使你让那个节点不停地运行几天，它也会在完成所有数据处理之前就耗尽内存。
- en: 'In order to get it to run, I experimented with a few Spark properties so that
    I could use large machines in the cluster, but split the data into very small
    partitions so that each core would have just a bit to work through and output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让它运行，我尝试了几个 Spark 属性，目的是能够在集群中使用大型机器，但将数据拆分成非常小的分区，以便每个核心只需要处理少量数据并输出：
- en: 'spark.executor.memory: Amount of memory to use per executor process'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: spark.executor.memory：每个执行器进程使用的内存量。
- en: 'spark.sql.files.maxPartitionBytes: The maximum number of bytes to pack into
    a single partition when reading files.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: spark.sql.files.maxPartitionBytes：读取文件时单个分区中要打包的最大字节数。
- en: 'spark.executor.cores: The number of cores to use on each executor.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: spark.executor.cores：每个执行器使用的核心数。
- en: You’ll have to tweak these depending on the particular nature of the your data,
    and embedding still isn’t a speedy process, but it was able to work through my
    data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要根据数据的具体性质调整这些设置，嵌入仍然不是一个快速的过程，但它能够处理我的数据。
- en: '**Conclusion**'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: As with my [previous post](https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea)
    the results certainly aren’t perfect, and by no means a replacement for solid
    book recommendations from other humans! But that being said there were some spot
    on answers to a number of my searches, which I thought was pretty cool.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 与我的[上一篇文章](https://medium.com/@erevear/building-semantic-book-search-with-openais-clip-model-b7c3dafa2bea)一样，结果当然不是完美的，绝对不能替代其他人提供的真实书籍推荐！但话说回来，对于我搜索的一些问题，确实有一些准确的答案，我觉得还挺酷的。
- en: If you want to play around with the app yourself, its in [Colab](https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing),
    and the full code for the pipeline is in [Github](https://github.com/erevear/book_semantic_search_cloud)!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想自己玩一下这个应用，它在[Colab](https://colab.research.google.com/drive/1QH_ZlDKAJ9I5yEitew6X_ZJWIvcmsqfv?usp=sharing)上，整个管道的代码在[Github](https://github.com/erevear/book_semantic_search_cloud)上！
