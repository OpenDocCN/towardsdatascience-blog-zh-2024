- en: Sensitivity Analysis for Unobserved Confounding
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„æ•æ„Ÿæ€§åˆ†æ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13](https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13](https://towardsdatascience.com/sensitivity-analysis-for-unobserved-confounding-465970a969e0?source=collection_archive---------10-----------------------#2024-02-13)
- en: How to know the unknowable in observational studies
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨è§‚å¯Ÿæ€§ç ”ç©¶ä¸­äº†è§£é‚£äº›æ— æ³•çŸ¥æ™“çš„äº‹ç‰©
- en: '[](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[![Ugur
    Yildirim](../Images/33db36531a170c9621504f466d61334b.png)](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)
    [Ugur Yildirim](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[![Ugur
    Yildirim](../Images/33db36531a170c9621504f466d61334b.png)](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)
    [Ugur Yildirim](https://medium.com/@uguryi?source=post_page---byline--465970a969e0--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)
    Â·10 min readÂ·Feb 13, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--465970a969e0--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 10 åˆ†é’ŸÂ·2024å¹´2æœˆ13æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Outline
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤§çº²
- en: '[Introduction](#48c3)'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å¼•è¨€](#48c3)'
- en: '[Problem Setup](#c5b8)'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[é—®é¢˜è®¾ç½®](#c5b8)'
- en: 2.1\. [Causal Graph](#3d15)
  id: totrans-9
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2.1\. [å› æœå›¾](#3d15)
- en: 2.2\. [Model With and Without *Z*](#b3b3)2.3\. [Strength of *Z* as a Confounder](#4b5a)
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2.2\. [æœ‰æ—  *Z* çš„æ¨¡å‹](#b3b3)2.3\. [ä½œä¸ºæ··æ‚å› ç´ çš„ *Z* çš„å¼ºåº¦](#4b5a)
- en: '[Sensitivity Analysis](#e05a)'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[æ•æ„Ÿæ€§åˆ†æ](#e05a)'
- en: 3.1\. [Goal](#3e88)
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3.1\. [ç›®æ ‡](#3e88)
- en: 3.2\. [Robustness Value](#dd07)
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3.2\. [ç¨³å¥æ€§å€¼](#dd07)
- en: '[PySensemakr](#5e81)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[PySensemakr](#5e81)'
- en: '[Conclusion](#8395)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ç»“è®º](#8395)'
- en: '[Acknowledgements](#d671)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[è‡´è°¢](#d671)'
- en: '[References](#b5bc)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å‚è€ƒæ–‡çŒ®](#b5bc)'
- en: 1\. Introduction
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. å¼•è¨€
- en: The specter of unobserved confounding (aka omitted variable bias) is a notorious
    problem in observational studies. In most observational studies, unless we can
    reasonably assume that treatment assignment is *as-if* random as in a natural
    experiment, we can never be truly certain that we controlled for all possible
    confounders in our model. As a result, our model estimates can be severely biased
    if we fail to control for an important confounderâ€“and we wouldnâ€™t even know it
    since the unobserved confounder is, well, unobserved!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ ï¼ˆå³é—æ¼å˜é‡åå€šï¼‰æ˜¯è§‚å¯Ÿæ€§ç ”ç©¶ä¸­çš„ä¸€ä¸ªè‘—åé—®é¢˜ã€‚åœ¨å¤§å¤šæ•°è§‚å¯Ÿæ€§ç ”ç©¶ä¸­ï¼Œé™¤éæˆ‘ä»¬èƒ½åˆç†å‡è®¾æ²»ç–—åˆ†é…åœ¨æŸäº›æ–¹é¢æ˜¯éšæœºçš„ï¼Œå¦‚åŒè‡ªç„¶å®éªŒä¸€æ ·ï¼Œå¦åˆ™æˆ‘ä»¬æ°¸è¿œæ— æ³•çœŸæ­£ç¡®å®šæˆ‘ä»¬åœ¨æ¨¡å‹ä¸­æ§åˆ¶äº†æ‰€æœ‰å¯èƒ½çš„æ··æ‚å› ç´ ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æœªèƒ½æ§åˆ¶ä½ä¸€ä¸ªé‡è¦çš„æ··æ‚å› ç´ ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼°è®¡å€¼å¯èƒ½ä¼šä¸¥é‡åå€šâ€”â€”è€Œæˆ‘ä»¬ç”šè‡³ä¸çŸ¥é“ï¼Œå› ä¸ºæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ ï¼Œå—¯ï¼Œç¡®å®æ˜¯æœªè§‚å¯Ÿåˆ°çš„ï¼
- en: 'Given this problem, it is important to assess how sensitive our estimates are
    to possible sources of unobserved confounding. In other words, it is a helpful
    exercise to ask ourselves: how much unobserved confounding would there have to
    be for our estimates to drastically change (e.g., treatment effect no longer statistically
    significant)? Sensitivity analysis for unobserved confounding is an active area
    of research, and there are several approaches to tackling this problem. In this
    post, I will cover a simple linear method [[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023)
    based on the concept of partial *RÂ²* that is widely applicable to a large spectrum
    of cases.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºè¿™ä¸ªé—®é¢˜ï¼Œè¯„ä¼°æˆ‘ä»¬çš„ä¼°è®¡å€¼å¯¹æ½œåœ¨æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„æ•æ„Ÿæ€§éå¸¸é‡è¦ã€‚æ¢å¥è¯è¯´ï¼Œé—®é—®è‡ªå·±ä¸€ä¸ªé—®é¢˜æ˜¯æœ‰å¸®åŠ©çš„ï¼šå¦‚æœæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ è¶³å¤Ÿå¤§ï¼Œæˆ‘ä»¬çš„ä¼°è®¡å€¼ä¼šå‘ç”Ÿå‰§çƒˆå˜åŒ–ï¼ˆä¾‹å¦‚ï¼Œæ²»ç–—æ•ˆåº”ä¸å†å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼‰å—ï¼Ÿæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„æ•æ„Ÿæ€§åˆ†ææ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸï¼Œè§£å†³è¿™ä¸ªé—®é¢˜æœ‰å‡ ç§æ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»‹ç»ä¸€ç§åŸºäºéƒ¨åˆ†
    *RÂ²* æ¦‚å¿µçš„ç®€å•çº¿æ€§æ–¹æ³•[[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023)ï¼Œè¿™ç§æ–¹æ³•å¹¿æ³›é€‚ç”¨äºå¤§å¤šæ•°æƒ…å†µã€‚
- en: 2\. Problem Setup
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. é—®é¢˜è®¾ç½®
- en: 2.1\. Causal Graph
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. å› æœå›¾
- en: 'Let us assume that we have four variables:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰å››ä¸ªå˜é‡ï¼š
- en: '*Y*: outcome'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y*: ç»“æœ'
- en: '*D*: treatment'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D*: æ²»ç–—'
- en: '*X*: observed confounder(s)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X*: è§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ '
- en: '*Z*: unobserved confounder(s)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Z*: æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å˜é‡'
- en: This is a common setting in many observational studies where the researcher
    is interested in knowing whether the treatment of interest has an effect on the
    outcome after controlling for possible treatment-outcome confounders.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è®¸å¤šè§‚å¯Ÿæ€§ç ”ç©¶ä¸­çš„å¸¸è§æƒ…å¢ƒï¼Œç ”ç©¶äººå‘˜å¸Œæœ›åœ¨æ§åˆ¶å¯èƒ½çš„æ²»ç–—â€”ç»“æœæ··æ‚å˜é‡åï¼Œäº†è§£æ‰€å…³æ³¨çš„æ²»ç–—æ˜¯å¦å¯¹ç»“æœäº§ç”Ÿå½±å“ã€‚
- en: In our hypothetical setting, the relationship between these variables are such
    that *X* and *Z* both affect *D* and *Y*, but *D* has no effect on *Y*. In other
    words, we are describing a scenario where the true treatment effect is null. As
    will become clear in the next section, the purpose of sensitivity analysis is
    being able to reason about this treatment effect when we have no access to *Z*,
    as we normally wonâ€™t since itâ€™s unobserved. Figure 1 visualizes our setup.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„å‡è®¾æƒ…å¢ƒä¸­ï¼Œè¿™äº›å˜é‡ä¹‹é—´çš„å…³ç³»æ˜¯*X*å’Œ*Z*éƒ½å½±å“*D*å’Œ*Y*ï¼Œä½†*D*å¯¹*Y*æ²¡æœ‰å½±å“ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æè¿°çš„æ˜¯ä¸€ä¸ªçœŸå®æ²»ç–—æ•ˆåº”ä¸ºé›¶çš„æƒ…æ™¯ã€‚æ­£å¦‚ä¸‹ä¸€éƒ¨åˆ†å°†æ˜ç¡®æŒ‡å‡ºçš„ï¼Œæ•æ„Ÿæ€§åˆ†æçš„ç›®çš„æ˜¯èƒ½å¤Ÿæ¨ç†å‡ºè¿™ä¸ªæ²»ç–—æ•ˆåº”ï¼Œå°½ç®¡æˆ‘ä»¬é€šå¸¸æ— æ³•è®¿é—®*Z*ï¼Œå› ä¸ºå®ƒæ˜¯æœªè§‚å¯Ÿåˆ°çš„ã€‚å›¾1å±•ç¤ºäº†æˆ‘ä»¬çš„è®¾å®šã€‚
- en: '**Figure 1: Problem Setup**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 1ï¼šé—®é¢˜è®¾å®š**'
- en: '![](../Images/bfd5d56edce6e7152043c61de6fe28f6.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bfd5d56edce6e7152043c61de6fe28f6.png)'
- en: 2.2\. Model With and Without Z
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. å¸¦*Z*å’Œä¸å¸¦*Z*çš„æ¨¡å‹
- en: To demonstrate the problem that our unobserved *Z* can cause, I simulated some
    data in line with the problem setup described above. You can refer to [this notebook](https://github.com/uguryi/unobserved_confounding/blob/main/unobserved_confounding.ipynb)
    for the details of the simulation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å±•ç¤ºæœªè§‚å¯Ÿåˆ°çš„*Z*å¯èƒ½é€ æˆçš„é—®é¢˜ï¼Œæˆ‘æ ¹æ®ä¸Šè¿°é—®é¢˜è®¾å®šæ¨¡æ‹Ÿäº†ä¸€äº›æ•°æ®ã€‚ä½ å¯ä»¥å‚è€ƒ[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/uguryi/unobserved_confounding/blob/main/unobserved_confounding.ipynb)æŸ¥çœ‹æ¨¡æ‹Ÿçš„è¯¦ç»†ä¿¡æ¯ã€‚
- en: Since *Z* would be unobserved in real life, the only model we can normally fit
    to data is *Y~D+X*. Let us see what results we get if we run that regression.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº*Z*åœ¨ç°å®ç”Ÿæ´»ä¸­æ— æ³•è§‚å¯Ÿåˆ°ï¼Œæˆ‘ä»¬é€šå¸¸èƒ½æ‹Ÿåˆåˆ°æ•°æ®çš„å”¯ä¸€æ¨¡å‹æ˜¯*Y~D+X*ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚æœæˆ‘ä»¬è¿è¡Œè¿™ä¸ªå›å½’ï¼Œç»“æœä¼šæ˜¯ä»€ä¹ˆã€‚
- en: Based on these results, it seems like *D* has a statistically significant effect
    of 0.2686 (*p*<0.001) per one unit change on *Y*, which we know isnâ€™t true based
    on how we generated the data (no *D* effect).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®è¿™äº›ç»“æœï¼Œä¼¼ä¹*D*å¯¹*Y*çš„æ¯å•ä½å˜åŒ–æœ‰ç»Ÿè®¡æ˜¾è‘—æ•ˆåº”0.2686ï¼ˆ*p*<0.001ï¼‰ï¼Œä½†æˆ‘ä»¬çŸ¥é“è¿™ä¸ç¬¦åˆäº‹å®ï¼Œå› ä¸ºæˆ‘ä»¬ç”Ÿæˆæ•°æ®çš„æ–¹å¼æ˜¯æ²¡æœ‰*D*æ•ˆåº”çš„ã€‚
- en: Now, letâ€™s see what happens to our *D* estimate when we control for *Z* as well.
    (In real life, we of course wonâ€™t be able to run this additional regression since
    *Z* is unobserved but our simulation setting allows us to peek behind the curtain
    into the true data generation process.)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬åŒæ—¶æ§åˆ¶*Z*æ—¶ï¼Œ*D*ä¼°è®¡å€¼ä¼šå‘ç”Ÿä»€ä¹ˆå˜åŒ–ã€‚ï¼ˆåœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œå½“ç„¶æˆ‘ä»¬æ— æ³•è¿›è¡Œè¿™ä¸ªé¢å¤–çš„å›å½’ï¼Œå› ä¸º*Z*æ˜¯æœªè§‚å¯Ÿåˆ°çš„ï¼Œä½†æˆ‘ä»¬çš„æ¨¡æ‹Ÿè®¾ç½®å…è®¸æˆ‘ä»¬çª¥æ¢çœŸæ­£çš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹ã€‚ï¼‰
- en: As expected, controlling for *Z* correctly removes the *D* effect by shrinking
    the estimate towards zero and giving us a *p*-value that is no longer statistically
    significant at the ğ›¼=0.05 threshold (*p*=0.059).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæ§åˆ¶*Z*åï¼Œ*D*æ•ˆåº”è¢«æ­£ç¡®ç§»é™¤ï¼Œä¼°è®¡å€¼æ”¶ç¼©è‡³é›¶ï¼Œå¹¶ä¸”æˆ‘ä»¬å¾—åˆ°çš„*p*å€¼åœ¨ğ›¼=0.05çš„æ˜¾è‘—æ€§æ°´å¹³ä¸‹ä¸å†æ˜¾è‘—ï¼ˆ*p*=0.059ï¼‰ã€‚
- en: 2.3\. Strength of Z as a Confounder
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3\. *Z*ä½œä¸ºæ··æ‚å˜é‡çš„å¼ºåº¦
- en: At this point, we have established that *Z* is strong enough of a confounder
    to eliminate the spurious *D* effect since the statistically significant *D* effect
    disappears when we control for *Z*. What we havenâ€™t discussed yet is exactly how
    strong *Z* is as a confounder. For this, we will utilize a useful statistical
    concept called partial *RÂ²*, which quantifies the proportion of variation that
    a given variable of interest can explain that canâ€™t already be explained by the
    existing variables in a model. In other words, partial *RÂ²* tells us the *added*
    explanatory power of that variable of interest, above and beyond the other variables
    that are already in the model. Formally, it can be defined as follows
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»ç¡®è®¤*Z*è¶³å¤Ÿå¼ºå¤§ï¼Œèƒ½å¤Ÿæ¶ˆé™¤è™šå‡çš„*D*æ•ˆåº”ï¼Œå› ä¸ºåœ¨æˆ‘ä»¬æ§åˆ¶*Z*ä¹‹åï¼Œç»Ÿè®¡ä¸Šæ˜¾è‘—çš„*D*æ•ˆåº”æ¶ˆå¤±äº†ã€‚æˆ‘ä»¬å°šæœªè®¨è®ºçš„æ˜¯*Z*ä½œä¸ºæ··æ‚å˜é‡çš„å…·ä½“å¼ºåº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ä¸€ä¸ªæœ‰ç”¨çš„ç»Ÿè®¡å­¦æ¦‚å¿µï¼Œå«åšéƒ¨åˆ†*RÂ²*ï¼Œå®ƒé‡åŒ–äº†ä¸€ä¸ªç»™å®šçš„å…´è¶£å˜é‡èƒ½å¤Ÿè§£é‡Šçš„å˜å¼‚é‡çš„æ¯”ä¾‹ï¼Œè¿™äº›å˜å¼‚é‡æ˜¯æ¨¡å‹ä¸­ç°æœ‰å˜é‡æ— æ³•è§£é‡Šçš„ã€‚æ¢å¥è¯è¯´ï¼Œéƒ¨åˆ†*RÂ²*å‘Šè¯‰æˆ‘ä»¬è¯¥å˜é‡çš„*é¢å¤–*è§£é‡ŠåŠ›ï¼Œè¶…å‡ºäº†æ¨¡å‹ä¸­å·²åŒ…å«çš„å…¶ä»–å˜é‡ã€‚å½¢å¼ä¸Šï¼Œå®ƒå¯ä»¥å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![](../Images/841f01ffb074c5bbcd67165995585666.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/841f01ffb074c5bbcd67165995585666.png)'
- en: where *RSS_reduced* is the residual sum of squares from the model that doesnâ€™t
    include the variable(s) of interest and *RSS_full* is the residual sum of squares
    from the model that includes the variable(s) of interest.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ*RSS_reduced* æ˜¯ä¸åŒ…å«æ„Ÿå…´è¶£å˜é‡çš„æ¨¡å‹çš„æ®‹å·®å¹³æ–¹å’Œï¼Œè€Œ *RSS_full* æ˜¯åŒ…å«æ„Ÿå…´è¶£å˜é‡çš„æ¨¡å‹çš„æ®‹å·®å¹³æ–¹å’Œã€‚
- en: In our case, the variable of interest is *Z*, and we would like to know what
    proportion of the variation in *Y* and *D* that *Z* can explain that canâ€™t already
    be explained by the existing variables. More precisely, we are interested in the
    following two partial *RÂ²* values
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ„Ÿå…´è¶£çš„å˜é‡æ˜¯ *Z*ï¼Œæˆ‘ä»¬æƒ³çŸ¥é“ *Z* èƒ½è§£é‡Š *Y* å’Œ *D* ä¸­çš„å˜å¼‚æ€§æœ‰å¤šå°‘æ˜¯ç°æœ‰å˜é‡æ— æ³•è§£é‡Šçš„ã€‚æ›´å‡†ç¡®åœ°è¯´ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯ä»¥ä¸‹ä¸¤ä¸ªéƒ¨åˆ†
    *RÂ²* å€¼ï¼š
- en: '![](../Images/ac6d3bca9e64679028bcb56422a4b6fc.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac6d3bca9e64679028bcb56422a4b6fc.png)'
- en: where (1) quantifies the proportion of variance in *Y* that can be explained
    by *Z* that canâ€™t already be explained by *D* and *X* (so the reduced model is
    Y~D+X and the full model is Y~D+X+Z), and (2) quantifies the proportion of variance
    in *D* that can be explained by *Z* that canâ€™t already be explained by *X* (so
    the reduced model is D~X and the full model is D~X+Z).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ (1) é‡åŒ–äº† *Y* ä¸­æ— æ³•é€šè¿‡ *D* å’Œ *X* å·²ç»è§£é‡Šçš„éƒ¨åˆ†ï¼Œèƒ½å¤Ÿè¢« *Z* è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ï¼ˆå› æ­¤ï¼Œç®€åŒ–æ¨¡å‹ä¸º Y~D+Xï¼Œå®Œæ•´æ¨¡å‹ä¸º
    Y~D+X+Zï¼‰ï¼Œ(2) é‡åŒ–äº† *D* ä¸­æ— æ³•é€šè¿‡ *X* å·²ç»è§£é‡Šçš„éƒ¨åˆ†ï¼Œèƒ½å¤Ÿè¢« *Z* è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ï¼ˆå› æ­¤ï¼Œç®€åŒ–æ¨¡å‹ä¸º D~Xï¼Œå®Œæ•´æ¨¡å‹ä¸º D~X+Zï¼‰ã€‚
- en: Now, let us see how strongly associated *Z* is with *D* and *Y* in our data
    in terms of partial *RÂ²*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ *Z* åœ¨æˆ‘ä»¬çš„æ•°æ®ä¸­ä¸ *D* å’Œ *Y* çš„å…³è”ç¨‹åº¦ï¼Œå…·ä½“æ˜¯é€šè¿‡éƒ¨åˆ† *RÂ²* æ¥è¡¡é‡ã€‚
- en: 'It turns out that *Z* explains 16% of the variation in *Y* that canâ€™t already
    be explained by *D* and *X* (this is partial *RÂ²* equation #1 above), and 20%
    of the variation in *D* that canâ€™t already be explained by *X* (this is partial
    *RÂ²* equation #2 above).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç»“æœè¡¨æ˜ï¼Œ*Z* è§£é‡Šäº† *Y* ä¸­ 16% çš„å˜å¼‚æ€§ï¼Œè¿™æ˜¯ *D* å’Œ *X* æ— æ³•è§£é‡Šçš„éƒ¨åˆ†ï¼ˆè¿™å°±æ˜¯ä¸Šé¢æåˆ°çš„éƒ¨åˆ† *RÂ²* æ–¹ç¨‹ #1ï¼‰ï¼Œå¹¶ä¸”è§£é‡Šäº†
    *D* ä¸­ 20% çš„å˜å¼‚æ€§ï¼Œè¿™æ˜¯ *X* æ— æ³•è§£é‡Šçš„éƒ¨åˆ†ï¼ˆè¿™å°±æ˜¯ä¸Šé¢æåˆ°çš„éƒ¨åˆ† *RÂ²* æ–¹ç¨‹ #2ï¼‰ã€‚'
- en: 3\. Sensitivity Analysis
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. æ•æ„Ÿæ€§åˆ†æ
- en: 3.1\. Goal
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1\. ç›®æ ‡
- en: As we discussed in the previous section, unobserved confounding poses a problem
    in real research settings precisely because, unlike in our simulation setting,
    *Z* cannot be observed. In other words, we are stuck with the model *Y~D+X*, having
    no way to know what our results would have been if we could run the model *Y~D+X+Z*
    instead. So, what can we do?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨å‰ä¸€èŠ‚ä¸­è®¨è®ºçš„ï¼Œæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ åœ¨çœŸå®ç ”ç©¶ç¯å¢ƒä¸­æ„æˆé—®é¢˜ï¼Œæ­£æ˜¯å› ä¸ºï¼Œå’Œæˆ‘ä»¬çš„æ¨¡æ‹Ÿè®¾ç½®ä¸åŒï¼Œ*Z* æ— æ³•è¢«è§‚å¯Ÿåˆ°ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬åªèƒ½ä½¿ç”¨æ¨¡å‹
    *Y~D+X*ï¼Œè€Œæ— æ³•çŸ¥é“å¦‚æœèƒ½è¿è¡Œæ¨¡å‹ *Y~D+X+Z*ï¼Œæˆ‘ä»¬çš„ç»“æœä¼šæ˜¯ä»€ä¹ˆæ ·å­ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½åšä»€ä¹ˆå‘¢ï¼Ÿ
- en: Intuitively, a reasonable sensitivity analysis approach should be able to tell
    us that if a *Z* such as the one we have in our data *were to exist*, it would
    nullify our results. Remember that our *Z* explains 16% of the variation in *Y*
    and 20% of the variation in *D* that canâ€™t be explained by observed variables.
    Therefore, we expect sensitivity analysis to tell us that a hypothetical *Z*-like
    confounder of similar strength would be enough to eliminate the statistically
    significant *D* effect.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´è§‚åœ°è¯´ï¼Œä¸€ä¸ªåˆç†çš„æ•æ„Ÿæ€§åˆ†ææ–¹æ³•åº”è¯¥èƒ½å¤Ÿå‘Šè¯‰æˆ‘ä»¬ï¼Œå¦‚æœæ•°æ®ä¸­å­˜åœ¨ç±»ä¼¼äº *Z* çš„å˜é‡ï¼Œå®ƒå°†ä½¿æˆ‘ä»¬çš„ç»“æœå¤±æ•ˆã€‚è®°ä½ï¼Œ*Z* è§£é‡Šäº† *Y* ä¸­ 16%
    çš„å˜å¼‚æ€§ï¼Œä»¥åŠ *D* ä¸­ 20% çš„å˜å¼‚æ€§ï¼Œè¿™äº›æ˜¯ç°æœ‰å˜é‡æ— æ³•è§£é‡Šçš„éƒ¨åˆ†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœŸæœ›æ•æ„Ÿæ€§åˆ†æèƒ½å¤Ÿå‘Šè¯‰æˆ‘ä»¬ï¼Œä¸€ä¸ªå‡è®¾çš„ã€ç±»ä¼¼ *Z* å¼ºåº¦çš„æ··æ‚å› ç´ å°†è¶³ä»¥æ¶ˆé™¤ç»Ÿè®¡ä¸Šæ˜¾è‘—çš„
    *D* æ•ˆåº”ã€‚
- en: But how can we calculate that the unobserved confounderâ€™s strength should be
    in this 16â€“20% range in the partial *RÂ²* scale *without ever having access to
    it*? Enter robustness value.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œå¦‚ä½•è®¡ç®—æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„å¼ºåº¦åº”è¯¥è½åœ¨è¿™ä¸ª 16% åˆ° 20% èŒƒå›´å†…ï¼Œ*è€Œä¸”æˆ‘ä»¬æ ¹æœ¬æ— æ³•æ¥è§¦åˆ°å®ƒ* å‘¢ï¼Ÿè¿™æ—¶å°±éœ€è¦å¼•å…¥ç¨³å¥æ€§å€¼ã€‚
- en: 3.2\. Robustness Value
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2\. ç¨³å¥æ€§å€¼
- en: Robustness value (RV) formalizes the idea we mentioned above of determining
    the necessary strength of a hypothetical unobserved confounder that could nullify
    our results. The usefulness of RV emanates from the fact that we only need our
    observable model *Y~D+X* and not the unobservable model *Y~D+X+Z* to be able to
    calculate it.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å¥æ€§å€¼ï¼ˆRVï¼‰æ­£å¼åŒ–äº†æˆ‘ä»¬ä¸Šé¢æåˆ°çš„æ¦‚å¿µï¼Œå³ç¡®å®šä¸€ä¸ªå‡è®¾çš„æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„å¿…è¦å¼ºåº¦ï¼Œè¶³ä»¥ä½¿æˆ‘ä»¬çš„ç»“æœå¤±æ•ˆã€‚ç¨³å¥æ€§å€¼çš„å®ç”¨æ€§åœ¨äºï¼Œæˆ‘ä»¬åªéœ€è¦æˆ‘ä»¬çš„å¯è§‚å¯Ÿæ¨¡å‹
    *Y~D+X*ï¼Œè€Œä¸éœ€è¦ä¸å¯è§‚å¯Ÿçš„æ¨¡å‹ *Y~D+X+Z*ï¼Œå°±èƒ½å¤Ÿè®¡ç®—å‡ºå®ƒã€‚
- en: Formally, we can write down as follows the RV that quantifies how strong unobserved
    confounding needs to be to change our observed statistical significance of the
    treatment effect (if the notation is too much to follow, just remember the key
    idea that the RV is a measure of the strength of confounding needed to change
    our results)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¼åœ°ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å†™ä¸ºå¦‚ä¸‹å½¢å¼ï¼Œæ¥é‡åŒ–éœ€è¦å¤šå¼ºçš„æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ ï¼Œæ‰èƒ½æ”¹å˜æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„å¤„ç†æ•ˆåº”çš„ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆå¦‚æœç¬¦å·å¤ªå¤æ‚è·Ÿä¸ä¸Šï¼Œå¯ä»¥è®°ä½è¿™ä¸ªå…³é”®ç‚¹ï¼šRVæ˜¯è¡¡é‡æ··æ‚å› ç´ å¼ºåº¦çš„åº¦é‡ï¼Œè¶³ä»¥æ”¹å˜æˆ‘ä»¬çš„ç»“æœï¼‰
- en: '![](../Images/a792c163556de1c4ad40364b6a2578b2.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a792c163556de1c4ad40364b6a2578b2.png)'
- en: Image by author, equations based on [[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023),
    see pages 49â€“52
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ï¼Œæ–¹ç¨‹å¼åŸºäº[[1]](https://academic.oup.com/jrsssb/article/82/1/39/7056023)ï¼Œå‚è§ç¬¬49â€“52é¡µ
- en: where
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­
- en: ğ›¼ is our chosen significance level (generally set to 0.05 or 5%),
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğ›¼æ˜¯æˆ‘ä»¬é€‰æ‹©çš„æ˜¾è‘—æ€§æ°´å¹³ï¼ˆé€šå¸¸è®¾ç½®ä¸º0.05æˆ–5%ï¼‰ï¼Œ
- en: '*q* determines the percent reduction *q**100% in significance that we care
    about (generally set to 1, since we usually care about confounding that would
    reduce statistical significance by 1*100%=100% hence rendering it not statistically
    significant),'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*q*å†³å®šäº†æˆ‘ä»¬å…³å¿ƒçš„æ˜¾è‘—æ€§å‡å°‘çš„ç™¾åˆ†æ¯”*q**100%ï¼ˆé€šå¸¸è®¾ç½®ä¸º1ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸å…³å¿ƒèƒ½å¤Ÿå°†ç»Ÿè®¡æ˜¾è‘—æ€§å‡å°‘1*100%=100%çš„æ··æ‚å› ç´ ï¼Œä»è€Œä½¿å…¶ä¸å†å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼‰ï¼Œ'
- en: '*t_betahat_treat* is the observed *t*-value of our treatment from the model
    *Y~D+X* (which is 8.389 in this case as can be seen from the regression results
    above),'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t_betahat_treat*æ˜¯æˆ‘ä»¬ä»æ¨¡å‹*Y~D+X*ä¸­è§‚å¯Ÿåˆ°çš„* t*-å€¼ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ä¸º8.389ï¼Œå¯ä»¥ä»ä¸Šé¢çš„å›å½’ç»“æœä¸­çœ‹åˆ°ï¼‰ï¼Œ'
- en: '*df* is our degrees of freedom (which is 1000â€“3=997 in this case since we simulated
    1000 samples and are estimating 3 parameters including the intercept), and'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*df*æ˜¯æˆ‘ä»¬çš„è‡ªç”±åº¦ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ä¸º1000â€“3=997ï¼Œå› ä¸ºæˆ‘ä»¬æ¨¡æ‹Ÿäº†1000ä¸ªæ ·æœ¬ï¼Œå¹¶ä¸”æ­£åœ¨ä¼°è®¡åŒ…æ‹¬æˆªè·åœ¨å†…çš„3ä¸ªå‚æ•°ï¼‰ï¼Œå¹¶ä¸”'
- en: '*t*_alpha,df-1* is the *t*-value threshold associated with a given ğ›¼ and *df-1*
    (1.96 if ğ›¼ is set to 0.05).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t*_alpha,df-1*æ˜¯ä¸ç»™å®šğ›¼å’Œ*df-1*ï¼ˆå¦‚æœğ›¼è®¾ç½®ä¸º0.05ï¼Œåˆ™ä¸º1.96ï¼‰ç›¸å…³çš„*t*-å€¼ä¸´ç•Œå€¼ã€‚'
- en: We are now ready to calculate the RV in our own data using only the observed
    model *Y~D+X* (*res_ydx*).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨ä»…è§‚å¯Ÿåˆ°çš„æ¨¡å‹*Y~D+X*ï¼ˆ*res_ydx*ï¼‰åœ¨æˆ‘ä»¬è‡ªå·±çš„æ•°æ®ä¸­è®¡ç®—RVäº†ã€‚
- en: It is by no struck of luck that our RV (18%) falls right in the range of the
    partial *RÂ²* values we calculated for *Y~Z|D,X* (16%) and *D~Z|X* (20%) above.
    What the RV is telling us here is that, *even without any explicit knowledge of
    Z*, we can still reason that any unobserved confounder needs, on average, at least
    18% strength in the partial *RÂ²* scale vis-Ã -vis both the treatment and the outcome
    to be able to nullify our statistically significant result.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„RVï¼ˆ18%ï¼‰æ°å¥½è½åœ¨æˆ‘ä»¬ä¸º*Y~Z|D,X*ï¼ˆ16%ï¼‰å’Œ*D~Z|X*ï¼ˆ20%ï¼‰è®¡ç®—çš„éƒ¨åˆ†*RÂ²*å€¼èŒƒå›´å†…ï¼Œè¿™å¹¶éå¶ç„¶ã€‚è¿™é‡ŒRVå‘Šè¯‰æˆ‘ä»¬çš„æ˜¯ï¼Œ*å³ä½¿æ²¡æœ‰Zçš„æ˜ç¡®çŸ¥è¯†*ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥æ¨ç†å‡ºï¼Œä»»ä½•æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ å¹³å‡éœ€è¦è‡³å°‘18%çš„å¼ºåº¦ï¼Œæ‰èƒ½åœ¨éƒ¨åˆ†*RÂ²*å°ºåº¦ä¸Šå¯¹å¤„ç†å’Œç»“æœéƒ½äº§ç”Ÿå½±å“ï¼Œä»è€Œä½¿å¾—æˆ‘ä»¬åŸæœ¬æ˜¾è‘—çš„ç»“æœä¸å†æ˜¾è‘—ã€‚
- en: 'The reason why the RV isnâ€™t 16% or 20% but falls somewhere in between (18%)
    is that it is designed to be a single number that *summarizes* the necessary strength
    of the confounder with both the outcome and the treatment, so 18% makes perfect
    sense given what we know about the data. You can think about it like this: since
    the method doesnâ€™t have access to the actual numbers 16% and 20% when calculating
    the RV, it is doing its best to quantify the strength of the confounder by assigning
    18% to both partial *RÂ²* values (*Y~Z|D,X* and *D~Z|X*), which isnâ€™t too far off
    from the truth at all and actually does a great job summarizing the strength of
    the confounder.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: RVä¹‹æ‰€ä»¥ä¸æ˜¯16%æˆ–20%ï¼Œè€Œæ˜¯è½åœ¨ä¸­é—´ï¼ˆ18%ï¼‰ï¼Œæ˜¯å› ä¸ºå®ƒè¢«è®¾è®¡ä¸ºä¸€ä¸ªå•ä¸€çš„æ•°å­—ï¼Œ*æ€»ç»“*äº†ä¸ç»“æœå’Œå¤„ç†ç›¸å…³çš„æ··æ‚å› ç´ çš„å¿…è¦å¼ºåº¦ï¼Œå› æ­¤18%æ˜¯åˆæƒ…åˆç†çš„ï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬å¯¹æ•°æ®çš„äº†è§£ã€‚ä½ å¯ä»¥è¿™æ ·ç†è§£ï¼šç”±äºè¯¥æ–¹æ³•åœ¨è®¡ç®—RVæ—¶æ²¡æœ‰å®é™…è®¿é—®16%å’Œ20%çš„æ•°å­—ï¼Œå®ƒå°½åŠ›é€šè¿‡å°†18%åˆ†é…ç»™ä¸¤ä¸ªéƒ¨åˆ†çš„*RÂ²*å€¼ï¼ˆ*Y~Z|D,X*
    å’Œ *D~Z|X*ï¼‰ï¼Œæ¥é‡åŒ–æ··æ‚å› ç´ çš„å¼ºåº¦ï¼Œè¿™ä¸€ç‚¹ä¸å®é™…æƒ…å†µç›¸å·®ä¸å¤§ï¼Œå®é™…ä¸Šä¹Ÿå¾ˆå¥½åœ°æ€»ç»“äº†æ··æ‚å› ç´ çš„å¼ºåº¦ã€‚
- en: Of course, in real life we wonâ€™t have the *Z* variable to double check that
    our RV is correct, but seeing how the two results align here should at least give
    you some confidence in the method. Finally, once we calculate the RV, we should
    think about whether an unobserved confounder of that strength is plausible. In
    our case, the answer is â€˜yesâ€™ because we have access to the data generation process,
    but for your specific real-life application, the existence of such a strong confounder
    might be an unreasonable assumption. This would be good news for you since no
    realistic unobserved confounder could drastically change your results.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œåœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šæœ‰ *Z* å˜é‡æ¥å†æ¬¡æ£€æŸ¥æˆ‘ä»¬çš„ RV æ˜¯å¦æ­£ç¡®ï¼Œä½†çœ‹åˆ°è¿™ä¸¤ä¸ªç»“æœçš„å¯¹é½è‡³å°‘å¯ä»¥è®©ä½ å¯¹è¿™ä¸ªæ–¹æ³•æœ‰ä¸€äº›ä¿¡å¿ƒã€‚æœ€åï¼Œä¸€æ—¦æˆ‘ä»¬è®¡ç®—å‡º
    RVï¼Œæˆ‘ä»¬åº”è¯¥è€ƒè™‘ä¸€ä¸ªå¦‚æ­¤å¼ºåº¦çš„æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ æ˜¯å¦åˆç†ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œç­”æ¡ˆæ˜¯â€œæ˜¯çš„â€ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥è®¿é—®æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼Œä½†å¯¹äºä½ çš„ç‰¹å®šå®é™…åº”ç”¨ï¼Œå‡è®¾å­˜åœ¨å¦‚æ­¤å¼ºçš„æ··æ‚å› ç´ å¯èƒ½æ˜¯ä¸åˆç†çš„ã€‚å¯¹ä½ æ¥è¯´è¿™æ˜¯å¥½æ¶ˆæ¯ï¼Œå› ä¸ºæ²¡æœ‰ç°å®ä¸­æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ å¯ä»¥æå¤§åœ°æ”¹å˜ä½ çš„ç»“æœã€‚
- en: 4\. PySensemakr
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. PySensemakr
- en: The sensitivity analysis technique described above has already been implemented
    with all of its bells and whistles as a Python package under the name [PySensemakr](https://github.com/nlapier2/PySensemakr)
    (R, Stata, and Shiny App versions exist as well). For example, to get the exact
    same result that we manually calculated in the previous section, we can simply
    run the following code chunk.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°æ•æ„Ÿæ€§åˆ†ææŠ€æœ¯å·²ç»ä»¥ [PySensemakr](https://github.com/nlapier2/PySensemakr) è¿™ä¸ª Python
    åŒ…çš„å½¢å¼å®ç°äº†ï¼Œä¸”å…·å¤‡äº†æ‰€æœ‰çš„åŠŸèƒ½ï¼ˆä¹Ÿæœ‰ Rã€Stata å’Œ Shiny App ç‰ˆæœ¬ï¼‰ã€‚ä¾‹å¦‚ï¼Œè¦è·å¾—ä¸æˆ‘ä»¬åœ¨å‰ä¸€éƒ¨åˆ†æ‰‹åŠ¨è®¡ç®—çš„å®Œå…¨ç›¸åŒçš„ç»“æœï¼Œæˆ‘ä»¬åªéœ€è¿è¡Œä»¥ä¸‹ä»£ç å—ã€‚
- en: Note that â€œRobustness Value, q = 1 alpha = 0.05â€ is 0.184, which is exactly
    what we calculated above. In addition to the RV for statistical significance,
    the package also provides the RV that is needed for the coefficient estimate itself
    to shrink to 0\. Not surprisingly, unobserved confounding needs to be even larger
    for this to happen (0.233 vs 0.184).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œâ€œRobustness Value, q = 1 alpha = 0.05â€ çš„å€¼ä¸º 0.184ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬ä¹‹å‰è®¡ç®—çš„ç»“æœã€‚é™¤äº†ç”¨äºç»Ÿè®¡æ˜¾è‘—æ€§çš„
    RVï¼Œè½¯ä»¶åŒ…è¿˜æä¾›äº†ç”¨äºå°†ç³»æ•°ä¼°è®¡å€¼æ”¶ç¼©è‡³ 0 æ‰€éœ€çš„ RVã€‚æ¯«ä¸å¥‡æ€ªï¼Œä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ éœ€è¦æ›´å¤§ï¼ˆ0.233 ä¸ 0.184ï¼‰ã€‚
- en: The package also provides contour plots for the two partial *RÂ²* values, which
    allows for an intuitive visual display of sensitivity to possible levels of confounding
    with the treatment and the outcome (in this case, it shouldnâ€™t be surprising to
    see that the x/y-axis value pairs that meet the red dotted line include 0.18/0.18
    as well as 0.20/0.16).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è½¯ä»¶åŒ…è¿˜æä¾›äº†ä¸¤ä¸ªéƒ¨åˆ† *RÂ²* å€¼çš„è½®å»“å›¾ï¼Œè¿™å¯ä»¥ç›´è§‚åœ°æ˜¾ç¤ºæ²»ç–—å’Œç»“æœå¯èƒ½çš„æ··æ‚ç¨‹åº¦å¯¹æ•æ„Ÿæ€§çš„å½±å“ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œçœ‹åˆ°æ»¡è¶³çº¢è‰²è™šçº¿çš„ x/y è½´å€¼å¯¹åŒ…æ‹¬
    0.18/0.18 å’Œ 0.20/0.16 æ˜¯ä¸è¶³ä¸ºå¥‡çš„ï¼‰ã€‚
- en: One can even add benchmark values to the contour plot as proxies for possible
    amounts of confounding. In our case, since we only have one observed covariate
    *X*, we can set our benchmarks to be 0.25x, 0.5x and 1x as strong as that observed
    covariate. The resulting plot tells us that a confounder that is half as strong
    as *X* should be enough to nullify our statistically significant result (since
    the â€œ0.5x Xâ€ value falls right on the red dotted line).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç”šè‡³å¯ä»¥å°†åŸºå‡†å€¼æ·»åŠ åˆ°è½®å»“å›¾ä¸­ï¼Œä½œä¸ºæ··æ‚å› ç´ å¯èƒ½ç¨‹åº¦çš„ä»£ç†ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªè§‚å¯Ÿåˆ°çš„åå˜é‡ *X*ï¼Œæˆ‘ä»¬å¯ä»¥å°†åŸºå‡†å€¼è®¾ç½®ä¸ºä¸è¯¥è§‚å¯Ÿåˆ°çš„åå˜é‡å¼ºåº¦ç›¸å½“çš„
    0.25xã€0.5x å’Œ 1xã€‚ç”±æ­¤å¾—åˆ°çš„å›¾è¡¨å‘Šè¯‰æˆ‘ä»¬ï¼Œä¸€ä¸ªå¼ºåº¦ä»…ä¸º *X* ä¸€åŠçš„æ··æ‚å› ç´ åº”è¯¥è¶³ä»¥ä½¿æˆ‘ä»¬ç»Ÿè®¡æ˜¾è‘—çš„ç»“æœæ— æ•ˆï¼ˆå› ä¸ºâ€œ0.5x Xâ€å€¼æ°å¥½ä½äºçº¢è‰²è™šçº¿å¤„ï¼‰ã€‚
- en: Finally, I would like to note that while the simulated data in this example
    used a continuous treatment variable, in practice the method works for any kind
    of treatment variable including binary treatments. On the other hand, the outcome
    variable technically needs to be a continuous one since we are operating in the
    OLS framework. However, the method can still be used even with a binary outcome
    if we model it using OLS (this is called a LPM [[2]](https://murraylax.org/rtutorials/linearprob.html)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘æƒ³æŒ‡å‡ºï¼Œå°½ç®¡æœ¬ç¤ºä¾‹ä¸­çš„æ¨¡æ‹Ÿæ•°æ®ä½¿ç”¨äº†ä¸€ä¸ªè¿ç»­çš„å¤„ç†å˜é‡ï¼Œä½†åœ¨å®è·µä¸­ï¼Œè¯¥æ–¹æ³•é€‚ç”¨äºä»»ä½•ç±»å‹çš„å¤„ç†å˜é‡ï¼ŒåŒ…æ‹¬äºŒå…ƒå¤„ç†ã€‚å¦ä¸€æ–¹é¢ï¼Œç»“æœå˜é‡åœ¨æŠ€æœ¯ä¸Šéœ€è¦æ˜¯è¿ç»­å‹çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¤„åœ¨
    OLS æ¡†æ¶ä¸­ã€‚ç„¶è€Œï¼Œå³ä½¿ç»“æœæ˜¯äºŒå…ƒçš„ï¼Œåªè¦æˆ‘ä»¬é€šè¿‡ OLS å»ºæ¨¡ï¼ˆè¿™ç§°ä¸º LPM [[2]](https://murraylax.org/rtutorials/linearprob.html)ï¼‰ï¼Œè¯¥æ–¹æ³•ä»ç„¶å¯ä»¥ä½¿ç”¨ã€‚
- en: 5\. Conclusion
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. ç»“è®º
- en: The possibility that our effect estimate may be biased due to unobserved confounding
    is a common danger in observational studies. Despite this potential danger, observational
    studies are a vital tool in data science because randomization simply isnâ€™t feasible
    in many cases. Therefore, it is important to know how we can address the issue
    of unobserved confounding by running sensitivity analyses to see how robust our
    estimates are to potential such confounding.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ•ˆåº”ä¼°è®¡å¯èƒ½ç”±äºæœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ è€Œäº§ç”Ÿåå·®ï¼Œè¿™æ˜¯è§‚å¯Ÿæ€§ç ”ç©¶ä¸­çš„å¸¸è§é£é™©ã€‚å°½ç®¡å­˜åœ¨è¿™ä¸€æ½œåœ¨é£é™©ï¼Œè§‚å¯Ÿæ€§ç ”ç©¶ä»ç„¶æ˜¯æ•°æ®ç§‘å­¦ä¸­ä¸€é¡¹è‡³å…³é‡è¦çš„å·¥å…·ï¼Œå› ä¸ºåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼ŒéšæœºåŒ–å®éªŒæ˜¯ä¸å¯è¡Œçš„ã€‚å› æ­¤ï¼Œäº†è§£å¦‚ä½•é€šè¿‡è¿›è¡Œæ•æ„Ÿæ€§åˆ†ææ¥è§£å†³æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ é—®é¢˜ï¼Œä»¥æŸ¥çœ‹æˆ‘ä»¬çš„ä¼°è®¡åœ¨æ½œåœ¨æ··æ‚å› ç´ ä¸‹çš„é²æ£’æ€§ï¼Œæ˜¯éå¸¸é‡è¦çš„ã€‚
- en: The robustness value method by Cinelli and Hazlett discussed in this post is
    a simple and intuitive approach to sensitivity analysis formulated in a familiar
    linear model framework. If you are interested in learning more about the method,
    I highly recommend taking a look at the original paper and the [package documentation](https://pysensemakr.readthedocs.io/en/latest/index.html)
    where you can learn about many more interesting applications of the method such
    as â€˜extreme scenarioâ€™ analysis.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡è®¨è®ºçš„Cinelliå’ŒHazlettæå‡ºçš„é²æ£’å€¼æ–¹æ³•æ˜¯ä¸€ç§ç®€å•ç›´è§‚çš„æ•æ„Ÿæ€§åˆ†ææ–¹æ³•ï¼ŒåŸºäºç†Ÿæ‚‰çš„çº¿æ€§æ¨¡å‹æ¡†æ¶ã€‚å¦‚æœä½ æœ‰å…´è¶£æ·±å…¥äº†è§£è¯¥æ–¹æ³•ï¼Œæˆ‘å¼ºçƒˆæ¨èé˜…è¯»åŸå§‹è®ºæ–‡ä»¥åŠ[åŒ…æ–‡æ¡£](https://pysensemakr.readthedocs.io/en/latest/index.html)ï¼Œåœ¨å…¶ä¸­ä½ å¯ä»¥äº†è§£è¯¥æ–¹æ³•çš„è®¸å¤šæœ‰è¶£åº”ç”¨ï¼Œå¦‚â€œæç«¯æƒ…æ™¯â€åˆ†æã€‚
- en: There are also many other approaches to sensitivity analysis for unobserved
    confounding, and I would like briefly mention some of them here for readers who
    would like to continue learning more on this topic. One versatile technique is
    the E-value developed by VanderWeele and Ding that formulates the problem in terms
    of risk ratios [[3]](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)
    (implemented in R [here](https://cran.r-project.org/web/packages/EValue/index.html)).
    Another technique is the Austen plot developed by Veitch and Zaveri based on the
    concepts of partial *RÂ²* and propensity score [[4]](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf)
    (implemented in Python [here](https://github.com/anishazaveri/austen_plots)),
    and yet another recent approach is by Chernozhukov et al [[5]](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf)
    (implemented in Python [here](https://docs.doubleml.org/stable/examples/py_double_ml_sensitivity.html)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰è®¸å¤šå…¶ä»–é’ˆå¯¹æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ çš„æ•æ„Ÿæ€§åˆ†ææ–¹æ³•ï¼Œæˆ‘åœ¨æ­¤ç®€è¦æåŠå…¶ä¸­ä¸€äº›ï¼Œä¾›æœ‰å…´è¶£æ·±å…¥å­¦ä¹ è¯¥ä¸»é¢˜çš„è¯»è€…å‚è€ƒã€‚ä¸€ä¸ªå¤šåŠŸèƒ½çš„æŠ€æœ¯æ˜¯VanderWeeleå’ŒDingå¼€å‘çš„Eå€¼ï¼Œå®ƒå°†é—®é¢˜è¡¨è¿°ä¸ºé£é™©æ¯”
    [[3]](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)ï¼ˆåœ¨Rä¸­å®ç°çš„ç‰ˆæœ¬
    [è¿™é‡Œ](https://cran.r-project.org/web/packages/EValue/index.html)ï¼‰ã€‚å¦ä¸€ç§æŠ€æœ¯æ˜¯Veitchå’ŒZaveriåŸºäºéƒ¨åˆ†*RÂ²*å’Œå€¾å‘è¯„åˆ†æ¦‚å¿µå¼€å‘çš„Austenå›¾
    [[4]](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf)ï¼ˆåœ¨Pythonä¸­å®ç°çš„ç‰ˆæœ¬
    [è¿™é‡Œ](https://github.com/anishazaveri/austen_plots)ï¼‰ï¼Œè¿˜æœ‰ä¸€ç§æœ€è¿‘çš„åŠæ³•æ˜¯Chernozhukovç­‰äººæå‡ºçš„
    [[5]](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf)ï¼ˆåœ¨Pythonä¸­å®ç°çš„ç‰ˆæœ¬
    [è¿™é‡Œ](https://docs.doubleml.org/stable/examples/py_double_ml_sensitivity.html)ï¼‰ã€‚
- en: 6\. Acknowledgements
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. è‡´è°¢
- en: I would like to thank Chad Hazlett for answering my question related to using
    the method with binary outcomes and Xinyi Zhang for providing a lot of valuable
    feedback on the post. Unless otherwise noted, all images are by the author.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æ„Ÿè°¢Chad Hazlettè§£ç­”æˆ‘å…³äºå¦‚ä½•åœ¨äºŒé¡¹ç»“æœä¸­ä½¿ç”¨è¯¥æ–¹æ³•çš„é—®é¢˜ï¼Œå¹¶æ„Ÿè°¢Xinyi Zhangå¯¹æœ¬æ–‡æä¾›äº†å¤§é‡æœ‰ä»·å€¼çš„åé¦ˆã€‚é™¤éå¦æœ‰æ³¨æ˜ï¼Œæ–‡ä¸­çš„æ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚
- en: 7\. References
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. å‚è€ƒæ–‡çŒ®
- en: '[1] C. Cinelli and C. Hazlett, [Making Sense of Sensitivity: Extending Omitted
    Variable Bias](https://academic.oup.com/jrsssb/article/82/1/39/7056023) (2019),
    Journal of the Royal Statistical Society'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] C. Cinelli å’Œ C. Hazlettï¼Œ [ç†è§£æ•æ„Ÿæ€§ï¼šæ‰©å±•é—æ¼å˜é‡åå·®](https://academic.oup.com/jrsssb/article/82/1/39/7056023)ï¼ˆ2019ï¼‰ï¼Œã€Šçš‡å®¶ç»Ÿè®¡å­¦ä¼šå­¦æŠ¥ã€‹'
- en: '[2] J. Murray, [Linear Probability Model](https://murraylax.org/rtutorials/linearprob.html),
    Murrayâ€™s personal website'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] J. Murrayï¼Œ[çº¿æ€§æ¦‚ç‡æ¨¡å‹](https://murraylax.org/rtutorials/linearprob.html)ï¼ŒMurrayçš„ä¸ªäººç½‘ç«™'
- en: '[3] T. VanderWeele and P. Ding, [Sensitivity Analysis in Observational Research:
    Introducing the E-Value](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)
    (2017), Annals of Internal Medicine'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] T. VanderWeele å’Œ P. Dingï¼Œ[è§‚å¯Ÿæ€§ç ”ç©¶ä¸­çš„æ•æ„Ÿæ€§åˆ†æï¼šå¼•å…¥Eå€¼](https://hrr.w.uib.no/files/2019/01/VanderWeeleDing_2017_e_-value.pdf)ï¼ˆ2017ï¼‰ï¼Œã€Šå†…ç§‘å­¦å¹´é‰´ã€‹'
- en: '[4] V. Veitch and A. Zaveri, [Sense and Sensitivity Analysis: Simple Post-Hoc
    Analysis of Bias Due to Unobserved Confounding](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf)
    (2020), NeurIPS'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] V. Veitch å’Œ A. Zaveriï¼Œ [æ•æ„Ÿæ€§ä¸çµæ•åº¦åˆ†æï¼šå¯¹æœªè§‚å¯Ÿåˆ°çš„æ··æ‚å› ç´ å¼•èµ·çš„åå·®çš„ç®€å•äº‹ååˆ†æ](https://proceedings.neurips.cc/paper_files/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf)
    ï¼ˆ2020ï¼‰ï¼ŒNeurIPS'
- en: '[5] V. Chernozhukov, C. Cinelli, W. Newey, A. Sharma, and V. Syrgkanis, [Long
    Story Short: Omitted Variable Bias in Causal Machine Learning](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf)
    (2022), NBER'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] V. Chernozhukov, C. Cinelli, W. Newey, A. Sharma, å’Œ V. Syrgkanisï¼Œ [ç®€è€Œè¨€ä¹‹ï¼šå› æœæœºå™¨å­¦ä¹ ä¸­çš„é—æ¼å˜é‡åå·®](https://www.nber.org/system/files/working_papers/w30302/w30302.pdf)
    ï¼ˆ2022ï¼‰ï¼ŒNBER'
