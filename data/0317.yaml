- en: Find Unusual Segments in Your Data with Subgroup Discovery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用子群发现方法在数据中找到不寻常的细分群体
- en: 原文：[https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02](https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02](https://towardsdatascience.com/find-unusual-segments-in-your-data-with-subgroup-discovery-2661a586e60c?source=collection_archive---------8-----------------------#2024-02-02)
- en: Patient rule induction method finds 35% better segments than previously reported
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 患者规则归纳法发现了比之前报告更优的35%细分群体
- en: '[](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)[![Vadim
    Arzamasov](../Images/70ced2eafa6fc926052979875a0a4265.png)](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)
    [Vadim Arzamasov](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)[![Vadim
    Arzamasov](../Images/70ced2eafa6fc926052979875a0a4265.png)](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)
    [Vadim Arzamasov](https://medium.com/@vadim.arzamasov?source=post_page---byline--2661a586e60c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)
    ·8 min read·Feb 2, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2661a586e60c--------------------------------)
    ·阅读时间：8分钟·2024年2月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/5c58998cb8355e53823acdd3947bda6e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c58998cb8355e53823acdd3947bda6e.png)'
- en: Image created by author with recraft.ai
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者通过recraft.ai创建
- en: 'Inspired by an in-depth [Medium article](https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2)
    [1] with a case study on identifying bank customer segments with high churn reduction
    potential, this story explores a similar challenge through the lens of subgroup
    discovery methods [2]. Intrigued by the parallels, I applied a subgroup discovery
    approach to the same dataset and uncovered a segment with a 35% higher churn reduction
    potential — a significant improvement over what was previously reported. This
    story will take you through each step of the process, including building the methodology
    from the ground up. At the end of this journey, you’ll gain:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 受一篇深入的[Medium文章](https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2)
    [1]启发，文章通过一个案例研究，探讨了如何识别具有高流失率降低潜力的银行客户细分，本故事则通过子群发现方法[2]的视角探索了类似的挑战。受这种相似性的启发，我将子群发现方法应用于相同的数据集，发现了一个流失率降低潜力高出35%的细分群体——相比之前报告的结果，这是一个显著的改进。本故事将带你走过每一个步骤，包括从零开始构建方法论。在这个过程结束时，你将获得：
- en: A clear understanding of the Patient Rule Induction Method (PRIM), a mature
    yet powerful subgroup discovery technique.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰理解患者规则归纳法（PRIM），这是一种成熟且强大的子群发现技术。
- en: The skills to apply PRIM to your datasets and tailor it to your specific needs.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运用PRIM方法分析你的数据集并根据具体需求进行调整的技能。
- en: The complete code for PRIM and the experiment is on [GitHub](https://github.com/Arzik1987/medium/tree/main/prim_segments)
    [3].
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: PRIM方法及实验的完整代码在[GitHub](https://github.com/Arzik1987/medium/tree/main/prim_segments)
    [3]上。
- en: Patient Rule Induction Method
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 患者规则归纳法
- en: 'For the experiment, I’ve chosen my favorite subgroup discovery method: PRIM
    [4]. Despite its long presence in the field, PRIM has a unique mix of properties
    that make it very versatile:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我选择了我最喜欢的子群发现方法：PRIM [4]。尽管PRIM已经在该领域存在很长时间，但它拥有一套独特的特性，使得它非常多才多艺：
- en: '**Numerical data handling**: PRIM easily handles numerical data without the
    need for binning. Unlike typical methods that discretize variables (e.g., categorizing
    age into predefined groups such as `45–54 years`), PRIM overcomes this limitation.
    For example, it can identify more nuanced criteria such as `age > 37`.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值数据处理**：PRIM能够轻松处理数值数据，无需分箱。与典型方法（例如将年龄按预定义的组别如`45–54岁`进行分类）将变量离散化不同，PRIM克服了这一局限性。例如，它可以识别更细致的标准，如`age
    > 37`。'
- en: '**Intelligent categorical data processing**: PRIM can discover complex segments
    within categorical data. It can go beyond simple classifications such as `country
    = Germany` to more complex definitions such as `country not in {France}`.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能分类数据处理**：PRIM能够发现分类数据中的复杂片段。它可以超越简单的分类，如`country = Germany`，而定义更复杂的条件，如`country
    not in {France}`。'
- en: '**Simplicity**: While traditional subgroup discovery methods are often burdened
    with multiple parameters, PRIM is refreshingly simple. It relies primarily on
    a single, unambiguous `peeling parameter`: the proportion of points removed from
    a candidate segment in each iteration.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简洁性**：尽管传统的子群体发现方法通常涉及多个参数，PRIM却简单明了。它主要依赖一个单一、明确的`去皮参数`：每次迭代中从候选片段中移除的点的比例。'
- en: '**Efficiency**: Being a heuristic approach, PRIM is remarkably fast. Despite
    its large search space, segment identification is typically resolved in milliseconds.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：作为一种启发式方法，PRIM非常快速。尽管它的搜索空间很大，片段识别通常在毫秒级别内完成。'
- en: '**Interactivity and control**: PRIM enables interactive analysis. Users can
    balance segment size against potential impact by examining a series of “nested”
    segments and selecting the most appropriate one. It also supports incremental
    segment discovery by removing already segmented data.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互性和控制**：PRIM支持交互式分析。用户可以通过检查一系列“嵌套”片段并选择最合适的片段，来平衡片段大小与潜在影响。它还支持通过移除已分段的数据来逐步发现新片段。'
- en: '**Flexibility**: The flexibility of the method extends to the optimization
    function it is designed to enhance. This function isn’t limited to a single variable.
    For example, PRIM can identify segments where the correlation between two variables
    is significantly different from their correlation in the entire data set.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：该方法的灵活性扩展到了它旨在优化的目标函数。这个函数并不限于单一变量。例如，PRIM可以识别在某些片段中，两个变量之间的相关性显著不同于它们在整个数据集中的相关性。'
- en: In summary, PRIM’s straightforward logic not only makes it easy to implement,
    but also allows for customization.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，PRIM的直接逻辑不仅使其容易实现，还允许进行定制化。
- en: PRIM algorithm
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PRIM算法
- en: 'PRIM works through two distinct phases: peeling and pasting. Peeling starts
    from a segment encompassing the entire dataset and gradually shrinks it while
    optimizing its quality. Pasting works similarly, but in the opposite direction
    — it tries to expand the selected candidate segment without quality loss. In our
    previous experiments [5], we observed that the pasting phase typically contributes
    minimally to the output quality. Therefore, I will focus on the peeling phase.
    The underlying logic of the peeling phase is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: PRIM通过两个不同的阶段工作：去皮和粘贴。去皮从一个包含整个数据集的片段开始，逐渐缩小该片段的范围，同时优化其质量。粘贴的工作方式类似，但方向相反——它试图在不损失质量的情况下扩展选定的候选片段。在我们之前的实验[5]中，我们观察到粘贴阶段对输出质量的贡献通常较小。因此，我将重点讨论去皮阶段。去皮阶段的基本逻辑如下：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this pseudo-code:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个伪代码中：
- en: '`box` refers to the current segment of the data.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`box`指的是当前的数据片段。'
- en: The `target quality function` is typically some statistic of the response variable
    (mean, median, etc) that we want to maximize or minimize.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`目标质量函数`通常是响应变量的某个统计量（如均值、中位数等），我们希望最大化或最小化该统计量。'
- en: The `peeling parameter` determines the proportion of data points to be removed
    in each iteration. It is usually set to a small value, such as 0.05, hence the
    word “patient” in the method’s name.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`去皮参数`决定了每次迭代中要移除的数据点比例。它通常设置为一个小值，如0.05，因此该方法名称中有“耐心”一词。'
- en: The `stopping criterion` ensures that enough data points remain for analysis.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`停止准则`确保了分析过程中保留足够的数据点。'
- en: 'Consider simple examples of how PRIM handles numeric and categorical variables:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑PRIM如何处理数值型和分类变量的简单示例：
- en: '**Numeric variables:** Imagine you have a numeric variable such as age. In
    each step of the peeling phase, PRIM looks at the range of that variable (say,
    age from 18 to 80). PRIM then “peels off” a portion of that range from either
    end, as defined by the `peeling parameter`. For example, it might remove ages
    75 to 80 because doing so improves the `target quality function` in the remaining
    data (e.g., increasing the churn reduction potential). The animation below shows
    PRIM finding an interesting segment (with a high proportion of orange squares)
    in a 2D numeric dataset.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值变量：** 假设你有一个数值变量，比如年龄。在剥离阶段的每一步，PRIM 会查看该变量的范围（比如，年龄从 18 到 80）。然后，PRIM
    会根据`剥离参数`从两端“剥离”该范围的一部分。例如，它可能会移除 75 到 80 岁的年龄段，因为这样做可以提高剩余数据的`目标质量函数`（例如，增加流失率减少潜力）。下面的动画展示了
    PRIM 在一个 2D 数值数据集中找到一个有趣的数据段（其中橙色方块的比例较高）。'
- en: '![](../Images/b490dcc06d4384cccf544002f220f0f4.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b490dcc06d4384cccf544002f220f0f4.png)'
- en: PRIM at work on a 2D numerical data set. Image by the author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: PRIM 在 2D 数值数据集上的应用。图像由作者提供
- en: '**Categorical nominal variables:** Now consider a categorical nominal variable
    such as country, with categories such as Germany, France, and Spain. In the peeling
    phase, PRIM evaluates each category based on how well it improves the `target
    quality function`. It then removes the least promising category. For example,
    if removing “Germany” results in a subset where the `target quality function`
    is improved (such as a higher potential churn reduction), then all data points
    with “Germany” are “peeled”. Note that the `peeling parameter` has no effect on
    the processing of categorical data, which can cause undesired effects in some
    cases, as I will discuss and provide a simple remedy (in section “Better segments
    via enforced ‘patience’”).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类名义变量：** 现在考虑一个分类名义变量，比如国家，类别包括德国、法国和西班牙。在剥离阶段，PRIM 会根据每个类别如何改善`目标质量函数`来评估该类别。然后，它会移除最不有前景的类别。例如，如果移除“德国”后，剩余的数据子集的`目标质量函数`有所改善（如更高的流失率减少潜力），那么所有带有“德国”的数据点将被“剥离”。请注意，`剥离参数`对分类数据的处理没有影响，这在某些情况下可能会导致不良效果，正如我将讨论的并提供简单的解决方法（在“通过强制‘耐心’获得更好的数据段”一节中）。'
- en: '**Categorical ordinal variables:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类序数变量：**'
- en: For ordinal variables, disjoint intervals in segment descriptions can sometimes
    be less intuitive. Consider an education variable with levels such as primary,
    secondary, vocational, bachelor, and graduate. Finding a rule like `education
    in {primary, bachelor}` may not fit well with the ordinal nature of the data because
    it combines non-adjacent categories. For those looking for a more coherent segmentation,
    such as `education > secondary`, that respects the natural order of the variable,
    using an ordinal encoding can be a useful workaround. For more insight into categorical
    encoding, you may find my [earlier post](https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe)
    [6] helpful, as it navigates you to the necessary information.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于序数变量，在描述数据段时，非重叠区间有时可能不太直观。考虑一个教育变量，等级包括小学、中学、职业教育、本科和研究生。找到像`education in
    {primary, bachelor}`这样的规则可能不太适合数据的序数特性，因为它结合了不相邻的类别。对于那些寻找更一致的数据分割的人来说，比如`education
    > secondary`，它尊重变量的自然顺序，使用序数编码可能是一个有用的变通方法。关于类别编码的更多见解，你可以参考我的[早期文章](https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe)[6]，它为你提供了必要的信息。
- en: 'Experiment: Churn for bank customers'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验：银行客户流失
- en: 'Now everything is ready to start the experiment. Following the Medium article
    on identifying unique data segments [1], I will apply the PRIM method to the [Churn
    for Bank Customers](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)
    [7] dataset from Kaggle, available under the CC0: Public Domain license. I will
    also adopt the `target quality function` from the article:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '现在一切准备就绪，可以开始实验了。根据 Medium 上关于识别独特数据段的文章[1]，我将应用 PRIM 方法到来自 Kaggle 的[银行客户流失](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)[7]数据集，该数据集使用
    CC0: 公共领域许可。我还将采用文章中的`目标质量函数`：'
- en: '![](../Images/24f1b331624a6e6cc65d360d7fb1ec59.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24f1b331624a6e6cc65d360d7fb1ec59.png)'
- en: That is, I will look for the segments with many customers where the churn rate
    is much higher than the baseline, which is the average churn rate in the entire
    dataset. So I use PRIM, which gives me a set of nested candidate segments, and
    plot the `churn_est_reduction` against the number of clients.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我将寻找具有大量客户的段落，其中流失率远高于基线（即整个数据集中的平均流失率）。因此，我使用PRIM，它为我提供了一组嵌套的候选段落，并将`churn_est_reduction`与客户数量进行对比。
- en: '![](../Images/f2f6519be48b38e624fb8716ef89341d.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2f6519be48b38e624fb8716ef89341d.png)'
- en: Image by the author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The highest quality, `churn_est_reduction = 457` is achieved for the 11th candidate
    segment with the description `num_of_products < 2, is_active_member < 1, age >
    37`. This is quite an improvement over the previously reported maximum `churn_est_reduction
    = 410` in [1]. Comparing the segment descriptions, I suspect that the main reason
    for this improvement is PRIM’s ability to handle numeric variables.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`churn_est_reduction = 457` 的最高质量是在第11个候选段落中实现的，其描述为`num_of_products < 2, is_active_member
    < 1, age > 37`。这比[1]中之前报告的最大`churn_est_reduction = 410`有了相当大的提升。比较这些段落的描述，我怀疑这种改进的主要原因是PRIM能够处理数值变量。'
- en: Better segments via enforced ‘patience’
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过强制“耐心”获得更好的段落
- en: Something suspicious is going on in the previous plot. By its nature, PRIM is
    expected to be “patient”, i.e. to reduce the segment size only a little bit at
    each iteration. However, the second candidate segment is twice as small as the
    previous one — PRIM has cut off half the data at once. The reason for this is
    the low cardinality of some features, which is often the case with categorical
    or indicator variables. For example, `is_active_member` only takes the values
    0 or 1\. PRIM can only cut off large chunks of data for such variables, giving
    them an unfair advantage.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图中出现了一些可疑情况。PRIM本应是“耐心”的，也就是说，在每次迭代中仅稍微减少段落大小。然而，第二个候选段落的大小是第一个的两倍——PRIM一次性切掉了大量数据。这是由于某些特征的基数较低，通常发生在分类变量或指示变量上。例如，`is_active_member`仅取值0或1。PRIM对于这种变量只能大规模切割数据，导致它们获得了不公平的优势。
- en: To address this issue, I’ve added an additional parameter called `patience`
    to give more weight to smaller cuts. Specifically, for the task at hand, I prioritize
    cuts by multiplying the churn rate reduction by the segment size raised to the
    power of `patience`. This approach helps to fine-tune the selection of segments
    based on their size, making it more tailored to our analysis needs. Applying PRIM
    with `patience = 2` to the data yields the following candidate segments
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我添加了一个额外的参数`patience`，以便对较小的切割赋予更多的权重。具体来说，对于当前任务，我通过将流失率减少量与段落大小的`patience`次方相乘来优先考虑切割。这种方法有助于根据段落的大小微调选择，使其更符合我们的分析需求。应用`patience
    = 2`的PRIM后，得到了以下候选段落：
- en: '![](../Images/a1434019563bc9df4066f3424e5c1032.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1434019563bc9df4066f3424e5c1032.png)'
- en: Image by the author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Now the best candidate segment is `num_of_products < 2, 37 < age < 64` with
    `churn_est_reduction = 548`, much better than any previous result!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，最好的候选段落是`num_of_products < 2, 37 < age < 64`，其`churn_est_reduction = 548`，比任何之前的结果都要好！
- en: Finding multiple segments
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找多个段落
- en: 'Let us say we have selected the just discovered segment and ask one of two
    responsible teams to focus on it. Can PRIM find a job for another team, i.e.,
    find another group of clients, not in the first segment, with a high potential
    churn rate reduction? Yes it can, with so-called “covering” approach [4]. This
    means that one simply drops the clients belonging to the previously selected segment(s)
    from the dataset and apply PRIM once again. So I removed data with `num_of_products
    < 2, 37 < age < 64` and applied PRIM to the rest:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经选择了刚刚发现的段落，并要求两个负责的团队之一专注于它。那么PRIM能否为另一个团队找到任务，也就是找出一个与第一个段落不同的客户群体，并且该群体的潜在流失率减少较高呢？是的，PRIM可以，通过所谓的“覆盖”方法[4]。这意味着，只需从数据集中删除属于先前选定段落的客户，然后重新应用PRIM。因此，我移除了数据中`num_of_products
    < 2, 37 < age < 64`的部分，并对剩余部分应用了PRIM：
- en: '![](../Images/829eaac3357952969256d1bf7521d29d.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/829eaac3357952969256d1bf7521d29d.png)'
- en: Image by the author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Here the best candidate segment is `gender != ‘Male’, num_of_products > 2, balance
    > 0.0` with `chirn_est_reduction = 93.`
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最好的候选段落是`gender != 'Male', num_of_products > 2, balance > 0.0`，其`churn_est_reduction
    = 93`。
- en: Summary
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'To wrap things up, I illustrated PRIM’s strong performance on a Customer Churn
    Dataset for a task to find unusual segments. Points to note:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我在客户流失数据集上展示了PRIM的强大表现，任务是找出不寻常的段落。需要注意的几点：
- en: PRIM has identified highly insightful segments with 35% higher quality than
    previously reported.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PRIM已识别出高质量的有洞察力的区段，其质量比之前报告的高出35%。
- en: I shared the code [3] for practical application and further experimentation.
    It is very concise and, unlike to other existing implementations [8–9], allows
    one to easily replace the target quality function tailored to a specific need.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我分享了[3]中的代码用于实际应用和进一步实验。它非常简洁，与其他现有实现[8–9]不同，允许轻松替换目标质量函数，以便满足特定需求。
- en: I endorse PRIM for its robust features, such as effective handling of both numeric
    and categorical data, flexible segment definition, and fast execution, and recommend
    it for similar analytical challenges.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我推荐PRIM，因为它具有强大的功能，如有效处理数值和分类数据、灵活的区段定义以及快速的执行速度，并且推荐它用于类似的分析挑战。
- en: References
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [Figuring out the most unusual segments in data](https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [找出数据中最不寻常的区段](https://medium.com/towards-data-science/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2)'
- en: '[2] Atzmueller, Martin. “[Subgroup discovery](https://www.kde.cs.uni-kassel.de/wp-content/uploads/atzmueller/paper/2005-SDSchlagwortKI_AtzmuellerM.pdf).”
    *Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery* 5.1 (2015):
    35–49.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Atzmueller, Martin. “[子群发现](https://www.kde.cs.uni-kassel.de/wp-content/uploads/atzmueller/paper/2005-SDSchlagwortKI_AtzmuellerM.pdf).”
    *《数据挖掘与知识发现的跨学科评论》* 5.1 (2015): 35–49.'
- en: '[3] [My code for PRIM and the experiment](https://github.com/Arzik1987/medium/tree/main/prim_segments)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [我的PRIM代码和实验](https://github.com/Arzik1987/medium/tree/main/prim_segments)'
- en: '[4] Friedman, Jerome H., and Nicholas I. Fisher. “[Bump hunting in high-dimensional
    data](https://www.researchgate.net/profile/Nicholas-Fisher-10/publication/283550136_Bump_hunting_in_high-dimensional_data-Discussion/links/5a4350980f7e9ba868a54cd9/Bump-hunting-in-high-dimensional-data-Discussion.pdf).”
    *Statistics and computing* 9.2 (1999): 123–143.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Friedman, Jerome H., 和 Nicholas I. Fisher. “[高维数据中的拐点搜索](https://www.researchgate.net/profile/Nicholas-Fisher-10/publication/283550136_Bump_hunting_in_high-dimensional_data-Discussion/links/5a4350980f7e9ba868a54cd9/Bump-hunting-in-high-dimensional-data-Discussion.pdf).”
    *统计与计算* 9.2 (1999): 123–143.'
- en: '[5] Arzamasov, Vadim, and Klemens Böhm. “[REDS: rule extraction for discovering
    scenarios](https://dl.acm.org/doi/abs/10.1145/3448016.3457301?casa_token=MK5vsUGKNz8AAAAA%3ASdp6s_axuda7ZPTNtz6ajP9_pAIIeMFu4VTPUbbQhuLlGmajVgVBmuIgShjGln2FlwebBuv5JwJS2w).”
    *Proceedings of the 2021 International Conference on Management of Data*. 2021.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Arzamasov, Vadim, 和 Klemens Böhm. “[REDS：规则提取以发现场景](https://dl.acm.org/doi/abs/10.1145/3448016.3457301?casa_token=MK5vsUGKNz8AAAAA%3ASdp6s_axuda7ZPTNtz6ajP9_pAIIeMFu4VTPUbbQhuLlGmajVgVBmuIgShjGln2FlwebBuv5JwJS2w).”
    *2021年国际数据管理会议论文集*，2021年。'
- en: '[6] [Categorical Encoding: Key Insights](https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [分类编码：关键见解](https://medium.com/@vadim.arzamasov/navigating-categorical-encoder-maze-c04e49b165fe)'
- en: '[7] [Churn for Bank Customers dataset](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [银行客户流失数据集](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)'
- en: '[8] [Patient Rule Induction Method for Python](https://pypi.org/project/PRIM/)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [Python中的患者规则归纳方法](https://pypi.org/project/PRIM/)'
- en: '[9] [Patient Rule Induction Method for R](https://cran.r-project.org/web/packages/prim/index.html)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [R语言中的患者规则归纳方法](https://cran.r-project.org/web/packages/prim/index.html)'
