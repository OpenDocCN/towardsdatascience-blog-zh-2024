- en: Speaker’s Privacy Protection in DNN-Based Speech Processing Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于DNN的语音处理工具中的说话人隐私保护
- en: 原文：[https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20](https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20](https://towardsdatascience.com/speakers-privacy-protection-in-dnn-based-speech-processing-tools-f446ad1d8871?source=collection_archive---------15-----------------------#2024-08-20)
- en: A novel method in privacy-preserving speech processing which anonymizes the
    speaker attributes using space-filling vector quantization
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种新颖的隐私保护语音处理方法，通过空间填充向量量化匿名化说话人属性
- en: '[](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)[![Mohammad
    Hassan Vali](../Images/b057aa7bd9e1c629fc3743a7f69f013e.png)](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)
    [Mohammad Hassan Vali](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)[![Mohammad
    Hassan Vali](../Images/b057aa7bd9e1c629fc3743a7f69f013e.png)](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)
    [Mohammad Hassan Vali](https://medium.com/@mohammad.vali?source=post_page---byline--f446ad1d8871--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)
    ·9 min read·Aug 20, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--f446ad1d8871--------------------------------)
    ·阅读时间9分钟·2024年8月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This post is a short explanation of our proposed privacy preservation technique
    called Privacy-PORCUPINE [1] published at Interspeech 2024 conference. The post
    discusses a potential privacy threat that might happen when using ordinary vector
    quantization in the bottleneck of DNN-based speech processing tools. For more
    detail, please look at the paper under [this link](https://www.isca-archive.org/interspeech_2024/vali24_interspeech.pdf).
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文简要介绍了我们提出的隐私保护技术——Privacy-PORCUPINE [1]，该技术在2024年Interspeech会议上发表。文章讨论了在DNN基础的语音处理工具瓶颈中使用普通向量量化时可能出现的隐私威胁。欲了解更多详情，请查看[此链接](https://www.isca-archive.org/interspeech_2024/vali24_interspeech.pdf)下的论文。
- en: '![](../Images/7b7bc224819148110e096999c192ace4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b7bc224819148110e096999c192ace4.png)'
- en: Photo by [Dayne Topkin](https://unsplash.com/@dtopkin1?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Dayne Topkin](https://unsplash.com/@dtopkin1?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Speech is a convenient medium for interacting between humans and with technology,
    yet evidence demonstrates that it exposes speakers to threats to their privacy.
    A central issue is that, besides the linguistic content which may be private,
    speech contains also private side-information such as the speaker’s identity,
    age, state of health, ethnic background, gender, and emotions. Revealing such
    sensitive information to a listener may expose the speaker to threats such as
    price gouging, tracking, harassment, extortion, and identity theft. To protect
    speakers, privacy-preserving speech processing seeks to anonymize speech signals
    by stripping away private information that is not required for the downstream
    task [2].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 语音是人类与技术之间互动的便捷媒介，但证据表明它也使说话人面临隐私威胁。一个核心问题是，除了可能是私密的语言内容，语音还包含诸如说话人身份、年龄、健康状况、种族背景、性别和情绪等私密的附加信息。将这些敏感信息透露给听众可能使说话人面临价格抬高、追踪、骚扰、敲诈和身份盗窃等威胁。为了保护说话人，隐私保护语音处理旨在通过剥离下游任务不需要的私密信息来匿名化语音信号
    [2]。
- en: A common operating principle for privacy-preserving speech processing is to
    pass information through an information bottleneck that is tight enough to allow
    only the desired information pass through it and prevent transmission of any other
    private information. Such bottlenecks can be implemented for example as *autoencoders*,
    where a neural network, known as the encoder, compresses information to a bottleneck,
    and a second network, the decoder, reconstructs the desired output. The information
    rate of the bottleneck can be quantified absolutely, only if it is quantized,
    and quantization is thus a required component of any proof of privacy [2]. The
    figure below shows a vector quantized variational autoencoder (VQ-VAE) architecture,
    and its bottleneck.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的隐私保护语音处理操作原理是通过一个信息瓶颈传递信息，瓶颈必须足够紧密，只允许所需的信息通过，并防止任何其他私人信息的传输。例如，可以通过*自编码器*实现这样的瓶颈，其中一个神经网络，称为编码器，将信息压缩到瓶颈中，另一个网络，解码器，重建所需的输出。瓶颈的信息传输速率可以绝对量化，但只有在量化的情况下才能量化，因此量化是任何隐私证明的必需组件[2]。下图展示了一个矢量量化变分自编码器（VQ-VAE）架构及其瓶颈。
- en: '![](../Images/7d11ef396bd9ebff33a3d4294d1e5b6b.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d11ef396bd9ebff33a3d4294d1e5b6b.png)'
- en: 'Figure 1: Architecture of a vector quantized variational autoencoder (VQ-VAE).
    (image by author)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：矢量量化变分自编码器（VQ-VAE）的架构。（图片来源：作者）
- en: As pointed out in the Privacy ZEBRA framework [3], we need to characterize privacy
    protections both in terms of average disclosure of private information (in bits)
    as well as worst-case disclosure (in bits). [Vector quantization](https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce)
    (VQ) [4] is a constant-bitrate quantizer in the sense that it quantizes the input
    with a codebook of K elements, and the indices of such a codebook can be expressed
    with B=log2(K) bits. This B equals to the average disclosure of private information
    in bits. In terms of the worst-case disclosure, it is obvious that different codebook
    elements are used with different frequencies (see Fig. 2.1 below). This means
    that a relatively smaller subset of speakers could be assigned to a particular
    codebook index, such that any time a speaker is assigned to that codebook index,
    the range of possible speakers is relatively smaller than for other codebook indices
    and the corresponding disclosure of private information is larger (for the speakers
    assigned to this particular codebook index). However, to the best of the authors’
    knowledge, this disclosure has not previously been quantified nor do we have prior
    solutions for compensating for such an increase in disclosure. Hence, our main
    goal is to modify VQ such that all codebook elements have equal occurrence likelihoods
    to prevent private information leakage (and thus improve worst-case disclosure).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如隐私ZEBRA框架[3]中所指出的，我们需要从平均泄露私人信息的比特数以及最坏情况下泄露（比特数）的角度来表征隐私保护。[矢量量化](https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce)（VQ）[4]是一个恒定比特率量化器，因为它使用一个包含K个元素的码本对输入进行量化，且此码本的索引可以用B=log2(K)比特表示。这个B等于私人信息泄露的平均比特数。就最坏情况的泄露而言，很明显，不同的码本元素以不同的频率使用（见下图2.1）。这意味着，相对较小的发言人子集可能会被分配到特定的码本索引，以至于每当一个发言人被分配到该索引时，可能的发言人范围比其他码本索引的范围要小，且相应的私人信息泄露也较大（对于分配到该特定码本索引的发言人）。然而，据作者所知，这种泄露此前并未被量化，也没有现有的解决方案来补偿这种泄露的增加。因此，我们的主要目标是修改VQ，使所有码本元素的出现概率相等，从而防止私人信息泄露（并因此改善最坏情况下的泄露）。
- en: As a solution, we use here our recently proposed modification of VQ known as
    [space-filling vector quantization](https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14)
    (SFVQ) [5], which incorporates space-filling curves into VQ. We define the SFVQ
    as the linear continuation of VQ, such that subsequent codebook elements are connected
    with a line where inputs can be mapped to any point on that piece-wise continuous
    line (see Fig. 2.2). To read more about SFVQ, please see [this post](https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作为解决方案，我们在此采用了我们最近提出的向量量化修改方法，称为[空间填充向量量化](https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14)（SFVQ）[5]，它将空间填充曲线引入到向量量化中。我们将SFVQ定义为向量量化的线性延续，使得后续的代码本元素通过一条线连接，在该分段连续线的任意点上可以映射输入（见图2.2）。要了解更多关于SFVQ的内容，请参阅[这篇文章](https://medium.com/towards-data-science/interpretable-latent-spaces-using-space-filling-vector-quantization-e4eb26691b14)。
- en: In our technique, named Privacy PORCUPINE [1], we proposed to use a codebook
    resampling method together with SFVQ, where a vector quantizer is resampled along
    the SFVQ’s curve, such that all elements of the resampled codebook have equal
    occurrence likelihoods (see Fig. 2.3 and 2.4).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的技术中，名为Privacy PORCUPINE [1]，我们提出了结合SFVQ的代码本重新采样方法，其中向量量化器沿着SFVQ的曲线重新采样，使得所有重新采样的代码本元素具有相等的出现概率（见图2.3和2.4）。
- en: '![](../Images/27c1e3136b235a773683a26aad95fab6.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27c1e3136b235a773683a26aad95fab6.png)'
- en: 'Figure 2: 1\. Codebook vectors (blue points) of a 5 bit vector quantization
    applied on a Gaussian distribution (gray points); Voronoi-regions are shown in
    green 2\. Space-filling vector quantization (SFVQ) with 5 bit applied on the same
    Gaussian distribution (curve in black with codebook vectors in blue) 3\. Same
    SFVQ curve together with the resampled codebook vectors (red crosses) 4\. Same
    resampled codebook vectors along with their Voronoi-regions (in green). (image
    by author)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：1. 5位向量量化在高斯分布（灰点）上的代码本向量（蓝点）；Voronoi区域用绿色表示 2. 同样的高斯分布上应用5位空间填充向量量化（SFVQ）（黑色曲线，代码本向量为蓝色）
    3. 相同的SFVQ曲线及重新采样的代码本向量（红色交叉） 4. 相同的重新采样代码本向量及其Voronoi区域（绿色）。(图像由作者提供)
- en: How we measure the disclosure?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何衡量泄露度？
- en: Figure 2.1 demonstrates that in areas where inputs are less likely, the Voronoi-regions
    are larger. Hence, such larger Voronoi-regions contain a smaller number of input
    samples. Similarly, small Voronoi-regions have a larger number of input samples.
    Such differences are due to the optimization of the codebook by minimizing the
    mean square error (MSE) criterion; more common inputs are quantized with a smaller
    error to minimize the average error. Our objective is to determine how such uneven
    distribution of inputs to codebook entries influences the disclosure of private
    information.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1展示了在输入较少的区域，Voronoi区域较大。因此，这些较大的Voronoi区域包含较少的输入样本。类似地，较小的Voronoi区域包含较多的输入样本。这些差异是由于通过最小化均方误差（MSE）准则来优化代码本；较常见的输入通过较小的误差量化，从而最小化平均误差。我们的目标是确定输入不均匀分布到代码本条目时，如何影响私密信息的泄露。
- en: We measure disclosure in terms of how much the population size of possible identities
    for an unknown speaker is decreased with a new observation. In other words, assume
    that we have prior knowledge that the speaker belongs to a population of size
    M. If we have an observation that the speaker is quantized to an index k, we have
    to evaluate how many speakers L out of M will be quantized to the same index.
    This decrease can be quantified by the ratio of populations L/M corresponding
    to the disclosure of B_leak=log2(M/L) bits of information.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过衡量新的观察如何减少未知说话者可能身份的群体大小来度量泄露度。换句话说，假设我们已知说话者属于一个大小为M的群体。如果我们有一个观察结果，表明说话者被量化为索引k，我们需要评估M中的有多少个说话者L会被量化到相同的索引。这个减少可以通过群体比例L/M来量化，表示泄露了B_leak=log2(M/L)比特的信息。
- en: At the extreme, it is possible that only a single speaker may be quantized to
    a particular index. This means that only one speaker L=1 is quantized to the bin
    out of an arbitrarily large M, though in practice we can verify results only for
    finite M. Still, in theory, if M → ∞, then also the disclosure diverges B_leak
    → ∞ bits. The main objective of our proposed method is to modify vector quantization
    to prevent such catastrophic leaks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在极端情况下，可能只有一个说话人被量化到某个特定的索引。这意味着在一个任意大的M中，只有一个说话人L=1被量化到该区间，尽管在实践中，我们只能对有限的M进行验证结果。尽管如此，从理论上讲，如果M
    → ∞，那么信息泄漏也会发散，即B_leak → ∞比特。我们所提出方法的主要目标是修改向量量化，以防止这种灾难性的泄漏。
- en: Codebook Resampling
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 码本重采样
- en: After training the space-filling vector quantizer (SFVQ) [5] on the training
    set comprising speaker embeddings for a population of M speakers (Fig. 2.2), we
    map all the M embedding vectors onto the learned curve. To normalize the occurrence
    frequency using K codebook vectors, each codebook element has to represent M/K
    speaker embeddings. In other words, each Voronoi- region should encompass M/K
    speaker embeddings. Considering these M mapped embeddings on SFVQ’s curve, we
    start from the first codebook element (one end of the curve), take the first M/K
    mapped embeddings, and calculate the average of these vectors. We define this
    average vector as the new resampled codebook vector (red crosses in Fig. 2.3)
    representing the first chunk of M/K speaker embeddings. Then similarly, we continue
    until we compute all K resampled codebook vectors for all K chunks of M/K speaker
    embeddings.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练集上训练空间填充向量量化器（SFVQ）[5]，该训练集包含了M个说话人的嵌入向量（图2.2），我们将所有M个嵌入向量映射到已学习的曲线上。为了使用K个码本向量归一化出现频率，每个码本元素必须表示M/K个说话人嵌入。换句话说，每个Voronoi区域应包含M/K个说话人嵌入。考虑到这些映射到SFVQ曲线上的M个嵌入，我们从第一个码本元素（曲线的一端）开始，取前M/K个映射的嵌入，并计算这些向量的平均值。我们将这个平均向量定义为新的重采样码本向量（图2.3中的红色交叉点），代表第一块M/K个说话人嵌入。然后，我们继续类似的操作，直到计算出所有K个重采样码本向量，表示所有K块M/K个说话人嵌入。
- en: Experiments
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验
- en: In our experiments, we used [Common Voice corpus (version 16.1)](https://commonvoice.mozilla.org/en/datasets)
    to get a large pool of speakers. We selected 10,240 speakers randomly for the
    test set and 79,984 speakers for the train set. To compute speaker embeddings,
    we used the pretrained speaker verification model of ECAPA-TDNN [6]. We trained
    vector quantization (VQ) and space-filling vector quantization (SFVQ) methods
    on the train set (of speaker embeddings) for different bitrates ranging from 4
    bit to 10 bit (16 to 1024 codebook vectors).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实验中，我们使用了[Common Voice语料库（版本16.1）](https://commonvoice.mozilla.org/en/datasets)来获取大量的说话人数据。我们随机选择了10,240名说话人作为测试集，79,984名说话人作为训练集。为了计算说话人嵌入，我们使用了ECAPA-TDNN的预训练说话人验证模型[6]。我们在训练集（说话人嵌入）上训练了向量量化（VQ）和空间填充向量量化（SFVQ）方法，采用不同的比特率，从4位到10位（16到1024个码本向量）。
- en: As a showcase to compare VQ and resampled SFVQ, the figure below illustrates
    the occurrence frequencies for VQ and resampled SFVQ, both with 4 bit of information
    corresponding to 16 codebook vectors. By informal visual inspection we can see
    that entries in the proposed method are more uniformly distributed, as desired,
    but to confirm results we need a proper evaluation. To compare the obtained histograms
    from VQ and resampled SFVQ, we used different evaluation metrics which are discussed
    in the next section.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为VQ和重采样SFVQ比较的示例，下面的图示展示了VQ和重采样SFVQ在4位信息（对应16个码本向量）情况下的出现频率。通过非正式的视觉检查，我们可以看到所提出方法的条目分布更加均匀，正如我们所期望的那样，但为了确认结果，我们需要进行适当的评估。为了比较VQ和重采样SFVQ得到的直方图，我们使用了不同的评估指标，这些指标将在下一节中讨论。
- en: '![](../Images/43cd12afd0f2d09d9bb42b211cfb76f3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43cd12afd0f2d09d9bb42b211cfb76f3.png)'
- en: 'Figure 3: Probability of codebook occurrences for VQ and resampled SFVQ in
    case of 4 bit quantization. (image by author)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：4位量化情况下VQ和重采样SFVQ的码本出现概率。（图像来源：作者）
- en: Evaluation Metrics
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: Suppose we have K codebook vectors (bins) to quantize a population of M speakers.
    Our target is to achieve a uniform distribution of samples onto the K codebook
    vectors, U(1,K), such that every codebook vector is used M/K times. If we sample
    M integers from the uniform distribution of U(1,K), we will obtain the histogram
    h(k). Then, if we take the histogram of occurrences in the bins of h(k) (i.e.
    histogram of histogram), we will see that the new histogram follows a binomial
    distribution f(k) such that
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有 K 个代码簿向量（区间）来量化 M 个讲者的样本。我们的目标是将样本均匀地分布到 K 个代码簿向量上，U(1,K)，使得每个代码簿向量被使用
    M/K 次。如果我们从均匀分布 U(1,K) 中抽取 M 个整数，就能获得直方图 h(k)。然后，如果我们计算 h(k) 各个区间的出现频率的直方图（即直方图的直方图），我们会发现新的直方图遵循二项分布
    f(k)，使得
- en: where the random variable X is the occurrence in each bin, n is the number of
    trials (n=M), and p is the success probability for each trial which is p=1/K.
    After obtaining the histogram of codebook indices occurrences g(k) (Figure 3)
    for both VQ and resampled SFVQ methods, we compute the histogram of occurrences
    in the bins of g(k) denoted by f_hat(k). The binomial distribution f(k) is the
    theoretical optimum, to which our observation f_hat(k) should coincide. Hence,
    we use Kullback-Leibler (KL) divergence between f(k) and f_hat(k) to assess the
    distance between the observed and the ideal distributions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其中随机变量 X 是每个区间内的出现次数，n 是实验次数（n=M），p 是每次实验的成功概率，p=1/K。在获得 VQ 和重采样 SFVQ 方法的代码簿索引出现次数的直方图
    g(k)（图 3）之后，我们计算出 g(k) 各个区间内的出现频率直方图，记为 f_hat(k)。二项分布 f(k) 是理论最优分布，我们的观测值 f_hat(k)
    应与其一致。因此，我们使用 Kullback-Leibler（KL）散度来评估观察分布与理想分布之间的距离。
- en: 'By having the histogram of occurrences g(k), we calculate the minimum of the
    histogram divided by the total number of samples (M=Σ g(k)) as the worst-case
    disclosure. We also compute the average disclosure as entropy of occurrence frequencies
    g(k)/M. In addition, we use a sparseness measure and standard deviation as heuristic
    measures of uniformity of the obtained histogram g(k). Here are the evaluation
    formulas:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过获得出现频率的直方图 g(k)，我们计算直方图的最小值除以总样本数（M=Σ g(k)）作为最坏情况泄露。我们还计算了平均泄露，即出现频率的熵 g(k)/M。此外，我们使用稀疏度度量和标准差作为启发式度量，评估获得的直方图
    g(k) 的均匀性。以下是评估公式：
- en: Results
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: Figure 4 shows the performance of VQ and resampled SFVQ as a function of bitrate.
    In each case and for all bitrates, the proposed method (blue line) is below VQ
    (red line), indicating that the leakage of private information is smaller for
    the proposed method. One important point to mention is that as expected, resampled
    SFVQ makes the average disclosure to be slightly higher than VQ, whereas the average
    disclosure for both resampled SFVQ and VQ are extremely close to the upper bound
    of average disclosure where the histogram of occurrence frequencies is perfectly
    flat.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 显示了 VQ 和重采样 SFVQ 在比特率函数下的性能。在每种情况下以及所有比特率下，所提出的方法（蓝线）低于 VQ（红线），这表明所提出的方法泄露的私人信息较少。需要提到的一个重要点是，正如预期的那样，重采样
    SFVQ 使得平均泄露略高于 VQ，而重采样 SFVQ 和 VQ 的平均泄露都极其接近平均泄露的上限，在该上限下，出现频率的直方图是完全平坦的。
- en: '![](../Images/f2f74881c88f2ca40c545d1931dfd991.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2f74881c88f2ca40c545d1931dfd991.png)'
- en: 'Figure 4: Performance comparison between VQ and resampled SFVQ under evaluation
    metrics. (image by author)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：VQ 与重采样 SFVQ 在评估指标下的性能对比。（图片由作者提供）
- en: Conclusions
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Privacy-preserving speech processing is becoming increasingly important as the
    usage of speech technology is increasing. By removing superfluous private information
    from a speech signal by passing it through a quantized information bottleneck,
    we can gain provable protections for privacy. Such protections however rely on
    the assumption that quantization levels are used with equal frequency. Our theoretical
    analysis and experiments demonstrate that vector quantization, optimized with
    the minimum mean square (MSE) criterion, does generally not provide such uniform
    occurrence frequencies. In the worst case, some speakers could be uniquely identified
    even if the quantizer on average provides ample protection.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私保护语音处理变得越来越重要，因为语音技术的使用正在增加。通过将语音信号通过量化的信息瓶颈去除多余的私人信息，我们可以获得可证明的隐私保护。然而，这些保护依赖于量化水平的使用频率相等的假设。我们的理论分析和实验表明，使用最小均方误差（MSE）准则优化的向量量化通常不能提供均匀的发生频率。在最坏的情况下，即使量化器平均提供了充分的保护，某些说话人仍然可能被唯一识别出来。
- en: We proposed the resampled SFVQ method to avoid such privacy threats. The protection
    of privacy is thus achieved by increasing the quantization error for inputs that
    occur less frequently, while more common inputs gain better accuracy (see Fig.
    2.4). This is in line with the theory of differential privacy [7].
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了重采样SFVQ方法，以避免此类隐私威胁。因此，通过增加对较少出现输入的量化误差来实现隐私保护，而对较常见的输入则提高准确性（见图2.4）。这与差分隐私理论[7]一致。
- en: We used speaker identification as an illustrative application, though the proposed
    method can be used in gaining a provable reduction of private information leakage
    for any attributes of speech. In summary, resampled SFVQ is a generic tool for
    privacy-preserving speech processing. It provides a method for quantifying the
    amount of information passing through an information bottleneck and thus forms
    the basis of speech processing methods with provable privacy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以说话人身份识别作为示例应用，尽管所提方法可以用于实现任何语音属性的可证明隐私泄露减少。总之，重采样SFVQ是一个通用的隐私保护语音处理工具。它提供了一种量化通过信息瓶颈传递信息量的方法，从而为具有可证明隐私保护的语音处理方法奠定基础。
- en: GitHub Repository
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GitHub 仓库
- en: 'The code for implementation of our proposed method and the relevant evaluations
    is publicly available in the following link:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所提方法的实现代码及相关评估公开可用，链接如下：
- en: '[](https://github.com/MHVali/Privacy-PORCUPINE.git?source=post_page-----f446ad1d8871--------------------------------)
    [## GitHub - MHVali/Privacy-PORCUPINE'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/MHVali/Privacy-PORCUPINE.git?source=post_page-----f446ad1d8871--------------------------------)
    [## GitHub - MHVali/Privacy-PORCUPINE'
- en: Contribute to MHVali/Privacy-PORCUPINE development by creating an account on
    GitHub.
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在GitHub上创建账户，参与MHVali/Privacy-PORCUPINE的开发。
- en: github.com](https://github.com/MHVali/Privacy-PORCUPINE.git?source=post_page-----f446ad1d8871--------------------------------)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/MHVali/Privacy-PORCUPINE.git?source=post_page-----f446ad1d8871--------------------------------)
- en: Acknowledgement
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: Special thanks to my doctoral program supervisor [Prof. Tom Bäckström](https://research.aalto.fi/en/persons/tom-bäckström),
    who supported me and was the other contributor for this work.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢我的博士项目导师[Tom Bäckström教授](https://research.aalto.fi/en/persons/tom-bäckström)，他在这项工作中给予了我支持，并且是另一位贡献者。
- en: References
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M.H. Vali, T. Bäckström, “Privacy PORCUPINE: Anonymization of Speaker Attributes
    Using Occurrence Normalization for Space-Filling Vector Quantization”, in *Proceedings
    of Interspeech*, 2024.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M.H. Vali, T. Bäckström, “隐私PORCUPINE：使用发生率归一化进行空间填充向量量化的说话人属性匿名化”，发表于*Interspeech
    会议论文集*，2024年。'
- en: '[2] T. Bäckström, “Privacy in speech technology”, 2024\. [Online] Available
    at: [https://arxiv.org/abs/2305.05227](https://arxiv.org/abs/2305.05227)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] T. Bäckström, “语音技术中的隐私”，2024年。[在线] 可在以下链接获取：[https://arxiv.org/abs/2305.05227](https://arxiv.org/abs/2305.05227)'
- en: '[3] A. Nautsch et. al. , “The Privacy ZEBRA: Zero Evidence Biometric Recognition
    Assessment,” in *Proceedings of Interspeech*, 2020.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] A. Nautsch 等， “隐私ZEBRA：零证据生物识别评估”，发表于*Interspeech 会议论文集*，2020年。'
- en: '[4] M. H. Vali and T. Bäckström, “NSVQ: Noise Substitution in Vector Quantization
    for Machine Learning,” *IEEE Access*, 2022.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] M. H. Vali 和 T. Bäckström, “NSVQ：用于机器学习的向量量化中的噪声替代”，*IEEE Access*，2022年。'
- en: '[5] M.H. Vali, T. Bäckström, “Interpretable Latent Space Using Space-Filling
    Curves for Phonetic Analysis in Voice Conversion”, in *Proceedings of Interspeech*,
    2023.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] M.H. Vali, T. Bäckström, “使用空间填充曲线进行语音转换中的语音分析的可解释潜在空间”，发表于*Interspeech
    会议论文集*，2023年。'
- en: '[6] B. Desplanques, J. Thienpondt, and K. Demuynck, “ECAPA-TDNN: Emphasized
    Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification,”
    in *Proceedings of Interspeech*, 2020.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] B. Desplanques, J. Thienpondt, 和 K. Demuynck, “ECAPA-TDNN：在基于TDNN的说话人验证中强调通道注意力、传播与聚合，”发表于
    *Interspeech 会议论文集*，2020年。'
- en: '[7] C. Dwork, “Differential privacy: A survey of results,” in'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] C. Dwork, “差分隐私：结果综述，”发表于'
- en: International conference on theory and applications of models
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 模型理论与应用国际会议
- en: of computation. Springer, 2008.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 计算学。Springer，2008年。
