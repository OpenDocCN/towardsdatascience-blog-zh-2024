- en: 'Unlocking Hidden Potential: Exploring Second-Round Purchasers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁隐藏的潜力：探索第二轮购买者
- en: 原文：[https://towardsdatascience.com/unlocking-hidden-potential-exploring-second-round-purchasers-d47958c4d61c?source=collection_archive---------4-----------------------#2024-12-09](https://towardsdatascience.com/unlocking-hidden-potential-exploring-second-round-purchasers-d47958c4d61c?source=collection_archive---------4-----------------------#2024-12-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unlocking-hidden-potential-exploring-second-round-purchasers-d47958c4d61c?source=collection_archive---------4-----------------------#2024-12-09](https://towardsdatascience.com/unlocking-hidden-potential-exploring-second-round-purchasers-d47958c4d61c?source=collection_archive---------4-----------------------#2024-12-09)
- en: Finding customer segments for optimal retargetting using LLM embeddings and
    ML model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LLM嵌入和机器学习模型寻找客户细分，以实现最佳再营销
- en: '[](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)[![Iqbal
    Hamdi](../Images/6e6fe77bd1be3cb9a7f74e0a855cd503.png)](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)
    [Iqbal Hamdi](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)[![Iqbal
    Hamdi](../Images/6e6fe77bd1be3cb9a7f74e0a855cd503.png)](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)
    [Iqbal Hamdi](https://medium.com/@iqbal.hamdi?source=post_page---byline--d47958c4d61c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)
    ·14 min read·Dec 9, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--d47958c4d61c--------------------------------)
    ·阅读时间14分钟·2024年12月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: In this article, we are talking about a method of finding the customer segments
    within a binary classification dataset which have the maximum potential to tip
    over into the wanted class. This method can be employed for different use-cases
    such as selective targetting of customers in the second round of a promotional
    campaign, or finding nodes in a network, which are providing less-than-desirable
    experience, with the highest potential to move over into the desirable category.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了一种方法，用于在二分类数据集中找到具有最大潜力转向目标类别的客户细分。这种方法可以应用于不同的用例，比如在促销活动的第二轮中选择性地定向客户，或者寻找网络中体验较差、但具有最大潜力转向理想类别的节点。
- en: Essentially, the method provides a way to prioritise a segment of the dataset
    which can provide the maximum bang for the buck.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，该方法提供了一种优先选择数据集中特定片段的方式，这些片段能够提供最大价值。
- en: '![](../Images/872319a92573f15f30b9ec40eb58443c.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/872319a92573f15f30b9ec40eb58443c.png)'
- en: The context
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景
- en: 'In this case, we are looking at a bank dataset. The bank is actively trying
    to sell loan products to the potential customers by runnign a campaign. This dataset
    is in public domain provided at Kaggle:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，我们正在研究一个银行数据集。该银行正在通过开展营销活动，积极向潜在客户销售贷款产品。这个数据集是公开的，提供在Kaggle上：
- en: '[](https://www.kaggle.com/datasets/itsmesunil/bank-loan-modelling?source=post_page-----d47958c4d61c--------------------------------)
    [## Bank_Loan_modelling'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/datasets/itsmesunil/bank-loan-modelling?source=post_page-----d47958c4d61c--------------------------------)
    [## Bank_Loan_modelling'
- en: Personal Loan classification problem
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 个人贷款分类问题
- en: www.kaggle.com](https://www.kaggle.com/datasets/itsmesunil/bank-loan-modelling?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/datasets/itsmesunil/bank-loan-modelling?source=post_page-----d47958c4d61c--------------------------------)
- en: 'The description of the problem given above is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题的描述如下：
- en: “The majority of Thera-Bank’s customers are depositors. The number of customers
    who are also borrowers (asset customers) is quite small, and the bank is interested
    in quickly expanding this base to do more loan business while earning more through
    loan interest. In particular, management wants to look for ways to convert its
    liability customers into retail loan customers while keeping them as depositors.
    A campaign the bank ran last year for deposit customers showed a conversion rate
    of over 9.6% success. This has prompted the retail marketing department to develop
    campaigns with better target marketing to increase the success rate with a minimal
    budget.”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: “Thera-Bank的大多数客户都是存款客户。既是借款人（资产客户）的客户数量相对较少，银行希望迅速扩大这一客户群，以便做更多的贷款业务，同时通过贷款利息赚取更多收入。特别是，管理层希望寻找将负债客户转化为零售贷款客户的方式，同时保持他们作为存款客户。去年银行为存款客户开展的一项活动，成功的转化率超过了9.6%。这促使零售营销部门制定更具目标性的营销活动，以更少的预算提高成功率。”
- en: The above problem deals with classifying the customers and helping to prioritise
    new customers. But what if we can use the data collected in the first round to
    target customers who did not purchase the loan in the first round but are most
    likely to purchase in the second round, given that at least one attribute or feature
    about them changes. Preferably, this would be the feature which is easiest to
    change through manual interventions or which can change by itself over time (for
    example, income generally tends to increase over time or family size or education
    level attained).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题涉及到客户分类，并帮助优先考虑新客户。但是，如果我们能够利用第一轮收集的数据，针对那些第一轮没有购买贷款但在第二轮最有可能购买的客户（前提是他们的至少一个属性或特征发生了变化）呢？理想情况下，这个变化的特征应该是通过人工干预容易改变的，或者是随着时间的推移自然会发生变化的（例如，收入通常会随着时间的推移而增加，或者家庭规模、受教育程度等）。
- en: The Solution
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Here is an overview of how this problem is approached in this example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是该问题在本示例中的处理概述：
- en: '![](../Images/d04020542b11d40f2d32e95dfcb4b2c4.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d04020542b11d40f2d32e95dfcb4b2c4.png)'
- en: High Level Process Flow
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 高级流程图
- en: 'Step -1a : Loading the ML Model'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步-a：加载机器学习模型
- en: There are numerous notebooks on Kaggle/Github which provide solutions to do
    model tuning using the above dataset. We will start our discussion with the assumption
    that the model is already tuned and will load it up from our MLFlow repository.
    This is a XGBoost model with F1 Score of 0.99 and AUC of 0.99\. The dependent
    variable (y_label) in this case is ‘Personal Loan’ column.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kaggle/Github上有大量的笔记本提供了使用上述数据集进行模型调优的解决方案。我们将从假设模型已经调优并从我们的MLFlow库中加载它开始讨论。这是一个F1得分为0.99且AUC为0.99的XGBoost模型。此时的因变量（y_label）是‘Personal
    Loan’列。
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step-1b: Loading the data'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步-b：加载数据
- en: Next, we would load up the dataset. This is the dataset which has been used
    for training the model, which means all the rows with missing data or the ones
    which are considered outliers are already removed from the dataset. We would also
    calculate the probabilities for each of the customers in the dataset to purchase
    the loan (given by the column ‘Personal Loan). We will then filter out the customers
    with probabilities greater than 0.5 but which did not purchase the loan (‘Personal
    Loan’ = 0). These are the customers which should have purchased the Loan as per
    the prediction model but they did not in the first round, due to factors not captured
    by the features in the dataset. These are also the cases wrongly predicted by
    the model and which have contributed to a lower than 1 Accuracy and F1 figures.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将加载数据集。这是用于训练模型的数据集，这意味着所有缺失数据的行或被认为是异常值的行已经从数据集中删除。我们还将计算每个客户购买贷款的概率（由‘Personal
    Loan’列给出）。然后我们会过滤出那些概率大于0.5，但没有购买贷款的客户（‘Personal Loan’ = 0）。这些客户应按照预测模型购买贷款，但他们在第一轮没有购买，原因是数据集中的特征未能捕捉到的因素。这些也是模型错误预测的案例，导致准确率和F1得分低于1。
- en: '![](../Images/3a1edb90bee5a763115a73c23341bb50.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a1edb90bee5a763115a73c23341bb50.png)'
- en: Confusion Matrix
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: As we set out for round 2 campaign, these customers would serve as the basis
    for the targetted marketing approach.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始第二轮活动时，这些客户将成为定向营销方法的基础。
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We see that there are only 4 such cases which get added to potential customers
    table and are removed from the main dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到只有4个这样的案例被添加到潜在客户表中，并从主数据集中删除。
- en: '![](../Images/f8075ff4e1ff2698365321d93b51fa2c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8075ff4e1ff2698365321d93b51fa2c.png)'
- en: 'Step-2: Generating SHAP values'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤-2：生成 SHAP 值
- en: 'We are now going to generate the Shapely values to determine the local importance
    of the features and extract the Tipping feature ie. the feature whose variation
    can move over the customer from unwanted class (‘Personal Loan’ = 0) to the wanted
    class (‘Personal Loan’ = 1). Details about Shapely values can be found here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将生成 Shapley 值，以确定特征的局部重要性，并提取关键特征，即能够将客户从不希望的类别（‘个人贷款’ = 0）移动到希望的类别（‘个人贷款’
    = 1）的特征。关于 Shapley 值的详细信息可以在此找到：
- en: '[](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html?source=post_page-----d47958c4d61c--------------------------------)
    [## An introduction to explainable AI with Shapley values - SHAP latest documentation'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html?source=post_page-----d47958c4d61c--------------------------------)
    [## 介绍使用 Shapley 值的可解释 AI - SHAP 最新文档]'
- en: This is an introduction to explaining machine learning models with Shapley values.
    Shapley values are a widely used…
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这是一个介绍如何通过 Shapley 值解释机器学习模型的内容。Shapley 值是一种广泛使用的……
- en: shap.readthedocs.io](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: shap.readthedocs.io](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html?source=post_page-----d47958c4d61c--------------------------------)
- en: We will have a look at some of the important features as well to have an idea
    about the correlation with the dependent variable (‘Personal Loan’). The three
    features we have shortlisted for this purpose are ‘Income’, ‘Family’ (Family Size)
    and ‘Education’. As we will see later on, these are the features which we would
    want to keep our focus on to get the probability changed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将查看一些重要特征，以了解它们与因变量（‘个人贷款’）的相关性。我们为此目的挑选的三个特征是‘收入’，‘家庭’（家庭规模）和‘教育’。正如我们稍后将看到的，这些是我们希望集中关注的特征，以便改变概率。
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/fc77f60e99929f9070ade1c6bada755a.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc77f60e99929f9070ade1c6bada755a.png)'
- en: Purchase of Personal Loan increases with Income
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 个人贷款购买量随收入增加
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/5c73c268902fd4bb8cf469d0ba786c89.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c73c268902fd4bb8cf469d0ba786c89.png)'
- en: Purchase of Personal Loan increases with Family Size
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 个人贷款购买量随家庭规模增加
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/33025fac6f8347d947fe642dde9cadc1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33025fac6f8347d947fe642dde9cadc1.png)'
- en: Purchase of Personal Loan increases with Education
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 个人贷款购买量随教育水平增加
- en: We see that for all 3 features, the purchase of Personal Loan increase as the
    feature value tends to increase, with Shap values of greater than 0 as the feature
    value increases indicating a positive impact of these features on the tendency
    to purchase.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，对于所有 3 个特征，当特征值增加时，个人贷款的购买量也随之增加，Shap 值随着特征值的增加而大于 0，表明这些特征对购买倾向有正面影响。
- en: We will now store the shap values for each of the customers in a dataframe so
    we can access the locally most important feature for later processing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将为每个客户存储 shap 值到一个数据框中，这样我们就可以在后续处理中访问最重要的局部特征。
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Step-3 : Creating Vector Embeddings:'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤-3：创建向量嵌入：
- en: As the next step, we move on to create the vector embeddings for our dataset
    using LLM model. The main purpose for this is to be able to do vector similarity
    search. We intend to find the customers in the dataset, who did not purchase the
    loan, who are closest to the customers in the dataset, who did purchase the loan.
    We would then pick the top closest customers and see how the probability changes
    for these once we change the values for the most important feature for these customers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，我们将使用 LLM 模型为数据集创建向量嵌入。这样做的主要目的是能够进行向量相似度搜索。我们打算在数据集中找到那些没有购买贷款的客户，并找出与那些购买了贷款的客户最相似的客户。然后我们将选择最相似的客户，查看在改变这些客户最重要特征的值后，概率如何变化。
- en: 'There are a number of steps involved in creating the vector embeddings using
    LLM and they are not described in detail here. For a good understanding of these
    processes, I would suggest to go through the below post by Damian Gill:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 LLM 向量嵌入的过程涉及多个步骤，本文中没有详细描述。如果想更好地理解这些过程，我建议阅读 Damian Gill 撰写的以下文章：
- en: '[](/mastering-customer-segmentation-with-llm-3d9008235f41?source=post_page-----d47958c4d61c--------------------------------)
    [## Mastering Customer Segmentation with LLM'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/mastering-customer-segmentation-with-llm-3d9008235f41?source=post_page-----d47958c4d61c--------------------------------)
    [## 精通客户细分与LLM'
- en: Unlock advanced customer segmentation techniques using LLMs, and improve your
    clustering models with advanced…
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLM）解锁先进的客户细分技术，并通过先进的技术改善您的聚类模型…
- en: towardsdatascience.com](/mastering-customer-segmentation-with-llm-3d9008235f41?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/mastering-customer-segmentation-with-llm-3d9008235f41?source=post_page-----d47958c4d61c--------------------------------)
- en: 'In our case, we are using the sentence transformer SBERT model available at
    Hugging Face. Here are the details of the model:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们使用的是Hugging Face上可用的句子变换器SBERT模型。以下是该模型的详细信息：
- en: '[](https://huggingface.co/sentence-transformers?source=post_page-----d47958c4d61c--------------------------------)
    [## sentence-transformers (Sentence Transformers)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://huggingface.co/sentence-transformers?source=post_page-----d47958c4d61c--------------------------------)
    [## sentence-transformers（句子变换器）'
- en: In the following you find models tuned to be used for sentence / text embedding
    generation. They can be used with the…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 以下是经过调整的用于句子/文本嵌入生成的模型。它们可以与…
- en: huggingface.co](https://huggingface.co/sentence-transformers?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: huggingface.co](https://huggingface.co/sentence-transformers?source=post_page-----d47958c4d61c--------------------------------)
- en: 'For us to get better vector embeddings, we would want to provide as much details
    about the data in words as possible. For the bank dataset, the details of each
    of the columns are provided in ‘Description’ sheet of the Excel file ‘Bank_Personal_Loan_Modelling.xlsx’.
    We use this description for the column names. Additionally, we convert the values
    with a little more description than just having numbers in there. For example,
    we replace column name **‘Family’** with **‘Family size of the customer’** and
    the values in this column from integers such as **2** to string such as **‘2 persons’.**
    Here is a sample of the dataset after making these conversions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更好的向量嵌入，我们希望尽可能多地提供关于数据的文字描述。对于银行数据集，关于每一列的详细描述已在Excel文件‘Bank_Personal_Loan_Modelling.xlsx’的‘Description’表中提供。我们使用此描述作为列名。此外，我们将数值转换为稍微更具描述性的内容，而不仅仅是数字。例如，我们将列名**‘Family’**替换为**‘客户的家庭规模’**，并将该列中的值从整数（如**2**）转换为字符串（如**‘2人’**）。以下是进行这些转换后的数据集示例：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/dc4daaad782a43332fcc5b98e9664246.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4daaad782a43332fcc5b98e9664246.png)'
- en: We will create two separate datasets — one for customers who purchased the loans
    and one for those who didn’t.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建两个独立的数据集——一个是购买了贷款的客户，另一个是没有购买的客户。
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will create vector embeddings for both of these cases. Before we pass on
    the dataset to sentence transformer, here is what each row of the bank customer
    dataset would look like:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为这两种情况创建向量嵌入。在将数据集传递给句子变换器之前，以下是银行客户数据集每一行的样子：
- en: '![](../Images/cd7490c99fcc4c43e81e44b49fc895da.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd7490c99fcc4c43e81e44b49fc895da.png)'
- en: Example of one customer input to Sentence Transformer
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个客户输入示例，用于句子变换器
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Step-4+5: Doing the Vector Search'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步+5步：进行向量搜索
- en: Next, we will be doing the Approximate Nearest Neighbor similarity search using
    Euclidean Distance L2 with Facebook AI Similarity Search (FAISS) and will create
    FAISS indexes for these vector datasets. The idea is to search for customers in
    the ‘Personal Loan = 0’ dataset which are most similar to the ones in the ‘Personal
    Loan = 1’ dataset. Basically we are looking for customers who did not purchase
    the loan but are most similar in nature to the ones who purchased the loan. In
    this case, we are doing the search for one ‘false’ customer for each ‘true’ customer
    by setting k=1 (one approximate nearest neighbor) and then sorting the results
    based on their distances.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用欧几里得距离L2进行近似最近邻相似性搜索，并使用Facebook AI相似性搜索（FAISS），为这些向量数据集创建FAISS索引。我们的目标是寻找‘Personal
    Loan = 0’数据集中与‘Personal Loan = 1’数据集中最相似的客户。基本上，我们在寻找那些没有购买贷款但与购买贷款的客户最相似的客户。在这种情况下，我们通过设置k=1（一个近似最近邻）为每个‘true’客户搜索一个‘false’客户，并根据距离对结果进行排序。
- en: 'Details about FAISS similarity search can be found here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有关FAISS相似性搜索的详细信息，请参见此处：
- en: '[](https://github.com/facebookresearch/faiss?source=post_page-----d47958c4d61c--------------------------------)
    [## GitHub - facebookresearch/faiss: A library for efficient similarity search
    and clustering of dense…'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/facebookresearch/faiss?source=post_page-----d47958c4d61c--------------------------------)
    [## GitHub - facebookresearch/faiss：一个用于高效相似性搜索和稠密向量聚类的库…'
- en: A library for efficient similarity search and clustering of dense vectors. -
    facebookresearch/faiss
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个用于高效相似性搜索和稠密向量聚类的库。 - facebookresearch/faiss
- en: github.com](https://github.com/facebookresearch/faiss?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/facebookresearch/faiss?source=post_page-----d47958c4d61c--------------------------------)
- en: 'Here is another article which explains the use of L2 with FAISS:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有另一篇文章解释了如何使用L2与FAISS：
- en: '[](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772?source=post_page-----d47958c4d61c--------------------------------)
    [## How to Use FAISS to Build Your First Similarity Search'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772?source=post_page-----d47958c4d61c--------------------------------)
    [## 如何使用FAISS构建您的第一个相似性搜索'
- en: At Loopio, we use Facebook AI Similarity Search (FAISS) to efficiently search
    for similar text. Finding items that are…
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Loopio，我们使用Facebook AI相似性搜索（FAISS）高效地搜索相似文本。找到与…
- en: medium.com](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772?source=post_page-----d47958c4d61c--------------------------------)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772?source=post_page-----d47958c4d61c--------------------------------)
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This gives us the list of customers most similar to the ones who purchased the
    loan and most likely to purchase in the second round, given the most important
    feature which was holding them back in the first round, gets slightly changed.
    This customer list can now be prioritized.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们列出与已购买贷款的客户最相似且最有可能在第二轮购买的客户，前提是阻碍他们第一次购买的最重要特征稍微发生变化。现在可以优先处理这份客户名单。
- en: '![](../Images/517fc3e6711b65a1af25c1dfff5666d3.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/517fc3e6711b65a1af25c1dfff5666d3.png)'
- en: 'Step-6: A comparison with other method'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Step-6：与其他方法的比较
- en: At this point, we would like to assess if the above methodology is worth the
    time and if there can be another efficient way of extracting the same information?
    For example, we can think of getting the ‘False’ customers with the highest probabilities
    as the ones which have the highest potential for second round purchases. A comparison
    of such a list with the above list can be helpful to see if that can be a faster
    way of deriving conclusions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们希望评估上述方法是否值得花费时间，以及是否存在另一种更高效的方式来提取相同的信息？例如，我们可以考虑将‘False’客户中具有最高概率的客户视为最有可能进行第二轮购买的客户。将这样一份名单与上述名单进行比较，可以帮助我们判断是否有更快速的方式来得出结论。
- en: For this, we simply load up our dataset with the probabilities that we created
    earlier and pick the top 10 ‘False’ customers with the highest probabilities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们只需加载我们之前创建的概率数据集，然后选择概率最高的前10个‘False’客户。
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/12754683785469e14e1a4253b42614b9.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12754683785469e14e1a4253b42614b9.png)'
- en: How effective this list is as compared to our first list and how to measure
    that? For this, we would like to think of the effectiveness of the list as the
    percentage of customers which we are able to tip over into the wanted category
    with minimal change in the most important feature by calculating new probability
    values after making slight change in the most important feature. For our analysis,
    we will only focus on the features Education and Family — the features which are
    likely to change over time. Even though Income can also be included in this category,
    for simplification purposes, we will not consider it for now. We will shortlist
    the top 10 candidates from both lists which have these as the Tipping_Feature.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个名单与我们第一个名单相比有多有效？我们如何衡量这一点？为此，我们希望将名单的有效性定义为能够将客户轻微调整后转为目标类别的百分比，方法是通过对最重要特征进行轻微变化后重新计算概率值。对于我们的分析，我们将仅关注教育和家庭这两个特征——这些特征更有可能随着时间的推移发生变化。尽管收入也可以纳入此类别，但为了简化分析，我们暂时不考虑收入。我们将从两个名单中筛选出前10个客户，这些客户将作为Tipping_Feature。
- en: 'This will give us the below 2 lists:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们提供以下两份名单：
- en: 'List_A: This is the list we get using the similarity search method'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: List_A：这是我们使用相似性搜索方法得到的名单
- en: 'List_B: This is the list we get through sorting the False cases using their
    probabilities'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: List_B：这是我们通过按概率对False案例进行排序得到的名单
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/dd9a198419251c8ee26655618f8578cc.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd9a198419251c8ee26655618f8578cc.png)'
- en: We will convert List_A into the original format which can be then used by the
    ML Model to calculate the probabilities. This would require a reference back to
    the original df_pred dataset and here is a function which can be used for that
    purpose.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把A列表转换回原始格式，然后可以被ML模型用来计算概率。这需要参考原始的df_pred数据集，下面是可以用来实现这一目的的函数。
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/a46b24ed72d5b99d3d6e1c8f09a5a5f4.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a46b24ed72d5b99d3d6e1c8f09a5a5f4.png)'
- en: 'Potential Candidates List_A: Extracted using the similarity Search method'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在候选者A列表：通过相似度搜索方法提取
- en: Below is how we will get List_B by putting in the required filters on the original
    df_pred dataframe.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过在原始df_pred数据框中应用所需过滤器来获取B列表的方法。
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/c7a092ed639944ca1253c7d0cbe1d207.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7a092ed639944ca1253c7d0cbe1d207.png)'
- en: 'Potential Candidates List_B: Extracted by sorting the probabilities of purchasing
    the loan in the first round'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在候选者B列表：通过对第一次计算贷款购买概率进行排序提取
- en: For evaluation, I have created a function which does a grid search on the values
    of Family or Education depending upon the Tipping_Feature for that customer from
    minimum value (which would be the current value) to the maximum value (which is
    the maximum value seen in the entire dataset for that feature) till the probability
    increases beyond 0.5.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行评估，我创建了一个函数，根据该客户的Tipping_Feature对Family或Education的值进行网格搜索，从最小值（即当前值）到最大值（即在整个数据集中该特征的最大值），直到概率超过0.5。
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/6b6dae91482d6dc8abf1bb9191ed61c5.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b6dae91482d6dc8abf1bb9191ed61c5.png)'
- en: List B Probabilities after changing the value for the Tipping_Feature
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 改变Tipping_Feature值后B列表的概率
- en: We see that with List B, the candidates which we got through the use of probabilities,
    there was one candidate which couldn’t move into the wanted category after changing
    the tipping_values. At the same time, there were 4 candidates (highlighted in
    red) which show very high probability of purchasing the loan after the tipping
    feature changes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在使用概率得到的B列表中，有一个候选者在改变Tipping_Feature值后无法进入期望的类别。与此同时，有4个候选者（以红色突出显示）在改变Tipping_Feature后显示出非常高的贷款购买概率。
- en: We run this again for the candidates in List A.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次对A列表中的候选者执行相同的操作。
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/fc764e69368b576dcfc7cd2fd91ca11f.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc764e69368b576dcfc7cd2fd91ca11f.png)'
- en: List A Probabilities after changing the value for the Tipping_Feature
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 改变Tipping_Feature值后A列表的概率
- en: For List A, we see that while there is one candidate which couldn’t tip over
    into the wanted category, there are 6 candidates (highlighted in red) which show
    very high probability once the tipping feature value is changed. We can also see
    that these candidates originally had very low probabilities of purchasing the
    loan and without the use of similarity search, these potential candidates would
    have been missed out.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于A列表，我们看到虽然有一个候选者未能进入期望的类别，但有6个候选者（以红色突出显示），在改变Tipping_Feature值后显示出非常高的购买贷款概率。我们还可以看到，这些候选者原本的贷款购买概率非常低，如果没有使用相似度搜索，这些潜在的候选者将会被忽略。
- en: Conclusion
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: While there can be other methods to search for potential candidates, similarity
    search using LLM vector embeddings can highlight candidates which would most likely
    not get prioritized otherwise. The method can have various usage and in this case
    was combined with the probabilities calculated with the help of XGBoost model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以采用其他方法来搜索潜在候选者，但使用LLM向量嵌入进行的相似度搜索可以突出那些否则很可能不会被优先考虑的候选者。这种方法可以有多种用途，在本案例中，它与使用XGBoost模型计算出的概率结合使用。
- en: '*Unless stated otherwise, all images are by the author.*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均来自作者。*'
