- en: Tackle Complex LLM Decision-Making with Language Agent Tree Search (LATS) &
    GPT-4o
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应对复杂LLM决策制定：语言代理树搜索（LATS）与GPT-4o的结合
- en: 原文：[https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26](https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26](https://towardsdatascience.com/tackle-complex-llm-decision-making-with-language-agent-tree-search-lats-gpt4-o-0bc648c46ea4?source=collection_archive---------2-----------------------#2024-08-26)
- en: 'Enhancing LLM decision-making: integrating language agent tree search with
    GPT-4o for superior problem-solving'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强LLM决策制定：将语言代理树搜索与GPT-4o结合，实现卓越的问题解决能力
- en: '[](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Ozgur
    Guler](../Images/0fa0f9412fddfff81c9004af33e277e8.png)](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    [Ozgur Guler](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Ozgur
    Guler](../Images/0fa0f9412fddfff81c9004af33e277e8.png)](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    [Ozgur Guler](https://cloudatlas.me/?source=post_page---byline--0bc648c46ea4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    ·9 min read·Aug 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--0bc648c46ea4--------------------------------)
    ·9分钟阅读·2024年8月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1af94ed3cff9126b91f6176f1e210758.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1af94ed3cff9126b91f6176f1e210758.png)'
- en: 'Image by the author: midjourney — abstract puzzle'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片：midjourney — 抽象拼图
- en: Large Language Models (LLMs) have demonstrated exceptional abilities in performing
    natural language tasks that involve complex reasoning. As a result, these models
    have evolved to function as agents capable of planning, strategising, and solving
    complex problems. However, challenges persist when it comes to making decisions
    under uncertainty, where outcomes are not deterministic, or when adaptive decision-making
    is required in changing environments, especially in multi-step scenarios where
    each step influences the next. We need more advanced capabilities…
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在执行涉及复杂推理的自然语言任务中展现出了卓越的能力。因此，这些模型已经发展成能够规划、制定战略并解决复杂问题的代理。然而，当面临不确定性时，决策仍然存在挑战，尤其是在结果不是确定性的情况下，或者当在变化的环境中需要适应性决策时，尤其是在多步骤场景中，每一步都会影响到下一步。我们需要更先进的能力……
- en: This is where GPT-4’s advanced reasoning capabilities and Language Agent Tree
    Search (LATS) come together to address these challenges. LATS incorporates a dynamic,
    tree-based search methodology that enhances the reasoning capabilities of GPT-4O.
    By integrating Monte Carlo Tree Search (MCTS) with LLMs, LATS unifies reasoning,
    acting, and planning, creating a more deliberate and adaptive problem-solving
    framework. This powerful combination allows for improved decision-making and more
    robust handling of complex tasks, setting a new standard in the deployment of
    language models as autonomous agents.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GPT-4的高级推理能力和语言代理树搜索（LATS）结合在一起，解决这些挑战的地方。LATS结合了一种动态的基于树的搜索方法，增强了GPT-4O的推理能力。通过将蒙特卡洛树搜索（MCTS）与大语言模型（LLMs）结合，LATS统一了推理、行动和规划，创造了一个更加深思熟虑且适应性强的问题解决框架。这一强大的组合提高了决策制定的能力，更加稳健地应对复杂任务，为语言模型作为自主代理的应用设立了新的标准。
- en: Is “search” the missing piece in GenAI problem solving?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “搜索”是生成式AI问题解决中的缺失环节吗？
- en: '![](../Images/2a16198d5a97e718d980dec57e08a408.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a16198d5a97e718d980dec57e08a408.png)'
- en: 'Image by the author: midjourney — abstract puzzle'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片：midjourney — 抽象拼图
- en: Computational problem solving can be broadly defined as “***search through a
    combinatorial problem space***”, represented as a tree. [**Depth-First Search
    (DFS)**](https://en.wikipedia.org/wiki/Depth-first_search) and [**Breadth-First
    Search (BFS)**](https://en.wikipedia.org/wiki/Breadth-first_search) are fundamental
    methods for exploring such solution spaces. A notable example of the power of
    deep search is AlphaGo’s “[Move 37,”](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol)
    which showcased how innovative, human-surpassing solutions can emerge from extensive
    exploration.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 计算问题解决可以广泛定义为“***在组合问题空间中搜索***”，通常表现为一棵树。[**深度优先搜索（DFS）**](https://en.wikipedia.org/wiki/Depth-first_search)和[**广度优先搜索（BFS）**](https://en.wikipedia.org/wiki/Breadth-first_search)是探索这些解空间的基本方法。深度搜索的一个显著例子是AlphaGo的“[第37手](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol)”，它展示了如何通过广泛探索涌现出创新的、超越人类的解决方案。
- en: Unlike traditional methods that follow **predefined paths**, LLMs can dynamically
    generate new branches within the solution space by predicting potential outcomes,
    strategies, or actions based on context. This capability allows LLMs to not only
    navigate but also expand the problem space, making them exceptionally powerful
    in situations where the problem structure is not fully known, is continuously
    evolving, or is highly complex.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与遵循**预定义路径**的传统方法不同，LLMs可以通过根据上下文预测潜在的结果、策略或行动，动态生成解空间中的新分支。这一能力使得LLMs不仅能够导航，还能扩展问题空间，使它们在问题结构尚不完全明确、不断演变或高度复杂的情况下具有非凡的能力。
- en: Inference-time Reasoning with Meta Generation Algorithms (MGA)
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于推理时间的推理与元生成算法（MGA）
- en: '![](../Images/6678b242a08f9b2c8c2ea23a1627ce23.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6678b242a08f9b2c8c2ea23a1627ce23.png)'
- en: 'Image by the author: midjourney — abstract puzzle'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：midjourney — 抽象拼图
- en: Scaling compute during training is widely recognised for its ability to improve
    model performance. **The benefits of scaling compute during inference remain under-explored.**
    MGA’s offer a novel approach by amplifying computational resources during inference…
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中扩展计算能力被广泛认可为提高模型性能的有效方法。**在推理过程中扩展计算的好处仍然没有得到充分探索。** MGA通过在推理过程中增强计算资源提供了一种新颖的方法……
- en: Unlike traditional token-level generation methods, meta-generation algorithms
    employ higher-order control structures such as planning, loops with multiple model
    calls, self-reflection, task decomposition, and dynamic conditioning. These mechanisms
    allow the model to execute tasks end-to-end, mimicking higher-level cognitive
    processes often referred to as Systems-2 thinking.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的标记级生成方法不同，元生成算法采用更高阶的控制结构，如规划、带有多个模型调用的循环、自我反思、任务分解和动态调节。这些机制使得模型能够端到端地执行任务，模仿通常被称为系统2思维的高级认知过程。
- en: '![](../Images/398973dd49349edcc22c35cf5384dc0f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/398973dd49349edcc22c35cf5384dc0f.png)'
- en: 'Image by the author: Inference-time Reasoning methods — summarised'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：推理时间推理方法 — 摘要
- en: '**Therefore one-way meta generation algorithms may enhance LLM reasoning by
    integrating search into the generation process**. During inference, MGA’s dynamically
    explore a broader solution space, allowing the model to reason through potential
    outcomes and adapt strategies in real-time. By generating multiple paths and evaluating
    their viability, meta generation algorithms enable LLMs to simulate deeper, more
    complex reasoning akin to traditional search methods. This approach not only expands
    the model’s ability to generate novel insights but also improves decision-making
    in scenarios with incomplete or evolving information.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**因此，一种单向的元生成算法可能通过将搜索整合到生成过程中，增强LLM的推理能力**。在推理过程中，MGA动态地探索更广泛的解空间，使模型能够实时地推理潜在结果并调整策略。通过生成多个路径并评估其可行性，元生成算法使LLMs能够模拟出类似于传统搜索方法的更深层次、更复杂的推理。这种方法不仅扩展了模型生成新颖见解的能力，还改善了在信息不完整或不断变化的情况下的决策能力。'
- en: Techniques like **Tree of Thoughts (ToT)**, and **Graph of Thought (GoT)** are
    employed to navigate combinatorial solution spaces efficiently.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 技术如**思想树（ToT）**和**思想图（GoT）**被用来高效地在组合解空间中导航。
- en: '**ToT** (*2**) enables hierarchical decision-making by structuring potential
    outcomes as tree branches, facilitating exploration of multiple paths.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ToT** (*2**)通过将潜在结果结构化为树枝来实现分层决策，使得探索多个路径成为可能。'
- en: '**GoT (***6****)**maps complex relationships between ideas, allowing the model
    to dynamically adjust and optimize its reasoning path.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GoT (***6****)** 映射了思想之间的复杂关系，使得模型能够动态调整并优化其推理路径。'
- en: '**CoT** (*5**) provides step-by-step reasoning that links sequential thoughts,
    improving the coherence and depth of the generation.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CoT** (*5**)提供逐步推理，链接顺序思维，增强生成的连贯性和深度。'
- en: Why is MCTS better ?
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么MCTS更好？
- en: In the Tree of Thoughts (ToT) approach, traditional methods like Depth-First
    Search (DFS) or Breadth-First Search (BFS) can navigate this tree, but they are
    computationally expensive because they explore each possible path systematically
    & exhaustively.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在思想树（ToT）方法中，传统方法如深度优先搜索（DFS）或广度优先搜索（BFS）可以遍历这棵树，但它们计算开销大，因为它们系统性地和穷举地探索每一条路径。
- en: Monte Carlo Tree Search (MCTS) is an improvement on this by simulating different
    outcomes for actions and updating the tree based on these simulations. It uses
    a “selection” process where it picks decision nodes using a strategy that balances
    exploration (trying new paths) and exploitation (choosing known good paths). This
    is guided by a formula called Upper Confidence Bound (UCB).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡洛树搜索（MCTS）通过模拟不同的行动结果并根据这些模拟更新树结构，改进了这一点。它采用一种“选择”过程，通过平衡探索（尝试新路径）和利用（选择已知有效路径）的策略来选择决策节点。这一过程由一个称为上置信界（UCB）的公式指导。
- en: 'The UCB formula has two key parts:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: UCB公式有两个关键部分：
- en: '**Exploration Term:** This represents the potential reward of choosing a node
    and is calculated through simulations.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**探索项：** 这代表选择某个节点的潜在奖励，通过模拟进行计算。'
- en: '**Exploitation Term:** This decreases the deeper you go into a certain path,
    meaning that if a path is over-explored, the algorithm may shift to a less-explored
    path even if it seems less promising initially.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**利用项：** 这个值随着你进入某条路径的深度而减少，这意味着如果某条路径被过度探索，算法可能会转向一个探索较少的路径，即使该路径最初看起来不那么有前景。'
- en: By selecting nodes using UCB, simulating outcomes (rewards) with LLMs, and back-propagating
    the rewards up the tree, MCTS effectively balances between exploring new strategies
    and exploiting known successful ones.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用UCB选择节点，利用LLM模拟结果（奖励），并将奖励反向传播到树的上层，MCTS有效地平衡了探索新策略和利用已知成功策略之间的关系。
- en: The second part of the UCB formula is the **‘exploitation term,’** which decreases
    as you explore deeper into a specific path. This decrease may lead the selection
    algorithm to switch to another path in the decision tree, even if that path has
    a lower immediate reward, because the exploitation term remains higher when that
    path is less explored.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: UCB公式的第二部分是**‘利用项’**，它随着你在特定路径中的探索深度增加而减少。这种减少可能导致选择算法切换到决策树中的另一条路径，即使那条路径的即时奖励较低，因为当该路径较少被探索时，利用项会保持较高。
- en: Node selection with UCB, reward calculations with LLM simulations and backpropagation
    are the essence of MCTS.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用UCB进行节点选择、通过LLM模拟进行奖励计算以及反向传播是MCTS的核心。
- en: An Implementation — Financial Decision Making…
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种实现——金融决策……
- en: '![](../Images/3710dd691db8b2ce49c431938a9ad80f.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3710dd691db8b2ce49c431938a9ad80f.png)'
- en: LATS operation (1*) [https://arxiv.org/pdf/2310.04406](https://arxiv.org/pdf/2310.04406)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: LATS 操作 (1*) [https://arxiv.org/pdf/2310.04406](https://arxiv.org/pdf/2310.04406)
- en: For the sake of demonstration we will use LATS to solve the challenging problem
    of coming up with the optimal investment strategy in todays macroeconomic climate.
    We will feed LLM with the macro-economic statu susing the “IMF World Economic
    Outlook Report” as the context simply summarising the document. RAG is not used.
    Below is an example as to how LATS searches through the solution space…
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示，我们将使用LATS来解决在当今宏观经济环境中制定最佳投资策略的挑战性问题。我们将使用“国际货币基金组织世界经济展望报告”中的宏观经济状况作为上下文，将文档简要总结后输入LLM。RAG不使用。以下是LATS如何在解空间中进行搜索的示例……
- en: 'Iteration 1:'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代1：
- en: '**Selection:** We start at the root node, and since this is the first LATS
    iteration, we will select all initial decision nodes generated by the LLM (A,
    B, and C nodes) and simulate their outcomes.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择：** 我们从根节点开始，由于这是第一次LATS迭代，我们将选择LLM生成的所有初始决策节点（A、B和C节点）并模拟它们的结果。'
- en: '**Simulation & Backpropagation:** NextLLM “simulates” each strategy based on
    the context it has and assigns the following “rewards” — investment returns —
    to each “node”.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模拟与反向传播：** NextLLM根据它所拥有的上下文“模拟”每个策略，并为每个“节点”分配以下“奖励”——投资回报。'
- en: '**Strategy A**: $5,000'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略A**：$5,000'
- en: '**Strategy B**: $7,000'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略B**：$7,000'
- en: '**Strategy C**: $4,000'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略C**：$4,000'
- en: 3\. **Expansion:** Based on the selection, **Strategy B** has the highest UCB1
    value (since all nodes are at the same depth), so we expand only **Strategy B**
    by simulating its child nodes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 3. **扩展：** 根据选择，**策略 B** 具有最高的 UCB1 值（因为所有节点处于相同深度），所以我们仅通过模拟其子节点来扩展 **策略 B**。
- en: '![](../Images/dbce1fa357313bed6d2079283a726f17.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbce1fa357313bed6d2079283a726f17.png)'
- en: 'Image by the author: B node expanded as it has the higher simulated reward
    value'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图示：由于模拟奖励值更高，B 节点被扩展
- en: 'Iteration 2:'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 2 次迭代：
- en: '**Selection**: Since B1 & B2 strategies are not simulated, there is a tie in
    terms of their UCB scores and both nodes will be simulated.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择：** 由于 B1 和 B2 策略没有被模拟，它们的 UCB 分数存在平局，因此两个节点都将被模拟。'
- en: '**Simulate Both Nodes**:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模拟两个节点**：'
- en: '**Simulate B1**: LLM predicts a return of **$8,500** for **B1**.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模拟 B1**：LLM 预测 **B1** 的回报为 **$8,500**。'
- en: '**Simulate B2**: LLM predicts a return of **$7,500** for **B2**.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模拟 B2**：LLM 预测 **B2** 的回报为 **$7,500**。'
- en: '3\. **Backpropagation**:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 3. **反向传播：**
- en: After each simulation, results of the simulation are back-propagated up the
    tree, updating the values of the parent nodes. This step ensures that the impact
    of the new information is reflected throughout the tree.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每次模拟后，模拟结果会被反向传播到树中，更新父节点的值。此步骤确保新信息的影响在整个树中得到反映。
- en: '**Updating Strategy B’s Value**: **Strategy B** now needs to reflect the outcomes
    of **B1** and **B2**. One common approach is to average the rewards of **B1**
    and **B2** to update **Strategy B**’s value. Now, **Strategy B** has an updated
    value of **$8,000** based on the outcomes of its child nodes.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新策略 B 的值：** **策略 B** 现在需要反映 **B1** 和 **B2** 的结果。一种常见的方法是平均 **B1** 和 **B2**
    的奖励，以更新 **策略 B** 的值。现在，**策略 B** 的更新值为 **$8,000**，基于其子节点的结果。'
- en: '![](../Images/bc33d70a8576e8f639748eacc8d2360a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc33d70a8576e8f639748eacc8d2360a.png)'
- en: 'Image by the author: Strategy B reward value is updated following backpropagation'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图示：策略 B 的奖励值在反向传播后被更新
- en: 4\. **Recalculate UCB Scores:**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 4. **重新计算 UCB 分数：**
- en: After backpropagation, the UCB scores **for all nodes in the tree** are recalculated.
    This recalculation uses the updated values (average rewards) and visit counts,
    ensuring that each node’s UCB1 score accurately reflects both its potential reward
    and how much it has been explored.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播后，**所有树中节点的 UCB 分数**都会重新计算。此重新计算使用更新后的值（平均奖励）和访问次数，确保每个节点的 UCB1 分数准确反映其潜在奖励和已被探索的程度。
- en: UCB(s) = (exploration/reward term)+ (exploitation term)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: UCB(s) = (探索/奖励项) + (利用项)
- en: Note again the exploitation term decreases for all nodes on a path that is continously
    explored deeper.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，对于所有路径上持续被更深探索的节点，其利用项会减小。
- en: '**5\. Next selection & simulation:**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**5. 下一步选择与模拟：**'
- en: '**B1** is selected for further expansion (as it has the higher reward) into
    child nodes:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**B1** 被选中进行进一步扩展（因为它具有更高的奖励），进入其子节点：'
- en: '**B1a**: “Invest in AI companies”'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B1a**：“投资于人工智能公司”'
- en: '**B1b**: “Invest in green tech”'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B1b**：“投资于绿色技术”'
- en: '![](../Images/da47d0a75d12cd098eebbf2a64845349.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da47d0a75d12cd098eebbf2a64845349.png)'
- en: 'Image by the author: B1 node is expanded further as it has the higher reward'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图示：由于有更高的奖励，B1 节点进一步扩展
- en: 6\. **Backpropagation:**
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 6. **反向传播：**
- en: '![](../Images/0e80b6cb8ff2fcd14c6e1672b6db1165.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e80b6cb8ff2fcd14c6e1672b6db1165.png)'
- en: 'Image by the author: Child node rewards are backpropagated upwards'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图示：子节点的奖励值被反向传播到父节点
- en: B1 reward updated as (9200 + 6800) / 2 = 8000
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: B1 的奖励值更新为 (9200 + 6800) / 2 = 8000
- en: B reward updated as (8000 + 7500) / 2 = 7750
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: B 的奖励更新为 (8000 + 7500) / 2 = 7750
- en: '**7.UCB Calculation:**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**7. UCB 计算：**'
- en: Following backpropagation UCB values of all nodes are recalculated. Assume that
    due to the decaying exploration factor, **B2** now has a higher UCB score than
    both **B1a** and **B1b**. This could occur if **B1** has been extensively explored,
    reducing the exploration term for its children. Instead of continuing to expand
    **B1**’s children, the algorithm shifts back to explore **B2**, which has become
    more attractive due to its unexplored potential i.e. higher exploitation value.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播后，所有节点的 UCB 值都会重新计算。假设由于衰减的探索因子，**B2** 现在的 UCB 分数高于 **B1a** 和 **B1b**。如果
    **B1** 已经被广泛探索，导致其子节点的探索项减少，那么这种情况就会发生。算法会转而探索 **B2**，因为 **B2** 因为未被探索的潜力变得更有吸引力，即其更高的利用价值。
- en: '![](../Images/1f27254ac66074364aa2ee0ff364b4c4.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f27254ac66074364aa2ee0ff364b4c4.png)'
- en: 'Image by the author: When a path through a node is explored deeper exploitation
    value of the node decreases which may trigger a branch switch — a new path through
    a new decision node to be explored further'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：当深入探索节点的路径时，节点的进一步利用价值会下降，这可能会触发分支切换——即通过新的决策节点进一步探索的新路径
- en: This example illustrates how MCTS can dynamically adjust its search path based
    on new information, ensuring that the algorithm remains efficient and focused
    on the most promising strategies as it progresses.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例展示了MCTS如何基于新信息动态调整其搜索路径，确保算法在进行过程中仍然高效，并集中关注最有前景的策略。
- en: An Implementation with Azure OpenAI GPT-4o
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Azure OpenAI GPT-4o的实现
- en: Next we will build a “financial advisor” using GPT-4o, implementing LATS. (Please
    refer to the Github repo [here](https://github.com/ozgurgulerx/llm-reasoning-lats/tree/main)
    for the code.)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将使用GPT-4o构建一个“财务顾问”，实现LATS。（代码请参阅GitHub仓库[这里](https://github.com/ozgurgulerx/llm-reasoning-lats/tree/main)。）
- en: '*(For an accurate analysis I am using the* [*IMF World Economic Outlook report*](https://www.imf.org/en/Publications/WEO)
    *from July, 24 as my LLM context for simulations i.e. for generating child nodes
    and for assigning rewards to decision nodes …)*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*(为了进行准确分析，我正在使用* [*IMF世界经济展望报告*](https://www.imf.org/en/Publications/WEO)
    *（2023年7月24日发布）作为我的LLM上下文进行模拟，即用于生成子节点并为决策节点分配奖励…)*'
- en: Here is how the code runs…
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码运行的方式…
- en: LATS iterating MCTS over the decision tree, creating new nodes and exploring
    the tree
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: LATS迭代MCTS遍历决策树，创建新节点并探索树
- en: The code leverages the `graphviz` library to visually represent the decision
    tree generated during the execution of the investment strategy simulations. Decision
    tree is too wide and cannot fit into a single picture hence I have added snippets
    as to how the tree looks below. You can find a sample decision tree in the github
    repo [here](https://github.com/ozgurgulerx/llm-reasoning-lats/blob/main/investment_decision_tree_with_optimal_path.pdf)…
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码利用`graphviz`库可视化表示在执行投资策略模拟过程中生成的决策树。由于决策树过于宽广，无法容纳在一张图片中，因此我已经添加了关于树形图样式的片段。您可以在GitHub仓库[这里](https://github.com/ozgurgulerx/llm-reasoning-lats/blob/main/investment_decision_tree_with_optimal_path.pdf)找到一个决策树示例…
- en: '![](../Images/be7c8818cadaa56d25b6e271fecc3611.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be7c8818cadaa56d25b6e271fecc3611.png)'
- en: 'Image by the author: Sample run of the MCTS code to find the best investment
    strategy in current macroeconomic climate'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：MCTS代码运行示例，用于在当前宏观经济环境下寻找最佳投资策略
- en: '![](../Images/b8b3f1f0093188458ab090f95a3b765d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8b3f1f0093188458ab090f95a3b765d.png)'
- en: 'Image by the author: Screen capture from the generated decision tree'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：来自生成的决策树的屏幕截图
- en: Below is the optimal strategy inferred by LATS…
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是LATS推断出的最佳策略…
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Conclusion:'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论：
- en: By integrating LATS, we harness the reasoning capabilities of LLMs to simulate
    and evaluate potential strategies dynamically. This combination allows for the
    construction of decision trees that not only represent the logical progression
    of decisions but also adapt to changing contexts and insights, provided by the
    LLM through simulations and reflections.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合LATS，我们利用大型语言模型（LLMs）的推理能力，动态模拟和评估潜在的策略。这种结合不仅能构建出代表决策逻辑进展的决策树，还能根据LLM通过模拟和反思提供的变化的背景和见解进行自适应。
- en: (Unless otherwise noted, all images are by the author)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: （除非另有注明，所有图片均来自作者）
- en: 'References:'
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '*[1] Language Agent Tree Search: Unifying Reasoning, Acting, and Planning in
    Language Models* by Zhou et al'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*[1] 语言代理树搜索：统一推理、行动和规划在语言模型中的应用* 由Zhou等人撰写'
- en: '*[2] Tree of Thoughts: Deliberate Problem Solving with Large Language Models*
    by Yao et al'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*[2] 思维树：利用大型语言模型进行深思熟虑的问题解决* 由Yao等人撰写'
- en: '*[3] The Landscape of Emerging AI Agent Architectures for Reasoning, Planning,
    and Tool Calling: A Survey* by Tula Masterman, Mason Sawtell, Sandi Besen, and
    Alex Chao'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*[3] 新兴AI代理架构在推理、规划和工具调用中的应用：一项调查* 由Tula Masterman、Mason Sawtell、Sandi Besen和Alex
    Chao撰写'
- en: '*[4] From Decoding to Meta-Generation: Inference-time Algorithms for Large
    Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson*, Hailey Schoelkopf*,
    Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*[4] 从解码到元生成：大型语言模型的推理时间算法* 由Sean Welleck、Amanda Bertsch、Matthew Finlayson、Hailey
    Schoelkopf、Alex Xie、Graham Neubig、Ilia Kulikov和Zaid Harchaoui撰写。'
- en: '*[5] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models*
    by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia,
    Ed H. Chi, Quoc V. Le, and Denny Zhou'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*[5] 连锁思维提示引发大语言模型的推理*，作者：Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
    Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le 和 Denny Zhou。'
- en: '*[7] Graph of Thoughts: Solving Elaborate Problems with Large Language Models*
    by Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michał Podstawski,
    Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk,
    and Torsten Hoefler.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*[7] 思维图谱：使用大语言模型解决复杂问题*，作者：Maciej Besta, Nils Blach, Ales Kubicek, Robert
    Gerstenberger, Michał Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann,
    Hubert Niewiadomski, Piotr Nyczyk 和 Torsten Hoefler。'
- en: '*[8] From Decoding to Meta-Generation: Inference-time Algorithms for Large
    Language Models” by Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf,
    Alex Xie, Graham Neubig, Ilia Kulikov, and Zaid Harchaoui.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*[8] 从解码到元生成：大语言模型的推理时算法*，作者：Sean Welleck, Amanda Bertsch, Matthew Finlayson,
    Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov 和 Zaid Harchaoui。'
