- en: Self-Service ML with Relational Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助式机器学习与关系型深度学习
- en: 原文：[https://towardsdatascience.com/self-service-ml-with-relational-deep-learning-beb693a21d5b?source=collection_archive---------9-----------------------#2024-10-22](https://towardsdatascience.com/self-service-ml-with-relational-deep-learning-beb693a21d5b?source=collection_archive---------9-----------------------#2024-10-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/self-service-ml-with-relational-deep-learning-beb693a21d5b?source=collection_archive---------9-----------------------#2024-10-22](https://towardsdatascience.com/self-service-ml-with-relational-deep-learning-beb693a21d5b?source=collection_archive---------9-----------------------#2024-10-22)
- en: Do ML directly on your relational database
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接在关系型数据库上进行机器学习
- en: '[](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)[![Laurin
    Brechter](../Images/5a68b96bddf86846a2bef9d482ef9dd3.png)](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)
    [Laurin Brechter](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)[![Laurin
    Brechter](../Images/5a68b96bddf86846a2bef9d482ef9dd3.png)](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)
    [Laurin Brechter](https://medium.com/@brechterlaurin?source=post_page---byline--beb693a21d5b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)
    ·7 min read·Oct 22, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--beb693a21d5b--------------------------------)
    ·阅读时间7分钟·2024年10月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/fd3ee51120626ff5eccf5c3fc113c1db.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd3ee51120626ff5eccf5c3fc113c1db.png)'
- en: Relational Schema of our Dataset, [source](https://www.kaggle.com/datasets/mmohaiminulislam/ecommerce-data-analysis/data);
    Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据集的关系模式，[来源](https://www.kaggle.com/datasets/mmohaiminulislam/ecommerce-data-analysis/data)；图像由作者提供
- en: In this blog post, we will dive into an interesting new approach to Deep Learning
    (DL) called Relational Deep Learning (RDL). We will also gain some hands-on experience
    by doing some RDL on a real-world database (not a dataset!) of an e-commerce company.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将深入探讨一种有趣的新型深度学习（DL）方法——关系型深度学习（RDL）。我们还将通过在一个实际的电子商务公司数据库（而不是数据集！）上进行RDL，来获得一些实践经验。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In the real world, we usually have a relational database against which we want
    to run some ML task. But especially when the database is highly normalized, this
    implies lots of time-consuming feature engineering and loss of granularity as
    we have to do many aggregations. What’s more, there’s a myriad of possible combinations
    of features that we can construct each of which might yield good performance [2].
    That means we are likely to leave some information relevant to the ML task on
    the table.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，我们通常会有一个关系型数据库，我们希望在其上执行一些机器学习任务。但是，特别是当数据库高度规范化时，这意味着需要大量耗时的特征工程，而且由于需要进行许多聚合操作，细节会丢失。此外，我们可以构造出许多不同的特征组合，而每种组合可能都会带来良好的性能[2]。这意味着我们很可能会遗漏一些对机器学习任务相关的信息。
- en: This is similar to the early days of computer vision, before the advent of deep
    neural networks where features were hand-crafted from the pixel values. Nowadays,
    models work directly with the raw pixels instead of relying on this intermediate
    layer.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于计算机视觉的早期阶段，在深度神经网络出现之前，当时的特征是通过像素值手工构建的。如今，模型直接处理原始像素，而不再依赖于这一中间层。
- en: Relational Deep Learning
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关系型深度学习
- en: RDL promises to do the same for tabular learning. That is, it removes the extra
    step of constructing a feature matrix by learning directly on top of your relational
    database. It does so by transforming the database with its relations into a graph
    where a row in a table becomes a node and relations between tables become edges.
    The row values are stored inside the nodes as node features.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 关系型深度学习（RDL）承诺为表格学习带来相同的效果。也就是说，它通过直接在关系型数据库上进行学习，去除了构建特征矩阵的额外步骤。它通过将数据库及其关系转化为图形来实现这一点，其中表格中的每一行成为一个节点，表格之间的关系成为边缘。行的值存储在节点内部，作为节点特征。
- en: '*In this blog post, we will be using this* [*e-commerce dataset*](https://www.kaggle.com/datasets/mmohaiminulislam/ecommerce-data-analysis/data)
    *from kaggle which contains transactional data about an e-commerce platform in
    a star schema with a central fact table (transactions) and some dimension tables.
    The full code can be found in this* [*notebook*](https://github.com/LaurinBrechter/GraphTheory/blob/main/rdl/rdl_ecommerce.ipynb)*.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*在这篇博客文章中，我们将使用来自Kaggle的这个* [*电子商务数据集*](https://www.kaggle.com/datasets/mmohaiminulislam/ecommerce-data-analysis/data)
    *，它包含了一个电子商务平台的交易数据，采用星型模式，中央事实表（交易）和一些维度表。完整的代码可以在这个* [*笔记本*](https://github.com/LaurinBrechter/GraphTheory/blob/main/rdl/rdl_ecommerce.ipynb)*中找到。*'
- en: Throughout this blog post, we will be using the [relbench](https://github.com/snap-stanford/relbench)
    library to do [RDL](https://relbench.stanford.edu/). The first thing we have to
    do in relbench is to specify the schema of our relational database. Below is an
    example of how we can do so for the ‘transactions’ table in the database. We give
    the table as a pandas dataframe and specify the primary key and the timestamp
    column. The primary key column is used to uniquely identify the entity. The timestamp
    ensures that we can only learn from past transactions when we want to forecast
    future transactions. In the graph, this means that information can only flow from
    nodes with a lower timestamp (i.e. in the past) to ones with a higher timestamp.
    Additionally, we specify the foreign keys that exist in the relation. In this
    case, the transactions table has the column ‘customer_key’ which is a foreign
    key that points to the ‘customer_dim’ table.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在整篇博客文章中，我们将使用 [relbench](https://github.com/snap-stanford/relbench) 库来执行 [RDL](https://relbench.stanford.edu/)。在relbench中，我们必须做的第一件事是指定我们关系数据库的模式。下面是我们如何为数据库中的“transactions”表指定模式的一个示例。我们将表格作为pandas数据框传递，并指定主键和时间戳列。主键列用于唯一标识实体。时间戳确保当我们想要预测未来的交易时，我们只能从过去的交易中学习。在图中，这意味着信息只能从时间戳较低（即过去）的节点流向时间戳较高的节点。此外，我们还指定了关系中存在的外键。在本例中，“transactions”表有一列“customer_key”，它是一个指向“customer_dim”表的外键。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The rest of the tables need to be defined in the same way. Note that this could
    also be automated if you already have a database schema. Since the dataset is
    from Kaggle, I needed to create the schema manually. We also need to convert the
    date columns to actual pandas datetime objects and remove any NaN values.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的表格需要以相同的方式进行定义。请注意，如果你已经有了数据库模式，这个过程也可以自动化。由于数据集来自Kaggle，我需要手动创建模式。我们还需要将日期列转换为实际的pandas日期时间对象，并去除任何NaN值。
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Crucially, the authors introduce the idea of a training table. This training
    table essentially defines the ML task. The idea here is that we want to predict
    the future state (i.e. a future value) of some entity in the database. We do this
    by specifying a table where each row has a timestamp, the identifier of the entity,
    and some value we want to predict. The id serves to specify the entity, the timestamp
    specifies at which point in time we need to predict the entity. This will also
    limit the data that can be used to infer the value of this entity (i.e. only past
    data). The value itself is what we want to predict (i.e. ground truth).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 至关重要的是，作者引入了训练表的概念。这个训练表本质上定义了机器学习任务。这里的思路是，我们希望预测数据库中某个实体的未来状态（即未来的值）。我们通过指定一个表来实现这一点，该表中的每一行都有一个时间戳、实体的标识符和我们希望预测的某些值。id
    用于指定实体，时间戳则指定我们需要预测该实体的时间点。这也将限制可用于推断该实体值的数据（即仅限过去的数据）。值本身就是我们想要预测的内容（即真实值）。
- en: In our case, we have an online platform with customers. We want to predict a
    customer’s revenue in the next 30 days. We can create the training table with
    a SQL statement executed with DuckDB. This is the big advantage of RDL as we could
    create any kind of ML task with just SQL. For example, we can define a query to
    select the number of purchases of buyers in the next 30 days to make a churn prediction.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们有一个在线平台和顾客。我们想要预测顾客在接下来的30天内的收入。我们可以通过执行DuckDB的SQL语句来创建训练表。这就是RDL的巨大优势，因为我们可以仅通过SQL创建任何类型的机器学习任务。例如，我们可以定义一个查询来选择买家在接下来的30天内的购买次数，从而做出客户流失预测。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The result will be a table that has the seller_id as the key of the entity that
    we want to predict, the revenue as the target, and the timestamp as the time at
    which we need to make the prediction (i.e. we can only use data up until this
    point to make the prediction).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是一个表格，其中卖家ID作为我们要预测的实体的键，收入作为目标，时间戳作为我们需要进行预测的时间（即我们只能使用直到这个时间点的数据来进行预测）。
- en: '![](../Images/249add07383580218f2c4e9e3b3cf33d.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/249add07383580218f2c4e9e3b3cf33d.png)'
- en: Training Table; Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 训练表格；图片来源：作者
- en: Below is the complete code for creating the ‘customer_revenue’ task.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建“customer_revenue”任务的完整代码。
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With that, we have done the bulk of the work. The rest of the workflow will
    be similar, independent of the ML task. I was able to copy most of the code from
    the [example notebook](https://github.com/snap-stanford/relbench/blob/main/tutorials/train_model.ipynb)
    that relbench provides.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经完成了大部分工作。剩下的工作流程将是类似的，独立于ML任务。我能够从[示例笔记本](https://github.com/snap-stanford/relbench/blob/main/tutorials/train_model.ipynb)中复制大部分代码，这些代码是relbench提供的。
- en: For example, we need to encode the node features. Here, we can use glove embeddings
    to encode all the text features such as the product descriptions and the product
    names.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们需要对节点特征进行编码。在这里，我们可以使用GloVe嵌入来编码所有文本特征，如产品描述和产品名称。
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After that, we can apply those transformations to our data and build out the
    graph.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以将这些转换应用于我们的数据，并构建出图。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The rest of the code will be building the GNN from standard layers, coding the
    training loop, and doing some evaluations. I will leave this code out of this
    blog post for brevity since it is very standard and will be the same across tasks.
    You can check out the notebook [here](https://github.com/LaurinBrechter/GraphTheory/tree/main/rdl).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的代码将是从标准层构建GNN、编写训练循环以及进行一些评估。我会将这些代码省略在这篇博客中，因为它非常标准且在任务之间相同。你可以在[这里](https://github.com/LaurinBrechter/GraphTheory/tree/main/rdl)查看该笔记本。
- en: '![](../Images/885dfaed5f9ea9705ffb86ecb8d1fca9.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/885dfaed5f9ea9705ffb86ecb8d1fca9.png)'
- en: Result of Training, Image by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结果，图片来源：作者
- en: As a result, we can train this GNN to reach an r2 of around 0.3 and an MAE of
    500\. This means that it predicts the seller’s revenue in the next 30 days with
    an average error of +- $500\. Of course, we can’t know if this is good or not,
    maybe we could have gotten an r2 of 80% with a combination of classical ML and
    feature engineering.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以训练这个GNN，使其达到大约0.3的r2和500的MAE。这意味着它预测卖家未来30天的收入时，平均误差为+-$500。当然，我们无法知道这是否算好，可能通过结合经典ML和特征工程，我们能够获得80%的r2。
- en: Conclusion
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Relational Deep Learning is an interesting new approach to ML especially when
    we have a complex relational schema where manual feature engineering would be
    too laborious. It gives us the ability to define an ML task with just SQL which
    can be especially useful for individuals that are not deep into data science but
    know some SQL. This also means that we can iterate quickly and experiment a lot
    with different tasks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 关系深度学习是一种有趣的新型ML方法，特别是在我们拥有复杂的关系模式时，人工特征工程会显得过于繁琐。它使我们能够仅通过SQL定义ML任务，这对于那些没有深入数据科学背景但懂一些SQL的人尤其有用。这也意味着我们可以快速迭代并进行大量不同任务的实验。
- en: At the same time, this approach presents its own problems such as the difficulty
    of training GNNs and constructing the graph from the relational schema. Additionally,
    the question is to what extent RDL can compete in terms of performance with classical
    ML models. In the past, we have seen that models such as XGboost have proven to
    be better than neural networks on tabular prediction problems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，这种方法也存在一些问题，例如训练GNN的难度和从关系模式构建图的复杂性。此外，问题在于RDL在性能上能否与经典的ML模型竞争。过去，我们已经看到像XGBoost这样的模型在表格预测问题上比神经网络更优。
- en: References
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Robinson, Joshua, et al. “RelBench: A Benchmark for Deep Learning on Relational
    Databases.” *arXiv*, 2024, [https://arxiv.org/abs/2407.20060](https://arxiv.org/abs/2407.20060).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Robinson, Joshua, 等. “RelBench: A Benchmark for Deep Learning on Relational
    Databases.” *arXiv*, 2024, [https://arxiv.org/abs/2407.20060](https://arxiv.org/abs/2407.20060)。'
- en: '[2] Fey, Matthias, et al. “Relational deep learning: Graph representation learning
    on relational databases.” *arXiv preprint arXiv:2312.04615* (2023).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Fey, Matthias, 等. “Relational deep learning: Graph representation learning
    on relational databases.” *arXiv预印本 arXiv:2312.04615* (2023)。'
- en: '[3] Schlichtkrull, Michael, et al. “Modeling relational data with graph convolutional
    networks.” *The semantic web: 15th international conference, ESWC 2018, Heraklion,
    Crete, Greece, June 3–7, 2018, proceedings 15*. Springer International Publishing,
    2018.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Schlichtkrull, Michael, 等. “使用图卷积网络对关系数据建模。” *语义网：第十五届国际会议，ESWC 2018，希腊克里特岛赫拉克利翁，2018年6月3日至7日，会议录
    15*. 施普林格国际出版社，2018年。'
