- en: 'Random Forest, Explained: A Visual Guide with Code Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—è§£æï¼šå¸¦æœ‰ä»£ç ç¤ºä¾‹çš„è§†è§‰æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07](https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07](https://towardsdatascience.com/random-forest-explained-a-visual-guide-with-code-examples-9f736a6e1b3c?source=collection_archive---------0-----------------------#2024-11-07)
- en: ENSEMBLE LEARNING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆå­¦ä¹ 
- en: Making tree-mendous predictions with random trees
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨éšæœºæ ‘åšå‡ºæƒŠäººçš„é¢„æµ‹
- en: '[](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Samy
    Baladram](../Images/715cb7af97c57601966c5d2f9edd0066.png)](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    [Samy Baladram](https://medium.com/@samybaladram?source=post_page---byline--9f736a6e1b3c--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    Â·12 min readÂ·Nov 7, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--9f736a6e1b3c--------------------------------)
    Â·é˜…è¯»æ—¶é—´12åˆ†é’ŸÂ·2024å¹´11æœˆ7æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
    [## Decision Tree Classifier, Explained: A Visual Guide with Code Examples for
    Beginners'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
    [## å†³ç­–æ ‘åˆ†ç±»å™¨è§£æï¼šå¸¦æœ‰ä»£ç ç¤ºä¾‹çš„åˆå­¦è€…è§†è§‰æŒ‡å—'
- en: A fresh look on our favorite upside-down tree
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»å…¨æ–°çš„è§’åº¦çœ‹æˆ‘ä»¬æœ€å–œçˆ±çš„å€’ç«‹æ ‘
- en: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e?source=post_page-----9f736a6e1b3c--------------------------------)
- en: '[Decision trees](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)
    are a great starting point in machine learning â€” theyâ€™re clear and make sense.
    But thereâ€™s a catch: they often donâ€™t work well when dealing with new data. The
    predictions can be inconsistent and unreliable, which is a real problem when youâ€™re
    trying to build something useful.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[å†³ç­–æ ‘](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹â€”â€”å®ƒä»¬ç›´è§‚ä¸”æ˜“äºç†è§£ã€‚ä½†æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå®ƒä»¬åœ¨å¤„ç†æ–°æ•°æ®æ—¶å¾€å¾€æ•ˆæœä¸å¥½ã€‚é¢„æµ‹ç»“æœå¯èƒ½ä¸ç¨³å®šä¸”ä¸å¯é ï¼Œè¿™åœ¨ä½ è¯•å›¾æ„å»ºæœ‰ç”¨çš„ä¸œè¥¿æ—¶æ˜¯ä¸€ä¸ªçœŸæ­£çš„é—®é¢˜ã€‚'
- en: This is where Random Forest comes in. It takes whatâ€™s good about decision trees
    and makes them work better by combining multiple trees together. Itâ€™s become a
    favorite tool for many data scientists because itâ€™s both effective and practical.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ—¶ï¼Œéšæœºæ£®æ—å°±æ´¾ä¸Šç”¨åœºäº†ã€‚å®ƒç»“åˆäº†å†³ç­–æ ‘çš„ä¼˜ç‚¹ï¼Œå¹¶é€šè¿‡å°†å¤šæ£µæ ‘ç»“åˆåœ¨ä¸€èµ·ï¼Œä½¿å®ƒä»¬çš„æ•ˆæœæ›´å¥½ã€‚å®ƒå·²ç»æˆä¸ºè®¸å¤šæ•°æ®ç§‘å­¦å®¶æœ€å–œçˆ±çš„å·¥å…·ï¼Œå› ä¸ºå®ƒæ—¢æœ‰æ•ˆåˆå®ç”¨ã€‚
- en: Letâ€™s see how Random Forest works and why it might be exactly what you need
    for your next project. Itâ€™s time to stop getting lost in the trees and see the
    forest for what it really is â€” your next reliable tool in machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹çœ‹éšæœºæ£®æ—æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆå¯èƒ½æ­£æ˜¯ä½ ä¸‹ä¸€ä¸ªé¡¹ç›®æ‰€éœ€è¦çš„ã€‚æ˜¯æ—¶å€™ä¸å†è¿·å¤±åœ¨æ ‘æœ¨ä¸­ï¼ŒçœŸæ­£çœ‹åˆ°æ£®æ—çš„å…¨è²Œâ€”â€”ä½ ä¸‹ä¸€ä¸ªå¯é çš„æœºå™¨å­¦ä¹ å·¥å…·ã€‚
- en: '![](../Images/a46fad3053f42f475b5f070c27b60998.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a46fad3053f42f475b5f070c27b60998.png)'
- en: 'All visuals: Author-created using Canva Pro. Optimized for mobile; may appear
    oversized on desktop.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å›¾åƒï¼šä½œè€…ä½¿ç”¨Canva Proåˆ›å»ºã€‚ä¼˜åŒ–äº†ç§»åŠ¨è®¾å¤‡æ˜¾ç¤ºï¼›åœ¨æ¡Œé¢è®¾å¤‡ä¸Šå¯èƒ½ä¼šæ˜¾å¾—è¿‡å¤§ã€‚
- en: Definition
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰
- en: A Random Forest is an ensemble machine learning model that combines multiple
    decision trees. Each tree in the forest is trained on a random sample of the data
    (bootstrap sampling) and considers only a random subset of features when making
    splits (feature randomization).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—æ˜¯ä¸€ç§é›†æˆæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒç»“åˆäº†å¤šä¸ªå†³ç­–æ ‘ã€‚æ£®æ—ä¸­çš„æ¯ä¸€æ£µæ ‘éƒ½åœ¨æ•°æ®çš„éšæœºæ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼ˆè‡ªåŠ©é‡‡æ ·ï¼‰ï¼Œå¹¶ä¸”åœ¨åšå‡ºåˆ†è£‚æ—¶ä»…è€ƒè™‘ç‰¹å¾çš„éšæœºå­é›†ï¼ˆç‰¹å¾éšæœºåŒ–ï¼‰ã€‚
- en: For classification tasks, the forest predicts by majority voting among trees,
    while for regression tasks, it averages the predictions. The modelâ€™s strength
    comes from its â€œwisdom of crowdsâ€ approach â€” while individual trees might make
    errors, the collective decision-making process **tends to average out these mistakes**
    and arrive at more reliable predictions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œæ£®æ—é€šè¿‡æ ‘ä¹‹é—´çš„å¤šæ•°æŠ•ç¥¨æ¥è¿›è¡Œé¢„æµ‹ï¼›è€Œå¯¹äºå›å½’ä»»åŠ¡ï¼Œå®ƒé€šè¿‡å¹³å‡å„æ£µæ ‘çš„é¢„æµ‹ç»“æœæ¥è¿›è¡Œé¢„æµ‹ã€‚è¯¥æ¨¡å‹çš„ä¼˜åŠ¿æ¥è‡ªäºå®ƒçš„â€œé›†ä½“æ™ºæ…§â€æ–¹æ³•â€”â€”è™½ç„¶å•æ£µæ ‘å¯èƒ½ä¼šçŠ¯é”™ï¼Œä½†é›†ä½“å†³ç­–è¿‡ç¨‹**å¾€å¾€èƒ½å°†è¿™äº›é”™è¯¯å¹³å‡åŒ–**ï¼Œä»è€Œå¾—å‡ºæ›´å¯é çš„é¢„æµ‹ç»“æœã€‚
- en: '![](../Images/a7c8ea0333ddfcdeb2779b785e896929.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7c8ea0333ddfcdeb2779b785e896929.png)'
- en: Random Forest is a part of bagging (bootstrap aggregating) algorithm because
    it builds each tree using different random part of data and combines their answers
    together.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—æ˜¯è¢‹è£…ï¼ˆè‡ªåŠ©èšåˆï¼‰ç®—æ³•çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä½¿ç”¨æ•°æ®çš„ä¸åŒéšæœºéƒ¨åˆ†æ¥æ„å»ºæ¯æ£µæ ‘ï¼Œå¹¶å°†å®ƒä»¬çš„ç»“æœç»“åˆèµ·æ¥ã€‚
- en: Dataset Used
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çš„æ•°æ®é›†
- en: Throughout this article, weâ€™ll focus on the classic golf dataset as an example
    for classification. While Random Forests can handle both classification and regression
    tasks equally well, weâ€™ll concentrate on the classification part â€” predicting
    whether someone will play golf based on weather conditions. The concepts weâ€™ll
    explore can be easily adapted to regression problems (like predicting number of
    player) using the same principles.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥ç»å…¸çš„é«˜å°”å¤«æ•°æ®é›†ä¸ºåˆ†ç±»ä»»åŠ¡çš„ä¾‹å­è¿›è¡Œè®²è§£ã€‚è™½ç„¶éšæœºæ£®æ—æ—¢å¯ä»¥å¤„ç†åˆ†ç±»ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥å¤„ç†å›å½’ä»»åŠ¡ï¼Œä½†æˆ‘ä»¬å°†é›†ä¸­è®¨è®ºåˆ†ç±»éƒ¨åˆ†â€”â€”æ ¹æ®å¤©æ°”æ¡ä»¶é¢„æµ‹æŸäººæ˜¯å¦ä¼šæ‰“é«˜å°”å¤«ã€‚æˆ‘ä»¬æ¢è®¨çš„æ¦‚å¿µä¹Ÿå¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå›å½’é—®é¢˜ï¼ˆä¾‹å¦‚é¢„æµ‹çƒå‘˜æ•°é‡ï¼‰ï¼Œä½¿ç”¨ç›¸åŒçš„åŸç†ã€‚
- en: '![](../Images/05586d1dcea17f8a18206b58019181ea.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05586d1dcea17f8a18206b58019181ea.png)'
- en: 'Columns: â€˜Overcast (one-hot-encoded into 3 columns)â€™, â€™Temperatureâ€™ (in Fahrenheit),
    â€˜Humidityâ€™ (in %), â€˜Windyâ€™ (Yes/No) and â€˜Playâ€™ (Yes/No, target feature)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—ï¼šâ€˜Overcastï¼ˆè¢«ä¸€çƒ­ç¼–ç æˆ3åˆ—ï¼‰â€™ï¼Œâ€™Temperatureï¼ˆåæ°æ¸©åº¦ï¼‰â€™ï¼Œâ€˜Humidityï¼ˆæ¹¿åº¦ï¼Œ%ï¼‰â€™ï¼Œâ€˜Windyï¼ˆæ˜¯å¦æœ‰é£ï¼ŒYes/Noï¼‰â€™å’Œâ€˜Playï¼ˆæ˜¯å¦æ‰“çƒï¼ŒYes/Noï¼Œç›®æ ‡ç‰¹å¾ï¼‰â€™
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Main Mechanism
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸»è¦æœºåˆ¶
- en: 'Hereâ€™s how Random Forest works:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯éšæœºæ£®æ—çš„å·¥ä½œåŸç†ï¼š
- en: '**Bootstrap Sampling:** Each tree gets its own unique training set, created
    by randomly sampling from the original data with replacement. This means some
    data points may appear multiple times while others arenâ€™t used.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è‡ªåŠ©é‡‡æ ·ï¼ˆBootstrap Samplingï¼‰ï¼š** æ¯æ£µæ ‘éƒ½æœ‰è‡ªå·±çš„ç‹¬ç‰¹è®­ç»ƒé›†ï¼Œè¿™äº›è®­ç»ƒé›†æ˜¯é€šè¿‡ä»åŸå§‹æ•°æ®ä¸­éšæœºæŠ½æ ·å¹¶å…è®¸é‡å¤æŠ½å–å¾—åˆ°çš„ã€‚è¿™æ„å‘³ç€ä¸€äº›æ•°æ®ç‚¹å¯èƒ½ä¼šå‡ºç°å¤šæ¬¡ï¼Œè€Œå…¶ä»–æ•°æ®ç‚¹åˆ™æœªè¢«ä½¿ç”¨ã€‚'
- en: '**Random Feature Selection:** When making a split, each tree only considers
    a random subset of features (typically square root of total features).'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éšæœºç‰¹å¾é€‰æ‹©ï¼š** åœ¨è¿›è¡Œåˆ†è£‚æ—¶ï¼Œæ¯æ£µæ ‘åªè€ƒè™‘ä¸€ä¸ªéšæœºçš„ç‰¹å¾å­é›†ï¼ˆé€šå¸¸æ˜¯æ€»ç‰¹å¾æ•°çš„å¹³æ–¹æ ¹ï¼‰ã€‚'
- en: '**Growing Trees:** Each tree grows using only its bootstrap sample and selected
    features, making splits until it reaches a stopping point (like pure groups or
    minimum sample size).'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç”Ÿé•¿æ ‘æœ¨ï¼š** æ¯æ£µæ ‘ä»…ä½¿ç”¨å…¶è‡ªåŠ©æ ·æœ¬å’Œé€‰å®šçš„ç‰¹å¾è¿›è¡Œç”Ÿé•¿ï¼Œè¿›è¡Œåˆ†è£‚ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢ç‚¹ï¼ˆå¦‚çº¯å‡€ç»„æˆ–æœ€å°æ ·æœ¬é‡ï¼‰ã€‚'
- en: '**Final Prediction:** All trees vote together for the final prediction. For
    classification, take the majority vote of class predictions; for regression, average
    the predicted values from all trees.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœ€ç»ˆé¢„æµ‹ï¼š** æ‰€æœ‰æ ‘ä¸€èµ·æŠ•ç¥¨å†³å®šæœ€ç»ˆçš„é¢„æµ‹ç»“æœã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œé‡‡ç”¨ç±»åˆ«é¢„æµ‹çš„å¤šæ•°æŠ•ç¥¨ï¼›å¯¹äºå›å½’ä»»åŠ¡ï¼Œè®¡ç®—æ‰€æœ‰æ ‘çš„é¢„æµ‹å€¼çš„å¹³å‡å€¼ã€‚'
- en: '![](../Images/3e815426c28ac98519c4884d12f43fac.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e815426c28ac98519c4884d12f43fac.png)'
- en: A Random Forest Classifier makes predictions by combining results from 100 different
    decision trees, each analyzing features like temperature and outlook conditions.
    The final prediction comes from the most common answer among all trees.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—åˆ†ç±»å™¨é€šè¿‡ç»“åˆæ¥è‡ª100æ£µä¸åŒå†³ç­–æ ‘çš„ç»“æœæ¥è¿›è¡Œé¢„æµ‹ï¼Œæ¯æ£µæ ‘åˆ†æçš„ç‰¹å¾åŒ…æ‹¬æ¸©åº¦å’Œå¤©æ°”æ¡ä»¶ã€‚æœ€ç»ˆçš„é¢„æµ‹æ¥è‡ªæ‰€æœ‰æ ‘ä¸­æœ€å¸¸è§çš„ç­”æ¡ˆã€‚
- en: Training Steps
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®­ç»ƒæ­¥éª¤
- en: 'The Random Forest algorithm constructs multiple decision trees and combines
    them. Hereâ€™s how it works:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—ç®—æ³•æ„å»ºå¤šä¸ªå†³ç­–æ ‘å¹¶å°†å®ƒä»¬ç»“åˆèµ·æ¥ã€‚å…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š
- en: '**Step 1: Bootstrap Sample Creation**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤1ï¼šè‡ªåŠ©æ ·æœ¬åˆ›å»º**'
- en: 1.0\. Set the number of trees (default = 100)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 1.0\. è®¾ç½®æ ‘çš„æ•°é‡ï¼ˆé»˜è®¤ = 100ï¼‰
- en: '1.1\. For each tree in the forest:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1\. å¯¹äºæ£®æ—ä¸­çš„æ¯ä¸€æ£µæ ‘ï¼š
- en: a. Create new training set by random sampling original data with replacement
    until reaching original dataset size. This is called **bootstrap sampling**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: a. é€šè¿‡ä»åŸå§‹æ•°æ®ä¸­è¿›è¡ŒéšæœºæŠ½æ ·å¹¶å…è®¸é‡å¤æŠ½å–ï¼Œç›´åˆ°è¾¾åˆ°åŸå§‹æ•°æ®é›†çš„å¤§å°ã€‚è¿™è¢«ç§°ä¸º**è‡ªåŠ©é‡‡æ ·**ã€‚
- en: b. Mark and set aside non-selected samples as out-of-bag (OOB) samples for later
    error estimation
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: b. æ ‡è®°å¹¶å°†æœªé€‰ä¸­çš„æ ·æœ¬ä½œä¸ºè¢‹å¤–ï¼ˆOOBï¼‰æ ·æœ¬ä¿ç•™ï¼Œä»¥ä¾¿åç»­è¿›è¡Œè¯¯å·®ä¼°ç®—
- en: '![](../Images/1671fe794bccb45ec5a642740a8d0d8f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1671fe794bccb45ec5a642740a8d0d8f.png)'
- en: Random Forest creates different training sets for each tree by randomly picking
    data points from the original training set, with some numbers appearing multiple
    times. The unused data points become test sets for checking each treeâ€™s performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—é€šè¿‡ä»åŸå§‹è®­ç»ƒé›†ä¸­éšæœºé€‰æ‹©æ•°æ®ç‚¹ä¸ºæ¯æ£µæ ‘åˆ›å»ºä¸åŒçš„è®­ç»ƒé›†ï¼ŒæŸäº›æ•°æ®ç‚¹å¯èƒ½ä¼šè¢«å¤šæ¬¡é€‰æ‹©ã€‚æœªä½¿ç”¨çš„æ•°æ®ç‚¹åˆ™æˆä¸ºæµ‹è¯•é›†ï¼Œç”¨äºæ£€æŸ¥æ¯æ£µæ ‘çš„æ€§èƒ½ã€‚
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/fd0d49cc5d9614e8b4d96dedd10a6ca2.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd0d49cc5d9614e8b4d96dedd10a6ca2.png)'
- en: Notice how similar the percentages of OOB above? When doing bootstrap sampling
    of *n* samples, each individual sample has about a 37% chance of never being picked.
    This comes from the probability calculation (1â€“1/*n*)*â¿*, which approaches 1/e
    â‰ˆ 0.368 as *n* gets larger. Thatâ€™s why each tree ends up using roughly 63% of
    the data for training, with the remaining 37% becoming OOB samples.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼ŒOOBçš„ç™¾åˆ†æ¯”æ˜¯å¤šä¹ˆç›¸ä¼¼ï¼Ÿåœ¨è¿›è¡Œ*n*æ ·æœ¬çš„è‡ªåŠ©æ³•æŠ½æ ·æ—¶ï¼Œæ¯ä¸ªæ ·æœ¬å¤§çº¦æœ‰37%çš„æœºä¼šæ°¸è¿œä¸ä¼šè¢«é€‰æ‹©ã€‚è¿™æ¥è‡ªäºæ¦‚ç‡è®¡ç®—ï¼ˆ1â€“1/*n*)*â¿*ï¼Œéšç€*n*çš„å¢å¤§ï¼Œå®ƒæ¥è¿‘1/e
    â‰ˆ 0.368ã€‚å› æ­¤ï¼Œæ¯æ£µæ ‘æœ€ç»ˆä½¿ç”¨çº¦63%çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå…¶ä½™çš„37%æˆä¸ºOOBæ ·æœ¬ã€‚
- en: '**Step 2: Tree Construction**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤2ï¼šæ ‘çš„æ„å»º**'
- en: 2.1\. Start at root node with complete bootstrap sample
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 2.1. ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œä½¿ç”¨å®Œæ•´çš„è‡ªåŠ©æ³•æ ·æœ¬
- en: '![](../Images/58dd94d352eb90afbfe2312662b55270.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58dd94d352eb90afbfe2312662b55270.png)'
- en: When building each decision tree, Random Forest considers a subset of data points
    and creates splits based on questions about their values â€” sending smaller values
    to the left and larger values to the right to make predictions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„å»ºæ¯æ£µå†³ç­–æ ‘æ—¶ï¼Œéšæœºæ£®æ—ä¼šè€ƒè™‘æ•°æ®ç‚¹çš„å­é›†ï¼Œå¹¶åŸºäºè¿™äº›æ•°æ®ç‚¹çš„å€¼æå‡ºåˆ†å‰²é—®é¢˜â€”â€”å°†è¾ƒå°çš„å€¼åˆ†é…åˆ°å·¦ä¾§ï¼Œå°†è¾ƒå¤§çš„å€¼åˆ†é…åˆ°å³ä¾§è¿›è¡Œé¢„æµ‹ã€‚
- en: a. Calculate initial node impurity using all samples in node
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: a. ä½¿ç”¨èŠ‚ç‚¹ä¸­çš„æ‰€æœ‰æ ·æœ¬è®¡ç®—åˆå§‹èŠ‚ç‚¹æ‚è´¨
- en: 'Â· Classification: Gini or entropy'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åˆ†ç±»ï¼šåŸºå°¼æŒ‡æ•°æˆ–ç†µ
- en: 'Â· Regression: MSE'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Â· å›å½’ï¼šå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
- en: '![](../Images/49ffa6509e2a0b7efc710bf7c8891e58.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49ffa6509e2a0b7efc710bf7c8891e58.png)'
- en: Random Forest starts by calculating the Gini Impurity of the entire dataset
    (before any splits) using the ratio of YES and NO labels â€” a measure of how mixed
    the labels are in the current data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—é¦–å…ˆè®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„åŸºå°¼æ‚è´¨ï¼ˆåœ¨ä»»ä½•åˆ†å‰²ä¹‹å‰ï¼‰ï¼Œä½¿ç”¨YESå’ŒNOæ ‡ç­¾çš„æ¯”ä¾‹â€”â€”è¿™æ˜¯ä¸€ç§è¡¡é‡å½“å‰æ•°æ®ä¸­æ ‡ç­¾æ··åˆç¨‹åº¦çš„æŒ‡æ ‡ã€‚
- en: 'b. Select random subset of features from total available features:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: b. ä»æ€»å¯ç”¨ç‰¹å¾ä¸­é€‰æ‹©éšæœºå­é›†ï¼š
- en: 'Â· Classification: âˆšn_features'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Â· åˆ†ç±»ï¼šâˆšn_features
- en: 'Â· Regression: n_features/3'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Â· å›å½’ï¼šn_features/3
- en: '![](../Images/71393bd15609a6d43354efe5d9f06ac3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71393bd15609a6d43354efe5d9f06ac3.png)'
- en: For each split in a tree, Random Forest randomly picks a subset of weather features
    (here 2 out of 6) to consider, making each tree focus on different aspects of
    the data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ ‘ä¸­çš„æ¯æ¬¡åˆ†å‰²ï¼Œéšæœºæ£®æ—ä¼šéšæœºé€‰æ‹©ä¸€ä¸ªå¤©æ°”ç‰¹å¾çš„å­é›†ï¼ˆè¿™é‡Œæ˜¯ä»6ä¸ªç‰¹å¾ä¸­é€‰æ‹©2ä¸ªï¼‰æ¥è¿›è¡Œè€ƒè™‘ï¼Œä»è€Œä½¿æ¯æ£µæ ‘å…³æ³¨æ•°æ®çš„ä¸åŒæ–¹é¢ã€‚
- en: 'c. For each selected feature:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: c. å¯¹æ¯ä¸ªé€‰å®šçš„ç‰¹å¾ï¼š
- en: Â· Sort data points by feature values
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Â· æŒ‰ç‰¹å¾å€¼å¯¹æ•°æ®ç‚¹è¿›è¡Œæ’åº
- en: Â· Identify potential split points (midpoints between consecutive unique feature
    values)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ç¡®å®šæ½œåœ¨çš„åˆ†å‰²ç‚¹ï¼ˆè¿ç»­å”¯ä¸€ç‰¹å¾å€¼ä¹‹é—´çš„ä¸­ç‚¹ï¼‰
- en: '![](../Images/31b2530c2f2eab495683e971a5cc88da.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31b2530c2f2eab495683e971a5cc88da.png)'
- en: For each chosen feature, Random Forest looks at all possible split points in
    the sorted data (like temperature values 66.0, 69.0, 71.0, etc.) to find the best
    way to separate the data into two groups.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªé€‰å®šçš„ç‰¹å¾ï¼Œéšæœºæ£®æ—ä¼šæŸ¥çœ‹æ’åºåçš„æ•°æ®ä¸­æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²ç‚¹ï¼ˆå¦‚æ¸©åº¦å€¼66.0ã€69.0ã€71.0ç­‰ï¼‰ï¼Œä»¥æ‰¾å‡ºæœ€ä½³çš„æ–¹å¼å°†æ•°æ®åˆ†ä¸ºä¸¤ç»„ã€‚
- en: 'd. For each potential split point:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: d. å¯¹æ¯ä¸ªæ½œåœ¨çš„åˆ†å‰²ç‚¹ï¼š
- en: Â· Divide samples into left and right groups
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Â· å°†æ ·æœ¬åˆ†ä¸ºå·¦å³ä¸¤ç»„
- en: Â· Calculate left child impurity using its samples
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ä½¿ç”¨å…¶æ ·æœ¬è®¡ç®—å·¦å­èŠ‚ç‚¹çš„æ‚è´¨
- en: Â· Calculate right child impurity using its samples
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Â· ä½¿ç”¨å…¶æ ·æœ¬è®¡ç®—å³å­èŠ‚ç‚¹çš„æ‚è´¨
- en: 'Â· Calculate impurity reduction:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Â· è®¡ç®—æ‚è´¨å‡å°‘ï¼š
- en: parent_impurity â€” (left_weight Ã— left_impurity + right_weight Ã— right_impurity)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: parent_impurity â€” (left_weight Ã— left_impurity + right_weight Ã— right_impurity)
- en: '![](../Images/3a76a1bc476cd60a143540debd4b04b3.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a76a1bc476cd60a143540debd4b04b3.png)'
- en: To find the best split point, Random Forest calculates Gini Impurity for each
    possible split, takes a weighted average based on group sizes, and picks the split
    that gives the biggest reduction in impurity from the parent node.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹ï¼Œéšæœºæ£®æ—ä¼šè®¡ç®—æ¯ä¸ªå¯èƒ½åˆ†å‰²ç‚¹çš„åŸºå°¼æ‚è´¨ï¼ŒåŸºäºç»„çš„å¤§å°è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå¹¶é€‰æ‹©é‚£ä¸ªèƒ½æœ€å¤§ç¨‹åº¦å‡å°‘çˆ¶èŠ‚ç‚¹æ‚è´¨çš„åˆ†å‰²ç‚¹ã€‚
- en: e. Split the current node data using the feature and split point that gives
    the highest impurity reduction. Then pass data points to the respective child
    nodes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: e. ä½¿ç”¨æä¾›æœ€å¤§çº¯åº¦å‡å°‘çš„ç‰¹å¾å’Œåˆ†å‰²ç‚¹æ¥åˆ†å‰²å½“å‰èŠ‚ç‚¹çš„æ•°æ®ã€‚ç„¶åå°†æ•°æ®ç‚¹ä¼ é€’ç»™å„è‡ªçš„å­èŠ‚ç‚¹ã€‚
- en: '![](../Images/e71e8da4672712136d3478ad9d1cd59b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e71e8da4672712136d3478ad9d1cd59b.png)'
- en: 'After comparing all possible splits, Random Forest picks the temperature threshold
    of 73.5Â°F as it gives the largest impurity reduction (0.041), creating two groups:
    one mixed group with temperatures below 73.5Â°F and one pure group.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯”è¾ƒæ‰€æœ‰å¯èƒ½çš„åˆ†å‰²åï¼Œéšæœºæ£®æ—é€‰æ‹©73.5Â°Fçš„æ¸©åº¦é˜ˆå€¼ï¼Œå› ä¸ºå®ƒæä¾›äº†æœ€å¤§çš„çº¯åº¦å‡å°‘ï¼ˆ0.041ï¼‰ï¼Œå¹¶åˆ›å»ºäº†ä¸¤ä¸ªåˆ†ç»„ï¼šä¸€ä¸ªæ˜¯ä½äº73.5Â°Fçš„æ··åˆç»„ï¼Œå¦ä¸€ä¸ªæ˜¯çº¯å‡€ç»„ã€‚
- en: 'f. For each child node, repeat the process (step b-e) until:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: f. å¯¹æ¯ä¸ªå­èŠ‚ç‚¹ï¼Œé‡å¤è¿‡ç¨‹ï¼ˆæ­¥éª¤b-eï¼‰ï¼Œç›´åˆ°ï¼š
- en: '- Pure node or minimum impurity decrease'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '- çº¯èŠ‚ç‚¹æˆ–æœ€å°ä¸çº¯åº¦å‡å°‘'
- en: '- Minimum samples threshold'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '- æœ€å°æ ·æœ¬æ•°é˜ˆå€¼'
- en: '- Maximum depth'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '- æœ€å¤§æ·±åº¦'
- en: '- Maximum leaf nodes'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '- æœ€å¤§å¶å­èŠ‚ç‚¹æ•°'
- en: '![](../Images/8e9f1677218a52ede01934cdc731077e.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e9f1677218a52ede01934cdc731077e.png)'
- en: 'This process continues for each new group (node): randomly select features,
    find the best split point, and divide the data further until each group is pure
    (all YES or all NO) or canâ€™t be split anymore.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¿‡ç¨‹å¯¹æ¯ä¸ªæ–°çš„åˆ†ç»„ï¼ˆèŠ‚ç‚¹ï¼‰ç»§ç»­è¿›è¡Œï¼šéšæœºé€‰æ‹©ç‰¹å¾ï¼Œæ‰¾åˆ°æœ€ä½³çš„åˆ†å‰²ç‚¹ï¼Œå¹¶è¿›ä¸€æ­¥åˆ’åˆ†æ•°æ®ï¼Œç›´åˆ°æ¯ä¸ªåˆ†ç»„æ˜¯çº¯å‡€çš„ï¼ˆå…¨éƒ¨ä¸ºYESæˆ–å…¨éƒ¨ä¸ºNOï¼‰æˆ–æ— æ³•å†åˆ†å‰²ã€‚
- en: '**Step 3: Tree Construction** Repeat the whole Step 2 for other bootstrap samples.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤3ï¼šæ ‘æ„å»º** å¯¹å…¶ä»–è‡ªåŠ©æŠ½æ ·é‡å¤æ•´ä¸ªæ­¥éª¤2ã€‚'
- en: '![](../Images/5a6197d5a37f101b794221d1c2c3383d.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a6197d5a37f101b794221d1c2c3383d.png)'
- en: Each decision tree in the Random Forest splits data in different ways using
    different features and thresholds. This variety helps the forest make better predictions
    than any single tree.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—ä¸­çš„æ¯æ£µå†³ç­–æ ‘é€šè¿‡ä½¿ç”¨ä¸åŒçš„ç‰¹å¾å’Œé˜ˆå€¼ä»¥ä¸åŒçš„æ–¹å¼åˆ†å‰²æ•°æ®ã€‚è¿™ç§å¤šæ ·æ€§å¸®åŠ©æ£®æ—åšå‡ºæ¯”å•æ£µæ ‘æ›´å¥½çš„é¢„æµ‹ã€‚
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/b46220bdf49910aa49e1d13e353fe1fc.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b46220bdf49910aa49e1d13e353fe1fc.png)'
- en: Accessing the internal bootstrap indices directly isnâ€™t possible in the current
    scikit-learn implementation so this gives different trees than the one calculated
    in our previous example.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å‰çš„scikit-learnå®ç°ä¸­æ— æ³•ç›´æ¥è®¿é—®å†…éƒ¨çš„è‡ªåŠ©æŠ½æ ·ç´¢å¼•ï¼Œå› æ­¤ç”Ÿæˆçš„æ ‘ä¸æˆ‘ä»¬ä¹‹å‰ç¤ºä¾‹ä¸­è®¡ç®—çš„æ ‘ä¸åŒã€‚
- en: Testing Step
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æµ‹è¯•æ­¥éª¤
- en: 'For prediction, route new samples through all trees and aggregate:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºé¢„æµ‹ï¼Œé€šè¿‡æ‰€æœ‰æ ‘è·¯ç”±æ–°æ ·æœ¬å¹¶è¿›è¡Œæ±‡æ€»ï¼š
- en: '- Classification: majority vote'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '- åˆ†ç±»ï¼šå¤šæ•°æŠ•ç¥¨'
- en: '- Regression: mean prediction'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '- å›å½’ï¼šå¹³å‡é¢„æµ‹'
- en: '![](../Images/e8bd423acc3d8361e5ce82ec3fd542e4.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8bd423acc3d8361e5ce82ec3fd542e4.png)'
- en: When new data comes in, each tree in the Random Forest uses its own decision
    path to make a prediction. The forest combines all these predictions (74 YES vs
    26 NO) and the majority vote becomes the final answer (YES in this case).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ–°æ•°æ®è¿›å…¥æ—¶ï¼Œéšæœºæ£®æ—ä¸­çš„æ¯æ£µæ ‘ä½¿ç”¨è‡ªå·±çš„å†³ç­–è·¯å¾„è¿›è¡Œé¢„æµ‹ã€‚æ£®æ—ç»“åˆæ‰€æœ‰è¿™äº›é¢„æµ‹ï¼ˆ74ä¸ªYESä¸26ä¸ªNOï¼‰ï¼Œå¹¶é€šè¿‡å¤šæ•°æŠ•ç¥¨å¾—åˆ°æœ€ç»ˆç­”æ¡ˆï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯YESï¼‰ã€‚
- en: Out-of-Bag (OOB) Evaluation
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¢‹å¤–ï¼ˆOOBï¼‰è¯„ä¼°
- en: Remember those samples that didnâ€™t get used for training each tree â€” that leftover
    1/3? Those are your OOB samples. Instead of just ignoring them, Random Forest
    uses them as a convenient validation set for each tree.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½é‚£äº›æœªè¢«ç”¨äºè®­ç»ƒæ¯æ£µæ ‘çš„æ ·æœ¬â€”â€”é‚£å‰©ä¸‹çš„1/3ï¼Ÿå®ƒä»¬å°±æ˜¯ä½ çš„OOBæ ·æœ¬ã€‚éšæœºæ£®æ—ä¸ä»…ä»…æ˜¯å¿½ç•¥å®ƒä»¬ï¼Œè€Œæ˜¯å°†å®ƒä»¬ä½œä¸ºæ¯æ£µæ ‘çš„ä¾¿æ·éªŒè¯é›†ã€‚
- en: '![](../Images/afccd043882db9aba10d7e5fb93558e5.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afccd043882db9aba10d7e5fb93558e5.png)'
- en: Each tree gets tested on its own out-of-bag samples (data not used in its training).
    By averaging these individual OOB accuracy scores (50%, 66.6%, 60%), Random Forest
    provides a built-in way to measure performance without needing a separate test
    set.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯æ£µæ ‘éƒ½ä¼šåœ¨å…¶è‡ªå·±çš„è¢‹å¤–æ ·æœ¬ä¸Šè¿›è¡Œæµ‹è¯•ï¼ˆå³æœªç”¨äºè®­ç»ƒçš„æ•°æ®ï¼‰ã€‚é€šè¿‡å¹³å‡è¿™äº›å•ä¸ªçš„OOBå‡†ç¡®ç‡å¾—åˆ†ï¼ˆ50%ã€66.6%ã€60%ï¼‰ï¼Œéšæœºæ£®æ—æä¾›äº†ä¸€ç§å†…å»ºçš„æ–¹å¼æ¥æµ‹é‡æ€§èƒ½ï¼Œæ— éœ€å•ç‹¬çš„æµ‹è¯•é›†ã€‚
- en: Evaluation Step
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¯„ä¼°æ­¥éª¤
- en: After building all the trees, we can evaluate the test set.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºå®Œæ‰€æœ‰æ ‘åï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°æµ‹è¯•é›†ã€‚
- en: '![](../Images/55f4ae7dd4d6a6513400959cda5c3c12.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55f4ae7dd4d6a6513400959cda5c3c12.png)'
- en: By combining multiple diverse decision trees and using majority voting, Random
    Forest achieves a high accuracy of 85.7% â€” typically better than single decision
    trees or simpler models!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ç»“åˆå¤šä¸ªå¤šæ ·åŒ–çš„å†³ç­–æ ‘å¹¶ä½¿ç”¨å¤šæ•°æŠ•ç¥¨ï¼Œéšæœºæ£®æ—è¾¾åˆ°äº†85.7%çš„é«˜å‡†ç¡®ç‡â€”â€”é€šå¸¸æ¯”å•æ£µå†³ç­–æ ‘æˆ–æ›´ç®€å•çš„æ¨¡å‹è¡¨ç°æ›´å¥½ï¼
- en: Key Parameters
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³é”®å‚æ•°
- en: The key Random Forest parameters (especially in `scikit-learn`) include all
    Decision Tree parameters, plus some unique ones.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—çš„å…³é”®å‚æ•°ï¼ˆå°¤å…¶æ˜¯åœ¨`scikit-learn`ä¸­ï¼‰åŒ…æ‹¬æ‰€æœ‰å†³ç­–æ ‘å‚æ•°ï¼Œä»¥åŠä¸€äº›ç‹¬ç‰¹çš„å‚æ•°ã€‚
- en: Random Forest-specific parameters
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšæœºæ£®æ—ç‰¹å®šå‚æ•°
- en: '`oob_score` This uses leftover data (out-of-bag samples) to check how well
    the model works. This gives you a way to test your model without setting aside
    separate test data. Itâ€™s especially helpful with small datasets.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oob_score` è¿™ä¸ªå‚æ•°ä½¿ç”¨å‰©ä½™çš„æ•°æ®ï¼ˆè¢‹å¤–æ ·æœ¬ï¼‰æ¥æ£€æŸ¥æ¨¡å‹çš„è¡¨ç°ã€‚è¿™ä¸ºä½ æä¾›äº†ä¸€ç§ä¸éœ€è¦å•ç‹¬è®¾ç½®æµ‹è¯•æ•°æ®æ¥æµ‹è¯•æ¨¡å‹çš„æ–¹æ³•ï¼Œå°¤å…¶é€‚ç”¨äºå°æ•°æ®é›†ã€‚'
- en: '`n_estimators` This parameter controls how many trees to build (default is
    100).To find the optimal number of trees, **track the OOB error rate** as you
    add more trees to the forest. The error typically drops quickly at first, then
    levels off. **The point where it stabilizes suggests the optimal number** â€” adding
    more trees after this gives minimal improvement while increasing computation time.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators` è¿™ä¸ªå‚æ•°æ§åˆ¶è¦æ„å»ºå¤šå°‘æ£µæ ‘ï¼ˆé»˜è®¤å€¼æ˜¯100ï¼‰ã€‚ä¸ºäº†æ‰¾åˆ°æœ€ä½³çš„æ ‘æœ¨æ•°é‡ï¼Œ**åœ¨æ·»åŠ æ›´å¤šæ ‘æœ¨æ—¶è·Ÿè¸ªOOBè¯¯å·®ç‡**ã€‚è¯¯å·®é€šå¸¸ä¼šè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ã€‚**ç¨³å®šçš„ç‚¹å³æ˜¯æœ€ä½³æ ‘æœ¨æ•°é‡**â€”â€”åœ¨æ­¤ä¹‹åå¢åŠ æ›´å¤šæ ‘æœ¨åªä¼šå¸¦æ¥æœ€å°çš„æ”¹å–„ï¼ŒåŒæ—¶å¢åŠ è®¡ç®—æ—¶é—´ã€‚'
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/97234d73657a128e85e5409216f55df5.png)![](../Images/3d6b30f69790966d7d1dc81b1bed0c83.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97234d73657a128e85e5409216f55df5.png)![](../Images/3d6b30f69790966d7d1dc81b1bed0c83.png)'
- en: In our results, while around 27 trees showed the best score (0.2857), this early
    performance can be unreliable. Between 40â€“100 trees, the error rates settle around
    0.5000, showing more consistent results. Using more than 100 trees doesnâ€™t help
    and sometimes makes things worse. This suggests that using about 50â€“60 trees is
    a good choice â€” itâ€™s stable, efficient, and reliable.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ç»“æœä¸­ï¼Œå°½ç®¡å¤§çº¦27æ£µæ ‘æ˜¾ç¤ºå‡ºæœ€ä½³çš„å¾—åˆ†ï¼ˆ0.2857ï¼‰ï¼Œä½†è¿™ä¸ªæ—©æœŸè¡¨ç°å¯èƒ½ä¸å¤ªå¯é ã€‚åœ¨40åˆ°100æ£µæ ‘ä¹‹é—´ï¼Œè¯¯å·®ç‡å¤§çº¦ç¨³å®šåœ¨0.5000ï¼Œæ˜¾ç¤ºå‡ºæ›´ä¸€è‡´çš„ç»“æœã€‚è¶…è¿‡100æ£µæ ‘å¹¶æ²¡æœ‰å¸®åŠ©ï¼Œåè€Œæœ‰æ—¶ä¼šä½¿ç»“æœå˜å·®ã€‚è¿™è¡¨æ˜ï¼Œä½¿ç”¨å¤§çº¦50åˆ°60æ£µæ ‘æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©â€”â€”å®ƒæ—¢ç¨³å®šã€é«˜æ•ˆï¼Œåˆå¯é ã€‚
- en: '`bootstrap` This decides whether each tree learns from a random sample of data
    (`True`) or uses all data ( `False`). The default (`True`) helps create different
    kinds of trees, which is key to how Random Forests work. Only consider **setting
    it to** `**False**` **when you have very little data** and canâ€™t afford to skip
    any samples.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap` è¿™ä¸ªå‚æ•°å†³å®šäº†æ¯æ£µæ ‘æ˜¯ä»æ•°æ®çš„éšæœºæ ·æœ¬ä¸­å­¦ä¹ ï¼ˆ`True`ï¼‰ï¼Œè¿˜æ˜¯ä½¿ç”¨æ‰€æœ‰æ•°æ®ï¼ˆ`False`ï¼‰ã€‚é»˜è®¤å€¼ï¼ˆ`True`ï¼‰æœ‰åŠ©äºåˆ›å»ºä¸åŒç±»å‹çš„æ ‘ï¼Œè¿™æ˜¯éšæœºæ£®æ—å·¥ä½œåŸç†çš„å…³é”®ã€‚**åªæœ‰åœ¨æ•°æ®éå¸¸å°‘ï¼Œæ— æ³•è·³è¿‡ä»»ä½•æ ·æœ¬æ—¶ï¼Œæ‰è€ƒè™‘å°†å…¶è®¾ç½®ä¸º**`**False**`ã€‚'
- en: '`n_jobs` This controls how many processor cores to use during training. Setting
    it to `-1` uses all available cores, making training faster but using more memory.
    With big datasets, you might need to use fewer cores to avoid running out of memory.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_jobs` è¿™ä¸ªå‚æ•°æ§åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„å¤„ç†å™¨æ ¸å¿ƒæ•°ã€‚å°†å…¶è®¾ç½®ä¸º `-1` ä¼šä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„æ ¸å¿ƒï¼ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œä½†ä¼šå ç”¨æ›´å¤šå†…å­˜ã€‚å¯¹äºå¤§æ•°æ®é›†ï¼Œä½ å¯èƒ½éœ€è¦ä½¿ç”¨æ›´å°‘çš„æ ¸å¿ƒï¼Œä»¥é¿å…å†…å­˜ä¸è¶³ã€‚'
- en: Shared parameters with Decision Trees
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸å†³ç­–æ ‘å…±äº«çš„å‚æ•°
- en: The following parameters works the [same way as in Decision Tree](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å‚æ•°ä¸[å†³ç­–æ ‘ä¸­çš„å·¥ä½œæ–¹å¼ç›¸åŒ](/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e)ã€‚
- en: '`max_depth`: Maximum tree depth'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`: æœ€å¤§æ ‘æ·±åº¦'
- en: '`min_samples_split`: Minimum samples needed to split a node'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_split`: åˆ‡åˆ†èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°'
- en: '`min_samples_leaf`: Minimum samples required at leaf node'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_samples_leaf`: å¶èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°'
- en: 'Compared to Decision Tree, here are key differences in parameter importance:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å†³ç­–æ ‘ç›¸æ¯”ï¼Œä»¥ä¸‹æ˜¯å‚æ•°é‡è¦æ€§çš„å…³é”®å·®å¼‚ï¼š
- en: '`max_depth` This matters less in Random Forests because combining many trees
    helps prevent overfitting, even with deeper trees. You can usually let trees grow
    deeper to catch complex patterns in your data.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`max_depth` åœ¨éšæœºæ£®æ—ä¸­ä¸å¤ªé‡è¦ï¼Œå› ä¸ºç»“åˆå¤šä¸ªæ ‘å¯ä»¥å¸®åŠ©é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå³ä½¿æ˜¯è¾ƒæ·±çš„æ ‘ä¹Ÿå¦‚æ­¤ã€‚é€šå¸¸ä½ å¯ä»¥è®©æ ‘é•¿å¾—æ›´æ·±ï¼Œä»¥æ•æ‰æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚'
- en: '`min_samples_split` and `min_samples_leaf` These are less important in Random
    Forests because using many trees naturally helps avoid overfitting. You can usually
    set these to smaller numbers than you would with a single decision tree.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`min_samples_split` å’Œ `min_samples_leaf` åœ¨éšæœºæ£®æ—ä¸­ä¸å¤ªé‡è¦ï¼Œå› ä¸ºä½¿ç”¨å¤šæ£µæ ‘å¤©ç„¶æœ‰åŠ©äºé¿å…è¿‡æ‹Ÿåˆã€‚é€šå¸¸å¯ä»¥å°†è¿™äº›å‚æ•°è®¾ç½®ä¸ºæ¯”å•æ£µå†³ç­–æ ‘æ›´å°çš„å€¼ã€‚'
- en: Pros & Cons
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ä¸ç¼ºç‚¹
- en: 'Pros:'
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¼˜ç‚¹ï¼š
- en: '**Strong and Reliable:** Random Forests give accurate results and are less
    likely to overfit than single decision trees. By using random sampling and mixing
    up which features each tree considers at each node, they work well across many
    problems without needing much adjustment.'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¼ºå¤§ä¸”å¯é ï¼š** éšæœºæ£®æ—èƒ½æä¾›å‡†ç¡®çš„ç»“æœï¼Œå¹¶ä¸”æ¯”å•æ£µå†³ç­–æ ‘æ›´ä¸å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚é€šè¿‡ä½¿ç”¨éšæœºé‡‡æ ·å¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹æ··åˆä¸åŒçš„ç‰¹å¾ï¼Œéšæœºæ£®æ—èƒ½åœ¨å¤šä¸ªé—®é¢˜ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä¸”æ— éœ€è¿‡å¤šè°ƒæ•´ã€‚'
- en: '**Feature Importance:** The model can tell you which features matter most in
    making predictions by measuring how much each feature helps across all trees.
    This helps you understand what drives your predictions.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾é‡è¦æ€§ï¼š** é€šè¿‡è¡¡é‡æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰æ ‘ä¸­çš„è´¡çŒ®ï¼Œæ¨¡å‹å¯ä»¥å‘Šè¯‰ä½ å“ªäº›ç‰¹å¾å¯¹é¢„æµ‹æœ€ä¸ºé‡è¦ã€‚è¿™æœ‰åŠ©äºä½ ç†è§£é©±åŠ¨é¢„æµ‹çš„å› ç´ ã€‚'
- en: '**Minimal Preprocessing:** Random Forests handle both numerical and categorical
    variables well without much preparation. They work well with missing values and
    outliers, and can find complex relationships in your data automatically.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœ€å°é¢„å¤„ç†ï¼š** éšæœºæ£®æ—èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†æ•°å€¼å‹å’Œç±»åˆ«å‹å˜é‡ï¼Œå‡ ä¹ä¸éœ€è¦é¢å¤–çš„å‡†å¤‡å·¥ä½œã€‚å®ƒä»¬èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼ï¼Œå¹¶ä¸”å¯ä»¥è‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ã€‚'
- en: 'Cons:'
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¼ºç‚¹ï¼š
- en: '**Computational Cost:** Training and using the model takes more time as you
    add more trees or make them deeper. While you can speed up training by using multiple
    processors, it still needs substantial computing power for big datasets.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—æˆæœ¬ï¼š** éšç€æ ‘çš„å¢åŠ æˆ–æ ‘çš„æ·±åº¦åŠ æ·±ï¼Œè®­ç»ƒå’Œä½¿ç”¨æ¨¡å‹æ‰€éœ€çš„æ—¶é—´ä¹Ÿä¼šå¢åŠ ã€‚å°½ç®¡å¯ä»¥é€šè¿‡ä½¿ç”¨å¤šä¸ªå¤„ç†å™¨æ¥åŠ é€Ÿè®­ç»ƒï¼Œä½†å¯¹äºå¤§æ•°æ®é›†æ¥è¯´ï¼Œä»ç„¶éœ€è¦å¤§é‡çš„è®¡ç®—èƒ½åŠ›ã€‚'
- en: '**Limited Interpretability:** While you can see which features are important
    overall, itâ€™s harder to understand exactly why the model made a specific prediction,
    unlike with single decision trees. This can be a problem when you need to explain
    each decision.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœ‰é™çš„å¯è§£é‡Šæ€§ï¼š** å°½ç®¡ä½ å¯ä»¥çœ‹åˆ°å“ªäº›ç‰¹å¾åœ¨æ•´ä½“ä¸Šæœ€é‡è¦ï¼Œä½†å¾ˆéš¾ç¡®åˆ‡ç†è§£æ¨¡å‹ä¸ºä½•åšå‡ºç‰¹å®šé¢„æµ‹ï¼Œè¿™ä¸å•æ£µå†³ç­–æ ‘ä¸åŒã€‚å½“ä½ éœ€è¦è§£é‡Šæ¯ä¸ªå†³ç­–æ—¶ï¼Œè¿™å¯èƒ½ä¼šæˆä¸ºä¸€ä¸ªé—®é¢˜ã€‚'
- en: '**Prediction Speed:** To make a prediction, data must go through all trees
    and then combine their answers. This makes Random Forests slower than simpler
    models, which might be an issue for real-time applications.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é¢„æµ‹é€Ÿåº¦ï¼š** ä¸ºäº†åšå‡ºé¢„æµ‹ï¼Œæ•°æ®å¿…é¡»é€šè¿‡æ‰€æœ‰çš„æ ‘ï¼Œç„¶åå°†å®ƒä»¬çš„ç­”æ¡ˆç»“åˆèµ·æ¥ã€‚è¿™ä½¿å¾—éšæœºæ£®æ—æ¯”ç®€å•æ¨¡å‹æ›´æ…¢ï¼Œå¯èƒ½ä¼šæˆä¸ºå®æ—¶åº”ç”¨ä¸­çš„ä¸€ä¸ªé—®é¢˜ã€‚'
- en: Final Remarks
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ€ç»ˆè¯„è®º
- en: Iâ€™ve grown to really like Random Forests after seeing how well they work in
    practice. By combining multiple trees and letting each one learn from different
    parts of the data, they consistently make better predictions â€” of course, more
    than using just one tree alone.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çœ‹åˆ°éšæœºæ£®æ—åœ¨å®è·µä¸­çš„å‡ºè‰²è¡¨ç°åï¼Œæˆ‘å¼€å§‹çœŸæ­£å–œæ¬¢å®ƒä»¬ã€‚é€šè¿‡ç»“åˆå¤šæ£µæ ‘å¹¶è®©æ¯æ£µæ ‘ä»æ•°æ®çš„ä¸åŒéƒ¨åˆ†å­¦ä¹ ï¼Œå®ƒä»¬å§‹ç»ˆèƒ½åšå‡ºæ›´å¥½çš„é¢„æµ‹â€”â€”å½“ç„¶ï¼Œæ¯”ä»…ä½¿ç”¨å•æ£µæ ‘æ›´æœ‰æ•ˆã€‚
- en: While you do need to adjust some settings like the number of trees, they usually
    perform well even without much fine-tuning. They do need more computing power
    (and sometimes struggle with rare cases in the data) but their reliable performance
    and ease of use make them my go-to choice for many projects. Itâ€™s clear why so
    many data scientists feel the same way!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ä½ ç¡®å®éœ€è¦è°ƒæ•´ä¸€äº›è®¾ç½®ï¼Œæ¯”å¦‚æ ‘çš„æ•°é‡ï¼Œä½†é€šå¸¸å³ä½¿æ²¡æœ‰è¿‡å¤šçš„å¾®è°ƒï¼Œå®ƒä»¬ä¹Ÿèƒ½è¡¨ç°å¾—å¾ˆå¥½ã€‚å®ƒä»¬ç¡®å®éœ€è¦æ›´å¤šçš„è®¡ç®—èƒ½åŠ›ï¼ˆæœ‰æ—¶åœ¨å¤„ç†æ•°æ®ä¸­çš„ç¨€æœ‰æƒ…å†µæ—¶å¯èƒ½ä¼šé‡åˆ°å›°éš¾ï¼‰ï¼Œä½†å®ƒä»¬å¯é çš„æ€§èƒ½å’Œæ˜“ç”¨æ€§ä½¿å®ƒä»¬æˆä¸ºæˆ‘è®¸å¤šé¡¹ç›®ä¸­çš„é¦–é€‰ã€‚å¾ˆæ˜æ˜¾ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆå¤šæ•°æ®ç§‘å­¦å®¶ä¹Ÿæœ‰åŒæ ·çš„çœ‹æ³•ï¼
- en: ğŸŒŸ Random Forest Classifier Code Summarized
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŒŸ éšæœºæ£®æ—åˆ†ç±»å™¨ä»£ç æ€»ç»“
- en: '[PRE4]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ğŸŒŸ Random Forest Regressor Code Summarized
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸŒŸ éšæœºæ£®æ—å›å½’å™¨ä»£ç æ€»ç»“
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Further Reading
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: For a detailed explanation of the [RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    and [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
    and its implementation in scikit-learn, readers can refer to the official documentation,
    which provides comprehensive information on its usage and parameters.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº[RandomForestClassifier](https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html)å’Œ[RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)çš„è¯¦ç»†è§£é‡ŠåŠå…¶åœ¨scikit-learnä¸­çš„å®ç°ï¼Œè¯»è€…å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œå…¶ä¸­æä¾›äº†å…³äºä½¿ç”¨å’Œå‚æ•°çš„å…¨é¢ä¿¡æ¯ã€‚
- en: Technical Environment
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ç¯å¢ƒ
- en: This article uses Python 3.7 and scikit-learn 1.5\. While the concepts discussed
    are generally applicable, specific code implementations may vary slightly with
    different versions.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä½¿ç”¨çš„æ˜¯Python 3.7å’Œscikit-learn 1.5ç‰ˆæœ¬ã€‚å°½ç®¡è®¨è®ºçš„æ¦‚å¿µé€šå¸¸æ˜¯é€‚ç”¨çš„ï¼Œä½†ä¸åŒç‰ˆæœ¬çš„ä»£ç å®ç°å¯èƒ½ä¼šç•¥æœ‰ä¸åŒã€‚
- en: About the Illustrations
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³äºæ’å›¾
- en: Unless otherwise noted, all images are created by the author, incorporating
    licensed design elements from Canva Pro.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰æ’å›¾å‡ç”±ä½œè€…åˆ›ä½œï¼ŒåŒ…å«äº†æ¥è‡ªCanva Proçš„æˆæƒè®¾è®¡å…ƒç´ ã€‚
- en: 'ğ™ğ™šğ™š ğ™¢ğ™¤ğ™§ğ™š ğ™€ğ™£ğ™¨ğ™šğ™¢ğ™—ğ™¡ğ™š ğ™‡ğ™šğ™–ğ™§ğ™£ğ™ğ™£ğ™œ ğ™ğ™šğ™§ğ™š:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡ŒæŸ¥çœ‹æ›´å¤šå…³äºé›†æˆå­¦ä¹ çš„ä¿¡æ¯ï¼š
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
- en: Ensemble Learning
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›†æˆå­¦ä¹ 
- en: '[View list](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----9f736a6e1b3c--------------------------------)4
    stories![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/ensemble-learning-673fc83cd7db?source=post_page-----9f736a6e1b3c--------------------------------)4ä¸ªæ•…äº‹![](../Images/1bd2995b5cb6dcc956ceadadc5ee3036.png)![](../Images/22a5d43568e70222eb89fd36789a9333.png)![](../Images/8ea1a2f29053080a5feffc709f5b8669.png)'
- en: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğ™”ğ™¤ğ™ª ğ™¢ğ™ğ™œğ™ğ™© ğ™–ğ™¡ğ™¨ğ™¤ ğ™¡ğ™ğ™ ğ™š:'
- en: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![Samy Baladram](../Images/835013c69e08fec04ad9ca465c2adf6c.png)'
- en: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samy Baladram](https://medium.com/@samybaladram?source=post_page-----9f736a6e1b3c--------------------------------)'
- en: Classification Algorithms
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ†ç±»ç®—æ³•
- en: '[View list](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9f736a6e1b3c--------------------------------)8
    stories![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://medium.com/@samybaladram/list/classification-algorithms-b3586f0a772c?source=post_page-----9f736a6e1b3c--------------------------------)8ä¸ªæ•…äº‹![](../Images/f95c1a80b88fe6220b18cd3b2a83a30d.png)![](../Images/6ea70d9d2d9456e0c221388dbb253be8.png)![](../Images/7221f0777228e7bcf08c1adb44a8eb76.png)'
