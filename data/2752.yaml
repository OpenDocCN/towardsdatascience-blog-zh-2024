- en: From Parallel Computing Principles to Programming for CPU and GPU Architectures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从并行计算原理到CPU和GPU架构的编程
- en: 原文：[https://towardsdatascience.com/from-parallel-computing-principles-to-programming-for-cpu-and-gpu-architectures-dd06e1f30586?source=collection_archive---------5-----------------------#2024-11-12](https://towardsdatascience.com/from-parallel-computing-principles-to-programming-for-cpu-and-gpu-architectures-dd06e1f30586?source=collection_archive---------5-----------------------#2024-11-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-parallel-computing-principles-to-programming-for-cpu-and-gpu-architectures-dd06e1f30586?source=collection_archive---------5-----------------------#2024-11-12](https://towardsdatascience.com/from-parallel-computing-principles-to-programming-for-cpu-and-gpu-architectures-dd06e1f30586?source=collection_archive---------5-----------------------#2024-11-12)
- en: For early ML Engineers and Data Scientists, to understand memory fundamentals,
    parallel execution, and how code is written for CPU and GPU.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 适用于早期的机器学习工程师和数据科学家，旨在帮助他们理解内存基础、并行执行，以及如何为CPU和GPU编写代码。
- en: '[](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)[![Shreya
    Shukla](../Images/202aca58677a445ec618494f1151d2d7.png)](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)
    [Shreya Shukla](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)[![Shreya
    Shukla](../Images/202aca58677a445ec618494f1151d2d7.png)](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)
    [Shreya Shukla](https://medium.com/@shreyashukla04?source=post_page---byline--dd06e1f30586--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)
    ·19 min read·Nov 12, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--dd06e1f30586--------------------------------)
    ·19分钟阅读·2024年11月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/655d3adf6d073a78237e2072eedbb398.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/655d3adf6d073a78237e2072eedbb398.png)'
- en: Photo by [Olav Ahrens Røtne](https://unsplash.com/@olav_ahrens?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Olav Ahrens Røtne](https://unsplash.com/@olav_ahrens?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This article aims to explain the fundamentals of parallel computing. We start
    with the basics, including understanding shared vs. distributed architectures
    and communication within these systems. We will explore GPU architecture and how
    coding elements (using C++ Kokkos) help map architectural principles to code implementation.
    Finally, we will measure performance metrics (speedup) using the runtime data
    obtained from running the Kokkos code on both CPU and GPU architectures for vector-matrix
    multiplication, one of the most common operations in the machine learning domain.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在解释并行计算的基础知识。我们从基础开始，包括理解共享架构与分布式架构以及这些系统之间的通信。我们将探讨GPU架构以及如何通过编写代码（使用C++
    Kokkos）将架构原理映射到代码实现。最后，我们将使用运行Kokkos代码所获得的运行时数据来测量性能指标（加速），这些数据来自CPU和GPU架构下的向量-矩阵乘法，这是机器学习领域中最常见的操作之一。
- en: The central theme of the article is exploring and answering questions. It may
    seem like a lengthy journey, but it will be worth it. Let’s get started!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的核心主题是探索和解答问题。虽然这似乎是一次漫长的旅程，但它将是值得的。让我们开始吧！
- en: Fundamentals of System Architecture
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统架构基础
- en: I get that parallel computing saves time by running multiple operations at once.
    But I’ve heard that system time is different from human time or wall-clock time.
    How is it different?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我理解并行计算可以通过同时执行多个操作来节省时间。但是我听说系统时间与人类时间或挂钟时间不同。它们有什么不同之处？
- en: The smallest unit of time in computing is called a **clock tick**. It represents
    the minimum time required to perform an operation, such as fetching data, executing
    computations, or during communication. A **clock tick** technically refers to
    the change of state necessary for an instruction.The state can be processor state,
    data state, memory state, or control signals.In one clock tick, a complete instruction,
    part of an instruction, or multiple instructions may be executed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 计算中的最小时间单位称为**时钟周期**。它代表执行一个操作所需的最短时间，例如获取数据、执行计算或进行通信。**时钟周期**从技术上讲是指执行指令所需的状态变化。状态可以是处理器状态、数据状态、内存状态或控制信号。在一个时钟周期内，可能执行完整的指令、部分指令或多个指令。
- en: '**CPU allows for a limited number of state changes per second**. For example,
    a CPU with 3GHz clock speed allows for 3 billion changes of state per second.
    There is a limit to the allowable clock speed because each clock tick generates
    heat, and excessive speed can damage the CPU chip due to the heat generated.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**CPU允许每秒进行有限数量的状态变化**。例如，一个3GHz时钟频率的CPU每秒可以进行30亿次状态变化。时钟频率有上限，因为每个时钟周期都会产生热量，过高的频率会因为产生的热量损坏CPU芯片。'
- en: Therefore, we want to utilize the available capacity by using parallel computing
    methodologies. The purpose is to hide **memory latency** (the time it takes for
    the first data to arrive from memory), increase **memory bandwidth** (the amount
    of data transferred per unit of time), and enhance **compute throughput** (the
    tasks performed in a clock tick).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望通过使用并行计算方法来充分利用可用的计算能力。目的是隐藏**内存延迟**（从内存获取第一条数据所需的时间），提高**内存带宽**（每单位时间传输的数据量），并增强**计算吞吐量**（每个时钟周期内执行的任务数量）。
- en: To compare **performance**, such as when calculating efficiency of a parallel
    program, we use wall-clock time instead of clock ticks, since it includes all
    real-time overheads like memory latency and communication delays, that cannot
    be directly translated to clock ticks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较**性能**，例如在计算并行程序效率时，我们使用壁钟时间而非时钟周期，因为壁钟时间包括了所有的实际时间开销，如内存延迟和通信延迟，这些是无法直接转换为时钟周期的。
- en: What does the architecture of a basic system look like?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本系统的架构是什么样的？
- en: A system can consist of a single processor, a node, or even a cluster. Some
    of the **physical** building blocks of a system are —
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个系统可以由单个处理器、一个节点甚至一个集群组成。系统的一些**物理**构件是——
- en: '**Node** — A physical computer unit that has several processor chips. Multiple
    nodes combine to form a **cluster**.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**节点** — 一个包含多个处理器芯片的物理计算单元。多个节点组合形成一个**集群**。'
- en: '**Processor Chips** — Chips contain multiple processing elements called cores.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理器芯片** — 芯片包含多个被称为核心的处理单元。'
- en: '**Core** — Each core is capable of running an independent **thread** of execution.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**核心** — 每个核心都能够运行一个独立的**线程**。'
- en: In set terms, a node can have a one-to-many relationship with processor chips,
    and each processor chip can have a one-to-many relationship with cores. The image
    below gives a visual description of a node with processors and cores.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在设定的术语中，一个节点可以与处理器芯片建立一对多的关系，而每个处理器芯片可以与核心建立一对多的关系。下图给出了包含处理器和核心的节点的可视化描述。
- en: '![](../Images/c153ab76de53b118f94f98245679085f.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c153ab76de53b118f94f98245679085f.png)'
- en: 'Modern node with four eight-core processors that share a common memory pool.
    Ref: [Cornell Virtual Workshop](https://cvw.cac.cornell.edu/parallel/hpc/nodes)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现代节点具有四个八核心处理器，共享一个公共内存池。参考：[康奈尔虚拟研讨会](https://cvw.cac.cornell.edu/parallel/hpc/nodes)
- en: The **non-physical** components of a system include threads and processes —
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的**非物理**组件包括线程和进程——
- en: '**Thread** — Thread is a **sequence of CPU instructions** that operating system
    treats as a single unit for scheduling and execution purposes.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线程** — 线程是操作系统视为一个单独单元进行调度和执行的**CPU指令序列**。'
- en: '**Process** — In computing, a process is a **coherent unit** of resource allocation,
    including memory, file handlers, ports and devices. A single process may manage
    resources for several threads. [Threads can be modelled as components of a process.](https://cvw.cac.cornell.edu/parallel/terminology/threads-processes)'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**进程** — 在计算中，进程是一个**资源分配的整体单元**，包括内存、文件处理器、端口和设备。一个进程可以管理多个线程的资源。[线程可以作为进程的组件进行建模。](https://cvw.cac.cornell.edu/parallel/terminology/threads-processes)'
- en: So, do threads run on cores on the same system, or can they be spread across
    different systems for a single program? And in either case, how do they communicate?
    How’s memory handled for these threads ? Do they share it, or do they each get
    their own separate memory?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，线程是在同一系统的核心上运行，还是可以分布在不同系统中执行单个程序？无论哪种情况，它们如何通信？这些线程的内存是如何处理的？它们共享内存，还是每个线程都有自己的独立内存？
- en: A single program can execute across multiple cores on the same or different
    systems/ nodes. The design of the system and the program determines whether it
    aligns with the desired execution strategy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 单个程序可以在同一系统/节点或不同的系统/节点上的多个核心上执行。系统和程序的设计决定了它是否符合预期的执行策略。
- en: 'When designing a system, three key aspects must be considered: **execution**
    (how threads run), **memory access** (how memory is allocated to these threads),
    and **communication** (how threads communicate, especially when they need to update
    the same data). It’s important to note that these aspects are mostly interdependent.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计系统时，必须考虑三个关键方面：**执行**（线程如何运行）、**内存访问**（内存如何分配给这些线程）和**通信**（线程如何通信，特别是当它们需要更新相同的数据时）。需要注意的是，这些方面大多是相互依赖的。
- en: '**Execution**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行**'
- en: '**Serial execution***—* This uses a single thread of execution to work on a
    single data item at any time.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**串行执行** — *这使用单个执行线程在任何时候处理单一数据项。*'
- en: '**Parallel execution** — In this, more than one thing happens simultaneously.
    In computing, this can be —'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行执行** — 在这种方式中，多个任务同时发生。在计算中，这可以是—'
- en: '**One worker** — A single thread of execution operating on multiple data items
    simultaneously (vector instructions in a CPU). Imagine a single person sorting
    a deck of cards by suit. With four suits to categorize, the individual must go
    through the entire deck to organize the cards for each suit.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**单个工人** — 单个执行线程同时处理多个数据项（CPU中的向量指令）。想象一个人根据花色整理扑克牌。由于有四种花色要分类，这个人必须逐一浏览整副牌，整理每种花色的卡片。'
- en: '**Working Together** — Multiple threads of execution in a single process. It
    is equivalent to multiple people working together to sort a single deck of cards
    by suit.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**协作工作** — 单个进程中的多个执行线程。它相当于多个人一起合作，根据花色对一副扑克牌进行排序。'
- en: '**Working Independently** — Multiple processes can work on the same problem,
    utilizing either the same node or multiple nodes. In this scenario, each person
    would be sorting their deck of cards.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**独立工作** — 多个进程可以处理同一个问题，利用相同的节点或多个节点。在这种情况下，每个人都会单独整理自己的扑克牌。'
- en: Any combination of the above.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以上的任意组合。
- en: '![](../Images/6d28c89a540999a37bf692c49d4ab184.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d28c89a540999a37bf692c49d4ab184.png)'
- en: 'Working Together: Two workers need to insert cards from the same suit. Worker
    A is holding the partial results'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**协作工作**：两个工人需要插入同一花色的卡片。工人A持有部分结果'
- en: 'for the clubs suit, so Worker B is temporarily blocked. Ref: [Cornell Virtual
    Workshop](https://cvw.cac.cornell.edu/parallel/intro/working-together)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于梅花花色，工人B被暂时阻塞。参考：[康奈尔虚拟研讨会](https://cvw.cac.cornell.edu/parallel/intro/working-together)
- en: '**Memory Access**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存访问**'
- en: '**Shared Memory** — When a program runs on multiple cores (**a single multithreaded
    process**) on the same system, each thread within the process has access to memory
    in the same virtual address space.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**共享内存** — 当程序在同一系统上的多个核心（**单个多线程进程**）中运行时，进程中的每个线程都可以访问相同虚拟地址空间中的内存。'
- en: '**Distributed Memory** — A distributed memory design is employed when a program
    utilizes **multiple processes** (whether on a single node or across different
    nodes). In this architecture, each process owns a portion of the data, and other
    processes must send messages to the owner to update their respective parts. Even
    when multiple processes run on a single node, each has its own virtual memory
    space. Therefore, such processes should use distributed memory programming for
    communication.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分布式内存** — 当程序使用**多个进程**（无论是在单个节点上还是跨不同节点）时，采用分布式内存设计。在这种架构中，每个进程拥有数据的一部分，其他进程必须向数据拥有者发送消息以更新它们各自的部分。即使多个进程运行在单个节点上，每个进程仍有自己的虚拟内存空间。因此，这类进程应使用分布式内存编程进行通信。'
- en: '**Hybrid Strategy** — **Multithreaded processes** that can run on the same
    or different nodes, designed to use multiple cores on a single node through shared
    memory programming. At the same time, they can employ distributed memory strategies
    to coordinate with processes on other nodes. Imagine multiple people or threads
    working in multiple cubicles in the image above. Workers in the same cubicle communicate
    using shared memory programming, while those in different cubicles interact through
    distributed memory programming.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**混合策略** — **多线程进程**可以在同一节点或不同节点上运行，旨在通过共享内存编程利用单一节点上的多个核心。同时，它们还可以采用分布式内存策略与其他节点上的进程进行协调。可以想象，在上图中，多个人或线程在多个隔间工作。相同隔间中的工作者通过共享内存编程进行通信，而不同隔间中的工作者则通过分布式内存编程进行交互。'
- en: '![](../Images/55c24c2dcde05cd6ce2f376d807bdda8.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55c24c2dcde05cd6ce2f376d807bdda8.png)'
- en: 'In a distributed memory design, parallel workers are assigned to different
    cubicles (processes). Ref: [Cornell Virtual Workshop](https://cvw.cac.cornell.edu/parallel/terminology/tasks)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式内存设计中，多个并行工作者被分配到不同的隔间（进程）。参考：[康奈尔虚拟工作坊](https://cvw.cac.cornell.edu/parallel/terminology/tasks)
- en: '**Communication**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**通信**'
- en: The communication mechanism depends on the memory architecture. In **shared
    memory architectures**, application programming interfaces like **OpenMP** (Open
    Multi-Processing)enable communication between threads that share memory and data.
    On the other hand, **MPI** (Message Passing Interface) can be used for communication
    between processes running on the same or different nodes in **distributed memory
    architectures**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通信机制依赖于内存架构。在**共享内存架构**中，像**OpenMP**（开放多处理）这样的应用程序接口可以实现共享内存和数据的线程之间的通信。另一方面，**MPI**（消息传递接口）可以用于在**分布式内存架构**中，运行在同一节点或不同节点上的进程之间的通信。
- en: Parallelization Strategy and Performance
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化策略和性能
- en: How can we tell if our parallelization strategy is working effectively?
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何判断我们的并行化策略是否有效？
- en: There are several methods, but here, we discuss efficiency and speedup. In parallel
    computing, efficiency refers to the proportion of available resources that are
    actively utilized during a computation. It is determined by comparing the actual
    resource utilization against the peak performance, i.e., optimal resource utilization.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法，但在这里我们讨论的是效率和加速比。在并行计算中，效率指的是在计算过程中实际利用的资源与可用资源的比例。它是通过将实际资源利用率与峰值性能进行比较来确定的，也就是最优资源利用率。
- en: '**Actual processor utilization** refers to the number of floating point operations
    (FLOP) performed over a specific period.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**实际处理器利用率**指的是在特定时间段内执行的浮点运算（FLOP）数量。'
- en: '**Peak performance** assumes that each processor core executes the maximum
    possible FLOPs during every clock cycle.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**峰值性能**假设每个处理器核心在每个时钟周期内执行最大可能的浮点运算（FLOP）。'
- en: '**Efficiency for parallel code** is the ratio of actual floating-point operations
    per second (FLOPS) to the peak possible performance.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行代码的效率**是每秒实际浮点运算（FLOPS）与可能的峰值性能之比。'
- en: '**Speedup** is used to assess efficiency and is measured as:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速比**用于评估效率，其计算公式为：'
- en: '![](../Images/917b99538054a2358cb3c512063c8ceb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/917b99538054a2358cb3c512063c8ceb.png)'
- en: '[Speedup cannot be greater than the number of parallel resources](https://cvw.cac.cornell.edu/parallel/efficiency/about-efficiency)
    when programs are limited by computing speed of the processors.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[当程序受限于处理器的计算速度时，速度提升不能超过并行资源的数量](https://cvw.cac.cornell.edu/parallel/efficiency/about-efficiency)。'
- en: 'Using speedup, parallel efficiency is measured as :'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加速比，测量并行效率的公式为：
- en: '![](../Images/5979f6439a7de8b14daa2056e1bdd6b5.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5979f6439a7de8b14daa2056e1bdd6b5.png)'
- en: '[*Hence, a worthy goal for optimization of a parallel program is to bring its
    speedup as close as possible to the number of cores.*](https://cvw.cac.cornell.edu/parallel/efficiency/about-efficiency)'
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[*因此，优化并行程序的一个重要目标是将其加速比尽可能接近核心数量。*](https://cvw.cac.cornell.edu/parallel/efficiency/about-efficiency)'
- en: 'Suppose the serial execution of code took 300 seconds. After parallelizing
    the tasks using 50 cores, the overall wall-clocktime for parallel execution was
    6 seconds. In this case, the speedup can be calculated as the wall-clock time
    for serial execution divided by the wall-clock time for parallel execution, resulting
    in a speedup of 300s/6s = 50\. We get parallel efficiency by dividing the speedup
    by the number of cores, 50/50 ​= 1\. This is an example of the best-case scenario:
    the workload is perfectly parallelized, and all cores are utilized efficiently.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 假设代码的串行执行时间为300秒。在使用50个核心并行化任务后，整体的墙钟时间为6秒。在这种情况下，速度提升可以通过将串行执行的墙钟时间除以并行执行的墙钟时间来计算，结果为300秒/6秒
    = 50。我们通过将速度提升除以核心数来获得并行效率，即50/50 = 1。这是最佳情况的示例：工作负载完美地进行了并行化，且所有核心得到了高效利用。
- en: Will adding more computing units constantly improve performance if the data
    size or number of tasks increases?
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果数据大小或任务数量增加，增加更多的计算单元是否会持续提高性能？
- en: Only sometimes. In parallel computing, we have two types of scaling based on
    the problem size or the number of parallel tasks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 并不总是如此。在并行计算中，我们有两种类型的扩展性，分别是基于问题规模或并行任务数量的扩展性。
- en: '**Strong Scaling** — Increasing the number of parallel tasks while keeping
    the problem size constant. However, even as we increase the number of computational
    units (cores, processors, or nodes) to process more tasks in parallel, there is
    an overhead associated with communication between these units or the host program,
    such as the time spent sending and receiving data.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**强扩展性** — 在保持问题规模不变的情况下增加并行任务的数量。然而，即使我们增加计算单元（核心、处理器或节点）来并行处理更多任务，也会有与这些单元之间或与主程序之间的通信相关的开销，例如发送和接收数据所花费的时间。'
- en: S[*trong scaling performance is affected by the ratio of time communicating
    to the time spent computing. The larger the ratio, worse the strong scaling behaviour
    will be.*](https://cvw.cac.cornell.edu/parallel/efficiency/scaling)
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**强扩展性表现受到通信时间与计算时间比率的影响。比率越大，强扩展性表现越差。**](https://cvw.cac.cornell.edu/parallel/efficiency/scaling)'
- en: Ideally, the execution time decreases as the number of parallel tasks increases.
    However, if the code doesn’t get faster with strong scaling, it could indicate
    that we’re using too many tasks for the amount of work being done.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，随着并行任务数量的增加，执行时间会减少。然而，如果代码在强扩展性下没有加速，可能表明我们为当前工作量使用了过多的任务。
- en: '**Weak Scaling —** In this, problem size increases as the number of tasks increase,
    so computation per task remains constant. If your program has good weak scaling
    performance, you can run a problem twice as large on twice as many nodes in the
    same wall-clock time.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**弱扩展性** — 在这种情况下，随着任务数量的增加，问题规模也会增加，因此每个任务的计算量保持不变。如果您的程序具有良好的弱扩展性，您可以在相同的墙钟时间内，用两倍的节点运行一个规模为原来的两倍的问题。'
- en: There are restrictions around what we can parallelize since some operations
    can’t be parallelized. Is that right?
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确实，存在一些限制，无法并行化某些操作，对吗？
- en: Yes, parallelizing certain sequential operations can be quite challenging. Parallelizing
    depends on multiple instruction streams and/or multiple data streams.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，将某些顺序操作并行化确实可能相当具有挑战性。并行化依赖于多个指令流和/或多个数据流。
- en: '![](../Images/826d67454a004c65b755cbb6b327bc25.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/826d67454a004c65b755cbb6b327bc25.png)'
- en: 'Different types of parallel computing architectures. Ref: [Cornell Virtual
    Workshop](https://cvw.cac.cornell.edu/parallel/hpc/taxonomy-parallel-computers)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的并行计算架构。参考：[康奈尔虚拟工作坊](https://cvw.cac.cornell.edu/parallel/hpc/taxonomy-parallel-computers)
- en: To understand what can be parallelized, let’s look at SIMD in CPUs, which is
    achieved using vectorization.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解什么可以并行化，我们来看看CPU中的SIMD，它是通过矢量化实现的。
- en: '*Vectorization is a programming technique in which operations are applied to
    entire arrays at once rather than processing individual elements one by one. It
    is achieved using the vector unit in processors, which includes vector registers
    and vector instructions.*'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*矢量化是一种编程技术，其中操作是一次性应用到整个数组，而不是逐个处理单个元素。它是通过使用处理器中的矢量单元实现的，矢量单元包括矢量寄存器和矢量指令。*'
- en: 'Consider a scenario where we iterate over an array and perform multiple operations
    on a single element within a for loop. When the data is independent, writing vectorizable
    code becomes straightforward; see the example below:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这样一种情况，我们遍历数组，并在for循环中对单个元素执行多个操作。当数据是独立的时，编写可矢量化的代码变得非常简单；请参见下面的示例：
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this loop, each iteration is independent — meaning `a(i)` is processed independently
    of `a(i+1)` and so on. Therefore, this code is vectorizable, that will allow multiple
    elements of array `a` to be computed in parallel using elements from `b` and `c`,
    as demonstrated below:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个循环中，每次迭代都是独立的——意味着 `a(i)` 的处理与 `a(i+1)` 等是独立的。因此，这段代码是可向量化的，允许使用来自 `b` 和
    `c` 的元素并行计算数组 `a` 的多个元素，示例如下：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Modern compilers are generally capable of analyzing such loops and transforming
    them into sequences of vector operations.* [*Problem arises when an operation
    in one iteration depends upon the result of a previous iteration. In this case,
    automatic vectorization might lead to incorrect results. This situation is known
    as a data dependency.*](https://cvw.cac.cornell.edu/vector/coding/data-dependencies)'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*现代编译器通常能够分析这样的循环并将其转化为向量操作序列。* [*当某次迭代中的操作依赖于前一次迭代的结果时，问题就出现了。在这种情况下，自动向量化可能导致错误的结果。这种情况被称为数据依赖性。*](https://cvw.cac.cornell.edu/vector/coding/data-dependencies)'
- en: Data dependencies commonly encountered in scientific code are -
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 科学代码中常遇到的数据依赖性包括 -
- en: '**Read After Write (RAW)** — *Not Vectorizable*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**读后写（RAW）** — *不可向量化*'
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Write After Read (WAR)** — *Vectorizable*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**写后读（WAR）** — *可向量化*'
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Write After Write (WAW)** — *Not Vectorizable*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**写后写（WAW）** — *不可向量化*'
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Read After Read (RAR)** — *Vectorizable*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**读后读（RAR）** — *可向量化*'
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Adhering to certain standard rules for vectorization — such as ensuring independent
    assignments in loop iterations, avoiding random data access, and preventing dependencies
    between iterations — can help write vectorizable code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循某些标准规则进行向量化——例如确保循环迭代中的独立赋值、避免随机数据访问以及防止迭代之间的依赖性——可以帮助编写可向量化的代码。
- en: GPU architecture and cross-architectural code
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU 架构与跨架构代码
- en: When data increases, it makes sense to parallelize as many parallelizable operations
    as possible to create scalable solutions, but that means we need bigger systems
    with lots of cores. Is that why we use GPUs? How are they different from CPUs,
    and what leads to their high throughput?
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当数据量增加时，尽可能将更多可并行化的操作进行并行化，以创建可扩展的解决方案是有意义的，但这意味着我们需要更大的系统，拥有更多的核心。难道这就是为什么我们使用
    GPU 吗？它们与 CPU 有何不同，是什么导致了它们的高吞吐量？
- en: YES!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 是的！
- en: '![](../Images/7b996318622b4ea4b0acd28a9998e877.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b996318622b4ea4b0acd28a9998e877.png)'
- en: 'Comparing the relative capabilities of the basic elements of CPU and GPU architectures.
    Ref: [Cornell Virtual Workshop](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/design)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 CPU 和 GPU 架构中基本元素的相对能力。参考：[康奈尔虚拟研讨会](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/design)
- en: '**GPUs (Graphics processing units)** have many more processor units (green)
    and higher aggregate *memory bandwidth* (the amount of data transferred per unit
    of time) as compared to CPUs, which, on the other hand, have more sophisticated
    instruction processing and faster clock speed. As seen above, CPUs have more cache
    memory than GPUs. However, CPUs have fewer arithmetic logic units (ALUs) and floating
    point units (FPUs) than GPUs. Considering these points, **using CPUs for complex
    workflow and GPUs for computationally intensive tasks is intuitive.**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPU（图形处理单元）** 相比 CPU，拥有更多的处理单元（绿色）和更高的整体 *内存带宽*（每单位时间传输的数据量）。而 CPU 则拥有更复杂的指令处理和更快的时钟速度。如上所示，CPU
    的缓存内存比 GPU 多。然而，CPU 的算术逻辑单元（ALU）和浮点单元（FPU）少于 GPU。考虑到这些因素，**使用 CPU 处理复杂的工作流，而将
    GPU 用于计算密集型任务是直观的。**'
- en: '[GPUs are designed to produce high computational throughput](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/performance)
    using their massively parallel architecture. Their computational potential can
    be measured in billions of floating point operations per second (GFLOPS). GPU
    hardware comes in the form of standard graphic cards (NVIDIA quad), High-end accelerator
    cards (NVIDIA Tesla), etc.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPU 被设计用来利用其大规模并行架构产生高计算吞吐量](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/performance)。其计算潜力可以通过每秒数十亿次浮点运算（GFLOPS）来衡量。GPU
    硬件通常以标准显卡（如 NVIDIA Quadro）、高端加速卡（如 NVIDIA Tesla）等形式出现。'
- en: Two key properties of the graphics pipeline that enable parallelization and,
    thus, high throughput are —
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图形管线的两个关键特性使得并行化成为可能，从而实现高吞吐量——
- en: '**Independence of Objects —** A typical graphics scene consists of many independent
    objects; each object can be processed separately without dependencies on the others.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对象的独立性** — 一个典型的图形场景由许多独立的对象组成；每个对象可以独立处理，而不依赖于其他对象。'
- en: '**Uniform Processing Steps —** The sequence of processing steps is the same
    for all objects.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**统一处理步骤 —** 处理步骤的顺序对于所有对象都是相同的。'
- en: So, multiple cores of GPUs work on different data at the same time, executing
    computations in parallel like a SIMD (Single Instruction Multiple Data) architecture.
    How are tasks divided between cores? Does each core run a single thread like in
    the CPU?
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因此，GPU的多个核心可以同时处理不同的数据，像SIMD（单指令多数据）架构一样并行执行计算。任务是如何在核心之间划分的？每个核心是否像CPU一样只运行一个线程？
- en: In a GPU, **Streaming Multiprocessors (SMs)** are similar to cores in a CPU.
    Cores in GPUs are similar to vector lanes in CPUs. SMs are the hardware units
    that house cores.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU中，**流式多处理器（SMs）**类似于CPU中的核心。GPU中的核心类似于CPU中的向量通道。SM是容纳核心的硬件单元。
- en: When a function or computation, referred as a **kernel,** is executed on the
    GPU, it is often broken down into **thread blocks**. These thread blocks contain
    **multiple threads;** each SM can manage many threads across its cores. If there
    are more thread blocks than SMs, multiple thread blocks can be assigned to a single
    SM. Also, multiple threads can run on a single core.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个被称为**内核（kernel）**的函数或计算在GPU上执行时，它通常会被分解成**线程块（thread blocks）**。这些线程块包含**多个线程（multiple
    threads）**；每个SM可以管理其核心上的多个线程。如果线程块的数量超过SM的数量，多个线程块可以被分配到单个SM上。同时，多个线程可以在单个核心上运行。
- en: '[Each SM further divides the **thread blocks** into groups called **warps**,
    with each warp consisting of **32 threads**.](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/simt_warp)
    These threads execute the same stream of instructions on different data elements,
    following a **Single Instruction, Multiple Data (SIMD)** model. The warp size
    is set to 32 because, in NVIDIA’s architecture, CUDA cores are grouped into sets
    of 32\. This enables all threads in a warp to be processed together in parallel
    by the 32 CUDA cores, achieving high efficiency and optimized resource utilization.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[每个SM进一步将**线程块（thread blocks）**划分为称为**warps**的组，每个warp由**32个线程**组成。](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/simt_warp)
    这些线程在不同的数据元素上执行相同的指令流，遵循**单指令多数据（SIMD）**模型。warp大小被设置为32，因为在NVIDIA的架构中，CUDA核心是按32个一组进行分组的。这使得warp中的所有线程可以通过32个CUDA核心并行处理，从而实现高效率和优化的资源利用。'
- en: In **SIMD (Single Instruction, Multiple Data)**, a single instruction acts uniformly
    on all data elements, with each data element processed in exactly the same way.
    **SIMT (Single Instruction, Multiple Threads)**, which is commonly used in GPUs,
    relaxes this restriction. In SIMT, threads can be activated or deactivated so
    that instruction and data are processed in active threads; however, the local
    data remains unchanged on inactive threads.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在**SIMD（单指令多数据）**中，单一指令对所有数据元素执行相同的操作，每个数据元素以完全相同的方式进行处理。**SIMT（单指令多线程）**，这是GPU中常用的方式，放宽了这一限制。在SIMT中，线程可以被激活或停用，因此指令和数据在激活的线程中被处理；然而，局部数据在非激活线程中保持不变。
- en: I want to understand how we can code to use different architectures. Can similar
    code work for both CPU and GPU architectures? What parameters and methods can
    we use to ensure that the code efficiently utilizes the underlying hardware architecture,
    whether it’s CPUs or GPUs?
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我想理解如何编写代码以利用不同的架构。相似的代码可以同时在CPU和GPU架构上工作吗？我们可以使用哪些参数和方法来确保代码有效地利用底层硬件架构，无论是CPU还是GPU？
- en: Code is generally written in high-level languages like C or C++ and must be
    converted into binary code by a compiler since machines cannot directly process
    high-level instructions. While both GPUs and CPUs can execute the same kernel,
    as we will see in the example code, we need to use directives or parameters to
    run the code on a specific architecture to compile and generate an instruction
    set for that architecture. This approach allows us to use architecture-specific
    capabilities. To ensure compatibility, we can specify the appropriate flags for
    the compiler to produce binary code optimized for the desired architecture, whether
    it is a CPU or a GPU.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代码通常用高级语言如C或C++编写，并且必须通过编译器转换为二进制代码，因为计算机无法直接处理高级指令。虽然GPU和CPU都可以执行相同的内核，但正如我们将在示例代码中看到的，我们需要使用指令或参数来运行代码在特定架构上，编译并生成该架构的指令集。这种方法使我们能够利用架构特定的功能。为了确保兼容性，我们可以为编译器指定适当的标志，以生成针对所需架构优化的二进制代码，无论是CPU还是GPU。
- en: Various coding frameworks, such as SYCL, CUDA, and Kokkos, are used to write
    kernels or functions for different architectures. In this article, we will use
    examples from Kokkos.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 各种编码框架，如 SYCL、CUDA 和 Kokkos，广泛用于为不同架构编写内核或函数。在本文中，我们将使用来自 Kokkos 的示例。
- en: '**A bit about Kokkos —** An open-source C++ programming model for performance
    portability for writing Kernels: it is implemented as a template library on top
    of CUDA, OpenMP, and other backends and aims to be descriptive, in the sense that
    we define *what* we want to do rather than prescriptive (how we want to do it).
    Kokkos Core provides a programming model for parallel algorithms that uses many-core
    chips and shares memory across those cores.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于 Kokkos —** 一个开源的 C++ 编程模型，旨在实现性能可移植性，用于编写内核：它作为一个模板库，构建在 CUDA、OpenMP 和其他后端之上，旨在描述性地定义我们想要做的事情，而非规定性地定义我们想如何做。Kokkos
    Core 提供了一种并行算法的编程模型，适用于多核芯片，并在这些核心之间共享内存。'
- en: A **kernel** has three components —
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**内核**有三个组件—'
- en: '**Pattern —** Structure of the computation: for, scan, reduction, task-graph'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模式 —** 计算的结构：for、scan、reduction、task-graph'
- en: '**Execution policy —** How computations are executed: static scheduling, dynamic
    scheduling, thread teams.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**执行策略 —** 计算如何执行：静态调度、动态调度、线程组。'
- en: '**Computational Body —** Code which performs each unit of work. e.g., loop
    body'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算体 —** 执行每个工作单元的代码。例如，循环体'
- en: Pattern and policy drive computational body. In the example below, used just
    for illustration, ‘for**’** is the *pattern***,** the *condition* to control the
    pattern (element=0; element<n; ++element) is the *policy*, and the *computational
    body* is the code executed within the pattern
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模式和策略驱动计算体。在下面的示例中，仅为说明用途，‘for**’** 是 *模式*，控制模式的 *条件*（element=0; element<n;
    ++element）是 *策略*，而 *计算体* 是模式内执行的代码
- en: '[PRE6]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The Kokkos framework allows developers to define parameters and methods based
    on three key factors: where the code will run **(Execution Space)**, what memory
    resources will be utilized **(Memory Space)**, and how data will be structured
    and managed **(Data Structure and Data management**).'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 框架允许开发人员根据三个关键因素来定义参数和方法：代码将在哪运行 **（执行空间）**，将使用哪些内存资源 **（内存空间）**，以及数据如何结构化和管理
    **（数据结构与数据管理）**。
- en: We primarily discuss how to write the Kokkos kernel for the **vector-matrix
    product** to understand how these factors are implemented for different architectures.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要讨论如何编写 Kokkos 内核来实现**向量矩阵乘法**，以了解这些因素如何在不同架构上实现。
- en: But before that, let’s discuss the building blocks of the kernel we want to
    write.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 但在此之前，我们先来讨论一下我们想要编写的内核的构建块。
- en: '**Memory Space —**'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存空间 —**'
- en: Kokkos provides a range of memory space options that enable users to control
    memory management and data placement on different computing platforms. Some commonly
    used memory spaces are —
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Kokkos 提供了多种内存空间选项，使用户能够控制内存管理和数据在不同计算平台上的布置。一些常用的内存空间包括—
- en: '**HostSpace —** This memory space represents the CPU’s main memory. It is used
    for computations on the CPU and is typically the default memory space when working
    on a CPU-based system.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**HostSpace —** 此内存空间代表 CPU 的主内存。它用于 CPU 上的计算，通常是基于 CPU 的系统的默认内存空间。'
- en: '**CudaSpace —** CudaSpace is used for NVIDIA GPUs with CUDA. It provides memory
    allocation and management for GPU devices, allowing for efficient data transfer
    and computation.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**CudaSpace —** CudaSpace 用于具有 CUDA 的 NVIDIA GPU。它提供 GPU 设备的内存分配和管理，支持高效的数据传输和计算。'
- en: '**CudaUVMSpac —** For Unified Virtual Memory (UVM) systems, such as those on
    some NVIDIA GPUs, CudaUVMSpace enables the allocation of memory accessible from
    both the CPU and GPU without explicit data transfers. Cuda runtime automatically
    handles data movement at a performance hit.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**CudaUVMSpac —** 对于统一虚拟内存（UVM）系统，如某些 NVIDIA GPU 上的 UVM，CudaUVMSpac 使得可以分配从
    CPU 和 GPU 都可以访问的内存，而无需显式的数据传输。Cuda 运行时自动处理数据移动，但会有性能损失。'
- en: It is also essential to discuss **memory layout**, which refers to the organization
    and arrangement of data in memory. Kokkos provides several memory layout options
    to help users optimize their data storage for various computations. Some commonly
    used memory layouts are —
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论**内存布局**也非常重要，它指的是内存中数据的组织和安排。Kokkos 提供了几种内存布局选项，帮助用户优化不同计算的数据显示方式。一些常用的内存布局包括—
- en: '![](../Images/1049e781fcb83e45fec8455b8c008e2d.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1049e781fcb83e45fec8455b8c008e2d.png)'
- en: 'Row-major vs Column-major iteration of a matrix. Ref: [Wikipedia](https://en.wikipedia.org/wiki/Row-_and_column-major_order)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的行主序与列主序迭代。参考：[Wikipedia](https://en.wikipedia.org/wiki/Row-_and_column-major_order)
- en: '**LayoutRight (also known as Row-Major)** is the default memory layout for
    multi-dimensional arrays in C and C++. In LayoutRight, the rightmost index varies
    most rapidly in memory. If no layout is chosen, the default layout for HostSpace
    is LayoutRight.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LayoutRight（也称为行主序）**是 C 和 C++ 中多维数组的默认内存布局。在 LayoutRight 中，最右边的索引在内存中变化最快。如果未选择布局，HostSpace
    的默认布局为 LayoutRight。'
- en: '**LayoutLeft (also known as Column-Major) —** In LayoutLeft, the leftmost index
    varies most rapidly in memory. If no layout is chosen, the default layout for
    CudaSpace is LayoutLeft.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LayoutLeft（也称为列主序）—** 在 LayoutLeft 中，最左边的索引在内存中变化最快。如果未选择布局，CudaSpace 的默认布局为
    LayoutLeft。'
- en: In the programmatic implementation below, we defined memory space and layout
    as macros based on the compiler flag ENABLE_CUDA, which will be True if we want
    to run our code on GPU and False for CPU.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的程序实现中，我们根据编译器标志 ENABLE_CUDA 定义了内存空间和布局的宏，当我们希望在 GPU 上运行代码时，ENABLE_CUDA 为
    True，CPU 上则为 False。
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Data Structure and Data Management —**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据结构与数据管理 —**'
- en: '**Kokkos Views *—*** In Kokkos, a “view” is a **fundamental data structure**
    representing one-dimensional and multi-dimensional arrays, which can be used to
    store and access data efficiently. Kokkos views provide a high-level abstraction
    for managing data and is designed to work seamlessly with different execution
    spaces and memory layouts.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kokkos 视图 *—*** 在 Kokkos 中，"视图"是一个**基础数据结构**，表示一维和多维数组，可用于高效地存储和访问数据。Kokkos
    视图为数据管理提供了高级抽象，并设计为与不同的执行空间和内存布局无缝协作。'
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Kokkos Mirroring technique for data management** — Mirrors are views of equivalent
    arrays residing in possible different memory spaces, which is when we need data
    in both CPU and GPU architecture. This technique is helpful for scenarios like
    reading data from a file on the CPU and subsequently processing it on the GPU.
    Kokkos’ mirroring creates a mirrored view of the data, allowing seamless sharing
    between the CPU and GPU execution spaces and facilitating data transfer and synchronization.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kokkos 数据管理的镜像技术** — 镜像是等效数组的视图，这些数组可能位于不同的内存空间中，适用于在 CPU 和 GPU 架构中都需要数据的场景。这项技术在读取
    CPU 上的文件数据并随后在 GPU 上处理时非常有用。Kokkos 的镜像技术创建了数据的镜像视图，允许在 CPU 和 GPU 执行空间之间无缝共享，并促进数据传输和同步。'
- en: To create a mirrored copy of the primary data, we can use Kokkos’ *create_mirror_view()*
    function. This function generates a mirror view in a specified execution space
    (e.g., GPU) with the same data type and dimensions as the primary view.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建主数据的镜像副本，我们可以使用 Kokkos 的 *create_mirror_view()* 函数。该函数在指定的执行空间（例如 GPU）中生成一个具有与主视图相同数据类型和维度的镜像视图。
- en: '[PRE9]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Execution Space —**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**执行空间 —**'
- en: In Kokkos, the **execution space** refers to the specific computing environment
    or hardware platform where parallel operations and computations are executed.
    Kokkos abstracts the execution space, enabling code to be written in a descriptive
    manner while adapting to various hardware platforms.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kokkos 中，**执行空间**指的是并行操作和计算执行的特定计算环境或硬件平台。Kokkos 抽象了执行空间，使得代码可以以描述性方式编写，同时适应各种硬件平台。
- en: We discuss two primary execution spaces —
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论两个主要的执行空间 —
- en: '**Serial**: The Serial execution space is a primary and portable option suitable
    for single-threaded CPU execution. It is often used for debugging, testing, and
    as a baseline for performance comparisons.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Serial**：Serial 执行空间是一种主要且可移植的选项，适用于单线程的 CPU 执行。它通常用于调试、测试以及作为性能比较的基准。'
- en: '**Cuda**: The Cuda execution space is used for NVIDIA GPUs and relies on CUDA
    technology for parallel processing. It enables efficient GPU acceleration and
    management of GPU memory.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Cuda**：Cuda 执行空间用于 NVIDIA GPU，并依赖 CUDA 技术进行并行处理。它可以实现高效的 GPU 加速和 GPU 内存管理。'
- en: 'Either the ExecSpace can be defined, or it can be determined dynamically based
    on the Memory space as below:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 可以定义 ExecSpace，也可以根据内存空间动态确定，如下所示：
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How can we use these building blocks to write an actual kernel? Can we use it
    to compare performance between different architectures?
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何利用这些构件来编写实际的内核？我们能否用它来比较不同架构之间的性能？
- en: 'For the purpose of writing a kernel and performance comparison, we use following
    computation:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编写一个内核并进行性能比较，我们使用以下计算：
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The kernel for this operation in Kokkos —
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作在Kokkos中的内核—
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For the above kernel, `parallel_reduce` serves as the pattern, `range_policy`
    defines the policy, and the actual operations constitute the computational body.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述内核，`parallel_reduce`作为模式，`range_policy`定义了策略，而实际的操作构成了计算体。
- en: 'I executed this kernel on a TACC Frontera node which has an NVIDIA Quadro RTX
    5000 GPU. The experiments were performed with varying values of **N**, which refers
    to the lengths of the vectors **y** and **x**, and the number of rows in matrix
    **A**. Computation was performed 100 times to get notable results, and the execution
    time of the kernel was recorded for both Serial (Host) and CUDA execution spaces.
    I used `**ENABLE_CUDA**` compiler flag to switch between execution environments:
    **True** for GPU/CUDA execution space and **False** for CPU/serial execution space.
    The results of these experiments are presented below, with the corresponding speedup.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一台配有NVIDIA Quadro RTX 5000 GPU的TACC Frontera节点上执行了此内核实验。实验使用了不同的**N**值，**N**代表向量**y**和**x**的长度，以及矩阵**A**的行数。计算执行了100次以获得显著结果，并记录了内核在串行（主机）和CUDA执行空间中的执行时间。我使用了`**ENABLE_CUDA**`编译器标志在执行环境之间切换：**True**表示GPU/CUDA执行空间，**False**表示CPU/串行执行空间。以下展示了这些实验的结果及相应的加速比。
- en: 'Data on kernel execution runtime data and speedup for CPU vs GPU architecture
    Ref: Table by author'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有关CPU与GPU架构下内核执行时间和加速比的数据参考：作者提供的表格
- en: '![](../Images/29171354662a8b3bac463f48c99db523.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29171354662a8b3bac463f48c99db523.png)'
- en: 'Speedup trend for varying data size (GPU vs CPU) Ref: Image by author'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 不同数据大小下的加速比趋势（GPU vs CPU）参考：作者提供的图片
- en: We notice that the speedup increases significantly with the size of N, indicating
    that the CUDA implementation becomes increasingly advantageous for larger problem
    sizes.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，随着N值的增大，加速比显著增加，这表明CUDA实现对于较大规模的问题变得越来越有优势。
- en: That’s all for now! I hope this article has been helpful in getting started
    on the right foot in exploring the domain of computing. Understanding the basics
    of the GPU architecture is crucial, and this article introduces one way of writing
    cross-architectural code that I experimented with. However, there are several
    methods and technologies worth exploring.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止就这些！希望本文能在探索计算领域时为您提供一个良好的开端。理解GPU架构的基础至关重要，本文介绍了一种我实验过的跨架构代码编写方法。然而，还有多种值得探索的方法和技术。
- en: While I’m not a field expert, this article reflects my learning journey from
    my brief experience working at TACC in Austin, TX. I welcome feedback and discussions,
    and I would be happy to assist if you have any questions or want to learn more.
    Please refer to the excellent resources below for further learning. Happy computing!
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我不是该领域的专家，但本文反映了我在德州奥斯汀TACC短暂工作的学习经历。我欢迎反馈和讨论，如果您有任何问题或想了解更多内容，我很乐意提供帮助。请参考下面的优秀资源以进一步学习。祝计算愉快！
- en: Acknowledgments
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'This article draws from three primary sources. The first is the graduate-level
    course **SDS394: Scientific and Technical Computing at UT Austin**, which provided
    essential background knowledge on single-core multithreaded systems. The second
    is the [**Cornell Virtual Workshop: Parallel Programming Concepts and High Performance
    Computing**](https://cvw.cac.cornell.edu/parallel), an excellent resource for
    learning about parallel computing. The Kokkos code implementation is primarily
    based on materials available at [**Kokkos Tutorials on GitHub**](https://github.com/kokkos/kokkos-tutorials).
    These are all amazing resources for anyone interested in learning more about parallel
    computing.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '本文参考了三个主要来源。第一个来源是**SDS394: UT Austin的科学与技术计算研究生课程**，该课程提供了关于单核多线程系统的基础知识。第二个来源是[**Cornell虚拟工作坊：并行编程概念与高性能计算**](https://cvw.cac.cornell.edu/parallel)，这是一个关于并行计算的优秀学习资源。Kokkos代码实现主要基于[**GitHub上的Kokkos教程**](https://github.com/kokkos/kokkos-tutorials)中的材料。这些都是任何有兴趣学习并行计算的人的绝佳资源。'
- en: — — — — — — — — — —
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: — — — — — — — — — —
- en: The development of C++ Kokkos kernels for performance comparison across different
    architectures was part of a project supported by the **Intel OneAPI Center of
    Excellence** and the **TACC STAR Scholars program**, funded through generous contributions
    from TACC industry partners, including **Intel, Shell, Exxon,** and **Chevron**.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: C++ Kokkos内核的开发，用于在不同架构之间进行性能比较，作为由**Intel OneAPI卓越中心**和**TACC STAR学者计划**支持的项目的一部分，该项目得到了TACC行业合作伙伴的慷慨资助，其中包括**Intel、Shell、Exxon**和**Chevron**。
- en: — — — — — — — — — —
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: — — — — — — — — — —
- en: 'References/Resources:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 参考资料/资源：
- en: '[](https://github.com/VictorEijkhout/TheArtofHPC_pdfs/tree/main?source=post_page-----dd06e1f30586--------------------------------)
    [## GitHub - VictorEijkhout/TheArtofHPC_pdfs: All pdfs of Victor Eijkhout''s Art
    of HPC books and…'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/VictorEijkhout/TheArtofHPC_pdfs/tree/main?source=post_page-----dd06e1f30586--------------------------------)
    [## GitHub - VictorEijkhout/TheArtofHPC_pdfs：Victor Eijkhout《高性能计算艺术》书籍及课程的所有pdf]'
- en: All pdfs of Victor Eijkhout's Art of HPC books and courses - VictorEijkhout/TheArtofHPC_pdfs
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Victor Eijkhout《高性能计算艺术》书籍及课程的所有pdf - VictorEijkhout/TheArtofHPC_pdfs
- en: github.com](https://github.com/VictorEijkhout/TheArtofHPC_pdfs/tree/main?source=post_page-----dd06e1f30586--------------------------------)
    [](https://docs.tacc.utexas.edu/hpc/frontera/?source=post_page-----dd06e1f30586--------------------------------)
    [## Frontera - TACC HPC Documentation
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/VictorEijkhout/TheArtofHPC_pdfs/tree/main?source=post_page-----dd06e1f30586--------------------------------)
    [](https://docs.tacc.utexas.edu/hpc/frontera/?source=post_page-----dd06e1f30586--------------------------------)
    [## Frontera - TACC HPC文档]'
- en: 'Last update: October 24, 2024 Important: Please note TACC''s new SU charge
    policy. Frontera is funded by the National…'
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最近更新：2024年10月24日 重要提示：请注意TACC的新SU收费政策。Frontera由国家资助…
- en: 'docs.tacc.utexas.edu](https://docs.tacc.utexas.edu/hpc/frontera/?source=post_page-----dd06e1f30586--------------------------------)  [##
    Cornell Virtual Workshop: Parallel Programming Concepts and High Performance Computing'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[docs.tacc.utexas.edu](https://docs.tacc.utexas.edu/hpc/frontera/?source=post_page-----dd06e1f30586--------------------------------)
    [## 康奈尔虚拟研讨会：并行编程概念与高性能计算]'
- en: This roadmap explains parallel programming concepts, how parallel programming
    relates to high performance computing…
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本路线图解释了并行编程概念，以及并行编程如何与高性能计算相关……
- en: 'cvw.cac.cornell.edu](https://cvw.cac.cornell.edu/parallel?source=post_page-----dd06e1f30586--------------------------------)  [##
    Cornell Virtual Workshop: Understanding GPU Architecture'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[康奈尔虚拟研讨会：了解GPU架构](https://cvw.cac.cornell.edu/parallel?source=post_page-----dd06e1f30586--------------------------------)'
- en: This roadmap is intended for those who are relatively new to GPUs or who would
    like to learn more about computer technology that goes into them….
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本路线图面向那些相对较新的GPU使用者或希望深入了解其中的计算机技术的人员……
- en: 'cvw.cac.cornell.edu](https://cvw.cac.cornell.edu/gpu-architecture?source=post_page-----dd06e1f30586--------------------------------)  [##
    Cornell Virtual Workshop: Vectorization'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[cvw.cac.cornell.edu](https://cvw.cac.cornell.edu/gpu-architecture?source=post_page-----dd06e1f30586--------------------------------)
    [## 康奈尔虚拟研讨会：矢量化]'
- en: This roadmap describes the vectorization process as it relates to computing
    hardwares, compilers, and coding practices…
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本路线图描述了与计算硬件、编译器和编码实践相关的矢量化过程……
- en: 'cvw.cac.cornell.edu](https://cvw.cac.cornell.edu/vector?source=post_page-----dd06e1f30586--------------------------------)
    [](https://github.com/kokkos/kokkos-tutorials?source=post_page-----dd06e1f30586--------------------------------)
    [## GitHub — kokkos/kokkos-tutorials: Tutorials for the Kokkos C++ Performance
    Portability Programming…'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[cvw.cac.cornell.edu](https://cvw.cac.cornell.edu/vector?source=post_page-----dd06e1f30586--------------------------------)
    [](https://github.com/kokkos/kokkos-tutorials?source=post_page-----dd06e1f30586--------------------------------)
    [## GitHub — kokkos/kokkos-tutorials：Kokkos C++ 性能可移植性编程教程]'
- en: Tutorials for the Kokkos C++ Performance Portability Programming Ecosystem —
    kokkos/kokkos-tutorials
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos C++ 性能可移植性编程生态系统教程 — kokkos/kokkos-tutorials
- en: github.com](https://github.com/kokkos/kokkos-tutorials?source=post_page-----dd06e1f30586--------------------------------)
    [](https://github.com/kokkos/kokkos-tutorials/wiki/Kokkos-Lecture-Series?source=post_page-----dd06e1f30586--------------------------------)
    [## Kokkos Lecture Series
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/kokkos/kokkos-tutorials?source=post_page-----dd06e1f30586--------------------------------)
    [](https://github.com/kokkos/kokkos-tutorials/wiki/Kokkos-Lecture-Series?source=post_page-----dd06e1f30586--------------------------------)
    [## Kokkos讲座系列]'
- en: Tutorials for the Kokkos C++ Performance Portability Programming Ecosystem -
    Kokkos Lecture Series ·…
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kokkos C++ 性能可移植性编程生态系统教程 - Kokkos讲座系列 ·…
- en: github.com](https://github.com/kokkos/kokkos-tutorials/wiki/Kokkos-Lecture-Series?source=post_page-----dd06e1f30586--------------------------------)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/kokkos/kokkos-tutorials/wiki/Kokkos-Lecture-Series?source=post_page-----dd06e1f30586--------------------------------)'
