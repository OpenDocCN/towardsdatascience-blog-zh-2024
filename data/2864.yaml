- en: Explainable Generic ML Pipeline with MLflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯è§£é‡Šçš„é€šç”¨æœºå™¨å­¦ä¹ ç®¡é“ä¸MLflow
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26](https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26](https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26)
- en: An end-to-end demo to wrap a pre-processor and explainer into an algorithm-agnostic
    ML pipeline with `mlflow.pyfunc`
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç«¯åˆ°ç«¯çš„ç¤ºèŒƒï¼Œå°†é¢„å¤„ç†å™¨å’Œè§£é‡Šå™¨åŒ…è£…æˆä¸€ä¸ªç®—æ³•æ— å…³çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œä½¿ç”¨`mlflow.pyfunc`
- en: '[](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Mena
    Wang, PhD](../Images/eac9fa55026f9fc119bc868439ff311b.png)](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    [Mena Wang, PhD](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Mena
    Wang, PhD](../Images/eac9fa55026f9fc119bc868439ff311b.png)](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    [Mena Wang, PhD](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    Â·13 min readÂ·Nov 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    Â·13åˆ†é’Ÿé˜…è¯»Â·2024å¹´11æœˆ26æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/718ec8036048d1449b127442c59434ab.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/718ec8036048d1449b127442c59434ab.png)'
- en: Photo by [Hannah Murrell](https://unsplash.com/@hannahj236?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/person-holding-ball-focus-on-tree-pTfdcT0hxGc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Hannah Murrell](https://unsplash.com/@hannahj236?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    æä¾›ï¼Œæ¥æº [Unsplash](https://unsplash.com/photos/person-holding-ball-focus-on-tree-pTfdcT0hxGc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: '**Intro**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ä»‹ç»**'
- en: One common challenge in MLOps is the hassle of migrating between various algorithms
    or frameworks. To tackle the challenge, this is my second article on the topic
    of generic model building using `mlflow.pyfunc`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: MLOpsä¸­çš„ä¸€ä¸ªå¸¸è§æŒ‘æˆ˜æ˜¯è¿ç§»ä¸åŒç®—æ³•æˆ–æ¡†æ¶æ—¶çš„éº»çƒ¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿™æ˜¯æˆ‘å…³äºä½¿ç”¨`mlflow.pyfunc`è¿›è¡Œé€šç”¨æ¨¡å‹æ„å»ºçš„ç¬¬äºŒç¯‡æ–‡ç« ã€‚
- en: In my previous article, I offered a beginner-friendly step-by-step demo on creating
    a minimalist algorithm-agnostic model wrapper.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä¹‹å‰çš„æ–‡ç« ä¸­ï¼Œæˆ‘æä¾›äº†ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„é€æ­¥ç¤ºèŒƒï¼Œå±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªæç®€çš„ç®—æ³•æ— å…³æ¨¡å‹åŒ…è£…å™¨ã€‚
- en: '[](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
    [## Algorithm-Agnostic Model Building with MLflow'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
    [## ä½¿ç”¨MLflowè¿›è¡Œç®—æ³•æ— å…³æ¨¡å‹æ„å»º'
- en: A beginner-friendly step-by-step guide to creating generic ML pipelines using
    mlflow.pyfunc
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„é€æ­¥æŒ‡å—ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨mlflow.pyfuncåˆ›å»ºé€šç”¨æœºå™¨å­¦ä¹ ç®¡é“
- en: towardsdatascience.com](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
- en: 'To further our journey, by the end of this article, we will build a much more
    sophisticated ML pipeline with the below functionalities:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¨è¿›æˆ‘ä»¬çš„æ—…ç¨‹ï¼Œåœ¨æœ¬æ–‡ç»“æŸæ—¶ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ›´ä¸ºå¤æ‚çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå…·å¤‡ä»¥ä¸‹åŠŸèƒ½ï¼š
- en: This pipeline supports both classification (binary) and regression tasks. It
    works with scikit-learn models and other algorithms that follow the scikit-learn
    interface (i.e., fit, predict/predict_proba).
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯¥ç®¡é“æ”¯æŒåˆ†ç±»ï¼ˆäºŒåˆ†ç±»ï¼‰å’Œå›å½’ä»»åŠ¡ã€‚å®ƒé€‚ç”¨äºscikit-learnæ¨¡å‹ä»¥åŠå…¶ä»–éµå¾ªscikit-learnæ¥å£çš„ç®—æ³•ï¼ˆå³ï¼Œfitã€predict/predict_probaï¼‰ã€‚
- en: Incorporating a fully functional `Pre-Processor` that can be fitted on train
    data and then used to transform new data for model consumption. This pre-processor
    can handle both numeric and categorical features and handle missing values with
    various imputation strategies.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼•å…¥ä¸€ä¸ªåŠŸèƒ½å®Œå¤‡çš„`é¢„å¤„ç†å™¨`ï¼Œå®ƒå¯ä»¥åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆï¼Œç„¶åç”¨äºè½¬æ¢æ–°æ•°æ®ï¼Œä»¥ä¾›æ¨¡å‹ä½¿ç”¨ã€‚è¿™ä¸ªé¢„å¤„ç†å™¨å¯ä»¥å¤„ç†æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾ï¼Œå¹¶èƒ½é€šè¿‡å„ç§æ’è¡¥ç­–ç•¥å¤„ç†ç¼ºå¤±å€¼ã€‚
- en: Adding an `explainer` to shed light on the modelâ€™s reasoning, which is invaluable
    for model selection, monitoring and implementation. This task can be tricky due
    to the varying implementations of SHAP values across different ML algorithms.
    But, all good, we will address the challenge in this article. ğŸ˜
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ª`explainer`æ¥é˜æ˜æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œè¿™å¯¹äºæ¨¡å‹é€‰æ‹©ã€ç›‘æ§å’Œå®ç°è‡³å…³é‡è¦ã€‚ç”±äºä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•å¯¹SHAPå€¼çš„å®ç°å„å¼‚ï¼Œè¿™é¡¹ä»»åŠ¡å¯èƒ½ä¼šå¾ˆæ£˜æ‰‹ã€‚ä½†æ²¡é—®é¢˜ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­è§£å†³è¿™ä¸ªæŒ‘æˆ˜ã€‚ğŸ˜
- en: Consistent with the previous article,
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å‰ä¸€ç¯‡æ–‡ç« ä¸€è‡´ï¼Œ
- en: You will see how easy it is to switch between different customized pre-processors,
    similar to switching between various ML algorithms.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å°†çœ‹åˆ°åˆ‡æ¢ä¸åŒè‡ªå®šä¹‰é¢„å¤„ç†å™¨æ˜¯å¤šä¹ˆç®€å•ï¼Œç±»ä¼¼äºåˆ‡æ¢ä¸åŒçš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚
- en: This ML pipeline then encapsulates any customized pipeline elements under the
    hood, yet still offers a unified model representation in `pyfunc` flavour to simplify
    model deployment, redeployment, and downstream scoring.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæœºå™¨å­¦ä¹ ç®¡é“å°†æ‰€æœ‰è‡ªå®šä¹‰çš„ç®¡é“å…ƒç´ å°è£…åœ¨èƒŒåï¼ŒåŒæ—¶ä»ç„¶æä¾›ç»Ÿä¸€çš„`pyfunc`æ¨¡å‹è¡¨ç¤ºï¼Œä»¥ç®€åŒ–æ¨¡å‹çš„éƒ¨ç½²ã€é‡æ–°éƒ¨ç½²å’Œä¸‹æ¸¸è¯„åˆ†ã€‚
- en: ğŸ”— All code and config are available [on GitHub](https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_pipeline.ipynb).
    ğŸ§°
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”— æ‰€æœ‰ä»£ç å’Œé…ç½®å¯ä»¥åœ¨[GitHub](https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_pipeline.ipynb)ä¸Šæ‰¾åˆ°ã€‚ğŸ§°
- en: '**The Pre-Processor (V1)**'
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**é¢„å¤„ç†å™¨ï¼ˆV1ï¼‰**'
- en: Many machine learning algorithms â€” such as linear models (e.g., linear regression,
    SVM), distance-based models (e.g., KNN, PCA), and gradient-based models (e.g.,
    gradient boosting methods or gradient descent optimization) â€” tend to perform
    better with scaled input features, because scaling prevents features with larger
    ranges from dominating the learning process. Additionally, real-world data often
    contains missing values. Therefore, in this first iteration, we will build a pre-processor
    that can be trained to scale new data and impute missing values, preparing it
    for model consumption.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•â€”â€”ä¾‹å¦‚çº¿æ€§æ¨¡å‹ï¼ˆå¦‚çº¿æ€§å›å½’ã€æ”¯æŒå‘é‡æœºï¼‰ã€åŸºäºè·ç¦»çš„æ¨¡å‹ï¼ˆå¦‚KNNã€PCAï¼‰ä»¥åŠåŸºäºæ¢¯åº¦çš„æ¨¡å‹ï¼ˆå¦‚æ¢¯åº¦æå‡æ–¹æ³•æˆ–æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼‰â€”â€”é€šå¸¸åœ¨å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œç¼©æ”¾åè¡¨ç°æ›´å¥½ï¼Œå› ä¸ºç¼©æ”¾å¯ä»¥é˜²æ­¢å…·æœ‰è¾ƒå¤§èŒƒå›´çš„ç‰¹å¾ä¸»å¯¼å­¦ä¹ è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç°å®ä¸–ç•Œä¸­çš„æ•°æ®é€šå¸¸åŒ…å«ç¼ºå¤±å€¼ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªç¬¬ä¸€ç‰ˆä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªé¢„å¤„ç†å™¨ï¼Œå®ƒå¯ä»¥è®­ç»ƒæ¥ç¼©æ”¾æ–°æ•°æ®å¹¶å¡«å……ç¼ºå¤±å€¼ï¼Œä¸ºæ¨¡å‹çš„ä½¿ç”¨åšå‡†å¤‡ã€‚
- en: Once this pre-processor is built, I will then demo how to easily plug it into
    `pyfunc` ML pipeline. Sounds good? Letâ€™s go. ğŸ¤ 
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è¿™ä¸ªé¢„å¤„ç†å™¨æ„å»ºå®Œæˆï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•è½»æ¾åœ°å°†å®ƒé›†æˆåˆ°`pyfunc`æœºå™¨å­¦ä¹ ç®¡é“ä¸­ã€‚å¬èµ·æ¥ä¸é”™å§ï¼Ÿæˆ‘ä»¬å¼€å§‹å§ã€‚ğŸ¤ 
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This pre-processor can be fitted on train data and then used to process any
    new data. It will become an element in the ML pipeline below, but of course, we
    can use or test it independently. Letâ€™s create a synthetic dataset and use the
    pre-processor to transform it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé¢„å¤„ç†å™¨å¯ä»¥åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œæ‹Ÿåˆï¼Œç„¶åç”¨äºå¤„ç†ä»»ä½•æ–°çš„æ•°æ®ã€‚å®ƒå°†æˆä¸ºä¸‹é¢æœºå™¨å­¦ä¹ ç®¡é“ä¸­çš„ä¸€ä¸ªå…ƒç´ ï¼Œä½†å½“ç„¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç‹¬ç«‹ä½¿ç”¨æˆ–æµ‹è¯•å®ƒã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåˆæˆæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨é¢„å¤„ç†å™¨æ¥è½¬æ¢å®ƒã€‚
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Below are screenshots from {sweetViz} reports before vs after scaling; you can
    see that scaling didnâ€™t change the underlying shape of each featureâ€™s distribution
    but simply rescaled and shifted it. BTW, it takes two lines to generate a pretty
    comprehensive EDA report with {sweetViz}, code available in the GitHub repo linked
    above. ğŸ¥‚
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯{sweetViz}æŠ¥å‘Šåœ¨ç¼©æ”¾å‰åçš„æˆªå›¾ï¼›ä½ å¯ä»¥çœ‹åˆ°ï¼Œç¼©æ”¾æ²¡æœ‰æ”¹å˜æ¯ä¸ªç‰¹å¾åˆ†å¸ƒçš„åŸºæœ¬å½¢çŠ¶ï¼Œåªæ˜¯é‡æ–°ç¼©æ”¾å¹¶ç§»åŠ¨äº†å®ƒã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œåªéœ€è¦ä¸¤è¡Œä»£ç å°±èƒ½ç”Ÿæˆä¸€ä»½éå¸¸å…¨é¢çš„EDAæŠ¥å‘Šï¼Œ{sweetViz}çš„ä»£ç å¯ä»¥åœ¨ä¸Šé¢é“¾æ¥çš„GitHubä»“åº“ä¸­æ‰¾åˆ°ã€‚ğŸ¥‚
- en: '![](../Images/7a1b3029a4739afeff34a9d50170c3d3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1b3029a4739afeff34a9d50170c3d3.png)'
- en: Screenshots from SweetViz reports before vs after preprocessing
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†å‰åSweetVizæŠ¥å‘Šçš„æˆªå›¾
- en: '**ML Pipeline with Pre-Processor**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å¸¦é¢„å¤„ç†å™¨çš„æœºå™¨å­¦ä¹ ç®¡é“**'
- en: Now, let's create an ML pipeline in the `mlflow.pyfunc` flavour that can encapsulate
    this preprocessor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`mlflow.pyfunc`é£æ ¼çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå®ƒå¯ä»¥å°è£…è¿™ä¸ªé¢„å¤„ç†å™¨ã€‚
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The ML pipeline defined above takes the preprocessor and ML algorithm as parameters.
    Usage example below
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢å®šä¹‰çš„æœºå™¨å­¦ä¹ ç®¡é“å°†é¢„å¤„ç†å™¨å’Œæœºå™¨å­¦ä¹ ç®—æ³•ä½œä¸ºå‚æ•°ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ç¤ºä¾‹
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It is as simple as that! ğŸ‰ If you want to experiment with another algorithm,
    just swap it like shown below. As a wrapper, it can encapsulate both regression
    and classification algorithms. For the latter, predicted probabilities are returned,
    as shown in the example above.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™ä¹ˆç®€å•ï¼ğŸ‰ å¦‚æœä½ æƒ³å°è¯•å…¶ä»–ç®—æ³•ï¼Œåªéœ€åƒä¸‹é¢ä¸€æ ·äº¤æ¢å³å¯ã€‚ä½œä¸ºåŒ…è£…å™¨ï¼Œå®ƒå¯ä»¥å°è£…å›å½’å’Œåˆ†ç±»ç®—æ³•ã€‚å¯¹äºåè€…ï¼Œå°†è¿”å›é¢„æµ‹çš„æ¦‚ç‡ï¼Œå¦‚ä¸Šä¾‹æ‰€ç¤ºã€‚
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you can see from the code chunk below, passing hyperparameters to the algorithms
    is easy, making this ML pipeline a perfect instrument for hyperparameter tuning.
    I will elaborate on this topic in the following articles.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹æ–¹ä»£ç ç‰‡æ®µæ‰€ç¤ºï¼Œå‘ç®—æ³•ä¼ é€’è¶…å‚æ•°éå¸¸ç®€å•ï¼Œè¿™ä½¿å¾—è¯¥MLç®¡é“æˆä¸ºè¶…å‚æ•°è°ƒä¼˜çš„å®Œç¾å·¥å…·ã€‚æˆ‘å°†åœ¨åç»­çš„æ–‡ç« ä¸­è¯¦ç»†è®²è§£è¿™ä¸ªè¯é¢˜ã€‚
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Because this ml pipeline is built in the `mlflow.pyfunc` flavour. We can log
    it with rich metadata saved automatically by `mlflow` for downstream use. When
    deployed, we can feed the metadata as `context` for the model in the `predict`
    function as shown below. More info and demos are available in my previous article,
    which is linked at the beginning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºè¿™ä¸ªMLç®¡é“æ˜¯åŸºäº`mlflow.pyfunc`ç‰ˆæœ¬æ„å»ºçš„ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`mlflow`è‡ªåŠ¨ä¿å­˜çš„ä¸°å¯Œå…ƒæ•°æ®è¿›è¡Œæ—¥å¿—è®°å½•ï¼Œä¾›ä¸‹æ¸¸ä½¿ç”¨ã€‚éƒ¨ç½²åï¼Œæˆ‘ä»¬å¯ä»¥å°†å…ƒæ•°æ®ä½œä¸º`context`ä¼ é€’ç»™æ¨¡å‹ï¼Œåœ¨`predict`å‡½æ•°ä¸­ä½¿ç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚æ›´å¤šä¿¡æ¯å’Œæ¼”ç¤ºå¯ä»¥åœ¨æˆ‘ä¹‹å‰çš„æ–‡ç« ä¸­æ‰¾åˆ°ï¼Œé“¾æ¥å·²åœ¨æ–‡ä¸­ç»™å‡ºã€‚
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Pre-Processor (V2)
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†å™¨ï¼ˆV2ï¼‰
- en: The above pre-processor has worked well so far, but letâ€™s improve it in two
    ways below and then demonstrate how to swap between pre-processors easily.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„é¢„å¤„ç†å™¨åˆ°ç›®å‰ä¸ºæ­¢è¡¨ç°è‰¯å¥½ï¼Œä½†æˆ‘ä»¬å°†é€šè¿‡ä¸‹é¢çš„ä¸¤ç§æ–¹å¼è¿›è¡Œæ”¹è¿›ï¼Œç„¶åå±•ç¤ºå¦‚ä½•è½»æ¾åˆ‡æ¢é¢„å¤„ç†å™¨ã€‚
- en: Allow users to customize the pre-processing process. For instance, to specify
    the impute strategy.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å…è®¸ç”¨æˆ·è‡ªå®šä¹‰é¢„å¤„ç†è¿‡ç¨‹ã€‚ä¾‹å¦‚ï¼ŒæŒ‡å®šå¡«å……ç­–ç•¥ã€‚
- en: Expand pre-processor capacity to handle categorical features.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰©å±•é¢„å¤„ç†å™¨çš„èƒ½åŠ›ï¼Œä»¥å¤„ç†ç±»åˆ«ç‰¹å¾ã€‚
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Easy Switch of Custom Pre-Processors**'
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**è‡ªå®šä¹‰é¢„å¤„ç†å™¨çš„è½»æ¾åˆ‡æ¢**'
- en: 'There you have it: a new preprocessor that is 1) more customizable and 2) handles
    both numerical and categorical features. Letâ€™s define an ML pipeline instance
    with it.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ï¼šä¸€ä¸ªæ–°çš„é¢„å¤„ç†å™¨ï¼Œå®ƒ 1ï¼‰æ›´åŠ å¯å®šåˆ¶ï¼Œ2ï¼‰èƒ½å¤Ÿå¤„ç†æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾ã€‚è®©æˆ‘ä»¬ç”¨å®ƒå®šä¹‰ä¸€ä¸ªMLç®¡é“å®ä¾‹ã€‚
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Letâ€™s test this new ML pipeline instance with another synthetic dataset containing
    both numerical and categorical features.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨å¦ä¸€ä¸ªåŒ…å«æ•°å€¼ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾çš„åˆæˆæ•°æ®é›†æµ‹è¯•è¿™ä¸ªæ–°çš„MLç®¡é“å®ä¾‹ã€‚
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There you have itâ€”the ML pipeline runs smoothly with the new data. As expected,
    however, if we define the ML pipeline with the previous preprocessor and then
    run it on this dataset, we will encounter errors because the previous preprocessor
    was not designed to handle categorical features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·â€”â€”è¿™ä¸ªMLç®¡é“åœ¨æ–°æ•°æ®ä¸Šè¿è¡Œé¡ºåˆ©ã€‚ç„¶è€Œï¼Œæ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œå¦‚æœæˆ‘ä»¬ç”¨ä¹‹å‰çš„é¢„å¤„ç†å™¨å®šä¹‰MLç®¡é“ï¼Œç„¶ååœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¿è¡Œå®ƒï¼Œæˆ‘ä»¬å°†é‡åˆ°é”™è¯¯ï¼Œå› ä¸ºä¹‹å‰çš„é¢„å¤„ç†å™¨å¹¶æ²¡æœ‰è®¾è®¡æ¥å¤„ç†ç±»åˆ«ç‰¹å¾ã€‚
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Benefit of An Explainable ML Pipeline
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯è§£é‡Šçš„MLç®¡é“çš„å¥½å¤„
- en: 'Adding an explainer to an ML pipeline can be super helpful in several ways:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨MLç®¡é“ä¸­æ·»åŠ è§£é‡Šå™¨åœ¨å¤šä¸ªæ–¹é¢éƒ½éå¸¸æœ‰å¸®åŠ©ï¼š
- en: '**Model Selection**: It helps us select the best model by evaluating the soundness
    of its reasoning. Two algorithms may perform similarly on metrics like AUC or
    precision, but the key features they rely on may differ. Reviewing model reasoning
    with domain experts to discuss which model makes more sense in such scenarios
    is a good idea.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹é€‰æ‹©**ï¼šé€šè¿‡è¯„ä¼°æ¨¡å‹æ¨ç†çš„åˆç†æ€§ï¼Œå®ƒæœ‰åŠ©äºæˆ‘ä»¬é€‰æ‹©æœ€ä½³æ¨¡å‹ã€‚ä¸¤ä¸ªç®—æ³•åœ¨åƒAUCæˆ–ç²¾åº¦è¿™æ ·çš„æŒ‡æ ‡ä¸Šå¯èƒ½è¡¨ç°ç›¸ä¼¼ï¼Œä½†å®ƒä»¬ä¾èµ–çš„å…³é”®ç‰¹å¾å¯èƒ½ä¸åŒã€‚ä¸é¢†åŸŸä¸“å®¶ä¸€èµ·å›é¡¾æ¨¡å‹çš„æ¨ç†ï¼Œè®¨è®ºåœ¨è¿™ç§æƒ…å†µä¸‹å“ªä¸ªæ¨¡å‹æ›´åˆç†æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚'
- en: '**Troubleshooting**: One helpful strategy for model improvement is to analyze
    the reasoning behind mistakes. For example, in classification problems, we can
    identify false positives where the model was most confident (i.e., produced the
    highest predicted possibilities) and investigate what went wrong in the reasoning
    and what key features contributed to the mistakes.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ•…éšœæ’é™¤**ï¼šä¸€ç§æœ‰åŠ©äºæ¨¡å‹æ”¹è¿›çš„ç­–ç•¥æ˜¯åˆ†æé”™è¯¯èƒŒåçš„æ¨ç†ã€‚ä¾‹å¦‚ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«å‡ºæ¨¡å‹æœ€æœ‰ä¿¡å¿ƒçš„å‡é˜³æ€§ï¼ˆå³é¢„æµ‹çš„å¯èƒ½æ€§æœ€é«˜ï¼‰ï¼Œå¹¶è°ƒæŸ¥æ¨ç†ä¸­å‡ºäº†ä»€ä¹ˆé—®é¢˜ï¼Œå“ªäº›å…³é”®ç‰¹å¾å¯¼è‡´äº†é”™è¯¯ã€‚'
- en: '**Model Monitoring**: Besides the typical monitoring elements such as data
    drift and performance metrics, it is informative to monitor model reasoning as
    well. If there is a significant shift in key features that drive the decisions
    made by a model in production, I want to be alerted.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹ç›‘æ§**ï¼šé™¤äº†æ•°æ®æ¼‚ç§»å’Œæ€§èƒ½æŒ‡æ ‡ç­‰å…¸å‹ç›‘æ§å…ƒç´ å¤–ï¼Œç›‘æ§æ¨¡å‹æ¨ç†åŒæ ·å…·æœ‰é‡è¦æ„ä¹‰ã€‚å¦‚æœç”Ÿäº§ä¸­é©±åŠ¨æ¨¡å‹å†³ç­–çš„å…³é”®ç‰¹å¾å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ”¶åˆ°è­¦æŠ¥ã€‚'
- en: '**Model Implementation**: In some scenarios, supplying model reasoning along
    with model predictions can be highly beneficial to our end users. For example,
    to help a customer service agent best retain a churning customer, we can provide
    the churn score alongside the customer features that contributed to this score.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹å®ç°**ï¼šåœ¨æŸäº›åœºæ™¯ä¸­ï¼Œæä¾›æ¨¡å‹æ¨ç†å’Œæ¨¡å‹é¢„æµ‹çš„ç»“åˆå¯¹äºæœ€ç»ˆç”¨æˆ·æ¥è¯´æ˜¯éå¸¸æœ‰ç›Šçš„ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†å¸®åŠ©å®¢æˆ·æœåŠ¡äººå‘˜æœ€æœ‰æ•ˆåœ°æŒ½ç•™æµå¤±å®¢æˆ·ï¼Œæˆ‘ä»¬å¯ä»¥æä¾›æµå¤±è¯„åˆ†ä»¥åŠè´¡çŒ®è¯¥è¯„åˆ†çš„å®¢æˆ·ç‰¹å¾ã€‚'
- en: Adding An Explainer to the ML Pipeline
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°†è§£é‡Šå™¨æ·»åŠ åˆ°æœºå™¨å­¦ä¹ ç®¡é“ä¸­
- en: Because our ML pipeline is algorithm agnostic, it is imperative that the explainer
    can also work across algorithms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç®¡é“æ˜¯ç®—æ³•æ— å…³çš„ï¼Œå› æ­¤è§£é‡Šå™¨ä¹Ÿå¿…é¡»èƒ½å¤Ÿè·¨ç®—æ³•å·¥ä½œã€‚
- en: SHAP (SHapley Additive exPlanations) values are an excellent choice for our
    purpose because they provide theoretically robust explanations based on game theory.
    They are designed to work consistently across algorithms, including both tree-based
    and non-tree-based models, with some approximations for the latter. Additionally,
    SHAP offers rich visualization capabilities and is widely regarded as an industry
    standard.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: SHAPï¼ˆShapleyåŠ æ€§è§£é‡Šï¼‰å€¼æ˜¯æˆ‘ä»¬ç›®çš„çš„ç†æƒ³é€‰æ‹©ï¼Œå› ä¸ºå®ƒä»¬åŸºäºåšå¼ˆè®ºæä¾›ç†è®ºä¸Šç¨³å¥çš„è§£é‡Šã€‚å®ƒä»¬è®¾è®¡ä¸Šèƒ½å¤Ÿåœ¨å„ç§ç®—æ³•ä¸­ä¸€è‡´å·¥ä½œï¼ŒåŒ…æ‹¬åŸºäºæ ‘çš„å’ŒéåŸºäºæ ‘çš„æ¨¡å‹ï¼Œå¯¹äºåè€…ä¼šæœ‰ä¸€äº›è¿‘ä¼¼ã€‚æ­¤å¤–ï¼ŒSHAPè¿˜æä¾›ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½ï¼Œå¹¶è¢«å¹¿æ³›è®¤ä¸ºæ˜¯è¡Œä¸šæ ‡å‡†ã€‚
- en: In the notebooks below, I have dug into the similarities and differences between
    SHAP implementations for various ML algorithms.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘æ·±å…¥æ¢è®¨äº†SHAPåœ¨å„ç§æœºå™¨å­¦ä¹ ç®—æ³•ä¸­çš„å®ç°çš„ç›¸ä¼¼æ€§ä¸å·®å¼‚ã€‚
- en: '[SHAP for regressor](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_regression.ipynb)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAPç”¨äºå›å½’æ¨¡å‹](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_regression.ipynb)'
- en: '[SHAP for XGBoost Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAPç”¨äºXGBooståˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb)'
- en: '[SHAP for RandomForest Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_RF_classification.ipynb)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAPç”¨äºéšæœºæ£®æ—åˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_RF_classification.ipynb)'
- en: '[SHAP for LightGBM Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_lightgbm_classification.ipynb)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAPç”¨äºLightGBMåˆ†ç±»å™¨](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_lightgbm_classification.ipynb)'
- en: To create a generic explainer for our ML pipeline, the key differences to address
    are
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä¸ºæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ ç®¡é“åˆ›å»ºä¸€ä¸ªé€šç”¨çš„è§£é‡Šå™¨ï¼Œéœ€è¦è§£å†³çš„å…³é”®å·®å¼‚æ˜¯
- en: '***1\. Whether the model is directly supported by*** `***shap.Explainer***`'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***1\. æ¨¡å‹æ˜¯å¦è¢«*** `***shap.Explainer***` ***ç›´æ¥æ”¯æŒ***'
- en: The model-specific SHAP explainers are significantly more efficient than the
    model-agnostic ones. Therefore, the approach we take here is
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å®šæ¨¡å‹çš„SHAPè§£é‡Šå™¨æ¯”æ¨¡å‹æ— å…³çš„è§£é‡Šå™¨æ›´é«˜æ•ˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé‡‡ç”¨çš„æ–¹æ³•æ˜¯
- en: first attempts to use the direct SHAP explainer for the model type,
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¦–å…ˆå°è¯•ä½¿ç”¨ç›´æ¥çš„SHAPè§£é‡Šå™¨æ¥é€‚åº”æ¨¡å‹ç±»å‹ï¼Œ
- en: If that fails, falls back to a model-agnostic explainer using the predict function.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™å¤±è´¥äº†ï¼Œåˆ™å›é€€åˆ°ä½¿ç”¨predictå‡½æ•°çš„æ¨¡å‹æ— å…³è§£é‡Šå™¨ã€‚
- en: '***2\. The shape of SHAP values***'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***2\. SHAPå€¼çš„å½¢çŠ¶***'
- en: For binary classification problems, SHAP values can come in two formats/shapes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºäºŒåˆ†ç±»é—®é¢˜ï¼ŒSHAPå€¼å¯ä»¥æœ‰ä¸¤ç§æ ¼å¼/å½¢çŠ¶ã€‚
- en: '**Format 1**: Only shows impact on positive class'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ¼å¼ 1**ï¼šä»…æ˜¾ç¤ºå¯¹æ­£ç±»çš„å½±å“'
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Format 2**: Shows impact on both classes'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ¼å¼ 2**ï¼šæ˜¾ç¤ºå¯¹ä¸¤ä¸ªç±»åˆ«çš„å½±å“'
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The explainer implementation below always shows the impact on the positive class.
    When the impact on both classes is available in SHAP values, it selects the ones
    on the positive class.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹çš„è§£é‡Šå™¨å®ç°æ€»æ˜¯å±•ç¤ºå¯¹æ­£ç±»çš„å½±å“ã€‚å½“SHAPå€¼ä¸­åŒæ—¶æœ‰æ­£ç±»å’Œè´Ÿç±»çš„å½±å“æ—¶ï¼Œå®ƒä¼šé€‰æ‹©æ­£ç±»çš„å½±å“ã€‚
- en: Please see the code below for the implementation of the approach discussed above.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è§ä¸‹é¢çš„ä»£ç ï¼Œäº†è§£ä¸Šè¿°æ–¹æ³•çš„å®ç°ã€‚
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, the updated ML pipeline instance can create explanatory graphs for you
    in just one line of code. ğŸ˜
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæ›´æ–°åçš„æœºå™¨å­¦ä¹ ç®¡é“å®ä¾‹å¯ä»¥é€šè¿‡ä¸€è¡Œä»£ç ä¸ºä½ åˆ›å»ºè§£é‡Šæ€§å›¾è¡¨ã€‚ğŸ˜
- en: '![](../Images/130400a4a9c80519ff731a20d3ede222.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/130400a4a9c80519ff731a20d3ede222.png)'
- en: SHAP plot for global explanation of the model
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºæ¨¡å‹å…¨å±€è§£é‡Šçš„SHAPå›¾
- en: '![](../Images/b20822a6bb527748b1849d31e4cb83d0.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b20822a6bb527748b1849d31e4cb83d0.png)'
- en: SHAP plot for local explanation of any specific case
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç‰¹å®šæ¡ˆä¾‹å±€éƒ¨è§£é‡Šçš„SHAPå›¾
- en: '**Log and Use the Model**'
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**è®°å½•å¹¶ä½¿ç”¨æ¨¡å‹**'
- en: Of course, you can log a trained ML pipeline using `mlflow` and enjoy all the
    metadata for model deployment and reproducibility. In the screenshot below, you
    can see that in addition to the pickled `pyfunc` model itself, the Python environment,
    metrics, and hyperparameters have all been logged in just a few lines of code
    below. To learn more, please refer to my previous article on `mlflow.pyfunc`,
    which is linked at the beginning.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œä½ å¯ä»¥ä½¿ç”¨`mlflow`è®°å½•è®­ç»ƒå¥½çš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œå¹¶äº«å—æ‰€æœ‰å…³äºæ¨¡å‹éƒ¨ç½²å’Œå¯é‡å¤æ€§çš„å…ƒæ•°æ®ã€‚åœ¨ä¸‹é¢çš„æˆªå›¾ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°ï¼Œé™¤äº†pickleä¿å­˜çš„`pyfunc`æ¨¡å‹æœ¬èº«ï¼ŒPythonç¯å¢ƒã€æŒ‡æ ‡å’Œè¶…å‚æ•°éƒ½å·²ç»åœ¨ä¸‹é¢çš„å‡ è¡Œä»£ç ä¸­è®°å½•ä¸‹æ¥äº†ã€‚æƒ³äº†è§£æ›´å¤šï¼Œè¯·å‚è€ƒæˆ‘ä¹‹å‰å…³äº`mlflow.pyfunc`çš„æ–‡ç« ï¼Œé“¾æ¥å·²åœ¨æ–‡ä¸­æåˆ°ã€‚
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/d1ce888009587f800ff1a165eb1fb61a.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1ce888009587f800ff1a165eb1fb61a.png)'
- en: Rich model metadata and artifacts logged with mlflow
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨mlflowè®°å½•ä¸°å¯Œçš„æ¨¡å‹å…ƒæ•°æ®å’Œå·¥ä»¶
- en: '**Conclusions & Next Steps**'
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç»“è®ºä¸ä¸‹ä¸€æ­¥**'
- en: This is it, a generic and explainable ML pipeline that works for both classification
    and regression algorithms. Take the code and extend it to suit your use case.
    ğŸ¤— If you find this useful, please give me a clap ğŸ‘ğŸ¥°
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ï¼Œä¸€ä¸ªé€šç”¨ä¸”å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ ç®¡é“ï¼Œé€‚ç”¨äºåˆ†ç±»å’Œå›å½’ç®—æ³•ã€‚æ‹¿èµ°ä»£ç å¹¶æ‰©å±•å®ƒä»¥é€‚åº”ä½ çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚ğŸ¤— å¦‚æœä½ è§‰å¾—è¿™ä¸ªæœ‰ç”¨ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ªæŒå£° ğŸ‘ğŸ¥°
- en: To further our journey on the `mlflow.pyfunc` series, below are some topics
    I am considering. Feel free to leave a comment and let me know what you would
    like to see. ğŸ¥°
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿›ä¸€æ­¥æ¨è¿›`mlflow.pyfunc`ç³»åˆ—çš„æ—…ç¨‹ï¼Œä»¥ä¸‹æ˜¯æˆ‘æ­£åœ¨è€ƒè™‘çš„ä¸€äº›è¯é¢˜ã€‚æ¬¢è¿ç•™è¨€å‘Šè¯‰æˆ‘ä½ å¸Œæœ›çœ‹åˆ°å“ªäº›å†…å®¹ã€‚ğŸ¥°
- en: Feature selection
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾é€‰æ‹©
- en: Hyperparameter tuning
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¶…å‚æ•°è°ƒä¼˜
- en: If instead of *choosing* between off-the-shelf algorithms, one decides to *ensemble*
    multiple algorithms or have highly customized solutions, they can still enjoy
    a generic model representation and seamless migration via `mlflow.pyfunc`.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸é€‰æ‹©åœ¨ç°æˆç®—æ³•ä¸­*æŒ‘é€‰*ä¸€ä¸ªï¼Œè€Œæ˜¯å†³å®š*é›†æˆ*å¤šä¸ªç®—æ³•æˆ–æ‹¥æœ‰é«˜åº¦å®šåˆ¶çš„è§£å†³æ–¹æ¡ˆï¼Œä»–ä»¬ä¾ç„¶å¯ä»¥äº«å—é€šç”¨æ¨¡å‹è¡¨ç¤ºå’Œé€šè¿‡`mlflow.pyfunc`çš„æ— ç¼è¿ç§»ã€‚
- en: Stay tuned and follow me on [Medium](https://menawang.medium.com/). ğŸ˜
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ•¬è¯·å…³æ³¨å¹¶åœ¨[Medium](https://menawang.medium.com/)ä¸Šå…³æ³¨æˆ‘ã€‚ğŸ˜
- en: ğŸ’¼[LinkedIn](https://www.linkedin.com/in/mena-ning-wang/) | ğŸ˜º[GitHub](https://github.com/MenaWANG)
    | ğŸ•Šï¸[Twitter/X](https://x.com/mena_wang)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¼[LinkedIn](https://www.linkedin.com/in/mena-ning-wang/) | ğŸ˜º[GitHub](https://github.com/MenaWANG)
    | ğŸ•Šï¸[Twitter/X](https://x.com/mena_wang)
- en: Unless otherwise noted, all images are by the author.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚
