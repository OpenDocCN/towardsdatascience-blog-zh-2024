- en: Explainable Generic ML Pipeline with MLflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释的通用机器学习管道与MLflow
- en: 原文：[https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26](https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26](https://towardsdatascience.com/explainable-generic-ml-pipeline-with-mlflow-2494ca1b3f96?source=collection_archive---------5-----------------------#2024-11-26)
- en: An end-to-end demo to wrap a pre-processor and explainer into an algorithm-agnostic
    ML pipeline with `mlflow.pyfunc`
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个端到端的示范，将预处理器和解释器包装成一个算法无关的机器学习管道，使用`mlflow.pyfunc`
- en: '[](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Mena
    Wang, PhD](../Images/eac9fa55026f9fc119bc868439ff311b.png)](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    [Mena Wang, PhD](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Mena
    Wang, PhD](../Images/eac9fa55026f9fc119bc868439ff311b.png)](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    [Mena Wang, PhD](https://menawang.medium.com/?source=post_page---byline--2494ca1b3f96--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    ·13 min read·Nov 26, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--2494ca1b3f96--------------------------------)
    ·13分钟阅读·2024年11月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/718ec8036048d1449b127442c59434ab.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/718ec8036048d1449b127442c59434ab.png)'
- en: Photo by [Hannah Murrell](https://unsplash.com/@hannahj236?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/person-holding-ball-focus-on-tree-pTfdcT0hxGc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Hannah Murrell](https://unsplash.com/@hannahj236?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    提供，来源 [Unsplash](https://unsplash.com/photos/person-holding-ball-focus-on-tree-pTfdcT0hxGc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
- en: '**Intro**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: One common challenge in MLOps is the hassle of migrating between various algorithms
    or frameworks. To tackle the challenge, this is my second article on the topic
    of generic model building using `mlflow.pyfunc`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps中的一个常见挑战是迁移不同算法或框架时的麻烦。为了解决这个问题，这是我关于使用`mlflow.pyfunc`进行通用模型构建的第二篇文章。
- en: In my previous article, I offered a beginner-friendly step-by-step demo on creating
    a minimalist algorithm-agnostic model wrapper.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的文章中，我提供了一个适合初学者的逐步示范，展示如何创建一个极简的算法无关模型包装器。
- en: '[](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
    [## Algorithm-Agnostic Model Building with MLflow'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
    [## 使用MLflow进行算法无关模型构建'
- en: A beginner-friendly step-by-step guide to creating generic ML pipelines using
    mlflow.pyfunc
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个适合初学者的逐步指南，展示如何使用mlflow.pyfunc创建通用机器学习管道
- en: towardsdatascience.com](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/algorithm-agnostic-model-building-with-mlflow-b106a5a29535?source=post_page-----2494ca1b3f96--------------------------------)
- en: 'To further our journey, by the end of this article, we will build a much more
    sophisticated ML pipeline with the below functionalities:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推进我们的旅程，在本文结束时，我们将构建一个更为复杂的机器学习管道，具备以下功能：
- en: This pipeline supports both classification (binary) and regression tasks. It
    works with scikit-learn models and other algorithms that follow the scikit-learn
    interface (i.e., fit, predict/predict_proba).
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该管道支持分类（二分类）和回归任务。它适用于scikit-learn模型以及其他遵循scikit-learn接口的算法（即，fit、predict/predict_proba）。
- en: Incorporating a fully functional `Pre-Processor` that can be fitted on train
    data and then used to transform new data for model consumption. This pre-processor
    can handle both numeric and categorical features and handle missing values with
    various imputation strategies.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 引入一个功能完备的`预处理器`，它可以在训练数据上拟合，然后用于转换新数据，以供模型使用。这个预处理器可以处理数值型和类别型特征，并能通过各种插补策略处理缺失值。
- en: Adding an `explainer` to shed light on the model’s reasoning, which is invaluable
    for model selection, monitoring and implementation. This task can be tricky due
    to the varying implementations of SHAP values across different ML algorithms.
    But, all good, we will address the challenge in this article. 😎
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个`explainer`来阐明模型的推理过程，这对于模型选择、监控和实现至关重要。由于不同机器学习算法对SHAP值的实现各异，这项任务可能会很棘手。但没问题，我们将在本文中解决这个挑战。😎
- en: Consistent with the previous article,
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一篇文章一致，
- en: You will see how easy it is to switch between different customized pre-processors,
    similar to switching between various ML algorithms.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到切换不同自定义预处理器是多么简单，类似于切换不同的机器学习算法。
- en: This ML pipeline then encapsulates any customized pipeline elements under the
    hood, yet still offers a unified model representation in `pyfunc` flavour to simplify
    model deployment, redeployment, and downstream scoring.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个机器学习管道将所有自定义的管道元素封装在背后，同时仍然提供统一的`pyfunc`模型表示，以简化模型的部署、重新部署和下游评分。
- en: 🔗 All code and config are available [on GitHub](https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_pipeline.ipynb).
    🧰
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 🔗 所有代码和配置可以在[GitHub](https://github.com/MenaWANG/mlflow-demo/blob/main/pyfunc_pipeline.ipynb)上找到。🧰
- en: '**The Pre-Processor (V1)**'
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**预处理器（V1）**'
- en: Many machine learning algorithms — such as linear models (e.g., linear regression,
    SVM), distance-based models (e.g., KNN, PCA), and gradient-based models (e.g.,
    gradient boosting methods or gradient descent optimization) — tend to perform
    better with scaled input features, because scaling prevents features with larger
    ranges from dominating the learning process. Additionally, real-world data often
    contains missing values. Therefore, in this first iteration, we will build a pre-processor
    that can be trained to scale new data and impute missing values, preparing it
    for model consumption.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法——例如线性模型（如线性回归、支持向量机）、基于距离的模型（如KNN、PCA）以及基于梯度的模型（如梯度提升方法或梯度下降优化）——通常在对输入特征进行缩放后表现更好，因为缩放可以防止具有较大范围的特征主导学习过程。此外，现实世界中的数据通常包含缺失值。因此，在这个第一版中，我们将构建一个预处理器，它可以训练来缩放新数据并填充缺失值，为模型的使用做准备。
- en: Once this pre-processor is built, I will then demo how to easily plug it into
    `pyfunc` ML pipeline. Sounds good? Let’s go. 🤠
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个预处理器构建完成，我将演示如何轻松地将它集成到`pyfunc`机器学习管道中。听起来不错吧？我们开始吧。🤠
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This pre-processor can be fitted on train data and then used to process any
    new data. It will become an element in the ML pipeline below, but of course, we
    can use or test it independently. Let’s create a synthetic dataset and use the
    pre-processor to transform it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预处理器可以在训练数据上进行拟合，然后用于处理任何新的数据。它将成为下面机器学习管道中的一个元素，但当然，我们也可以独立使用或测试它。让我们创建一个合成数据集，并使用预处理器来转换它。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Below are screenshots from {sweetViz} reports before vs after scaling; you can
    see that scaling didn’t change the underlying shape of each feature’s distribution
    but simply rescaled and shifted it. BTW, it takes two lines to generate a pretty
    comprehensive EDA report with {sweetViz}, code available in the GitHub repo linked
    above. 🥂
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是{sweetViz}报告在缩放前后的截图；你可以看到，缩放没有改变每个特征分布的基本形状，只是重新缩放并移动了它。顺便说一下，只需要两行代码就能生成一份非常全面的EDA报告，{sweetViz}的代码可以在上面链接的GitHub仓库中找到。🥂
- en: '![](../Images/7a1b3029a4739afeff34a9d50170c3d3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a1b3029a4739afeff34a9d50170c3d3.png)'
- en: Screenshots from SweetViz reports before vs after preprocessing
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理前后SweetViz报告的截图
- en: '**ML Pipeline with Pre-Processor**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**带预处理器的机器学习管道**'
- en: Now, let's create an ML pipeline in the `mlflow.pyfunc` flavour that can encapsulate
    this preprocessor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个`mlflow.pyfunc`风格的机器学习管道，它可以封装这个预处理器。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The ML pipeline defined above takes the preprocessor and ML algorithm as parameters.
    Usage example below
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上面定义的机器学习管道将预处理器和机器学习算法作为参数。以下是使用示例
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It is as simple as that! 🎉 If you want to experiment with another algorithm,
    just swap it like shown below. As a wrapper, it can encapsulate both regression
    and classification algorithms. For the latter, predicted probabilities are returned,
    as shown in the example above.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这么简单！🎉 如果你想尝试其他算法，只需像下面一样交换即可。作为包装器，它可以封装回归和分类算法。对于后者，将返回预测的概率，如上例所示。
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you can see from the code chunk below, passing hyperparameters to the algorithms
    is easy, making this ML pipeline a perfect instrument for hyperparameter tuning.
    I will elaborate on this topic in the following articles.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如下方代码片段所示，向算法传递超参数非常简单，这使得该ML管道成为超参数调优的完美工具。我将在后续的文章中详细讲解这个话题。
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Because this ml pipeline is built in the `mlflow.pyfunc` flavour. We can log
    it with rich metadata saved automatically by `mlflow` for downstream use. When
    deployed, we can feed the metadata as `context` for the model in the `predict`
    function as shown below. More info and demos are available in my previous article,
    which is linked at the beginning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个ML管道是基于`mlflow.pyfunc`版本构建的。我们可以使用`mlflow`自动保存的丰富元数据进行日志记录，供下游使用。部署后，我们可以将元数据作为`context`传递给模型，在`predict`函数中使用，如下所示。更多信息和演示可以在我之前的文章中找到，链接已在文中给出。
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Pre-Processor (V2)
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理器（V2）
- en: The above pre-processor has worked well so far, but let’s improve it in two
    ways below and then demonstrate how to swap between pre-processors easily.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的预处理器到目前为止表现良好，但我们将通过下面的两种方式进行改进，然后展示如何轻松切换预处理器。
- en: Allow users to customize the pre-processing process. For instance, to specify
    the impute strategy.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 允许用户自定义预处理过程。例如，指定填充策略。
- en: Expand pre-processor capacity to handle categorical features.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展预处理器的能力，以处理类别特征。
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Easy Switch of Custom Pre-Processors**'
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**自定义预处理器的轻松切换**'
- en: 'There you have it: a new preprocessor that is 1) more customizable and 2) handles
    both numerical and categorical features. Let’s define an ML pipeline instance
    with it.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样：一个新的预处理器，它 1）更加可定制，2）能够处理数值特征和类别特征。让我们用它定义一个ML管道实例。
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s test this new ML pipeline instance with another synthetic dataset containing
    both numerical and categorical features.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用另一个包含数值特征和类别特征的合成数据集测试这个新的ML管道实例。
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There you have it—the ML pipeline runs smoothly with the new data. As expected,
    however, if we define the ML pipeline with the previous preprocessor and then
    run it on this dataset, we will encounter errors because the previous preprocessor
    was not designed to handle categorical features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样——这个ML管道在新数据上运行顺利。然而，正如预期的那样，如果我们用之前的预处理器定义ML管道，然后在这个数据集上运行它，我们将遇到错误，因为之前的预处理器并没有设计来处理类别特征。
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Benefit of An Explainable ML Pipeline
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释的ML管道的好处
- en: 'Adding an explainer to an ML pipeline can be super helpful in several ways:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML管道中添加解释器在多个方面都非常有帮助：
- en: '**Model Selection**: It helps us select the best model by evaluating the soundness
    of its reasoning. Two algorithms may perform similarly on metrics like AUC or
    precision, but the key features they rely on may differ. Reviewing model reasoning
    with domain experts to discuss which model makes more sense in such scenarios
    is a good idea.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型选择**：通过评估模型推理的合理性，它有助于我们选择最佳模型。两个算法在像AUC或精度这样的指标上可能表现相似，但它们依赖的关键特征可能不同。与领域专家一起回顾模型的推理，讨论在这种情况下哪个模型更合理是一个好主意。'
- en: '**Troubleshooting**: One helpful strategy for model improvement is to analyze
    the reasoning behind mistakes. For example, in classification problems, we can
    identify false positives where the model was most confident (i.e., produced the
    highest predicted possibilities) and investigate what went wrong in the reasoning
    and what key features contributed to the mistakes.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**故障排除**：一种有助于模型改进的策略是分析错误背后的推理。例如，在分类问题中，我们可以识别出模型最有信心的假阳性（即预测的可能性最高），并调查推理中出了什么问题，哪些关键特征导致了错误。'
- en: '**Model Monitoring**: Besides the typical monitoring elements such as data
    drift and performance metrics, it is informative to monitor model reasoning as
    well. If there is a significant shift in key features that drive the decisions
    made by a model in production, I want to be alerted.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型监控**：除了数据漂移和性能指标等典型监控元素外，监控模型推理同样具有重要意义。如果生产中驱动模型决策的关键特征发生了显著变化，我希望能够收到警报。'
- en: '**Model Implementation**: In some scenarios, supplying model reasoning along
    with model predictions can be highly beneficial to our end users. For example,
    to help a customer service agent best retain a churning customer, we can provide
    the churn score alongside the customer features that contributed to this score.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型实现**：在某些场景中，提供模型推理和模型预测的结合对于最终用户来说是非常有益的。例如，为了帮助客户服务人员最有效地挽留流失客户，我们可以提供流失评分以及贡献该评分的客户特征。'
- en: Adding An Explainer to the ML Pipeline
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将解释器添加到机器学习管道中
- en: Because our ML pipeline is algorithm agnostic, it is imperative that the explainer
    can also work across algorithms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的机器学习管道是算法无关的，因此解释器也必须能够跨算法工作。
- en: SHAP (SHapley Additive exPlanations) values are an excellent choice for our
    purpose because they provide theoretically robust explanations based on game theory.
    They are designed to work consistently across algorithms, including both tree-based
    and non-tree-based models, with some approximations for the latter. Additionally,
    SHAP offers rich visualization capabilities and is widely regarded as an industry
    standard.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP（Shapley加性解释）值是我们目的的理想选择，因为它们基于博弈论提供理论上稳健的解释。它们设计上能够在各种算法中一致工作，包括基于树的和非基于树的模型，对于后者会有一些近似。此外，SHAP还提供丰富的可视化功能，并被广泛认为是行业标准。
- en: In the notebooks below, I have dug into the similarities and differences between
    SHAP implementations for various ML algorithms.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的笔记本中，我深入探讨了SHAP在各种机器学习算法中的实现的相似性与差异。
- en: '[SHAP for regressor](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_regression.ipynb)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP用于回归模型](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_regression.ipynb)'
- en: '[SHAP for XGBoost Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP用于XGBoost分类器](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb)'
- en: '[SHAP for RandomForest Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_RF_classification.ipynb)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP用于随机森林分类器](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_basic_RF_classification.ipynb)'
- en: '[SHAP for LightGBM Classifier](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_lightgbm_classification.ipynb)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP用于LightGBM分类器](https://github.com/MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_lightgbm_classification.ipynb)'
- en: To create a generic explainer for our ML pipeline, the key differences to address
    are
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要为我们的机器学习管道创建一个通用的解释器，需要解决的关键差异是
- en: '***1\. Whether the model is directly supported by*** `***shap.Explainer***`'
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***1\. 模型是否被*** `***shap.Explainer***` ***直接支持***'
- en: The model-specific SHAP explainers are significantly more efficient than the
    model-agnostic ones. Therefore, the approach we take here is
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 特定模型的SHAP解释器比模型无关的解释器更高效。因此，我们在这里采用的方法是
- en: first attempts to use the direct SHAP explainer for the model type,
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先尝试使用直接的SHAP解释器来适应模型类型，
- en: If that fails, falls back to a model-agnostic explainer using the predict function.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果这失败了，则回退到使用predict函数的模型无关解释器。
- en: '***2\. The shape of SHAP values***'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***2\. SHAP值的形状***'
- en: For binary classification problems, SHAP values can come in two formats/shapes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类问题，SHAP值可以有两种格式/形状。
- en: '**Format 1**: Only shows impact on positive class'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式 1**：仅显示对正类的影响'
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Format 2**: Shows impact on both classes'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式 2**：显示对两个类别的影响'
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The explainer implementation below always shows the impact on the positive class.
    When the impact on both classes is available in SHAP values, it selects the ones
    on the positive class.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下的解释器实现总是展示对正类的影响。当SHAP值中同时有正类和负类的影响时，它会选择正类的影响。
- en: Please see the code below for the implementation of the approach discussed above.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见下面的代码，了解上述方法的实现。
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, the updated ML pipeline instance can create explanatory graphs for you
    in just one line of code. 😎
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，更新后的机器学习管道实例可以通过一行代码为你创建解释性图表。😎
- en: '![](../Images/130400a4a9c80519ff731a20d3ede222.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/130400a4a9c80519ff731a20d3ede222.png)'
- en: SHAP plot for global explanation of the model
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 用于模型全局解释的SHAP图
- en: '![](../Images/b20822a6bb527748b1849d31e4cb83d0.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b20822a6bb527748b1849d31e4cb83d0.png)'
- en: SHAP plot for local explanation of any specific case
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 用于特定案例局部解释的SHAP图
- en: '**Log and Use the Model**'
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**记录并使用模型**'
- en: Of course, you can log a trained ML pipeline using `mlflow` and enjoy all the
    metadata for model deployment and reproducibility. In the screenshot below, you
    can see that in addition to the pickled `pyfunc` model itself, the Python environment,
    metrics, and hyperparameters have all been logged in just a few lines of code
    below. To learn more, please refer to my previous article on `mlflow.pyfunc`,
    which is linked at the beginning.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以使用`mlflow`记录训练好的机器学习管道，并享受所有关于模型部署和可重复性的元数据。在下面的截图中，你可以看到，除了pickle保存的`pyfunc`模型本身，Python环境、指标和超参数都已经在下面的几行代码中记录下来了。想了解更多，请参考我之前关于`mlflow.pyfunc`的文章，链接已在文中提到。
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/d1ce888009587f800ff1a165eb1fb61a.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1ce888009587f800ff1a165eb1fb61a.png)'
- en: Rich model metadata and artifacts logged with mlflow
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用mlflow记录丰富的模型元数据和工件
- en: '**Conclusions & Next Steps**'
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论与下一步**'
- en: This is it, a generic and explainable ML pipeline that works for both classification
    and regression algorithms. Take the code and extend it to suit your use case.
    🤗 If you find this useful, please give me a clap 👏🥰
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，一个通用且可解释的机器学习管道，适用于分类和回归算法。拿走代码并扩展它以适应你的使用案例。🤗 如果你觉得这个有用，请给我一个掌声 👏🥰
- en: To further our journey on the `mlflow.pyfunc` series, below are some topics
    I am considering. Feel free to leave a comment and let me know what you would
    like to see. 🥰
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步推进`mlflow.pyfunc`系列的旅程，以下是我正在考虑的一些话题。欢迎留言告诉我你希望看到哪些内容。🥰
- en: Feature selection
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征选择
- en: Hyperparameter tuning
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数调优
- en: If instead of *choosing* between off-the-shelf algorithms, one decides to *ensemble*
    multiple algorithms or have highly customized solutions, they can still enjoy
    a generic model representation and seamless migration via `mlflow.pyfunc`.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不选择在现成算法中*挑选*一个，而是决定*集成*多个算法或拥有高度定制的解决方案，他们依然可以享受通用模型表示和通过`mlflow.pyfunc`的无缝迁移。
- en: Stay tuned and follow me on [Medium](https://menawang.medium.com/). 😁
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 敬请关注并在[Medium](https://menawang.medium.com/)上关注我。😁
- en: 💼[LinkedIn](https://www.linkedin.com/in/mena-ning-wang/) | 😺[GitHub](https://github.com/MenaWANG)
    | 🕊️[Twitter/X](https://x.com/mena_wang)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 💼[LinkedIn](https://www.linkedin.com/in/mena-ning-wang/) | 😺[GitHub](https://github.com/MenaWANG)
    | 🕊️[Twitter/X](https://x.com/mena_wang)
- en: Unless otherwise noted, all images are by the author.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供。
