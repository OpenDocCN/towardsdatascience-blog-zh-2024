- en: 'How to Make the Most Out of LLM Production Data: Simulated User Feedback'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何充分利用LLM生产数据：模拟用户反馈
- en: 原文：[https://towardsdatascience.com/how-to-make-the-most-out-of-llm-production-data-simulated-user-feedback-843c444febc7?source=collection_archive---------6-----------------------#2024-04-11](https://towardsdatascience.com/how-to-make-the-most-out-of-llm-production-data-simulated-user-feedback-843c444febc7?source=collection_archive---------6-----------------------#2024-04-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-make-the-most-out-of-llm-production-data-simulated-user-feedback-843c444febc7?source=collection_archive---------6-----------------------#2024-04-11](https://towardsdatascience.com/how-to-make-the-most-out-of-llm-production-data-simulated-user-feedback-843c444febc7?source=collection_archive---------6-----------------------#2024-04-11)
- en: A novel approach to use production data to simulate user feedback for testing
    and evaluating your LLM app
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种新颖的方法，通过使用生产数据来模拟用户反馈，以测试和评估您的LLM应用
- en: '[](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)[![Pasquale
    Antonante, Ph.D.](../Images/97733117413b3daeb79886e171ab30c9.png)](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)
    [Pasquale Antonante, Ph.D.](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)[![Pasquale
    Antonante, Ph.D.](../Images/97733117413b3daeb79886e171ab30c9.png)](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)
    [Pasquale Antonante, Ph.D.](https://medium.com/@pasquale_68605?source=post_page---byline--843c444febc7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)
    ·9 min read·Apr 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--843c444febc7--------------------------------)
    ·阅读时间9分钟·2024年4月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/17386b21ff3d693432dc70e815185505.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17386b21ff3d693432dc70e815185505.png)'
- en: Image by author and ChatGPT. “Image of two llamas, one with a thumbs up and
    another with thumbs down” prompt. ChatGPT, 4, OpenAI, April 10th 2024\. [https://chat.openai.com.](https://chat.openai.com./)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者和ChatGPT提供。“两只羊驼的图像，一只竖起大拇指，另一只竖起大拇指向下”提示。ChatGPT，4，OpenAI，2024年4月10日。[https://chat.openai.com.](https://chat.openai.com./)
- en: A series of blog posts to share our perspectives on how to evaluate and improve
    your GenAI application pipelines
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列博客文章，分享我们如何评估和改进您的GenAI应用管道的观点
- en: '*(written by Pasquale Antonante and Yi Zhang at Relari.ai)*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*(由Pasquale Antonante和Yi Zhang在Relari.ai撰写)*'
- en: The world of LLM app development is always on the move — new tricks, models,
    and apps pop up every week. As tech gets better, what users expect keeps ramping
    up. Staying ahead in this game is key to making sure it’s the one users keep coming
    back to.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应用开发的世界总是变化无常——每周都有新的技巧、模型和应用出现。随着技术的进步，用户的期望也在不断提高。保持领先地位是确保用户不断回归的关键。
- en: 'The problem now becomes: how do you measure performance improvements? When
    you’re fiddling with prompts, tweaking the temperature, or switching up models,
    do you ever pause and think, “Will my users actually like this more?”'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题变成了：如何衡量性能提升？当你调整提示、调整温度或更换模型时，你是否曾停下来思考过，“我的用户真的会更喜欢这个吗？”
- en: In this post, we’ll walk through how in-app user feedback from earlier deployments
    (or internal human evaluation) can be instrumental in quickly shaping future versions
    of a product. We’ll discuss the limitations of traditional feedback mechanisms
    and introduce a new technique that allows AI developers to use feedback data directly
    in offline testing and iterations (before a new deployment), making the development
    cycle more adaptable and responsive to user preferences.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将详细介绍如何利用早期部署中的应用内用户反馈（或内部人工评估）快速塑造产品的未来版本。我们将讨论传统反馈机制的局限性，并介绍一种新技术，使AI开发者能够直接在离线测试和迭代中使用反馈数据（在新的部署之前），从而使开发周期更加灵活，能够更好地响应用户偏好。
- en: Understanding the Value of User Feedback
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解用户反馈的价值
- en: Why User Feedback Matters and Its Challenges
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么用户反馈很重要以及它的挑战
- en: 'When developing LLM-based applications, we are often faced with a particular
    problem we want to address, *e.g.*, a specific type of question has a low accuracy.
    As we experiment with tweaks in prompts, parameters, architecture, etc., we want
    to evaluate performance of the new pipeline, in particular whether users will
    like the new version(s) of your AI application. The most straightforward way is
    to A/B test each change with the end users and collect their feedback data such
    as thumbs up / down, score rating, or written comments, but practically it is
    challenging for a few reasons:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发基于大语言模型（LLM）的应用程序时，我们常常会遇到一个特定的问题需要解决，*例如*，某种特定类型的问题准确度较低。当我们在调整提示语、参数、架构等方面进行实验时，我们希望评估新流程的表现，特别是用户是否会喜欢您应用程序的新版本。最直接的方式是通过A/B测试每个变化并收集用户的反馈数据，如点赞/点踩、评分或书面评论，但实际上，由于以下几个原因，这会面临一些挑战：
- en: '**Slow to collect:** Unless your application is already seeing huge volume,
    you don’t have that much feedback data. Anecdotally, we’ve seen the feedback participation
    rate in our customers’ AI applications range from <1% (normal) to ~10% (exceptional,
    often through deliberate UI/UX design to encourage more feedback). As a result,
    it can take a long time before you get enough feedback data to make a statistically
    confident judgment of whether a particular change resonated positively or negatively
    with your users.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集缓慢：**除非您的应用程序已经有了大量的用户流量，否则您无法获得太多的反馈数据。据我们的客户反馈，AI应用中的反馈参与率通常在<1%（正常）到~10%（优秀，通常通过精心设计的UI/UX来鼓励更多的反馈）之间。因此，可能需要很长时间才能收集到足够的反馈数据，从而做出统计学上可靠的判断，判断某个变化是否在用户中产生了积极或消极的反响。'
- en: '**Risk of jeopardizing user relationships:** Testing directly with users is
    the most effective way to gain insights, but there’s a real risk of damaging your
    relationship with them if they encounter an unsatisfactory version. Users can
    be quick to judge, potentially dismissing your application at the first sign of
    a mistake. Consequently, developers tend to opt for more conservative or less
    disruptive changes for A/B testing with users, reserving the bolder, more innovative
    updates for internal testing. This approach allows for experimentation while minimizing
    the risk of alienating the user base.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**破坏用户关系的风险：**直接与用户测试是获得洞察的最有效方式，但如果用户遇到不满意的版本，确实有破坏与他们关系的风险。用户判断可能非常迅速，可能会在出现错误的第一时间就放弃您的应用程序。因此，开发者往往选择更保守或影响较小的变化进行A/B测试，保留更大胆、更具创新性的更新供内部测试。这种方法既允许实验，又能最大程度地减少疏远用户群体的风险。'
- en: '**Inconsistent measurement:** With most AI applications being fairly open-ended,
    it is often difficult to get truly apples-to-apples comparison of feedback data
    given different users can interact with your product in a different way. As a
    result, feedback data A/B testing for LLM-based applications tends to be more
    noisy than those from traditional applications.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测量不一致：**由于大多数AI应用程序具有相当大的开放性，考虑到不同用户可能以不同的方式与您的产品互动，因此通常很难获得真正的“同类对比”的反馈数据。因此，基于LLM的应用程序的反馈数据A/B测试往往比传统应用程序的反馈数据更加嘈杂。'
- en: In the next section, we’ll introduce a novel approach that we’ve deployed to
    multiple customers to help them make the most out of their user feedback data
    in offline development.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍一种新颖的方法，已经被我们部署到多个客户身上，帮助他们在离线开发中充分利用用户反馈数据。
- en: 'A Novel Approach: Simulate User Feedback'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种新颖的方法：模拟用户反馈
- en: In response to these challenges in collecting user feedback, we have developed
    a novel approach to simulate user feedback using a small sample of user (or internally
    labeled) feedback data. Specifically, we use metric ensembling and conformal prediction
    to learn user preferences and use them offline during the development phase. At
    its core, we learn how users weigh different criteria (e.g., tone, conciseness,
    etc) and leverage conformal prediction to provide predictions to quantify confidence.
    This method drastically accelerates LLM app development by providing a way to
    anticipate how users might react to new features or changes before they are fully
    implemented.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些用户反馈收集的挑战，我们开发了一种新颖的方法，通过少量的用户（或内部标注的）反馈数据来模拟用户反馈。具体来说，我们使用度量集成和符合性预测来学习用户偏好，并在开发阶段离线使用它们。其核心是我们学习用户如何权衡不同的标准（例如语气、简洁性等），并利用符合性预测提供预测来量化信心。这种方法通过提供一种在完全实施新功能或更改之前预测用户可能反应的方式，极大地加速了LLM应用程序的开发。
- en: To evaluate its effectiveness, we compared this approach with the more conventional
    one of using a single LLM call that assesses different aspects of the response
    to make a judgment. To compare the two alternatives (the proposed approach vs.
    the single LLM call), we conducted an experiment using the [Unified-Feedback](https://huggingface.co/datasets/llm-blender/Unified-Feedback)
    dataset. We used Kendall’s tau, a measure of rank correlation, to compare the
    rankings produced by our user feedback simulation and the single LLM call approach
    against the ground truth established by human evaluations. This analysis allows
    us to assess not only the degree of agreement, but also the order of preference
    that each method predicts compared to the human rankings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估其有效性，我们将此方法与使用单一LLM调用来评估响应不同方面并做出判断的传统方法进行了比较。为了比较这两种方法（建议的方法与单一LLM调用），我们使用了[Unified-Feedback](https://huggingface.co/datasets/llm-blender/Unified-Feedback)数据集进行实验。我们使用Kendall
    tau这一排名相关性度量，比较了我们的用户反馈模拟和单一LLM调用方法产生的排名与由人工评估建立的真实排名。这一分析不仅帮助我们评估了各方法之间的一致性，还可以比较每种方法与人类排名的偏好顺序。
- en: '**Our experiment revealed that the user feedback simulation has a correlation
    of 93% that significantly exceeded that of the single LLM call approach, which
    attains roughly 70% correlation. This indicates that, in terms of ranking , the
    simulated user feedback simulation provides a closer approximation to human judgment.**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们的实验表明，用户反馈模拟与人类评判之间的相关性达到了93%，远远超过了单一LLM调用方法的约70%的相关性。这表明，在排名方面，模拟的用户反馈提供了更接近人类判断的近似结果。**'
- en: '![](../Images/60384adfaaf39c33f4a4ee9b84534c31.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60384adfaaf39c33f4a4ee9b84534c31.png)'
- en: Kendall’s tau of the two methods. Higher values indicate a stronger correlation
    between the ranking produced by the method and the human. Simulated User Feedback
    (proposed, lighter blue) shows higher agreement with humans when tasked with identifying
    improvements, suggesting that it more accurately reflects human judgment in identifying
    and evaluating improvements. Image by the author.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法的Kendall tau值。较高的值表示该方法生成的排名与人类判断之间的相关性更强。模拟用户反馈（建议的方法，浅蓝色）在识别改进时与人类的意见高度一致，表明它更准确地反映了人类在识别和评估改进方面的判断。图像由作者提供。
- en: 'The reason why the simulated user feedback performs better is twofold:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟用户反馈表现更好的原因有两个：
- en: it learns from actual user feedback the importance of different criteria, making
    the approach custom to your use case
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过实际用户反馈学习不同标准的重要性，使得该方法能够根据您的使用案例进行定制。
- en: while individual criteria may have appeared in the LLM training set, the complex
    (and potentially large) set of different criteria likely have not appeared in
    the training data, making it more difficult for the LLM evaluator to get right.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然个别标准可能出现在LLM的训练集里，但不同标准的复杂（且可能是庞大的）集合可能并未出现在训练数据中，这使得LLM评估器更难准确判断。
- en: While single LLM calls can identify major improvements in the pipeline, they
    fall short of detecting the more frequent, minor enhancements critical in mature
    pipelines. Simulated user feedback, however, exhibits a high correlation with
    human judgment, enabling the detection of these incremental advances.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然单一LLM调用能够识别管道中的重大改进，但它未必能发现成熟管道中至关重要的、更为频繁的小改进。然而，模拟的用户反馈与人类判断具有高度相关性，使其能够发现这些渐进的改进。
- en: As a side note, while we could have used the data to fine-tune an LLM, this
    has the typical drawback of requiring more data and not being as interpretable.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁注，虽然我们本可以利用这些数据来微调一个大语言模型（LLM），但这种方法通常需要更多的数据，并且不如直观易懂。
- en: In the next section, we will walk through an example on how to create your simulated
    user feedback.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将演示如何创建您的模拟用户反馈。
- en: How It Works
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: In this section we will show how we can use the open-source library [continuous-eval](https://github.com/relari-ai/continuous-eval)
    to create simulated user feedback.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何使用开源库[continuous-eval](https://github.com/relari-ai/continuous-eval)来创建模拟用户反馈。
- en: 'Consider a Q&A chatbot application. After deployment, users begin rating responses
    with thumbs up or down, indicating a need for performance enhancement. For this
    example we will use the example named `correctness` in continuous-eval:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个问答聊天机器人应用为例。部署后，用户开始用点赞或点踩来评分反馈，表示需要提升性能。对于这个例子，我们将使用`correctness`这个在continuous-eval中定义的示例：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we mentioned, we want to create some custom criteria. We leverage the `LLMBasedCustomMetric`
    class to define the *Tone* and *Conciseness* metrics. To do so we need to define
    the metric and provide a scoring rubric.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所提到的，我们希望创建一些自定义标准。我们利用`LLMBasedCustomMetric`类来定义*语气*和*简洁性*指标。为此，我们需要定义指标并提供评分标准。
- en: 'For the tone:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 关于语气：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'while for conciseness:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于简洁性：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We use *Tone* and *Conciseness* together with more standard metrics, in particular
    we will consider the
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将*语气*和*简洁性*与更多的标准化指标结合使用，特别是我们会考虑
- en: Answer Correctness (`DeterministicAnswerCorrectens` and `LLMBasedAnswerCorrectness)`
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答正确性（`DeterministicAnswerCorrectens` 和 `LLMBasedAnswerCorrectness`）
- en: Answer Relevance (`LLMBasedAnswerRelevance`)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答相关性（`LLMBasedAnswerRelevance`）
- en: Style Consistency (`LLMBasedStyleConsistency`)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 风格一致性（`LLMBasedStyleConsistency`）
- en: Readability (`FleschKincaidReadability`)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可读性（`FleschKincaidReadability`）
- en: The next step is to put all the metrics together and specify what field of the
    dataset should be used to compute the metrics. To do that we can use the `SingleModulePipeline`
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将所有指标汇总，并指定数据集中应使用的字段来计算这些指标。为此，我们可以使用`SingleModulePipeline`
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: and run all the metrics using the `EvaluationManager`
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用`EvaluationManager`运行所有指标
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The next step is to train simulated user feedback predictor
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是训练模拟用户反馈预测器
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This simulated user feedback predictor is able to correctly predict the human
    feedback in the test split 96.67% of the time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模拟用户反馈预测器能够在测试集上正确预测人类反馈的准确率为96.67%。
- en: We can leverage the proposed approach to better understand what is important
    to the user. Below is the learned importance of every metric by the simulated
    user feedback predictor.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用所提出的方法更好地理解用户关注的重点。下面是通过模拟用户反馈预测器学到的每个指标的重要性。
- en: '![](../Images/6404708dceb38cba2037dde13c071620.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6404708dceb38cba2037dde13c071620.png)'
- en: Learned importance of every metric by the simulated user feedback predictor.
    Image by the author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模拟用户反馈预测器学到的每个指标的重要性。图片由作者提供。
- en: Looking at the plot, we see that *Correctness* (including *token overlap*, which
    is another measure for correctness) and *Relevance* to the question are the most
    important predictors of user preference. But the user also weighs *tone* and *style
    consistency* into the decision. At the same time, we can see that *conciseness*
    and *readability* are not as important. Reviewing this graph provides valuable
    insight into user preferences, giving a clear indication of what elements are
    essential and what can be adjusted if compromises need to be made.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中，我们可以看到*正确性*（包括*令牌重叠*，它是衡量正确性的另一种方式）和与问题的*相关性*是用户偏好的最重要预测因素。但用户也会将*语气*和*风格一致性*纳入决策。同时，我们可以看到*简洁性*和*可读性*的重要性较低。回顾这个图表可以为我们提供有关用户偏好的宝贵见解，清楚地表明哪些元素是必要的，哪些可以在需要做出妥协时进行调整。
- en: Wrapping Up
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Collecting user feedback is challenging, yet it is the most important information
    for developers of large language models (LLMs). By simulating user feedback during
    offline testing, we significantly reduces the time it takes for feedback to travel
    from the field back to developers, while maintaining positive user relationships.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 收集用户反馈是一个挑战，但它是大型语言模型（LLM）开发者最重要的信息。通过在离线测试中模拟用户反馈，我们显著缩短了反馈从实际场景到开发者之间的传递时间，同时保持了积极的用户关系。
- en: In practice, our approach has proven to closely mirror actual human responses,
    outperforming traditional methods that rely on isolated LLM responses. This strategy
    allows for the incremental improvement of generative AI applications, fostering
    continuous refinement and greater congruence with what users expect.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们的方法已被证明能够与实际人类反应高度一致，超过了传统依赖于孤立LLM响应的方法。这一策略使得生成性AI应用得以渐进式改进，促进了持续的优化，并与用户期望保持更高的一致性。
- en: —
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: —
- en: 'Note: We will soon publish a research paper with more details on this methodology.
    Stay tuned!'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注：我们很快将发布一篇关于这种方法的研究论文，敬请关注！
- en: Coming Next
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步
- en: Techniques for curating golden dataset
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建黄金数据集的技术
- en: How to make the most out of your Embedding Model?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何最大化使用你的嵌入模型？
- en: What data should I use for Fine-Tuning?
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我应该使用哪些数据进行微调？
- en: Earlier Posts
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早期帖子
- en: '[Practical Guide to RAG Pipeline Evaluation Part 1: Retrieval](https://medium.com/p/27a472b09893)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RAG管道评估实用指南 第1部分：检索](https://medium.com/p/27a472b09893)'
- en: '[Practical Guide to RAG Pipeline Evaluation Part 2: Generation](https://medium.com/relari/a-practical-guide-to-rag-evaluation-part-2-generation-c79b1bde0f5d)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RAG管道评估实践指南第2部分：生成](https://medium.com/relari/a-practical-guide-to-rag-evaluation-part-2-generation-c79b1bde0f5d)'
- en: '[How important is a Golden Dataset for LLM pipeline evaluation?](https://medium.com/relari/how-important-is-a-golden-dataset-for-llm-pipeline-evaluation-4ef6deb14dc5)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黄金数据集对LLM管道评估有多重要？](https://medium.com/relari/how-important-is-a-golden-dataset-for-llm-pipeline-evaluation-4ef6deb14dc5)'
- en: '[Case Study: Reference-free vs Reference-based evaluation](https://medium.com/relari/case-study-reference-free-vs-reference-based-evaluation-of-rag-pipeline-9a49ef49866c)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[案例研究：无参考与基于参考的评估](https://medium.com/relari/case-study-reference-free-vs-reference-based-evaluation-of-rag-pipeline-9a49ef49866c)'
- en: '[How to evaluate complex GenAI Apps: a granular approach](https://medium.com/relari/how-to-evaluate-complex-genai-apps-a-granular-approach-0ab929d5b3e2)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何评估复杂的GenAI应用：一种细化方法](https://medium.com/relari/how-to-evaluate-complex-genai-apps-a-granular-approach-0ab929d5b3e2)'
