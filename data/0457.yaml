- en: 'A Weekend AI Project: Making a Visual Assistant for People with Vision Impairments'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 周末AI项目：为视力障碍人士制作视觉助手
- en: 原文：[https://towardsdatascience.com/a-weekend-ai-project-making-a-visual-assistant-for-people-with-vision-impairments-df0b9f0b8c23?source=collection_archive---------6-----------------------#2024-02-17](https://towardsdatascience.com/a-weekend-ai-project-making-a-visual-assistant-for-people-with-vision-impairments-df0b9f0b8c23?source=collection_archive---------6-----------------------#2024-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-weekend-ai-project-making-a-visual-assistant-for-people-with-vision-impairments-df0b9f0b8c23?source=collection_archive---------6-----------------------#2024-02-17](https://towardsdatascience.com/a-weekend-ai-project-making-a-visual-assistant-for-people-with-vision-impairments-df0b9f0b8c23?source=collection_archive---------6-----------------------#2024-02-17)
- en: Running a multimodal LLaVA model, camera, and speech synthesis
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行多模态LLaVA模型、摄像头和语音合成
- en: '[](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)
    ·8 min read·Feb 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--df0b9f0b8c23--------------------------------)
    ·阅读时间：8分钟·2024年2月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/0413a659f0b961e489105065af810837.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0413a659f0b961e489105065af810837.png)'
- en: Image by Enoc Valenzuela, [Unsplash](https://unsplash.com/photos/tilt-shift-photography-of-eyeglasses-with-silver-colored-frames-WJolaNbXt90)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自Enoc Valenzuela，[Unsplash](https://unsplash.com/photos/tilt-shift-photography-of-eyeglasses-with-silver-colored-frames-WJolaNbXt90)
- en: Modern large multimodal models (LMMs) can process not only text but also different
    types of data. Indeed, “a picture is worth a thousand words,” and this functionality
    can be crucial during the interaction with the real world. In this “weekend project,”
    I will use a free [LLaVA](https://llava-vl.github.io) (Large Language-and-Vision
    Assistant) model, a camera, and a speech synthesizer; we will make an AI assistant
    that can help people with vision impairments. In the same way as in previous parts,
    all components will run fully offline without any cloud cost.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现代大型多模态模型（LMMs）不仅能够处理文本，还能处理不同类型的数据。确实，“一图胜千言”，这种功能在与现实世界互动时至关重要。在这个“周末项目”中，我将使用一个免费的[LLaVA](https://llava-vl.github.io)（大型语言与视觉助手）模型、一台摄像头和一个语音合成器；我们将制作一个AI助手，帮助视力障碍人士。与之前的部分一样，所有组件将完全离线运行，不会产生任何云端费用。
- en: Without further ado, let’s get into it!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 事不宜迟，让我们开始吧！
- en: Components
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组件
- en: 'In this project, I will use several components:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我将使用几个组件：
- en: A [LLaVA](https://llava-vl.github.io) model, which combines a large language
    model and a visual encoder with the help of a special projection matrix. This
    allows the model to understand not only text but also image prompts. I will be
    using the [LlamaCpp](https://github.com/abetlen/llama-cpp-python) library to run
    the model (despite its name, it can run not only LLaMA but LLaVA models as well).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个[LLaVA](https://llava-vl.github.io)模型，它结合了大型语言模型和视觉编码器，并借助一个特殊的投影矩阵，使得该模型不仅能够理解文本，还能理解图像提示。我将使用[LlamaCpp](https://github.com/abetlen/llama-cpp-python)库来运行该模型（尽管它的名字中有“LLaMA”，但它不仅能运行LLaMA模型，也能运行LLaVA模型）。
- en: '[Streamlit](https://streamlit.io) Python library that allows us to make an
    interactive UI. Using the camera, we can take the image and ask the LMM different…'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Streamlit](https://streamlit.io) Python库，允许我们制作交互式UI。使用摄像头，我们可以拍摄图像，并向LMM提出不同的问题…'
