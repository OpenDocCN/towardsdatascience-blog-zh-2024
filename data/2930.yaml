- en: 'Introducing Univariate Exemplar Recommenders: how to profile Customer Behavior
    in a single vector'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍单变量样本推荐系统：如何在一个向量中描述客户行为
- en: 原文：[https://towardsdatascience.com/introducing-univariate-exemplar-recommenders-how-to-profile-customer-behavior-in-a-single-vector-c90c9943fe7d?source=collection_archive---------3-----------------------#2024-12-04](https://towardsdatascience.com/introducing-univariate-exemplar-recommenders-how-to-profile-customer-behavior-in-a-single-vector-c90c9943fe7d?source=collection_archive---------3-----------------------#2024-12-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/introducing-univariate-exemplar-recommenders-how-to-profile-customer-behavior-in-a-single-vector-c90c9943fe7d?source=collection_archive---------3-----------------------#2024-12-04](https://towardsdatascience.com/introducing-univariate-exemplar-recommenders-how-to-profile-customer-behavior-in-a-single-vector-c90c9943fe7d?source=collection_archive---------3-----------------------#2024-12-04)
- en: Customer Profiling
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户画像
- en: Surveying and improving the current methodologies for customer profiling
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调查并改进当前的客户画像方法
- en: '[](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)[![Michelangiolo
    Mazzeschi](../Images/9211748ac638d2ed07679ac73ea17296.png)](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)
    [Michelangiolo Mazzeschi](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)[![Michelangiolo
    Mazzeschi](../Images/9211748ac638d2ed07679ac73ea17296.png)](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)
    [Michelangiolo Mazzeschi](https://medium.com/@ardito.bryan?source=post_page---byline--c90c9943fe7d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)
    ·17 min read·Dec 4, 2024
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--c90c9943fe7d--------------------------------)
    ·阅读时长17分钟·2024年12月4日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '***To understand this article, knowledge of **embeddings, clustering, and recommendation
    systems** is required. The implementation of this algorithm has been released
    on [GitHub](https://github.com/atlantis-nova/univariate-sequential-recommender)
    and is fully open-source. **I am open to criticism** and **welcome any feedback.**'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***要理解本文，需具备**嵌入、聚类和推荐系统**的相关知识。此算法的实现已发布在[GitHub](https://github.com/atlantis-nova/univariate-sequential-recommender)并完全开源。**我欢迎批评**，并**欢迎任何反馈**。'
- en: Most platforms, nowadays, understand that tailoring individual choices for each
    customer leads to increased user engagement. Because of this, **the recommender
    systems' domain has been constantly evolving**, witnessing the birth of new algorithms
    every year.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，大多数平台都意识到，为每个客户量身定制个人化选择会提高用户参与度。正因如此，**推荐系统领域一直在不断发展**，每年都会诞生新的算法。
- en: '![](../Images/d918db3f6c1275e082b084893edeb392.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d918db3f6c1275e082b084893edeb392.png)'
- en: hierarchical clustering, **image by Author**
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类，**图像来源：作者**
- en: Unfortunately, **no existing taxonomy is keeping track** of all algorithms in
    this domain. While most recommendation algorithms, such as matrix factorization,
    employ a neural network to make recommendations based on a list of choices, in
    this article, I will focus on the ones that **employ a vector-based architecture
    to keep track of user preferences.**
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，**目前没有现有的分类体系在跟踪**该领域的所有算法。虽然大多数推荐算法，如矩阵分解，使用神经网络基于一系列选择进行推荐，但在本文中，我将专注于那些**采用基于向量的架构来跟踪用户偏好的算法**。
- en: Exemplar Recommenders
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 样本推荐系统
- en: 'Thanks to the simplicity of embeddings, each sample that can be recommended
    (ex. products, content…) is converted into a vector using a pre-trained neural
    network (for example a matrix factorization): we can then use knn to make recommendations
    of similar products/customers. The algorithms following this paradigm are known
    as **vector-based recommender systems.** However, when these models take into
    consideration the previous user choices, **they add a sequential layer** to their
    base architecture and become technically known as **vector-based** **sequential
    recommenders**. Because these architectures are becoming increasingly difficult
    (to both remember and pronounce), I am calling them **exemplar recommenders**:
    they extract a set of representative vectors from an initial set of choices to
    represent a **user vector**.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于嵌入的简单性，每个可以推荐的样本（例如产品、内容等）都通过一个预训练的神经网络（例如矩阵分解）转化为一个向量：然后我们可以使用knn算法推荐相似的产品/客户。遵循这种范式的算法被称为**基于向量的推荐系统**。然而，当这些模型考虑到用户的先前选择时，**它们为基础架构增加了一个顺序层**，并在技术上被称为**基于向量的**
    **顺序推荐系统**。由于这些架构越来越难以记忆（和发音），我将它们称为**样本推荐系统**：它们从初始选择集中提取一组代表性向量来表示**用户向量**。
- en: '![](../Images/2791e63bf766ddfe1cf2da8d8b469e9a.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2791e63bf766ddfe1cf2da8d8b469e9a.png)'
- en: subdivision of recommender systems, **image by Author**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统的细分，**图片来源：作者**
- en: 'One of the first systems built on top of this architecture is **Pinterest**,
    which is running on top of [its Pinnersage Recommendation engine](https://medium.com/pinterest-engineering/pinnersage-multi-modal-user-embedding-framework-for-recommendations-at-pinterest-bfd116b49475):
    this scaled engine capable of managing over 2 Billion pins runs its own specific
    architecture and **performs clustering on the choices** of each individual user.
    As we can imagine, this represents a computational challenge when scaled. Especially
    after discovering **covariate encoding**, I would like to introduce four complementary
    architectures (two in particular, with the article''s name) that can **relieve
    the stress of clustering algorithms** when trying to profile each customer. You
    can refer to the following diagram to differentiate between them.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基于该架构构建的第一个系统之一是**Pinterest**，它运行在[其Pinnersage推荐引擎](https://medium.com/pinterest-engineering/pinnersage-multi-modal-user-embedding-framework-for-recommendations-at-pinterest-bfd116b49475)之上：这个可扩展的引擎能够管理超过20亿个钉图，运行其特定架构并**对每个用户的选择进行聚类**。正如我们所想，这在扩展时代表了一个计算挑战。尤其是在发现**协变量编码**后，我想介绍四种互补的架构（其中两种，特别是文章中提到的名称），它们可以**减轻聚类算法的压力**，在尝试分析每个客户时。你可以参考以下图示来区分它们。
- en: '![](../Images/736be38c19281ee285c158b9b656dd4e.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/736be38c19281ee285c158b9b656dd4e.png)'
- en: summary of exemplar recommenders, **image by Author**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 样本推荐系统概述，**图片来源：作者**
- en: 'Note that all the above approaches are classified as content-based filtering,
    and **not collaborative filtering**. In regards to the exemplar architecture,
    we can identify **two main defining parameters**: **in-stack clustering implementation**
    (we either perform clustering on the sample embedding or directly on the user
    embedding), and **the number of vectors** used to store user preferences over
    time.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以上所有方法都属于基于内容的过滤，而**非协同过滤**。关于样本架构，我们可以识别出**两个主要定义参数**：**堆栈内聚类实现**（我们可以在样本嵌入或用户嵌入上执行聚类），以及**用于存储用户偏好的向量数量**。
- en: In-Stack Clustering implementation
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆栈内聚类实现
- en: Using once again Pinnersage as an example, we can see how it performs **a novel
    clustering iter for each user**. However advantageous from an accuracy perspective,
    this is computationally very heavy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 再以Pinnersage为例，我们可以看到它是如何为每个用户执行**一个新颖的聚类迭代**。尽管从准确度的角度来看，这具有优势，但从计算角度而言，非常耗费资源。
- en: Post-Clustering
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后聚类
- en: When clustering is used on top of the user embeddings, we can refer to this
    approach (in this specific stack) as **post-clustering**. However inefficient
    this may look, applying a non-parametric clustering algorithm on billions of samples
    is borderline impossible, and probably not the best option.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当聚类应用于用户嵌入时，我们可以将这种方法（在此特定堆栈中）称为**后聚类**。尽管这种方法看起来效率不高，但在数十亿个样本上应用非参数聚类算法几乎是不可能的，可能也不是最好的选择。
- en: Pre-Clustering
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预聚类
- en: 'There might be some use cases when applying clustering on top of the sample
    data could be advantageous: we can refer to this approach (in this specific stack)
    as **pre-clustering.** For example, a retail store may need to track the history
    of millions of users, requiring the same computational resources of the Pinnersage
    architecture.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些使用案例中，在样本数据上应用聚类可能是有利的：我们可以将这种方法（在这个特定的堆栈中）称为**预聚类**。例如，零售商店可能需要跟踪数百万用户的历史记录，这将需要与Pinnersage架构相同的计算资源。
- en: However, the number of samples of a retail store, compared to the Pinterest
    platform, **should not exceed 10.000**, against the staggering **2 Billion** in
    comparison. With such a small number of samples, performing clustering on the
    sample embedding **is very efficient**, and will relieve the need to use it on
    the user embedding, if utilized properly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与Pinterest平台相比，零售商店的样本数量**不应超过10,000**，而后者则是惊人的**20亿**。在如此少量的样本下，对样本嵌入进行聚类**非常高效**，如果合理利用，这也将减轻对用户嵌入进行聚类的需求。
- en: Introducing the Univariate Architecture
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入单变量架构
- en: As mentioned, the biggest challenge when creating these architectures is scalability.
    Each user amounts to **hundreds of past choices held in record** that need to
    be computed for **exemplar extraction**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，创建这些架构时面临的最大挑战是可扩展性。每个用户有**数百个过去的选择记录**，需要为**示例提取**进行计算。
- en: Multivariate architecture
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多变量架构
- en: 'The most common way of building a vector-based recommender is to pin every
    user choice to an existing pre-computed vector. However, even if we resort to
    decay functions to minimize the number of vectors to take into account for our
    calculation, we still need to **fill the cache with all the vectors at the time
    of our computation**. In addition, at the time of retrieval, the vectors cannot
    be stored on the machine that performs the calculation, but need to be queried
    from a database: this sets an additional challenge for scalability.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 构建基于向量的推荐系统的最常见方式是将每个用户选择与现有的预计算向量绑定。然而，即使我们采用衰减函数来最小化在计算中需要考虑的向量数量，我们仍然需要**在计算时填充所有的向量缓存**。此外，在检索时，向量不能存储在执行计算的机器上，而需要从数据库中查询：这为可扩展性带来了额外的挑战。
- en: The flow of this approach is the limited variance in recommendations. The recommended
    samples will be spatially very close to each other (the sample variance is minimized)
    and will only belong to the same category (unless there is in place a more complex
    logic defining this interaction).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的流程是推荐中的方差有限。推荐的样本将在空间上非常接近（样本方差最小化），并且仅属于同一类别（除非有更复杂的逻辑定义这种交互）。
- en: '![](../Images/309a8b6ba10a2d190222402b49ef26d0.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/309a8b6ba10a2d190222402b49ef26d0.png)'
- en: multivariate exemplar recommendation, **image by Author**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量示例推荐，**图片由作者提供**
- en: 'WHEN TO USE: This approach (I am only taking into account the behavior of the
    model, not its computational needs) is suited for applications where **we can
    recommend a batch of samples all from the same category.** Art or social media
    applications are one example.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用：这种方法（我这里只考虑模型的行为，而非其计算需求）适用于那些**我们可以推荐一批来自同一类别的样本**的应用。艺术或社交媒体应用就是一个例子。
- en: Univariate architecture
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单变量架构
- en: With this novel approach, we can store each user choice using a single vector
    that keeps updating over time. This should prove to be a remarkable improvement
    in scalability, minimizing the computational stress derived from both **knn**
    and **retrieval**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种新方法，我们可以通过一个单一的向量来存储每个用户的选择，并随着时间推移不断更新。这应该是可扩展性的显著提升，最小化来自**knn**和**检索**的计算压力。
- en: To make it even more complicated, there are two indexes where we can perform
    clustering. We can either cluster the **items** or the **categories** (both labeled
    using tags). There is no superior approach, we have to choose one depending on
    our use case.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的是，我们有两个索引可以进行聚类。我们可以聚类**项目**或**类别**（两者都使用标签标注）。没有绝对优越的方法，我们必须根据使用案例选择其中一个。
- en: category-based
  id: totrans-38
  prefs:
  - PREF_H2
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于类别
- en: This article is entirely based on the construction of a category-based model.
    After tagging our data we can perform **a clustering to group our data into a
    hierarchy of categories** (in case our data is already organized into categories,
    there is no need to apply hierarchical clustering).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本文完全基于构建基于类别的模型。在标记数据后，我们可以执行**聚类，将数据分组为类别层次结构**（如果我们的数据已经按类别组织，则无需应用层次聚类）。
- en: The main advantage of this approach is that the exemplar indicating the user
    preferences will be linked to similar categories (increasing product variance).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要优点是，指示用户偏好的示例将与相似类别相关联（增加了产品的多样性）。
- en: '![](../Images/f0a97569cbae95f0f87036ceadefcc2b.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0a97569cbae95f0f87036ceadefcc2b.png)'
- en: univariate category-based exemplar recommendation, **image by Author**
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量基于类别的示例推荐，**图片由作者提供**
- en: 'WHEN TO USE: Sometimes, we want to focus on recommending an entire category
    to our customers, rather than individual products. For example, if our user enjoys
    buying shirts (and by chance the exemplar is located in the latent region of **red
    shirts**), we would benefit more from recommending him the entire clothing category,
    rather than **only red shirts**. This approach is best suited for retail and fashion
    companies.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用：有时，我们希望向客户推荐整个类别，而不是单个产品。例如，如果我们的用户喜欢购买衬衫（而且碰巧示例位于**红色衬衫**的潜在区域），我们更有利于推荐他整个服装类别，而不是**仅仅红色衬衫**。这种方法最适合零售和时尚公司。
- en: item-based
  id: totrans-44
  prefs:
  - PREF_H2
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于项目
- en: 'With an item-based approach, we are performing clustering on top of our samples.
    This will allow us to capture more granular information on the data, rather than
    focusing on separated categories: we want to expand beyond the limitations of
    the product categorization and recommend items across existing categories.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于项目的方法，我们是在对样本进行聚类。这将允许我们捕捉数据的更细粒度信息，而不是仅仅关注分开的类别：我们希望超越产品分类的限制，并跨现有类别推荐项目。
- en: '![](../Images/b0111b8cd5ace445e774e16f707bdb73.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0111b8cd5ace445e774e16f707bdb73.png)'
- en: univariate item-based exemplar recommendation, **image by Author**
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量基于项目的示例推荐，**图片由作者提供**
- en: 'WHEN TO USE: The best companies that can make the best use for this approach
    are human resources and retailers with cross-categorical products (ex. videogames).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用：能够充分利用这种方法的最佳公司是人力资源公司和拥有跨类别产品的零售商（例如：视频游戏）。
- en: Univariate Exemplar Recommenders
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单变量示例推荐系统
- en: 'Finally, we can explain in depth the architecture behind the category-based
    approach. This algorithm will perform exemplar extraction **by only storing a
    single vector** over time: the only technology capable of managing it is **covariate
    encoding**, hence **we will use tags** on top of the data. Because it uses **pre-clustering**,
    it is ideal for use cases with a manageable number of samples, but an unlimited
    number of users.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以深入解释基于类别方法背后的架构。该算法将通过**仅存储一个单一的向量**来执行示例提取：唯一能够管理它的技术是**协变量编码**，因此**我们将使用标签**来处理数据。由于它使用**预聚类**，它非常适合样本数量可管理但用户数量无限制的应用场景。
- en: 'For this example, I will be using the open-source collection of the **Steam
    game library** ([downloadable from Kaggle](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset)
    — [MIT License](https://www.mit.edu/~amini/LICENSE.md)), which is a perfect use
    case for this recommender at scale: Steam uses no more than 450 tags, and the
    number can occasionally increase over time; yet, **it is manageable**. This set
    of tags can be clustered very easily, and **can even allow for manual intervention**
    if we question the cluster assignment. Last, it serves millions of users, proving
    to be **a realistic use case** for our recommender.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我将使用开源的**Steam游戏库**集合（[可从Kaggle下载](https://www.kaggle.com/datasets/fronkongames/steam-games-dataset)
    — [MIT许可证](https://www.mit.edu/~amini/LICENSE.md)），这是一个完美的适用于大规模推荐系统的案例：Steam最多使用450个标签，并且该数量可能会随着时间的推移有所增加；然而，**它是可管理的**。这些标签可以很容易地进行聚类，**如果我们对聚类分配有疑问，甚至可以进行手动干预**。最后，它服务于数百万用户，证明它是**一个现实的应用案例**。
- en: '![](../Images/65304e7769ea6e3d06f49ac9958745e3.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65304e7769ea6e3d06f49ac9958745e3.png)'
- en: Sample of the Steam game dataset, **image by Author**
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Steam游戏数据集的示例，**图片由作者提供**
- en: 'Its architecture can be articulated into the following phases:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 它的架构可以分为以下几个阶段：
- en: '***Note that when creating the sample code of this architecture I am using
    LLMs to make the entire process **free from any human supervision**. However,
    **LLMs remain optional**, and while they may improve the level of this recommender
    system, they are not an essential part of it.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意，当创建此架构的样本代码时，我使用LLM使整个过程**摆脱任何人为监督**。然而，**LLM仍然是可选的**，虽然它们可能会提高推荐系统的水平，但它们不是这个系统的核心部分。'
- en: Sample Labeling
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 样本标注
- en: We need to make sure to assign tags to each of our samples. Because of semantic
    tag filtering, we do not need to resort to zero-shots, but we can let a LLM manage
    this process without any supervision.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要确保为每个样本分配标签。由于语义标签过滤，我们不需要依赖零样本，而是可以让LLM在没有任何监督的情况下管理此过程。
- en: Pre-Clustering
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预聚类
- en: We are going to divide the tag embedding into different clusters. For a higher
    level of accuracy, we are going to use **hierarchical clustering** with a depth
    of 3.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将把标签嵌入分成不同的聚类。为了提高准确性，我们将使用**层次聚类**，深度为3。
- en: Cluster labeling
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类标注
- en: Once we have defined our cluster tree, we need to label each generated supercluster.
    We can still use LLM for this purpose. If you decide to avoid using LLMs, not
    that clusters can remain in a numerical form (this may only alter the user perception
    of the recommender).
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们定义了聚类树，就需要为每个生成的超级聚类打上标签。我们仍然可以使用LLM来实现这一目的。如果你决定避免使用LLM，需要注意的是，聚类可以保持为数字形式（这可能只是改变了推荐系统用户的感知）。
- en: Balance non-uniform tag frequency
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平衡非均匀标签频率
- en: The first challenge in picking from a list of tags is that the tags that appear
    the most (and are assigned to one cluster), heavily skew the recommender **to
    propose that very cluster**. We need to make sure that each cluster has the same
    probability of being recommended. We can achieve this by adding a custom multiplier
    that uniforms the probability of each cluster being recommended.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从标签列表中挑选标签的第一个挑战是，出现频率最高的标签（并且被分配到一个聚类中）会严重偏向推荐系统**建议该聚类**。我们需要确保每个聚类有相同的推荐概率。我们可以通过添加一个自定义的倍增器来实现这一点，从而统一每个聚类被推荐的概率。
- en: Univariate sequential encoding
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单变量序列编码
- en: Now that our encoding weights have been defined, we can encode the user history
    in a vector, but with the possibility of updating it over time (using a decay
    function to get rid of old user preferences).
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经定义了编码权重，可以将用户历史编码为一个向量，并且可以随着时间的推移更新它（使用衰减函数来去除过时的用户偏好）。
- en: 'Account for scalability: pruning mechanism'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑可扩展性：剪枝机制
- en: Because the dimensions of our vector are equivalent to the number of tags, we
    need to find a way to limit the size of the vector over time. PCA is a valid option,
    but because of the sum operations on the vector, feature pruning has proved to
    be more efficient.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因为我们的向量维度等于标签的数量，所以我们需要找到一种方法来限制向量的大小。PCA是一个有效的选择，但由于对向量的求和操作，特征剪枝已被证明更为高效。
- en: Exemplar estimation
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例估算
- en: This is where the innovation lies. We can encode the user profile **as a single
    exemplar** and **still obtain separate cluster recommendations** without any information
    loss that would arise IF we were to average multiple exemplars. This means that
    each of the previous multivariate methods would be incompatible with this architecture.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创新之处在于这里。我们可以将用户档案**编码为单一示例**，**并且仍然获得单独的聚类推荐**，而不会有因为将多个示例平均化而导致的信息丢失。这意味着之前的所有多变量方法都与此架构不兼容。
- en: 'Let us begin with the full explanation behind the Univariate Exemplar Recommender:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从对单变量示例推荐系统的全面解释开始：
- en: 1\. Sample Labeling
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 样本标注
- en: In our reference dataset all samples have already been labeled using tags. If
    by any chance we are working with labeled data, we can easily do that using a
    LLM, **prompting a request for a list of tags** for each sample. As explained
    in my article on semantic tag filtering, we do not need to use zero-shots to guide
    the choice of labels, and the process can be completely unsupervised.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的参考数据集中，所有样本已经使用标签进行了标注。如果我们恰好正在处理带标签的数据，可以轻松使用LLM来完成这项工作，**通过提示请求为每个样本列出标签**。正如我在关于语义标签过滤的文章中所解释的那样，我们不需要使用零样本来指导标签选择，整个过程可以完全无监督。
- en: '![](../Images/23bfbf713c6524eaa34c3b854c8b5df8.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23bfbf713c6524eaa34c3b854c8b5df8.png)'
- en: Screenshot of our sample data, each sample labeled with tags, **image by Author**
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的样本数据截图，每个样本都标注了标签，**图像由作者提供**
- en: 2\. Pre-Clustering
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 预聚类
- en: As mentioned, the idea behind this recommender is to first organize the data
    into clusters, and then identify the most common clusters (exemplars) that define
    the preferences of every single user. Because the data is ideally very small (thousands
    of tags against billions of samples), clustering is no longer a burden and can
    be done on the tag embedding, **rather than on the millions of user embeddings**.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，该推荐系统背后的想法是首先将数据组织成簇，然后识别出最常见的簇（示例簇），这些簇定义了每个用户的偏好。由于数据理想情况下非常小（数千个标签对比数十亿个样本），因此聚类不再是一种负担，可以在标签嵌入上进行，而**不是在数百万个用户嵌入上**。
- en: The more the number of tags increases, the more it makes sense to use a hierarchical
    structure to manage its complexity. Ideally, I would want not only to keep track
    of the main interests of each user but also **their sub-interests** and make recommendations
    accordingly. By using a dendrogram, we can define the different levels of clusters
    by **using a threshold level**.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 标签数量越多，使用层次结构来管理其复杂性就越有意义。理想情况下，我不仅希望跟踪每个用户的主要兴趣，还希望跟踪**他们的子兴趣**并据此进行推荐。通过使用树状图，我们可以通过**使用阈值水平**来定义不同层次的簇。
- en: The first superclusters (level 1) will be the result of using a threshold of
    11.4, resulting in the first 81 clusters. We can also see how their distribution
    is non-uniform (some clusters are bigger than others), but all considered, is
    not excessively skewed.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个超级簇（第一层）将是使用阈值11.4的结果，生成前81个簇。我们还可以看到它们的分布是不均匀的（一些簇比其他簇大），但总体来看，并不会过于偏斜。
- en: '![](../Images/1fb4156cb9e3ba2388e560fa57b2e64c.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fb4156cb9e3ba2388e560fa57b2e64c.png)'
- en: hierarchical clustering, level 1, threshold=11.4, **image by Author**
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类，第一层，阈值=11.4，**图像来源：作者**
- en: '![](../Images/09e6f67f767fc4b0b96b752b9da264f5.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09e6f67f767fc4b0b96b752b9da264f5.png)'
- en: all the cluster sizes of level 1 clustering, **image by Author**
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 第一层聚类的所有簇大小，**图像来源：作者**
- en: The next clustering level will be defined by a smaller threshold (9), which
    organizes the data in 181 clusters. Equivalently for the first level of clustering,
    the size distribution is uneven, but there are only two big clusters, so it should
    not be this big of an issue.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个聚类层级将由一个较小的阈值（9）定义，它将数据组织成181个簇。同样，第一层聚类的大小分布不均匀，但只有两个大簇，因此这不应是一个大问题。
- en: '![](../Images/27ec7f451249f727f4b7667d98a6556a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27ec7f451249f727f4b7667d98a6556a.png)'
- en: hierarchical clustering, level 2, threshold=9, **image by Author**
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类，第二层，阈值=9，**图像来源：作者**
- en: '![](../Images/ebd50f4535567bb1b45eb9d06eeb0f5a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebd50f4535567bb1b45eb9d06eeb0f5a.png)'
- en: all the cluster sizes of level 2 clustering, **image by Author**
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 第二层聚类的所有簇大小，**图像来源：作者**
- en: These thresholds have been arbitrarily chosen. Although **there are non-parametric
    clustering algorithms** that can perform the clustering process without any human
    input, they are quite challenging to manage, especially at scale, and show side
    effects such as the **non-uniform distribution of cluster sizes**. If among our
    clusters there are some that are too big (ex. one single cluster may even account
    for 20% of the overall data), then they may incorporate most recommendations without
    much sense.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些阈值是随意选择的。尽管**有非参数聚类算法**可以在没有任何人工输入的情况下执行聚类过程，但它们管理起来相当具有挑战性，尤其是在大规模数据上，并且会出现一些副作用，比如**簇大小的分布不均匀**。如果我们的簇中有一些过大（例如，某个簇可能占据总体数据的20%），那么它们可能会包含大部分推荐内容，但并没有太多意义。
- en: Our priority when executing clustering is to **obtain the most uniform distribution
    while maximizing the number of clusters** so that the data can be split and differently
    represented as much as possible.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在执行聚类时的优先事项是**在最大化簇的数量的同时获得最均匀的分布**，以便尽可能多地划分数据并进行不同的表示。
- en: 3\. Cluster labeling
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 聚类标记
- en: Because we have chosen to perform clustering on two levels of depths on top
    of our existing data, we have reached a total of 3 layers. The last layer is made
    by individual labels and is the only labeled layer. The other two, instead, only
    hold the cluster number without proper naming.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们选择在现有数据的基础上对两个层次的深度进行聚类，所以我们达到了总共三层。最后一层由单个标签构成，并且是唯一的标记层。其他两层则仅包含簇编号，没有适当的命名。
- en: To solve this problem (note that this supercluster labeling step is not mandatory,
    but can improve how the user interacts with our recommender) we can use LLM on
    top of the superclusters.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题（请注意，这一步骤中的超级簇标记并非强制执行，但可以改善用户与我们推荐系统的交互方式），我们可以在超级簇之上使用大型语言模型（LLM）。
- en: 'Let us try to automatically label all our clusters by feeding the tags inside
    of each group:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过将每个组中的标签喂入来自动标记所有簇：
- en: '![](../Images/5cf71c6a898b38ca7d779b7921154232.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cf71c6a898b38ca7d779b7921154232.png)'
- en: labeling for clusters at different depths, **image by Author**
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 不同深度的簇标签，**图片来自作者**
- en: Now that also our clusters have been labeled correctly, we can start building
    the foundation of our sequential recommender.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的簇也已经正确标记完毕，可以开始构建我们的序列推荐系统的基础了。
- en: 4\. Balance non-uniform tag frequency
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 平衡非均匀标签频率
- en: So far, we have completed the easy part. Now that we have all our elements ready
    to create a recommender, we still need to adjust the imbalances. It would be much
    more intuitive to showcase this step after the recommender is done, but, unfortunately,
    it is part of its base structure, you will need to bear this with me.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经完成了简单的部分。现在我们已经准备好了所有元素来创建推荐系统，但我们仍然需要调整不平衡。虽然展示这一步骤在推荐系统完成之后会更加直观，但不幸的是，它是推荐系统基础结构的一部分，你需要和我一起承担这个部分。
- en: 4.1 What if we skip balancing?
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 如果我们跳过平衡呢？
- en: Let us, for a moment, skip ahead of time, and show the capabilities of our finished
    recommender by simply **skipping this essential step**. By assigning a score of
    1 to each tag, there will be some tags that are so common that they will heavily
    skew the recommendation scores.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微提前一点，展示完成的推荐系统的能力，简单地**跳过这个必要的步骤**。通过给每个标签分配1的得分，有些标签会非常常见，从而严重扭曲推荐得分。
- en: The following is a Monte Carlo simulation **of 5000 random tag choices from
    the dataset**. What we are looking at is the distribution of clusters that end
    up being chosen randomly after summing the scores. As we can see, the distribution
    is highly skewed and it will certainly break the recommender in favor of the clusters
    with the highest score.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个蒙特卡洛模拟**来自数据集的5000次随机标签选择**。我们所看到的是在加总得分后被随机选择的簇的分布。正如我们所见，分布高度倾斜，肯定会使推荐系统倾向于得分最高的簇。
- en: '![](../Images/18af5b555ed587667fe24d0fe67e92aa.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18af5b555ed587667fe24d0fe67e92aa.png)'
- en: recommended cluster frequency over 10k simulations, **image by Author**
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在10k次模拟中推荐的簇频率，**图片来自作者**
- en: For example, the cluster **“Dark Norse Realms”** contains the tag **Indie**,
    which appears in 64% of all Samples (basically is almost impossible not to pick
    repetitively).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，簇**“黑暗北欧王国”**包含标签**独立游戏**，它出现在64%的所有样本中（基本上几乎不可能不反复选择）。
- en: '![](../Images/d9c04470b7d75d0810db6ee85642ea54.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9c04470b7d75d0810db6ee85642ea54.png)'
- en: example of recommended clusters, **image by Author**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐簇的示例，**图片来自作者**
- en: To be even more precise, let us directly simulate 100 different random sessions,
    each one picking **the top 3 clusters from the session** (the main user preference
    we keep track of), let us simulate entire user sessions so that the data is more
    complete. It is normal, especially when using a decay function, for the distribution
    to be non-uniform, and keep shifting over time.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更精确一些，让我们直接模拟100次不同的随机会话，每次选择**会话中的前3个簇**（我们跟踪的主要用户偏好），让我们模拟整个用户会话，以便数据更完整。尤其是在使用衰减函数时，分布不均匀且随时间不断变化是正常的。
- en: '![](../Images/1194c03cc13c07c59ea1bb2c4d06832a.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1194c03cc13c07c59ea1bb2c4d06832a.png)'
- en: recommended cluster frequency over 10k simulations, **image by Author**
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在10k次模拟中推荐的簇频率，**图片来自作者**
- en: However, if the skewness is excessive, the result is that the majority of users
    will be recommended **the top 5% of the clusters 95% of the time** (it is not
    precise numbers, just to prove my point).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果倾斜过度，结果就是大多数用户**95%的时间将会推荐前5%的簇**（这不是精确的数字，只是为了证明我的观点）。
- en: 4.2 Balancing probability distribution
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 平衡概率分布
- en: '**Instead**, let us use a proper formula for frequency adjustment. Because
    the probability for each cluster is different, we want to assign a score that,
    when used to balance the weights of our user vector, **will balance cluster retrieval:**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**相反**，让我们使用一个适当的频率调整公式。由于每个簇的概率不同，我们希望分配一个得分，在用它来平衡我们用户向量的权重时，**能够平衡簇的检索：**'
- en: '![](../Images/3e1caf0f15a64ec7ed217ae81ea38b1d.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e1caf0f15a64ec7ed217ae81ea38b1d.png)'
- en: scoring function to balance probability non-uniformity, **image by Author**
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 用于平衡概率非均匀性的得分函数，**图片来自作者**
- en: 'Let us look at the score assigned to each tag for **4 different random clusters**:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下为**4个不同的随机簇**分配的得分：
- en: '![](../Images/0135220f5fb5a238c79b7cfb8a1ef387.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0135220f5fb5a238c79b7cfb8a1ef387.png)'
- en: example of recommended clusters, **image by Author**
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐聚类的示例，**作者提供的图片**
- en: 'If we apply the score to the random pick (5000 picks, counting the frequency
    adjusted by the aforementioned **weight**), we can see how the tag distribution
    is now balanced (the outline ~ “Adrenaline Rush” is caused by a duplicate name):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将评分应用于随机选择（5000次选择，计数频率并调整上述**权重**），我们可以看到标签分布现在已经平衡（轮廓~“肾上腺素冲击”是由重复名称引起的）：
- en: '![](../Images/177ebdc4f83d3186500aa718391e901b.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/177ebdc4f83d3186500aa718391e901b.png)'
- en: cluster probability over 10k simulations, **image by Author**
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 10k次模拟中的聚类概率，**作者提供的图片**
- en: In fact, by looking at the normal distribution of the fluctuations, we see that
    the standard deviation for picking any cluster is approx. 0.1, **which is extremely
    low** (especially compared to before).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，通过查看波动的正态分布，我们可以看到，选择任何一个聚类的标准差大约是0.1，**这非常低**（尤其是与之前相比）。
- en: '![](../Images/96ba2f4a02e2a0f3f14b9119710dd98e.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96ba2f4a02e2a0f3f14b9119710dd98e.png)'
- en: fluctuation distribution over 10k simulations, **image by Author**
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 10k次模拟中的波动分布，**作者提供的图片**
- en: By replicating 100 sessions, we see how, even with a pseudo-uniform probability
    distribution, the clusters amass over time following the Pareto principle.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复制100次会话，我们可以看到，即使是伪均匀的概率分布，聚类也会随着时间的推移，遵循帕累托原则积累。
- en: '![](../Images/c26f6ebf20506d50f86549f157ceb8dc.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c26f6ebf20506d50f86549f157ceb8dc.png)'
- en: recommended cluster frequency over 10k simulations, **image by Author**
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 10k次模拟中的推荐聚类频率，**作者提供的图片**
- en: '**5\. Univariate sequential encoding**'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5. 单变量顺序编码**'
- en: It is time to build the sequential mechanism to keep track of user choices over
    time. The mechanism I idealized **works on two separate vectors** (that after
    the process end up being one, hence univariate), a **historical vector** and a
    **caching vector**.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是构建顺序机制的时候，以跟踪用户的选择随时间的变化。我理想化的机制**基于两个独立的向量**（经过处理后最终合并成一个，因此是单变量的），分别是**历史向量**和**缓存向量**。
- en: The **historical vector** is the one that is used to perform knn on the existing
    clusters. Once a session is concluded, we update the historical vector with the
    new user choices. At the same time, we adjust existing values with a decay function
    that diminishes the existing weights over time. By doing so, we make sure to keep
    up with the customer trends and **give more weight to new choices, rather than
    older ones**.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**历史向量**用于在现有聚类上执行k近邻算法。一旦会话结束，我们将使用新的用户选择更新历史向量。同时，我们会通过一个衰减函数调整现有的值，使得现有的权重随着时间的推移逐渐减少。通过这样做，我们确保跟上客户的趋势，并**给新选择赋予更多权重，而不是旧的选择**。'
- en: Rather than updating the vector at each user makes a choice (which is not computationally
    efficient, in addition, we risk letting older choices decay too quickly, as every
    user interaction will trigger the decay mechanism), **we can store a temporary
    vector** that is only valid for the current session. Each user interaction, converted
    into a vector **using the tag frequency as one hot weight**, will be summed to
    the existing cached vector.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 与其在每次用户做出选择时更新向量（这在计算上效率较低，此外，我们还可能会让较旧的选择过早衰减，因为每次用户交互都会触发衰减机制），**我们可以存储一个临时向量**，该向量仅对当前会话有效。每次用户交互转化为向量**并使用标签频率作为独热权重**，将被加到现有的缓存向量中。
- en: '![](../Images/c2b1254238d7ad8f05e0f56050143d74.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2b1254238d7ad8f05e0f56050143d74.png)'
- en: vector sum workflow, **image by Author**
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 向量和流工作流程，**作者提供的图片**
- en: Once the session is closed, we will retrieve the historical vector from the
    database, merge it with the cached vector, and **apply the adjustment mechanisms**,
    such as the decay function and pruning, as we will see later). After the historical
    vector has been updated, it will be stored in the database replacing the old one.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦会话结束，我们将从数据库中检索历史向量，将其与缓存向量合并，并**应用调整机制**，例如衰减函数和修剪机制，正如我们稍后所见）。历史向量更新后，将替换旧的向量并存储在数据库中。
- en: '![](../Images/03b301f6696962b86a1f8eb98a594437.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03b301f6696962b86a1f8eb98a594437.png)'
- en: session recommender workflow, **image by Author**
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 会话推荐器工作流程，**作者提供的图片**
- en: The two reasons to follow this approach are to minimize the weight difference
    between older and newer interactions and to make the entire process scalable and
    computationally efficient.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法的两个原因是：最小化旧的和新的交互之间的权重差异，以及使整个过程具有可扩展性和计算效率。
- en: 6\. Pruning Mechanism
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. 修剪机制
- en: 'The system has been completed. However, there is an additional problem: covariate
    encoding has one flaw: its base vector **is scaled proportionally to the number
    of encoded tags.** For example, if our database were to reach 100k tags, the vector
    would have an equivalent number of dimensions.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 系统已经完成。然而，存在一个额外的问题：协变量编码有一个缺陷：其基础向量**是根据编码标签的数量按比例缩放的**。例如，如果我们的数据库达到10万标签，向量将具有等同数量的维度。
- en: The original covariate encoding architecture already takes this problem into
    account, proposing a PCA compression mechanism as a solution. However, applied
    to our recommender, PCA causes issues when iteratively summing vectors, resulting
    in information loss. Because every user choice will cause a summation of existing
    vectors with a new one, this solution is not advisable.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的协变量编码架构已经考虑到这个问题，提出了一种PCA压缩机制作为解决方案。然而，当应用到我们的推荐系统时，PCA在迭代求和向量时会导致信息丢失。因为每次用户选择都会将现有向量与新的向量相加，因此这种解决方案不建议使用。
- en: However, If we cannot compress the vector we can prune the dimensions with the
    lowest scores. The system will execute a knn based on the most relevant scores
    of the vector; this direct method of feature engineering won’t affect negatively
    (better yet, not excessively) the results of the final recommendation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们无法压缩向量，我们可以修剪掉得分最低的维度。系统将基于向量中最相关的得分执行kNN；这种直接的特征工程方法不会对最终推荐结果产生负面影响（更好的是，不会过度影响）。
- en: '![](../Images/46c1392526fd1dff0a09f0e42bbeef5e.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46c1392526fd1dff0a09f0e42bbeef5e.png)'
- en: pruning mechanism, **image by Author**
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪机制，**图像由作者提供**
- en: By pruning our vector, we can arbitrarily set a maximum number of dimensions
    to our vectors. Without altering the tag indexes, we can start operating on sparse
    vectors, rather than a dense one, a data structure that only saves the active
    indexes of our vectors, being able to scale indefinitely. We can compare the recommendations
    obtained from a full vector (dense vector) against a sparse vector (pruned vector).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 通过修剪我们的向量，我们可以任意设置向量的最大维度数。在不改变标签索引的情况下，我们可以开始操作稀疏向量，而不是密集向量，稀疏向量是一种只保存我们向量中活动索引的数据结构，能够实现无限扩展。我们可以将从完整向量（密集向量）获得的推荐与稀疏向量（修剪向量）进行比较。
- en: '![](../Images/b204cc738fbcbbf25a164ce6503df5d7.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b204cc738fbcbbf25a164ce6503df5d7.png)'
- en: recommendation of the same user vector using a **dense** vs. **sparse** vector,
    **image by Author**
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**密集**向量与**稀疏**向量进行相同用户向量推荐，**图像由作者提供**
- en: As we can see, we can spot minor differences, but the overall integrity of the
    vector has been maintained **in exchange for scalability**. A very intuitive alternative
    to this process is by performing clustering at the tag level, maintaining the
    vector size fixed. In this case, a tag will need to be assigned to the closest
    tag semantically, and will not occupy its dedicated dimension.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们可以察觉到一些细微的差别，但向量的整体完整性保持了下来，**以换取可扩展性**。这种过程的一个非常直观的替代方法是，在标签级别进行聚类，保持向量大小固定。在这种情况下，标签将需要分配给语义上最接近的标签，并且不会占用其专有的维度。
- en: 7\. Exemplar estimation
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 示例估计
- en: Now that you have fully grasped the theory behind this new approach, we can
    compare them more clearly. In a multivariate approach, the first step was to identify
    the top user preferences using clustering. As we can see, this process required
    us to store as many vectors as found exemplars.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完全掌握了这种新方法背后的理论，我们可以更清楚地进行比较。在多变量方法中，第一步是使用聚类识别出用户的主要偏好。如我们所见，这个过程需要我们存储尽可能多的向量，以作为示例。
- en: '![](../Images/55e9fe07679c0340a30f4bd9c6e2f76c.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55e9fe07679c0340a30f4bd9c6e2f76c.png)'
- en: Examplar extraction, **image by Author**
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 示例提取，**图像由作者提供**
- en: 'However, in a univariate approach, **because covariate encoding works on a
    transposed version of the encoded data**, we can **use sections of our historical
    vector** to store user preferences, hence only using a single vector for the entire
    process. Using **the historical vector as a query** to search through encoded
    tags: its **top-k results from a knn search** will be equivalent to the top-k
    preferential clusters.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在单变量方法中，**因为协变量编码作用于编码数据的转置版本**，我们可以**使用我们历史向量的部分**来存储用户偏好，从而只使用一个向量完成整个过程。使用**历史向量作为查询**在编码标签中进行搜索：其**来自kNN搜索的top-k结果**将等同于top-k偏好聚类。
- en: '![](../Images/5cf17d3e31b20326a241e4f55ab28ced.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cf17d3e31b20326a241e4f55ab28ced.png)'
- en: difference between multivariate and univariate sets of vectors, **image by Author**
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量与单变量向量集的区别，**图像由作者提供**
- en: 8\. Recommendation approaches
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 推荐方法
- en: Now that we have captured more than one preference, how do we plan to recommend
    items? This is the major difference between the two systems. The traditional multivariate
    recommender will use the exemplar to **recommend k items** to a user. However,
    our system has assigned our customer one supercluster and the top subclusters
    under it (depending on our level of tag segmentation, we can increase the number
    of levels). We will not recommend the top k items, **but the top k subclusters**.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经捕捉到多个偏好，我们如何规划推荐项目？这是两个系统之间的主要区别。传统的多变量推荐系统将使用示例来**推荐k个项目**给用户。然而，我们的系统已经为客户分配了一个超级簇和其下的顶级子簇（根据我们的标签分割级别，我们可以增加层级数）。我们不会推荐前k个项目，而是**推荐前k个子簇**。
- en: Using groupby instead of vector search
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用groupby代替向量搜索
- en: So far, we have been using a vector to store data, but that **does not mean
    we need to rely on vector search** to perform recommendations, because it will
    be much slower than a SQL operation. Note that obtaining the same exact results
    using vector search on the user array is indeed possible.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直使用向量来存储数据，但这**并不意味着我们需要依赖向量搜索**来执行推荐，因为它比SQL操作要慢得多。请注意，确实可以使用向量搜索在用户数组上获得完全相同的结果。
- en: If you are wondering why you would be switching from a vector-based system to
    a count-based system, it is a legitimate question. The simple answer to **that
    is that this is the most loyal replica of the multivariate system** (as portrayed
    in the reference images), but much more scalable (it can reach up to 3000 recommendations/s
    on 16 CPU cores using pandas). Originally, the univariate recommender was designed
    to employ vector search, but, as showcased, there are simpler and better search
    algorithms.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在疑惑为什么要从基于向量的系统切换到基于计数的系统，这是一个合理的问题。简单的回答是**这是多变量系统最忠实的复制品**（如参考图像所示），但它具有更高的可扩展性（使用pandas在16个CPU核心上可以达到每秒3000个推荐）。最初，单变量推荐系统设计是使用向量搜索的，但正如所展示的，存在更简单、更好的搜索算法。
- en: Simulation
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟
- en: 'Let us run a full test that we can monitor. We can use the code from the sample
    notebook: for our simple example, the user selects at least one game **labeled
    with corresponding tags**.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一个完整的测试，我们可以监控它。我们可以使用示例笔记本中的代码：对于我们的简单示例，用户至少选择一个**带有相应标签的**游戏。
- en: '[PRE0]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At the end of 3 sessions, these are the top 3 exemplars (label_1) **extracted
    from our recommender**:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在三次会话结束时，这些是从我们的推荐系统**提取的前三个示例（label_1）**：
- en: '![](../Images/9ba1cb6df92b3ec947667c1b4c82be9e.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ba1cb6df92b3ec947667c1b4c82be9e.png)'
- en: recommendation after 3 sessions, **image by Author**
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 三次会话后的推荐，**图像由作者提供**
- en: In the notebook, you will find the option to perform Monte Carlo simulations,
    but there would be no easy way to validate them (mostly because team games are
    not tagged with the highest accuracy, and I noticed that most small games list
    too many unrelated or common tags).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，你将找到执行蒙特卡洛模拟的选项，但验证它们的方式并不简单（主要是因为团队游戏没有被标记为最高准确度，而且我注意到大多数小型游戏列出了太多不相关或常见的标签）。
- en: Conclusion
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The architectures of the most popular recommender systems still do not take
    into account session history, but with the development of new algorithms and the
    increase in computing power, it is now possible to tackle a higher level of complexity.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最受欢迎的推荐系统架构仍然没有考虑会话历史，但随着新算法的发展和计算能力的提高，现在可以应对更高层次的复杂性。
- en: This new approach should offer a comprehensive alternative to the **sequential
    recommender systems** available on the market, but I am convinced that there is
    always room for improvement. To further enhance this architecture it would be
    possible to switch from a **clustering-based** to a **network-based** approach.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新方法应该为市场上可用的**顺序推荐系统**提供一种全面的替代方案，但我相信总有改进的空间。为了进一步增强这一架构，可以考虑从**基于聚类**的方法切换到**基于网络**的方法。
- en: It is important to note that this recommender system can only excel when applied
    to a limited number of domains but has the potential to shine in conditions of
    scarce computational resources or extremely high demand.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这个推荐系统只有在应用于有限数量的领域时才能表现出色，但在计算资源匮乏或需求极高的情况下，仍具有闪光的潜力。
