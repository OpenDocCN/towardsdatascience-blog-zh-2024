- en: Extracting Information from Natural Language Using Generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成式 AI 从自然语言中提取信息
- en: 原文：[https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03](https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03](https://towardsdatascience.com/extracting-information-from-natural-language-using-generative-ai-ed64dcf1de66?source=collection_archive---------5-----------------------#2024-05-03)
- en: Extracting and structuring text elements with high accuracy using small models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用小型模型高精度地提取和结构化文本元素
- en: '[](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)[![Oren
    Matar](../Images/8b1fa6aa3585fc283d51828b53a0754c.png)](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)
    [Oren Matar](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)[![Oren
    Matar](../Images/8b1fa6aa3585fc283d51828b53a0754c.png)](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)
    [Oren Matar](https://medium.com/@orenmatar?source=post_page---byline--ed64dcf1de66--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)
    ·6 min read·May 3, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--ed64dcf1de66--------------------------------)
    ·6 分钟阅读 ·2024年5月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/12de85af31069135ae128e15c4e03a46.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12de85af31069135ae128e15c4e03a46.png)'
- en: Image generated by an AI by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者通过 AI 生成的图像
- en: In this post, I’ll introduce a paradigm recently developed at Anaplan for extracting
    temporal information from natural language text, as part of an NLQ (natural language
    query) project. While I will focus on time extraction, the paradigm is versatile
    and applicable for parsing various unstructured texts and extracting diverse patterns
    of information. This includes named entity recognition, text-to-SQL conversion,
    quantity extraction, and more.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍最近在 Anaplan 开发的一个范式，用于从自然语言文本中提取时间信息，这是 NLQ（自然语言查询）项目的一部分。虽然我将重点讨论时间提取，但这个范式具有多功能性，适用于解析各种非结构化文本并提取不同类型的信息模式。包括命名实体识别、文本到
    SQL 转换、数量提取等。
- en: The paradigm's core lies in constructing a flexible pipeline, which provides
    maximal flexibility, making it easy to fine-tune a model to extract the meaning
    from any conceivable expression in the language. It is based on a deep learning
    model (transformers) but for us, it achieved a 99.98% accuracy which is relatively
    rare for ML methods. Additionally, it does not utilize LLMs (large language models),
    in fact, it requires a minimal transformer model. This yields a compact, adaptable
    ML model, exhibiting the precision of rule-based systems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个范式的核心在于构建一个灵活的流水线，它提供了最大的灵活性，使得微调模型来提取任何可以想象的语言表达的意义变得简单。它基于深度学习模型（transformers），但对我们来说，它实现了
    99.98% 的准确率，这在机器学习方法中相对罕见。此外，它不使用大型语言模型（LLMs），实际上，它只需要一个最小的 transformer 模型。这生成了一个紧凑且适应性强的机器学习模型，展现了规则基础系统的精度。
- en: For those seeking time, numerical value, or phone number extraction, Facebook’s
    [Duckling package](https://github.com/facebook/duckling) offers a rule-based solution.
    However, if Duckling falls short of your requirements or you’re eager to explore
    a new ML paradigm, read on.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些需要提取时间、数值或电话号码的用户，Facebook 的 [Duckling 包](https://github.com/facebook/duckling)提供了一个基于规则的解决方案。但是，如果
    Duckling 无法满足您的需求，或者您希望探索一个新的机器学习范式，继续阅读吧。
- en: Can LLMs capture the meaning?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs 能否捕捉到意义？
- en: LLMs, despite their capabilities, face challenges in parsing such phrases and
    extracting their meaning comprehensively. Consider the expression “the first 15
    weeks of last year.” Converting this to a date range necessitates the model to
    determine the current year, subtract one, and calculate the position of the 15th
    week as it adjusts for leap years. Language models were not built for this kind
    of computation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大语言模型（LLMs）具有强大的能力，但在解析这些短语并全面提取其含义时仍然面临挑战。考虑表达式“the first 15 weeks of last
    year”。将其转换为日期范围要求模型确定当前年份，减去一年，并根据闰年调整计算第15周的位置。语言模型并不是为了这种计算而设计的。
- en: 'In my experience, LLMs can accurately output the correct date range around
    90–95% of the time but struggle with the remaining 5–10%, no matter the prompting
    techniques you use. Not to mention: LLMs are resource-intensive and slow.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，大语言模型可以在90-95%的时间里准确输出正确的日期范围，但在剩下的5-10%情况下会遇到困难，无论你使用什么提示技巧。更不用说：大语言模型资源消耗大且速度较慢。
- en: Thankfully, by following three principles, compact transformers can successfully
    accomplish the task
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，通过遵循三个原则，紧凑型变换器可以成功完成这个任务。
- en: Separate information extraction from logical deduction.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将信息提取与逻辑推理分开。
- en: Auto-generate a dataset using structured patterns.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用结构化模式自动生成数据集。
- en: Constrain the generative AI to the required structure.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成型AI限制为所需的结构。
- en: In this post, I will cover the first two, as the third one I covered in [a previous
    post](https://medium.com/towards-data-science/structured-generative-ai-e772123428e4).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍前两项，因为第三项我在[上一篇文章](https://medium.com/towards-data-science/structured-generative-ai-e772123428e4)中已经讨论过了。
- en: Separate information extraction from logical deduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将信息提取与逻辑推理分开。
- en: 'The first principle is to ensure that the language model’s role is to extract
    information from free text, rather than to make any logical deduction: logical
    deductions can easily be implemented in code.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个原则是确保语言模型的角色是从自由文本中提取信息，而不是进行任何逻辑推理：逻辑推理可以很容易地通过代码实现。
- en: 'Consider the phrase: “How many movies came out two years ago?” The language
    model’s task should be to identify that the relevant year is: `**this_year - 2**`,
    without calculating the actual year (which means it doesn’t need to know the current
    year). Its focus is parsing the meaning and structuring unstructured language.
    Once that formula is extracted, we can implement its calculation in code.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个短语：“How many movies came out two years ago？”语言模型的任务应该是识别出相关的年份是：`**this_year
    - 2**`，而不是计算实际年份（这意味着它不需要知道当前年份）。它的重点是解析意义并将非结构化语言进行结构化。一旦提取出这个公式，我们就可以在代码中实现其计算。
- en: 'For this to work, we introduce a Structured Time Language (STL) capable of
    expressing time elements. For instance, “on 2020” translates to “TIME.year==2020,”
    and “three months from now” becomes “NOW.month==3.” While the entire STL language
    isn’t detailed here, it should be relatively intuitive: you can reference attributes
    like year, quarter, and month for an absolute time or relative to NOW. The translation
    of “the last 12 weeks of last year” is “NOW.year==-1 AND TIME.week>=-12”'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一目标，我们引入了一种结构化时间语言（STL），能够表达时间元素。例如，“on 2020”翻译为“TIME.year==2020”，而“three
    months from now”则变成“NOW.month==3”。尽管本文没有详细介绍整个STL语言，但它应该是相对直观的：你可以引用像年份、季度和月份这样的属性来表示绝对时间或相对于NOW的时间。“last
    year’s last 12 weeks”的翻译是“NOW.year==-1 AND TIME.week>=-12”
- en: By removing any logical deduction or calculation from the task, we take a huge
    burden off the language model and allow it to focus on information extraction.
    This division of labor will improve its accuracy significantly. After the translation
    process is complete, it is straightforward to develop code for a parser that reads
    the structured language and retrieves the necessary date range.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将任务中的逻辑推理或计算去除，我们减轻了语言模型的负担，使其能够专注于信息提取。这种劳动分工将显著提高其准确性。翻译过程完成后，开发一个解析器的代码来读取结构化语言并检索所需的日期范围是非常简单的。
- en: Since this is a translation task — from natural language to STL — we used an
    encoder-decoder transformer. We used the [Bart model from Hugging Face](https://huggingface.co/docs/transformers/en/model_doc/bart),
    which can easily be fine-tuned for this task.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个翻译任务——从自然语言到STL——我们使用了一个编码器-解码器变换器。我们使用了[Hugging Face的Bart模型](https://huggingface.co/docs/transformers/en/model_doc/bart)，它可以很容易地针对这个任务进行微调。
- en: But how do we get the data for training the model?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何获取用于训练模型的数据呢？
- en: '**Auto-generate a dataset using structured patterns**'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**使用结构化模式自动生成数据集**'
- en: 'Since a training dataset for this translation task does not exist, we must
    generate it ourselves. This was done by following these steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此翻译任务没有现成的训练数据集，我们必须自己生成。这个过程是通过以下步骤完成的：
- en: '*Step one*: Write functions to map datetime objects to both “natural language”
    and STL formats:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*第一步*：编写函数，将日期时间对象映射到“自然语言”和STL格式：'
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Given a datetime object, these functions return a tuple of free text and its
    corresponding STL, for instance: “since 2020”, “TIME.year >= 2020”.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个日期时间对象，这些函数返回一个自由文本及其对应的STL元组，例如：“自2020年以来”，“TIME.year >= 2020”。
- en: '*Step two*: Sample a random function, and sample a random date within a specified
    range:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*第二步*：对一个随机函数进行采样，并在指定范围内采样一个随机日期：'
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: now insert the datetime to the function.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将日期时间插入到函数中。
- en: '*Step three*: Append the free text to a random question (we can easily randomly
    generate questions or draw them from some question dataset, their quality and
    meaning is not very important).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*第三步*：将自由文本附加到一个随机问题上（我们可以轻松地随机生成问题或从某个问题数据集中抽取，问题的质量和意义并不重要）。'
- en: 'With this pipeline, we can quickly generate 1000s of text-STL pairs, for example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个管道，我们可以快速生成成千上万的文本-STL对，例如：
- en: “What was the GDP growth in Q2–2019?”, “TIME.quarter==2 AND TIME.year==2019”
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “2019年第二季度的GDP增长是多少？”、“TIME.quarter==2 AND TIME.year==2019”
- en: “Since 2017, who won the most Oscars?”, “TIME.year>=2017”
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “自2017年以来，谁赢得了最多的奥斯卡奖？”、“TIME.year>=2017”
- en: “Who was the president on 3 May 2020?”, “TIME.date==2020/05/03”
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “2020年5月3日的总统是谁？”、“TIME.date==2020/05/03”
- en: This approach ensures flexibility in adding new patterns effortlessly. If you
    find a time expression that is not covered by one of these functions (e.g. “In
    N years”), you can write a function that will generate examples for this pattern
    within seconds.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法确保了在添加新模式时的灵活性。如果你发现一个时间表达式没有被这些函数覆盖（例如“在N年后”），你可以编写一个函数，几秒钟内就能生成这个模式的示例。
- en: In practice, we can optimize the code efficiency further. Rather than separate
    functions for each pattern like “since 2020” and “until 2020,” we can randomly
    sample connective words like “since,” “until,” “on,” etc. This initial batch of
    functions may require some time to develop, but you can quickly scale to 100s
    of patterns. Subsequently, addressing any missing expressions becomes trivial,
    as the pipeline is already established. With a few iterations, nearly all relevant
    expressions can be covered.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可以进一步优化代码效率。与其为每个模式（如“自2020年以来”和“直到2020年”）分别编写函数，不如随机采样连接词，如“自”、“直到”、“在”等。这个初步的函数集可能需要一些时间来开发，但你可以很快扩展到数百个模式。随后，解决任何缺失的表达式将变得微不足道，因为管道已经建立。通过几轮迭代，几乎所有相关的表达式都可以覆盖。
- en: '**Moreover, we don’t need to cover all the expressions**: Since the transformer
    model we used is pre-trained on a huge corpus of text, it will generalize from
    the provided patterns to new ones.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**此外，我们不需要覆盖所有表达式**：由于我们使用的变换模型已经在庞大的文本语料库上进行过预训练，它将从提供的模式中进行泛化，适应新的表达方式。'
- en: '**Finally, we can use an LLM to generate more examples**. Simply ask an LLM:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**最后，我们可以使用LLM来生成更多的示例**。只需向LLM提问：'
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And it may return:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能返回：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This data augmentation process can be automated too: sending numerous examples
    to an LLM, thus adding variety to our dataset. Given that the LLM’s role is solely
    in dataset creation, considerations of cost and speed become inconsequential.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据增强过程也可以自动化：将大量示例发送给LLM，从而为我们的数据集增加多样性。鉴于LLM的作用仅限于数据集创建，成本和速度的考量变得无关紧要。
- en: '**Combining the flexibility of adding new patterns, the generalization of the
    pre-trained model, and data augmentation using an LLM, we can effectively cover
    almost any expression.**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**结合新增模式的灵活性、预训练模型的泛化能力，以及使用LLM的数据增强，我们可以有效地覆盖几乎所有的表达方式。**'
- en: The final principle of this paradigm is to constrain the generative AI to produce
    only STL queries, ensuring adherence to the required structure. The method to
    achieve this, as well as a method for optimizing the tokenization process, was
    discussed [in a previous post](https://medium.com/towards-data-science/structured-generative-ai-e772123428e4).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个范式的最终原则是将生成式AI限制为仅生成STL查询，确保遵循所需的结构。实现这一目标的方法，以及优化标记化过程的方法，已在[之前的文章](https://medium.com/towards-data-science/structured-generative-ai-e772123428e4)中讨论过。
- en: By adhering to these three principles, we achieved an impressive accuracy of
    99.98% on our test dataset. Moreover, this paradigm gave us the flexibility to
    address new, unsupported, time expressions swiftly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这三条原则，我们在测试数据集上达到了99.98%的令人印象深刻的准确率。此外，这一范式赋予了我们灵活性，能够迅速处理新的、未支持的时间表达式。
- en: '**Summary**'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Large Language Models (LLMs) aren’t always the optimal solution for language
    tasks. With the right approach, shallower transformer models can efficiently extract
    information from natural language with high accuracy and flexibility, at a reduced
    time and cost.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）并不总是语言任务的最佳解决方案。采用正确的方法，较浅层的变压器模型能够高效、灵活地从自然语言中提取信息，同时减少时间和成本，且具有高准确性。
- en: 'The key principles to remember are:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的关键原则是：
- en: Focusing the model only on information extraction, avoiding complex logical
    deductions. This may require generating a mediating language and implementing
    a parser and logical deduction in code.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型专注于信息提取，避免复杂的逻辑推理。这可能需要生成一个中介语言，并在代码中实现解析器和逻辑推理。
- en: Establishing a pipeline for generating a dataset and training a model, so that
    adding new functionality (new language patterns) is straightforward and fast.
    This pipeline can include the use of an LLM, adding more variety to the dataset.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立一个数据集生成和模型训练的管道，使得添加新功能（新的语言模式）变得简单而快捷。这个管道可以包括使用大型语言模型（LLM），为数据集添加更多的多样性。
- en: Confining the model generation to the constraints of a structured language.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型生成限制在结构化语言的约束之内。
- en: While this post focused on extracting time elements, the paradigm applies to
    extracting any information from free text and structuring it into various formats.
    With this paradigm, you can achieve the accuracy of a rule-based engine, with
    the flexibility of a machine learning model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这篇文章主要关注提取时间元素，但这一范式适用于从自由文本中提取任何信息，并将其结构化为各种格式。通过这一范式，你可以实现规则引擎的精确性，同时具备机器学习模型的灵活性。
