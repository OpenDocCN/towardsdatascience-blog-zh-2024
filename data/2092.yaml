- en: How to Easily Set Up a Neat User Interface for Your Local LLM
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何轻松为你的本地LLM设置一个简洁的用户界面
- en: 原文：[https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28](https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28](https://towardsdatascience.com/how-to-easily-set-up-a-neat-user-interface-for-your-local-llm-1a972da2310e?source=collection_archive---------3-----------------------#2024-08-28)
- en: A step-by-step guide to run Llama3 locally with Open WebUI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一步步的指南：如何使用Open WebUI在本地运行Llama3
- en: '[](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Guillaume
    Weingertner](../Images/fbfb34af986a7788394b6033c6954d57.png)](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    [Guillaume Weingertner](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Guillaume
    Weingertner](../Images/fbfb34af986a7788394b6033c6954d57.png)](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    [Guillaume Weingertner](https://guillaume-weingertner.medium.com/?source=post_page---byline--1a972da2310e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    ·6 min read·Aug 28, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--1a972da2310e--------------------------------)
    ·阅读时间6分钟·2024年8月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3b758ee77d1c941a6348673fd2974348.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b758ee77d1c941a6348673fd2974348.png)'
- en: Image generated by AI (Midjourney) by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由AI（Midjourney）生成，作者提供
- en: '#1 Why Local LLMs'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '#1 为什么选择本地LLM'
- en: Whether it’s due to company restrictions or a desire to handle personal data
    securely, many have avoided using ChatGPT due to data privacy concerns.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是由于公司限制，还是希望安全地处理个人数据，许多人因为数据隐私问题避免使用ChatGPT。
- en: Fortunately, there are solutions that allow **unlimited** use of LLMs without
    sending sensitive data to the cloud.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一些解决方案可以让你**无限制**地使用LLM，而不需要将敏感数据发送到云端。
- en: In my previous article, I explored one such solution by explaining how to run
    Llama 3 locally thanks to Ollama.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的文章中，我探讨了通过Ollama在本地运行Llama 3的一种解决方案。
- en: '[](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
    [## Running Local LLMs is More Useful and Easier Than You Think'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
    [## 本地运行LLM比你想象的更有用、更容易'
- en: A step-by-step guide to run Llama3 locally with Python
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一步步的指南：如何使用Python在本地运行Llama3
- en: towardsdatascience.com](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/running-local-llms-is-more-useful-and-easier-than-you-think-f735631272ad?source=post_page-----1a972da2310e--------------------------------)
- en: '**PREREQUISITE**: by the end of that last article we had Llama 3 running locally
    thanks to Ollama and we could use it either through the terminal or within a Jupyter
    Notebook.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件**：在上一篇文章的结尾，我们已经通过Ollama在本地运行了Llama 3，并且可以通过终端或在Jupyter Notebook中使用它。'
- en: In this article I explain how to make the use of local LLMs more user-friendly
    through a neat UI in a matter of minutes!
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在本文中，我将解释如何通过简洁的用户界面在几分钟内使本地LLM的使用变得更加用户友好！
