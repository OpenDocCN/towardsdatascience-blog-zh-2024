- en: 'Building a RAG Pipeline with MongoDB: Vector Search for Personalized Picks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MongoDB 构建 RAG 流水线：个性化推荐的向量搜索
- en: 原文：[https://towardsdatascience.com/building-a-rag-pipeline-with-mongodb-vector-search-for-personalized-movie-picks-46a58a2aaac9?source=collection_archive---------8-----------------------#2024-08-01](https://towardsdatascience.com/building-a-rag-pipeline-with-mongodb-vector-search-for-personalized-movie-picks-46a58a2aaac9?source=collection_archive---------8-----------------------#2024-08-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-a-rag-pipeline-with-mongodb-vector-search-for-personalized-movie-picks-46a58a2aaac9?source=collection_archive---------8-----------------------#2024-08-01](https://towardsdatascience.com/building-a-rag-pipeline-with-mongodb-vector-search-for-personalized-movie-picks-46a58a2aaac9?source=collection_archive---------8-----------------------#2024-08-01)
- en: '[](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)[![Pablo
    Merchán-Rivera, Ph.D.](../Images/a560330911c7ba23fd4839e33e528f5a.png)](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)
    [Pablo Merchán-Rivera, Ph.D.](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)[![Pablo
    Merchán-Rivera, Ph.D.](../Images/a560330911c7ba23fd4839e33e528f5a.png)](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)
    [Pablo Merchán-Rivera, Ph.D.](https://medium.com/@pablomerchanrivera?source=post_page---byline--46a58a2aaac9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)
    ·7 min read·Aug 1, 2024
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--46a58a2aaac9--------------------------------)
    ·7 分钟阅读·2024 年 8 月 1 日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This article explores the construction of a movie recommendation system using
    a Retrieval-Augmented Generation (RAG) pipeline. The objective is to learn how
    to harness the power of MongoDB’s vector search capabilities, transform data descriptions
    into searchable digital fingerprints, and create a system that understands the
    nuances of your preferences and your communication. In other words, we will aim
    to build a recommendation system that’s not just smart, but also efficient.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了使用检索增强生成（RAG）流水线构建电影推荐系统的过程。目标是学习如何利用 MongoDB 的向量搜索功能，将数据描述转化为可搜索的数字指纹，并创建一个能够理解你偏好和沟通细节的系统。换句话说，我们的目标是构建一个不仅智能，而且高效的推荐系统。
- en: By the end of this article, you’ll have built a functional movie recommendation
    system. This system will be able to take a user’s query, such as *“I want to watch
    a good sci-fi movie that explores artificial intelligence”* or *“What is a good
    animated film that adults would enjoy too? What makes your suggestion a good fit?”*
    and return relevant movie suggestions and the choice reasoning.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文结束时，你将能够构建一个功能完整的电影推荐系统。该系统能够接受用户的查询，如 *“我想看一部探讨人工智能的科幻电影”* 或 *“什么是适合成人也能欣赏的好动画电影？为什么你的建议适合？”*
    并返回相关的电影建议及选择理由。
- en: '![](../Images/a1cde82c3c844d5926591d0148cf5a4f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1cde82c3c844d5926591d0148cf5a4f.png)'
- en: Photo by [Alexandr Popadin](https://unsplash.com/@irrabagon?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Alexandr Popadin](https://unsplash.com/@irrabagon?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: What is a RAG Pipeline?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 RAG 流水线？
- en: A RAG pipeline refers to the sequential flow of data through a series of processing
    steps that combines the strengths of large language models (LLMs) with structured
    data retrieval. It works by first retrieving relevant information from a knowledge
    base, and then using this information to augment the input of a large language
    model, which generates the final output. The primary objective of such a pipeline
    is to generate more accurate, contextually appropriate, and personalised responses
    to user-specific queries from vast databases.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: RAG管道指的是数据通过一系列处理步骤的顺序流动，结合了大型语言模型（LLM）与结构化数据检索的优势。它的工作原理是首先从知识库中检索相关信息，然后利用这些信息增强大型语言模型的输入，从而生成最终的输出。此类管道的主要目标是生成更准确、更具上下文相关性且更具个性化的响应，以回答用户针对庞大数据库提出的查询。
- en: Why MongoDB?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择MongoDB？
- en: MongoDB is a open-source NoSQL database that stores data in flexible, JSON-like
    documents, allowing for easy scalability and handling of diverse data types and
    structures. MongoDB plays a significant role in this project. Its document model
    aligns well with our movie data, while its vector search capabilities enable similarity
    searches on our embeddings (i.e., the numerical representations of movie content).
    We can also take advantage of indexing and query optimisation features to maintain
    quick data retrieval even as the dataset expands.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB是一个开源的NoSQL数据库，它以灵活的、类似JSON的文档形式存储数据，允许轻松扩展，并能处理多种数据类型和结构。MongoDB在这个项目中扮演了重要角色。它的文档模型与我们的电影数据非常契合，而它的向量搜索功能可以对我们的嵌入（即电影内容的数字表示）进行相似度搜索。我们还可以利用索引和查询优化功能，以保持即使数据集扩展时也能快速检索数据。
- en: Our Project
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的项目
- en: 'Here’s what our pipeline will look like:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的管道流程如下所示：
- en: Set up the environment and load movie data from Hugging Face
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置环境并从Hugging Face加载电影数据
- en: Model the data using Pydantic
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Pydantic对数据进行建模
- en: Generate embeddings for the movies information
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为电影信息生成嵌入
- en: Ingest the data into a MongoDB database
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据导入MongoDB数据库
- en: Create a Vector Search Index in MongoDB Atlas
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在MongoDB Atlas中创建向量搜索索引
- en: Perform vector search operations to find relevant movies
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行向量搜索操作，找到相关电影
- en: Handle user queries with an LLM model
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用LLM模型处理用户查询
- en: Use the RAG pipeline to get a movie recommendation
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RAG管道获取电影推荐
- en: 'Step 1: Setting Up the Environment and Loading the Dataset'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：设置环境并加载数据集
- en: 'First, we need to import the necessary libraries and set up our environment.
    This also involves setting up our API keys and the connection string that the
    application uses to connect to a MongoDB database:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入必要的库并设置我们的环境。这还包括设置API密钥和应用程序用于连接MongoDB数据库的连接字符串：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we load our movie dataset:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载我们的电影数据集：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The dataset contains more than 9000 entries. However, for this exercise, we’re
    limiting our dataset to 200 movies using `dataset.take(200)`. In a real-world
    scenario, you’d likely use a much larger dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含超过9000条记录。然而，在这个练习中，我们将数据集限制为200部电影，使用`dataset.take(200)`。在实际应用中，您可能会使用更大的数据集。
- en: 'Step 2: Modeling the Data with Pydantic'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：使用Pydantic对数据建模
- en: 'Data modeling is crucial for ensuring consistency and type safety in our application.
    Hence, we use Pydantic for this purpose:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模对于确保我们应用程序的一致性和类型安全至关重要。因此，我们使用Pydantic来实现这一目的：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Using Pydantic provides several benefits, such as automatic data validation,
    type checking, and easy serialization/deserialization. Notice that we also created
    a `text_embeddings` field that will store our generated embeddings as a list of
    floats
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Pydantic提供了多个好处，例如自动数据验证、类型检查和简便的序列化/反序列化。注意，我们还创建了一个`text_embeddings`字段，用于存储我们生成的嵌入，作为浮动点数列表。
- en: 'Step 3: Embedding Generation'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步：嵌入生成
- en: 'Now, we can use the OpenAI API and write a function for generating embeddings,
    as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用OpenAI API，并编写一个生成嵌入的函数，如下所示：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the previous code lines, we first check if the input is valid (non-empty
    string). Then, we use OpenAI’s embeddings.create method to generate the embedding
    using the “text-embedding-3-small” model, which generates 1536-dimensional embeddings.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码行中，我们首先检查输入是否有效（非空字符串）。然后，我们使用OpenAI的embeddings.create方法生成嵌入，采用“text-embedding-3-small”模型，该模型生成1536维的嵌入。
- en: Now, we can process each record and generate embeddings with the previous function.
    We also add some lines to process the `'Genre'` field, converting it from a string
    (if it exists) to a list of genres.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以处理每条记录并使用之前的函数生成嵌入。我们还添加了一些代码来处理 `'Genre'` 字段，将其从字符串（如果存在）转换为一组类型列表。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: These embeddings will allow us to perform semantic searches later, finding movies
    that are conceptually similar to a given query. Notice that this process might
    take some time, especially for larger datasets, as we’re making an API call for
    each movie.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些嵌入将使我们能够进行语义搜索，找到与给定查询在概念上相似的电影。请注意，这一过程可能需要一些时间，尤其是在数据集较大的情况下，因为我们为每部电影都要进行一次
    API 调用。
- en: 'Step 4: Data Ingestion into MongoDB'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 4 步：将数据导入 MongoDB
- en: 'We establish a connection to our MongoDB database:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建立与 MongoDB 数据库的连接：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We insert our processed and embedded data into MongoDB, which allows us to
    efficiently store and query our movie data, including the high-dimensional embeddings:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理并嵌入的数据插入 MongoDB，这使得我们能够高效地存储和查询我们的电影数据，包括高维嵌入：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Step 5: Creating a Vector Search Index in MongoDB Atlas'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 5 步：在 MongoDB Atlas 中创建向量搜索索引
- en: 'Before we can perform vector search operations, we need to create a vector
    search index. This step can be done directly in the MongoDB Atlas platform:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行向量搜索操作之前，我们需要创建一个向量搜索索引。此步骤可以直接在 MongoDB Atlas 平台上完成：
- en: Log in to your MongoDB Atlas account
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到您的 MongoDB Atlas 帐户
- en: Navigate to your cluster
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到您的集群
- en: Go to the “Search & Vector Search” tab
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到“搜索与向量搜索”标签
- en: Click on “Create Search Index”
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“创建搜索索引”
- en: 'Choose “JSON Editor” in the “Atlas Vector Search” section and use the following
    configuration:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“Atlas 向量搜索”部分选择“JSON 编辑器”，并使用以下配置：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The idea is to create a vector search index named `"vector_index_text"` on the
    `"text_embeddings"` field. We use cosine similarity because it helps us find movies
    with similar themes or content by comparing the direction of their embedding vectors,
    ignoring differences in length or amount of detail, which is really good for matching
    a user’s query to movie descriptions.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是创建一个名为 `"vector_index_text"` 的向量搜索索引，索引的字段为 `"text_embeddings"`。我们使用余弦相似度，因为它有助于通过比较嵌入向量的方向来找到主题或内容相似的电影，忽略长度或细节的差异，这对于将用户的查询与电影描述进行匹配非常有效。
- en: 'Step 6: Implementing Vector Search'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 6 步：实现向量搜索
- en: Now, we implement the vector search function. The following function is meant
    to perform a vector search in our MongoDB collection. It first generates an embedding
    for the user’s query. It then constructs a MongoDB aggregation pipeline using
    the $vectorSearch operator. The search looks for the 20 nearest neighbors among
    150 candidates.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们实现向量搜索功能。以下函数用于在我们的 MongoDB 集合中执行向量搜索。它首先为用户的查询生成嵌入。然后，利用 `$vectorSearch`
    运算符构建 MongoDB 聚合管道。搜索会在 150 个候选项中查找 20 个最近的邻居。
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We implement a retry mechanism (up to 3 attempts) to handle potential transient
    issues. The function executes the `explain` command as well, which provides detailed
    information about the query execution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个重试机制（最多 3 次尝试），以处理可能的临时问题。该函数还执行 `explain` 命令，提供有关查询执行的详细信息。
- en: 'Step 7: Handling User Queries with a LLM'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 7 步：使用 LLM 处理用户查询
- en: 'Finally, we can handle user queries. First, we define a `SearchResultItem`
    class to structure our search results. Then, the `handle_user_query` function
    ties everything together: it performs a vector search based on the user’s query,
    formats the search results into a pandas DataFrame, and then uses OpenAI’s GPT
    model (i.e., gpt-3.5-turbo) to generate a response based on the search results
    and the user’s query, and displays the results and the generated response:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以处理用户查询。首先，我们定义一个 `SearchResultItem` 类来构建搜索结果。然后，`handle_user_query` 函数将所有内容结合在一起：它根据用户的查询执行向量搜索，将搜索结果格式化为
    pandas DataFrame，并使用 OpenAI 的 GPT 模型（即 gpt-3.5-turbo）根据搜索结果和用户的查询生成回应，并显示结果及生成的回应：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This function actually demonstrates the core value of this RAG: we generate
    a contextually appropriate response by retrieving relevant information from our
    database.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能实际上展示了 RAG 的核心价值：通过从我们的数据库中检索相关信息，生成一个情境适当的回应。
- en: 8\. Using the RAG Pipeline
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 使用 RAG 管道
- en: 'To use this RAG pipeline, you can now make queries like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此 RAG 管道，现在可以进行如下查询：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The system would give a respond similar to this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 系统将返回类似以下的响应：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Building a RAG pipeline involves several steps, from data loading and modeling
    to embedding generation and vector search. This example showcases how a RAG pipeline
    can provide informative, context-aware responses by combining the specific movie
    data in our database with the natural language understanding and generation capabilities
    of the language model. On top of this, we use MongoDB because it is well-suited
    for this type of workflow due to its native vector search capabilities, flexible
    document model, and scalability.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个RAG管道涉及多个步骤，从数据加载和建模到嵌入生成和向量搜索。这个示例展示了如何通过将我们数据库中的特定电影数据与语言模型的自然语言理解和生成能力结合，来提供信息丰富、上下文感知的回答。在此基础上，我们使用MongoDB，因为它具有原生向量搜索功能、灵活的文档模型和可扩展性，非常适合这种工作流程。
- en: You can expand on this system by adding more data, fine-tuning your embeddings,
    or implementing more complex recommendation algorithms.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过添加更多数据、微调你的嵌入，或实现更复杂的推荐算法来扩展这个系统。
- en: '*For the complete code and additional resources, check out the* [*GitHub repository*](https://github.com/mr-pablinho/rag-mongodb-moviepl)*.
    The dataset used in this project is sourced from* [*Kaggle*](https://www.kaggle.com/datasets/disham993/9000-movies-dataset/data)
    *and has been granted CC0 1.0 Universal (CC0 1.0) Public Domain Dedication by
    the original author. You can find the dataset and more information* [*here*](https://huggingface.co/datasets/Pablinho/movies-dataset)*.*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*有关完整代码和更多资源，请查看* [*GitHub 仓库*](https://github.com/mr-pablinho/rag-mongodb-moviepl)*。此项目使用的数据集来源于*
    [*Kaggle*](https://www.kaggle.com/datasets/disham993/9000-movies-dataset/data)
    *，并已获得原作者授予的CC0 1.0 通用公共领域授权（CC0 1.0）。你可以在* [*这里*](https://huggingface.co/datasets/Pablinho/movies-dataset)
    *找到数据集和更多信息*。'
