- en: 'Human Pose Tracking with MediaPipe in 2D and 3D: Rerun Showcase'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MediaPipe进行2D和3D的人体姿势跟踪：Rerun展示
- en: 原文：[https://towardsdatascience.com/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=collection_archive---------1-----------------------#2024-03-11](https://towardsdatascience.com/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=collection_archive---------1-----------------------#2024-03-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=collection_archive---------1-----------------------#2024-03-11](https://towardsdatascience.com/human-pose-tracking-with-mediapipe-rerun-showcase-125053cfe64f?source=collection_archive---------1-----------------------#2024-03-11)
- en: How to easily visualise MediaPipe’s human pose tracking with Rerun
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何轻松地使用Rerun可视化MediaPipe的人体姿势跟踪
- en: '[](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)[![Andreas
    Naoum](../Images/e14d545f270170877e0af31572275e17.png)](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)
    [Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)[![Andreas
    Naoum](../Images/e14d545f270170877e0af31572275e17.png)](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)
    [Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page---byline--125053cfe64f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)
    ·7 min read·Mar 11, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--125053cfe64f--------------------------------)
    ·7分钟阅读·2024年3月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f8588c83a6d99bada222874b26a1f256.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8588c83a6d99bada222874b26a1f256.png)'
- en: Human Pose Tracking | Image by Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 人体姿势跟踪 | 作者图片
- en: Overview
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: We explore a use case that leverages the power of [MediaPipe](https://developers.google.com/mediapipe)
    for tracking human poses in both 2D and 3D. What makes this exploration even more
    fascinating is the visualisation aspect powered by the open-source visualisation
    tool [Rerun](https://www.rerun.io), which provides a holistic view of human poses
    in action.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了一个利用[MediaPipe](https://developers.google.com/mediapipe)跟踪2D和3D人体姿势的应用案例。更吸引人的是，使用开源可视化工具[Rerun](https://www.rerun.io)的可视化功能，为人体姿势提供了全景式的动态展示。
- en: In this blog post, you’ll be guided to use MediaPipe to track human poses in
    2D and 3D, and explore the visualisation capabilities of Rerun.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，您将学习如何使用MediaPipe进行2D和3D人体姿势跟踪，并探索Rerun的可视化功能。
- en: Human Pose Tracking
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人体姿势跟踪
- en: Human pose tracking is a task in computer vision that focuses on identifying
    key body locations, analysing posture, and categorising movements. At the heart
    of this technology is a pre-trained machine-learning model to assess the visual
    input and recognise landmarks on the body in both image coordinates and 3D world
    coordinates. The use cases and applications of this technology include but are
    not limited to Human-Computer Interaction, Sports Analysis, Gaming, Virtual Reality,
    Augmented Reality, Health, etc.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人体姿势跟踪是计算机视觉中的一项任务，重点是识别关键的身体位置、分析姿势并分类动作。这项技术的核心是一种预训练的机器学习模型，用于评估视觉输入并识别图像坐标和3D世界坐标中的身体关键点。该技术的应用案例包括但不限于人机交互、运动分析、游戏、虚拟现实、增强现实、健康等。
- en: It would be good to have a perfect model, but unfortunately, the current models
    are still imperfect. Although datasets could have a variety of body types, the
    human body differs among individuals. The uniqueness of each individual’s body
    poses a challenge, particularly for those with non-standard arm and leg dimensions,
    which may result in lower accuracy when using this technology. When considering
    the integration of this technology into systems, it is crucial to acknowledge
    the possibility of inaccuracies. Hopefully, ongoing efforts within the scientific
    community will pave the way for the development of more robust models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个完美的模型固然好，但遗憾的是，目前的模型仍不完善。尽管数据集可能包含各种人体类型，但每个人的身体差异很大。每个人体态的独特性带来了挑战，尤其是对于那些具有非标准臂长和腿长的人群，这可能会导致使用此技术时准确度降低。在考虑将这项技术整合到系统时，必须认识到可能存在的不准确性。希望科学界的持续努力能够为开发更强大的模型铺平道路。
- en: Beyond lack of accuracy, ethical and legal considerations emerge from utilising
    this technology. For instance, capturing human body poses in public spaces could
    potentially invade privacy rights if individuals have not given their consent.
    It’s crucial to take into account any ethical and legal concerns before implementing
    this technology in real-world scenarios.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了缺乏准确性，利用这项技术还涉及到伦理和法律方面的问题。例如，在公共场所捕捉人体姿势可能会侵犯隐私权，尤其是在个人未同意的情况下。 在将这项技术应用于实际场景之前，考虑任何伦理和法律问题是至关重要的。
- en: Prerequisites & Setup
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前置条件与设置
- en: 'Begin by installing the required libraries:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先安装所需的库：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Track Human Pose using MediaPipe
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MediaPipe跟踪人体姿势
- en: '![](../Images/d027aae91cc4189161358f87f836a4f4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d027aae91cc4189161358f87f836a4f4.png)'
- en: Image via [Pose Landmark Detection Guide](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    by [Google](https://about.google/brand-resource-center/) [1]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[姿势标记检测指南](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    [Google](https://about.google/brand-resource-center/) [1]
- en: '[**MediaPipe Python**](https://mediapipe-studio.webapps.google.com/home) is
    a handy tool for developers looking to integrate on-device ML solutions for computer
    vision and machine learning.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[**MediaPipe Python**](https://mediapipe-studio.webapps.google.com/home)是一个方便的工具，适用于希望将设备端机器学习解决方案集成到计算机视觉和机器学习中的开发者。'
- en: In the code below, [MediaPipe pose landmark detection](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    was utilised for detecting landmarks of human bodies in an image. This model can
    detect body pose landmarks as both image coordinates and 3D world coordinates.
    Once you have successfully run the ML model, you can use the image coordinates
    and the 3D world coordinates to visualise the output.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，使用了[MediaPipe 姿势标记检测](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)来检测图像中的人体标记。此模型可以检测人体姿势标记，既可以作为图像坐标，也可以作为3D世界坐标。一旦成功运行了机器学习模型，就可以使用图像坐标和3D世界坐标来可视化输出结果。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualise the output of MediaPipe using Rerun
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Rerun可视化MediaPipe的输出
- en: '![](../Images/0ffbd838ee50a8f7b64114417b1e978b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ffbd838ee50a8f7b64114417b1e978b.png)'
- en: Rerun Viewer | Image via [Rerun Docs](https://www.rerun.io/docs/reference/viewer/overview)
    [2]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Rerun 观察器 | 图片来自 [Rerun 文档](https://www.rerun.io/docs/reference/viewer/overview)
    [2]
- en: '[Rerun](https://www.rerun.io) serves as a visualisation tool for multi-modal
    data. Through the [Rerun Viewer](https://www.rerun.io/docs/reference/viewer/overview),
    you can build layouts, customise visualisations and interact with your data. The
    rest part of this section details how you can log and present data using the Rerun
    SDK to visualise it within the Rerun Viewer'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[Rerun](https://www.rerun.io)作为一个多模态数据可视化工具，通过[Rerun观察器](https://www.rerun.io/docs/reference/viewer/overview)，你可以构建布局、定制可视化效果，并与数据进行交互。
    本节的其余部分将详细介绍如何使用Rerun SDK记录和呈现数据，并在Rerun观察器中进行可视化。'
- en: '![](../Images/bba414c2f083ce237872945da1c80150.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bba414c2f083ce237872945da1c80150.png)'
- en: Pose Landmarker Model | Image via [Pose Landmark Detection Guide](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    by [Google](https://about.google/brand-resource-center/) [1]
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势标记模型 | 图片来自[姿势标记检测指南](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    [Google](https://about.google/brand-resource-center/) [1]
- en: In both 2D and 3D points, specifying connections between points is essential.
    Defining these connections automatically renders lines between them. Using the
    information provided by MediaPipe, you can get the pose points connections from
    the `POSE_CONNECTIONS` set and then set them as keypoint connections using [Annotation
    Context](https://www.rerun.io/docs/concepts/annotation-context).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在2D和3D点中，指定点之间的连接是至关重要的。定义这些连接会自动渲染它们之间的线条。利用MediaPipe提供的信息，你可以从`POSE_CONNECTIONS`集合中获取姿势点连接，然后通过[Annotation
    Context](https://www.rerun.io/docs/concepts/annotation-context)将它们设置为关键点连接。
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Image Coordinates — 2D Positions
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像坐标 — 2D位置
- en: '![](../Images/20e233978eee38de893191d9b35b30f8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20e233978eee38de893191d9b35b30f8.png)'
- en: Visualising Human Pose as 2D Points | Image by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以2D点可视化人体姿势 | 图片作者
- en: Visualising the body pose landmarks on the video appears to be a good choice.
    To achieve that, you need to follow the rerun documentation for Entities and Components.
    [The Entity Path Hierarchy](https://www.rerun.io/docs/concepts/entity-path) page
    describes how to log multiple Components on the same Entity. For example, you
    can create the ‘video’ entity and include the components ‘video/rgb’ for the video
    and ‘video/pose’ for the body pose. If you’re aiming to use that for a video,
    you need the concept of [Timelines](https://www.rerun.io/docs/concepts/timelines).
    Each frame can be associated with the appropriate data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在视频上可视化身体姿势关键点似乎是一个不错的选择。为了实现这一点，你需要遵循Rerun文档中的实体和组件部分。[实体路径层次结构](https://www.rerun.io/docs/concepts/entity-path)页面描述了如何在同一实体上记录多个组件。例如，你可以创建“video”实体，并包括‘video/rgb’（视频）和‘video/pose’（身体姿势）组件。如果你打算将其用于视频，你需要使用[时间线](https://www.rerun.io/docs/concepts/timelines)的概念。每一帧都可以与适当的数据关联。
- en: 'Here is a function that can visualise the 2D points on the video:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个可以在视频上可视化2D点的函数：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 3D World Coordinates — 3D Points
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D世界坐标 — 3D点
- en: '![](../Images/fc0f27b3622dd6cffc6cbae4a70cb5fb.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc0f27b3622dd6cffc6cbae4a70cb5fb.png)'
- en: Visualising Human Pose as 3D Points | Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以3D点可视化人体姿势 | 图片作者
- en: Why settle on 2D points when you have 3D Points? Create a new entity, name it
    “Person”, and log the 3D points. It’s done! You just created a 3D presentation
    of the human body pose.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要满足于2D点，当你可以使用3D点呢？创建一个新的实体，命名为“Person”，并记录3D点。完成！你刚刚创建了一个人类身体姿势的3D展示。
- en: 'Here is how to do it:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何实现的：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Source Code
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码
- en: The tutorial focuses on the main parts of the Human Pose Tracking example. For
    those who prefer a hands-on approach, the full source code for this example is
    available on [GitHub](https://github.com/rerun-io/rerun/tree/latest/examples/python/human_pose_tracking).
    Feel free to explore, modify, and understand the inner workings of the implementation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程专注于人体姿势追踪示例的主要部分。对于那些喜欢动手实践的人来说，这个示例的完整源代码可以在[GitHub](https://github.com/rerun-io/rerun/tree/latest/examples/python/human_pose_tracking)上找到。随意探索、修改并理解实现的内部工作原理。
- en: Tips & Suggestions
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示与建议
- en: 1\. Compress the image for efficiency
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 为了提高效率，压缩图像
- en: 'You can boost the overall procedure speed by compressing the logged images:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过压缩记录的图像来提升整体处理速度：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 2\. Limit Memory Use
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 限制内存使用
- en: If you’re logging more data than can be fitted into your RAM, it will start
    dropping the old data. The default limit is 75% of your system RAM. If you want
    to increase that you could use the command line argument — memory-limit. More
    information about memory limits can be found on Rerun’s [How To Limit Memory Use](https://www.rerun.io/docs/howto/limit-ram)
    page.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记录的数据超出了RAM的容量，系统会开始丢弃旧数据。默认的限制是系统RAM的75%。如果你希望增加该限制，可以使用命令行参数—memory-limit。更多关于内存限制的信息可以在Rerun的[如何限制内存使用](https://www.rerun.io/docs/howto/limit-ram)页面找到。
- en: 3\. Customise Visualisations for your needs
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 根据需求定制可视化
- en: '![](../Images/98f7548f01e6161352b1194f993aaf09.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98f7548f01e6161352b1194f993aaf09.png)'
- en: Customise Rerun Viewer | Image by Author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义Rerun Viewer | 图片作者
- en: Beyond Human Pose Tracking
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越人体姿势追踪
- en: '*If you found this article useful and insightful, there’s more!*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得这篇文章有用并富有洞察力，那么还有更多内容！*'
- en: '*Similar articles:*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*类似的文章：*'
- en: '[](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----125053cfe64f--------------------------------)
    [## Real-Time Face and Face Landmark Detection with MediaPipe: Rerun Showcase'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----125053cfe64f--------------------------------)
    [## 实时人脸与面部关键点检测与MediaPipe：Rerun展示'
- en: How to easily visualise MediaPipe’s face and face landmark detection in 2D and
    3D with Rerun
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何轻松使用Rerun可视化MediaPipe的人脸和面部地标检测（2D和3D）
- en: 'ai.gopubby.com](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----125053cfe64f--------------------------------)
    [](/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=post_page-----125053cfe64f--------------------------------)
    [## Real-Time Hand Tracking and Gesture Recognition with MediaPipe: Rerun Showcase'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ai.gopubby.com](https://ai.gopubby.com/real-time-face-and-face-landmark-detection-with-mediapipe-rerun-showcase-40481baa1763?source=post_page-----125053cfe64f--------------------------------)
    [](/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=post_page-----125053cfe64f--------------------------------)
    [## 使用MediaPipe进行实时手部跟踪和手势识别：Rerun展示
- en: How to visualise MediaPipe’s Hand Tracking and Gesture Recognition with Rerun
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何使用Rerun可视化MediaPipe的手部跟踪和手势识别
- en: towardsdatascience.com](/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=post_page-----125053cfe64f--------------------------------)
    ![Andreas Naoum](../Images/5af57533919b28694a1f6a0caf923221.png)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/real-time-hand-tracking-and-gesture-recognition-with-mediapipe-rerun-showcase-9ec57cb0c831?source=post_page-----125053cfe64f--------------------------------)
    ![Andreas Naoum](../Images/5af57533919b28694a1f6a0caf923221.png)
- en: '[Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page-----125053cfe64f--------------------------------)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[Andreas Naoum](https://andreasnaoum.medium.com/?source=post_page-----125053cfe64f--------------------------------)'
- en: Multimodal Data Visualizations
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态数据可视化
- en: '[View list](https://andreasnaoum.medium.com/list/multimodal-data-visualizations-48083691fa4b?source=post_page-----125053cfe64f--------------------------------)5
    stories![](../Images/afd598e10c2627e4d16424dd5903e02f.png)![](../Images/6ce441267a7e6f182643f87d802ee4ac.png)![](../Images/431a1a3f42709b335dddbdfeecffb9ef.png)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://andreasnaoum.medium.com/list/multimodal-data-visualizations-48083691fa4b?source=post_page-----125053cfe64f--------------------------------)5个故事![](../Images/afd598e10c2627e4d16424dd5903e02f.png)![](../Images/6ce441267a7e6f182643f87d802ee4ac.png)![](../Images/431a1a3f42709b335dddbdfeecffb9ef.png)'
- en: '*I regularly share tutorials on visualisation for computer vision and robotics.
    Follow me for future updates!*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*我定期分享计算机视觉和机器人学的可视化教程。请关注我以获取未来更新！*'
- en: '*Also, you can find me on* [***LinkedIn***](http://www.linkedin.com/in/andreas-naoum)***.***'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*此外，你还可以在* [***LinkedIn***](http://www.linkedin.com/in/andreas-naoum)***上找到我。***'
- en: Sources
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: '[1] [Pose Landmark Detection Guide](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)
    by [Google](https://about.google/brand-resource-center/), Portions of this page
    are reproduced from work created and [shared by Google](https://developers.google.com/readme/policies)
    and used according to terms described in the [Creative Commons 4.0 Attribution
    License](https://creativecommons.org/licenses/by/4.0/).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [姿势地标检测指南](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)由[Google](https://about.google/brand-resource-center/)提供，部分内容转载自由[Google](https://developers.google.com/readme/policies)创建并共享的作品，使用符合[创意共享
    4.0 姓名标注许可协议](https://creativecommons.org/licenses/by/4.0/)的条款。'
- en: '[2] [Rerun Docs](https://www.rerun.io/docs/reference/viewer/overview) by [Rerun](https://www.rerun.io)
    under [MIT license](https://github.com/rerun-io/rerun/blob/main/LICENSE-MIT)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [Rerun文档](https://www.rerun.io/docs/reference/viewer/overview)由[Rerun](https://www.rerun.io)提供，采用[MIT许可证](https://github.com/rerun-io/rerun/blob/main/LICENSE-MIT)'
