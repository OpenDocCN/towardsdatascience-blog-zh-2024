- en: '2024 in Review: What I Got Right, Where I Was Wrong, and Bolder Predictions
    for 2025'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2024年回顾：我对2024年的预测正确与错误，以及对2025年更大胆的预测
- en: 原文：[https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17](https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17](https://towardsdatascience.com/2024-in-review-what-i-got-right-where-i-was-wrong-and-bolder-predictions-for-2025-4092c2d726cd?source=collection_archive---------7-----------------------#2024-12-17)
- en: What I got right (and wrong) about trends in 2024 and daring to make bolder
    predictions for the year ahead
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我对2024年趋势的正确与错误的看法，以及对未来一年更大胆的预测
- en: '[](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page---byline--4092c2d726cd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    ·8 min read·Dec 17, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--4092c2d726cd--------------------------------)
    ·8分钟阅读·2024年12月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7b891fef4d659f8e35239ca469597357.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b891fef4d659f8e35239ca469597357.png)'
- en: AI Buzzword and Trend Bingo (Image by the author)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: AI流行语和趋势宾果游戏（图片由作者提供）
- en: In 2023, building AI-powered applications felt full of promise, but the challenges
    were already starting to show. By 2024, we began experimenting with techniques
    to tackle the hard realities of making them work in production.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年，构建AI驱动的应用充满了希望，但挑战已经开始显现。到了2024年，我们开始尝试一些技术，来应对将这些应用投入生产中的艰难现实。
- en: 'Last year, I [reviewed the biggest trends in AI in 2023 and made predictions
    for 2024](/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024-bb4357a4e827?sk=0a494f87bd0b0344594fa1e6694773a6).
    This year, instead of a timeline, I want to focus on key themes: What trends emerged?
    Where did I get it wrong? And what can we expect for 2025?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 去年，我[回顾了2023年AI领域的最大趋势并对2024年做出了预测](/2023-in-review-recapping-the-post-chatgpt-era-and-what-to-expect-for-2024-bb4357a4e827?sk=0a494f87bd0b0344594fa1e6694773a6)。今年，我不打算列出时间线，而是专注于关键主题：出现了哪些趋势？我哪里预测错了？我们可以期待2025年会发生什么？
- en: 2024 in Review
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2024年回顾
- en: If I have to summarize the AI space in 2024, it would be the “Captain, it’s
    Wednesday” meme. The amount of major releases this year was overwhelming. I don’t
    blame anyone in this space who’s feeling exhausted towards the end of this year.
    It’s been a crazy ride, and it's been hard to keep up. Let’s review key themes
    in the AI space and see if I correctly predicted them last year.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我必须总结2024年AI领域的情况，那就是“船长，今天是星期三”这个梗。今年的重大发布数量令人震惊。我不怪任何一个在这个领域感到疲惫的人，尤其是到了年底。这真是一次疯狂的旅程，而且很难跟得上。让我们回顾一下AI领域的关键主题，看看我去年是否正确预测了这些变化。
- en: Evaluations
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: Let’s start by looking at some generative AI solutions that made it to production.
    There aren’t many. As a [survey by A16Z](https://a16z.com/generative-ai-enterprise-2024/)
    revealed in 2024, companies are still hesitant to deploy generative AI in customer-facing
    applications. Instead, they feel more confident using it for internal tasks, like
    document search or chatbots.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一些已投入生产的生成型AI解决方案开始。数量并不多。正如A16Z的[调查报告](https://a16z.com/generative-ai-enterprise-2024/)所显示，2024年，许多公司仍然对在面向客户的应用中部署生成型AI感到犹豫。相反，它们更愿意将其用于内部任务，如文档搜索或聊天机器人。
- en: So, why aren’t there that many customer-facing generative AI applications in
    the wild? Probably because we are still figuring out how to evaluate them properly.
    This was one of my predictions for 2024.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么目前市面上并没有那么多面向客户的生成式AI应用呢？可能是因为我们仍在摸索如何正确评估它们。这是我对2024年的预测之一。
- en: Much of the research involved using another LLM to evaluate the output of an
    LLM ([LLM-as-a-judge](https://arxiv.org/abs/2411.15594)). While the approach may
    be clever, it’s also imperfect due to added cost, introduction of bias, and unreliability.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 很多研究涉及使用另一个LLM来评估LLM的输出（[LLM-as-a-judge](https://arxiv.org/abs/2411.15594)）。虽然这种方法可能很巧妙，但由于增加了成本、引入了偏见以及不可靠性，它也并不完美。
- en: Looking back, I anticipated we would see this issue solved this year. However,
    looking at the landscape today, despite being a major topic of discussion, we
    still haven’t found a reliable way to evaluate generative AI solutions effectively.
    Although I think LLM-as-a-judge is the only way we’re able to evaluate generative
    AI solutions at scale, this shows how early we are in this field.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾过去，我曾预计今年会解决这个问题。然而，今天来看，尽管这一话题是讨论的重点，但我们依然没有找到一种可靠的方式来有效评估生成式AI解决方案。虽然我认为LLM作为评判工具是我们唯一能够大规模评估生成式AI解决方案的方法，但这也表明我们在这个领域仍处于早期阶段。
- en: Multimodality
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态性
- en: Although this one might have been obvious to many of you, I didn’t have this
    on my radar for 2024\. With the releases of [GPT4](https://openai.com/index/gpt-4-research/),
    [Llama 3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/),
    and [ColPali](https://arxiv.org/abs/2407.01449), multimodal foundation models
    were a big trend in 2024\. While we, developers, were busy figuring out how to
    make LLMs work in our existing pipelines, researchers were already one step ahead.
    They were already building foundation models that could handle more than one modality.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这对许多人来说可能是显而易见的，但我并没有把它纳入我2024年的预测中。随着[GPT4](https://openai.com/index/gpt-4-research/)、[Llama
    3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)和[ColPali](https://arxiv.org/abs/2407.01449)的发布，多模态基础模型成为2024年的一个重要趋势。尽管我们开发者忙于弄清楚如何在现有管道中使LLM发挥作用，研究人员却已经走在了前面，他们已经在构建能够处理多种模态的基础模型。
- en: “There is ***absolutely no way in hell*** we will ever reach human-level AI
    without getting machines to learn from high-bandwidth sensory inputs, such as
    vision.” — [Yann LeCun](https://www.linkedin.com/posts/yann-lecun_parm-prmshra-on-x-activity-7172266619103080448-iqvP/?utm_source=share&utm_medium=member_desktop)
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “***绝对不可能***在没有让机器从高带宽感官输入（如视觉）中学习的情况下，我们能达到人类水平的AI。” — [Yann LeCun](https://www.linkedin.com/posts/yann-lecun_parm-prmshra-on-x-activity-7172266619103080448-iqvP/?utm_source=share&utm_medium=member_desktop)
- en: Take PDF parsing as an example of multimodal models’ usefulness beyond text-to-image
    tasks. [ColPali](https://arxiv.org/abs/2407.01449)’s researchers avoided the difficult
    steps of OCR and layout extraction by using visual language models (VLMs). Systems
    like ColPali and [ColQwen2](https://huggingface.co/vidore/colqwen2-v0.1) process
    PDFs as images, extracting information directly without pre-processing or chunking.
    This is a reminder that simpler solutions often come from changing how you frame
    the problem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以PDF解析作为多模态模型在文本到图像任务之外的有用示例。[ColPali](https://arxiv.org/abs/2407.01449)的研究人员通过使用视觉语言模型（VLMs）避免了OCR和布局提取的复杂步骤。像ColPali和[ColQwen2](https://huggingface.co/vidore/colqwen2-v0.1)这样的系统将PDF作为图像处理，直接提取信息，无需预处理或分块。这提醒我们，简单的解决方案往往来源于改变问题的框架方式。
- en: Multimodal models are a bigger shift than they might seem. Document search across
    PDFs is just the beginning. Multimodality in foundation models will unlock entirely
    new possibilities for applications across industries. With more modalities, AI
    is no longer just about language — it’s about understanding the world.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态模型的变革比看起来更为深远。PDF文档的搜索仅仅是开始。基础模型中的多模态性将为各行各业的应用解锁全新的可能性。随着模态的增多，AI不再仅仅局限于语言——它关乎于理解世界。
- en: Fine-tuning open-weight models and quantization
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调开放权重模型与量化
- en: Open-weight models are closing the performance gap to closed models. Fine-tuning
    them gives you a performance boost while still being lightweight. Quantization
    makes these models smaller and more efficient (see also [Green AI](https://medium.com/towards-data-science/towards-green-ai-how-to-make-deep-learning-models-more-efficient-in-production-3b1e7430a14))
    to run anywhere, even on small devices. Quantization pairs well with fine-tuning,
    especially since fine-tuning language models is inherently challenging (see [QLoRA](https://arxiv.org/abs/2305.14314)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型正在缩小与封闭模型之间的性能差距。对它们进行微调可以提升性能，同时保持轻量化。量化技术使这些模型更小、更高效（另见[绿色AI](https://medium.com/towards-data-science/towards-green-ai-how-to-make-deep-learning-models-more-efficient-in-production-3b1e7430a14)），能够在任何地方运行，甚至在小型设备上。量化与微调配合得很好，尤其是考虑到微调语言模型本身就具有挑战性（另见[QLoRA](https://arxiv.org/abs/2305.14314)）。
- en: Together, these trends make it clear that the future isn’t just bigger models
    — it’s smarter ones.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 综合来看，这些趋势表明，未来不仅仅是更大的模型——而是更智能的模型。
- en: Great visual summary by [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page---user_mention--4092c2d726cd--------------------------------).
    Also, check out his blog if you are interested in fine-tuning LLMs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page---user_mention--4092c2d726cd--------------------------------)做出的精彩视觉总结。如果你对微调LLM感兴趣，也可以查看他的博客。
- en: I don’t think I explicitly mentioned this one and only [wrote a small piece
    on this in the second quarter of 2024](https://medium.com/towards-data-science/shifting-tides-the-competitive-edge-of-open-source-llms-over-closed-source-llms-aee76018b5c7).
    So, I will not give myself a point here.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得我并没有明确提到过这一点，而只是[在2024年第二季度写了一篇关于此的文章](https://medium.com/towards-data-science/shifting-tides-the-competitive-edge-of-open-source-llms-over-closed-source-llms-aee76018b5c7)。所以，我在这里不会给自己加分。
- en: AI agents
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI代理
- en: This year, AI agents and agentic workflows gained much attention, as Andrew
    Ng predicted at the beginning of the year. We saw [Langchain](https://www.langchain.com/langgraph)
    and [LlamaIndex](https://docs.llamaindex.ai/en/stable/use_cases/agents/) move
    into incorporating agents, [CrewAI](https://www.crewai.com/) gained a lot of momentum,
    and OpenAI came out with [Swarm](https://github.com/openai/swarm). This is another
    topic I hadn’t seen coming since I didn’t look into it.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 今年，AI代理和代理工作流受到了广泛关注，正如Andrew Ng年初所预测的那样。我们看到[Langchain](https://www.langchain.com/langgraph)和[LlamaIndex](https://docs.llamaindex.ai/en/stable/use_cases/agents/)开始整合代理，[CrewAI](https://www.crewai.com/)获得了很大动力，OpenAI推出了[Swarm](https://github.com/openai/swarm)。这是另一个我没有预料到的主题，因为我之前没有深入研究过。
- en: “I think AI agentic workflows will drive massive AI progress this year — perhaps
    even more than the next generation of foundation models.” — [Andrew Ng](https://x.com/AndrewYNg/status/1770897666702233815?lang=en)
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我认为AI代理工作流将在今年推动大规模的AI进展——可能甚至超过下一代基础模型。” — [Andrew Ng](https://x.com/AndrewYNg/status/1770897666702233815?lang=en)
- en: '![](../Images/02dce8059388e447c1d4872fbfcd443b.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02dce8059388e447c1d4872fbfcd443b.png)'
- en: '[Screenshot from Google Trends for the term “AI agents” in 2024.](https://trends.google.com/trends/explore?date=2024-01-01+2024-12-16&q=AI+agents&hl=en-US)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[2024年“AI代理”这一术语在Google Trends上的截图。](https://trends.google.com/trends/explore?date=2024-01-01+2024-12-16&q=AI+agents&hl=en-US)'
- en: Despite the massive interest in AI agents, they can be controversial. First,
    there is still no clear definition of “AI agent” and its capabilities. Are AI
    agents just LLMs with access to tools, or do they have other specific capabilities?
    Second, they come with added latency and cost. I have read many comments saying
    that agent systems aren’t suitable for production systems due to this.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AI代理引起了极大的关注，但它们也可能具有争议。首先，关于“AI代理”及其能力仍然没有明确的定义。AI代理只是具备工具访问能力的LLM，还是具备其他特定能力？其次，它们带来了额外的延迟和成本。我读到很多评论说，代理系统由于这些问题不适合用于生产系统。
- en: But I think we have already been seeing some agentic pipelines in production
    with lightweight workflows, such as routing user queries to specific function
    calls. I think we will continue to see agents in 2025\. Hopefully, we will get
    a clearer definition and picture.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但我认为我们已经开始在生产环境中看到一些具有轻量化工作流的代理管道，比如将用户查询路由到特定的功能调用。我认为我们将在2025年继续看到AI代理。希望我们能得到更清晰的定义和图景。
- en: RAG isn’t de*d and retrieval goes mainstream
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG并未*死亡*，信息检索正在成为主流
- en: '[Retrieval-Augmented Generation (RAG)](https://medium.com/@iamleonie/building-retrieval-augmented-generation-systems-be587f42aedb)
    gained significant attention in 2023 and remained a key topic in 2024, with many
    new variants emerging. However, it remains a topic of debate. Some argue it’s
    becoming obsolete with long-context models, while others question whether it’s
    even a new idea. While I think the criticism of the terminology is justified,
    I think the concept is here to stay (for a little while at least).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[检索增强生成（RAG）](https://medium.com/@iamleonie/building-retrieval-augmented-generation-systems-be587f42aedb)在2023年获得了显著关注，并在2024年依然是一个关键话题，许多新的变体应运而生。然而，这仍然是一个备受争议的话题。一些人认为，随着长上下文模型的出现，RAG正在变得过时，而另一些人则质疑这是否真的是一个新思想。虽然我认为关于术语的批评是有道理的，但我认为这个概念会持续存在（至少还会有一段时间）。'
- en: All the different RAG variants
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 所有不同的RAG变体
- en: Every time a new long context model is released, some people predict it will
    be the end of RAG pipelines. I don’t think that’s going to happen. This whole
    discussion should be a blog post of its own, so I’m not going into depth here
    and saving the discussion for another one. Let me just say that I don’t think
    it’s one or the other. They are complements. Instead, we will probably be using
    long context models together with RAG pipelines.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 每次发布一个新的长上下文模型时，有些人就预测这将是RAG管道的终结。我不认为这会发生。这个讨论本应成为一篇单独的博客文章，所以我在这里不会深入探讨，讨论会留到下一篇。让我只是说，我认为它们并不是互相排斥的，它们是互补的。相反，我们可能会将长上下文模型与RAG管道一起使用。
- en: Also, having a database in applications is not a new concept. The term ‘RAG,’
    which refers to retrieving information from a knowledge source to enhance an LLM’s
    output, has faced criticism. Some argue it’s merely a rebranding of techniques
    long used in other fields, such as software engineering. While I think we will
    probably part from the term in the long run, the technique is here to stay.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在应用程序中拥有数据库并不是一个新概念。‘RAG’这一术语，指的是从知识源中检索信息以增强LLM的输出，面临着批评。有些人认为这不过是对其他领域（如软件工程）中长期使用的技术的重新命名。虽然我认为我们可能会在长远来看抛弃这个术语，但这一技术将继续存在。
- en: Despite predictions of RAG’s demise, retrieval remains a cornerstone of AI pipelines.
    While I may be biased by my work in retrieval, it felt like this topic became
    more mainstream in AI this year. It started with many discussions around keyword
    search (BM25) as a baseline for RAG pipelines. It then evolved into a larger discussion
    around dense retrieval models, such as [ColBERT](https://arxiv.org/abs/2004.12832)
    or ColPali.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有预测认为RAG（检索增强生成）的时代将结束，但检索依然是AI流程的基石。虽然我可能会因为自己在检索领域的工作而有所偏见，但我感觉这个话题在今年变得更加主流。最初，许多讨论集中在将关键词搜索（BM25）作为RAG流程的基准。随后，这一讨论扩展到了更广泛的密集检索模型，如[ColBERT](https://arxiv.org/abs/2004.12832)或ColPali。
- en: Knowledge graphs
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识图谱
- en: I completely missed this topic because I’m not too familiar with it. Knowledge
    graphs in RAG systems (e.g., Graph RAG) were another big topic. Since all I can
    say about knowledge graphs at this moment is that they seem to be a powerful external
    knowledge source, I will keep this section short.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我完全错过了这个话题，因为我对此不太熟悉。RAG系统中的知识图谱（例如，图RAG）是另一个大话题。由于我目前能说的关于知识图谱的内容只是它们似乎是强大的外部知识源，因此我会简短地处理这一部分。
- en: The key topics of 2024 suggest that we are now realizing the limitations of
    building applications with foundation models. The hype around ChatGPT may have
    settled, but the drive to integrate foundation models into applications is still
    very much alive. It’s just way more difficult than we had anticipated.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年的关键话题表明，我们现在已经意识到仅仅构建基础模型应用程序的局限性。围绕ChatGPT的热潮可能已经平息，但将基础模型集成到应用中的推动力依然强劲。只不过这比我们预期的要困难得多。
- en: “ The race to make AI more efficient and more useful, before investors lose
    their enthusiasm, is on.” — [The Economist](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在投资者失去热情之前，争夺让AI更加高效和有用的竞赛已经开始。” — [经济学人](https://www.economist.com/the-world-ahead/2024/11/18/will-the-bubble-burst-for-ai-in-2025-or-will-it-start-to-deliver)
- en: 2024 taught us that scaling foundation models isn’t enough. We need better evaluation,
    smarter retrieval, and more efficient workflows to make AI useful. The limitations
    we ran into this year aren’t signs of stagnation — they’re clues about what we
    need to fix next in 2025.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年告诉我们，仅仅扩大基础模型的规模是不够的。我们需要更好的评估、更智能的检索和更高效的工作流，以使AI变得有用。今年我们遇到的局限性并不是停滞的标志——它们是关于我们需要在2025年解决的问题的线索。
- en: My 2025 Predictions
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的2025年预测
- en: 'OK, now, for the interesting part, what are my 2025 predictions? This year,
    I want to make some bolder predictions for the next year to make it a little more
    fun:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在进入有趣的部分，我的 2025 年预测是什么？今年，我想为来年做出一些更大胆的预测，让它更有趣：
- en: '**Video will be an important modality:** After text-only LLMs evolved into
    multimodal foundation models (mostly text and images), it’s only natural that
    video will be the next modality. I can imagine seeing more video-capable foundation
    models follow in [Sora](https://openai.com/sora/)’s footsteps.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频将成为一种重要的模态：** 在纯文本 LLM 发展为多模态基础模型（主要是文本和图像）之后，视频自然会成为下一个模态。我可以想象更多支持视频的基础模型将会追随[Sora](https://openai.com/sora/)的步伐。'
- en: '**From one-shot to agentic to human-in-the-loop:** I imagine we will start
    incorporating humans into AI-powered systems. While we started with one-shot systems,
    we are not at the stage of having AI agents coordinate different tasks to improve
    results. But AI agents won’t replace humans. They’ll empower them. Systems that
    incorporate human feedback will deliver better outcomes across industries. In
    the long-term, I imagine that we will have to have systems that wait for human
    feedback before taking action on the next task.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从单次到代理式，再到人机协作：** 我想象我们将开始将人类融入 AI 驱动的系统中。虽然我们从单次系统开始，但我们尚未达到由 AI 代理协调不同任务以提高结果的阶段。但
    AI 代理不会取代人类，它们将赋能于人类。结合人类反馈的系统将在各个行业提供更好的成果。从长远来看，我想象我们将必须拥有在执行下一任务之前等待人类反馈的系统。'
- en: '**Fusion of AI and crypto:** Admittedly, I don’t know much about the entire
    crypto scene, but I saw [this Tweet by Brian Armstrong about how AI agents should
    be equipped with crypto wallets](https://x.com/brian_armstrong/status/1824547713012080806).
    Also, concepts like [DePin (Decentralized Physical Infrastructure)](https://tokenomicsexplained.com/depin/)
    could be interesting to explore for model training and inference. While this sounds
    like buzzword bingo, I’m curious to see if early experiments will show if this
    is hype or reality.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI 与加密货币的融合：** 坦率地说，我对整个加密货币领域了解不多，但我看到了[Brian Armstrong 的这条推文，讨论 AI 代理应配备加密钱包](https://x.com/brian_armstrong/status/1824547713012080806)。此外，像[DePin（去中心化物理基础设施）](https://tokenomicsexplained.com/depin/)这样的概念，在模型训练和推理方面可能值得探索。虽然这听起来像是流行语游戏，但我很想看看早期实验是否能证明这是真实的还是炒作。'
- en: '**Latency and cost per token will drop:** Currently, one big issue for AI agents
    is added latency and cost. However, with Moore’s law and research for making AI
    models more efficient, like quantization and efficient training techniques (not
    only for cost reasons but also for environmental reasons), I can imagine both
    the latency and cost per token going down.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每个 token 的延迟和成本将下降：** 目前，AI 代理面临的一个大问题是延迟和成本的增加。然而，随着摩尔定律的推进和使 AI 模型更高效的研究，如量化和高效的训练技术（不仅是出于成本原因，也出于环保原因），我可以预见每个
    token 的延迟和成本将逐渐降低。'
- en: '**I am curious to hear your predictions for the AI space in 2025!**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**我很想听听你对 2025 年 AI 领域的预测！**'
- en: 'PS: Funnily, I was researching recipes for Christmas cookies with ChatGPT a
    few days ago instead of using Google, which I was wondering about two years ago
    when ChatGPT was released.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: PS：有趣的是，几天前，我和 ChatGPT 一起研究圣诞饼干食谱，而不是使用 Google，这让我想起两年前 ChatGPT 发布时我曾想过的事情。
- en: '[](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
    [## Will We Be Using ChatGPT Instead of Google To Get a Christmas Cookie Recipe
    Next Year?'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
    [## 我们明年会用 ChatGPT 代替 Google 查找圣诞饼干食谱吗？'
- en: Will ChatGPT replace search engines? A walkthrough with the use case of looking
    up a sugar cookie recipe
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatGPT 会取代搜索引擎吗？通过查找糖饼干食谱的使用案例来演示
- en: medium.com](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/geekculture/will-we-be-using-chatgpt-instead-of-google-to-get-a-christmas-cookie-recipe-next-year-45360d4a1178?source=post_page-----4092c2d726cd--------------------------------)
- en: Enjoyed This Story?
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 喜欢这个故事吗？
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://medium.com/subscribe/@iamleonie) *以便在我发布新故事时收到通知。*'
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)
    [## 每当Leonie Monigatti发布时，获取电子邮件通知。'
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每当Leonie Monigatti发布新内容时，您将收到电子邮件通知。通过注册，您将创建一个Medium账户（如果您还没有的话）…
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----4092c2d726cd--------------------------------)'
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*
    和* [*Kaggle*](https://www.kaggle.com/iamleonie)*上找到我！*'
