- en: 'Product-Oriented ML: A Guide for Data Scientists'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面向产品的机器学习：数据科学家的指南
- en: 原文：[https://towardsdatascience.com/planning-machine-learning-products-b43b9c4e10a1?source=collection_archive---------5-----------------------#2024-10-14](https://towardsdatascience.com/planning-machine-learning-products-b43b9c4e10a1?source=collection_archive---------5-----------------------#2024-10-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/planning-machine-learning-products-b43b9c4e10a1?source=collection_archive---------5-----------------------#2024-10-14](https://towardsdatascience.com/planning-machine-learning-products-b43b9c4e10a1?source=collection_archive---------5-----------------------#2024-10-14)
- en: How to build ML products users love.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何构建用户喜爱的机器学习产品。
- en: '[](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)[![Jake
    Minns](../Images/884ac297c07f1df432da41e0de427cff.png)](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)
    [Jake Minns](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)[![Jake
    Minns](../Images/884ac297c07f1df432da41e0de427cff.png)](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)
    [Jake Minns](https://medium.com/@minns.jake?source=post_page---byline--b43b9c4e10a1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)
    ·23 min read·Oct 14, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--b43b9c4e10a1--------------------------------)
    ·阅读时间：23分钟·2024年10月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/abde463343ddae14f9ce8fe414b8d702.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abde463343ddae14f9ce8fe414b8d702.png)'
- en: 'Photo by Pavel Danilyuk: https://www.pexels.com/photo/a-robot-holding-a-flower-8438979/'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Pavel Danilyuk： [https://www.pexels.com/photo/a-robot-holding-a-flower-8438979/](https://www.pexels.com/photo/a-robot-holding-a-flower-8438979/)
- en: Data science offers rich opportunities to explore new concepts and demonstrate
    their viability, all towards building the ‘intelligence’ behind features and products.
    However, most machine learning (ML) projects fail! And this isn’t just because
    of the inherently experimental nature of the work. Projects may lack purpose or
    grounding in real-world problems, while integration of ML into products requires
    a commitment to long-term problem-solving, investment in data infrastructure,
    and the involvement of multiple technical experts. This post is about mitigating
    these risks at the planning stage, fail here, fast, while developing into a product-oriented
    data scientist.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学为探索新概念并验证其可行性提供了丰富的机会，所有这些都是为了构建功能和产品背后的“智能”。然而，大多数机器学习（ML）项目都失败了！这不仅仅是因为工作的本质具有实验性。项目可能缺乏目的性，或者没有与实际问题相结合，而将机器学习整合到产品中需要致力于长期的解决问题、投资数据基础设施以及多方技术专家的参与。本文旨在帮助在规划阶段减少这些风险，快速失败，同时培养成为以产品为导向的数据科学家。
- en: This article provides a structured approach to planning ML products, by walking
    through the key areas of a product design document. We’ll cover clarifying requirements,
    understanding data constraints and defining what success looks like, all of which
    dictates your approach to building successful ML products. These documents should
    be flexible, use them to figure out what works for your team.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提供了一种规划机器学习（ML）产品的结构化方法，通过介绍产品设计文档的关键领域来进行讲解。我们将涵盖明确需求、理解数据限制以及定义成功标准等内容，这些内容决定了你构建成功机器学习产品的方式。这些文档应该具有灵活性，可以用来找出最适合你团队的方案。
- en: I’ve been fortunate to work in startups, part of small scrappy teams where roles
    and ownership become blended. I mention this because the topics covered below
    crossover traditional boundaries, into project management, product, UI/UX, marketing
    and more. I’ve found that people who can cross these boundaries and approach collaboration
    with empathy make great products and better colleagues.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我很幸运曾在初创公司工作，成为小型而灵活团队的一员，在这里，角色和责任通常是交叉的。我提到这一点是因为下面讨论的话题跨越了传统的边界，涉及项目管理、产品、UI/UX、市场营销等多个领域。我发现，那些能够跨越这些边界并以同理心进行协作的人，能够创造出优秀的产品，成为更好的同事。
- en: 'To illustrate the process, we will work through a feature request, set out
    by a hypothetical courier company:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个过程，我们将通过一个假设的快递公司提出的功能请求来进行讲解：
- en: '**“As a courier company, we’d like to improve our ability to provide users
    with advanced warning if their package delivery is expected to be delayed.”**'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“作为一家快递公司，我们希望提高在包裹预计延迟时，提前向用户发出警告的能力。”**'
- en: '**Problem Definition**'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**问题定义**'
- en: This section is about writing a concise description of the problem and the project’s
    motivation. As development spans months or years, not only does this start everyone
    on the same page, but unique to ML, it serves to anchor you as challenges arise
    and experiments fail. Start with a project kickoff. Encourage open collaboration
    and aim to surface the assumptions present in all cross-functional teams, ensuring
    alignment on product strategy and vision from day one.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在简洁地描述问题及项目动机。由于开发通常跨越数月或数年，这不仅能确保每个人从同一页面开始，尤其是在机器学习领域，它有助于你在面对挑战和实验失败时始终保持坚定。以项目启动为起点。鼓励开放合作，并努力揭示所有跨职能团队中的假设，确保从第一天起在产品战略和愿景上达成一致。
- en: Actually writing the statement starts with reiterating the problem in your own
    words. For me, making this long form and then whittling it down makes it easier
    to narrow down on the specifics. In our example, we are starting with a feature
    request. It provides some direction but leaves room for ambiguity around specific
    requirements. For instance, “improve our ability” suggests an existing system
    — do we have access to an existing dataset? “Advanced warning” is vague on information
    but tells us customers will be actively prompted in the event of a delayed delivery.
    These all have implications for how we build the system, and provides an opportunity
    to assess the feasibility of the project.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际撰写陈述时，首先要用你自己的话重述问题。对我而言，将其写成长篇并逐渐缩减，使得聚焦于具体细节变得更容易。在我们的示例中，我们从一个功能需求开始。它提供了一些方向，但在具体要求上留有模糊空间。例如，“提高我们的能力”暗示着现有系统——我们是否能访问现有的数据集？“提前警告”虽然信息模糊，但表明如果包裹延迟，客户会收到主动提示。这些都对我们如何构建系统产生影响，并为评估项目的可行性提供了机会。
- en: We also need to understand the motivation behind the project. While we can assume
    the new feature will provide a better user experience, what’s the business opportunity?
    When defining the problem, always tie it back to the larger business strategy.
    For example, improving delivery delay notifications isn’t just about building
    a better product — it’s about reducing customer churn and increasing satisfaction,
    which can boost brand loyalty and lower support costs. This is your real measure
    of success for the project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要理解项目背后的动机。虽然我们可以假设新功能将提供更好的用户体验，但商业机会在哪里？在定义问题时，始终要将其与更大的商业战略联系起来。例如，改进延迟通知不仅仅是为了构建一个更好的产品——它关系到减少客户流失和提高满意度，从而增强品牌忠诚度并降低支持成本。这才是你衡量项目成功的真正标准。
- en: Working within a team to unpack a problem is a skill all engineers should develop
    — not only is it commonly tested as part of an interview processes, but, as discussed,
    it sets expectations for a project and strategy that everyone, top-down can buy
    into. A lack of alignment from the start can be disastrous for a project, even
    years later. Unfortunately, this was the fate of a health chatbot developed by
    Babylon. Babylon set out with the ambitious goal of revolutionising healthcare
    by using AI to deliver accurate diagnostics. To its detriment, the company oversimplified
    the complexity of healthcare, especially across different regions and patient
    populations. For example, symptoms like fever might indicate a minor cold in the
    UK, but could signal something far more serious in Southeast Asia. This lack of
    clarity and overpromising on AI capabilities led to a major mismatch between what
    the system could actually do and what was needed in real-world healthcare environments
    ([https://sifted.eu/articles/the-rise-and-fall-of-babylon](https://sifted.eu/articles/the-rise-and-fall-of-babylon)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在团队中共同解决问题是所有工程师应该培养的技能——这不仅是面试过程中常常考察的内容，而且，正如之前所讨论的，它帮助设定项目和战略的期望，确保每个人自上而下都能认同。如果一开始就没有达成一致，可能会对项目造成灾难性的影响，甚至几年后仍然如此。不幸的是，这正是Babylon健康聊天机器人的命运。Babylon的目标是通过使用人工智能提供准确的诊断，来彻底改革医疗保健。然而，令公司吃亏的是，它过于简化了医疗保健的复杂性，尤其是在不同地区和患者群体之间。例如，在英国，发烧症状可能意味着普通感冒，但在东南亚可能意味着更为严重的疾病。缺乏清晰性并对人工智能能力的过度承诺导致了系统实际能做的与现实世界医疗环境中所需的严重不匹配（[https://sifted.eu/articles/the-rise-and-fall-of-babylon](https://sifted.eu/articles/the-rise-and-fall-of-babylon)）。
- en: '**Requirements and Constraints**'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**需求和约束**'
- en: 'With your problem defined and why it matters, we can now document the requirements
    for delivering the project and set the scope. These typically fall into two categories:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了问题及其重要性后，我们可以开始记录交付项目的需求并设定范围。这些需求通常分为两类：
- en: '**Functional requirements**, which define what the system should do from the
    user’s perspective. These are directly tied to the features and interactions the
    user expects.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**功能性需求**，即从用户的角度定义系统应做什么。这些需求直接关联到用户期望的功能和交互。'
- en: '**Non-functional requirements**, which address how the system operates — performance,
    security, scalability, and usability.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**非功能性需求**，即系统如何运行——性能、安全性、可扩展性和可用性。'
- en: If you’ve worked with agile frameworks, you’ll be familiar with user stories
    — short, simple descriptions of a feature told from the user’s perspective. I’ve
    found defining these as a team is a great way to align, this starts with documenting
    functional requirements from a user perspective. Then, map them across the user
    journey, and identify key moments your ML model will add value. This approach
    helps establish clear boundaries early on, reducing the likelihood of “scope creep”.
    If your project doesn’t have traditional end-users, perhaps you’re replacing an
    existing process? Talk to people with boots on the ground — be that operational
    staff or process engineers, they are your domain experts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经使用过敏捷框架，你会熟悉用户故事——从用户的角度讲述功能的简短、简单的描述。我发现，作为团队共同定义这些需求是对齐的好方法，首先从记录功能性需求开始，确保从用户的角度出发。然后，将这些需求映射到用户旅程中，识别出机器学习模型能够提供价值的关键时刻。这种方法有助于在早期确立明确的边界，减少“范围蔓延”的可能性。如果你的项目没有传统的最终用户，或许你是在替代现有的流程？和一线人员交谈——无论是操作员工还是流程工程师，他们是你的领域专家。
- en: 'From a simple set of stories we can build actionable model requirements:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从一组简单的故事中，我们可以构建可操作的模型需求：
- en: '**What information is being sent to users?**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户将接收到什么信息？**'
- en: As a **customer awaiting delivery**, I want to receive clear and timely notifications
    about whether my package is delayed or on time, so that I can plan my day accordingly.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为一名**等待交付的客户**，我希望及时而清晰地收到关于我的包裹是否延迟或准时的通知，这样我可以相应地规划我的一天。
- en: '**How will users be sent the warnings?**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户将如何收到警告？**'
- en: As a **customer awaiting delivery**, I want to receive notifications via my
    preferred communication channel (SMS or native app) about the delay of my package,
    so that I can take action without constantly checking the app.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为一名**等待交付的客户**，我希望通过我偏好的通信渠道（短信或本地应用）接收关于我的包裹是否延迟的通知，这样我可以采取行动，而无需一直检查应用程序。
- en: '**What user-specific data can the system use?**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统可以使用哪些用户特定的数据？**'
- en: As a **customer concerned about privacy**, I only want essential information
    like my address to be used to predict whether my package is delayed.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为一名**关注隐私的客户**，我只希望使用诸如我的地址等必要的信息来预测我的包裹是否延迟。
- en: 'Done right, these requirements should constrain your decisions regarding data,
    models and training evaluation. If you find conflicts, balance them based on user
    impact and feasibility. Let’s unpack the user stories above to find how our ML
    strategy will be constrained:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果做得对，这些需求应该能够约束你关于数据、模型和训练评估的决策。如果你发现存在冲突，可以根据用户影响和可行性进行权衡。让我们分析上面的用户故事，看看我们的机器学习策略会受到哪些约束：
- en: '**What information is being sent to users?**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户将接收到什么信息？**'
- en: The model can remain simple (binary classification) if only a delay notification
    is needed; more detailed outputs require more complex model and additional data.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果仅需要延迟通知，模型可以保持简单（例如二分类）；更详细的输出需要更复杂的模型和额外的数据。
- en: '**How will users be sent the warnings?**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户将如何收到警告？**'
- en: Real-time warnings necessitate low-latency systems, this creates constraints
    around model and preprocessing complexity.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时警告需要低延迟的系统，这就对模型和预处理的复杂度提出了限制。
- en: '**What user-specific data can the system use?**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统可以使用哪些用户特定的数据？**'
- en: If we can only use limited user-specific information, our model accuracy might
    suffer. Alternatively, using more detailed user-specific data requires consent
    from users and increased complexity around how data is stored in order to adhere
    to data privacy best practices and regulations.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们只能使用有限的用户特定信息，模型的准确性可能会受到影响。另一方面，使用更详细的用户特定数据需要获得用户同意，并增加了数据存储的复杂性，以便遵守数据隐私最佳实践和法规。
- en: Thinking about users prompts us to embed ethics and privacy into our design
    while building products people trust. Does our training data result in outputs
    that contain bias, discriminating against certain user groups? For instance, low-income
    areas may have worse infrastructure affecting delivery times — is this represented
    fairly in the data? We need to ensure the model does not perpetuate or amplify
    existing biases. Unfortunately, there are a litany of such cases, take the ML
    based recidivism tool COMPAS, used across the US that was shown to overestimated
    the recidivism risk for Black defendants while underestimating it for white defendants
    ([https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑用户促使我们在设计时将伦理和隐私嵌入其中，从而打造人们信任的产品。我们的训练数据是否导致包含偏见的输出，歧视某些用户群体？例如，低收入地区可能因基础设施较差而影响交付时间——这一点在数据中是否得到了公平反映？我们需要确保模型不会延续或放大现有的偏见。不幸的是，这类案例层出不穷，例如美国广泛使用的基于机器学习的再犯风险评估工具COMPAS，它被证明高估了黑人被告的再犯风险，而低估了白人被告的风险（[https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)）。
- en: 'In addition to ethics, we also need to consider other non-functional requirements
    such as performance and explainability:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除了伦理，我们还需要考虑其他非功能性需求，比如性能和可解释性：
- en: '**Transparency and Explainability**: How much of a “black-box” do we present
    the model as? What are the implications of a wrong prediction or bug? These aren’t
    easy questions to answer. Showing more information about how a model arrives at
    its decisions requires robust models and the use of explainable models like decision
    trees. Techniques like SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable
    Model-agnostic Explanations) can help explain how different features contribute
    to a prediction, at the risk of overwhelming users. For our example would telling
    users why a package is delayed build trust? Generally model explainability increases
    buy in from internal stakeholders.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透明性与可解释性**：我们将模型呈现为多少“黑箱”？错误预测或程序缺陷的后果是什么？这些问题并不容易回答。展示更多关于模型如何做出决策的信息需要强大的模型以及使用可解释的模型，如决策树。像SHAP（Shapley加性解释）和LIME（局部可解释模型无关解释）这样的技术可以帮助解释不同特征如何影响预测，尽管这有可能让用户感到信息过载。在我们的示例中，告诉用户为什么一个包裹会被延迟是否能建立信任？通常，模型的可解释性能增加内部利益相关者的认同。'
- en: '**Real-time or Batch Processing:** Real-time predictions require low-latency
    infrastructure and streaming data pipelines. Batch predictions can be processed
    at regular intervals, which might be sufficient for less time-sensitive needs.
    Choosing between real-time or batch predictions affects the complexity of the
    solution and influences which models are feasible to deploy. For instance, simpler
    models or optimisation techniques reduce latency. More on this later.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时或批量处理**：实时预测需要低延迟的基础设施和流式数据管道。批量预测则可以在定期的时间间隔内处理，通常对于不那么紧急的需求已经足够。选择实时预测或批量预测会影响解决方案的复杂性，并且会影响哪些模型适合部署。例如，简单的模型或优化技术可以减少延迟。稍后会详细讨论这个问题。'
- en: A tip borrowed from marketing is the creation of user personas. This typically
    builds on market research collected through formal interviews and surveys to understand
    the needs, behaviours, and motivations of users. It’s then segmented based on
    common characteristics like demographics, goals and challenges. From this we can
    develop detailed profiles for each segment, giving them names and backstories.
    Durning planning, personas helps us empathise with how model predictions will
    be received and the actions they elicit in various contexts.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从营销中借来的一个技巧是创建用户画像。通常，这基于通过正式访谈和调查收集的市场研究，以了解用户的需求、行为和动机。然后根据共同的特征（如人口统计学、目标和挑战）进行细分。由此，我们可以为每个细分群体开发详细的档案，给他们起名字并赋予背景故事。在规划过程中，用户画像帮助我们理解模型预测将如何被接收，并在不同情境下引发的行动。
- en: Take Sarah, a “Busy Parent” persona. She prioritises speed and simplicity. Hence,
    she values timely, concise notifications about package delays. This means our
    model should focus on quick, binary predictions (delayed or on-time) rather than
    detailed outputs. Finally, since Sarah prefers real-time notifications via her
    mobile, the model needs to integrate seamlessly with low-latency systems to deliver
    instant updates.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以莎拉为例，她是一个“忙碌的家长”角色。她优先考虑速度和简洁性。因此，她重视关于包裹延迟的及时简洁的通知。这意味着我们的模型应侧重于快速的二元预测（延迟或准时），而不是详细的输出。最后，由于莎拉更喜欢通过她的手机接收实时通知，模型需要无缝集成到低延迟的系统中，以便提供即时更新。
- en: By documenting functional and non-functional requirements, we define “What”
    we are building to meet the needs of users combine with “Why” this aligns with
    business objectives.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过记录功能性和非功能性需求，我们定义了“我们在构建什么”以满足用户需求，并结合“为什么”这与业务目标相符。
- en: '**Modelling Approach**'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**建模方法**'
- en: It’s now time to think about “How” we meet our requirements. This starts with
    framing the problem in ML terms by documenting the type of inputs (features),
    outputs (predictions) and a strategy for learning the relationship between them.
    At least something to get us started, we know it’s going to be experimental.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候思考我们如何满足需求了。这从用机器学习（ML）术语来描述问题开始，记录输入类型（特征）、输出类型（预测）以及学习它们之间关系的策略。至少需要一些起点，我们知道这将是一个实验性的过程。
- en: 'For our example, the input features could include traffic data, weather reports
    or package details while a binary prediction is required: “delayed” or “on-time”.
    It’s clear that our problem requires a binary classification model. For us this
    was simple, but for other product contexts a range of approaches exist:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的例子，输入特征可能包括交通数据、天气报告或包裹详情，同时需要一个二元预测：“延迟”或“准时”。显然，我们的问题需要一个二元分类模型。对我们来说，这很简单，但对于其他产品背景，有多种方法可供选择：
- en: '**Supervised Learning Models**: Requires a labeled dataset to train.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习模型**：需要一个带标签的数据集进行训练。'
- en: '**Classification Models**: Binary classification is simple to implement and
    interpret for stakeholders, making it ideal for a MVP. This comes at the cost
    of more nuanced insights provided by multi-class classification, like a reason
    for delay in our case. However, this often requires more data, meaning higher
    costs and development time.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类模型**：二元分类对于利益相关者来说容易实现和解释，非常适合最小可行产品（MVP）。但这会牺牲多类分类所提供的更细致的见解，比如我们案例中的延迟原因。然而，这通常需要更多的数据，意味着更高的成本和开发时间。'
- en: '**Regression Models**: If the target is a continuous value, like the exact
    time a package will be delayed (e.g., “Your package will be delayed by 20 minutes”),
    a regression model would be the appropriate choice. These outputs are also subject
    to more uncertainty.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归模型**：如果目标是一个连续值，比如包裹延迟的准确时间（例如，“您的包裹将延迟 20 分钟”），回归模型将是合适的选择。这些输出也会受到更多不确定性的影响。'
- en: '**Unsupervised Learning Models**: Works with unlabelled data.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习模型**：处理无标签数据。'
- en: '**Clustering Models**: In the context of delivery delays, clustering could
    be used during the exploratory phase to group deliveries based on similar characteristics,
    such as region or recurring traffic issues. Discovering patterns can inform product
    improvements or guide user segmentation for personalising features/notifications.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类模型**：在包裹延迟的背景下，聚类可以在探索阶段用于根据相似特征（如地区或常见交通问题）对交付进行分组。发现这些模式可以为产品改进提供信息，或指导用户细分，以便个性化功能/通知。'
- en: '**Dimensionality Reduction**: For noisy datasets with a large feature space
    dimensional reduction techniques like Principal Component Analysis (PCA) or autoencoders
    can be used to reduce computational costs and overfitting by allowing for smaller
    models at the cost of some loss in feature context.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：对于具有大量特征空间的噪声数据集，可以使用主成分分析（PCA）或自动编码器等降维技术来减少计算成本和过拟合，通过使用较小的模型来牺牲一些特征上下文的损失。'
- en: '**Generative Models**: Generates new data by training on either labelled and
    unlabelled data.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成模型**：通过对标签数据和无标签数据的训练，生成新的数据。'
- en: '**Generative Adversarial Networks (GANs)**: For us, GANs could be used sparingly
    to simulate rare but impactful delivery delay scenarios, such as extreme weather
    conditions or unforeseen traffic events, if a tolerance to edge cases is required.
    However, these are notoriously difficult to train with high computational costs
    and car must be taken that generated data is realistic. This isn’t typically appropriate
    for early-stage products.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成对抗网络（GANs）**：对于我们来说，GANs可以有限地用于模拟一些稀有但影响深远的配送延迟场景，比如极端天气条件或突发交通事件，前提是需要容忍边缘案例。然而，这些网络因训练难度大、计算成本高而著名，并且需要确保生成的数据具有现实性。对于早期产品来说，这通常不太适用。'
- en: '**Variational Autoencoders (VAEs)**: VAEs have a similar use case to GANs,
    with the added benefit of more control over the range of outputs generated.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变分自编码器（VAEs）**：VAEs的使用场景与GANs相似，具有更高的控制能力，能更好地控制生成输出的范围。'
- en: '**Large Language Models (LLMs)**: If we wanted to incorporate text-based data
    like customer feedback or driver notes into our predictions, LLMs could help generate
    summaries or insights. But, real-time processing is a challenge with heavy computational
    loads.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大语言模型（LLMs）**：如果我们想将基于文本的数据（如客户反馈或司机笔记）纳入预测，LLMs可以帮助生成摘要或洞察。然而，实时处理是一个挑战，尤其是当计算负载很重时。'
- en: '**Reinforcement Learning Models**: These models learn by interacting with an
    environment, receiving feedback through rewards or penalties. For a delivery company,
    reinforcement learning could be used to optimise the system based on the real
    outcome of the delivery. Again, this isn’t really appropriate for an MVP.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习模型**：这些模型通过与环境互动学习，并通过奖励或惩罚来接收反馈。对于一家配送公司，强化学习可以用于根据实际配送结果优化系统。然而，这对于最小可行产品（MVP）来说并不太适合。'
- en: It’s normal for the initial framing of a problem to evolve as we gain insights
    from data exploration and early model training. Therefore, start with a simple,
    interpretable model, to test feasibility. Then, incrementally increase complexity
    by adding more features, tuning hyperparameters, and then explore more complex
    models like ensemble methods or deep learning architectures. This keeps costs
    and development time low while making for a quick go to market.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在问题的初步框架设计中，随着我们从数据探索和早期模型训练中获得洞察，问题的定义会发生变化是很正常的。因此，首先从一个简单、可解释的模型开始，测试可行性。然后，通过增加更多的特征、调整超参数，逐步增加复杂性，再探索更复杂的模型，如集成方法或深度学习架构。这种方式既能保持较低的成本和开发时间，又能快速推向市场。
- en: ML differs significantly from traditional software development when it comes
    to estimating development time, with a large chunk of the work being made up of
    experiments. Where the outcome is always unknown, and so is the number required.
    This means any estimate you provide should have a large contingency baked in,
    or the expectation that it’s subject to change. If the product feature isn’t critical
    we can afford to give tighter time estimates by starting with simple models while
    planning for incremental improvements later.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与传统软件开发在估算开发时间方面有显著区别，工作中的很大一部分是由实验组成的。在实验中，结果总是未知的，所需的实验次数也无法预料。这意味着你提供的任何估算都应该包括较大的预留时间，或者要有这样的期望：它会随时变化。如果产品特性不是至关重要的，我们可以通过从简单模型开始并为后续逐步改进做计划，来提供更紧凑的时间估算。
- en: The time taken to develop your model is a significant cost to any project. In
    my experience, getting results from even a simple model fast, will be massively
    beneficial downstream, allowing you to handover to frontend developers and ops
    teams. To help, I have a few tips. First, fail fast and prioritise experiments
    by least effort, and maximum likelihood of success. Then adjust your plan on the
    go based on what you learn. Although obvious, people do struggle to embrace failure.
    So, be supportive of your team, it’s part of the process. My second tip is, do
    your research! Find examples of similar problems and how they were solved, or
    not. Despite the recent boom in popularity of ML, the field has been around for
    a long time, and 9 times out of 10 someone has solved a problem at least marginally
    related to yours. Keep up with the literature, use sites like Papers with Code,
    daily papers from Hugging Face or AlphaSignal, which provides a nice email newsletter.
    For databases try, Google Scholar, Web of Science or ResearchGate. Frustratingly,
    the cost of accessing major journals is a significant barrier to a comprehensive
    literature review. Sci-Hub…
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 开发模型所需的时间是任何项目中的一项重大成本。根据我的经验，即使是简单模型的快速结果，在后续环节中也会带来巨大好处，允许你将工作交接给前端开发人员和运营团队。为此，我有一些建议。首先，快速失败，优先进行最少工作量、最大成功可能性的实验。然后根据你的学习成果调整计划。虽然这很明显，但人们确实很难接受失败。所以，要支持你的团队，这是过程的一部分。我的第二个建议是，做好调研！查找类似问题的例子以及它们是如何被解决的，或者没有解决的。尽管机器学习最近的火爆趋势让它变得更加流行，但这个领域已经存在很长时间了，而且十有八九已经有人至少在某种程度上解决了与你的问题相关的挑战。保持关注文献，使用像
    Papers with Code、Hugging Face 的每日论文或 AlphaSignal 这样的站点，后者提供了一个很好的邮件通讯。对于数据库，可以尝试
    Google Scholar、Web of Science 或 ResearchGate。令人沮丧的是，获取主要期刊的费用成为了进行全面文献回顾的一个重大障碍。Sci-Hub…
- en: '**Data Requirements**'
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据需求**'
- en: Now that we know what our “black box” will do, what shall we put in it? It’s
    time for data, and from my experience this is the most critical part of the design
    with respect to mitigating risk. The goal is to create an early roadmap for sourcing
    sufficient, relevant, high-quality data. This covers training data, potential
    internal or external sources, and evaluating data relevance, quality, completeness,
    and coverage. Address privacy concerns and plan for data collection, storage,
    and preprocessing, while considering strategies for limitations like class imbalances.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们的“黑盒”会做什么，那么我们应该往里面放什么呢？是时候考虑数据了，根据我的经验，这是设计中最关键的一部分，关系到降低风险。目标是为获取足够的、相关的、高质量的数据创建一个早期的路线图。这包括训练数据、潜在的内部或外部数据源，以及评估数据的相关性、质量、完整性和覆盖范围。处理隐私问题，并规划数据的收集、存储和预处理，同时考虑应对类不平衡等限制的策略。
- en: Without proper accounting for the data requirements of a project, you risk exploding
    budgets and never fully delivering, take Tesla AutoPilot as one such example.
    Their challenge with data collection highlights the risks of underestimating real-world
    data needs. From the start, the system was limited by the data captured from early
    adopters vehicles, which to date, has lacked the sensor depth required for true
    autonomy ([https://spectrum.ieee.org/tesla-autopilot-data-deluge](https://spectrum.ieee.org/tesla-autopilot-data-deluge)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有充分考虑项目的数据需求，你将面临预算爆炸并且永远无法完全交付的风险，特斯拉自动驾驶就是一个这样的例子。他们在数据收集方面的挑战突显了低估实际数据需求的风险。从一开始，系统就受到早期采用者车辆所捕获数据的限制，至今仍然缺乏实现真正自动驾驶所需的传感器深度（[https://spectrum.ieee.org/tesla-autopilot-data-deluge](https://spectrum.ieee.org/tesla-autopilot-data-deluge)）。
- en: Data sourcing is made significantly easier if the feature you’re developing
    is already part of a manual process. If so, you’ll likely have existing datasets
    and a performance benchmark. If not, look internally. Most organisations capture
    vast amounts of data, this could be system logs, CRM data or user analytics. Remember
    though, garbage in, garbage out! Datasets not built for ML from the beginning
    often lack the quality required for training. They might not be rich enough, or
    fully representative of the task at hand.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在开发的功能已经是手动过程的一部分，那么数据源的获取会变得容易得多。如果是这样，你可能已经有现有的数据集和性能基准。如果没有，可以从内部寻找。大多数组织都会收集大量的数据，可能是系统日志、CRM
    数据或用户分析。然而请记住，垃圾进，垃圾出！如果数据集从一开始就没有为机器学习构建，通常会缺乏训练所需的质量。它们可能不够丰富，或无法完全代表手头的任务。
- en: If unsuccessful, you’ll have to look externally. Start with high-quality public
    repositories specifically designed for ML, such as Kaggle, UCI ML Repository and
    Google Dataset Search.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不成功，你需要向外部寻求帮助。从专为机器学习设计的高质量公开数据集开始，如 Kaggle、UCI ML 数据库和 Google Dataset Search。
- en: If problem-specific data isn’t available, try more general publicly available
    datasets. Look through data leaks like the Enron email dataset (for text analysis
    and natural language processing), government census data (for population-based
    studies), or commercially released datasets like the IMDb movie review dataset
    (for sentiment analysis). If that fails, you can start to aggregate from multiple
    sources to create an enriched dataset. This might involve pulling data from spreadsheets,
    APIs, or even scraping the web. The challenge for both cases is to ensure your
    data is clean, consistent, and appropriately formatted for ML purposes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特定问题的数据不可用，可以尝试更一般的公开数据集。浏览像恩隆邮件数据集（用于文本分析和自然语言处理）、政府人口普查数据（用于基于人口的研究）或商业发布的数据集，如
    IMDb 电影评论数据集（用于情感分析）等数据泄漏。如果这也失败了，你可以开始从多个来源汇总数据来创建一个丰富的数据集。这可能涉及从电子表格、API，甚至是爬取网页中提取数据。无论哪种情况，挑战在于确保你的数据是干净的、一致的，并且格式适合机器学习的用途。
- en: Worst case, you’re starting from scratch and need to collect your own raw data.
    This will be expensive and time-consuming, especially when dealing with unstructured
    data like video, images, or text. For some cases data collection can automated
    by conducting surveys, setting up sensors or IoT devices or even launching crowd
    sourced labelling challenges.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最坏的情况是，你从零开始，需要自己收集原始数据。特别是处理视频、图像或文本等非结构化数据时，这将非常昂贵且耗时。在某些情况下，数据收集可以通过进行调查、设置传感器或物联网设备，甚至发起众包标签挑战来实现自动化。
- en: Regardless, manual labelling is almost always necessary. There are many highly
    recommended, off the shelf solutions here, including LabelBox, Amazon SageMaker
    Ground Truth and Label Studio. Each of these can speed up labelling and help maintain
    quality, even across large datasets with random sampling.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，手动标注几乎总是必要的。这里有许多高度推荐的现成解决方案，包括 LabelBox、Amazon SageMaker Ground Truth
    和 Label Studio。它们都能加速标注过程，并帮助维持质量，即使在随机抽样的大数据集上也是如此。
- en: If it’s not clear already, as you move from internal sources to manual collection;
    the cost and complexity of building a dataset appropriate for ML grows significantly,
    and so does the risk for your project. While this isn’t a project-killer, it’s
    important to take into account what your timelines and budgets allow. If you can
    only collect a small dataset you’ll likely be restricted to smaller model solutions,
    or the fine tuning of foundation models from platforms like Hugging Face and Ollama.
    In addition, ensure you have a costed contingency for obtaining more data later
    in the project. This is important because understanding how much data is required
    for your project can only be answered by solving the ML problem. Therefore, mitigate
    the risk upfront by ensuring you have a route to gathering more. It’s common to
    see back-of-the-napkin calculations quoted as a reasonable estimate for how much
    data is required. But, this really only applies to very well understood problems
    like image classification and classical ML problems.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还不清楚，随着你从内部数据源转向手动收集数据，构建适合机器学习的数据库的成本和复杂性会显著增加，项目的风险也会随之增加。虽然这不是项目的致命问题，但考虑你的时间表和预算限制是非常重要的。如果你只能收集一个小数据集，你可能只能采用较小的模型解决方案，或者对像
    Hugging Face 和 Ollama 这样的基础模型进行微调。此外，确保你有一笔额外的预算来应对项目后期获取更多数据的需要。这一点很重要，因为理解项目所需的数据量只能通过解决机器学习问题来获得答案。因此，通过确保你有途径获取更多数据来提前缓解风险。常见的做法是引用“餐巾纸背面的估算”作为数据需求的合理估计。但这实际上只适用于一些非常明确的问题，如图像分类和传统的机器学习问题。
- en: If it becomes clear you won’t be able to gather enough data, there has been
    some limited success with generative models for producing synthetic training data.
    Fraud detection systems developed by American Express have used this technique
    to simulate card numbers and transactions in order to detect discrepancies or
    similarities with actual fraud ([https://masterofcode.com/blog/generative-ai-for-fraud-detection](https://masterofcode.com/blog/generative-ai-for-fraud-detection)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果明显无法收集足够的数据，生成模型在产生合成训练数据方面取得了一些有限的成功。例如，美国运通公司开发的欺诈检测系统就采用了这种技术，通过模拟卡号和交易来检测与实际欺诈的差异或相似之处
    ([https://masterofcode.com/blog/generative-ai-for-fraud-detection](https://masterofcode.com/blog/generative-ai-for-fraud-detection))。
- en: 'Once a basic dataset has been established you’ll need to understand the quality.
    I have found manually working the problem to be very effective. Providing insight
    into useful features and future challenges, while setting realistic expectations
    for model performance. All while uncovering data quality issues and gaps in coverage
    early on. Get hands on with the data and build up domain knowledge while taking
    note of the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦建立了基础数据集，你需要了解其质量。我发现手动操作问题非常有效。它能提供关于有用特征和未来挑战的洞察，同时为模型性能设定现实的期望。在这个过程中，你还能早期发现数据质量问题和覆盖范围的漏洞。动手处理数据，积累领域知识，并注意以下几点：
- en: '**Data relevance**: Ensure the available data reflects your attempts to solve
    the problem. For our example, traffic reports and delivery distances are useful,
    but customer purchase history may be irrelevant. Identifying the relevance of
    data helps reduce noise, while allowing smaller data sets and models to be more
    effective.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的相关性**：确保现有数据能反映你解决问题的努力。以我们的例子为例，交通报告和配送距离是有用的，但客户购买历史可能并不相关。识别数据的相关性有助于减少噪音，同时让较小的数据集和模型更有效。'
- en: '**Data quality**: Pay attention to any biases, missing data, or anomalies that
    you find, this will be useful when building data preprocessing pipelines later
    on.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量**：注意任何你发现的偏差、缺失数据或异常情况，这对后续构建数据预处理管道非常有用。'
- en: '**Data completeness and coverage**: Check the data sufficiently covers all
    relevant scenarios. For our example, data might be required for both city centres
    and more rural areas, failing to account for this impacts the model’s ability
    to generalise.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的完整性和覆盖面**：检查数据是否充分覆盖所有相关的场景。以我们的例子为例，数据可能需要涵盖城市中心和更为偏远的地区，忽略这一点会影响模型的泛化能力。'
- en: '**Class imbalance**: Understand the distribution of classes or the target variable
    so that you can collect more data if possible. Hopefully for our case, “delayed”
    packages will be a rare event. While training we can implement cost-sensitive
    learning to counter this. Personally, I have always had more success oversampling
    minority classes with techniques like SMOTE (Synthetic Minority Over-sampling
    Technique) or Adaptive Synthetic (ADASYN) sampling.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别不平衡**：了解类别或目标变量的分布，以便在可能的情况下收集更多数据。希望在我们的案例中，“延迟”包裹将是一个稀有事件。在训练过程中，我们可以实施成本敏感学习来应对这一点。就个人而言，我总是通过像SMOTE（合成少数类过采样技术）或自适应合成（ADASYN）采样等技术，在过采样少数类时获得更多成功。'
- en: '**Timeliness of data**: Consider how up-to-date the data needs to be for accurate
    predictions. For instance, it might be that real-time traffic data is required
    for the most accurate predictions.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的时效性**：考虑数据需要多么实时才能做出准确的预测。例如，可能需要实时交通数据才能做出最准确的预测。'
- en: When it comes to a more comprehensive look at quality, Exploratory Data Analysis
    (EDA) is the way to uncover patterns, spot anomalies, and better understand data
    distributions. I will cover EDA in more detail in a separate post, but visualising
    data trends, using correlation matrices, and understanding outliers can reveal
    potential feature importance or challenges.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到更全面的质量分析时，探索性数据分析（EDA）是发现模式、识别异常以及更好理解数据分布的有效方法。我将在另外一篇文章中详细介绍EDA，但通过可视化数据趋势、使用相关性矩阵以及理解异常值，可以揭示潜在的特征重要性或挑战。
- en: Finally, think beyond just solving the immediate problem — consider the long-term
    value of the data. Can it be reused for future projects or scaled for other models?
    For example, traffic and delivery data could eventually help optimise delivery
    routes across the whole logistics chain, improving efficiency and cutting costs
    in the long run.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，考虑不仅仅是解决眼前的问题——要考虑数据的长期价值。它是否可以用于未来的项目或扩展到其他模型？例如，交通和配送数据最终可以帮助优化整个物流链中的配送路线，从而提高效率并在长远来看降低成本。
- en: '**Success Metrics — Finding Good Enough**'
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**成功指标——找到足够好**'
- en: When training models, quick performance gains are often followed by a phase
    of diminishing returns. This can lead to directionless trial-and-error while killing
    morale. The solution? Define “good enough” training metrics from the start, such
    that you meet the minimum threshold to deliver the business goals for the project.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，快速的性能提升往往会伴随着收益递减的阶段。这可能导致没有方向的试验和错误，同时打击士气。解决方案是什么？从一开始就定义“足够好”的训练指标，以确保达到最小的阈值，从而实现项目的业务目标。
- en: Setting acceptable thresholds for these metrics requires a broad understanding
    of the product and soft skills to communicate the gap between technical and business
    perspectives. Within agile methodologies, we call these acceptance criteria. Doing
    so allows us to ship quick to the minimum spec and then iterate.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为这些指标设定可接受的阈值需要对产品有广泛的了解，并具备沟通技术与业务观点之间差距的软技能。在敏捷方法中，我们将这些称为验收标准。这样做可以让我们快速推出最低规格的版本，然后进行迭代。
- en: '**What are business metrics?** Business metrics are the real measure of success
    for any project. These could be reducing customer support costs or increasing
    user engagement, and are measured once the product is live, hence referred to
    as online metrics. For our example, 80% accuracy might be acceptable if it reduces
    customer service costs by 15%. In practice, you should track a single model with
    a single business metric, this keeps the project focused and avoids ambiguity
    about when you have successfully delivered. You’ll also want to establish how
    you track this metrics, look for internal dashboards and analytics that business
    teams should have available, if they’re not, maybe it’s not a driver for the business.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是业务指标？** 业务指标是衡量任何项目成功的真正标准。这些可以是降低客户支持成本或增加用户参与度，并在产品上线后进行衡量，因此也称为线上指标。在我们的例子中，如果准确率为80%，但能减少15%的客户服务成本，那可能是可以接受的。实际上，您应该使用单一模型和单一业务指标进行跟踪，这样可以保持项目的专注，并避免在何时成功交付的问题上产生歧义。您还需要确定如何跟踪这些指标，查找业务团队应该能够访问的内部仪表盘和分析工具，如果没有，可能就不是业务的驱动力。'
- en: '**Balancing business and technical metrics**: Finding a “good enough” performance
    starts with understanding the distribution of events in the real world, and then
    relating this to how it impacts users (and hence the business). Take our courier
    example, we expect delayed packages to be a rare event, and so for our binary
    classifier there is a class imbalance. This makes accuracy alone inappropriate
    and we need to factor in how our users respond to predictions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**平衡业务和技术指标**：找到一个“足够好”的性能，首先要理解现实世界中事件的分布，然后将其与用户（因此也影响业务）的反应联系起来。以我们的快递员示例为例，我们期望延迟的包裹是一个罕见事件，因此对于我们的二分类器来说，存在类别不平衡。这使得仅使用准确度不合适，我们需要考虑用户对预测的反应：'
- en: '**False positives** (predicting a delay when there isn’t one) could generate
    annoying notifications for customers, but when a package subsequently arrives
    on time, the inconvenience is minor. Avoiding false positives means prioritising
    high precision.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（预测存在延迟但实际上没有）可能会给客户带来烦人的通知，但当包裹随后按时到达时， inconvenience 很小。避免假阳性意味着优先考虑高精度。'
- en: '**False negatives** (failing to predict a delay) are likely to cause much higher
    frustration when customers don’t receive a package without warning, reducing the
    chance of repeat business and increasing customer support costs. Avoiding false
    negatives means prioritising high recall.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（未能预测到延迟）很可能会导致更高的客户挫败感，因为客户没有收到包裹且没有提前警告，降低了重复业务的机会，并增加了客户支持成本。避免假阴性意味着优先考虑高召回率。'
- en: For our example, it’s likely the business values high recall models. Still,
    for models less than 100% accurate, a balance between precision and recall is
    still necessary (we can’t notify every customer their package is delayed). This
    trade off is best illustrated with an ROC curve. For all classification problems,
    we measure a balance of precision and recall with the F1 score, and for imbalanced
    classes we can extend this to a weighted F1 score.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，业务可能更看重高召回率的模型。然而，对于准确度不足100%的模型，仍然需要在精度和召回率之间取得平衡（我们不能通知每个客户包裹延迟）。这种权衡最适合通过ROC曲线来说明。对于所有分类问题，我们通过F1得分来衡量精度和召回率的平衡，对于不平衡的类别，我们可以扩展为加权F1得分。
- en: Balancing precision and recall is a fine art, and can lead to unintended consequences
    for your users. To illustrate this point consider a services like Google calendar
    that offers both company and personal user accounts. In order to reduce the burden
    on businesses that frequently receive fake meeting requests, engineers might prioritise
    high precision spam filtering. This ensures most fake meetings are correctly flagged
    as spam, at the cost of lower recall, where some legitimate meetings will be mislabeled
    as spam. However, for personal accounts, receiving fake meeting requests is far
    less common. Over the lifetime of the account, the risk of a legitimate meeting
    being flagged becomes significant due to the trade-off of a lower recall model.
    Here, the negative impact on the user’s perception of the service is significant.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 平衡精度和召回率是一门精细的艺术，可能会对用户产生意想不到的后果。为了说明这一点，考虑像 Google 日历这样的服务，它提供公司和个人用户账户。为了减少经常收到假会议请求的企业的负担，工程师可能会优先考虑高精度的垃圾邮件过滤。这确保了大多数假会议会被正确标记为垃圾邮件，但也会以较低的召回率为代价，导致一些合法会议被错误标记为垃圾邮件。然而，对于个人账户来说，收到假会议请求的情况要少得多。随着账户使用时间的增长，由于模型召回率较低，合法会议被错误标记的风险变得显著。在这种情况下，用户对服务的负面看法会变得非常重要。
- en: 'If we consider our courier example as a regression tasks, with the aim of predicting
    a delay time, metrics like MAE and MSE are the choices, with slightly different
    implications for your product:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将我们的快递员示例视为回归任务，目标是预测延迟时间，那么像 MAE 和 MSE 这样的指标是合适的选择，它们对你的产品有略微不同的含义：
- en: '**Mean Absolute Error (MAE)**: This is fairly intuitive measure of how close
    the average prediction is to the actual value. Therefore a simple indicator for
    the accuracy of delay estimates sent to users.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**平均绝对误差（MAE）**：这是一个直观的指标，用于衡量平均预测值与实际值的接近程度。因此，它是一个简单的指标，用于评估发送给用户的延迟估计的准确性。'
- en: '**Mean Squared Error (MSE)**: This penalises larger errors more heavily due
    to the squaring of differences, and therefore important if significant errors
    in delay predictions are deemed more costly to user satisfaction. However, this
    does mean the metric is more sensitive to outliers.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**均方误差（MSE）**：由于差异被平方，这会更加惩罚较大的错误，因此如果延迟预测中的重大错误对用户满意度的影响更大，MSE 就显得很重要。然而，这也意味着该指标对离群值更为敏感。'
- en: As stated above, this is about translating model metrics into terms everyone
    can understand and communicating trade-offs. This is a collaborative process,
    as team members closer to the users and product will have a better understanding
    of the business metrics to drive. Find the single model metric that points the
    project in the same direction.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，这是将模型指标转化为每个人都能理解的术语，并传达权衡的过程。这是一个协作过程，因为与用户和产品更接近的团队成员会更好地理解需要推动的业务指标。找到那个能够指引项目朝着同一方向前进的单一模型指标。
- en: One final point, I have seen a tendency for projects involving ML to overpromise
    on what can be delivered. Generally this comes from the top of an organisation,
    where hype is generated for a product or amongst investors. This is detrimental
    to a project and your sanity. Your best chance to counter this is by communicating
    in your design realistic expectations that match the complexity of the problem.
    It’s always better to underpromise and overdeliver.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点，我发现涉及机器学习的项目往往会过度承诺可以交付的内容。通常这种现象来自组织的高层，在那里产品或投资者之间会产生炒作。这对项目和你的理智都是不利的。应对这种情况的最佳方法是通过在设计中沟通现实的期望值，这些期望值与问题的复杂性相匹配。永远记住，承诺少一些，交付多一些总是更好。
- en: '**High Level System Design**'
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**高层系统设计**'
- en: At this point, we’ve covered data, models, and metrics, and addresses how we
    will approach our functional requirements. Now, it’s time to focus on non-functional
    requirements, specifically scalability, performance, security, and deployment
    strategies. For ML systems, this involves documenting the system architecture
    with system-context or data-flow diagrams. These diagrams represent key components
    as blocks, with defined inputs, transformations, and outputs. Illustrating how
    different parts of the system interact, including data ingestion, processing pipelines,
    model serving, and user interfaces. This approach ensures a modular system, allowing
    teams to isolate and address issues without affecting the entire pipeline, as
    data volume or user demand grows. Therefore, minimising risks related to bottlenecks
    or escalating costs.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了数据、模型和指标，并讨论了如何处理我们的功能需求。现在，是时候关注非功能需求，特别是可扩展性、性能、安全性和部署策略了。对于机器学习系统，这涉及到使用系统上下文或数据流图来记录系统架构。这些图表将关键组件表示为模块，定义了输入、转换和输出。展示系统各部分如何交互，包括数据摄取、处理管道、模型服务和用户界面。通过这种方式，确保了系统的模块化，使得团队可以在不影响整个管道的情况下，隔离并解决问题，随着数据量或用户需求的增长，从而最小化瓶颈或成本上升相关的风险。
- en: 'Once our models are trained we need a plan for deploying the model into production,
    allowing it to be accessible to users or downstream systems. A common method is
    to expose your model through a REST API that other services or front-end can request.
    For real-time applications, serverless platforms like AWS Lambda or Google Cloud
    Functions are ideal for low latency (just manage your cold starts). If high-throughput
    is a requirement then use batch processing with scalable data pipelines like AWS
    Batch or Apache Spark. We can breakdown the considerations for ML system design
    into the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的模型训练完成，我们需要有一个计划，将模型部署到生产环境，使其能够被用户或下游系统访问。常见的方法是通过REST API暴露模型，其他服务或前端可以进行请求。对于实时应用，像AWS
    Lambda或Google Cloud Functions这样的无服务器平台非常适合低延迟（只需管理冷启动）。如果吞吐量是一个要求，那么可以使用批处理处理和可扩展的数据管道，如AWS
    Batch或Apache Spark。我们可以将机器学习系统设计的考虑因素分解为以下几项：
- en: '**Infrastructure and Scalability:**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**基础设施和可扩展性：**'
- en: 'Firstly, we need to make a choice about system infrastructure. Specifically,
    where will we deploy our system: on-premise, in the cloud, or as a hybrid solution.
    Cloud platforms, such as AWS or Google Cloud offer automated scaling in response
    to demand both vertically (bigger machines) and horizontally (adding more machines).
    Think about how the system would handle 10x or 100x the data volume. Netflix provides
    excellent insight via there technical blog for how they operate at scale. For
    instance, they have open sourced there container orchestration platform Titus,
    which automates deployment of thousands of containers across AWS EC2 instances
    using Autoscaling groups ([https://netflixtechblog.com/auto-scaling-production-services-on-titus-1f3cd49f5cd7](https://netflixtechblog.com/auto-scaling-production-services-on-titus-1f3cd49f5cd7)).
    Sometimes on-premises infrastructure is required if you’re handling sensitive
    data. This provides more control over security while being costly to maintain
    and scale. Regardless, prepare to version control your infrastructure with infrastructure-as-code
    tools like Terraform and AWS CloudFormation and automate deployment.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要选择系统的基础设施。具体来说，我们将把系统部署在哪里：本地、云端，还是作为一种混合解决方案。云平台，如AWS或Google Cloud，提供了基于需求的自动扩展，既可以垂直扩展（更大的机器），也可以水平扩展（增加更多的机器）。考虑系统如何应对10倍或100倍的数据量。Netflix通过他们的技术博客提供了关于如何在大规模下运作的宝贵见解。例如，他们开源了他们的容器编排平台Titus，Titus自动化了在AWS
    EC2实例上通过自动扩展组部署成千上万的容器（[https://netflixtechblog.com/auto-scaling-production-services-on-titus-1f3cd49f5cd7](https://netflixtechblog.com/auto-scaling-production-services-on-titus-1f3cd49f5cd7)）。有时候，如果处理敏感数据，可能需要本地基础设施。这能提供更好的安全控制，但在维护和扩展时成本较高。无论如何，准备好使用基础设施即代码工具（如Terraform和AWS
    CloudFormation）对基础设施进行版本控制，并实现自动化部署。
- en: '**Performance (Throughput and Latency):**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能（吞吐量和延迟）：**'
- en: For real-time predictions, performance is critical. Two key metrics to consider,
    throughput measuring how many requests your system can handle per second (i.e.,
    requests per second), and latency, measuring long how long it takes to return
    a prediction. If you expect to make repeated predictions with the same inputs
    then consider adding caching for either part or all the pipeline to reduce latency.
    In general, horizontal scaling is preferred in order to respond to spikes in traffic
    at peak times, and reducing single point bottlenecks. This highlights how key
    decisions taken during your system design process will have direct implications
    on performance. Take Uber, who built their core service around Cassandra database
    specifically to optimise for low latency real-time data replication, ensuring
    quick access to relevant data. ([https://www.uber.com/en-GB/blog/how-uber-optimized-cassandra-operations-at-scale/](https://www.uber.com/en-GB/blog/how-uber-optimized-cassandra-operations-at-scale/)).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实时预测，性能至关重要。有两个关键指标需要考虑：吞吐量，衡量系统每秒能够处理的请求数量（即每秒请求数）；延迟，衡量返回预测所需的时间。如果你预期使用相同的输入进行多次预测，则可以考虑为部分或整个管道添加缓存，以减少延迟。通常，水平扩展更为优先，以便在高峰时期响应流量激增并减少单点瓶颈。这强调了在系统设计过程中做出的关键决策将直接影响性能。例如，Uber围绕
    Cassandra 数据库构建了他们的核心服务，专门优化低延迟实时数据复制，确保快速访问相关数据。([https://www.uber.com/en-GB/blog/how-uber-optimized-cassandra-operations-at-scale/](https://www.uber.com/en-GB/blog/how-uber-optimized-cassandra-operations-at-scale/))。
- en: '**Security:**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**安全性：**'
- en: For ML systems security applies to API authentication for user requests. This
    is relatively standard with methods like OAuth2, and protecting endpoints with
    rate limiting, blocked IP address lists and following OWASP standards. Additionally,
    ensure that any stored user data is encrypted at rest and flight with strict access
    control polices for both internal and external users is in place.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习系统，安全性适用于用户请求的 API 认证。这通常是标准的做法，采用像 OAuth2 这样的认证方法，并通过速率限制、阻止 IP 地址列表和遵循
    OWASP 标准来保护端点。此外，确保任何存储的用户数据在静态和传输过程中都经过加密，并且对于内部和外部用户都实施严格的访问控制策略。
- en: '**Monitoring and Alerts:**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控与警报：**'
- en: It’s also key to consider monitoring for maintaining system health. Track key
    performance indicators (KPIs) like throughput, latency, and error rates, while
    alerts are setup to notify engineers if any of these metrics fall below acceptable
    thresholds. This can be done server-side (e.g., your model endpoint) or client-side
    (e.g., the users end) to include network latency.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，考虑监控以维护系统健康至关重要。跟踪关键性能指标（KPI），如吞吐量、延迟和错误率，并设置警报，以便在这些指标低于可接受的阈值时通知工程师。这可以在服务器端（例如你的模型端点）或客户端（例如用户端）进行，以包括网络延迟。
- en: '**Cost Considerations:**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本考虑：**'
- en: In return for simple infrastructure management the cost of cloud-based systems
    can quickly spiral. Start by estimating the number of instances required for data
    processing, model training, and serving, and balance these against project budgets
    and growing user demands. Most cloud platforms provide cost-management tools to
    help you keep track of spending and optimise resources.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化基础设施管理，基于云的系统成本可能迅速增加。首先估算处理数据、模型训练和服务所需的实例数量，并将这些与项目预算和不断增长的用户需求进行平衡。大多数云平台提供成本管理工具，帮助你跟踪支出并优化资源。
- en: '**MLOps:**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLOps：**'
- en: From the beginning include a plan to efficiently manage model lifecycle. The
    goal is to accelerate model iteration, automate deployment, and maintain robust
    monitoring for metrics and data drift. This allows you to start simple and iterate
    fast! Implement version control with Git for code and DVC (Data Version Control)
    for tracking data model artefact changes. Tools like MLFlow or Weights & Biases
    track experiments, while CI/CD pipelines automate testing and deployment. Once
    deployed, models require real-time monitoring with tools like Promethes and Grafana
    to detect issues like data drift.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从一开始就要包含一个有效管理模型生命周期的计划。目标是加速模型迭代，自动化部署，并保持对指标和数据漂移的强大监控。这使你能够从简单做起，并迅速进行迭代！使用
    Git 进行代码的版本控制，并使用 DVC（数据版本控制）来跟踪数据模型的变更。像 MLFlow 或 Weights & Biases 这样的工具跟踪实验，而
    CI/CD 管道则自动化测试和部署。一旦部署，模型需要实时监控，使用像 Prometheus 和 Grafana 这样的工具来检测数据漂移等问题。
- en: A high-level system design mitigates risks and ensures your team can adapt and
    evolve as the system grows. This means designing a system that is model agnostic
    and ready to scale by breaking down the system into modular components for a robust
    architecture that supports rapid trail and error, scalable deployment, and effective
    monitoring.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 高级系统设计可以降低风险，确保你的团队能够适应并随着系统的成长而演化。这意味着设计一个与模型无关且能够扩展的系统，通过将系统分解为模块化组件，构建一个强大的架构，以支持快速试验与错误、可扩展的部署和有效的监控。
- en: '**Prototyping By Mocking the ML**'
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**通过模拟机器学习进行原型设计**'
- en: We now have an approach for delivering the project requirements, at least from
    an ML perspective. To round our design off, we can now outline a product prototype,
    focusing on the user interface and experience (UI/UX). Where possible, this should
    be interactive, validating whether the feature provides real value to users, ready
    to iterate on the UX. Since we know ML to be time-consuming and resource-intensive,
    you can set aside your model design and prototype without a working ML component.
    Document how you’ll simulate these outputs and test the end-to-end system, detailing
    the tools and methods used for prototyping in your design document. This is important,
    as the prototype will likely be your first chance to gather feedback and refine
    the design, likely evolving into V1.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一种交付项目需求的方法，至少从机器学习的角度来看。为了完善我们的设计，我们现在可以概述一个产品原型，重点关注用户界面和体验（UI/UX）。在可能的情况下，原型应该是互动式的，验证该功能是否能为用户提供真正的价值，准备好在用户体验上进行迭代。由于我们知道机器学习是耗时且资源密集型的，你可以将模型设计和原型放在一边，而无需一个完整的机器学习组件。记录你将如何模拟这些输出，并测试端到端系统，详细描述在设计文档中原型制作所用的工具和方法。这一点非常重要，因为原型可能是你第一次收集反馈并完善设计的机会，可能会发展成V1版本。
- en: To mock our ML we replace predictions with a simple placeholder and simulate
    outputs. This can be as simple as generating random predictions or building a
    rule-based system. Prototyping the UI/UX involves creating mockups with design
    tools like Figma, or prototyping APIs with Postman and Swagger.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟我们的机器学习，我们用一个简单的占位符替代预测并模拟输出。这可以简单地是生成随机预测或构建一个基于规则的系统。原型设计UI/UX涉及使用像Figma这样的设计工具创建原型，或者使用Postman和Swagger进行API原型设计。
- en: Once your prototype is ready, put it in the hands of people, no matter how embarrassed
    you are of it. Larger companies often have resources for this, but smaller teams
    can create their own user panels. I’ve had great success with local universities
    — students love to engage with something new, Amazon vouchers also help! Gather
    feedback, iterate, and start basic A/B testing. As you approach a live product,
    consider more advanced methods like multi-armed bandit testing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的原型准备好，就让人们来体验它，无论你多么害羞。大公司通常有这方面的资源，但小团队也可以自己创建用户小组。我在当地大学取得了很好的成功——学生们喜欢参与新事物，亚马逊购物券也很有帮助！收集反馈，进行迭代，并开始基本的A/B测试。当你接近发布产品时，可以考虑更高级的方法，如多臂老虎机测试。
- en: There is an excellent write up by Apple as an example of mocking ML in this
    way. During user testing of a conversational digital assistant similar to Siri,
    they used human operators to impersonate a prototype assistant, varying responses
    between a conversational style — chatty, non-chatty, or mirror the user’s own
    style. With this approach they showed users preferred assistants that mirror their
    own level of chattiness, improving trustworthiness and likability. All without
    investing in extensive ML development to test UX ([https://arxiv.org/abs/1904.01664](https://arxiv.org/abs/1904.01664)).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果有一篇很好的文章，作为用这种方式模拟机器学习的例子。在类似Siri的对话式数字助手的用户测试中，他们使用人类操作员来模拟一个原型助手，在对话风格上进行变化——如健谈、不健谈或模仿用户的风格。通过这种方式，他们展示了用户更喜欢那些模仿自己健谈程度的助手，从而提高了可信度和可爱度。所有这一切都无需投入大量的机器学习开发来测试用户体验（[https://arxiv.org/abs/1904.01664](https://arxiv.org/abs/1904.01664)）。
- en: From this we see that mocking the ML component puts the emphasis on outcomes,
    allowing us to change output formats, test positive and negative flows and find
    edge cases. We can also gauge the limits of perceived performance and how we manage
    user frustration, this has implications for the complexity of models we can build
    and infrastructure costs. All without concern for model accuracy. Finally, sharing
    prototypes internally helps get buy in from business leaders, nothing sparks support
    and commitment for a project more than putting it people’s hands.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从中我们可以看出，模拟 ML 组件将重点放在结果上，使我们能够更改输出格式，测试正向和负向流程，并找到边缘情况。我们还可以衡量感知性能的限制，以及我们如何管理用户的挫败感，这对我们能够构建的模型的复杂性和基础设施成本有重要影响。所有这一切都不需要考虑模型的准确性。最后，内部分享原型有助于获得业务领导的支持，没有什么比把项目交到人们手中更能激发支持和承诺了。
- en: '**Gather Feedback and Iterate**'
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**收集反馈并进行迭代**'
- en: As you move into development and deployment, you’ll inevitably find that requirements
    evolve and your experiments will throw up the unexpected. You’ll need to iterate!
    Document changes with version control, incorporate feedback loops by revisiting
    the problem definition, re-evaluating data quality, and re-assessing user needs.
    This starts with continuous monitoring, as your product matures look for performance
    degradation by applying statistical tests to detect shifts in prediction distributions
    (data drift). Implement online learning to counter this or if possible bake into
    the UI feedback methods from users to help reveal real bias and build trust, so
    called human-in-the-loop. Actively seek feedback internally first, then from users,
    through interviews and panels understand how they interact with the product and
    how this causes new problems. Use A/B testing to compare select versions of your
    model to understand the impact on user behaviour and the relevant product/business
    metrics.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当你进入开发和部署阶段时，你不可避免地会发现需求发生变化，实验会带来一些意想不到的结果。你需要进行迭代！通过版本控制记录变化，通过重新审视问题定义、重新评估数据质量和重新评估用户需求来整合反馈循环。这一过程从持续监控开始，随着产品的成熟，应用统计测试来检测预测分布的变化（数据漂移），以识别性能退化。实施在线学习来应对这一变化，或者如果可能的话，将用户反馈方法集成到
    UI 中，以帮助揭示真实的偏见并建立信任，所谓的“人机协同”。首先积极寻求内部反馈，然后通过访谈和小组了解用户的反馈，了解他们如何与产品互动以及如何产生新的问题。使用
    A/B 测试来比较你选择的模型版本，了解它对用户行为和相关产品/业务指标的影响。
- en: ML projects benefit from adopting agile methodologies across the model life
    cycle, allowing us to manage the uncertainty and change that is inherent in ML,
    this starts with the planning process. Start small, test quickly, and don’t be
    afraid to fail fast. Applying this to the planning and discovery phase, will reduce
    risk, while delivering a product that not only works but resonates with your users.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ML 项目通过在整个模型生命周期中采用敏捷方法论能够带来好处，帮助我们管理 ML 中固有的不确定性和变化，这一切从规划过程开始。小步开始，快速测试，不要害怕快速失败。将其应用于规划和发现阶段，可以降低风险，同时交付一个不仅有效而且与用户产生共鸣的产品。
