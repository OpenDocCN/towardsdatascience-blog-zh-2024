- en: Some Thoughts on Operationalizing LLM Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于将大型语言模型（LLM）应用落地的一些思考
- en: 原文：[https://towardsdatascience.com/some-thoughts-on-operationalizing-llm-applications-aae3530821a8?source=collection_archive---------5-----------------------#2024-01-27](https://towardsdatascience.com/some-thoughts-on-operationalizing-llm-applications-aae3530821a8?source=collection_archive---------5-----------------------#2024-01-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/some-thoughts-on-operationalizing-llm-applications-aae3530821a8?source=collection_archive---------5-----------------------#2024-01-27](https://towardsdatascience.com/some-thoughts-on-operationalizing-llm-applications-aae3530821a8?source=collection_archive---------5-----------------------#2024-01-27)
- en: A few personal lessons learned from developing LLM applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从开发LLM应用程序中获得的一些个人经验教训
- en: '[](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)[](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page---byline--aae3530821a8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)
    ·10 min read·Jan 27, 2024
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page---byline--aae3530821a8--------------------------------)
    ·阅读时间 10 分钟·2024年1月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/06a99c53d8690f99691bca0f4712d7e1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06a99c53d8690f99691bca0f4712d7e1.png)'
- en: Source DALL·E 3 prompted with “Operationalizing LLMs, watercolor”
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：DALL·E 3 提示语为“Operationalizing LLMs, watercolor”
- en: It’s been fun posting articles exploring new Large Language Model (LLM) techniques
    and libraries as they emerge, but most of the time has been spent behind the scenes
    working on the operationalization of LLM solutions. Many organizations are working
    on this right now, so I thought I’d share a few quick thoughts about my journey
    so far.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 发布关于新型大型语言模型（LLM）技术和库的文章一直很有趣，但大多数时间我都在幕后为LLM解决方案的落地做工作。许多组织现在都在进行这方面的工作，所以我想分享一些我至今为止的经验和思考。
- en: Prototypes are Easy … Production is, well, hard
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原型很容易……但生产环境，嗯，确实很难
- en: It’s beguilingly easy to throw up a quick demo to showcase some of the amazing
    capabilities of LLMs, but anybody who is tasked with putting them in front of
    users with the hope of having a discernible impact soon realizes there’s a lot
    of work required to tame them. Below are some of the key areas that most organizations
    might need to consider.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示大型语言模型（LLM）的一些惊人能力，快速做一个简单的演示看似很容易，但任何被要求将其展示给用户，并希望能产生明显影响的人很快就会意识到，需要做大量的工作来驯服这些模型。以下是大多数组织可能需要考虑的一些关键领域。
- en: '![](../Images/67d97812b8e81b0c6233858040065131.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/67d97812b8e81b0c6233858040065131.png)'
- en: Some of the key areas that should be considered before launching applications
    that use Large Language Models (LLMs).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在推出使用大型语言模型（LLM）的应用程序之前，应该考虑的一些关键领域。
- en: The list isn’t exhaustive (see also [Kadour et al 2023](https://arxiv.org/pdf/2307.10169.pdf)),
    and which of the above applies to your application will of course vary, but even
    solving for safety, performance, and cost can be a daunting prospect.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表并不全面（另见 [Kadour et al 2023](https://arxiv.org/pdf/2307.10169.pdf)），哪些方面适用于你的应用程序当然会有所不同，但即便只是解决安全性、性能和成本问题，都是一项艰巨的任务。
- en: So what can we do about it?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们能为此做些什么呢？
- en: Not all LLM applications are equally scary
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不是所有的LLM应用都同样令人恐惧
- en: There is much concern about the safe use of LLMs, and quite right too. Trained
    on human output they suffer from many of the less favorable aspects of the human
    condition, and being so convincing in their responses raises new issues around
    safety. However, the risk profile is not the same for all cases, some applications
    are much safer than others. Asking an LLM to provide answers directly from its
    training data offers more potential for hallucination and bias than a low-level
    technical use of an [LLM to predict metadata](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d).
    This is an obvious distinction, but worthwhile considering for anybody about to
    build LLM solutions— starting with low-risk applications is an obvious first step
    and reduces the amount of work required for launch.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有很多关于LLM安全使用的担忧，而且这也是完全合理的。由于LLM是基于人类产出的数据进行训练的，因此它们受到了许多人类状况的负面影响，而其回应方式的高度可信度又引发了新的安全问题。然而，风险并非在所有情况下都是相同的，有些应用比其他应用更为安全。例如，让LLM直接从其训练数据中提供答案，比起[低级别技术使用LLM预测元数据](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)，更容易产生幻觉和偏见。这是一个明显的区别，但对于那些准备构建LLM解决方案的人来说，值得考虑——从低风险的应用开始是显而易见的第一步，并且能减少启动所需的工作量。
- en: '![](../Images/d787701e7957466a1f78b093a869bd82.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d787701e7957466a1f78b093a869bd82.png)'
- en: How LLMs are used influences how risky it is to use them
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的使用方式会影响它的风险性
- en: Future-proofing, hedge against hype
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来保障，对抗炒作
- en: We live in incredibly exciting times with so many rapid advances in AI coming
    out each week, but it sure makes building a roadmap difficult! Several times in
    the last year a new vendor feature, open-source model, or Python package has been
    released which has changed the landscape significantly. Figuring out which techniques,
    frameworks, and models to use such that LLM applications maintain value over time
    is challenging. No point in building something fabulous only to have its capabilities
    natively supported for free or very low cost in the next 6 months.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个极为激动人心的时代，每周都有许多快速发展的AI技术问世，但这确实让制定路线图变得困难！在过去的一年里，几次发布了新的供应商功能、开源模型或Python包，这些都显著改变了技术格局。弄清楚使用哪些技术、框架和模型，以确保LLM应用能随着时间的推移保持价值，是一个挑战。如果在未来6个月内，它的功能会以原生免费或非常低的成本得到支持，那就没有意义去打造一个非常棒的应用。
- en: Another key consideration is to ask whether an LLM is actually the best tool
    for the job. With all of the excitement in the last year, it’s easy to get swept
    away and “LLM the heck” out of everything. As with any new technology, using it
    just for the sake of using it is often a big mistake, and as LLM hype adjusts
    one may find our snazzy app becomes obsolete with real-world usage.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键的考虑因素是要问LLM是否真的是解决问题的最佳工具。随着去年各种激动人心的消息，容易让人被冲动带走，什么都想用“LLM来搞定”。和任何新技术一样，仅仅为了使用而使用通常是一个大错误，而随着LLM的热潮逐渐冷却，可能会发现我们炫酷的应用在实际使用中变得过时。
- en: That said, there is no doubt that LLMs can offer some incredible capabilities
    so if forging ahead, here are some ideas that might help …
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，毫无疑问，LLM可以提供一些令人难以置信的能力，因此，如果继续前进，以下是一些可能有用的建议……
- en: Adopt a “Cheap LLM First” Policy
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 采用“廉价LLM优先”策略
- en: In web design there is the concept of [mobile-first](https://medium.com/@Vincentxia77/what-is-mobile-first-design-why-its-important-how-to-make-it-7d3cf2e29d00),
    to develop web applications that work on less functional phones and tablets first,
    *then* figure out how to make things work nicely on more flexible desktop browsers.
    Doing things this way around can sometimes be easier than the converse. A similar
    idea can be applied to LLM applications — where possible try and develop them
    so that they work with cheaper, faster, and lower-cost models from the outset,
    such as GPT-3.5-turbo instead of GPT-4\. These models are a fraction of the cost
    and will often force the design process towards more elegant solutions that break
    the problem down into simpler parts with less reliance on monolithic lengthy prompts
    to expensive and slow models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在网页设计中有一个概念叫做[移动优先](https://medium.com/@Vincentxia77/what-is-mobile-first-design-why-its-important-how-to-make-it-7d3cf2e29d00)，即首先开发在功能较弱的手机和平板上能运行的网页应用，*然后*再考虑如何在更灵活的桌面浏览器上优化。这样做有时比反过来做更容易。类似的想法可以应用于LLM应用——在可能的情况下，尽量从一开始就使其与更便宜、更快速、成本更低的模型兼容，例如GPT-3.5-turbo，而不是GPT-4。这些模型的成本仅为前者的一小部分，而且通常会迫使设计过程朝向更加优雅的解决方案，将问题分解成更简单的部分，减少对昂贵且缓慢的模型的依赖。
- en: Of course, this isn’t always feasible and those advanced LLMs exist for a reason,
    but many key functions can be supported with less powerful LLMs — simple intent
    classification, planning, and memory operations. It may also be the case that
    careful design of your workflows can open the possibility of different streams
    where some use less powerful LLMs and others more powerful (I’ll be doing a later
    blog post on this).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这并非总是可行的，而那些先进的LLM存在是有原因的，但许多关键功能可以通过较不强大的LLM来支持——如简单的意图分类、规划和记忆操作。也有可能，通过精心设计工作流，可以开辟不同的流，其中一些使用较不强大的LLM，另一些则使用更强大的LLM（我会在之后的博客文章中讨论这个话题）。
- en: Down the road when those more advanced LLMs become cheaper and faster, you can
    then swap out the more basic LLMs and your application may magically improve with
    very little effort!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，当那些更先进的LLM变得更便宜、更快速时，你可以将更基础的LLM替换掉，而你的应用程序可能会在几乎不需要额外努力的情况下奇迹般地改善！
- en: '**Avoid native APIs, use generic interfaces instead**'
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**避免使用本地API，而应使用通用接口**'
- en: It is a good software engineering approach to use a generic interface where
    possible. For LLMs, this can mean using a service or Python module that presents
    a fixed interface that can interact with multiple LLM providers. A great example
    is [langchain](https://www.langchain.com/) which offers integration with a [wide
    range of LLMs](https://python.langchain.com/docs/integrations/llms/). By using
    Langchain to communicate with LLMs from the outset and not native LLM APIs, we
    can swap out different models in the future with minimal effort.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用通用接口是一种良好的软件工程方法。在LLM的情况下，这意味着使用一个服务或Python模块，它提供一个固定接口，可以与多个LLM提供商进行交互。一个很好的例子是[langchain](https://www.langchain.com/)，它提供与[多种LLM的集成](https://python.langchain.com/docs/integrations/llms/)。通过从一开始就使用Langchain与LLM进行通信，而不是使用本地LLM
    API，我们可以在未来以最小的努力更换不同的模型。
- en: Another example of this is to use [autogen](https://microsoft.github.io/autogen/)
    for agents, even if using [OpenAI assistants](https://microsoft.github.io/autogen/blog/2023/11/13/OAI-assistants/).
    That way as other native agents become available, your application can be adjusted
    more easily than if you had built a whole process around OpenAI’s native implementation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是使用[autogen](https://microsoft.github.io/autogen/)为代理提供支持，即使是使用[OpenAI助手](https://microsoft.github.io/autogen/blog/2023/11/13/OAI-assistants/)也是如此。通过这种方式，当其他本地代理可用时，你的应用程序可以比围绕OpenAI的本地实现构建整个流程更容易进行调整。
- en: '**Agents or Chains? You can use both!**'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**代理还是链条？你可以同时使用两者！**'
- en: A common pattern with LLM development is to break down the workflow into a chain
    of conditional steps using frameworks such as [promptflow](https://github.com/microsoft/promptflow).
    Chains are well-defined so we know, more or less, what’s going to happen in our
    application. They are a great place to start and have a high degree of transparency
    and reproducibility. However, they don’t support fringe cases well, that’s where
    groups of autonomous LLM agents can work well as they are able to iterate towards
    a solution and recover from errors (*most* of the time). The issue with these
    is that — for now at least — agents can be a bit slow due to their iterative nature,
    expensive due to LLM token usage, and have a tendency to be a bit wild at times
    and fail spectacularly. They are likely [the future of LLM applications](https://www.ted.com/talks/harrison_chase_the_magical_ai_assistants_of_the_future_and_the_engineering_behind_them)
    though, so it’s a good idea to prepare even if not using them in your application
    right now. By building your workflow as a modular chain, you are in fact doing
    just that! Individual nodes in the workflow can be swapped out to use agents later,
    providing the best of both worlds when needed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LLM开发中的一个常见模式是将工作流拆分为一系列条件步骤，使用诸如[promptflow](https://github.com/microsoft/promptflow)之类的框架。这些链条被明确定义，因此我们大致知道在我们的应用程序中会发生什么。它们是一个很好的起点，具有较高的透明度和可复现性。然而，它们不太适合处理边缘情况，这时自主LLM代理的组合可以很好地工作，因为它们能够迭代地朝着解决方案前进，并且从错误中恢复（*大多数*情况下）。这些代理的问题在于——至少目前——由于其迭代性质，它们可能会有点慢，因LLM令牌的使用而变得昂贵，而且有时会有点失控并且壮观地失败。不过，它们很可能是[LLM应用程序的未来](https://www.ted.com/talks/harrison_chase_the_magical_ai_assistants_of_the_future_and_the_engineering_behind_them)，因此即使现在没有在应用程序中使用它们，做好准备也是一个好主意。通过将工作流构建为模块化链条，你实际上是在做这件事！工作流中的各个节点可以稍后替换为代理，在需要时提供两全其美的解决方案。
- en: It should be noted there are some limitations with this approach, streaming
    of the LLM response becomes more complicated, but depending on your use case the
    benefits may outweigh these challenges.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这种方法存在一些局限性，LLM响应的流式传输变得更加复杂，但根据你的用例，收益可能会超过这些挑战。
- en: '![](../Images/562fe2cf7bb4712df4f30313435d68e3.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/562fe2cf7bb4712df4f30313435d68e3.png)'
- en: Linking together steps in an LLM workflow with [Promtpflow](https://microsoft.github.io/promptflow/).
    This has several advantages, one being that steps can be swapped out with more
    advanced techniques in the future.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Promtpflow](https://microsoft.github.io/promptflow/)将LLM工作流中的各个步骤连接起来。这有几个优点，其中之一是未来可以用更先进的技术替换这些步骤。
- en: Do you really want your application generating code on the fly?
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你真的想让你的应用程序动态生成代码吗？
- en: It is truly amazing to watch autogen agents and Open AI assistants generating
    code and automatically debugging to solve tasks, to me it feels like the future.
    It also opens up amazing opportunities such as LLM As Tool Maker (LATM, [Cai et
    al 2023](https://arxiv.org/abs/2305.17126)), where your application can generate
    its own tools. That said, from my personal experience, so far, code generation
    can be a bit wild. Yes, it’s possible to optimize prompts and implement a validation
    framework, but even if that generated code runs perfectly, is it *right* when
    solving new tasks? I have come across many cases where it isn’t, and it’s often
    quite subtle to catch — the scale on a graph, summing across the wrong elements
    in an array, and retrieving slightly the wrong data from an API. I think this
    will change as LLMs and frameworks advance, but right now, I would be very cautious
    about letting LLMs generate code on the fly in production and instead opt for
    some human-in-the-loop review, at least for now.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 看到自动生成代理和Open AI助手生成代码并自动调试解决任务，真的让人惊叹，我觉得这就像是未来一样。这也开启了像“LLM作为工具制造者”（LATM，[Cai
    et al 2023](https://arxiv.org/abs/2305.17126)）这样的惊人机会，在这种情况下，你的应用程序可以生成自己的工具。话虽如此，根据我个人的经验，到目前为止，代码生成还是有点“狂野”。是的，可以优化提示并实现验证框架，但即使生成的代码完美运行，当解决新任务时，它是否是*正确的*？我遇到过许多不正确的情况，而且通常很难发现——图表的刻度、在数组中加总错误的元素，或者从API中检索到略微错误的数据。我认为随着LLM和框架的进步，这种情况会有所改变，但目前来说，我会对让LLM在生产环境中动态生成代码非常谨慎，至少现在还是倾向于选择一些人工审核的环节。
- en: Start with LLM-enhanced applications rather than LLM-first applications
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从LLM增强型应用程序开始，而不是LLM优先的应用程序
- en: There are of course many use cases that absolutely require an LLM. But to ease
    into things, it might make sense to choose applications where the LLM adds value
    to the process rather than *being* the process. Imagine a web app that presents
    data to a user, already being useful. That application could be enhanced to implement
    LLM improvements for finding and summarizing that data. By placing slightly less
    emphasis on using LLMs, the application is less exposed to issues arising from
    LLM performance. Stating the obvious of course, but it’s easy to dive into generative
    AI without first taking baby steps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有很多用例绝对需要LLM。但是为了更好地适应，选择那些LLM为过程增加价值，而不是*成为*过程的应用程序可能更为合理。想象一下，一个已经对用户有用的网页应用，呈现数据。这款应用可以通过实现LLM改进来提升其数据查找和总结的功能。通过稍微减少对LLM的依赖，应用程序也就能更少暴露于LLM性能带来的问题。显而易见，但在深入探索生成性AI之前，很容易忽视从小处着手。
- en: Don’t forget the … errrr … oh yeah, memory!
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 别忘了……呃……对了，内存！
- en: Prompting LLMs incurs costs and can result in a poor user experience as they
    wait for slow responses. In many cases, the prompt is similar or identical to
    one previously made, so it’s useful to be able to remember past activity for reuse
    without having to call the LLM again. Some great packages exist such as [memgpt](https://memgpt.ai/)
    and [GPTCache](https://github.com/zilliztech/GPTCache) which use document embedding
    [vector store](https://python.langchain.com/docs/modules/data_connection/vectorstores/)s
    to persist ‘memories’. This is the same technology used for the common [RAG document
    retrieval](https://python.langchain.com/docs/use_cases/question_answering/), memories
    are just chunked documents. The slight difference is that frameworks like memgpt
    do some clever things to use LLM to *self-manage* memories.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 向LLM发送提示会产生费用，并可能导致用户在等待响应时体验较差。在许多情况下，提示与之前的请求相似或相同，因此能够记住过去的活动以供重用，而不必重新调用LLM是很有用的。一些很棒的工具包，如[memgpt](https://memgpt.ai/)和[GPTCache](https://github.com/zilliztech/GPTCache)，使用文档嵌入的[向量存储](https://python.langchain.com/docs/modules/data_connection/vectorstores/)来持久化“记忆”。这与常见的[RAG文档检索](https://python.langchain.com/docs/use_cases/question_answering/)技术相同，记忆实际上是分块的文档。稍微不同的是，像memgpt这样的框架做了一些巧妙的事情，利用LLM来*自我管理*记忆。
- en: You may find however that due to a specific use case, you need some form of
    custom memory management. In this scenario, it’s sometimes useful to be able to
    view and manipulate memory records without having to write code. A powerful tool
    for this is [pgvector](https://github.com/pgvector/pgvector) which combines vector
    store capabilities with Postgres relational database for querying, making it easy
    to understand the metadata stored with memories.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能会发现，由于特定的使用场景，你需要某种形式的自定义记忆管理。在这种情况下，有时能够查看和操作记忆记录，而无需编写代码，是很有用的。一款强大的工具是[pgvector](https://github.com/pgvector/pgvector)，它将向量存储能力与Postgres关系型数据库结合起来，以便进行查询，使得理解与记忆相关的元数据变得容易。
- en: Test, test, test
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试，测试，再测试
- en: At the end of the day, whether your application uses LLMs or not it is still
    a software application and so will benefit from standard engineering techniques.
    One obvious approach is to adopt [test-driven development](https://en.wikipedia.org/wiki/Test-driven_development#:~:text=Test%20Driven%20Development%20(TDD)%20is,leading%20to%20more%20robust%20software.).
    This is especially important with LLMs provided by vendors to control for the
    fact that the performance of those LLMs may vary over time, something you will
    need to quantify for any production application. Several validation frameworks
    exist, again promptflow offers some straightforward validation tools and has [native
    support in Microsoft AI Studio](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/prompt-flow).
    There are other testing frameworks out there, the point being, to use one from
    the start for a strong foundation in validation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，无论你的应用是否使用LLM，它仍然是一个软件应用，因此可以从标准的工程技术中受益。一种显而易见的方法是采用[测试驱动开发](https://en.wikipedia.org/wiki/Test-driven_development#:~:text=Test%20Driven%20Development%20(TDD)%20is,leading%20to%20more%20robust%20software.)。这对于由供应商提供的LLM尤为重要，因为你需要控制这些LLM的性能可能随着时间的推移而变化，这是任何生产应用都需要量化的内容。现有几种验证框架，promptflow提供了一些简单的验证工具，并且在[Microsoft
    AI Studio中原生支持](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/prompt-flow)。还有其他测试框架，关键是从一开始就使用某种框架，为验证打下坚实的基础。
- en: That said, it should be noted that LLMs are not deterministic, providing slightly
    different results each time depending on the use case. This has an interesting
    effect on tests in that the expected result isn’t set in stone. For example, testing
    that a summarization task is working as required can be challenging because the
    summary with slightly vary each time. In these cases, it’s often useful to use
    another LLM to evaluate the application LLM’s output. Metrics such as Groundedness,
    Relevance, Coherence, Fluency, GPT Similarity, ADA Similarity can be applied,
    see for example [Azure AI studio’s implementation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/evaluate-generative-ai-app?pivots=ai-studio#select-metrics).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，需要注意的是，LLM并不是确定性的，根据使用场景，每次提供的结果可能会有所不同。这对测试产生了有趣的影响，因为预期结果并非一成不变。例如，测试摘要任务是否按要求工作可能是一个挑战，因为每次的摘要可能略有不同。在这些情况下，通常有用的是使用另一个LLM来评估应用LLM的输出。可以应用一些度量标准，如Groundedness、Relevance、Coherence、Fluency、GPT
    Similarity、ADA Similarity，具体见例如[Azure AI studio的实现](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/evaluate-generative-ai-app?pivots=ai-studio#select-metrics)。
- en: Once you have a set of amazing tests that confirm your application is working
    as expected, you can incorporate them into a DevOps pipeline, for example running
    them in GitHub actions before your application is deployed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拥有了一套出色的测试，能够确认应用程序按预期工作，你可以将它们整合进 DevOps 管道，例如，在应用程序部署前通过 GitHub Actions
    运行这些测试。
- en: Use 3rd party tools and save yourself some work
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用第三方工具，省去一些工作
- en: No one size fits all of course, but for smaller organizations implementing LLM
    applications, developing every aspect of the solution may be a challenge. It might
    make sense to focus on the business logic and work closely with your users while
    using enterprise tools for areas such as LLM safety rather than developing them
    yourself. For example, Azure AI studio has some great features that enable various
    safety checks on LLMs with a click of a button, as well as easy deployment to
    API endpoints with integrating monitoring and safety. Other vendors such as [Google
    have similar offerings](https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并没有一种方案适用于所有情况，但对于实施大型语言模型应用的小型组织来说，开发每个解决方案的各个方面可能是一项挑战。将精力集中在业务逻辑上，并与用户密切合作，同时使用企业工具来处理像大型语言模型安全性这样的领域，而不是自行开发这些工具，可能更为明智。例如，Azure
    AI Studio 提供了一些很棒的功能，可以一键执行大型语言模型的安全检查，并轻松部署到 API 端点，同时集成监控和安全功能。其他供应商，如[谷歌也有类似的产品](https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/)。
- en: There is of course a cost associated with features like this, but it may be
    well worth it as developing them is a significant undertaking.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，像这样的功能是有成本的，但考虑到开发它们是一项重大的工作，它可能非常值得。
- en: '![](../Images/f9abe07e284be607efdc96dd48b0bfd9.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9abe07e284be607efdc96dd48b0bfd9.png)'
- en: '[Azure AI Content Safety Studio](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/studio-quickstart)
    is a great example of a cloud vendor solution to ensure your LLM application is
    safe, with no associated development effort'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure AI 内容安全工作室](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/studio-quickstart)是云供应商解决方案的一个很好的示例，可以确保你的大型语言模型应用安全，而无需任何开发工作。'
- en: Human in the loop, always
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人类参与，始终如此
- en: LLMs are far from being perfect, even the most powerful ones, so any application
    using them must have a human in the loop to ensure things are working as expected.
    For this to be effective all interactions with your LLM application must be logged
    and monitoring tools in place. This is of course no different to any well-managed
    production application, the difference being new types of monitoring to capture
    performance and safety issues.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最强大的大型语言模型，也远未完美，因此任何使用它们的应用程序都必须有人类参与，以确保一切按预期工作。为了实现这一点，所有与大型语言模型应用的互动都必须被记录，并且要有监控工具。这个要求与任何良好管理的生产应用程序并无不同，唯一的区别是需要新的监控方式来捕获性能和安全问题。
- en: Another key role humans can play is to correct and improve the LLM application
    when it makes mistakes. As mentioned above, the ability to view the application’s
    memory can help, especially if the human can make adjustments to the memory, working
    with the LLM to provide end-users with the best experience. Feeding this modified
    data back into prompt tunning of LLM fine-tuning can be a powerful tool in improving
    the application.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 人类可以扮演的另一个关键角色是，当大型语言模型应用出错时进行修正和改进。如上所述，查看应用的内存可以提供帮助，尤其是当人类可以调整内存时，与大型语言模型协作，向最终用户提供最佳体验。将这些修改后的数据反馈到提示调优和大型语言模型微调中，可以成为改进应用程序的强大工具。
- en: Conclusions
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The above thoughts are by no means exhaustive for operationalizing LLMs and
    may not apply to every scenario, but I hope they might be useful for some. We
    are all on an amazing journey right now!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 上述想法并不是操作大型语言模型的详尽指南，可能并不适用于每个场景，但我希望它们对一些人有帮助。我们现在正处于一段令人兴奋的旅程中！
- en: References
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Challenges and Applications of Large Language Models, [Kaddour et al, 2023](https://arxiv.org/pdf/2307.10169.pdf)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的挑战与应用，[Kaddour 等，2023](https://arxiv.org/pdf/2307.10169.pdf)
- en: Large Language Models as Tool Makers, [Cai et al, 2023](https://arxiv.org/abs/2305.17126).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型作为工具制造者，[Cai 等，2023](https://arxiv.org/abs/2305.17126).
- en: Unless otherwise noted, all images are by the author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供
- en: '*Please like this article if inclined and I’d be delighted if you followed
    me! You can find more articles* [*here*](https://medium.com/@astrobagel)*.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，请点赞，我会很高兴如果你关注我！你可以在这里找到更多文章* [*这里*](https://medium.com/@astrobagel)*.*'
